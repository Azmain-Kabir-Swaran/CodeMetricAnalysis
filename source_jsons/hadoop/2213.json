{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSClient.java",
  "functionName": "connectToDN",
  "functionId": "connectToDN___dn-DatanodeInfo__timeout-int__blockToken-Token__BlockTokenIdentifier__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
  "functionStartLine": 1912,
  "functionEndLine": 1917,
  "numCommitsSeen": 479,
  "timeTaken": 9205,
  "changeHistory": [
    "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6",
    "372d1302c63c6f49f99be5766c5da9647ebd9ca6",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8",
    "6ee0539ede78b640f01c5eac18ded161182a7835",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
    "2cc9514ad643ae49d30524743420ee9744e571bd",
    "3b54223c0f32d42a84436c670d80b791a8e9696d",
    "cfae13306ac0fb3f3c139d5ac511bf78cede1b77"
  ],
  "changeHistoryShort": {
    "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
    "372d1302c63c6f49f99be5766c5da9647ebd9ca6": "Ybodychange",
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": "Ybodychange",
    "6ee0539ede78b640f01c5eac18ded161182a7835": "Ybodychange",
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": "Ybodychange",
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": "Yfilerename",
    "2cc9514ad643ae49d30524743420ee9744e571bd": "Ybodychange",
    "3b54223c0f32d42a84436c670d80b791a8e9696d": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
    "cfae13306ac0fb3f3c139d5ac511bf78cede1b77": "Yintroduced"
  },
  "changeHistoryDetails": {
    "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6": {
      "type": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-9733. Refactor DFSClient#getFileChecksum and DataXceiver#blockChecksum. Contributed by Kai Zheng\n",
      "commitDate": "29/02/16 9:52 PM",
      "commitName": "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9733. Refactor DFSClient#getFileChecksum and DataXceiver#blockChecksum. Contributed by Kai Zheng\n",
          "commitDate": "29/02/16 9:52 PM",
          "commitName": "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/02/16 10:31 AM",
          "commitNameOld": "372d1302c63c6f49f99be5766c5da9647ebd9ca6",
          "commitAuthorOld": "Masatake Iwasaki",
          "daysBetweenCommits": 17.47,
          "commitsBetweenForRepo": 116,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,6 @@\n-  private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n-      LocatedBlock lb) throws IOException {\n-    boolean success \u003d false;\n-    Socket sock \u003d null;\n-    try {\n-      sock \u003d socketFactory.createSocket();\n-      String dnAddr \u003d dn.getXferAddr(getConf().isConnectToDnViaHostname());\n-      LOG.debug(\"Connecting to datanode {}\", dnAddr);\n-      NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n-      sock.setTcpNoDelay(dfsClientConf.getDataTransferTcpNoDelay());\n-      sock.setSoTimeout(timeout);\n-\n-      OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n-      InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n-      IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n-          lb.getBlockToken(), dn);\n-      success \u003d true;\n-      return ret;\n-    } finally {\n-      if (!success) {\n-        IOUtils.closeSocket(sock);\n-      }\n-    }\n+  protected IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n+                                     Token\u003cBlockTokenIdentifier\u003e blockToken)\n+      throws IOException {\n+    return DFSUtilClient.connectToDN(dn, timeout, conf, saslClient,\n+        socketFactory, getConf().isConnectToDnViaHostname(), this, blockToken);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n                                     Token\u003cBlockTokenIdentifier\u003e blockToken)\n      throws IOException {\n    return DFSUtilClient.connectToDN(dn, timeout, conf, saslClient,\n        socketFactory, getConf().isConnectToDnViaHostname(), this, blockToken);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {
            "oldValue": "[dn-DatanodeInfo, timeout-int, lb-LocatedBlock]",
            "newValue": "[dn-DatanodeInfo, timeout-int, blockToken-Token\u003cBlockTokenIdentifier\u003e]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-9733. Refactor DFSClient#getFileChecksum and DataXceiver#blockChecksum. Contributed by Kai Zheng\n",
          "commitDate": "29/02/16 9:52 PM",
          "commitName": "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/02/16 10:31 AM",
          "commitNameOld": "372d1302c63c6f49f99be5766c5da9647ebd9ca6",
          "commitAuthorOld": "Masatake Iwasaki",
          "daysBetweenCommits": 17.47,
          "commitsBetweenForRepo": 116,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,6 @@\n-  private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n-      LocatedBlock lb) throws IOException {\n-    boolean success \u003d false;\n-    Socket sock \u003d null;\n-    try {\n-      sock \u003d socketFactory.createSocket();\n-      String dnAddr \u003d dn.getXferAddr(getConf().isConnectToDnViaHostname());\n-      LOG.debug(\"Connecting to datanode {}\", dnAddr);\n-      NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n-      sock.setTcpNoDelay(dfsClientConf.getDataTransferTcpNoDelay());\n-      sock.setSoTimeout(timeout);\n-\n-      OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n-      InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n-      IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n-          lb.getBlockToken(), dn);\n-      success \u003d true;\n-      return ret;\n-    } finally {\n-      if (!success) {\n-        IOUtils.closeSocket(sock);\n-      }\n-    }\n+  protected IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n+                                     Token\u003cBlockTokenIdentifier\u003e blockToken)\n+      throws IOException {\n+    return DFSUtilClient.connectToDN(dn, timeout, conf, saslClient,\n+        socketFactory, getConf().isConnectToDnViaHostname(), this, blockToken);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n                                     Token\u003cBlockTokenIdentifier\u003e blockToken)\n      throws IOException {\n    return DFSUtilClient.connectToDN(dn, timeout, conf, saslClient,\n        socketFactory, getConf().isConnectToDnViaHostname(), this, blockToken);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[protected]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9733. Refactor DFSClient#getFileChecksum and DataXceiver#blockChecksum. Contributed by Kai Zheng\n",
          "commitDate": "29/02/16 9:52 PM",
          "commitName": "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/02/16 10:31 AM",
          "commitNameOld": "372d1302c63c6f49f99be5766c5da9647ebd9ca6",
          "commitAuthorOld": "Masatake Iwasaki",
          "daysBetweenCommits": 17.47,
          "commitsBetweenForRepo": 116,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,6 @@\n-  private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n-      LocatedBlock lb) throws IOException {\n-    boolean success \u003d false;\n-    Socket sock \u003d null;\n-    try {\n-      sock \u003d socketFactory.createSocket();\n-      String dnAddr \u003d dn.getXferAddr(getConf().isConnectToDnViaHostname());\n-      LOG.debug(\"Connecting to datanode {}\", dnAddr);\n-      NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n-      sock.setTcpNoDelay(dfsClientConf.getDataTransferTcpNoDelay());\n-      sock.setSoTimeout(timeout);\n-\n-      OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n-      InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n-      IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n-          lb.getBlockToken(), dn);\n-      success \u003d true;\n-      return ret;\n-    } finally {\n-      if (!success) {\n-        IOUtils.closeSocket(sock);\n-      }\n-    }\n+  protected IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n+                                     Token\u003cBlockTokenIdentifier\u003e blockToken)\n+      throws IOException {\n+    return DFSUtilClient.connectToDN(dn, timeout, conf, saslClient,\n+        socketFactory, getConf().isConnectToDnViaHostname(), this, blockToken);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n                                     Token\u003cBlockTokenIdentifier\u003e blockToken)\n      throws IOException {\n    return DFSUtilClient.connectToDN(dn, timeout, conf, saslClient,\n        socketFactory, getConf().isConnectToDnViaHostname(), this, blockToken);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {}
        }
      ]
    },
    "372d1302c63c6f49f99be5766c5da9647ebd9ca6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9700. DFSClient and DFSOutputStream should set TCP_NODELAY on sockets for DataTransferProtocol (Gary Helmling via iwasakims)\n",
      "commitDate": "12/02/16 10:31 AM",
      "commitName": "372d1302c63c6f49f99be5766c5da9647ebd9ca6",
      "commitAuthor": "Masatake Iwasaki",
      "commitDateOld": "25/01/16 6:32 PM",
      "commitNameOld": "bd909ed9f2d853f614f04a50e2230a7932732776",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 17.67,
      "commitsBetweenForRepo": 131,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,24 @@\n   private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n       LocatedBlock lb) throws IOException {\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     try {\n       sock \u003d socketFactory.createSocket();\n       String dnAddr \u003d dn.getXferAddr(getConf().isConnectToDnViaHostname());\n       LOG.debug(\"Connecting to datanode {}\", dnAddr);\n       NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n+      sock.setTcpNoDelay(dfsClientConf.getDataTransferTcpNoDelay());\n       sock.setSoTimeout(timeout);\n \n       OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n       InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n       IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n           lb.getBlockToken(), dn);\n       success \u003d true;\n       return ret;\n     } finally {\n       if (!success) {\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n      LocatedBlock lb) throws IOException {\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d socketFactory.createSocket();\n      String dnAddr \u003d dn.getXferAddr(getConf().isConnectToDnViaHostname());\n      LOG.debug(\"Connecting to datanode {}\", dnAddr);\n      NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n      sock.setTcpNoDelay(dfsClientConf.getDataTransferTcpNoDelay());\n      sock.setSoTimeout(timeout);\n\n      OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n      InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n      IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n          lb.getBlockToken(), dn);\n      success \u003d true;\n      return ret;\n    } finally {\n      if (!success) {\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {}
    },
    "39285e6a1978ea5e53bdc1b0aef62421382124a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8971. Remove guards when calling LOG.debug() and LOG.trace() in client package. Contributed by Mingliang Liu.\n",
      "commitDate": "29/09/15 5:52 PM",
      "commitName": "39285e6a1978ea5e53bdc1b0aef62421382124a8",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:51 PM",
      "commitNameOld": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,23 @@\n   private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n       LocatedBlock lb) throws IOException {\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     try {\n       sock \u003d socketFactory.createSocket();\n       String dnAddr \u003d dn.getXferAddr(getConf().isConnectToDnViaHostname());\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Connecting to datanode \" + dnAddr);\n-      }\n+      LOG.debug(\"Connecting to datanode {}\", dnAddr);\n       NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n       sock.setSoTimeout(timeout);\n   \n       OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n       InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n       IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n         lb.getBlockToken(), dn);\n       success \u003d true;\n       return ret;\n     } finally {\n       if (!success) {\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n      LocatedBlock lb) throws IOException {\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d socketFactory.createSocket();\n      String dnAddr \u003d dn.getXferAddr(getConf().isConnectToDnViaHostname());\n      LOG.debug(\"Connecting to datanode {}\", dnAddr);\n      NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n      sock.setSoTimeout(timeout);\n  \n      OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n      InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n      IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n        lb.getBlockToken(), dn);\n      success \u003d true;\n      return ret;\n    } finally {\n      if (!success) {\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {}
    },
    "6ee0539ede78b640f01c5eac18ded161182a7835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\"\n\nThis reverts commit d5a9a3daa0224249221ffa7b8bd5751ab2feca56.\n",
      "commitDate": "29/09/15 5:51 PM",
      "commitName": "6ee0539ede78b640f01c5eac18ded161182a7835",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/15 5:48 PM",
      "commitNameOld": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,25 @@\n   private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n       LocatedBlock lb) throws IOException {\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     try {\n       sock \u003d socketFactory.createSocket();\n       String dnAddr \u003d dn.getXferAddr(getConf().isConnectToDnViaHostname());\n-      LOG.debug(\"Connecting to datanode {}\", dnAddr);\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Connecting to datanode \" + dnAddr);\n+      }\n       NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n       sock.setSoTimeout(timeout);\n   \n       OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n       InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n       IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n         lb.getBlockToken(), dn);\n       success \u003d true;\n       return ret;\n     } finally {\n       if (!success) {\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n      LocatedBlock lb) throws IOException {\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d socketFactory.createSocket();\n      String dnAddr \u003d dn.getXferAddr(getConf().isConnectToDnViaHostname());\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Connecting to datanode \" + dnAddr);\n      }\n      NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n      sock.setSoTimeout(timeout);\n  \n      OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n      InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n      IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n        lb.getBlockToken(), dn);\n      success \u003d true;\n      return ret;\n    } finally {\n      if (!success) {\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {}
    },
    "d5a9a3daa0224249221ffa7b8bd5751ab2feca56": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9170. Move libhdfs / fuse-dfs / libwebhdfs to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "29/09/15 5:48 PM",
      "commitName": "d5a9a3daa0224249221ffa7b8bd5751ab2feca56",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/09/15 7:42 AM",
      "commitNameOld": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 1.42,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,23 @@\n   private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n       LocatedBlock lb) throws IOException {\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     try {\n       sock \u003d socketFactory.createSocket();\n       String dnAddr \u003d dn.getXferAddr(getConf().isConnectToDnViaHostname());\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Connecting to datanode \" + dnAddr);\n-      }\n+      LOG.debug(\"Connecting to datanode {}\", dnAddr);\n       NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n       sock.setSoTimeout(timeout);\n   \n       OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n       InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n       IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n         lb.getBlockToken(), dn);\n       success \u003d true;\n       return ret;\n     } finally {\n       if (!success) {\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n      LocatedBlock lb) throws IOException {\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d socketFactory.createSocket();\n      String dnAddr \u003d dn.getXferAddr(getConf().isConnectToDnViaHostname());\n      LOG.debug(\"Connecting to datanode {}\", dnAddr);\n      NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n      sock.setSoTimeout(timeout);\n  \n      OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n      InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n      IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n        lb.getBlockToken(), dn);\n      success \u003d true;\n      return ret;\n    } finally {\n      if (!success) {\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {}
    },
    "bf37d3d80e5179dea27e5bd5aea804a38aa9934c": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8053. Move DFSIn/OutputStream and related classes to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "26/09/15 11:08 AM",
      "commitName": "bf37d3d80e5179dea27e5bd5aea804a38aa9934c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/09/15 9:06 AM",
      "commitNameOld": "861b52db242f238d7e36ad75c158025be959a696",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.08,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n      LocatedBlock lb) throws IOException {\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d socketFactory.createSocket();\n      String dnAddr \u003d dn.getXferAddr(getConf().isConnectToDnViaHostname());\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Connecting to datanode \" + dnAddr);\n      }\n      NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n      sock.setSoTimeout(timeout);\n  \n      OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n      InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n      IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n        lb.getBlockToken(), dn);\n      success \u003d true;\n      return ret;\n    } finally {\n      if (!success) {\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSClient.java"
      }
    },
    "2cc9514ad643ae49d30524743420ee9744e571bd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8100. Refactor DFSClient.Conf to a standalone class and separates short-circuit related conf to ShortCircuitConf.\n",
      "commitDate": "10/04/15 2:48 PM",
      "commitName": "2cc9514ad643ae49d30524743420ee9744e571bd",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "10/04/15 11:40 AM",
      "commitNameOld": "7660da95cb67cbfe034aa8fa2a5bf0f8c9fdf41a",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 0.13,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,25 @@\n   private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n       LocatedBlock lb) throws IOException {\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     try {\n       sock \u003d socketFactory.createSocket();\n-      String dnAddr \u003d dn.getXferAddr(getConf().connectToDnViaHostname);\n+      String dnAddr \u003d dn.getXferAddr(getConf().isConnectToDnViaHostname());\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Connecting to datanode \" + dnAddr);\n       }\n       NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n       sock.setSoTimeout(timeout);\n   \n       OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n       InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n       IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n         lb.getBlockToken(), dn);\n       success \u003d true;\n       return ret;\n     } finally {\n       if (!success) {\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n      LocatedBlock lb) throws IOException {\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d socketFactory.createSocket();\n      String dnAddr \u003d dn.getXferAddr(getConf().isConnectToDnViaHostname());\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Connecting to datanode \" + dnAddr);\n      }\n      NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n      sock.setSoTimeout(timeout);\n  \n      OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n      InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n      IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n        lb.getBlockToken(), dn);\n      success \u003d true;\n      return ret;\n    } finally {\n      if (!success) {\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
      "extendedDetails": {}
    },
    "3b54223c0f32d42a84436c670d80b791a8e9696d": {
      "type": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-2856. Fix block protocol so that Datanodes don\u0027t require root or jsvc. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1610474 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/07/14 11:10 AM",
      "commitName": "3b54223c0f32d42a84436c670d80b791a8e9696d",
      "commitAuthor": "Chris Nauroth",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2856. Fix block protocol so that Datanodes don\u0027t require root or jsvc. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1610474 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/07/14 11:10 AM",
          "commitName": "3b54223c0f32d42a84436c670d80b791a8e9696d",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "30/05/14 5:12 PM",
          "commitNameOld": "880a0c673c74a128a01c72b60695f05327f5e961",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 44.75,
          "commitsBetweenForRepo": 266,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,25 @@\n-  private static IOStreamPair connectToDN(\n-      SocketFactory socketFactory, boolean connectToDnViaHostname,\n-      DataEncryptionKey encryptionKey, DatanodeInfo dn, int timeout)\n-      throws IOException\n-  {\n+  private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n+      LocatedBlock lb) throws IOException {\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     try {\n       sock \u003d socketFactory.createSocket();\n-      String dnAddr \u003d dn.getXferAddr(connectToDnViaHostname);\n+      String dnAddr \u003d dn.getXferAddr(getConf().connectToDnViaHostname);\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Connecting to datanode \" + dnAddr);\n       }\n       NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n       sock.setSoTimeout(timeout);\n   \n       OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n       InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n-      IOStreamPair ret;\n-      if (encryptionKey !\u003d null) {\n-        ret \u003d DataTransferEncryptor.getEncryptedStreams(\n-                unbufOut, unbufIn, encryptionKey);\n-      } else {\n-        ret \u003d new IOStreamPair(unbufIn, unbufOut);        \n-      }\n+      IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n+        lb.getBlockToken(), dn);\n       success \u003d true;\n       return ret;\n     } finally {\n       if (!success) {\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n      LocatedBlock lb) throws IOException {\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d socketFactory.createSocket();\n      String dnAddr \u003d dn.getXferAddr(getConf().connectToDnViaHostname);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Connecting to datanode \" + dnAddr);\n      }\n      NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n      sock.setSoTimeout(timeout);\n  \n      OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n      InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n      IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n        lb.getBlockToken(), dn);\n      success \u003d true;\n      return ret;\n    } finally {\n      if (!success) {\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {
            "oldValue": "[socketFactory-SocketFactory, connectToDnViaHostname-boolean, encryptionKey-DataEncryptionKey, dn-DatanodeInfo, timeout-int]",
            "newValue": "[dn-DatanodeInfo, timeout-int, lb-LocatedBlock]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-2856. Fix block protocol so that Datanodes don\u0027t require root or jsvc. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1610474 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/07/14 11:10 AM",
          "commitName": "3b54223c0f32d42a84436c670d80b791a8e9696d",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "30/05/14 5:12 PM",
          "commitNameOld": "880a0c673c74a128a01c72b60695f05327f5e961",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 44.75,
          "commitsBetweenForRepo": 266,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,25 @@\n-  private static IOStreamPair connectToDN(\n-      SocketFactory socketFactory, boolean connectToDnViaHostname,\n-      DataEncryptionKey encryptionKey, DatanodeInfo dn, int timeout)\n-      throws IOException\n-  {\n+  private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n+      LocatedBlock lb) throws IOException {\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     try {\n       sock \u003d socketFactory.createSocket();\n-      String dnAddr \u003d dn.getXferAddr(connectToDnViaHostname);\n+      String dnAddr \u003d dn.getXferAddr(getConf().connectToDnViaHostname);\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Connecting to datanode \" + dnAddr);\n       }\n       NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n       sock.setSoTimeout(timeout);\n   \n       OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n       InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n-      IOStreamPair ret;\n-      if (encryptionKey !\u003d null) {\n-        ret \u003d DataTransferEncryptor.getEncryptedStreams(\n-                unbufOut, unbufIn, encryptionKey);\n-      } else {\n-        ret \u003d new IOStreamPair(unbufIn, unbufOut);        \n-      }\n+      IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n+        lb.getBlockToken(), dn);\n       success \u003d true;\n       return ret;\n     } finally {\n       if (!success) {\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n      LocatedBlock lb) throws IOException {\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d socketFactory.createSocket();\n      String dnAddr \u003d dn.getXferAddr(getConf().connectToDnViaHostname);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Connecting to datanode \" + dnAddr);\n      }\n      NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n      sock.setSoTimeout(timeout);\n  \n      OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n      InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n      IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n        lb.getBlockToken(), dn);\n      success \u003d true;\n      return ret;\n    } finally {\n      if (!success) {\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {
            "oldValue": "[private, static]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2856. Fix block protocol so that Datanodes don\u0027t require root or jsvc. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1610474 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/07/14 11:10 AM",
          "commitName": "3b54223c0f32d42a84436c670d80b791a8e9696d",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "30/05/14 5:12 PM",
          "commitNameOld": "880a0c673c74a128a01c72b60695f05327f5e961",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 44.75,
          "commitsBetweenForRepo": 266,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,25 @@\n-  private static IOStreamPair connectToDN(\n-      SocketFactory socketFactory, boolean connectToDnViaHostname,\n-      DataEncryptionKey encryptionKey, DatanodeInfo dn, int timeout)\n-      throws IOException\n-  {\n+  private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n+      LocatedBlock lb) throws IOException {\n     boolean success \u003d false;\n     Socket sock \u003d null;\n     try {\n       sock \u003d socketFactory.createSocket();\n-      String dnAddr \u003d dn.getXferAddr(connectToDnViaHostname);\n+      String dnAddr \u003d dn.getXferAddr(getConf().connectToDnViaHostname);\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Connecting to datanode \" + dnAddr);\n       }\n       NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n       sock.setSoTimeout(timeout);\n   \n       OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n       InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n-      IOStreamPair ret;\n-      if (encryptionKey !\u003d null) {\n-        ret \u003d DataTransferEncryptor.getEncryptedStreams(\n-                unbufOut, unbufIn, encryptionKey);\n-      } else {\n-        ret \u003d new IOStreamPair(unbufIn, unbufOut);        \n-      }\n+      IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n+        lb.getBlockToken(), dn);\n       success \u003d true;\n       return ret;\n     } finally {\n       if (!success) {\n         IOUtils.closeSocket(sock);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private IOStreamPair connectToDN(DatanodeInfo dn, int timeout,\n      LocatedBlock lb) throws IOException {\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d socketFactory.createSocket();\n      String dnAddr \u003d dn.getXferAddr(getConf().connectToDnViaHostname);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Connecting to datanode \" + dnAddr);\n      }\n      NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n      sock.setSoTimeout(timeout);\n  \n      OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n      InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n      IOStreamPair ret \u003d saslClient.newSocketSend(sock, unbufOut, unbufIn, this,\n        lb.getBlockToken(), dn);\n      success \u003d true;\n      return ret;\n    } finally {\n      if (!success) {\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java",
          "extendedDetails": {}
        }
      ]
    },
    "cfae13306ac0fb3f3c139d5ac511bf78cede1b77": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4403. DFSClient can infer checksum type when not provided by reading first byte. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1436730 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/01/13 6:59 PM",
      "commitName": "cfae13306ac0fb3f3c139d5ac511bf78cede1b77",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,33 @@\n+  private static IOStreamPair connectToDN(\n+      SocketFactory socketFactory, boolean connectToDnViaHostname,\n+      DataEncryptionKey encryptionKey, DatanodeInfo dn, int timeout)\n+      throws IOException\n+  {\n+    boolean success \u003d false;\n+    Socket sock \u003d null;\n+    try {\n+      sock \u003d socketFactory.createSocket();\n+      String dnAddr \u003d dn.getXferAddr(connectToDnViaHostname);\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Connecting to datanode \" + dnAddr);\n+      }\n+      NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n+      sock.setSoTimeout(timeout);\n+  \n+      OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n+      InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n+      IOStreamPair ret;\n+      if (encryptionKey !\u003d null) {\n+        ret \u003d DataTransferEncryptor.getEncryptedStreams(\n+                unbufOut, unbufIn, encryptionKey);\n+      } else {\n+        ret \u003d new IOStreamPair(unbufIn, unbufOut);        \n+      }\n+      success \u003d true;\n+      return ret;\n+    } finally {\n+      if (!success) {\n+        IOUtils.closeSocket(sock);\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static IOStreamPair connectToDN(\n      SocketFactory socketFactory, boolean connectToDnViaHostname,\n      DataEncryptionKey encryptionKey, DatanodeInfo dn, int timeout)\n      throws IOException\n  {\n    boolean success \u003d false;\n    Socket sock \u003d null;\n    try {\n      sock \u003d socketFactory.createSocket();\n      String dnAddr \u003d dn.getXferAddr(connectToDnViaHostname);\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Connecting to datanode \" + dnAddr);\n      }\n      NetUtils.connect(sock, NetUtils.createSocketAddr(dnAddr), timeout);\n      sock.setSoTimeout(timeout);\n  \n      OutputStream unbufOut \u003d NetUtils.getOutputStream(sock);\n      InputStream unbufIn \u003d NetUtils.getInputStream(sock);\n      IOStreamPair ret;\n      if (encryptionKey !\u003d null) {\n        ret \u003d DataTransferEncryptor.getEncryptedStreams(\n                unbufOut, unbufIn, encryptionKey);\n      } else {\n        ret \u003d new IOStreamPair(unbufIn, unbufOut);        \n      }\n      success \u003d true;\n      return ret;\n    } finally {\n      if (!success) {\n        IOUtils.closeSocket(sock);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/DFSClient.java"
    }
  }
}