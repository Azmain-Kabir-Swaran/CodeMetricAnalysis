{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "GangliaSink30.java",
  "functionName": "putMetrics",
  "functionId": "putMetrics___record-MetricsRecord",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/ganglia/GangliaSink30.java",
  "functionStartLine": 109,
  "functionEndLine": 193,
  "numCommitsSeen": 6,
  "timeTaken": 767,
  "changeHistory": [
    "2ca9c8d926a8eeb871b2868e6eb4dfb97d7dc63d",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
    "224972e0558e7a0022002ed26e765acdfd9f8f6c"
  ],
  "changeHistoryShort": {
    "2ca9c8d926a8eeb871b2868e6eb4dfb97d7dc63d": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": "Yfilerename",
    "224972e0558e7a0022002ed26e765acdfd9f8f6c": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2ca9c8d926a8eeb871b2868e6eb4dfb97d7dc63d": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-7507. Allow ganglia metrics to include the metrics system tags in the gmetric names. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1166460 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/09/11 3:59 PM",
      "commitName": "2ca9c8d926a8eeb871b2868e6eb4dfb97d7dc63d",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 13.95,
      "commitsBetweenForRepo": 74,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,83 +1,85 @@\n   public void putMetrics(MetricsRecord record) {\n     // The method handles both cases whether Ganglia support dense publish\n     // of metrics of sparse (only on change) publish of metrics\n     try {\n       String recordName \u003d record.name();\n       String contextName \u003d record.context();\n \n       StringBuilder sb \u003d new StringBuilder();\n       sb.append(contextName);\n       sb.append(\u0027.\u0027);\n       sb.append(recordName);\n \n+      appendPrefix(record, sb);\n+      \n       String groupName \u003d sb.toString();\n       sb.append(\u0027.\u0027);\n       int sbBaseLen \u003d sb.length();\n \n       String type \u003d null;\n       GangliaSlope slopeFromMetric \u003d null;\n       GangliaSlope calculatedSlope \u003d null;\n       Record cachedMetrics \u003d null;\n       resetBuffer();  // reset the buffer to the beginning\n       if (!isSupportSparseMetrics()) {\n         // for sending dense metrics, update metrics cache\n         // and get the updated data\n         cachedMetrics \u003d metricsCache.update(record);\n \n         if (cachedMetrics !\u003d null \u0026\u0026 cachedMetrics.metricsEntrySet() !\u003d null) {\n           for (Map.Entry\u003cString, AbstractMetric\u003e entry : cachedMetrics\n               .metricsEntrySet()) {\n             AbstractMetric metric \u003d entry.getValue();\n             sb.append(metric.name());\n             String name \u003d sb.toString();\n \n             // visit the metric to identify the Ganglia type and\n             // slope\n             metric.visit(gangliaMetricVisitor);\n             type \u003d gangliaMetricVisitor.getType();\n             slopeFromMetric \u003d gangliaMetricVisitor.getSlope();\n \n             GangliaConf gConf \u003d getGangliaConfForMetric(name);\n             calculatedSlope \u003d calculateSlope(gConf, slopeFromMetric);\n \n             // send metric to Ganglia\n             emitMetric(groupName, name, type, metric.value().toString(), gConf,\n                 calculatedSlope);\n \n             // reset the length of the buffer for next iteration\n             sb.setLength(sbBaseLen);\n           }\n         }\n       } else {\n         // we support sparse updates\n \n         Collection\u003cAbstractMetric\u003e metrics \u003d (Collection\u003cAbstractMetric\u003e) record\n             .metrics();\n         if (metrics.size() \u003e 0) {\n           // we got metrics. so send the latest\n           for (AbstractMetric metric : record.metrics()) {\n             sb.append(metric.name());\n             String name \u003d sb.toString();\n \n             // visit the metric to identify the Ganglia type and\n             // slope\n             metric.visit(gangliaMetricVisitor);\n             type \u003d gangliaMetricVisitor.getType();\n             slopeFromMetric \u003d gangliaMetricVisitor.getSlope();\n \n             GangliaConf gConf \u003d getGangliaConfForMetric(name);\n             calculatedSlope \u003d calculateSlope(gConf, slopeFromMetric);\n \n             // send metric to Ganglia\n             emitMetric(groupName, name, type, metric.value().toString(), gConf,\n                 calculatedSlope);\n \n             // reset the length of the buffer for next iteration\n             sb.setLength(sbBaseLen);\n           }\n         }\n       }\n     } catch (IOException io) {\n       throw new MetricsException(\"Failed to putMetrics\", io);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void putMetrics(MetricsRecord record) {\n    // The method handles both cases whether Ganglia support dense publish\n    // of metrics of sparse (only on change) publish of metrics\n    try {\n      String recordName \u003d record.name();\n      String contextName \u003d record.context();\n\n      StringBuilder sb \u003d new StringBuilder();\n      sb.append(contextName);\n      sb.append(\u0027.\u0027);\n      sb.append(recordName);\n\n      appendPrefix(record, sb);\n      \n      String groupName \u003d sb.toString();\n      sb.append(\u0027.\u0027);\n      int sbBaseLen \u003d sb.length();\n\n      String type \u003d null;\n      GangliaSlope slopeFromMetric \u003d null;\n      GangliaSlope calculatedSlope \u003d null;\n      Record cachedMetrics \u003d null;\n      resetBuffer();  // reset the buffer to the beginning\n      if (!isSupportSparseMetrics()) {\n        // for sending dense metrics, update metrics cache\n        // and get the updated data\n        cachedMetrics \u003d metricsCache.update(record);\n\n        if (cachedMetrics !\u003d null \u0026\u0026 cachedMetrics.metricsEntrySet() !\u003d null) {\n          for (Map.Entry\u003cString, AbstractMetric\u003e entry : cachedMetrics\n              .metricsEntrySet()) {\n            AbstractMetric metric \u003d entry.getValue();\n            sb.append(metric.name());\n            String name \u003d sb.toString();\n\n            // visit the metric to identify the Ganglia type and\n            // slope\n            metric.visit(gangliaMetricVisitor);\n            type \u003d gangliaMetricVisitor.getType();\n            slopeFromMetric \u003d gangliaMetricVisitor.getSlope();\n\n            GangliaConf gConf \u003d getGangliaConfForMetric(name);\n            calculatedSlope \u003d calculateSlope(gConf, slopeFromMetric);\n\n            // send metric to Ganglia\n            emitMetric(groupName, name, type, metric.value().toString(), gConf,\n                calculatedSlope);\n\n            // reset the length of the buffer for next iteration\n            sb.setLength(sbBaseLen);\n          }\n        }\n      } else {\n        // we support sparse updates\n\n        Collection\u003cAbstractMetric\u003e metrics \u003d (Collection\u003cAbstractMetric\u003e) record\n            .metrics();\n        if (metrics.size() \u003e 0) {\n          // we got metrics. so send the latest\n          for (AbstractMetric metric : record.metrics()) {\n            sb.append(metric.name());\n            String name \u003d sb.toString();\n\n            // visit the metric to identify the Ganglia type and\n            // slope\n            metric.visit(gangliaMetricVisitor);\n            type \u003d gangliaMetricVisitor.getType();\n            slopeFromMetric \u003d gangliaMetricVisitor.getSlope();\n\n            GangliaConf gConf \u003d getGangliaConfForMetric(name);\n            calculatedSlope \u003d calculateSlope(gConf, slopeFromMetric);\n\n            // send metric to Ganglia\n            emitMetric(groupName, name, type, metric.value().toString(), gConf,\n                calculatedSlope);\n\n            // reset the length of the buffer for next iteration\n            sb.setLength(sbBaseLen);\n          }\n        }\n      }\n    } catch (IOException io) {\n      throw new MetricsException(\"Failed to putMetrics\", io);\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/ganglia/GangliaSink30.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void putMetrics(MetricsRecord record) {\n    // The method handles both cases whether Ganglia support dense publish\n    // of metrics of sparse (only on change) publish of metrics\n    try {\n      String recordName \u003d record.name();\n      String contextName \u003d record.context();\n\n      StringBuilder sb \u003d new StringBuilder();\n      sb.append(contextName);\n      sb.append(\u0027.\u0027);\n      sb.append(recordName);\n\n      String groupName \u003d sb.toString();\n      sb.append(\u0027.\u0027);\n      int sbBaseLen \u003d sb.length();\n\n      String type \u003d null;\n      GangliaSlope slopeFromMetric \u003d null;\n      GangliaSlope calculatedSlope \u003d null;\n      Record cachedMetrics \u003d null;\n      resetBuffer();  // reset the buffer to the beginning\n      if (!isSupportSparseMetrics()) {\n        // for sending dense metrics, update metrics cache\n        // and get the updated data\n        cachedMetrics \u003d metricsCache.update(record);\n\n        if (cachedMetrics !\u003d null \u0026\u0026 cachedMetrics.metricsEntrySet() !\u003d null) {\n          for (Map.Entry\u003cString, AbstractMetric\u003e entry : cachedMetrics\n              .metricsEntrySet()) {\n            AbstractMetric metric \u003d entry.getValue();\n            sb.append(metric.name());\n            String name \u003d sb.toString();\n\n            // visit the metric to identify the Ganglia type and\n            // slope\n            metric.visit(gangliaMetricVisitor);\n            type \u003d gangliaMetricVisitor.getType();\n            slopeFromMetric \u003d gangliaMetricVisitor.getSlope();\n\n            GangliaConf gConf \u003d getGangliaConfForMetric(name);\n            calculatedSlope \u003d calculateSlope(gConf, slopeFromMetric);\n\n            // send metric to Ganglia\n            emitMetric(groupName, name, type, metric.value().toString(), gConf,\n                calculatedSlope);\n\n            // reset the length of the buffer for next iteration\n            sb.setLength(sbBaseLen);\n          }\n        }\n      } else {\n        // we support sparse updates\n\n        Collection\u003cAbstractMetric\u003e metrics \u003d (Collection\u003cAbstractMetric\u003e) record\n            .metrics();\n        if (metrics.size() \u003e 0) {\n          // we got metrics. so send the latest\n          for (AbstractMetric metric : record.metrics()) {\n            sb.append(metric.name());\n            String name \u003d sb.toString();\n\n            // visit the metric to identify the Ganglia type and\n            // slope\n            metric.visit(gangliaMetricVisitor);\n            type \u003d gangliaMetricVisitor.getType();\n            slopeFromMetric \u003d gangliaMetricVisitor.getSlope();\n\n            GangliaConf gConf \u003d getGangliaConfForMetric(name);\n            calculatedSlope \u003d calculateSlope(gConf, slopeFromMetric);\n\n            // send metric to Ganglia\n            emitMetric(groupName, name, type, metric.value().toString(), gConf,\n                calculatedSlope);\n\n            // reset the length of the buffer for next iteration\n            sb.setLength(sbBaseLen);\n          }\n        }\n      }\n    } catch (IOException io) {\n      throw new MetricsException(\"Failed to putMetrics\", io);\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/ganglia/GangliaSink30.java",
      "extendedDetails": {
        "oldPath": "hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/ganglia/GangliaSink30.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/ganglia/GangliaSink30.java"
      }
    },
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-6671. Use maven for hadoop common builds. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1153184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/08/11 9:37 AM",
      "commitName": "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
      "commitAuthor": "Thomas White",
      "commitDateOld": "01/08/11 3:53 PM",
      "commitNameOld": "9bac807cedbcff34e1a144fb475eff267e5ed86d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void putMetrics(MetricsRecord record) {\n    // The method handles both cases whether Ganglia support dense publish\n    // of metrics of sparse (only on change) publish of metrics\n    try {\n      String recordName \u003d record.name();\n      String contextName \u003d record.context();\n\n      StringBuilder sb \u003d new StringBuilder();\n      sb.append(contextName);\n      sb.append(\u0027.\u0027);\n      sb.append(recordName);\n\n      String groupName \u003d sb.toString();\n      sb.append(\u0027.\u0027);\n      int sbBaseLen \u003d sb.length();\n\n      String type \u003d null;\n      GangliaSlope slopeFromMetric \u003d null;\n      GangliaSlope calculatedSlope \u003d null;\n      Record cachedMetrics \u003d null;\n      resetBuffer();  // reset the buffer to the beginning\n      if (!isSupportSparseMetrics()) {\n        // for sending dense metrics, update metrics cache\n        // and get the updated data\n        cachedMetrics \u003d metricsCache.update(record);\n\n        if (cachedMetrics !\u003d null \u0026\u0026 cachedMetrics.metricsEntrySet() !\u003d null) {\n          for (Map.Entry\u003cString, AbstractMetric\u003e entry : cachedMetrics\n              .metricsEntrySet()) {\n            AbstractMetric metric \u003d entry.getValue();\n            sb.append(metric.name());\n            String name \u003d sb.toString();\n\n            // visit the metric to identify the Ganglia type and\n            // slope\n            metric.visit(gangliaMetricVisitor);\n            type \u003d gangliaMetricVisitor.getType();\n            slopeFromMetric \u003d gangliaMetricVisitor.getSlope();\n\n            GangliaConf gConf \u003d getGangliaConfForMetric(name);\n            calculatedSlope \u003d calculateSlope(gConf, slopeFromMetric);\n\n            // send metric to Ganglia\n            emitMetric(groupName, name, type, metric.value().toString(), gConf,\n                calculatedSlope);\n\n            // reset the length of the buffer for next iteration\n            sb.setLength(sbBaseLen);\n          }\n        }\n      } else {\n        // we support sparse updates\n\n        Collection\u003cAbstractMetric\u003e metrics \u003d (Collection\u003cAbstractMetric\u003e) record\n            .metrics();\n        if (metrics.size() \u003e 0) {\n          // we got metrics. so send the latest\n          for (AbstractMetric metric : record.metrics()) {\n            sb.append(metric.name());\n            String name \u003d sb.toString();\n\n            // visit the metric to identify the Ganglia type and\n            // slope\n            metric.visit(gangliaMetricVisitor);\n            type \u003d gangliaMetricVisitor.getType();\n            slopeFromMetric \u003d gangliaMetricVisitor.getSlope();\n\n            GangliaConf gConf \u003d getGangliaConfForMetric(name);\n            calculatedSlope \u003d calculateSlope(gConf, slopeFromMetric);\n\n            // send metric to Ganglia\n            emitMetric(groupName, name, type, metric.value().toString(), gConf,\n                calculatedSlope);\n\n            // reset the length of the buffer for next iteration\n            sb.setLength(sbBaseLen);\n          }\n        }\n      }\n    } catch (IOException io) {\n      throw new MetricsException(\"Failed to putMetrics\", io);\n    }\n  }",
      "path": "hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/ganglia/GangliaSink30.java",
      "extendedDetails": {
        "oldPath": "common/src/java/org/apache/hadoop/metrics2/sink/ganglia/GangliaSink30.java",
        "newPath": "hadoop-common/src/main/java/org/apache/hadoop/metrics2/sink/ganglia/GangliaSink30.java"
      }
    },
    "224972e0558e7a0022002ed26e765acdfd9f8f6c": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7324. Ganglia plugins for metrics v2. (Priyo Mustafi via llu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1145525 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/07/11 3:23 AM",
      "commitName": "224972e0558e7a0022002ed26e765acdfd9f8f6c",
      "commitAuthor": "Luke Lu",
      "diff": "@@ -0,0 +1,83 @@\n+  public void putMetrics(MetricsRecord record) {\n+    // The method handles both cases whether Ganglia support dense publish\n+    // of metrics of sparse (only on change) publish of metrics\n+    try {\n+      String recordName \u003d record.name();\n+      String contextName \u003d record.context();\n+\n+      StringBuilder sb \u003d new StringBuilder();\n+      sb.append(contextName);\n+      sb.append(\u0027.\u0027);\n+      sb.append(recordName);\n+\n+      String groupName \u003d sb.toString();\n+      sb.append(\u0027.\u0027);\n+      int sbBaseLen \u003d sb.length();\n+\n+      String type \u003d null;\n+      GangliaSlope slopeFromMetric \u003d null;\n+      GangliaSlope calculatedSlope \u003d null;\n+      Record cachedMetrics \u003d null;\n+      resetBuffer();  // reset the buffer to the beginning\n+      if (!isSupportSparseMetrics()) {\n+        // for sending dense metrics, update metrics cache\n+        // and get the updated data\n+        cachedMetrics \u003d metricsCache.update(record);\n+\n+        if (cachedMetrics !\u003d null \u0026\u0026 cachedMetrics.metricsEntrySet() !\u003d null) {\n+          for (Map.Entry\u003cString, AbstractMetric\u003e entry : cachedMetrics\n+              .metricsEntrySet()) {\n+            AbstractMetric metric \u003d entry.getValue();\n+            sb.append(metric.name());\n+            String name \u003d sb.toString();\n+\n+            // visit the metric to identify the Ganglia type and\n+            // slope\n+            metric.visit(gangliaMetricVisitor);\n+            type \u003d gangliaMetricVisitor.getType();\n+            slopeFromMetric \u003d gangliaMetricVisitor.getSlope();\n+\n+            GangliaConf gConf \u003d getGangliaConfForMetric(name);\n+            calculatedSlope \u003d calculateSlope(gConf, slopeFromMetric);\n+\n+            // send metric to Ganglia\n+            emitMetric(groupName, name, type, metric.value().toString(), gConf,\n+                calculatedSlope);\n+\n+            // reset the length of the buffer for next iteration\n+            sb.setLength(sbBaseLen);\n+          }\n+        }\n+      } else {\n+        // we support sparse updates\n+\n+        Collection\u003cAbstractMetric\u003e metrics \u003d (Collection\u003cAbstractMetric\u003e) record\n+            .metrics();\n+        if (metrics.size() \u003e 0) {\n+          // we got metrics. so send the latest\n+          for (AbstractMetric metric : record.metrics()) {\n+            sb.append(metric.name());\n+            String name \u003d sb.toString();\n+\n+            // visit the metric to identify the Ganglia type and\n+            // slope\n+            metric.visit(gangliaMetricVisitor);\n+            type \u003d gangliaMetricVisitor.getType();\n+            slopeFromMetric \u003d gangliaMetricVisitor.getSlope();\n+\n+            GangliaConf gConf \u003d getGangliaConfForMetric(name);\n+            calculatedSlope \u003d calculateSlope(gConf, slopeFromMetric);\n+\n+            // send metric to Ganglia\n+            emitMetric(groupName, name, type, metric.value().toString(), gConf,\n+                calculatedSlope);\n+\n+            // reset the length of the buffer for next iteration\n+            sb.setLength(sbBaseLen);\n+          }\n+        }\n+      }\n+    } catch (IOException io) {\n+      throw new MetricsException(\"Failed to putMetrics\", io);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void putMetrics(MetricsRecord record) {\n    // The method handles both cases whether Ganglia support dense publish\n    // of metrics of sparse (only on change) publish of metrics\n    try {\n      String recordName \u003d record.name();\n      String contextName \u003d record.context();\n\n      StringBuilder sb \u003d new StringBuilder();\n      sb.append(contextName);\n      sb.append(\u0027.\u0027);\n      sb.append(recordName);\n\n      String groupName \u003d sb.toString();\n      sb.append(\u0027.\u0027);\n      int sbBaseLen \u003d sb.length();\n\n      String type \u003d null;\n      GangliaSlope slopeFromMetric \u003d null;\n      GangliaSlope calculatedSlope \u003d null;\n      Record cachedMetrics \u003d null;\n      resetBuffer();  // reset the buffer to the beginning\n      if (!isSupportSparseMetrics()) {\n        // for sending dense metrics, update metrics cache\n        // and get the updated data\n        cachedMetrics \u003d metricsCache.update(record);\n\n        if (cachedMetrics !\u003d null \u0026\u0026 cachedMetrics.metricsEntrySet() !\u003d null) {\n          for (Map.Entry\u003cString, AbstractMetric\u003e entry : cachedMetrics\n              .metricsEntrySet()) {\n            AbstractMetric metric \u003d entry.getValue();\n            sb.append(metric.name());\n            String name \u003d sb.toString();\n\n            // visit the metric to identify the Ganglia type and\n            // slope\n            metric.visit(gangliaMetricVisitor);\n            type \u003d gangliaMetricVisitor.getType();\n            slopeFromMetric \u003d gangliaMetricVisitor.getSlope();\n\n            GangliaConf gConf \u003d getGangliaConfForMetric(name);\n            calculatedSlope \u003d calculateSlope(gConf, slopeFromMetric);\n\n            // send metric to Ganglia\n            emitMetric(groupName, name, type, metric.value().toString(), gConf,\n                calculatedSlope);\n\n            // reset the length of the buffer for next iteration\n            sb.setLength(sbBaseLen);\n          }\n        }\n      } else {\n        // we support sparse updates\n\n        Collection\u003cAbstractMetric\u003e metrics \u003d (Collection\u003cAbstractMetric\u003e) record\n            .metrics();\n        if (metrics.size() \u003e 0) {\n          // we got metrics. so send the latest\n          for (AbstractMetric metric : record.metrics()) {\n            sb.append(metric.name());\n            String name \u003d sb.toString();\n\n            // visit the metric to identify the Ganglia type and\n            // slope\n            metric.visit(gangliaMetricVisitor);\n            type \u003d gangliaMetricVisitor.getType();\n            slopeFromMetric \u003d gangliaMetricVisitor.getSlope();\n\n            GangliaConf gConf \u003d getGangliaConfForMetric(name);\n            calculatedSlope \u003d calculateSlope(gConf, slopeFromMetric);\n\n            // send metric to Ganglia\n            emitMetric(groupName, name, type, metric.value().toString(), gConf,\n                calculatedSlope);\n\n            // reset the length of the buffer for next iteration\n            sb.setLength(sbBaseLen);\n          }\n        }\n      }\n    } catch (IOException io) {\n      throw new MetricsException(\"Failed to putMetrics\", io);\n    }\n  }",
      "path": "common/src/java/org/apache/hadoop/metrics2/sink/ganglia/GangliaSink30.java"
    }
  }
}