{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "TeraSort.java",
  "functionName": "run",
  "functionId": "run___args-String[]",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/terasort/TeraSort.java",
  "functionStartLine": 295,
  "functionEndLine": 337,
  "numCommitsSeen": 16,
  "timeTaken": 5542,
  "changeHistory": [
    "9f1c017f444d5e57899493dc23207c6b5fc26dae",
    "e82067bfe680ce04acc0153693cce3cd385e5567",
    "9d72f939759f407796ecb4715c2dc2f0d36d5578",
    "735b50e8bd23f7fbeff3a08cf8f3fff8cbff7449",
    "1972a76e5a4483b2da431cc7532207c2e6274c6c",
    "26447229ba2c3d43db978c1b3ce95613669182ee",
    "e1acb1222dd6fdb8fa688c815cbca6ae4193745d",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "9f1c017f444d5e57899493dc23207c6b5fc26dae": "Ybodychange",
    "e82067bfe680ce04acc0153693cce3cd385e5567": "Ybodychange",
    "9d72f939759f407796ecb4715c2dc2f0d36d5578": "Ybodychange",
    "735b50e8bd23f7fbeff3a08cf8f3fff8cbff7449": "Ybodychange",
    "1972a76e5a4483b2da431cc7532207c2e6274c6c": "Ybodychange",
    "26447229ba2c3d43db978c1b3ce95613669182ee": "Yfilerename",
    "e1acb1222dd6fdb8fa688c815cbca6ae4193745d": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9f1c017f444d5e57899493dc23207c6b5fc26dae": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16058. S3A tests to include Terasort.\n\nContributed by Steve Loughran.\n\nThis includes\n - HADOOP-15890. Some S3A committer tests don\u0027t match ITest* pattern; don\u0027t run in maven\n - MAPREDUCE-7090. BigMapOutput example doesn\u0027t work with paths off cluster fs\n - MAPREDUCE-7091. Terasort on S3A to switch to new committers\n - MAPREDUCE-7092. MR examples to work better against cloud stores\n",
      "commitDate": "21/03/19 4:15 AM",
      "commitName": "9f1c017f444d5e57899493dc23207c6b5fc26dae",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "21/09/17 9:27 PM",
      "commitNameOld": "53be075241f1ba92bfe47e89c2dfc3f0664e2578",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 545.28,
      "commitsBetweenForRepo": 4659,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,43 @@\n   public int run(String[] args) throws Exception {\n     if (args.length !\u003d 2) {\n       usage();\n       return 2;\n     }\n     LOG.info(\"starting\");\n     Job job \u003d Job.getInstance(getConf());\n     Path inputDir \u003d new Path(args[0]);\n     Path outputDir \u003d new Path(args[1]);\n     boolean useSimplePartitioner \u003d getUseSimplePartitioner(job);\n     TeraInputFormat.setInputPaths(job, inputDir);\n     FileOutputFormat.setOutputPath(job, outputDir);\n     job.setJobName(\"TeraSort\");\n     job.setJarByClass(TeraSort.class);\n     job.setOutputKeyClass(Text.class);\n     job.setOutputValueClass(Text.class);\n     job.setInputFormatClass(TeraInputFormat.class);\n     job.setOutputFormatClass(TeraOutputFormat.class);\n     if (useSimplePartitioner) {\n       job.setPartitionerClass(SimplePartitioner.class);\n     } else {\n       long start \u003d System.currentTimeMillis();\n       Path partitionFile \u003d new Path(outputDir, \n                                     TeraInputFormat.PARTITION_FILENAME);\n       URI partitionUri \u003d new URI(partitionFile.toString() +\n                                  \"#\" + TeraInputFormat.PARTITION_FILENAME);\n       try {\n         TeraInputFormat.writePartitionFile(job, partitionFile);\n       } catch (Throwable e) {\n-        LOG.error(e.getMessage());\n+        LOG.error(\"{}\", e.getMessage(), e);\n         return -1;\n       }\n       job.addCacheFile(partitionUri);  \n       long end \u003d System.currentTimeMillis();\n       System.out.println(\"Spent \" + (end - start) + \"ms computing partitions.\");\n       job.setPartitionerClass(TotalOrderPartitioner.class);\n     }\n     \n     job.getConfiguration().setInt(\"dfs.replication\", getOutputReplication(job));\n     int ret \u003d job.waitForCompletion(true) ? 0 : 1;\n     LOG.info(\"done\");\n     return ret;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    if (args.length !\u003d 2) {\n      usage();\n      return 2;\n    }\n    LOG.info(\"starting\");\n    Job job \u003d Job.getInstance(getConf());\n    Path inputDir \u003d new Path(args[0]);\n    Path outputDir \u003d new Path(args[1]);\n    boolean useSimplePartitioner \u003d getUseSimplePartitioner(job);\n    TeraInputFormat.setInputPaths(job, inputDir);\n    FileOutputFormat.setOutputPath(job, outputDir);\n    job.setJobName(\"TeraSort\");\n    job.setJarByClass(TeraSort.class);\n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(Text.class);\n    job.setInputFormatClass(TeraInputFormat.class);\n    job.setOutputFormatClass(TeraOutputFormat.class);\n    if (useSimplePartitioner) {\n      job.setPartitionerClass(SimplePartitioner.class);\n    } else {\n      long start \u003d System.currentTimeMillis();\n      Path partitionFile \u003d new Path(outputDir, \n                                    TeraInputFormat.PARTITION_FILENAME);\n      URI partitionUri \u003d new URI(partitionFile.toString() +\n                                 \"#\" + TeraInputFormat.PARTITION_FILENAME);\n      try {\n        TeraInputFormat.writePartitionFile(job, partitionFile);\n      } catch (Throwable e) {\n        LOG.error(\"{}\", e.getMessage(), e);\n        return -1;\n      }\n      job.addCacheFile(partitionUri);  \n      long end \u003d System.currentTimeMillis();\n      System.out.println(\"Spent \" + (end - start) + \"ms computing partitions.\");\n      job.setPartitionerClass(TotalOrderPartitioner.class);\n    }\n    \n    job.getConfiguration().setInt(\"dfs.replication\", getOutputReplication(job));\n    int ret \u003d job.waitForCompletion(true) ? 0 : 1;\n    LOG.info(\"done\");\n    return ret;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/terasort/TeraSort.java",
      "extendedDetails": {}
    },
    "e82067bfe680ce04acc0153693cce3cd385e5567": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6366. mapreduce.terasort.final.sync configuration in TeraSort doesn\u0027t work. Contributed by Takuya Fukudome.\n",
      "commitDate": "13/05/15 12:44 AM",
      "commitName": "e82067bfe680ce04acc0153693cce3cd385e5567",
      "commitAuthor": "Tsuyoshi Ozawa",
      "commitDateOld": "19/03/15 8:58 AM",
      "commitNameOld": "1ccbc29708f7e89b9292a861df3bc3b8f4f7febe",
      "commitAuthorOld": "Tsuyoshi Ozawa",
      "daysBetweenCommits": 54.66,
      "commitsBetweenForRepo": 546,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,43 @@\n   public int run(String[] args) throws Exception {\n     if (args.length !\u003d 2) {\n       usage();\n       return 2;\n     }\n     LOG.info(\"starting\");\n     Job job \u003d Job.getInstance(getConf());\n     Path inputDir \u003d new Path(args[0]);\n     Path outputDir \u003d new Path(args[1]);\n     boolean useSimplePartitioner \u003d getUseSimplePartitioner(job);\n     TeraInputFormat.setInputPaths(job, inputDir);\n     FileOutputFormat.setOutputPath(job, outputDir);\n     job.setJobName(\"TeraSort\");\n     job.setJarByClass(TeraSort.class);\n     job.setOutputKeyClass(Text.class);\n     job.setOutputValueClass(Text.class);\n     job.setInputFormatClass(TeraInputFormat.class);\n     job.setOutputFormatClass(TeraOutputFormat.class);\n     if (useSimplePartitioner) {\n       job.setPartitionerClass(SimplePartitioner.class);\n     } else {\n       long start \u003d System.currentTimeMillis();\n       Path partitionFile \u003d new Path(outputDir, \n                                     TeraInputFormat.PARTITION_FILENAME);\n       URI partitionUri \u003d new URI(partitionFile.toString() +\n                                  \"#\" + TeraInputFormat.PARTITION_FILENAME);\n       try {\n         TeraInputFormat.writePartitionFile(job, partitionFile);\n       } catch (Throwable e) {\n         LOG.error(e.getMessage());\n         return -1;\n       }\n       job.addCacheFile(partitionUri);  \n       long end \u003d System.currentTimeMillis();\n       System.out.println(\"Spent \" + (end - start) + \"ms computing partitions.\");\n       job.setPartitionerClass(TotalOrderPartitioner.class);\n     }\n     \n     job.getConfiguration().setInt(\"dfs.replication\", getOutputReplication(job));\n-    TeraOutputFormat.setFinalSync(job, true);\n     int ret \u003d job.waitForCompletion(true) ? 0 : 1;\n     LOG.info(\"done\");\n     return ret;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    if (args.length !\u003d 2) {\n      usage();\n      return 2;\n    }\n    LOG.info(\"starting\");\n    Job job \u003d Job.getInstance(getConf());\n    Path inputDir \u003d new Path(args[0]);\n    Path outputDir \u003d new Path(args[1]);\n    boolean useSimplePartitioner \u003d getUseSimplePartitioner(job);\n    TeraInputFormat.setInputPaths(job, inputDir);\n    FileOutputFormat.setOutputPath(job, outputDir);\n    job.setJobName(\"TeraSort\");\n    job.setJarByClass(TeraSort.class);\n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(Text.class);\n    job.setInputFormatClass(TeraInputFormat.class);\n    job.setOutputFormatClass(TeraOutputFormat.class);\n    if (useSimplePartitioner) {\n      job.setPartitionerClass(SimplePartitioner.class);\n    } else {\n      long start \u003d System.currentTimeMillis();\n      Path partitionFile \u003d new Path(outputDir, \n                                    TeraInputFormat.PARTITION_FILENAME);\n      URI partitionUri \u003d new URI(partitionFile.toString() +\n                                 \"#\" + TeraInputFormat.PARTITION_FILENAME);\n      try {\n        TeraInputFormat.writePartitionFile(job, partitionFile);\n      } catch (Throwable e) {\n        LOG.error(e.getMessage());\n        return -1;\n      }\n      job.addCacheFile(partitionUri);  \n      long end \u003d System.currentTimeMillis();\n      System.out.println(\"Spent \" + (end - start) + \"ms computing partitions.\");\n      job.setPartitionerClass(TotalOrderPartitioner.class);\n    }\n    \n    job.getConfiguration().setInt(\"dfs.replication\", getOutputReplication(job));\n    int ret \u003d job.waitForCompletion(true) ? 0 : 1;\n    LOG.info(\"done\");\n    return ret;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/terasort/TeraSort.java",
      "extendedDetails": {}
    },
    "9d72f939759f407796ecb4715c2dc2f0d36d5578": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5807. Print usage for TeraSort job. Contributed by Rohith.\n",
      "commitDate": "18/03/15 3:06 AM",
      "commitName": "9d72f939759f407796ecb4715c2dc2f0d36d5578",
      "commitAuthor": "Harsh J",
      "commitDateOld": "14/10/13 11:28 PM",
      "commitNameOld": "4407d5f65f11cbae7d547a28940cc50a16f57c68",
      "commitAuthorOld": "Devarajulu K",
      "daysBetweenCommits": 519.15,
      "commitsBetweenForRepo": 3969,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,44 @@\n   public int run(String[] args) throws Exception {\n+    if (args.length !\u003d 2) {\n+      usage();\n+      return 2;\n+    }\n     LOG.info(\"starting\");\n     Job job \u003d Job.getInstance(getConf());\n     Path inputDir \u003d new Path(args[0]);\n     Path outputDir \u003d new Path(args[1]);\n     boolean useSimplePartitioner \u003d getUseSimplePartitioner(job);\n     TeraInputFormat.setInputPaths(job, inputDir);\n     FileOutputFormat.setOutputPath(job, outputDir);\n     job.setJobName(\"TeraSort\");\n     job.setJarByClass(TeraSort.class);\n     job.setOutputKeyClass(Text.class);\n     job.setOutputValueClass(Text.class);\n     job.setInputFormatClass(TeraInputFormat.class);\n     job.setOutputFormatClass(TeraOutputFormat.class);\n     if (useSimplePartitioner) {\n       job.setPartitionerClass(SimplePartitioner.class);\n     } else {\n       long start \u003d System.currentTimeMillis();\n       Path partitionFile \u003d new Path(outputDir, \n                                     TeraInputFormat.PARTITION_FILENAME);\n       URI partitionUri \u003d new URI(partitionFile.toString() +\n                                  \"#\" + TeraInputFormat.PARTITION_FILENAME);\n       try {\n         TeraInputFormat.writePartitionFile(job, partitionFile);\n       } catch (Throwable e) {\n         LOG.error(e.getMessage());\n         return -1;\n       }\n       job.addCacheFile(partitionUri);  \n       long end \u003d System.currentTimeMillis();\n       System.out.println(\"Spent \" + (end - start) + \"ms computing partitions.\");\n       job.setPartitionerClass(TotalOrderPartitioner.class);\n     }\n     \n     job.getConfiguration().setInt(\"dfs.replication\", getOutputReplication(job));\n     TeraOutputFormat.setFinalSync(job, true);\n     int ret \u003d job.waitForCompletion(true) ? 0 : 1;\n     LOG.info(\"done\");\n     return ret;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    if (args.length !\u003d 2) {\n      usage();\n      return 2;\n    }\n    LOG.info(\"starting\");\n    Job job \u003d Job.getInstance(getConf());\n    Path inputDir \u003d new Path(args[0]);\n    Path outputDir \u003d new Path(args[1]);\n    boolean useSimplePartitioner \u003d getUseSimplePartitioner(job);\n    TeraInputFormat.setInputPaths(job, inputDir);\n    FileOutputFormat.setOutputPath(job, outputDir);\n    job.setJobName(\"TeraSort\");\n    job.setJarByClass(TeraSort.class);\n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(Text.class);\n    job.setInputFormatClass(TeraInputFormat.class);\n    job.setOutputFormatClass(TeraOutputFormat.class);\n    if (useSimplePartitioner) {\n      job.setPartitionerClass(SimplePartitioner.class);\n    } else {\n      long start \u003d System.currentTimeMillis();\n      Path partitionFile \u003d new Path(outputDir, \n                                    TeraInputFormat.PARTITION_FILENAME);\n      URI partitionUri \u003d new URI(partitionFile.toString() +\n                                 \"#\" + TeraInputFormat.PARTITION_FILENAME);\n      try {\n        TeraInputFormat.writePartitionFile(job, partitionFile);\n      } catch (Throwable e) {\n        LOG.error(e.getMessage());\n        return -1;\n      }\n      job.addCacheFile(partitionUri);  \n      long end \u003d System.currentTimeMillis();\n      System.out.println(\"Spent \" + (end - start) + \"ms computing partitions.\");\n      job.setPartitionerClass(TotalOrderPartitioner.class);\n    }\n    \n    job.getConfiguration().setInt(\"dfs.replication\", getOutputReplication(job));\n    TeraOutputFormat.setFinalSync(job, true);\n    int ret \u003d job.waitForCompletion(true) ? 0 : 1;\n    LOG.info(\"done\");\n    return ret;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/terasort/TeraSort.java",
      "extendedDetails": {}
    },
    "735b50e8bd23f7fbeff3a08cf8f3fff8cbff7449": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4493. Distibuted Cache Compatability Issues (Robert Evans via tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1367713 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/07/12 12:20 PM",
      "commitName": "735b50e8bd23f7fbeff3a08cf8f3fff8cbff7449",
      "commitAuthor": "Thomas Graves",
      "commitDateOld": "04/12/11 11:58 AM",
      "commitNameOld": "1972a76e5a4483b2da431cc7532207c2e6274c6c",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 239.97,
      "commitsBetweenForRepo": 1581,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,40 @@\n   public int run(String[] args) throws Exception {\n     LOG.info(\"starting\");\n     Job job \u003d Job.getInstance(getConf());\n     Path inputDir \u003d new Path(args[0]);\n     Path outputDir \u003d new Path(args[1]);\n     boolean useSimplePartitioner \u003d getUseSimplePartitioner(job);\n     TeraInputFormat.setInputPaths(job, inputDir);\n     FileOutputFormat.setOutputPath(job, outputDir);\n     job.setJobName(\"TeraSort\");\n     job.setJarByClass(TeraSort.class);\n     job.setOutputKeyClass(Text.class);\n     job.setOutputValueClass(Text.class);\n     job.setInputFormatClass(TeraInputFormat.class);\n     job.setOutputFormatClass(TeraOutputFormat.class);\n     if (useSimplePartitioner) {\n       job.setPartitionerClass(SimplePartitioner.class);\n     } else {\n       long start \u003d System.currentTimeMillis();\n       Path partitionFile \u003d new Path(outputDir, \n                                     TeraInputFormat.PARTITION_FILENAME);\n       URI partitionUri \u003d new URI(partitionFile.toString() +\n                                  \"#\" + TeraInputFormat.PARTITION_FILENAME);\n       try {\n         TeraInputFormat.writePartitionFile(job, partitionFile);\n       } catch (Throwable e) {\n         LOG.error(e.getMessage());\n         return -1;\n       }\n-      job.addCacheFile(partitionUri);\n-      job.createSymlink();    \n+      job.addCacheFile(partitionUri);  \n       long end \u003d System.currentTimeMillis();\n       System.out.println(\"Spent \" + (end - start) + \"ms computing partitions.\");\n       job.setPartitionerClass(TotalOrderPartitioner.class);\n     }\n     \n     job.getConfiguration().setInt(\"dfs.replication\", getOutputReplication(job));\n     TeraOutputFormat.setFinalSync(job, true);\n     int ret \u003d job.waitForCompletion(true) ? 0 : 1;\n     LOG.info(\"done\");\n     return ret;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    LOG.info(\"starting\");\n    Job job \u003d Job.getInstance(getConf());\n    Path inputDir \u003d new Path(args[0]);\n    Path outputDir \u003d new Path(args[1]);\n    boolean useSimplePartitioner \u003d getUseSimplePartitioner(job);\n    TeraInputFormat.setInputPaths(job, inputDir);\n    FileOutputFormat.setOutputPath(job, outputDir);\n    job.setJobName(\"TeraSort\");\n    job.setJarByClass(TeraSort.class);\n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(Text.class);\n    job.setInputFormatClass(TeraInputFormat.class);\n    job.setOutputFormatClass(TeraOutputFormat.class);\n    if (useSimplePartitioner) {\n      job.setPartitionerClass(SimplePartitioner.class);\n    } else {\n      long start \u003d System.currentTimeMillis();\n      Path partitionFile \u003d new Path(outputDir, \n                                    TeraInputFormat.PARTITION_FILENAME);\n      URI partitionUri \u003d new URI(partitionFile.toString() +\n                                 \"#\" + TeraInputFormat.PARTITION_FILENAME);\n      try {\n        TeraInputFormat.writePartitionFile(job, partitionFile);\n      } catch (Throwable e) {\n        LOG.error(e.getMessage());\n        return -1;\n      }\n      job.addCacheFile(partitionUri);  \n      long end \u003d System.currentTimeMillis();\n      System.out.println(\"Spent \" + (end - start) + \"ms computing partitions.\");\n      job.setPartitionerClass(TotalOrderPartitioner.class);\n    }\n    \n    job.getConfiguration().setInt(\"dfs.replication\", getOutputReplication(job));\n    TeraOutputFormat.setFinalSync(job, true);\n    int ret \u003d job.waitForCompletion(true) ? 0 : 1;\n    LOG.info(\"done\");\n    return ret;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/terasort/TeraSort.java",
      "extendedDetails": {}
    },
    "1972a76e5a4483b2da431cc7532207c2e6274c6c": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3458. Fix findbugs warnings in hadoop-examples. (Devaraj K via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1210190 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/12/11 11:58 AM",
      "commitName": "1972a76e5a4483b2da431cc7532207c2e6274c6c",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "18/11/11 5:24 PM",
      "commitNameOld": "26447229ba2c3d43db978c1b3ce95613669182ee",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 15.77,
      "commitsBetweenForRepo": 88,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,41 @@\n   public int run(String[] args) throws Exception {\n     LOG.info(\"starting\");\n     Job job \u003d Job.getInstance(getConf());\n     Path inputDir \u003d new Path(args[0]);\n     Path outputDir \u003d new Path(args[1]);\n     boolean useSimplePartitioner \u003d getUseSimplePartitioner(job);\n     TeraInputFormat.setInputPaths(job, inputDir);\n     FileOutputFormat.setOutputPath(job, outputDir);\n     job.setJobName(\"TeraSort\");\n     job.setJarByClass(TeraSort.class);\n     job.setOutputKeyClass(Text.class);\n     job.setOutputValueClass(Text.class);\n     job.setInputFormatClass(TeraInputFormat.class);\n     job.setOutputFormatClass(TeraOutputFormat.class);\n     if (useSimplePartitioner) {\n       job.setPartitionerClass(SimplePartitioner.class);\n     } else {\n       long start \u003d System.currentTimeMillis();\n       Path partitionFile \u003d new Path(outputDir, \n                                     TeraInputFormat.PARTITION_FILENAME);\n       URI partitionUri \u003d new URI(partitionFile.toString() +\n                                  \"#\" + TeraInputFormat.PARTITION_FILENAME);\n-      TeraInputFormat.writePartitionFile(job, partitionFile);\n+      try {\n+        TeraInputFormat.writePartitionFile(job, partitionFile);\n+      } catch (Throwable e) {\n+        LOG.error(e.getMessage());\n+        return -1;\n+      }\n       job.addCacheFile(partitionUri);\n       job.createSymlink();    \n       long end \u003d System.currentTimeMillis();\n       System.out.println(\"Spent \" + (end - start) + \"ms computing partitions.\");\n       job.setPartitionerClass(TotalOrderPartitioner.class);\n     }\n     \n     job.getConfiguration().setInt(\"dfs.replication\", getOutputReplication(job));\n     TeraOutputFormat.setFinalSync(job, true);\n     int ret \u003d job.waitForCompletion(true) ? 0 : 1;\n     LOG.info(\"done\");\n     return ret;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    LOG.info(\"starting\");\n    Job job \u003d Job.getInstance(getConf());\n    Path inputDir \u003d new Path(args[0]);\n    Path outputDir \u003d new Path(args[1]);\n    boolean useSimplePartitioner \u003d getUseSimplePartitioner(job);\n    TeraInputFormat.setInputPaths(job, inputDir);\n    FileOutputFormat.setOutputPath(job, outputDir);\n    job.setJobName(\"TeraSort\");\n    job.setJarByClass(TeraSort.class);\n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(Text.class);\n    job.setInputFormatClass(TeraInputFormat.class);\n    job.setOutputFormatClass(TeraOutputFormat.class);\n    if (useSimplePartitioner) {\n      job.setPartitionerClass(SimplePartitioner.class);\n    } else {\n      long start \u003d System.currentTimeMillis();\n      Path partitionFile \u003d new Path(outputDir, \n                                    TeraInputFormat.PARTITION_FILENAME);\n      URI partitionUri \u003d new URI(partitionFile.toString() +\n                                 \"#\" + TeraInputFormat.PARTITION_FILENAME);\n      try {\n        TeraInputFormat.writePartitionFile(job, partitionFile);\n      } catch (Throwable e) {\n        LOG.error(e.getMessage());\n        return -1;\n      }\n      job.addCacheFile(partitionUri);\n      job.createSymlink();    \n      long end \u003d System.currentTimeMillis();\n      System.out.println(\"Spent \" + (end - start) + \"ms computing partitions.\");\n      job.setPartitionerClass(TotalOrderPartitioner.class);\n    }\n    \n    job.getConfiguration().setInt(\"dfs.replication\", getOutputReplication(job));\n    TeraOutputFormat.setFinalSync(job, true);\n    int ret \u003d job.waitForCompletion(true) ? 0 : 1;\n    LOG.info(\"done\");\n    return ret;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/terasort/TeraSort.java",
      "extendedDetails": {}
    },
    "26447229ba2c3d43db978c1b3ce95613669182ee": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7590. Mavenize streaming and MR examples. (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1203941 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/11/11 5:24 PM",
      "commitName": "26447229ba2c3d43db978c1b3ce95613669182ee",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "18/11/11 1:04 AM",
      "commitNameOld": "905a127850d5e0cba85c2e075f989fa0f5cf129a",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.68,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int run(String[] args) throws Exception {\n    LOG.info(\"starting\");\n    Job job \u003d Job.getInstance(getConf());\n    Path inputDir \u003d new Path(args[0]);\n    Path outputDir \u003d new Path(args[1]);\n    boolean useSimplePartitioner \u003d getUseSimplePartitioner(job);\n    TeraInputFormat.setInputPaths(job, inputDir);\n    FileOutputFormat.setOutputPath(job, outputDir);\n    job.setJobName(\"TeraSort\");\n    job.setJarByClass(TeraSort.class);\n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(Text.class);\n    job.setInputFormatClass(TeraInputFormat.class);\n    job.setOutputFormatClass(TeraOutputFormat.class);\n    if (useSimplePartitioner) {\n      job.setPartitionerClass(SimplePartitioner.class);\n    } else {\n      long start \u003d System.currentTimeMillis();\n      Path partitionFile \u003d new Path(outputDir, \n                                    TeraInputFormat.PARTITION_FILENAME);\n      URI partitionUri \u003d new URI(partitionFile.toString() +\n                                 \"#\" + TeraInputFormat.PARTITION_FILENAME);\n      TeraInputFormat.writePartitionFile(job, partitionFile);\n      job.addCacheFile(partitionUri);\n      job.createSymlink();    \n      long end \u003d System.currentTimeMillis();\n      System.out.println(\"Spent \" + (end - start) + \"ms computing partitions.\");\n      job.setPartitionerClass(TotalOrderPartitioner.class);\n    }\n    \n    job.getConfiguration().setInt(\"dfs.replication\", getOutputReplication(job));\n    TeraOutputFormat.setFinalSync(job, true);\n    int ret \u003d job.waitForCompletion(true) ? 0 : 1;\n    LOG.info(\"done\");\n    return ret;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/terasort/TeraSort.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/src/examples/org/apache/hadoop/examples/terasort/TeraSort.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/terasort/TeraSort.java"
      }
    },
    "e1acb1222dd6fdb8fa688c815cbca6ae4193745d": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-1788. o.a.h.mapreduce.Job shouldn\u0027t make a copy of the JobConf. (Arun Murthy via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1172171 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/09/11 7:50 PM",
      "commitName": "e1acb1222dd6fdb8fa688c815cbca6ae4193745d",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 24.11,
      "commitsBetweenForRepo": 143,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,36 @@\n   public int run(String[] args) throws Exception {\n     LOG.info(\"starting\");\n-    Job job \u003d Job.getInstance(new Cluster(getConf()), getConf());\n+    Job job \u003d Job.getInstance(getConf());\n     Path inputDir \u003d new Path(args[0]);\n     Path outputDir \u003d new Path(args[1]);\n     boolean useSimplePartitioner \u003d getUseSimplePartitioner(job);\n     TeraInputFormat.setInputPaths(job, inputDir);\n     FileOutputFormat.setOutputPath(job, outputDir);\n     job.setJobName(\"TeraSort\");\n     job.setJarByClass(TeraSort.class);\n     job.setOutputKeyClass(Text.class);\n     job.setOutputValueClass(Text.class);\n     job.setInputFormatClass(TeraInputFormat.class);\n     job.setOutputFormatClass(TeraOutputFormat.class);\n     if (useSimplePartitioner) {\n       job.setPartitionerClass(SimplePartitioner.class);\n     } else {\n       long start \u003d System.currentTimeMillis();\n       Path partitionFile \u003d new Path(outputDir, \n                                     TeraInputFormat.PARTITION_FILENAME);\n       URI partitionUri \u003d new URI(partitionFile.toString() +\n                                  \"#\" + TeraInputFormat.PARTITION_FILENAME);\n       TeraInputFormat.writePartitionFile(job, partitionFile);\n       job.addCacheFile(partitionUri);\n       job.createSymlink();    \n       long end \u003d System.currentTimeMillis();\n       System.out.println(\"Spent \" + (end - start) + \"ms computing partitions.\");\n       job.setPartitionerClass(TotalOrderPartitioner.class);\n     }\n     \n     job.getConfiguration().setInt(\"dfs.replication\", getOutputReplication(job));\n     TeraOutputFormat.setFinalSync(job, true);\n     int ret \u003d job.waitForCompletion(true) ? 0 : 1;\n     LOG.info(\"done\");\n     return ret;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    LOG.info(\"starting\");\n    Job job \u003d Job.getInstance(getConf());\n    Path inputDir \u003d new Path(args[0]);\n    Path outputDir \u003d new Path(args[1]);\n    boolean useSimplePartitioner \u003d getUseSimplePartitioner(job);\n    TeraInputFormat.setInputPaths(job, inputDir);\n    FileOutputFormat.setOutputPath(job, outputDir);\n    job.setJobName(\"TeraSort\");\n    job.setJarByClass(TeraSort.class);\n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(Text.class);\n    job.setInputFormatClass(TeraInputFormat.class);\n    job.setOutputFormatClass(TeraOutputFormat.class);\n    if (useSimplePartitioner) {\n      job.setPartitionerClass(SimplePartitioner.class);\n    } else {\n      long start \u003d System.currentTimeMillis();\n      Path partitionFile \u003d new Path(outputDir, \n                                    TeraInputFormat.PARTITION_FILENAME);\n      URI partitionUri \u003d new URI(partitionFile.toString() +\n                                 \"#\" + TeraInputFormat.PARTITION_FILENAME);\n      TeraInputFormat.writePartitionFile(job, partitionFile);\n      job.addCacheFile(partitionUri);\n      job.createSymlink();    \n      long end \u003d System.currentTimeMillis();\n      System.out.println(\"Spent \" + (end - start) + \"ms computing partitions.\");\n      job.setPartitionerClass(TotalOrderPartitioner.class);\n    }\n    \n    job.getConfiguration().setInt(\"dfs.replication\", getOutputReplication(job));\n    TeraOutputFormat.setFinalSync(job, true);\n    int ret \u003d job.waitForCompletion(true) ? 0 : 1;\n    LOG.info(\"done\");\n    return ret;\n  }",
      "path": "hadoop-mapreduce-project/src/examples/org/apache/hadoop/examples/terasort/TeraSort.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int run(String[] args) throws Exception {\n    LOG.info(\"starting\");\n    Job job \u003d Job.getInstance(new Cluster(getConf()), getConf());\n    Path inputDir \u003d new Path(args[0]);\n    Path outputDir \u003d new Path(args[1]);\n    boolean useSimplePartitioner \u003d getUseSimplePartitioner(job);\n    TeraInputFormat.setInputPaths(job, inputDir);\n    FileOutputFormat.setOutputPath(job, outputDir);\n    job.setJobName(\"TeraSort\");\n    job.setJarByClass(TeraSort.class);\n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(Text.class);\n    job.setInputFormatClass(TeraInputFormat.class);\n    job.setOutputFormatClass(TeraOutputFormat.class);\n    if (useSimplePartitioner) {\n      job.setPartitionerClass(SimplePartitioner.class);\n    } else {\n      long start \u003d System.currentTimeMillis();\n      Path partitionFile \u003d new Path(outputDir, \n                                    TeraInputFormat.PARTITION_FILENAME);\n      URI partitionUri \u003d new URI(partitionFile.toString() +\n                                 \"#\" + TeraInputFormat.PARTITION_FILENAME);\n      TeraInputFormat.writePartitionFile(job, partitionFile);\n      job.addCacheFile(partitionUri);\n      job.createSymlink();    \n      long end \u003d System.currentTimeMillis();\n      System.out.println(\"Spent \" + (end - start) + \"ms computing partitions.\");\n      job.setPartitionerClass(TotalOrderPartitioner.class);\n    }\n    \n    job.getConfiguration().setInt(\"dfs.replication\", getOutputReplication(job));\n    TeraOutputFormat.setFinalSync(job, true);\n    int ret \u003d job.waitForCompletion(true) ? 0 : 1;\n    LOG.info(\"done\");\n    return ret;\n  }",
      "path": "hadoop-mapreduce-project/src/examples/org/apache/hadoop/examples/terasort/TeraSort.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/src/examples/org/apache/hadoop/examples/terasort/TeraSort.java",
        "newPath": "hadoop-mapreduce-project/src/examples/org/apache/hadoop/examples/terasort/TeraSort.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int run(String[] args) throws Exception {\n    LOG.info(\"starting\");\n    Job job \u003d Job.getInstance(new Cluster(getConf()), getConf());\n    Path inputDir \u003d new Path(args[0]);\n    Path outputDir \u003d new Path(args[1]);\n    boolean useSimplePartitioner \u003d getUseSimplePartitioner(job);\n    TeraInputFormat.setInputPaths(job, inputDir);\n    FileOutputFormat.setOutputPath(job, outputDir);\n    job.setJobName(\"TeraSort\");\n    job.setJarByClass(TeraSort.class);\n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(Text.class);\n    job.setInputFormatClass(TeraInputFormat.class);\n    job.setOutputFormatClass(TeraOutputFormat.class);\n    if (useSimplePartitioner) {\n      job.setPartitionerClass(SimplePartitioner.class);\n    } else {\n      long start \u003d System.currentTimeMillis();\n      Path partitionFile \u003d new Path(outputDir, \n                                    TeraInputFormat.PARTITION_FILENAME);\n      URI partitionUri \u003d new URI(partitionFile.toString() +\n                                 \"#\" + TeraInputFormat.PARTITION_FILENAME);\n      TeraInputFormat.writePartitionFile(job, partitionFile);\n      job.addCacheFile(partitionUri);\n      job.createSymlink();    \n      long end \u003d System.currentTimeMillis();\n      System.out.println(\"Spent \" + (end - start) + \"ms computing partitions.\");\n      job.setPartitionerClass(TotalOrderPartitioner.class);\n    }\n    \n    job.getConfiguration().setInt(\"dfs.replication\", getOutputReplication(job));\n    TeraOutputFormat.setFinalSync(job, true);\n    int ret \u003d job.waitForCompletion(true) ? 0 : 1;\n    LOG.info(\"done\");\n    return ret;\n  }",
      "path": "hadoop-mapreduce/src/examples/org/apache/hadoop/examples/terasort/TeraSort.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/examples/org/apache/hadoop/examples/terasort/TeraSort.java",
        "newPath": "hadoop-mapreduce/src/examples/org/apache/hadoop/examples/terasort/TeraSort.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,36 @@\n+  public int run(String[] args) throws Exception {\n+    LOG.info(\"starting\");\n+    Job job \u003d Job.getInstance(new Cluster(getConf()), getConf());\n+    Path inputDir \u003d new Path(args[0]);\n+    Path outputDir \u003d new Path(args[1]);\n+    boolean useSimplePartitioner \u003d getUseSimplePartitioner(job);\n+    TeraInputFormat.setInputPaths(job, inputDir);\n+    FileOutputFormat.setOutputPath(job, outputDir);\n+    job.setJobName(\"TeraSort\");\n+    job.setJarByClass(TeraSort.class);\n+    job.setOutputKeyClass(Text.class);\n+    job.setOutputValueClass(Text.class);\n+    job.setInputFormatClass(TeraInputFormat.class);\n+    job.setOutputFormatClass(TeraOutputFormat.class);\n+    if (useSimplePartitioner) {\n+      job.setPartitionerClass(SimplePartitioner.class);\n+    } else {\n+      long start \u003d System.currentTimeMillis();\n+      Path partitionFile \u003d new Path(outputDir, \n+                                    TeraInputFormat.PARTITION_FILENAME);\n+      URI partitionUri \u003d new URI(partitionFile.toString() +\n+                                 \"#\" + TeraInputFormat.PARTITION_FILENAME);\n+      TeraInputFormat.writePartitionFile(job, partitionFile);\n+      job.addCacheFile(partitionUri);\n+      job.createSymlink();    \n+      long end \u003d System.currentTimeMillis();\n+      System.out.println(\"Spent \" + (end - start) + \"ms computing partitions.\");\n+      job.setPartitionerClass(TotalOrderPartitioner.class);\n+    }\n+    \n+    job.getConfiguration().setInt(\"dfs.replication\", getOutputReplication(job));\n+    TeraOutputFormat.setFinalSync(job, true);\n+    int ret \u003d job.waitForCompletion(true) ? 0 : 1;\n+    LOG.info(\"done\");\n+    return ret;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    LOG.info(\"starting\");\n    Job job \u003d Job.getInstance(new Cluster(getConf()), getConf());\n    Path inputDir \u003d new Path(args[0]);\n    Path outputDir \u003d new Path(args[1]);\n    boolean useSimplePartitioner \u003d getUseSimplePartitioner(job);\n    TeraInputFormat.setInputPaths(job, inputDir);\n    FileOutputFormat.setOutputPath(job, outputDir);\n    job.setJobName(\"TeraSort\");\n    job.setJarByClass(TeraSort.class);\n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(Text.class);\n    job.setInputFormatClass(TeraInputFormat.class);\n    job.setOutputFormatClass(TeraOutputFormat.class);\n    if (useSimplePartitioner) {\n      job.setPartitionerClass(SimplePartitioner.class);\n    } else {\n      long start \u003d System.currentTimeMillis();\n      Path partitionFile \u003d new Path(outputDir, \n                                    TeraInputFormat.PARTITION_FILENAME);\n      URI partitionUri \u003d new URI(partitionFile.toString() +\n                                 \"#\" + TeraInputFormat.PARTITION_FILENAME);\n      TeraInputFormat.writePartitionFile(job, partitionFile);\n      job.addCacheFile(partitionUri);\n      job.createSymlink();    \n      long end \u003d System.currentTimeMillis();\n      System.out.println(\"Spent \" + (end - start) + \"ms computing partitions.\");\n      job.setPartitionerClass(TotalOrderPartitioner.class);\n    }\n    \n    job.getConfiguration().setInt(\"dfs.replication\", getOutputReplication(job));\n    TeraOutputFormat.setFinalSync(job, true);\n    int ret \u003d job.waitForCompletion(true) ? 0 : 1;\n    LOG.info(\"done\");\n    return ret;\n  }",
      "path": "mapreduce/src/examples/org/apache/hadoop/examples/terasort/TeraSort.java"
    }
  }
}