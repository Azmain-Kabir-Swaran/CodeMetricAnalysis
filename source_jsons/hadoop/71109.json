{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DynoInfraUtils.java",
  "functionName": "waitForNameNodeReadiness",
  "functionId": "waitForNameNodeReadiness___nameNodeProperties-Properties(modifiers-final)__numTotalDataNodes-int__triggerBlockReports-boolean__shouldExit-Supplier__Boolean____conf-Configuration(modifiers-final)__log-Logger(modifiers-final)",
  "sourceFilePath": "hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-infra/src/main/java/org/apache/hadoop/tools/dynamometer/DynoInfraUtils.java",
  "functionStartLine": 285,
  "functionEndLine": 402,
  "numCommitsSeen": 3,
  "timeTaken": 425,
  "changeHistory": [
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91"
  ],
  "changeHistoryShort": {
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91": "Yintroduced"
  },
  "changeHistoryDetails": {
    "ab0b180ddb5d0775a2452d5eeb7badd252aadb91": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-12345 Add Dynamometer to hadoop-tools, a tool for scale testing the HDFS NameNode with real metadata and workloads. Contributed by Erik Krogen.\n",
      "commitDate": "25/06/19 8:07 AM",
      "commitName": "ab0b180ddb5d0775a2452d5eeb7badd252aadb91",
      "commitAuthor": "Erik Krogen",
      "diff": "@@ -0,0 +1,118 @@\n+  static void waitForNameNodeReadiness(final Properties nameNodeProperties,\n+      int numTotalDataNodes, boolean triggerBlockReports,\n+      Supplier\u003cBoolean\u003e shouldExit, final Configuration conf, final Logger log)\n+      throws IOException, InterruptedException {\n+    if (shouldExit.get()) {\n+      return;\n+    }\n+    int minDataNodes \u003d (int) (conf.getFloat(DATANODE_LIVE_MIN_FRACTION_KEY,\n+        DATANODE_LIVE_MIN_FRACTION_DEFAULT) * numTotalDataNodes);\n+    log.info(String.format(\n+        \"Waiting for %d DataNodes to register with the NameNode...\",\n+        minDataNodes));\n+    waitForNameNodeJMXValue(\"Number of live DataNodes\",\n+        FSNAMESYSTEM_STATE_JMX_QUERY, JMX_LIVE_NODE_COUNT, minDataNodes,\n+        numTotalDataNodes * 0.001, false, nameNodeProperties, shouldExit, log);\n+    final int totalBlocks \u003d Integer.parseInt(fetchNameNodeJMXValue(\n+        nameNodeProperties, FSNAMESYSTEM_STATE_JMX_QUERY, JMX_BLOCKS_TOTAL));\n+    final AtomicBoolean doneWaiting \u003d new AtomicBoolean(false);\n+    if (triggerBlockReports) {\n+      // This will be significantly lower than the actual expected number of\n+      // blocks because it does not\n+      // take into account replication factor. However the block reports are\n+      // pretty binary; either a full\n+      // report has been received or it hasn\u0027t. Thus we don\u0027t mind the large\n+      // underestimate here.\n+      final int blockThreshold \u003d totalBlocks / numTotalDataNodes * 2;\n+      // The Configuration object here is based on the host cluster, which may\n+      // have security enabled; we need to disable it to talk to the Dyno NN\n+      conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n+          \"simple\");\n+      conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION,\n+          \"false\");\n+      final DistributedFileSystem dfs \u003d (DistributedFileSystem) FileSystem\n+          .get(getNameNodeHdfsUri(nameNodeProperties), conf);\n+      log.info(\"Launching thread to trigger block reports for Datanodes with \u003c\"\n+          + blockThreshold + \" blocks reported\");\n+      Thread blockReportThread \u003d new Thread(() -\u003e {\n+        // Here we count both Missing and UnderReplicated within under\n+        // replicated\n+        long lastUnderRepBlocks \u003d Long.MAX_VALUE;\n+        try {\n+          while (true) { // this will eventually exit via an interrupt\n+            try {\n+              Thread.sleep(TimeUnit.MINUTES.toMillis(1));\n+              long underRepBlocks \u003d Long\n+                  .parseLong(fetchNameNodeJMXValue(nameNodeProperties,\n+                      FSNAMESYSTEM_JMX_QUERY, JMX_MISSING_BLOCKS))\n+                  + Long.parseLong(fetchNameNodeJMXValue(nameNodeProperties,\n+                      FSNAMESYSTEM_STATE_JMX_QUERY,\n+                      JMX_UNDER_REPLICATED_BLOCKS));\n+              long blockDecrease \u003d lastUnderRepBlocks - underRepBlocks;\n+              lastUnderRepBlocks \u003d underRepBlocks;\n+              if (blockDecrease \u003c 0\n+                  || blockDecrease \u003e (totalBlocks * 0.001)) {\n+                continue;\n+              }\n+\n+              String liveNodeListString \u003d fetchNameNodeJMXValue(\n+                  nameNodeProperties, NAMENODE_INFO_JMX_QUERY,\n+                  JMX_LIVE_NODES_LIST);\n+              Set\u003cString\u003e datanodesToReport \u003d parseStaleDataNodeList(\n+                  liveNodeListString, blockThreshold, log);\n+              if (datanodesToReport.isEmpty() \u0026\u0026 doneWaiting.get()) {\n+                log.info(\"BlockReportThread exiting; all DataNodes have \"\n+                    + \"reported blocks\");\n+                break;\n+              }\n+              log.info(\"Queueing {} Datanodes for block report: {}\",\n+                      datanodesToReport.size(),\n+                      Joiner.on(\",\").join(datanodesToReport));\n+              DatanodeInfo[] datanodes \u003d dfs.getDataNodeStats();\n+              int cnt \u003d 0;\n+              for (DatanodeInfo datanode : datanodes) {\n+                if (datanodesToReport.contains(datanode.getXferAddr(true))) {\n+                  Thread.sleep(1); // to throw an interrupt if one is found\n+                  triggerDataNodeBlockReport(conf, datanode.getIpcAddr(true));\n+                  cnt++;\n+                  Thread.sleep(1000);\n+                }\n+              }\n+              if (cnt !\u003d datanodesToReport.size()) {\n+                log.warn(\"Found {} Datanodes to queue block reports for but \"\n+                        + \"was only able to trigger {}\",\n+                    datanodesToReport.size(), cnt);\n+              }\n+            } catch (IOException ioe) {\n+              log.warn(\"Exception encountered in block report thread\", ioe);\n+            }\n+          }\n+        } catch (InterruptedException ie) {\n+          // Do nothing; just exit\n+        }\n+        log.info(\"Block reporting thread exiting\");\n+      });\n+      blockReportThread.setDaemon(true);\n+      blockReportThread\n+          .setUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());\n+      blockReportThread.start();\n+    }\n+    float maxMissingBlocks \u003d totalBlocks * conf.getFloat(\n+        MISSING_BLOCKS_MAX_FRACTION_KEY, MISSING_BLOCKS_MAX_FRACTION_DEFAULT);\n+    log.info(\"Waiting for MissingBlocks to fall below {}...\",\n+        maxMissingBlocks);\n+    waitForNameNodeJMXValue(\"Number of missing blocks\", FSNAMESYSTEM_JMX_QUERY,\n+        JMX_MISSING_BLOCKS, maxMissingBlocks, totalBlocks * 0.0001, true,\n+        nameNodeProperties, shouldExit, log);\n+    float maxUnderreplicatedBlocks \u003d totalBlocks\n+        * conf.getFloat(UNDERREPLICATED_BLOCKS_MAX_FRACTION_KEY,\n+            UNDERREPLICATED_BLOCKS_MAX_FRACTION_DEFAULT);\n+    log.info(\"Waiting for UnderReplicatedBlocks to fall below {}...\",\n+        maxUnderreplicatedBlocks);\n+    waitForNameNodeJMXValue(\"Number of under replicated blocks\",\n+        FSNAMESYSTEM_STATE_JMX_QUERY, JMX_UNDER_REPLICATED_BLOCKS,\n+        maxUnderreplicatedBlocks, totalBlocks * 0.001, true, nameNodeProperties,\n+        shouldExit, log);\n+    log.info(\"NameNode is ready for use!\");\n+    doneWaiting.set(true);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static void waitForNameNodeReadiness(final Properties nameNodeProperties,\n      int numTotalDataNodes, boolean triggerBlockReports,\n      Supplier\u003cBoolean\u003e shouldExit, final Configuration conf, final Logger log)\n      throws IOException, InterruptedException {\n    if (shouldExit.get()) {\n      return;\n    }\n    int minDataNodes \u003d (int) (conf.getFloat(DATANODE_LIVE_MIN_FRACTION_KEY,\n        DATANODE_LIVE_MIN_FRACTION_DEFAULT) * numTotalDataNodes);\n    log.info(String.format(\n        \"Waiting for %d DataNodes to register with the NameNode...\",\n        minDataNodes));\n    waitForNameNodeJMXValue(\"Number of live DataNodes\",\n        FSNAMESYSTEM_STATE_JMX_QUERY, JMX_LIVE_NODE_COUNT, minDataNodes,\n        numTotalDataNodes * 0.001, false, nameNodeProperties, shouldExit, log);\n    final int totalBlocks \u003d Integer.parseInt(fetchNameNodeJMXValue(\n        nameNodeProperties, FSNAMESYSTEM_STATE_JMX_QUERY, JMX_BLOCKS_TOTAL));\n    final AtomicBoolean doneWaiting \u003d new AtomicBoolean(false);\n    if (triggerBlockReports) {\n      // This will be significantly lower than the actual expected number of\n      // blocks because it does not\n      // take into account replication factor. However the block reports are\n      // pretty binary; either a full\n      // report has been received or it hasn\u0027t. Thus we don\u0027t mind the large\n      // underestimate here.\n      final int blockThreshold \u003d totalBlocks / numTotalDataNodes * 2;\n      // The Configuration object here is based on the host cluster, which may\n      // have security enabled; we need to disable it to talk to the Dyno NN\n      conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,\n          \"simple\");\n      conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION,\n          \"false\");\n      final DistributedFileSystem dfs \u003d (DistributedFileSystem) FileSystem\n          .get(getNameNodeHdfsUri(nameNodeProperties), conf);\n      log.info(\"Launching thread to trigger block reports for Datanodes with \u003c\"\n          + blockThreshold + \" blocks reported\");\n      Thread blockReportThread \u003d new Thread(() -\u003e {\n        // Here we count both Missing and UnderReplicated within under\n        // replicated\n        long lastUnderRepBlocks \u003d Long.MAX_VALUE;\n        try {\n          while (true) { // this will eventually exit via an interrupt\n            try {\n              Thread.sleep(TimeUnit.MINUTES.toMillis(1));\n              long underRepBlocks \u003d Long\n                  .parseLong(fetchNameNodeJMXValue(nameNodeProperties,\n                      FSNAMESYSTEM_JMX_QUERY, JMX_MISSING_BLOCKS))\n                  + Long.parseLong(fetchNameNodeJMXValue(nameNodeProperties,\n                      FSNAMESYSTEM_STATE_JMX_QUERY,\n                      JMX_UNDER_REPLICATED_BLOCKS));\n              long blockDecrease \u003d lastUnderRepBlocks - underRepBlocks;\n              lastUnderRepBlocks \u003d underRepBlocks;\n              if (blockDecrease \u003c 0\n                  || blockDecrease \u003e (totalBlocks * 0.001)) {\n                continue;\n              }\n\n              String liveNodeListString \u003d fetchNameNodeJMXValue(\n                  nameNodeProperties, NAMENODE_INFO_JMX_QUERY,\n                  JMX_LIVE_NODES_LIST);\n              Set\u003cString\u003e datanodesToReport \u003d parseStaleDataNodeList(\n                  liveNodeListString, blockThreshold, log);\n              if (datanodesToReport.isEmpty() \u0026\u0026 doneWaiting.get()) {\n                log.info(\"BlockReportThread exiting; all DataNodes have \"\n                    + \"reported blocks\");\n                break;\n              }\n              log.info(\"Queueing {} Datanodes for block report: {}\",\n                      datanodesToReport.size(),\n                      Joiner.on(\",\").join(datanodesToReport));\n              DatanodeInfo[] datanodes \u003d dfs.getDataNodeStats();\n              int cnt \u003d 0;\n              for (DatanodeInfo datanode : datanodes) {\n                if (datanodesToReport.contains(datanode.getXferAddr(true))) {\n                  Thread.sleep(1); // to throw an interrupt if one is found\n                  triggerDataNodeBlockReport(conf, datanode.getIpcAddr(true));\n                  cnt++;\n                  Thread.sleep(1000);\n                }\n              }\n              if (cnt !\u003d datanodesToReport.size()) {\n                log.warn(\"Found {} Datanodes to queue block reports for but \"\n                        + \"was only able to trigger {}\",\n                    datanodesToReport.size(), cnt);\n              }\n            } catch (IOException ioe) {\n              log.warn(\"Exception encountered in block report thread\", ioe);\n            }\n          }\n        } catch (InterruptedException ie) {\n          // Do nothing; just exit\n        }\n        log.info(\"Block reporting thread exiting\");\n      });\n      blockReportThread.setDaemon(true);\n      blockReportThread\n          .setUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());\n      blockReportThread.start();\n    }\n    float maxMissingBlocks \u003d totalBlocks * conf.getFloat(\n        MISSING_BLOCKS_MAX_FRACTION_KEY, MISSING_BLOCKS_MAX_FRACTION_DEFAULT);\n    log.info(\"Waiting for MissingBlocks to fall below {}...\",\n        maxMissingBlocks);\n    waitForNameNodeJMXValue(\"Number of missing blocks\", FSNAMESYSTEM_JMX_QUERY,\n        JMX_MISSING_BLOCKS, maxMissingBlocks, totalBlocks * 0.0001, true,\n        nameNodeProperties, shouldExit, log);\n    float maxUnderreplicatedBlocks \u003d totalBlocks\n        * conf.getFloat(UNDERREPLICATED_BLOCKS_MAX_FRACTION_KEY,\n            UNDERREPLICATED_BLOCKS_MAX_FRACTION_DEFAULT);\n    log.info(\"Waiting for UnderReplicatedBlocks to fall below {}...\",\n        maxUnderreplicatedBlocks);\n    waitForNameNodeJMXValue(\"Number of under replicated blocks\",\n        FSNAMESYSTEM_STATE_JMX_QUERY, JMX_UNDER_REPLICATED_BLOCKS,\n        maxUnderreplicatedBlocks, totalBlocks * 0.001, true, nameNodeProperties,\n        shouldExit, log);\n    log.info(\"NameNode is ready for use!\");\n    doneWaiting.set(true);\n  }",
      "path": "hadoop-tools/hadoop-dynamometer/hadoop-dynamometer-infra/src/main/java/org/apache/hadoop/tools/dynamometer/DynoInfraUtils.java"
    }
  }
}