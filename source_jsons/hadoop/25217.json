{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "YARNRunner.java",
  "functionName": "createApplicationSubmissionContext",
  "functionId": "createApplicationSubmissionContext___jobConf-Configuration__jobSubmitDir-String__ts-Credentials",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
  "functionStartLine": 567,
  "functionEndLine": 666,
  "numCommitsSeen": 82,
  "timeTaken": 13059,
  "changeHistory": [
    "3721cfe1fbd98c5b6aa46aefdfcf62276c28c4a4",
    "9bae6720cb8432efd78c909dc624c00e367cedf5",
    "732ee6f0b58a12500198c0d934cc570c7490b520",
    "69fa81679f59378fd19a2c65db8019393d7c05a2",
    "819224dcf9c683aa52f58633ac8e13663f1916d8",
    "c77a1095dc556e8bea87df6d8ddf36e898f27e86",
    "f6f16118d38fcfe3b724f05fad752cb223f441ec",
    "f634505d48d97e4d461980d68a0cbdf87223646d",
    "62943b8e3aff3b274c439f72a8bb86094c1ab0e8",
    "3164e7d83875aa6b7435d1dfe61ac280aa277f1c",
    "03ab24aa01ffea1cacf1fa9cbbf73c3f2904d981",
    "10f9f5101c44be7c675a44ded4aad212627ecdee",
    "ed63b116465290fdb0acdf89170025f47b307599",
    "f19771a24c2f90982cf6dec35889836a6146c968",
    "3f282762d1afc916de9207d3adeda852ca344853",
    "de2595833cef21e3445fa7a4cb0ce7bc3f41fbd9",
    "96e0ca2d272dc7ecd7f7f0e65a0c596fcc063bcb",
    "a756de93effb8c4c041e79a72b6542d2e88b253f",
    "4594b74b8536aea308854493a0e82c8b2919174b",
    "a6ea460a9150e84128ebef97ab6ea8881215de03",
    "b64572b06b1282128180b9ebdd971f9b1e973e61",
    "643155cbee54809e1a7febd96cbb7d8111689b38",
    "259edf8dca44de54033e96f7eb65a83aaa6096f2",
    "43876770d91a374563bf3379a5ffab5c2bac2264",
    "e4c55e17fea55e2fcbef182bb2b0c4b22686f38c",
    "46315a2d914058969c7234272420c063ce268bf5",
    "88c7fdd06599671bdd519b0911c984410ecbe3fc",
    "5f7d4d2b451bec9d9db6b0a4c0b6e7991985116d",
    "2c5c8fdb80546467274607b26a1295b352c58fc8",
    "b50a3c5de32842835962e2c341cfffd14ad692d3",
    "49b20c2ed1be55c90a057acea71b55a28a3f69fb",
    "050fd3a11744cde3d54c1fff23d8fdeb3803bf92",
    "7b541d619f96ef7e447b0c3263d3ead89c8a6901",
    "dc33a0765cd27255021911c4abb435b5850387aa",
    "947ede4c4e03a1684890ede265c211482b172bec",
    "f73daf6af1c87c65dd97e5ec4608ba2742dc83ea",
    "f17ed541c76ce08b43713f06ecafd1685e16dff2",
    "6733a1ca5ef741d3bdf886f301954e9a9e7a875f",
    "df2991c0cbc3f35c2640b93680667507c4f810dd",
    "ab787f44aabfff0cd01b79a08a52ffaf923558b3",
    "b549c107825581b15fd14494099a943ff3213c6f",
    "4806d7ba74c668817ea6f35421c559eaf57a997e",
    "d00b3c49f6fb3f6a617add6203c6b55f6c345940",
    "88b82a0f6687ce103817fbb460fd30d870f717a0",
    "6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1",
    "a0ef2d7503669fe7fbbe0206ef0a41315925c150",
    "fafe8cd28e726566509c679e19d7da622f29f90d",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "3721cfe1fbd98c5b6aa46aefdfcf62276c28c4a4": "Ybodychange",
    "9bae6720cb8432efd78c909dc624c00e367cedf5": "Ybodychange",
    "732ee6f0b58a12500198c0d934cc570c7490b520": "Ybodychange",
    "69fa81679f59378fd19a2c65db8019393d7c05a2": "Ybodychange",
    "819224dcf9c683aa52f58633ac8e13663f1916d8": "Ybodychange",
    "c77a1095dc556e8bea87df6d8ddf36e898f27e86": "Ybodychange",
    "f6f16118d38fcfe3b724f05fad752cb223f441ec": "Ybodychange",
    "f634505d48d97e4d461980d68a0cbdf87223646d": "Ybodychange",
    "62943b8e3aff3b274c439f72a8bb86094c1ab0e8": "Ybodychange",
    "3164e7d83875aa6b7435d1dfe61ac280aa277f1c": "Ybodychange",
    "03ab24aa01ffea1cacf1fa9cbbf73c3f2904d981": "Ybodychange",
    "10f9f5101c44be7c675a44ded4aad212627ecdee": "Ybodychange",
    "ed63b116465290fdb0acdf89170025f47b307599": "Ybodychange",
    "f19771a24c2f90982cf6dec35889836a6146c968": "Ybodychange",
    "3f282762d1afc916de9207d3adeda852ca344853": "Ybodychange",
    "de2595833cef21e3445fa7a4cb0ce7bc3f41fbd9": "Ybodychange",
    "96e0ca2d272dc7ecd7f7f0e65a0c596fcc063bcb": "Ybodychange",
    "a756de93effb8c4c041e79a72b6542d2e88b253f": "Ybodychange",
    "4594b74b8536aea308854493a0e82c8b2919174b": "Ybodychange",
    "a6ea460a9150e84128ebef97ab6ea8881215de03": "Ybodychange",
    "b64572b06b1282128180b9ebdd971f9b1e973e61": "Ybodychange",
    "643155cbee54809e1a7febd96cbb7d8111689b38": "Ybodychange",
    "259edf8dca44de54033e96f7eb65a83aaa6096f2": "Ybodychange",
    "43876770d91a374563bf3379a5ffab5c2bac2264": "Ybodychange",
    "e4c55e17fea55e2fcbef182bb2b0c4b22686f38c": "Ybodychange",
    "46315a2d914058969c7234272420c063ce268bf5": "Ybodychange",
    "88c7fdd06599671bdd519b0911c984410ecbe3fc": "Ybodychange",
    "5f7d4d2b451bec9d9db6b0a4c0b6e7991985116d": "Ybodychange",
    "2c5c8fdb80546467274607b26a1295b352c58fc8": "Ybodychange",
    "b50a3c5de32842835962e2c341cfffd14ad692d3": "Ybodychange",
    "49b20c2ed1be55c90a057acea71b55a28a3f69fb": "Ybodychange",
    "050fd3a11744cde3d54c1fff23d8fdeb3803bf92": "Ybodychange",
    "7b541d619f96ef7e447b0c3263d3ead89c8a6901": "Ybodychange",
    "dc33a0765cd27255021911c4abb435b5850387aa": "Ybodychange",
    "947ede4c4e03a1684890ede265c211482b172bec": "Ybodychange",
    "f73daf6af1c87c65dd97e5ec4608ba2742dc83ea": "Ybodychange",
    "f17ed541c76ce08b43713f06ecafd1685e16dff2": "Ybodychange",
    "6733a1ca5ef741d3bdf886f301954e9a9e7a875f": "Ybodychange",
    "df2991c0cbc3f35c2640b93680667507c4f810dd": "Ybodychange",
    "ab787f44aabfff0cd01b79a08a52ffaf923558b3": "Ybodychange",
    "b549c107825581b15fd14494099a943ff3213c6f": "Ybodychange",
    "4806d7ba74c668817ea6f35421c559eaf57a997e": "Ybodychange",
    "d00b3c49f6fb3f6a617add6203c6b55f6c345940": "Ybodychange",
    "88b82a0f6687ce103817fbb460fd30d870f717a0": "Ybodychange",
    "6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1": "Ybodychange",
    "a0ef2d7503669fe7fbbe0206ef0a41315925c150": "Ymodifierchange",
    "fafe8cd28e726566509c679e19d7da622f29f90d": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "3721cfe1fbd98c5b6aa46aefdfcf62276c28c4a4": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6871. Allow users to specify racks and nodes for strict locality for AMs (rkanter)\n",
      "commitDate": "21/04/17 4:12 PM",
      "commitName": "3721cfe1fbd98c5b6aa46aefdfcf62276c28c4a4",
      "commitAuthor": "Robert Kanter",
      "commitDateOld": "27/03/17 5:23 PM",
      "commitNameOld": "9bae6720cb8432efd78c909dc624c00e367cedf5",
      "commitAuthorOld": "Robert Kanter",
      "daysBetweenCommits": 24.95,
      "commitsBetweenForRepo": 147,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,117 +1,100 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf, String jobSubmitDir, Credentials ts)\n       throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n-    // Setup resource requirements\n-    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n-    capability.setMemorySize(\n-        conf.getInt(\n-            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n-        )\n-    );\n-    capability.setVirtualCores(\n-        conf.getInt(\n-            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n-        )\n-    );\n-    LOG.debug(\"AppMaster capability \u003d \" + capability);\n-\n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         setupLocalResources(jobConf, jobSubmitDir);\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens \u003d\n         ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup ContainerLaunchContext for AM container\n     List\u003cString\u003e vargs \u003d setupAMCommand(jobConf);\n     ContainerLaunchContext amContainer \u003d setupContainerLaunchContextForAM(\n         jobConf, localResources, securityTokens, vargs);\n \n     String regex \u003d conf.get(MRJobConfig.MR_JOB_SEND_TOKEN_CONF);\n     if (regex !\u003d null \u0026\u0026 !regex.isEmpty()) {\n       setTokenRenewerConf(amContainer, conf, regex);\n     }\n \n \n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     // add reservationID if present\n     ReservationId reservationID \u003d null;\n     try {\n       reservationID \u003d\n           ReservationId.parseReservationId(jobConf\n               .get(JobContext.RESERVATION_ID));\n     } catch (NumberFormatException e) {\n       // throw exception as reservationid as is invalid\n       String errMsg \u003d\n           \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n               + \" specified for the app: \" + applicationId;\n       LOG.warn(errMsg);\n       throw new IOException(errMsg);\n     }\n     if (reservationID !\u003d null) {\n       appContext.setReservationID(reservationID);\n       LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n           + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n           + appContext.getReservationID());\n     }\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n-    appContext.setResource(capability);\n \n-    // set labels for the AM container request if present\n+    // Setup the AM ResourceRequests\n+    List\u003cResourceRequest\u003e amResourceRequests \u003d generateResourceRequests();\n+    appContext.setAMContainerResourceRequests(amResourceRequests);\n+\n+    // set labels for the AM container requests if present\n     String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n     if (null !\u003d amNodelabelExpression\n         \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n-      ResourceRequest amResourceRequest \u003d\n-          recordFactory.newRecordInstance(ResourceRequest.class);\n-      amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n-      amResourceRequest.setResourceName(ResourceRequest.ANY);\n-      amResourceRequest.setCapability(capability);\n-      amResourceRequest.setNumContainers(1);\n-      amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n-      appContext.setAMContainerResourceRequests(\n-          Collections.singletonList(amResourceRequest));\n+      for (ResourceRequest amResourceRequest : amResourceRequests) {\n+        amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n+      }\n     }\n     // set labels for the Job containers\n     appContext.setNodeLabelExpression(jobConf\n         .get(JobContext.JOB_NODE_LABEL_EXP));\n \n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n       appContext.setApplicationTags(new HashSet\u003c\u003e(tagsFromConf));\n     }\n \n     String jobPriority \u003d jobConf.get(MRJobConfig.PRIORITY);\n     if (jobPriority !\u003d null) {\n       int iPriority;\n       try {\n         iPriority \u003d TypeConverter.toYarnApplicationPriority(jobPriority);\n       } catch (IllegalArgumentException e) {\n         iPriority \u003d Integer.parseInt(jobPriority);\n       }\n       appContext.setPriority(Priority.newInstance(iPriority));\n     }\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf, String jobSubmitDir, Credentials ts)\n      throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        setupLocalResources(jobConf, jobSubmitDir);\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens \u003d\n        ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup ContainerLaunchContext for AM container\n    List\u003cString\u003e vargs \u003d setupAMCommand(jobConf);\n    ContainerLaunchContext amContainer \u003d setupContainerLaunchContextForAM(\n        jobConf, localResources, securityTokens, vargs);\n\n    String regex \u003d conf.get(MRJobConfig.MR_JOB_SEND_TOKEN_CONF);\n    if (regex !\u003d null \u0026\u0026 !regex.isEmpty()) {\n      setTokenRenewerConf(amContainer, conf, regex);\n    }\n\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    // add reservationID if present\n    ReservationId reservationID \u003d null;\n    try {\n      reservationID \u003d\n          ReservationId.parseReservationId(jobConf\n              .get(JobContext.RESERVATION_ID));\n    } catch (NumberFormatException e) {\n      // throw exception as reservationid as is invalid\n      String errMsg \u003d\n          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n              + \" specified for the app: \" + applicationId;\n      LOG.warn(errMsg);\n      throw new IOException(errMsg);\n    }\n    if (reservationID !\u003d null) {\n      appContext.setReservationID(reservationID);\n      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n          + appContext.getReservationID());\n    }\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n\n    // Setup the AM ResourceRequests\n    List\u003cResourceRequest\u003e amResourceRequests \u003d generateResourceRequests();\n    appContext.setAMContainerResourceRequests(amResourceRequests);\n\n    // set labels for the AM container requests if present\n    String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n    if (null !\u003d amNodelabelExpression\n        \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n      for (ResourceRequest amResourceRequest : amResourceRequests) {\n        amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n      }\n    }\n    // set labels for the Job containers\n    appContext.setNodeLabelExpression(jobConf\n        .get(JobContext.JOB_NODE_LABEL_EXP));\n\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003c\u003e(tagsFromConf));\n    }\n\n    String jobPriority \u003d jobConf.get(MRJobConfig.PRIORITY);\n    if (jobPriority !\u003d null) {\n      int iPriority;\n      try {\n        iPriority \u003d TypeConverter.toYarnApplicationPriority(jobPriority);\n      } catch (IllegalArgumentException e) {\n        iPriority \u003d Integer.parseInt(jobPriority);\n      }\n      appContext.setPriority(Priority.newInstance(iPriority));\n    }\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "9bae6720cb8432efd78c909dc624c00e367cedf5": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6050. AMs can\u0027t be scheduled on racks or nodes (rkanter)\n",
      "commitDate": "27/03/17 5:23 PM",
      "commitName": "9bae6720cb8432efd78c909dc624c00e367cedf5",
      "commitAuthor": "Robert Kanter",
      "commitDateOld": "22/02/17 3:38 PM",
      "commitNameOld": "732ee6f0b58a12500198c0d934cc570c7490b520",
      "commitAuthorOld": "Daniel Templeton",
      "daysBetweenCommits": 33.03,
      "commitsBetweenForRepo": 202,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,116 +1,117 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf, String jobSubmitDir, Credentials ts)\n       throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemorySize(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n         )\n     );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n         )\n     );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         setupLocalResources(jobConf, jobSubmitDir);\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens \u003d\n         ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup ContainerLaunchContext for AM container\n     List\u003cString\u003e vargs \u003d setupAMCommand(jobConf);\n     ContainerLaunchContext amContainer \u003d setupContainerLaunchContextForAM(\n         jobConf, localResources, securityTokens, vargs);\n \n     String regex \u003d conf.get(MRJobConfig.MR_JOB_SEND_TOKEN_CONF);\n     if (regex !\u003d null \u0026\u0026 !regex.isEmpty()) {\n       setTokenRenewerConf(amContainer, conf, regex);\n     }\n \n \n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     // add reservationID if present\n     ReservationId reservationID \u003d null;\n     try {\n       reservationID \u003d\n           ReservationId.parseReservationId(jobConf\n               .get(JobContext.RESERVATION_ID));\n     } catch (NumberFormatException e) {\n       // throw exception as reservationid as is invalid\n       String errMsg \u003d\n           \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n               + \" specified for the app: \" + applicationId;\n       LOG.warn(errMsg);\n       throw new IOException(errMsg);\n     }\n     if (reservationID !\u003d null) {\n       appContext.setReservationID(reservationID);\n       LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n           + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n           + appContext.getReservationID());\n     }\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n \n     // set labels for the AM container request if present\n     String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n     if (null !\u003d amNodelabelExpression\n         \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n       ResourceRequest amResourceRequest \u003d\n           recordFactory.newRecordInstance(ResourceRequest.class);\n       amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n       amResourceRequest.setResourceName(ResourceRequest.ANY);\n       amResourceRequest.setCapability(capability);\n       amResourceRequest.setNumContainers(1);\n       amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n-      appContext.setAMContainerResourceRequest(amResourceRequest);\n+      appContext.setAMContainerResourceRequests(\n+          Collections.singletonList(amResourceRequest));\n     }\n     // set labels for the Job containers\n     appContext.setNodeLabelExpression(jobConf\n         .get(JobContext.JOB_NODE_LABEL_EXP));\n \n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n       appContext.setApplicationTags(new HashSet\u003c\u003e(tagsFromConf));\n     }\n \n     String jobPriority \u003d jobConf.get(MRJobConfig.PRIORITY);\n     if (jobPriority !\u003d null) {\n       int iPriority;\n       try {\n         iPriority \u003d TypeConverter.toYarnApplicationPriority(jobPriority);\n       } catch (IllegalArgumentException e) {\n         iPriority \u003d Integer.parseInt(jobPriority);\n       }\n       appContext.setPriority(Priority.newInstance(iPriority));\n     }\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf, String jobSubmitDir, Credentials ts)\n      throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemorySize(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n        )\n    );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n        )\n    );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        setupLocalResources(jobConf, jobSubmitDir);\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens \u003d\n        ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup ContainerLaunchContext for AM container\n    List\u003cString\u003e vargs \u003d setupAMCommand(jobConf);\n    ContainerLaunchContext amContainer \u003d setupContainerLaunchContextForAM(\n        jobConf, localResources, securityTokens, vargs);\n\n    String regex \u003d conf.get(MRJobConfig.MR_JOB_SEND_TOKEN_CONF);\n    if (regex !\u003d null \u0026\u0026 !regex.isEmpty()) {\n      setTokenRenewerConf(amContainer, conf, regex);\n    }\n\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    // add reservationID if present\n    ReservationId reservationID \u003d null;\n    try {\n      reservationID \u003d\n          ReservationId.parseReservationId(jobConf\n              .get(JobContext.RESERVATION_ID));\n    } catch (NumberFormatException e) {\n      // throw exception as reservationid as is invalid\n      String errMsg \u003d\n          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n              + \" specified for the app: \" + applicationId;\n      LOG.warn(errMsg);\n      throw new IOException(errMsg);\n    }\n    if (reservationID !\u003d null) {\n      appContext.setReservationID(reservationID);\n      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n          + appContext.getReservationID());\n    }\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n\n    // set labels for the AM container request if present\n    String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n    if (null !\u003d amNodelabelExpression\n        \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n      ResourceRequest amResourceRequest \u003d\n          recordFactory.newRecordInstance(ResourceRequest.class);\n      amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n      amResourceRequest.setResourceName(ResourceRequest.ANY);\n      amResourceRequest.setCapability(capability);\n      amResourceRequest.setNumContainers(1);\n      amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n      appContext.setAMContainerResourceRequests(\n          Collections.singletonList(amResourceRequest));\n    }\n    // set labels for the Job containers\n    appContext.setNodeLabelExpression(jobConf\n        .get(JobContext.JOB_NODE_LABEL_EXP));\n\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003c\u003e(tagsFromConf));\n    }\n\n    String jobPriority \u003d jobConf.get(MRJobConfig.PRIORITY);\n    if (jobPriority !\u003d null) {\n      int iPriority;\n      try {\n        iPriority \u003d TypeConverter.toYarnApplicationPriority(jobPriority);\n      } catch (IllegalArgumentException e) {\n        iPriority \u003d Integer.parseInt(jobPriority);\n      }\n      appContext.setPriority(Priority.newInstance(iPriority));\n    }\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "732ee6f0b58a12500198c0d934cc570c7490b520": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6825. YARNRunner#createApplicationSubmissionContext method is longer than 150 lines (Contributed by Gergely Nov√°k via Daniel Templeton)\n",
      "commitDate": "22/02/17 3:38 PM",
      "commitName": "732ee6f0b58a12500198c0d934cc570c7490b520",
      "commitAuthor": "Daniel Templeton",
      "commitDateOld": "23/01/17 9:12 AM",
      "commitNameOld": "69fa81679f59378fd19a2c65db8019393d7c05a2",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 30.27,
      "commitsBetweenForRepo": 143,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,251 +1,116 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n-      Configuration jobConf,\n-      String jobSubmitDir, Credentials ts) throws IOException {\n+      Configuration jobConf, String jobSubmitDir, Credentials ts)\n+      throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemorySize(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n-            )\n-        );\n+        )\n+    );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n-            )\n-        );\n+        )\n+    );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n-        new HashMap\u003cString, LocalResource\u003e();\n-\n-    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n-\n-    URL yarnUrlForJobSubmitDir \u003d URL.fromPath(defaultFileContext.getDefaultFileSystem()\n-            .resolvePath(\n-                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n-    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n-        + yarnUrlForJobSubmitDir);\n-\n-    localResources.put(MRJobConfig.JOB_CONF_FILE,\n-        createApplicationResource(defaultFileContext,\n-            jobConfPath, LocalResourceType.FILE));\n-    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n-      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n-      LocalResource rc \u003d createApplicationResource(\n-          FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n-          jobJarPath,\n-          LocalResourceType.PATTERN);\n-      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n-          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n-      rc.setPattern(pattern);\n-      localResources.put(MRJobConfig.JOB_JAR, rc);\n-    } else {\n-      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n-      // mapreduce jar itself which is already on the classpath.\n-      LOG.info(\"Job jar is not present. \"\n-          + \"Not adding any jar to the list of resources.\");\n-    }\n-\n-    // TODO gross hack\n-    for (String s : new String[] {\n-        MRJobConfig.JOB_SPLIT,\n-        MRJobConfig.JOB_SPLIT_METAINFO }) {\n-      localResources.put(\n-          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n-          createApplicationResource(defaultFileContext,\n-              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n-    }\n+        setupLocalResources(jobConf, jobSubmitDir);\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n-    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n-\n-    // Setup the command to run the AM\n-    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n-    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n-        + \"/bin/java\");\n-\n-    Path amTmpDir \u003d\n-        new Path(MRApps.crossPlatformifyMREnv(conf, Environment.PWD),\n-            YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);\n-    vargs.add(\"-Djava.io.tmpdir\u003d\" + amTmpDir);\n-    MRApps.addLog4jSystemProperties(null, vargs, conf);\n-\n-    // Check for Java Lib Path usage in MAP and REDUCE configs\n-    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n-        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n-    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n-        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n-    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n-        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n-    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n-        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n-\n-    // Add AM admin command opts before user command opts\n-    // so that it can be overridden by user\n-    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n-        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n-    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n-        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n-    vargs.add(mrAppMasterAdminOptions);\n-    \n-    // Add AM user command opts\n-    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n-        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n-    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n-        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n-    vargs.add(mrAppMasterUserOptions);\n-\n-    if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n-        MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n-      final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n-          MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n-      if (profileParams !\u003d null) {\n-        vargs.add(String.format(profileParams,\n-            ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n-                + TaskLog.LogName.PROFILE));\n-      }\n-    }\n-\n-    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n-    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n-        Path.SEPARATOR + ApplicationConstants.STDOUT);\n-    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n-        Path.SEPARATOR + ApplicationConstants.STDERR);\n-\n-\n-    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n-    // Final command\n-    StringBuilder mergedCommand \u003d new StringBuilder();\n-    for (CharSequence str : vargs) {\n-      mergedCommand.append(str).append(\" \");\n-    }\n-    vargsFinal.add(mergedCommand.toString());\n-\n-    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n-        + mergedCommand);\n-\n-    // Setup the CLASSPATH in environment\n-    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n-    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n-    MRApps.setClasspath(environment, conf);\n-\n-    // Shell\n-    environment.put(Environment.SHELL.name(),\n-        conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n-            MRJobConfig.DEFAULT_SHELL));\n-\n-    // Add the container working directory in front of LD_LIBRARY_PATH\n-    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n-        MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n-\n-    // Setup the environment variables for Admin first\n-    MRApps.setEnvFromInputString(environment, \n-        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV,\n-            MRJobConfig.DEFAULT_MR_AM_ADMIN_USER_ENV), conf);\n-    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n-    MRApps.setEnvFromInputString(environment, \n-        conf.get(MRJobConfig.MR_AM_ENV), conf);\n-\n-    // Parse distributed cache\n-    MRApps.setupDistributedCache(jobConf, localResources);\n-\n-    Map\u003cApplicationAccessType, String\u003e acls\n-        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n-    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n-        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n-    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n-        MRJobConfig.JOB_ACL_MODIFY_JOB,\n-        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n+    ByteBuffer securityTokens \u003d\n+        ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup ContainerLaunchContext for AM container\n-    ContainerLaunchContext amContainer \u003d\n-        ContainerLaunchContext.newInstance(localResources, environment,\n-          vargsFinal, null, securityTokens, acls);\n+    List\u003cString\u003e vargs \u003d setupAMCommand(jobConf);\n+    ContainerLaunchContext amContainer \u003d setupContainerLaunchContextForAM(\n+        jobConf, localResources, securityTokens, vargs);\n \n     String regex \u003d conf.get(MRJobConfig.MR_JOB_SEND_TOKEN_CONF);\n     if (regex !\u003d null \u0026\u0026 !regex.isEmpty()) {\n       setTokenRenewerConf(amContainer, conf, regex);\n     }\n \n \n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     // add reservationID if present\n     ReservationId reservationID \u003d null;\n     try {\n       reservationID \u003d\n           ReservationId.parseReservationId(jobConf\n               .get(JobContext.RESERVATION_ID));\n     } catch (NumberFormatException e) {\n       // throw exception as reservationid as is invalid\n       String errMsg \u003d\n           \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n               + \" specified for the app: \" + applicationId;\n       LOG.warn(errMsg);\n       throw new IOException(errMsg);\n     }\n     if (reservationID !\u003d null) {\n       appContext.setReservationID(reservationID);\n       LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n           + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n           + appContext.getReservationID());\n     }\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n \n     // set labels for the AM container request if present\n     String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n     if (null !\u003d amNodelabelExpression\n         \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n       ResourceRequest amResourceRequest \u003d\n           recordFactory.newRecordInstance(ResourceRequest.class);\n       amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n       amResourceRequest.setResourceName(ResourceRequest.ANY);\n       amResourceRequest.setCapability(capability);\n       amResourceRequest.setNumContainers(1);\n       amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n       appContext.setAMContainerResourceRequest(amResourceRequest);\n     }\n     // set labels for the Job containers\n     appContext.setNodeLabelExpression(jobConf\n         .get(JobContext.JOB_NODE_LABEL_EXP));\n \n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n-      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n+      appContext.setApplicationTags(new HashSet\u003c\u003e(tagsFromConf));\n     }\n \n     String jobPriority \u003d jobConf.get(MRJobConfig.PRIORITY);\n     if (jobPriority !\u003d null) {\n       int iPriority;\n       try {\n         iPriority \u003d TypeConverter.toYarnApplicationPriority(jobPriority);\n       } catch (IllegalArgumentException e) {\n         iPriority \u003d Integer.parseInt(jobPriority);\n       }\n       appContext.setPriority(Priority.newInstance(iPriority));\n     }\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf, String jobSubmitDir, Credentials ts)\n      throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemorySize(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n        )\n    );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n        )\n    );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        setupLocalResources(jobConf, jobSubmitDir);\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens \u003d\n        ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup ContainerLaunchContext for AM container\n    List\u003cString\u003e vargs \u003d setupAMCommand(jobConf);\n    ContainerLaunchContext amContainer \u003d setupContainerLaunchContextForAM(\n        jobConf, localResources, securityTokens, vargs);\n\n    String regex \u003d conf.get(MRJobConfig.MR_JOB_SEND_TOKEN_CONF);\n    if (regex !\u003d null \u0026\u0026 !regex.isEmpty()) {\n      setTokenRenewerConf(amContainer, conf, regex);\n    }\n\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    // add reservationID if present\n    ReservationId reservationID \u003d null;\n    try {\n      reservationID \u003d\n          ReservationId.parseReservationId(jobConf\n              .get(JobContext.RESERVATION_ID));\n    } catch (NumberFormatException e) {\n      // throw exception as reservationid as is invalid\n      String errMsg \u003d\n          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n              + \" specified for the app: \" + applicationId;\n      LOG.warn(errMsg);\n      throw new IOException(errMsg);\n    }\n    if (reservationID !\u003d null) {\n      appContext.setReservationID(reservationID);\n      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n          + appContext.getReservationID());\n    }\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n\n    // set labels for the AM container request if present\n    String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n    if (null !\u003d amNodelabelExpression\n        \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n      ResourceRequest amResourceRequest \u003d\n          recordFactory.newRecordInstance(ResourceRequest.class);\n      amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n      amResourceRequest.setResourceName(ResourceRequest.ANY);\n      amResourceRequest.setCapability(capability);\n      amResourceRequest.setNumContainers(1);\n      amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n      appContext.setAMContainerResourceRequest(amResourceRequest);\n    }\n    // set labels for the Job containers\n    appContext.setNodeLabelExpression(jobConf\n        .get(JobContext.JOB_NODE_LABEL_EXP));\n\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003c\u003e(tagsFromConf));\n    }\n\n    String jobPriority \u003d jobConf.get(MRJobConfig.PRIORITY);\n    if (jobPriority !\u003d null) {\n      int iPriority;\n      try {\n        iPriority \u003d TypeConverter.toYarnApplicationPriority(jobPriority);\n      } catch (IllegalArgumentException e) {\n        iPriority \u003d Integer.parseInt(jobPriority);\n      }\n      appContext.setPriority(Priority.newInstance(iPriority));\n    }\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "69fa81679f59378fd19a2c65db8019393d7c05a2": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5910. Support for multi-cluster delegation tokens. Contributed by Jian He\n",
      "commitDate": "23/01/17 9:12 AM",
      "commitName": "69fa81679f59378fd19a2c65db8019393d7c05a2",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "11/07/16 10:36 PM",
      "commitNameOld": "819224dcf9c683aa52f58633ac8e13663f1916d8",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 195.48,
      "commitsBetweenForRepo": 1296,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,245 +1,251 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemorySize(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d URL.fromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(\n           FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n           jobJarPath,\n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n         + \"/bin/java\");\n \n     Path amTmpDir \u003d\n         new Path(MRApps.crossPlatformifyMREnv(conf, Environment.PWD),\n             YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);\n     vargs.add(\"-Djava.io.tmpdir\u003d\" + amTmpDir);\n     MRApps.addLog4jSystemProperties(null, vargs, conf);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n \n     if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n         MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n       final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n           MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n       if (profileParams !\u003d null) {\n         vargs.add(String.format(profileParams,\n             ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                 + TaskLog.LogName.PROFILE));\n       }\n     }\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n     // Shell\n     environment.put(Environment.SHELL.name(),\n         conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n             MRJobConfig.DEFAULT_SHELL));\n \n     // Add the container working directory in front of LD_LIBRARY_PATH\n     MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n         MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV,\n             MRJobConfig.DEFAULT_MR_AM_ADMIN_USER_ENV), conf);\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV), conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n+    String regex \u003d conf.get(MRJobConfig.MR_JOB_SEND_TOKEN_CONF);\n+    if (regex !\u003d null \u0026\u0026 !regex.isEmpty()) {\n+      setTokenRenewerConf(amContainer, conf, regex);\n+    }\n+\n+\n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     // add reservationID if present\n     ReservationId reservationID \u003d null;\n     try {\n       reservationID \u003d\n           ReservationId.parseReservationId(jobConf\n               .get(JobContext.RESERVATION_ID));\n     } catch (NumberFormatException e) {\n       // throw exception as reservationid as is invalid\n       String errMsg \u003d\n           \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n               + \" specified for the app: \" + applicationId;\n       LOG.warn(errMsg);\n       throw new IOException(errMsg);\n     }\n     if (reservationID !\u003d null) {\n       appContext.setReservationID(reservationID);\n       LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n           + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n           + appContext.getReservationID());\n     }\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n \n     // set labels for the AM container request if present\n     String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n     if (null !\u003d amNodelabelExpression\n         \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n       ResourceRequest amResourceRequest \u003d\n           recordFactory.newRecordInstance(ResourceRequest.class);\n       amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n       amResourceRequest.setResourceName(ResourceRequest.ANY);\n       amResourceRequest.setCapability(capability);\n       amResourceRequest.setNumContainers(1);\n       amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n       appContext.setAMContainerResourceRequest(amResourceRequest);\n     }\n     // set labels for the Job containers\n     appContext.setNodeLabelExpression(jobConf\n         .get(JobContext.JOB_NODE_LABEL_EXP));\n \n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n       appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n     }\n \n     String jobPriority \u003d jobConf.get(MRJobConfig.PRIORITY);\n     if (jobPriority !\u003d null) {\n       int iPriority;\n       try {\n         iPriority \u003d TypeConverter.toYarnApplicationPriority(jobPriority);\n       } catch (IllegalArgumentException e) {\n         iPriority \u003d Integer.parseInt(jobPriority);\n       }\n       appContext.setPriority(Priority.newInstance(iPriority));\n     }\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemorySize(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d URL.fromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(\n          FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n          jobJarPath,\n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n        + \"/bin/java\");\n\n    Path amTmpDir \u003d\n        new Path(MRApps.crossPlatformifyMREnv(conf, Environment.PWD),\n            YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);\n    vargs.add(\"-Djava.io.tmpdir\u003d\" + amTmpDir);\n    MRApps.addLog4jSystemProperties(null, vargs, conf);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n\n    if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n        MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n      final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n          MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n      if (profileParams !\u003d null) {\n        vargs.add(String.format(profileParams,\n            ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                + TaskLog.LogName.PROFILE));\n      }\n    }\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Shell\n    environment.put(Environment.SHELL.name(),\n        conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n            MRJobConfig.DEFAULT_SHELL));\n\n    // Add the container working directory in front of LD_LIBRARY_PATH\n    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n        MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n\n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV,\n            MRJobConfig.DEFAULT_MR_AM_ADMIN_USER_ENV), conf);\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV), conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    String regex \u003d conf.get(MRJobConfig.MR_JOB_SEND_TOKEN_CONF);\n    if (regex !\u003d null \u0026\u0026 !regex.isEmpty()) {\n      setTokenRenewerConf(amContainer, conf, regex);\n    }\n\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    // add reservationID if present\n    ReservationId reservationID \u003d null;\n    try {\n      reservationID \u003d\n          ReservationId.parseReservationId(jobConf\n              .get(JobContext.RESERVATION_ID));\n    } catch (NumberFormatException e) {\n      // throw exception as reservationid as is invalid\n      String errMsg \u003d\n          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n              + \" specified for the app: \" + applicationId;\n      LOG.warn(errMsg);\n      throw new IOException(errMsg);\n    }\n    if (reservationID !\u003d null) {\n      appContext.setReservationID(reservationID);\n      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n          + appContext.getReservationID());\n    }\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n\n    // set labels for the AM container request if present\n    String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n    if (null !\u003d amNodelabelExpression\n        \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n      ResourceRequest amResourceRequest \u003d\n          recordFactory.newRecordInstance(ResourceRequest.class);\n      amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n      amResourceRequest.setResourceName(ResourceRequest.ANY);\n      amResourceRequest.setCapability(capability);\n      amResourceRequest.setNumContainers(1);\n      amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n      appContext.setAMContainerResourceRequest(amResourceRequest);\n    }\n    // set labels for the Job containers\n    appContext.setNodeLabelExpression(jobConf\n        .get(JobContext.JOB_NODE_LABEL_EXP));\n\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n    }\n\n    String jobPriority \u003d jobConf.get(MRJobConfig.PRIORITY);\n    if (jobPriority !\u003d null) {\n      int iPriority;\n      try {\n        iPriority \u003d TypeConverter.toYarnApplicationPriority(jobPriority);\n      } catch (IllegalArgumentException e) {\n        iPriority \u003d Integer.parseInt(jobPriority);\n      }\n      appContext.setPriority(Priority.newInstance(iPriority));\n    }\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "819224dcf9c683aa52f58633ac8e13663f1916d8": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5270. Solve miscellaneous issues caused by YARN-4844. Contributed by Wangda Tan\n",
      "commitDate": "11/07/16 10:36 PM",
      "commitName": "819224dcf9c683aa52f58633ac8e13663f1916d8",
      "commitAuthor": "Jian He",
      "commitDateOld": "14/06/16 3:06 PM",
      "commitNameOld": "c77a1095dc556e8bea87df6d8ddf36e898f27e86",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 27.31,
      "commitsBetweenForRepo": 304,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,245 +1,245 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n-    capability.setMemory(\n+    capability.setMemorySize(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d URL.fromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(\n           FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n           jobJarPath,\n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n         + \"/bin/java\");\n \n     Path amTmpDir \u003d\n         new Path(MRApps.crossPlatformifyMREnv(conf, Environment.PWD),\n             YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);\n     vargs.add(\"-Djava.io.tmpdir\u003d\" + amTmpDir);\n     MRApps.addLog4jSystemProperties(null, vargs, conf);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n \n     if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n         MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n       final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n           MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n       if (profileParams !\u003d null) {\n         vargs.add(String.format(profileParams,\n             ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                 + TaskLog.LogName.PROFILE));\n       }\n     }\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n     // Shell\n     environment.put(Environment.SHELL.name(),\n         conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n             MRJobConfig.DEFAULT_SHELL));\n \n     // Add the container working directory in front of LD_LIBRARY_PATH\n     MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n         MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV,\n             MRJobConfig.DEFAULT_MR_AM_ADMIN_USER_ENV), conf);\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV), conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     // add reservationID if present\n     ReservationId reservationID \u003d null;\n     try {\n       reservationID \u003d\n           ReservationId.parseReservationId(jobConf\n               .get(JobContext.RESERVATION_ID));\n     } catch (NumberFormatException e) {\n       // throw exception as reservationid as is invalid\n       String errMsg \u003d\n           \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n               + \" specified for the app: \" + applicationId;\n       LOG.warn(errMsg);\n       throw new IOException(errMsg);\n     }\n     if (reservationID !\u003d null) {\n       appContext.setReservationID(reservationID);\n       LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n           + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n           + appContext.getReservationID());\n     }\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n \n     // set labels for the AM container request if present\n     String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n     if (null !\u003d amNodelabelExpression\n         \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n       ResourceRequest amResourceRequest \u003d\n           recordFactory.newRecordInstance(ResourceRequest.class);\n       amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n       amResourceRequest.setResourceName(ResourceRequest.ANY);\n       amResourceRequest.setCapability(capability);\n       amResourceRequest.setNumContainers(1);\n       amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n       appContext.setAMContainerResourceRequest(amResourceRequest);\n     }\n     // set labels for the Job containers\n     appContext.setNodeLabelExpression(jobConf\n         .get(JobContext.JOB_NODE_LABEL_EXP));\n \n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n       appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n     }\n \n     String jobPriority \u003d jobConf.get(MRJobConfig.PRIORITY);\n     if (jobPriority !\u003d null) {\n       int iPriority;\n       try {\n         iPriority \u003d TypeConverter.toYarnApplicationPriority(jobPriority);\n       } catch (IllegalArgumentException e) {\n         iPriority \u003d Integer.parseInt(jobPriority);\n       }\n       appContext.setPriority(Priority.newInstance(iPriority));\n     }\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemorySize(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d URL.fromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(\n          FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n          jobJarPath,\n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n        + \"/bin/java\");\n\n    Path amTmpDir \u003d\n        new Path(MRApps.crossPlatformifyMREnv(conf, Environment.PWD),\n            YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);\n    vargs.add(\"-Djava.io.tmpdir\u003d\" + amTmpDir);\n    MRApps.addLog4jSystemProperties(null, vargs, conf);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n\n    if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n        MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n      final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n          MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n      if (profileParams !\u003d null) {\n        vargs.add(String.format(profileParams,\n            ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                + TaskLog.LogName.PROFILE));\n      }\n    }\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Shell\n    environment.put(Environment.SHELL.name(),\n        conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n            MRJobConfig.DEFAULT_SHELL));\n\n    // Add the container working directory in front of LD_LIBRARY_PATH\n    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n        MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n\n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV,\n            MRJobConfig.DEFAULT_MR_AM_ADMIN_USER_ENV), conf);\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV), conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    // add reservationID if present\n    ReservationId reservationID \u003d null;\n    try {\n      reservationID \u003d\n          ReservationId.parseReservationId(jobConf\n              .get(JobContext.RESERVATION_ID));\n    } catch (NumberFormatException e) {\n      // throw exception as reservationid as is invalid\n      String errMsg \u003d\n          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n              + \" specified for the app: \" + applicationId;\n      LOG.warn(errMsg);\n      throw new IOException(errMsg);\n    }\n    if (reservationID !\u003d null) {\n      appContext.setReservationID(reservationID);\n      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n          + appContext.getReservationID());\n    }\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n\n    // set labels for the AM container request if present\n    String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n    if (null !\u003d amNodelabelExpression\n        \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n      ResourceRequest amResourceRequest \u003d\n          recordFactory.newRecordInstance(ResourceRequest.class);\n      amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n      amResourceRequest.setResourceName(ResourceRequest.ANY);\n      amResourceRequest.setCapability(capability);\n      amResourceRequest.setNumContainers(1);\n      amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n      appContext.setAMContainerResourceRequest(amResourceRequest);\n    }\n    // set labels for the Job containers\n    appContext.setNodeLabelExpression(jobConf\n        .get(JobContext.JOB_NODE_LABEL_EXP));\n\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n    }\n\n    String jobPriority \u003d jobConf.get(MRJobConfig.PRIORITY);\n    if (jobPriority !\u003d null) {\n      int iPriority;\n      try {\n        iPriority \u003d TypeConverter.toYarnApplicationPriority(jobPriority);\n      } catch (IllegalArgumentException e) {\n        iPriority \u003d Integer.parseInt(jobPriority);\n      }\n      appContext.setPriority(Priority.newInstance(iPriority));\n    }\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "c77a1095dc556e8bea87df6d8ddf36e898f27e86": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1942. Deprecate toString/fromString methods from ConverterUtils and move them to records classes like ContainerId/ApplicationId, etc. (wangda)\n",
      "commitDate": "14/06/16 3:06 PM",
      "commitName": "c77a1095dc556e8bea87df6d8ddf36e898f27e86",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "01/02/16 8:05 AM",
      "commitNameOld": "59a212b6e1265adfa9b55c71b65a22157dfccf77",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 134.25,
      "commitsBetweenForRepo": 866,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,246 +1,245 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n-    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n-        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n+    URL yarnUrlForJobSubmitDir \u003d URL.fromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(\n           FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n           jobJarPath,\n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n         + \"/bin/java\");\n \n     Path amTmpDir \u003d\n         new Path(MRApps.crossPlatformifyMREnv(conf, Environment.PWD),\n             YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);\n     vargs.add(\"-Djava.io.tmpdir\u003d\" + amTmpDir);\n     MRApps.addLog4jSystemProperties(null, vargs, conf);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n \n     if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n         MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n       final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n           MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n       if (profileParams !\u003d null) {\n         vargs.add(String.format(profileParams,\n             ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                 + TaskLog.LogName.PROFILE));\n       }\n     }\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n     // Shell\n     environment.put(Environment.SHELL.name(),\n         conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n             MRJobConfig.DEFAULT_SHELL));\n \n     // Add the container working directory in front of LD_LIBRARY_PATH\n     MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n         MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV,\n             MRJobConfig.DEFAULT_MR_AM_ADMIN_USER_ENV), conf);\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV), conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     // add reservationID if present\n     ReservationId reservationID \u003d null;\n     try {\n       reservationID \u003d\n           ReservationId.parseReservationId(jobConf\n               .get(JobContext.RESERVATION_ID));\n     } catch (NumberFormatException e) {\n       // throw exception as reservationid as is invalid\n       String errMsg \u003d\n           \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n               + \" specified for the app: \" + applicationId;\n       LOG.warn(errMsg);\n       throw new IOException(errMsg);\n     }\n     if (reservationID !\u003d null) {\n       appContext.setReservationID(reservationID);\n       LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n           + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n           + appContext.getReservationID());\n     }\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n \n     // set labels for the AM container request if present\n     String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n     if (null !\u003d amNodelabelExpression\n         \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n       ResourceRequest amResourceRequest \u003d\n           recordFactory.newRecordInstance(ResourceRequest.class);\n       amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n       amResourceRequest.setResourceName(ResourceRequest.ANY);\n       amResourceRequest.setCapability(capability);\n       amResourceRequest.setNumContainers(1);\n       amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n       appContext.setAMContainerResourceRequest(amResourceRequest);\n     }\n     // set labels for the Job containers\n     appContext.setNodeLabelExpression(jobConf\n         .get(JobContext.JOB_NODE_LABEL_EXP));\n \n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n       appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n     }\n \n     String jobPriority \u003d jobConf.get(MRJobConfig.PRIORITY);\n     if (jobPriority !\u003d null) {\n       int iPriority;\n       try {\n         iPriority \u003d TypeConverter.toYarnApplicationPriority(jobPriority);\n       } catch (IllegalArgumentException e) {\n         iPriority \u003d Integer.parseInt(jobPriority);\n       }\n       appContext.setPriority(Priority.newInstance(iPriority));\n     }\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d URL.fromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(\n          FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n          jobJarPath,\n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n        + \"/bin/java\");\n\n    Path amTmpDir \u003d\n        new Path(MRApps.crossPlatformifyMREnv(conf, Environment.PWD),\n            YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);\n    vargs.add(\"-Djava.io.tmpdir\u003d\" + amTmpDir);\n    MRApps.addLog4jSystemProperties(null, vargs, conf);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n\n    if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n        MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n      final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n          MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n      if (profileParams !\u003d null) {\n        vargs.add(String.format(profileParams,\n            ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                + TaskLog.LogName.PROFILE));\n      }\n    }\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Shell\n    environment.put(Environment.SHELL.name(),\n        conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n            MRJobConfig.DEFAULT_SHELL));\n\n    // Add the container working directory in front of LD_LIBRARY_PATH\n    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n        MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n\n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV,\n            MRJobConfig.DEFAULT_MR_AM_ADMIN_USER_ENV), conf);\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV), conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    // add reservationID if present\n    ReservationId reservationID \u003d null;\n    try {\n      reservationID \u003d\n          ReservationId.parseReservationId(jobConf\n              .get(JobContext.RESERVATION_ID));\n    } catch (NumberFormatException e) {\n      // throw exception as reservationid as is invalid\n      String errMsg \u003d\n          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n              + \" specified for the app: \" + applicationId;\n      LOG.warn(errMsg);\n      throw new IOException(errMsg);\n    }\n    if (reservationID !\u003d null) {\n      appContext.setReservationID(reservationID);\n      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n          + appContext.getReservationID());\n    }\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n\n    // set labels for the AM container request if present\n    String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n    if (null !\u003d amNodelabelExpression\n        \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n      ResourceRequest amResourceRequest \u003d\n          recordFactory.newRecordInstance(ResourceRequest.class);\n      amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n      amResourceRequest.setResourceName(ResourceRequest.ANY);\n      amResourceRequest.setCapability(capability);\n      amResourceRequest.setNumContainers(1);\n      amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n      appContext.setAMContainerResourceRequest(amResourceRequest);\n    }\n    // set labels for the Job containers\n    appContext.setNodeLabelExpression(jobConf\n        .get(JobContext.JOB_NODE_LABEL_EXP));\n\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n    }\n\n    String jobPriority \u003d jobConf.get(MRJobConfig.PRIORITY);\n    if (jobPriority !\u003d null) {\n      int iPriority;\n      try {\n        iPriority \u003d TypeConverter.toYarnApplicationPriority(jobPriority);\n      } catch (IllegalArgumentException e) {\n        iPriority \u003d Integer.parseInt(jobPriority);\n      }\n      appContext.setPriority(Priority.newInstance(iPriority));\n    }\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "f6f16118d38fcfe3b724f05fad752cb223f441ec": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6577. MR AM unable to load native library without MR_AM_ADMIN_USER_ENV set (sjlee)\n",
      "commitDate": "05/01/16 3:22 PM",
      "commitName": "f6f16118d38fcfe3b724f05fad752cb223f441ec",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "24/11/15 2:07 PM",
      "commitNameOld": "f634505d48d97e4d461980d68a0cbdf87223646d",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 42.05,
      "commitsBetweenForRepo": 206,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,245 +1,246 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(\n           FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n           jobJarPath,\n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n         + \"/bin/java\");\n \n     Path amTmpDir \u003d\n         new Path(MRApps.crossPlatformifyMREnv(conf, Environment.PWD),\n             YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);\n     vargs.add(\"-Djava.io.tmpdir\u003d\" + amTmpDir);\n     MRApps.addLog4jSystemProperties(null, vargs, conf);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n \n     if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n         MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n       final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n           MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n       if (profileParams !\u003d null) {\n         vargs.add(String.format(profileParams,\n             ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                 + TaskLog.LogName.PROFILE));\n       }\n     }\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n     // Shell\n     environment.put(Environment.SHELL.name(),\n         conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n             MRJobConfig.DEFAULT_SHELL));\n \n-    // Add the container working directory at the front of LD_LIBRARY_PATH\n+    // Add the container working directory in front of LD_LIBRARY_PATH\n     MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n         MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n-        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n+        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV,\n+            MRJobConfig.DEFAULT_MR_AM_ADMIN_USER_ENV), conf);\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV), conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     // add reservationID if present\n     ReservationId reservationID \u003d null;\n     try {\n       reservationID \u003d\n           ReservationId.parseReservationId(jobConf\n               .get(JobContext.RESERVATION_ID));\n     } catch (NumberFormatException e) {\n       // throw exception as reservationid as is invalid\n       String errMsg \u003d\n           \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n               + \" specified for the app: \" + applicationId;\n       LOG.warn(errMsg);\n       throw new IOException(errMsg);\n     }\n     if (reservationID !\u003d null) {\n       appContext.setReservationID(reservationID);\n       LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n           + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n           + appContext.getReservationID());\n     }\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n \n     // set labels for the AM container request if present\n     String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n     if (null !\u003d amNodelabelExpression\n         \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n       ResourceRequest amResourceRequest \u003d\n           recordFactory.newRecordInstance(ResourceRequest.class);\n       amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n       amResourceRequest.setResourceName(ResourceRequest.ANY);\n       amResourceRequest.setCapability(capability);\n       amResourceRequest.setNumContainers(1);\n       amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n       appContext.setAMContainerResourceRequest(amResourceRequest);\n     }\n     // set labels for the Job containers\n     appContext.setNodeLabelExpression(jobConf\n         .get(JobContext.JOB_NODE_LABEL_EXP));\n \n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n       appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n     }\n \n     String jobPriority \u003d jobConf.get(MRJobConfig.PRIORITY);\n     if (jobPriority !\u003d null) {\n       int iPriority;\n       try {\n         iPriority \u003d TypeConverter.toYarnApplicationPriority(jobPriority);\n       } catch (IllegalArgumentException e) {\n         iPriority \u003d Integer.parseInt(jobPriority);\n       }\n       appContext.setPriority(Priority.newInstance(iPriority));\n     }\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(\n          FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n          jobJarPath,\n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n        + \"/bin/java\");\n\n    Path amTmpDir \u003d\n        new Path(MRApps.crossPlatformifyMREnv(conf, Environment.PWD),\n            YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);\n    vargs.add(\"-Djava.io.tmpdir\u003d\" + amTmpDir);\n    MRApps.addLog4jSystemProperties(null, vargs, conf);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n\n    if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n        MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n      final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n          MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n      if (profileParams !\u003d null) {\n        vargs.add(String.format(profileParams,\n            ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                + TaskLog.LogName.PROFILE));\n      }\n    }\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Shell\n    environment.put(Environment.SHELL.name(),\n        conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n            MRJobConfig.DEFAULT_SHELL));\n\n    // Add the container working directory in front of LD_LIBRARY_PATH\n    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n        MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n\n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV,\n            MRJobConfig.DEFAULT_MR_AM_ADMIN_USER_ENV), conf);\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV), conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    // add reservationID if present\n    ReservationId reservationID \u003d null;\n    try {\n      reservationID \u003d\n          ReservationId.parseReservationId(jobConf\n              .get(JobContext.RESERVATION_ID));\n    } catch (NumberFormatException e) {\n      // throw exception as reservationid as is invalid\n      String errMsg \u003d\n          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n              + \" specified for the app: \" + applicationId;\n      LOG.warn(errMsg);\n      throw new IOException(errMsg);\n    }\n    if (reservationID !\u003d null) {\n      appContext.setReservationID(reservationID);\n      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n          + appContext.getReservationID());\n    }\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n\n    // set labels for the AM container request if present\n    String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n    if (null !\u003d amNodelabelExpression\n        \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n      ResourceRequest amResourceRequest \u003d\n          recordFactory.newRecordInstance(ResourceRequest.class);\n      amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n      amResourceRequest.setResourceName(ResourceRequest.ANY);\n      amResourceRequest.setCapability(capability);\n      amResourceRequest.setNumContainers(1);\n      amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n      appContext.setAMContainerResourceRequest(amResourceRequest);\n    }\n    // set labels for the Job containers\n    appContext.setNodeLabelExpression(jobConf\n        .get(JobContext.JOB_NODE_LABEL_EXP));\n\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n    }\n\n    String jobPriority \u003d jobConf.get(MRJobConfig.PRIORITY);\n    if (jobPriority !\u003d null) {\n      int iPriority;\n      try {\n        iPriority \u003d TypeConverter.toYarnApplicationPriority(jobPriority);\n      } catch (IllegalArgumentException e) {\n        iPriority \u003d Integer.parseInt(jobPriority);\n      }\n      appContext.setPriority(Priority.newInstance(iPriority));\n    }\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "f634505d48d97e4d461980d68a0cbdf87223646d": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5870. Support for passing Job priority through Application Submission Context in Mapreduce Side. Contributed by Sunil G\n",
      "commitDate": "24/11/15 2:07 PM",
      "commitName": "f634505d48d97e4d461980d68a0cbdf87223646d",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "15/09/15 12:43 PM",
      "commitNameOld": "62943b8e3aff3b274c439f72a8bb86094c1ab0e8",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 70.1,
      "commitsBetweenForRepo": 563,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,234 +1,245 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(\n           FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n           jobJarPath,\n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n         + \"/bin/java\");\n \n     Path amTmpDir \u003d\n         new Path(MRApps.crossPlatformifyMREnv(conf, Environment.PWD),\n             YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);\n     vargs.add(\"-Djava.io.tmpdir\u003d\" + amTmpDir);\n     MRApps.addLog4jSystemProperties(null, vargs, conf);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n \n     if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n         MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n       final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n           MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n       if (profileParams !\u003d null) {\n         vargs.add(String.format(profileParams,\n             ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                 + TaskLog.LogName.PROFILE));\n       }\n     }\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n     // Shell\n     environment.put(Environment.SHELL.name(),\n         conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n             MRJobConfig.DEFAULT_SHELL));\n \n     // Add the container working directory at the front of LD_LIBRARY_PATH\n     MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n         MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV), conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     // add reservationID if present\n     ReservationId reservationID \u003d null;\n     try {\n       reservationID \u003d\n           ReservationId.parseReservationId(jobConf\n               .get(JobContext.RESERVATION_ID));\n     } catch (NumberFormatException e) {\n       // throw exception as reservationid as is invalid\n       String errMsg \u003d\n           \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n               + \" specified for the app: \" + applicationId;\n       LOG.warn(errMsg);\n       throw new IOException(errMsg);\n     }\n     if (reservationID !\u003d null) {\n       appContext.setReservationID(reservationID);\n       LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n           + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n           + appContext.getReservationID());\n     }\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n \n     // set labels for the AM container request if present\n     String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n     if (null !\u003d amNodelabelExpression\n         \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n       ResourceRequest amResourceRequest \u003d\n           recordFactory.newRecordInstance(ResourceRequest.class);\n       amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n       amResourceRequest.setResourceName(ResourceRequest.ANY);\n       amResourceRequest.setCapability(capability);\n       amResourceRequest.setNumContainers(1);\n       amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n       appContext.setAMContainerResourceRequest(amResourceRequest);\n     }\n     // set labels for the Job containers\n     appContext.setNodeLabelExpression(jobConf\n         .get(JobContext.JOB_NODE_LABEL_EXP));\n \n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n       appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n     }\n \n+    String jobPriority \u003d jobConf.get(MRJobConfig.PRIORITY);\n+    if (jobPriority !\u003d null) {\n+      int iPriority;\n+      try {\n+        iPriority \u003d TypeConverter.toYarnApplicationPriority(jobPriority);\n+      } catch (IllegalArgumentException e) {\n+        iPriority \u003d Integer.parseInt(jobPriority);\n+      }\n+      appContext.setPriority(Priority.newInstance(iPriority));\n+    }\n+\n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(\n          FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n          jobJarPath,\n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n        + \"/bin/java\");\n\n    Path amTmpDir \u003d\n        new Path(MRApps.crossPlatformifyMREnv(conf, Environment.PWD),\n            YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);\n    vargs.add(\"-Djava.io.tmpdir\u003d\" + amTmpDir);\n    MRApps.addLog4jSystemProperties(null, vargs, conf);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n\n    if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n        MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n      final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n          MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n      if (profileParams !\u003d null) {\n        vargs.add(String.format(profileParams,\n            ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                + TaskLog.LogName.PROFILE));\n      }\n    }\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Shell\n    environment.put(Environment.SHELL.name(),\n        conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n            MRJobConfig.DEFAULT_SHELL));\n\n    // Add the container working directory at the front of LD_LIBRARY_PATH\n    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n        MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n\n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV), conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    // add reservationID if present\n    ReservationId reservationID \u003d null;\n    try {\n      reservationID \u003d\n          ReservationId.parseReservationId(jobConf\n              .get(JobContext.RESERVATION_ID));\n    } catch (NumberFormatException e) {\n      // throw exception as reservationid as is invalid\n      String errMsg \u003d\n          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n              + \" specified for the app: \" + applicationId;\n      LOG.warn(errMsg);\n      throw new IOException(errMsg);\n    }\n    if (reservationID !\u003d null) {\n      appContext.setReservationID(reservationID);\n      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n          + appContext.getReservationID());\n    }\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n\n    // set labels for the AM container request if present\n    String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n    if (null !\u003d amNodelabelExpression\n        \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n      ResourceRequest amResourceRequest \u003d\n          recordFactory.newRecordInstance(ResourceRequest.class);\n      amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n      amResourceRequest.setResourceName(ResourceRequest.ANY);\n      amResourceRequest.setCapability(capability);\n      amResourceRequest.setNumContainers(1);\n      amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n      appContext.setAMContainerResourceRequest(amResourceRequest);\n    }\n    // set labels for the Job containers\n    appContext.setNodeLabelExpression(jobConf\n        .get(JobContext.JOB_NODE_LABEL_EXP));\n\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n    }\n\n    String jobPriority \u003d jobConf.get(MRJobConfig.PRIORITY);\n    if (jobPriority !\u003d null) {\n      int iPriority;\n      try {\n        iPriority \u003d TypeConverter.toYarnApplicationPriority(jobPriority);\n      } catch (IllegalArgumentException e) {\n        iPriority \u003d Integer.parseInt(jobPriority);\n      }\n      appContext.setPriority(Priority.newInstance(iPriority));\n    }\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "62943b8e3aff3b274c439f72a8bb86094c1ab0e8": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6472. MapReduce AM should have java.io.tmpdir\u003d./tmp to be consistent with tasks. Contributed by Naganarasimha G R\n",
      "commitDate": "15/09/15 12:43 PM",
      "commitName": "62943b8e3aff3b274c439f72a8bb86094c1ab0e8",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "27/05/15 2:26 PM",
      "commitNameOld": "3164e7d83875aa6b7435d1dfe61ac280aa277f1c",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 110.93,
      "commitsBetweenForRepo": 684,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,230 +1,234 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(\n           FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n           jobJarPath,\n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n         + \"/bin/java\");\n \n+    Path amTmpDir \u003d\n+        new Path(MRApps.crossPlatformifyMREnv(conf, Environment.PWD),\n+            YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);\n+    vargs.add(\"-Djava.io.tmpdir\u003d\" + amTmpDir);\n     MRApps.addLog4jSystemProperties(null, vargs, conf);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n \n     if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n         MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n       final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n           MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n       if (profileParams !\u003d null) {\n         vargs.add(String.format(profileParams,\n             ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                 + TaskLog.LogName.PROFILE));\n       }\n     }\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n     // Shell\n     environment.put(Environment.SHELL.name(),\n         conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n             MRJobConfig.DEFAULT_SHELL));\n \n     // Add the container working directory at the front of LD_LIBRARY_PATH\n     MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n         MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV), conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     // add reservationID if present\n     ReservationId reservationID \u003d null;\n     try {\n       reservationID \u003d\n           ReservationId.parseReservationId(jobConf\n               .get(JobContext.RESERVATION_ID));\n     } catch (NumberFormatException e) {\n       // throw exception as reservationid as is invalid\n       String errMsg \u003d\n           \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n               + \" specified for the app: \" + applicationId;\n       LOG.warn(errMsg);\n       throw new IOException(errMsg);\n     }\n     if (reservationID !\u003d null) {\n       appContext.setReservationID(reservationID);\n       LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n           + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n           + appContext.getReservationID());\n     }\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n \n     // set labels for the AM container request if present\n     String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n     if (null !\u003d amNodelabelExpression\n         \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n       ResourceRequest amResourceRequest \u003d\n           recordFactory.newRecordInstance(ResourceRequest.class);\n       amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n       amResourceRequest.setResourceName(ResourceRequest.ANY);\n       amResourceRequest.setCapability(capability);\n       amResourceRequest.setNumContainers(1);\n       amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n       appContext.setAMContainerResourceRequest(amResourceRequest);\n     }\n     // set labels for the Job containers\n     appContext.setNodeLabelExpression(jobConf\n         .get(JobContext.JOB_NODE_LABEL_EXP));\n \n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n       appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n     }\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(\n          FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n          jobJarPath,\n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n        + \"/bin/java\");\n\n    Path amTmpDir \u003d\n        new Path(MRApps.crossPlatformifyMREnv(conf, Environment.PWD),\n            YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);\n    vargs.add(\"-Djava.io.tmpdir\u003d\" + amTmpDir);\n    MRApps.addLog4jSystemProperties(null, vargs, conf);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n\n    if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n        MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n      final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n          MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n      if (profileParams !\u003d null) {\n        vargs.add(String.format(profileParams,\n            ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                + TaskLog.LogName.PROFILE));\n      }\n    }\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Shell\n    environment.put(Environment.SHELL.name(),\n        conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n            MRJobConfig.DEFAULT_SHELL));\n\n    // Add the container working directory at the front of LD_LIBRARY_PATH\n    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n        MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n\n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV), conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    // add reservationID if present\n    ReservationId reservationID \u003d null;\n    try {\n      reservationID \u003d\n          ReservationId.parseReservationId(jobConf\n              .get(JobContext.RESERVATION_ID));\n    } catch (NumberFormatException e) {\n      // throw exception as reservationid as is invalid\n      String errMsg \u003d\n          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n              + \" specified for the app: \" + applicationId;\n      LOG.warn(errMsg);\n      throw new IOException(errMsg);\n    }\n    if (reservationID !\u003d null) {\n      appContext.setReservationID(reservationID);\n      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n          + appContext.getReservationID());\n    }\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n\n    // set labels for the AM container request if present\n    String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n    if (null !\u003d amNodelabelExpression\n        \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n      ResourceRequest amResourceRequest \u003d\n          recordFactory.newRecordInstance(ResourceRequest.class);\n      amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n      amResourceRequest.setResourceName(ResourceRequest.ANY);\n      amResourceRequest.setCapability(capability);\n      amResourceRequest.setNumContainers(1);\n      amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n      appContext.setAMContainerResourceRequest(amResourceRequest);\n    }\n    // set labels for the Job containers\n    appContext.setNodeLabelExpression(jobConf\n        .get(JobContext.JOB_NODE_LABEL_EXP));\n\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n    }\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "3164e7d83875aa6b7435d1dfe61ac280aa277f1c": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6304. Specifying node labels when submitting MR jobs. (Naganarasimha G R via wangda)\n",
      "commitDate": "27/05/15 2:26 PM",
      "commitName": "3164e7d83875aa6b7435d1dfe61ac280aa277f1c",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "10/03/15 6:21 AM",
      "commitNameOld": "d39bc903a0069a740744bafe10e506e452ed7018",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 78.34,
      "commitsBetweenForRepo": 746,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,212 +1,230 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(\n           FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n           jobJarPath,\n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n         + \"/bin/java\");\n \n     MRApps.addLog4jSystemProperties(null, vargs, conf);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n \n     if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n         MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n       final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n           MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n       if (profileParams !\u003d null) {\n         vargs.add(String.format(profileParams,\n             ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                 + TaskLog.LogName.PROFILE));\n       }\n     }\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n     // Shell\n     environment.put(Environment.SHELL.name(),\n         conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n             MRJobConfig.DEFAULT_SHELL));\n \n     // Add the container working directory at the front of LD_LIBRARY_PATH\n     MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n         MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV), conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     // add reservationID if present\n     ReservationId reservationID \u003d null;\n     try {\n       reservationID \u003d\n           ReservationId.parseReservationId(jobConf\n               .get(JobContext.RESERVATION_ID));\n     } catch (NumberFormatException e) {\n       // throw exception as reservationid as is invalid\n       String errMsg \u003d\n           \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n               + \" specified for the app: \" + applicationId;\n       LOG.warn(errMsg);\n       throw new IOException(errMsg);\n     }\n     if (reservationID !\u003d null) {\n       appContext.setReservationID(reservationID);\n       LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n           + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n           + appContext.getReservationID());\n     }\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n+\n+    // set labels for the AM container request if present\n+    String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n+    if (null !\u003d amNodelabelExpression\n+        \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n+      ResourceRequest amResourceRequest \u003d\n+          recordFactory.newRecordInstance(ResourceRequest.class);\n+      amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n+      amResourceRequest.setResourceName(ResourceRequest.ANY);\n+      amResourceRequest.setCapability(capability);\n+      amResourceRequest.setNumContainers(1);\n+      amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n+      appContext.setAMContainerResourceRequest(amResourceRequest);\n+    }\n+    // set labels for the Job containers\n+    appContext.setNodeLabelExpression(jobConf\n+        .get(JobContext.JOB_NODE_LABEL_EXP));\n+\n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n       appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n     }\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(\n          FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n          jobJarPath,\n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n        + \"/bin/java\");\n\n    MRApps.addLog4jSystemProperties(null, vargs, conf);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n\n    if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n        MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n      final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n          MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n      if (profileParams !\u003d null) {\n        vargs.add(String.format(profileParams,\n            ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                + TaskLog.LogName.PROFILE));\n      }\n    }\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Shell\n    environment.put(Environment.SHELL.name(),\n        conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n            MRJobConfig.DEFAULT_SHELL));\n\n    // Add the container working directory at the front of LD_LIBRARY_PATH\n    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n        MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n\n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV), conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    // add reservationID if present\n    ReservationId reservationID \u003d null;\n    try {\n      reservationID \u003d\n          ReservationId.parseReservationId(jobConf\n              .get(JobContext.RESERVATION_ID));\n    } catch (NumberFormatException e) {\n      // throw exception as reservationid as is invalid\n      String errMsg \u003d\n          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n              + \" specified for the app: \" + applicationId;\n      LOG.warn(errMsg);\n      throw new IOException(errMsg);\n    }\n    if (reservationID !\u003d null) {\n      appContext.setReservationID(reservationID);\n      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n          + appContext.getReservationID());\n    }\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n\n    // set labels for the AM container request if present\n    String amNodelabelExpression \u003d conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\n    if (null !\u003d amNodelabelExpression\n        \u0026\u0026 amNodelabelExpression.trim().length() !\u003d 0) {\n      ResourceRequest amResourceRequest \u003d\n          recordFactory.newRecordInstance(ResourceRequest.class);\n      amResourceRequest.setPriority(AM_CONTAINER_PRIORITY);\n      amResourceRequest.setResourceName(ResourceRequest.ANY);\n      amResourceRequest.setCapability(capability);\n      amResourceRequest.setNumContainers(1);\n      amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\n      appContext.setAMContainerResourceRequest(amResourceRequest);\n    }\n    // set labels for the Job containers\n    appContext.setNodeLabelExpression(jobConf\n        .get(JobContext.JOB_NODE_LABEL_EXP));\n\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n    }\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "03ab24aa01ffea1cacf1fa9cbbf73c3f2904d981": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5932. Provide an option to use a dedicated reduce-side shuffle log. Contributed by Gera Shegalov\n",
      "commitDate": "03/12/14 9:02 AM",
      "commitName": "03ab24aa01ffea1cacf1fa9cbbf73c3f2904d981",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "06/11/14 7:10 AM",
      "commitNameOld": "10f9f5101c44be7c675a44ded4aad212627ecdee",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 27.08,
      "commitsBetweenForRepo": 191,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,219 +1,212 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(\n           FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n           jobJarPath,\n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n         + \"/bin/java\");\n \n-    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n-    long logSize \u003d jobConf.getLong(MRJobConfig.MR_AM_LOG_KB,\n-        MRJobConfig.DEFAULT_MR_AM_LOG_KB) \u003c\u003c 10;\n-    String logLevel \u003d jobConf.get(\n-        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n-    int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n-        MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n-    MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs, conf);\n+    MRApps.addLog4jSystemProperties(null, vargs, conf);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n \n     if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n         MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n       final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n           MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n       if (profileParams !\u003d null) {\n         vargs.add(String.format(profileParams,\n             ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                 + TaskLog.LogName.PROFILE));\n       }\n     }\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n     // Shell\n     environment.put(Environment.SHELL.name(),\n         conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n             MRJobConfig.DEFAULT_SHELL));\n \n     // Add the container working directory at the front of LD_LIBRARY_PATH\n     MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n         MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV), conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     // add reservationID if present\n     ReservationId reservationID \u003d null;\n     try {\n       reservationID \u003d\n           ReservationId.parseReservationId(jobConf\n               .get(JobContext.RESERVATION_ID));\n     } catch (NumberFormatException e) {\n       // throw exception as reservationid as is invalid\n       String errMsg \u003d\n           \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n               + \" specified for the app: \" + applicationId;\n       LOG.warn(errMsg);\n       throw new IOException(errMsg);\n     }\n     if (reservationID !\u003d null) {\n       appContext.setReservationID(reservationID);\n       LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n           + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n           + appContext.getReservationID());\n     }\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n       appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n     }\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(\n          FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n          jobJarPath,\n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n        + \"/bin/java\");\n\n    MRApps.addLog4jSystemProperties(null, vargs, conf);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n\n    if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n        MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n      final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n          MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n      if (profileParams !\u003d null) {\n        vargs.add(String.format(profileParams,\n            ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                + TaskLog.LogName.PROFILE));\n      }\n    }\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Shell\n    environment.put(Environment.SHELL.name(),\n        conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n            MRJobConfig.DEFAULT_SHELL));\n\n    // Add the container working directory at the front of LD_LIBRARY_PATH\n    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n        MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n\n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV), conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    // add reservationID if present\n    ReservationId reservationID \u003d null;\n    try {\n      reservationID \u003d\n          ReservationId.parseReservationId(jobConf\n              .get(JobContext.RESERVATION_ID));\n    } catch (NumberFormatException e) {\n      // throw exception as reservationid as is invalid\n      String errMsg \u003d\n          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n              + \" specified for the app: \" + applicationId;\n      LOG.warn(errMsg);\n      throw new IOException(errMsg);\n    }\n    if (reservationID !\u003d null) {\n      appContext.setReservationID(reservationID);\n      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n          + appContext.getReservationID());\n    }\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n    }\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "10f9f5101c44be7c675a44ded4aad212627ecdee": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5960. JobSubmitter\u0027s check whether job.jar is local is incorrect with no authority in job jar path. Contributed by Gera Shegalov\n",
      "commitDate": "06/11/14 7:10 AM",
      "commitName": "10f9f5101c44be7c675a44ded4aad212627ecdee",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "01/11/14 12:47 AM",
      "commitNameOld": "ed63b116465290fdb0acdf89170025f47b307599",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 5.31,
      "commitsBetweenForRepo": 56,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,218 +1,219 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n-      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n-          jobJarPath, \n+      LocalResource rc \u003d createApplicationResource(\n+          FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n+          jobJarPath,\n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n         + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d jobConf.getLong(MRJobConfig.MR_AM_LOG_KB,\n         MRJobConfig.DEFAULT_MR_AM_LOG_KB) \u003c\u003c 10;\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n         MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs, conf);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n \n     if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n         MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n       final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n           MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n       if (profileParams !\u003d null) {\n         vargs.add(String.format(profileParams,\n             ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                 + TaskLog.LogName.PROFILE));\n       }\n     }\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n     // Shell\n     environment.put(Environment.SHELL.name(),\n         conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n             MRJobConfig.DEFAULT_SHELL));\n \n     // Add the container working directory at the front of LD_LIBRARY_PATH\n     MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n         MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV), conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     // add reservationID if present\n     ReservationId reservationID \u003d null;\n     try {\n       reservationID \u003d\n           ReservationId.parseReservationId(jobConf\n               .get(JobContext.RESERVATION_ID));\n     } catch (NumberFormatException e) {\n       // throw exception as reservationid as is invalid\n       String errMsg \u003d\n           \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n               + \" specified for the app: \" + applicationId;\n       LOG.warn(errMsg);\n       throw new IOException(errMsg);\n     }\n     if (reservationID !\u003d null) {\n       appContext.setReservationID(reservationID);\n       LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n           + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n           + appContext.getReservationID());\n     }\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n       appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n     }\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(\n          FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n          jobJarPath,\n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n        + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d jobConf.getLong(MRJobConfig.MR_AM_LOG_KB,\n        MRJobConfig.DEFAULT_MR_AM_LOG_KB) \u003c\u003c 10;\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n        MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs, conf);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n\n    if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n        MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n      final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n          MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n      if (profileParams !\u003d null) {\n        vargs.add(String.format(profileParams,\n            ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                + TaskLog.LogName.PROFILE));\n      }\n    }\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Shell\n    environment.put(Environment.SHELL.name(),\n        conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n            MRJobConfig.DEFAULT_SHELL));\n\n    // Add the container working directory at the front of LD_LIBRARY_PATH\n    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n        MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n\n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV), conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    // add reservationID if present\n    ReservationId reservationID \u003d null;\n    try {\n      reservationID \u003d\n          ReservationId.parseReservationId(jobConf\n              .get(JobContext.RESERVATION_ID));\n    } catch (NumberFormatException e) {\n      // throw exception as reservationid as is invalid\n      String errMsg \u003d\n          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n              + \" specified for the app: \" + applicationId;\n      LOG.warn(errMsg);\n      throw new IOException(errMsg);\n    }\n    if (reservationID !\u003d null) {\n      appContext.setReservationID(reservationID);\n      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n          + appContext.getReservationID());\n    }\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n    }\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "ed63b116465290fdb0acdf89170025f47b307599": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6052. Supported overriding the default container-log4j.properties file per job. Contributed by Junping Du.\n",
      "commitDate": "01/11/14 12:47 AM",
      "commitName": "ed63b116465290fdb0acdf89170025f47b307599",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "17/10/14 12:51 PM",
      "commitNameOld": "209b1699fcd150676d4cc47e8e817796086c1986",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 14.5,
      "commitsBetweenForRepo": 148,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,218 +1,218 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n         + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d jobConf.getLong(MRJobConfig.MR_AM_LOG_KB,\n         MRJobConfig.DEFAULT_MR_AM_LOG_KB) \u003c\u003c 10;\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n         MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n-    MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs);\n+    MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs, conf);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n \n     if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n         MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n       final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n           MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n       if (profileParams !\u003d null) {\n         vargs.add(String.format(profileParams,\n             ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                 + TaskLog.LogName.PROFILE));\n       }\n     }\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n     // Shell\n     environment.put(Environment.SHELL.name(),\n         conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n             MRJobConfig.DEFAULT_SHELL));\n \n     // Add the container working directory at the front of LD_LIBRARY_PATH\n     MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n         MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV), conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     // add reservationID if present\n     ReservationId reservationID \u003d null;\n     try {\n       reservationID \u003d\n           ReservationId.parseReservationId(jobConf\n               .get(JobContext.RESERVATION_ID));\n     } catch (NumberFormatException e) {\n       // throw exception as reservationid as is invalid\n       String errMsg \u003d\n           \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n               + \" specified for the app: \" + applicationId;\n       LOG.warn(errMsg);\n       throw new IOException(errMsg);\n     }\n     if (reservationID !\u003d null) {\n       appContext.setReservationID(reservationID);\n       LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n           + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n           + appContext.getReservationID());\n     }\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n       appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n     }\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n        + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d jobConf.getLong(MRJobConfig.MR_AM_LOG_KB,\n        MRJobConfig.DEFAULT_MR_AM_LOG_KB) \u003c\u003c 10;\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n        MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs, conf);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n\n    if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n        MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n      final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n          MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n      if (profileParams !\u003d null) {\n        vargs.add(String.format(profileParams,\n            ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                + TaskLog.LogName.PROFILE));\n      }\n    }\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Shell\n    environment.put(Environment.SHELL.name(),\n        conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n            MRJobConfig.DEFAULT_SHELL));\n\n    // Add the container working directory at the front of LD_LIBRARY_PATH\n    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n        MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n\n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV), conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    // add reservationID if present\n    ReservationId reservationID \u003d null;\n    try {\n      reservationID \u003d\n          ReservationId.parseReservationId(jobConf\n              .get(JobContext.RESERVATION_ID));\n    } catch (NumberFormatException e) {\n      // throw exception as reservationid as is invalid\n      String errMsg \u003d\n          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n              + \" specified for the app: \" + applicationId;\n      LOG.warn(errMsg);\n      throw new IOException(errMsg);\n    }\n    if (reservationID !\u003d null) {\n      appContext.setReservationID(reservationID);\n      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n          + appContext.getReservationID());\n    }\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n    }\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "f19771a24c2f90982cf6dec35889836a6146c968": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5970. Provide a boolean switch to enable MR-AM profiling. Contributed by Gera Shegalov\n",
      "commitDate": "15/10/14 10:50 AM",
      "commitName": "f19771a24c2f90982cf6dec35889836a6146c968",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "03/10/14 3:42 PM",
      "commitNameOld": "3f282762d1afc916de9207d3adeda852ca344853",
      "commitAuthorOld": "subru",
      "daysBetweenCommits": 11.8,
      "commitsBetweenForRepo": 87,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,207 +1,218 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n         + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d jobConf.getLong(MRJobConfig.MR_AM_LOG_KB,\n         MRJobConfig.DEFAULT_MR_AM_LOG_KB) \u003c\u003c 10;\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n         MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n-        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n+        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n-    \n+\n+    if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n+        MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n+      final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n+          MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n+      if (profileParams !\u003d null) {\n+        vargs.add(String.format(profileParams,\n+            ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n+                + TaskLog.LogName.PROFILE));\n+      }\n+    }\n+\n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n     // Shell\n     environment.put(Environment.SHELL.name(),\n         conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n             MRJobConfig.DEFAULT_SHELL));\n \n     // Add the container working directory at the front of LD_LIBRARY_PATH\n     MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n         MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV), conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     // add reservationID if present\n     ReservationId reservationID \u003d null;\n     try {\n       reservationID \u003d\n           ReservationId.parseReservationId(jobConf\n               .get(JobContext.RESERVATION_ID));\n     } catch (NumberFormatException e) {\n       // throw exception as reservationid as is invalid\n       String errMsg \u003d\n           \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n               + \" specified for the app: \" + applicationId;\n       LOG.warn(errMsg);\n       throw new IOException(errMsg);\n     }\n     if (reservationID !\u003d null) {\n       appContext.setReservationID(reservationID);\n       LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n           + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n           + appContext.getReservationID());\n     }\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n       appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n     }\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n        + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d jobConf.getLong(MRJobConfig.MR_AM_LOG_KB,\n        MRJobConfig.DEFAULT_MR_AM_LOG_KB) \u003c\u003c 10;\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n        MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n\n    if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE,\n        MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\n      final String profileParams \u003d jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS,\n          MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\n      if (profileParams !\u003d null) {\n        vargs.add(String.format(profileParams,\n            ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR\n                + TaskLog.LogName.PROFILE));\n      }\n    }\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Shell\n    environment.put(Environment.SHELL.name(),\n        conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n            MRJobConfig.DEFAULT_SHELL));\n\n    // Add the container working directory at the front of LD_LIBRARY_PATH\n    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n        MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n\n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV), conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    // add reservationID if present\n    ReservationId reservationID \u003d null;\n    try {\n      reservationID \u003d\n          ReservationId.parseReservationId(jobConf\n              .get(JobContext.RESERVATION_ID));\n    } catch (NumberFormatException e) {\n      // throw exception as reservationid as is invalid\n      String errMsg \u003d\n          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n              + \" specified for the app: \" + applicationId;\n      LOG.warn(errMsg);\n      throw new IOException(errMsg);\n    }\n    if (reservationID !\u003d null) {\n      appContext.setReservationID(reservationID);\n      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n          + appContext.getReservationID());\n    }\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n    }\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "3f282762d1afc916de9207d3adeda852ca344853": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6103.Adding reservation APIs to MR resource manager delegate. Contributed by Subru Krishnan and Carlo Curino.\n(cherry picked from commit aa92dd45f2d8c89a8a17ad2e4449aa3ff08bc53a)\n",
      "commitDate": "03/10/14 3:42 PM",
      "commitName": "3f282762d1afc916de9207d3adeda852ca344853",
      "commitAuthor": "subru",
      "commitDateOld": "07/08/14 1:15 PM",
      "commitNameOld": "de2595833cef21e3445fa7a4cb0ce7bc3f41fbd9",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 57.1,
      "commitsBetweenForRepo": 609,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,186 +1,207 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n         + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d jobConf.getLong(MRJobConfig.MR_AM_LOG_KB,\n         MRJobConfig.DEFAULT_MR_AM_LOG_KB) \u003c\u003c 10;\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n         MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n     \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n     // Shell\n     environment.put(Environment.SHELL.name(),\n         conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n             MRJobConfig.DEFAULT_SHELL));\n \n     // Add the container working directory at the front of LD_LIBRARY_PATH\n     MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n         MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV), conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n+    // add reservationID if present\n+    ReservationId reservationID \u003d null;\n+    try {\n+      reservationID \u003d\n+          ReservationId.parseReservationId(jobConf\n+              .get(JobContext.RESERVATION_ID));\n+    } catch (NumberFormatException e) {\n+      // throw exception as reservationid as is invalid\n+      String errMsg \u003d\n+          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n+              + \" specified for the app: \" + applicationId;\n+      LOG.warn(errMsg);\n+      throw new IOException(errMsg);\n+    }\n+    if (reservationID !\u003d null) {\n+      appContext.setReservationID(reservationID);\n+      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n+          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n+          + appContext.getReservationID());\n+    }\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n       appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n     }\n+\n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n        + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d jobConf.getLong(MRJobConfig.MR_AM_LOG_KB,\n        MRJobConfig.DEFAULT_MR_AM_LOG_KB) \u003c\u003c 10;\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n        MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n    \n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Shell\n    environment.put(Environment.SHELL.name(),\n        conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n            MRJobConfig.DEFAULT_SHELL));\n\n    // Add the container working directory at the front of LD_LIBRARY_PATH\n    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n        MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n\n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV), conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    // add reservationID if present\n    ReservationId reservationID \u003d null;\n    try {\n      reservationID \u003d\n          ReservationId.parseReservationId(jobConf\n              .get(JobContext.RESERVATION_ID));\n    } catch (NumberFormatException e) {\n      // throw exception as reservationid as is invalid\n      String errMsg \u003d\n          \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID)\n              + \" specified for the app: \" + applicationId;\n      LOG.warn(errMsg);\n      throw new IOException(errMsg);\n    }\n    if (reservationID !\u003d null) {\n      appContext.setReservationID(reservationID);\n      LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId\n          + \" to queue:\" + appContext.getQueue() + \" with reservationId:\"\n          + appContext.getReservationID());\n    }\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n    }\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "de2595833cef21e3445fa7a4cb0ce7bc3f41fbd9": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6021. MR AM should have working directory in LD_LIBRARY_PATH. Contributed by Jason Lowe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616585 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/14 1:15 PM",
      "commitName": "de2595833cef21e3445fa7a4cb0ce7bc3f41fbd9",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "16/03/14 11:32 AM",
      "commitNameOld": "96e0ca2d272dc7ecd7f7f0e65a0c596fcc063bcb",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 144.07,
      "commitsBetweenForRepo": 926,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,177 +1,186 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n         + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d jobConf.getLong(MRJobConfig.MR_AM_LOG_KB,\n         MRJobConfig.DEFAULT_MR_AM_LOG_KB) \u003c\u003c 10;\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n         MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n     \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n+    // Shell\n+    environment.put(Environment.SHELL.name(),\n+        conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n+            MRJobConfig.DEFAULT_SHELL));\n+\n+    // Add the container working directory at the front of LD_LIBRARY_PATH\n+    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n+        MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n+\n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV), conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n       appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n     }\n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n        + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d jobConf.getLong(MRJobConfig.MR_AM_LOG_KB,\n        MRJobConfig.DEFAULT_MR_AM_LOG_KB) \u003c\u003c 10;\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n        MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n    \n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Shell\n    environment.put(Environment.SHELL.name(),\n        conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL,\n            MRJobConfig.DEFAULT_SHELL));\n\n    // Add the container working directory at the front of LD_LIBRARY_PATH\n    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(),\n        MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\n\n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV), conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n    }\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "96e0ca2d272dc7ecd7f7f0e65a0c596fcc063bcb": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1824. Improved NodeManager and clients to be able to handle cross platform application submissions. Contributed by Jian He.\nMAPREDUCE-4052. Improved MapReduce clients to use NodeManagers\u0027 ability to handle cross platform application submissions. Contributed by Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1578135 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/03/14 11:32 AM",
      "commitName": "96e0ca2d272dc7ecd7f7f0e65a0c596fcc063bcb",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "04/03/14 12:39 PM",
      "commitNameOld": "88245b6a41171f939b22186c533ea2bc7994f9b3",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 11.91,
      "commitsBetweenForRepo": 103,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,176 +1,177 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n-    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n+    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n+        + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d jobConf.getLong(MRJobConfig.MR_AM_LOG_KB,\n         MRJobConfig.DEFAULT_MR_AM_LOG_KB) \u003c\u003c 10;\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n         MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n     \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n-    \n+\n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n-        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n+        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n-        conf.get(MRJobConfig.MR_AM_ENV));\n+        conf.get(MRJobConfig.MR_AM_ENV), conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n       appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n     }\n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME)\n        + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d jobConf.getLong(MRJobConfig.MR_AM_LOG_KB,\n        MRJobConfig.DEFAULT_MR_AM_LOG_KB) \u003c\u003c 10;\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n        MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n    \n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV), conf);\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV), conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n    }\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "a756de93effb8c4c041e79a72b6542d2e88b253f": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5773. Provide dedicated MRAppMaster syslog length limit. Contributed by Gera Shegalov\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1573775 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/03/14 2:02 PM",
      "commitName": "a756de93effb8c4c041e79a72b6542d2e88b253f",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "06/02/14 10:29 AM",
      "commitNameOld": "4594b74b8536aea308854493a0e82c8b2919174b",
      "commitAuthorOld": "Karthik Kambatla",
      "daysBetweenCommits": 25.15,
      "commitsBetweenForRepo": 198,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,175 +1,176 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n-    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n+    long logSize \u003d jobConf.getLong(MRJobConfig.MR_AM_LOG_KB,\n+        MRJobConfig.DEFAULT_MR_AM_LOG_KB) \u003c\u003c 10;\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n         MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n     \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n     \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV));\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n     Collection\u003cString\u003e tagsFromConf \u003d\n         jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n       appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n     }\n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d jobConf.getLong(MRJobConfig.MR_AM_LOG_KB,\n        MRJobConfig.DEFAULT_MR_AM_LOG_KB) \u003c\u003c 10;\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n        MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n    \n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n    \n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV));\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n    }\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "4594b74b8536aea308854493a0e82c8b2919174b": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5699. Allow setting tags on MR jobs (kasha)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1565384 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/02/14 10:29 AM",
      "commitName": "4594b74b8536aea308854493a0e82c8b2919174b",
      "commitAuthor": "Karthik Kambatla",
      "commitDateOld": "16/01/14 2:56 PM",
      "commitNameOld": "a6ea460a9150e84128ebef97ab6ea8881215de03",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 20.81,
      "commitsBetweenForRepo": 134,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,170 +1,175 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n         MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n     \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n     \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV));\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n+    Collection\u003cString\u003e tagsFromConf \u003d\n+        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n+    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n+      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n+    }\n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n        MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n    \n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n    \n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV));\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n    Collection\u003cString\u003e tagsFromConf \u003d\n        jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    if (tagsFromConf !\u003d null \u0026\u0026 !tagsFromConf.isEmpty()) {\n      appContext.setApplicationTags(new HashSet\u003cString\u003e(tagsFromConf));\n    }\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "a6ea460a9150e84128ebef97ab6ea8881215de03": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5672. Provide optional RollingFileAppender for container log4j (syslog). Contributed by Gera Shegalov\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1558948 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/01/14 2:56 PM",
      "commitName": "a6ea460a9150e84128ebef97ab6ea8881215de03",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "17/06/13 10:47 PM",
      "commitNameOld": "acc0d3eb521e3c1d1b2f4be9b46c685ee921504b",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 212.71,
      "commitsBetweenForRepo": 1277,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,168 +1,170 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n-    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n+    int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n+        MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n+    MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n     \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n     \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV));\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    int numBackups \u003d jobConf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS,\n        MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, numBackups, vargs);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n    \n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n    \n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV));\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "b64572b06b1282128180b9ebdd971f9b1e973e61": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5199. Removing ApplicationTokens file as it is no longer needed. Contributed by Daryn Sharp.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492848 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/06/13 1:20 PM",
      "commitName": "b64572b06b1282128180b9ebdd971f9b1e973e61",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "03/06/13 9:05 PM",
      "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 9.68,
      "commitsBetweenForRepo": 64,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,169 +1,168 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n-        MRJobConfig.JOB_SPLIT_METAINFO,\n-        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n+        MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n     \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n     \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV));\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         ContainerLaunchContext.newInstance(localResources, environment,\n           vargsFinal, null, securityTokens, acls);\n \n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n    \n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n    \n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV));\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "643155cbee54809e1a7febd96cbb7d8111689b38": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5270. Migrated MR app from using BuilderUtil factory methods to individual record factory methods. Contributed by Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1486271 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/05/13 6:46 PM",
      "commitName": "643155cbee54809e1a7febd96cbb7d8111689b38",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "23/05/13 8:22 PM",
      "commitNameOld": "259edf8dca44de54033e96f7eb65a83aaa6096f2",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.93,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,168 +1,169 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n     \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n     \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV));\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n-    ContainerLaunchContext amContainer \u003d BuilderUtils\n-        .newContainerLaunchContext(localResources,\n-            environment, vargsFinal, null, securityTokens, acls);\n+    ContainerLaunchContext amContainer \u003d\n+        ContainerLaunchContext.newInstance(localResources, environment,\n+          vargsFinal, null, securityTokens, acls);\n+\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n    \n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n    \n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV));\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        ContainerLaunchContext.newInstance(localResources, environment,\n          vargsFinal, null, securityTokens, acls);\n\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "259edf8dca44de54033e96f7eb65a83aaa6096f2": {
      "type": "Ybodychange",
      "commitMessage": "YARN-571. Remove user from ContainerLaunchContext. Contributed by Omkar Vinit Joshi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1485928 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/05/13 8:22 PM",
      "commitName": "259edf8dca44de54033e96f7eb65a83aaa6096f2",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "23/05/13 11:02 AM",
      "commitNameOld": "43876770d91a374563bf3379a5ffab5c2bac2264",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.39,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,169 +1,168 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n     \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n     \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV));\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d BuilderUtils\n-        .newContainerLaunchContext(UserGroupInformation\n-            .getCurrentUser().getShortUserName(), localResources,\n+        .newContainerLaunchContext(localResources,\n             environment, vargsFinal, null, securityTokens, acls);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n     appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n    \n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n    \n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV));\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d BuilderUtils\n        .newContainerLaunchContext(localResources,\n            environment, vargsFinal, null, securityTokens, acls);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "43876770d91a374563bf3379a5ffab5c2bac2264": {
      "type": "Ybodychange",
      "commitMessage": "YARN-563. Add the concept of an application-type for each application. Contributed by Mayank Bansal.\nMAPREDUCE-5246. Specify application-type at the time of job submission after YARN-563. Contributed by Mayank Bansal.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1485790 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/05/13 11:02 AM",
      "commitName": "43876770d91a374563bf3379a5ffab5c2bac2264",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "12/05/13 8:34 PM",
      "commitNameOld": "7359dc32d3781d5318efee4cf6185616c7c00c18",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 10.6,
      "commitsBetweenForRepo": 45,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,168 +1,169 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n     \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n     \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV));\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d BuilderUtils\n         .newContainerLaunchContext(UserGroupInformation\n             .getCurrentUser().getShortUserName(), localResources,\n             environment, vargsFinal, null, securityTokens, acls);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n     appContext.setResource(capability);\n+    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n    \n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n    \n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV));\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d BuilderUtils\n        .newContainerLaunchContext(UserGroupInformation\n            .getCurrentUser().getShortUserName(), localResources,\n            environment, vargsFinal, null, securityTokens, acls);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "e4c55e17fea55e2fcbef182bb2b0c4b22686f38c": {
      "type": "Ybodychange",
      "commitMessage": "YARN-486. Changed NM\u0027s startContainer API to accept Container record given by RM as a direct parameter instead of as part of the ContainerLaunchContext record. Contributed by Xuan Gong.\nMAPREDUCE-5139. Update MR AM to use the modified startContainer API after YARN-486. Contributed by Xuan Gong.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1467063 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/04/13 12:28 PM",
      "commitName": "e4c55e17fea55e2fcbef182bb2b0c4b22686f38c",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "03/04/13 11:45 AM",
      "commitNameOld": "d18cc69d4eeaf82f72c8f465321afbbf28e2a550",
      "commitAuthorOld": "Konstantin Boudnik",
      "daysBetweenCommits": 8.03,
      "commitsBetweenForRepo": 48,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,170 +1,168 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n     \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n     \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV));\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d BuilderUtils\n-        .newContainerLaunchContext(null, UserGroupInformation\n-            .getCurrentUser().getShortUserName(), capability, localResources,\n+        .newContainerLaunchContext(UserGroupInformation\n+            .getCurrentUser().getShortUserName(), localResources,\n             environment, vargsFinal, null, securityTokens, acls);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n-    appContext.setUser(                                        // User name\n-        UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n     appContext.setMaxAppAttempts(\n         conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n             MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n-\n+    appContext.setResource(capability);\n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n    \n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n    \n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV));\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d BuilderUtils\n        .newContainerLaunchContext(UserGroupInformation\n            .getCurrentUser().getShortUserName(), localResources,\n            environment, vargsFinal, null, securityTokens, acls);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n    appContext.setResource(capability);\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "46315a2d914058969c7234272420c063ce268bf5": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5062. Fix MR AM to read max-retries from the RM. Contributed by *Zhijie Shen.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1460923 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/03/13 3:33 PM",
      "commitName": "46315a2d914058969c7234272420c063ce268bf5",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "18/01/13 2:41 PM",
      "commitNameOld": "88c7fdd06599671bdd519b0911c984410ecbe3fc",
      "commitAuthorOld": "Jonathan Turner Eagles",
      "daysBetweenCommits": 65.99,
      "commitsBetweenForRepo": 284,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,167 +1,170 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     // Check for Java Lib Path usage in MAP and REDUCE configs\n     warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n         MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n     warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n         MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n \n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n     String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n         MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n     vargs.add(mrAppMasterAdminOptions);\n     \n     // Add AM user command opts\n     String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n     warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n         MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n     vargs.add(mrAppMasterUserOptions);\n     \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n     \n     // Setup the environment variables for Admin first\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV));\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d BuilderUtils\n         .newContainerLaunchContext(null, UserGroupInformation\n             .getCurrentUser().getShortUserName(), capability, localResources,\n             environment, vargsFinal, null, securityTokens, acls);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n+    appContext.setMaxAppAttempts(\n+        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n+            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n    \n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n    \n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV));\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d BuilderUtils\n        .newContainerLaunchContext(null, UserGroupInformation\n            .getCurrentUser().getShortUserName(), capability, localResources,\n            environment, vargsFinal, null, securityTokens, acls);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n    appContext.setMaxAppAttempts(\n        conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS,\n            MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "88c7fdd06599671bdd519b0911c984410ecbe3fc": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4458. Warn if java.library.path is used for AM or Task (Robert Parker via jeagles)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1435386 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/01/13 2:41 PM",
      "commitName": "88c7fdd06599671bdd519b0911c984410ecbe3fc",
      "commitAuthor": "Jonathan Turner Eagles",
      "commitDateOld": "11/01/13 11:00 AM",
      "commitNameOld": "12293f8a13054eb12ee8c346aeb24a211a0673de",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 7.15,
      "commitsBetweenForRepo": 52,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,147 +1,167 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n+    // Check for Java Lib Path usage in MAP and REDUCE configs\n+    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n+        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n+    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n+        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n+    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n+        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n+    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n+        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n+\n     // Add AM admin command opts before user command opts\n     // so that it can be overridden by user\n-    vargs.add(conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n-        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS));\n+    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n+        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n+    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n+        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n+    vargs.add(mrAppMasterAdminOptions);\n     \n-    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n-        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n-\n+    // Add AM user command opts\n+    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n+        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n+    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n+        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n+    vargs.add(mrAppMasterUserOptions);\n+    \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n     \n+    // Setup the environment variables for Admin first\n+    MRApps.setEnvFromInputString(environment, \n+        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV));\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d BuilderUtils\n         .newContainerLaunchContext(null, UserGroupInformation\n             .getCurrentUser().getShortUserName(), capability, localResources,\n             environment, vargsFinal, null, securityTokens, acls);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    // Check for Java Lib Path usage in MAP and REDUCE configs\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS,\"\"), \"map\", \n        MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS,\"\"), \"reduce\", \n        MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);   \n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    String mrAppMasterAdminOptions \u003d conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", \n        MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\n    vargs.add(mrAppMasterAdminOptions);\n    \n    // Add AM user command opts\n    String mrAppMasterUserOptions \u003d conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", \n        MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\n    vargs.add(mrAppMasterUserOptions);\n    \n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n    \n    // Setup the environment variables for Admin first\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV));\n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV));\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d BuilderUtils\n        .newContainerLaunchContext(null, UserGroupInformation\n            .getCurrentUser().getShortUserName(), capability, localResources,\n            environment, vargsFinal, null, securityTokens, acls);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "5f7d4d2b451bec9d9db6b0a4c0b6e7991985116d": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4810. Added new admin command options for MR AM. Contributed by Jerry Chen.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1430707 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/01/13 10:31 PM",
      "commitName": "5f7d4d2b451bec9d9db6b0a4c0b6e7991985116d",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "08/01/13 9:28 PM",
      "commitNameOld": "2c5c8fdb80546467274607b26a1295b352c58fc8",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,142 +1,147 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(\n         conf.getInt(\n             MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n             )\n         );\n     capability.setVirtualCores(\n         conf.getInt(\n             MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n             )\n         );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n+    // Add AM admin command opts before user command opts\n+    // so that it can be overridden by user\n+    vargs.add(conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n+        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS));\n+    \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n     \n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV));\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d BuilderUtils\n         .newContainerLaunchContext(null, UserGroupInformation\n             .getCurrentUser().getShortUserName(), capability, localResources,\n             environment, vargsFinal, null, securityTokens, acls);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    // Add AM admin command opts before user command opts\n    // so that it can be overridden by user\n    vargs.add(conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS));\n    \n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n    \n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV));\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d BuilderUtils\n        .newContainerLaunchContext(null, UserGroupInformation\n            .getCurrentUser().getShortUserName(), capability, localResources,\n            environment, vargsFinal, null, securityTokens, acls);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "2c5c8fdb80546467274607b26a1295b352c58fc8": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4520. Added support for MapReduce applications to request for CPU cores along-with memory post YARN-2. Contributed by Arun C. Murthy.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1430688 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/01/13 9:28 PM",
      "commitName": "2c5c8fdb80546467274607b26a1295b352c58fc8",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "04/01/13 12:15 PM",
      "commitNameOld": "e17cecf5505dddb92e2212147505c7c900184431",
      "commitAuthorOld": "Thomas Graves",
      "daysBetweenCommits": 4.38,
      "commitsBetweenForRepo": 25,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,134 +1,142 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n-    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n-        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n+    capability.setMemory(\n+        conf.getInt(\n+            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n+            )\n+        );\n+    capability.setVirtualCores(\n+        conf.getInt(\n+            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n+            )\n+        );\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n     \n     // Setup the environment variables (LD_LIBRARY_PATH, etc)\n     MRApps.setEnvFromInputString(environment, \n         conf.get(MRJobConfig.MR_AM_ENV));\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d BuilderUtils\n         .newContainerLaunchContext(null, UserGroupInformation\n             .getCurrentUser().getShortUserName(), capability, localResources,\n             environment, vargsFinal, null, securityTokens, acls);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(\n        conf.getInt(\n            MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB\n            )\n        );\n    capability.setVirtualCores(\n        conf.getInt(\n            MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES\n            )\n        );\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n    \n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV));\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d BuilderUtils\n        .newContainerLaunchContext(null, UserGroupInformation\n            .getCurrentUser().getShortUserName(), capability, localResources,\n            environment, vargsFinal, null, securityTokens, acls);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "b50a3c5de32842835962e2c341cfffd14ad692d3": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4746. The MR Application Master does not have a config to set environment variables (Rob Parker via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1404674 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/11/12 10:02 AM",
      "commitName": "b50a3c5de32842835962e2c341cfffd14ad692d3",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "08/10/12 1:50 PM",
      "commitNameOld": "49b20c2ed1be55c90a057acea71b55a28a3f69fb",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 23.84,
      "commitsBetweenForRepo": 145,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,130 +1,134 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n-    // Final commmand\n+    // Final command\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n+    \n+    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n+    MRApps.setEnvFromInputString(environment, \n+        conf.get(MRJobConfig.MR_AM_ENV));\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d BuilderUtils\n         .newContainerLaunchContext(null, UserGroupInformation\n             .getCurrentUser().getShortUserName(), capability, localResources,\n             environment, vargsFinal, null, securityTokens, acls);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final command\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n    \n    // Setup the environment variables (LD_LIBRARY_PATH, etc)\n    MRApps.setEnvFromInputString(environment, \n        conf.get(MRJobConfig.MR_AM_ENV));\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d BuilderUtils\n        .newContainerLaunchContext(null, UserGroupInformation\n            .getCurrentUser().getShortUserName(), capability, localResources,\n            environment, vargsFinal, null, securityTokens, acls);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "49b20c2ed1be55c90a057acea71b55a28a3f69fb": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4554. Job Credentials are not transmitted if security is turned off (Benoy Antony via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1395769 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/10/12 1:50 PM",
      "commitName": "49b20c2ed1be55c90a057acea71b55a28a3f69fb",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "26/09/12 8:22 AM",
      "commitNameOld": "050fd3a11744cde3d54c1fff23d8fdeb3803bf92",
      "commitAuthorOld": "Thomas Graves",
      "daysBetweenCommits": 12.23,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,133 +1,130 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       LocalResource rc \u003d createApplicationResource(defaultFileContext,\n           jobJarPath, \n           LocalResourceType.PATTERN);\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n-    ByteBuffer securityTokens \u003d null;\n-    if (UserGroupInformation.isSecurityEnabled()) {\n-      DataOutputBuffer dob \u003d new DataOutputBuffer();\n-      ts.writeTokenStorageToStream(dob);\n-      securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n-    }\n+    DataOutputBuffer dob \u003d new DataOutputBuffer();\n+    ts.writeTokenStorageToStream(dob);\n+    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final commmand\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d BuilderUtils\n         .newContainerLaunchContext(null, UserGroupInformation\n             .getCurrentUser().getShortUserName(), capability, localResources,\n             environment, vargsFinal, null, securityTokens, acls);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    ByteBuffer securityTokens  \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d BuilderUtils\n        .newContainerLaunchContext(null, UserGroupInformation\n            .getCurrentUser().getShortUserName(), capability, localResources,\n            environment, vargsFinal, null, securityTokens, acls);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "050fd3a11744cde3d54c1fff23d8fdeb3803bf92": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4647. We should only unjar jobjar if there is a lib directory in it. (Robert Evans via tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1390557 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/09/12 8:22 AM",
      "commitName": "050fd3a11744cde3d54c1fff23d8fdeb3803bf92",
      "commitAuthor": "Thomas Graves",
      "commitDateOld": "27/08/12 5:40 PM",
      "commitNameOld": "24e47ebc18a62f6de351ec1ab8b9816999cc3267",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 29.61,
      "commitsBetweenForRepo": 163,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,129 +1,133 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n-      localResources.put(MRJobConfig.JOB_JAR,\n-          createApplicationResource(defaultFileContext,\n-              jobJarPath, LocalResourceType.ARCHIVE));\n+      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n+          jobJarPath, \n+          LocalResourceType.PATTERN);\n+      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n+          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n+      rc.setPattern(pattern);\n+      localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     ByteBuffer securityTokens \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       ts.writeTokenStorageToStream(dob);\n       securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n     }\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final commmand\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d BuilderUtils\n         .newContainerLaunchContext(null, UserGroupInformation\n             .getCurrentUser().getShortUserName(), capability, localResources,\n             environment, vargsFinal, null, securityTokens, acls);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(defaultFileContext,\n          jobJarPath, \n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN, \n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    ByteBuffer securityTokens \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      ts.writeTokenStorageToStream(dob);\n      securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n    }\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d BuilderUtils\n        .newContainerLaunchContext(null, UserGroupInformation\n            .getCurrentUser().getShortUserName(), capability, localResources,\n            environment, vargsFinal, null, securityTokens, acls);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "7b541d619f96ef7e447b0c3263d3ead89c8a6901": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4408. allow jobs to set a JAR that is in the distributed cached (rkanter via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1377149 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/12 4:36 PM",
      "commitName": "7b541d619f96ef7e447b0c3263d3ead89c8a6901",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "22/08/12 2:18 PM",
      "commitNameOld": "dc33a0765cd27255021911c4abb435b5850387aa",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 2.1,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,129 +1,129 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n+      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n       localResources.put(MRJobConfig.JOB_JAR,\n           createApplicationResource(defaultFileContext,\n-              new Path(jobSubmitDir, MRJobConfig.JOB_JAR), \n-              LocalResourceType.ARCHIVE));\n+              jobJarPath, LocalResourceType.ARCHIVE));\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     ByteBuffer securityTokens \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       ts.writeTokenStorageToStream(dob);\n       securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n     }\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final commmand\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d BuilderUtils\n         .newContainerLaunchContext(null, UserGroupInformation\n             .getCurrentUser().getShortUserName(), capability, localResources,\n             environment, vargsFinal, null, securityTokens, acls);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      localResources.put(MRJobConfig.JOB_JAR,\n          createApplicationResource(defaultFileContext,\n              jobJarPath, LocalResourceType.ARCHIVE));\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    ByteBuffer securityTokens \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      ts.writeTokenStorageToStream(dob);\n      securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n    }\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d BuilderUtils\n        .newContainerLaunchContext(null, UserGroupInformation\n            .getCurrentUser().getShortUserName(), capability, localResources,\n            environment, vargsFinal, null, securityTokens, acls);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "dc33a0765cd27255021911c4abb435b5850387aa": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4068. Jars in lib subdirectory of the submittable JAR are not added to the classpath (rkanter via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1376253 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/08/12 2:18 PM",
      "commitName": "dc33a0765cd27255021911c4abb435b5850387aa",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "08/05/12 8:07 AM",
      "commitNameOld": "aa60da6c2ec049cc70897afee6c368cb70493773",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 106.26,
      "commitsBetweenForRepo": 559,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,128 +1,129 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n-            jobConfPath));\n+            jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       localResources.put(MRJobConfig.JOB_JAR,\n           createApplicationResource(defaultFileContext,\n-              new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n+              new Path(jobSubmitDir, MRJobConfig.JOB_JAR), \n+              LocalResourceType.ARCHIVE));\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n-              new Path(jobSubmitDir, s)));\n+              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     // Setup security tokens\n     ByteBuffer securityTokens \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       ts.writeTokenStorageToStream(dob);\n       securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n     }\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final commmand\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d BuilderUtils\n         .newContainerLaunchContext(null, UserGroupInformation\n             .getCurrentUser().getShortUserName(), capability, localResources,\n             environment, vargsFinal, null, securityTokens, acls);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      localResources.put(MRJobConfig.JOB_JAR,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, MRJobConfig.JOB_JAR), \n              LocalResourceType.ARCHIVE));\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    // Setup security tokens\n    ByteBuffer securityTokens \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      ts.writeTokenStorageToStream(dob);\n      securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n    }\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d BuilderUtils\n        .newContainerLaunchContext(null, UserGroupInformation\n            .getCurrentUser().getShortUserName(), capability, localResources,\n            environment, vargsFinal, null, securityTokens, acls);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "947ede4c4e03a1684890ede265c211482b172bec": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3696. MR job via oozie does not work on hadoop 23. (John George via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1239310 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/02/12 12:43 PM",
      "commitName": "947ede4c4e03a1684890ede265c211482b172bec",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "01/02/12 9:03 AM",
      "commitNameOld": "e3d555a6569f3600fae4bac04cb21adacfe7c7be",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 0.15,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,128 +1,128 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       localResources.put(MRJobConfig.JOB_JAR,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s)));\n     }\n \n     // Setup security tokens\n     ByteBuffer securityTokens \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       ts.writeTokenStorageToStream(dob);\n       securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n     }\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final commmand\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n-    // i.e. add { job jar, CWD, Hadoop jars} to classpath.\n+    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment, conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d BuilderUtils\n         .newContainerLaunchContext(null, UserGroupInformation\n             .getCurrentUser().getShortUserName(), capability, localResources,\n             environment, vargsFinal, null, securityTokens, acls);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      localResources.put(MRJobConfig.JOB_JAR,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s)));\n    }\n\n    // Setup security tokens\n    ByteBuffer securityTokens \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      ts.writeTokenStorageToStream(dob);\n      securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n    }\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { Hadoop jars, job jar, CWD } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d BuilderUtils\n        .newContainerLaunchContext(null, UserGroupInformation\n            .getCurrentUser().getShortUserName(), capability, localResources,\n            environment, vargsFinal, null, securityTokens, acls);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "f73daf6af1c87c65dd97e5ec4608ba2742dc83ea": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3505. yarn APPLICATION_CLASSPATH needs to be overridable. (ahmed via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1235391 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/01/12 10:21 AM",
      "commitName": "f73daf6af1c87c65dd97e5ec4608ba2742dc83ea",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "10/01/12 5:50 PM",
      "commitNameOld": "bc4b1f48d3aba7f7a324ae76ab65a0920b1e609e",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 13.69,
      "commitsBetweenForRepo": 58,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,128 +1,128 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n     LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       localResources.put(MRJobConfig.JOB_JAR,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s)));\n     }\n \n     // Setup security tokens\n     ByteBuffer securityTokens \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       ts.writeTokenStorageToStream(dob);\n       securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n     }\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final commmand\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { job jar, CWD, Hadoop jars} to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n-    MRApps.setClasspath(environment);\n+    MRApps.setClasspath(environment, conf);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d BuilderUtils\n         .newContainerLaunchContext(null, UserGroupInformation\n             .getCurrentUser().getShortUserName(), capability, localResources,\n             environment, vargsFinal, null, securityTokens, acls);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      localResources.put(MRJobConfig.JOB_JAR,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s)));\n    }\n\n    // Setup security tokens\n    ByteBuffer securityTokens \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      ts.writeTokenStorageToStream(dob);\n      securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n    }\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { job jar, CWD, Hadoop jars} to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment, conf);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d BuilderUtils\n        .newContainerLaunchContext(null, UserGroupInformation\n            .getCurrentUser().getShortUserName(), capability, localResources,\n            environment, vargsFinal, null, securityTokens, acls);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "f17ed541c76ce08b43713f06ecafd1685e16dff2": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3265. Removed debug logs during job submission to LOG.debug to cut down noise. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1205628 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/11/11 2:04 PM",
      "commitName": "f17ed541c76ce08b43713f06ecafd1685e16dff2",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "06/11/11 2:58 PM",
      "commitNameOld": "6733a1ca5ef741d3bdf886f301954e9a9e7a875f",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 16.96,
      "commitsBetweenForRepo": 82,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,128 +1,128 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n-    LOG.info(\"AppMaster capability \u003d \" + capability);\n+    LOG.debug(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       localResources.put(MRJobConfig.JOB_JAR,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s)));\n     }\n \n     // Setup security tokens\n     ByteBuffer securityTokens \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       ts.writeTokenStorageToStream(dob);\n       securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n     }\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final commmand\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n-    LOG.info(\"Command to launch container for ApplicationMaster is : \"\n+    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { job jar, CWD, Hadoop jars} to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d BuilderUtils\n         .newContainerLaunchContext(null, UserGroupInformation\n             .getCurrentUser().getShortUserName(), capability, localResources,\n             environment, vargsFinal, null, securityTokens, acls);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setCancelTokensWhenComplete(\n         conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.debug(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      localResources.put(MRJobConfig.JOB_JAR,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s)));\n    }\n\n    // Setup security tokens\n    ByteBuffer securityTokens \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      ts.writeTokenStorageToStream(dob);\n      securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n    }\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { job jar, CWD, Hadoop jars} to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d BuilderUtils\n        .newContainerLaunchContext(null, UserGroupInformation\n            .getCurrentUser().getShortUserName(), capability, localResources,\n            environment, vargsFinal, null, securityTokens, acls);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "6733a1ca5ef741d3bdf886f301954e9a9e7a875f": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3291. App fail to launch due to delegation token not found in cache (Robert Evans via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1198583 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/11/11 2:58 PM",
      "commitName": "6733a1ca5ef741d3bdf886f301954e9a9e7a875f",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "30/10/11 11:42 PM",
      "commitNameOld": "47a381e306877750b5a3ce5d76e0a5ff652ec188",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 6.68,
      "commitsBetweenForRepo": 56,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,126 +1,128 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n     LOG.info(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       localResources.put(MRJobConfig.JOB_JAR,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s)));\n     }\n \n     // Setup security tokens\n     ByteBuffer securityTokens \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       ts.writeTokenStorageToStream(dob);\n       securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n     }\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final commmand\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.info(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { job jar, CWD, Hadoop jars} to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     Map\u003cApplicationAccessType, String\u003e acls\n         \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n     acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n     acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n         MRJobConfig.JOB_ACL_MODIFY_JOB,\n         MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d BuilderUtils\n         .newContainerLaunchContext(null, UserGroupInformation\n             .getCurrentUser().getShortUserName(), capability, localResources,\n             environment, vargsFinal, null, securityTokens, acls);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n+    appContext.setCancelTokensWhenComplete(\n+        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.info(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      localResources.put(MRJobConfig.JOB_JAR,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s)));\n    }\n\n    // Setup security tokens\n    ByteBuffer securityTokens \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      ts.writeTokenStorageToStream(dob);\n      securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n    }\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.info(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { job jar, CWD, Hadoop jars} to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d BuilderUtils\n        .newContainerLaunchContext(null, UserGroupInformation\n            .getCurrentUser().getShortUserName(), capability, localResources,\n            environment, vargsFinal, null, securityTokens, acls);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setCancelTokensWhenComplete(\n        conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "df2991c0cbc3f35c2640b93680667507c4f810dd": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3104. Implemented Application-acls. (vinodkv)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1186748 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/10/11 4:45 AM",
      "commitName": "df2991c0cbc3f35c2640b93680667507c4f810dd",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "18/10/11 2:45 PM",
      "commitNameOld": "ab787f44aabfff0cd01b79a08a52ffaf923558b3",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 1.58,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,121 +1,126 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n     LOG.info(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       localResources.put(MRJobConfig.JOB_JAR,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s)));\n     }\n \n     // Setup security tokens\n     ByteBuffer securityTokens \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       ts.writeTokenStorageToStream(dob);\n       securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n     }\n \n     // Setup the command to run the AM\n     List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n     // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     String logLevel \u003d jobConf.get(\n         MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n     MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final commmand\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.info(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { job jar, CWD, Hadoop jars} to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n+    Map\u003cApplicationAccessType, String\u003e acls\n+        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n+    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n+        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n+    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n+        MRJobConfig.JOB_ACL_MODIFY_JOB,\n+        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n+\n     // Setup ContainerLaunchContext for AM container\n-    ContainerLaunchContext amContainer \u003d\n-        recordFactory.newRecordInstance(ContainerLaunchContext.class);\n-    amContainer.setResource(capability);             // Resource (mem) required\n-    amContainer.setLocalResources(localResources);   // Local resources\n-    amContainer.setEnvironment(environment);         // Environment\n-    amContainer.setCommands(vargsFinal);             // Command for AM\n-    amContainer.setContainerTokens(securityTokens);  // Security tokens\n+    ContainerLaunchContext amContainer \u003d BuilderUtils\n+        .newContainerLaunchContext(null, UserGroupInformation\n+            .getCurrentUser().getShortUserName(), capability, localResources,\n+            environment, vargsFinal, null, securityTokens, acls);\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.info(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      localResources.put(MRJobConfig.JOB_JAR,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s)));\n    }\n\n    // Setup security tokens\n    ByteBuffer securityTokens \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      ts.writeTokenStorageToStream(dob);\n      securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n    }\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.info(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { job jar, CWD, Hadoop jars} to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    Map\u003cApplicationAccessType, String\u003e acls\n        \u003d new HashMap\u003cApplicationAccessType, String\u003e(2);\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(\n        MRJobConfig.JOB_ACL_MODIFY_JOB,\n        MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d BuilderUtils\n        .newContainerLaunchContext(null, UserGroupInformation\n            .getCurrentUser().getShortUserName(), capability, localResources,\n            environment, vargsFinal, null, securityTokens, acls);\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "ab787f44aabfff0cd01b79a08a52ffaf923558b3": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3165. Ensure logging options are set correctly for MR AM and tasks. Contributed by Todd Lipcon. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1185887 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/10/11 2:45 PM",
      "commitName": "ab787f44aabfff0cd01b79a08a52ffaf923558b3",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "30/09/11 5:46 AM",
      "commitNameOld": "063e33a862f99ce93b8399924c35d39ccd880f01",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 18.37,
      "commitsBetweenForRepo": 137,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,121 +1,121 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n     LOG.info(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       localResources.put(MRJobConfig.JOB_JAR,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s)));\n     }\n \n     // Setup security tokens\n     ByteBuffer securityTokens \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       ts.writeTokenStorageToStream(dob);\n       securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n     }\n \n     // Setup the command to run the AM\n-    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n+    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n \n+    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n-    vargs.add(\"-Dlog4j.configuration\u003dcontainer-log4j.properties\");\n-    vargs.add(\"-D\" + MRJobConfig.TASK_LOG_DIR + \"\u003d\"\n-        + ApplicationConstants.LOG_DIR_EXPANSION_VAR);\n-    vargs.add(\"-D\" + MRJobConfig.TASK_LOG_SIZE + \"\u003d\" + logSize);\n+    String logLevel \u003d jobConf.get(\n+        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n+    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final commmand\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.info(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     // Setup the CLASSPATH in environment\n     // i.e. add { job jar, CWD, Hadoop jars} to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment);\n \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         recordFactory.newRecordInstance(ContainerLaunchContext.class);\n     amContainer.setResource(capability);             // Resource (mem) required\n     amContainer.setLocalResources(localResources);   // Local resources\n     amContainer.setEnvironment(environment);         // Environment\n     amContainer.setCommands(vargsFinal);             // Command for AM\n     amContainer.setContainerTokens(securityTokens);  // Security tokens\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,\n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME,\n         YarnConfiguration.DEFAULT_APPLICATION_NAME));\n     appContext.setAMContainerSpec(amContainer);         // AM Container\n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n\n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.info(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      localResources.put(MRJobConfig.JOB_JAR,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s)));\n    }\n\n    // Setup security tokens\n    ByteBuffer securityTokens \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      ts.writeTokenStorageToStream(dob);\n      securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n    }\n\n    // Setup the command to run the AM\n    List\u003cString\u003e vargs \u003d new ArrayList\u003cString\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n\n    // TODO: why do we use \u0027conf\u0027 some places and \u0027jobConf\u0027 others?\n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    String logLevel \u003d jobConf.get(\n        MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\n    MRApps.addLog4jSystemProperties(logLevel, logSize, vargs);\n\n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +\n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.info(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    // Setup the CLASSPATH in environment\n    // i.e. add { job jar, CWD, Hadoop jars} to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        recordFactory.newRecordInstance(ContainerLaunchContext.class);\n    amContainer.setResource(capability);             // Resource (mem) required\n    amContainer.setLocalResources(localResources);   // Local resources\n    amContainer.setEnvironment(environment);         // Environment\n    amContainer.setCommands(vargsFinal);             // Command for AM\n    amContainer.setContainerTokens(securityTokens);  // Security tokens\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,\n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME,\n        YarnConfiguration.DEFAULT_APPLICATION_NAME));\n    appContext.setAMContainerSpec(amContainer);         // AM Container\n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "b549c107825581b15fd14494099a943ff3213c6f": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3055. Simplified ApplicationAttemptId passing to ApplicationMaster via environment variable. (vinodkv)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1174785 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/09/11 7:07 AM",
      "commitName": "b549c107825581b15fd14494099a943ff3213c6f",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "22/09/11 8:14 AM",
      "commitNameOld": "4806d7ba74c668817ea6f35421c559eaf57a997e",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.95,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,124 +1,121 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n     \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n     LOG.info(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n     \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n     \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       localResources.put(MRJobConfig.JOB_JAR,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n     \n     // TODO gross hack\n     for (String s : new String[] { \n         MRJobConfig.JOB_SPLIT, \n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext, \n               new Path(jobSubmitDir, s)));\n     }\n     \n     // Setup security tokens\n     ByteBuffer securityTokens \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       ts.writeTokenStorageToStream(dob);\n       securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n     }\n \n     // Setup the command to run the AM\n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     \n     long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n     vargs.add(\"-Dlog4j.configuration\u003dcontainer-log4j.properties\");\n     vargs.add(\"-D\" + MRJobConfig.TASK_LOG_DIR + \"\u003d\"\n         + ApplicationConstants.LOG_DIR_EXPANSION_VAR);\n     vargs.add(\"-D\" + MRJobConfig.TASK_LOG_SIZE + \"\u003d\" + logSize);\n     \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n-    vargs.add(String.valueOf(applicationId.getClusterTimestamp()));\n-    vargs.add(String.valueOf(applicationId.getId()));\n-    vargs.add(ApplicationConstants.AM_FAIL_COUNT_STRING);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final commmand\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.info(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n     \n     // Setup the CLASSPATH in environment \n     // i.e. add { job jar, CWD, Hadoop jars} to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment);\n     \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         recordFactory.newRecordInstance(ContainerLaunchContext.class);\n     amContainer.setResource(capability);             // Resource (mem) required\n     amContainer.setLocalResources(localResources);   // Local resources\n     amContainer.setEnvironment(environment);         // Environment\n     amContainer.setCommands(vargsFinal);             // Command for AM\n     amContainer.setContainerTokens(securityTokens);  // Security tokens\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,     \n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME, \n         YarnConfiguration.DEFAULT_APPLICATION_NAME));              \n     appContext.setAMContainerSpec(amContainer);         // AM Container \n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n    \n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.info(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n    \n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n    \n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      localResources.put(MRJobConfig.JOB_JAR,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n    \n    // TODO gross hack\n    for (String s : new String[] { \n        MRJobConfig.JOB_SPLIT, \n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext, \n              new Path(jobSubmitDir, s)));\n    }\n    \n    // Setup security tokens\n    ByteBuffer securityTokens \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      ts.writeTokenStorageToStream(dob);\n      securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n    }\n\n    // Setup the command to run the AM\n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    \n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    vargs.add(\"-Dlog4j.configuration\u003dcontainer-log4j.properties\");\n    vargs.add(\"-D\" + MRJobConfig.TASK_LOG_DIR + \"\u003d\"\n        + ApplicationConstants.LOG_DIR_EXPANSION_VAR);\n    vargs.add(\"-D\" + MRJobConfig.TASK_LOG_SIZE + \"\u003d\" + logSize);\n    \n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.info(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n    \n    // Setup the CLASSPATH in environment \n    // i.e. add { job jar, CWD, Hadoop jars} to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment);\n    \n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        recordFactory.newRecordInstance(ContainerLaunchContext.class);\n    amContainer.setResource(capability);             // Resource (mem) required\n    amContainer.setLocalResources(localResources);   // Local resources\n    amContainer.setEnvironment(environment);         // Environment\n    amContainer.setCommands(vargsFinal);             // Command for AM\n    amContainer.setContainerTokens(securityTokens);  // Security tokens\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,     \n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME, \n        YarnConfiguration.DEFAULT_APPLICATION_NAME));              \n    appContext.setAMContainerSpec(amContainer);         // AM Container \n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "4806d7ba74c668817ea6f35421c559eaf57a997e": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2754. Fixed MR AM stdout, stderr and syslog to redirect to correct log-files. Contributed by Ravi Teja Ch N V.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1174194 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/09/11 8:14 AM",
      "commitName": "4806d7ba74c668817ea6f35421c559eaf57a997e",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "21/09/11 11:28 AM",
      "commitNameOld": "d00b3c49f6fb3f6a617add6203c6b55f6c345940",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.87,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,121 +1,124 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n     \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n     LOG.info(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n     \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n     \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       localResources.put(MRJobConfig.JOB_JAR,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n     \n     // TODO gross hack\n     for (String s : new String[] { \n         MRJobConfig.JOB_SPLIT, \n         MRJobConfig.JOB_SPLIT_METAINFO,\n         MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext, \n               new Path(jobSubmitDir, s)));\n     }\n     \n     // Setup security tokens\n     ByteBuffer securityTokens \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       ts.writeTokenStorageToStream(dob);\n       securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n     }\n \n     // Setup the command to run the AM\n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n-    vargs.add(\"-Dhadoop.root.logger\u003d\"\n-        + conf.get(MRJobConfig.MR_AM_LOG_OPTS,\n-            MRJobConfig.DEFAULT_MR_AM_LOG_OPTS) + \",console\");\n+    \n+    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n+    vargs.add(\"-Dlog4j.configuration\u003dcontainer-log4j.properties\");\n+    vargs.add(\"-D\" + MRJobConfig.TASK_LOG_DIR + \"\u003d\"\n+        + ApplicationConstants.LOG_DIR_EXPANSION_VAR);\n+    vargs.add(\"-D\" + MRJobConfig.TASK_LOG_SIZE + \"\u003d\" + logSize);\n     \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(String.valueOf(applicationId.getClusterTimestamp()));\n     vargs.add(String.valueOf(applicationId.getId()));\n     vargs.add(ApplicationConstants.AM_FAIL_COUNT_STRING);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \n         Path.SEPARATOR + ApplicationConstants.STDOUT);\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \n         Path.SEPARATOR + ApplicationConstants.STDERR);\n \n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final commmand\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.info(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n     \n     // Setup the CLASSPATH in environment \n     // i.e. add { job jar, CWD, Hadoop jars} to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n     MRApps.setClasspath(environment);\n     \n     // Parse distributed cache\n     MRApps.setupDistributedCache(jobConf, localResources);\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         recordFactory.newRecordInstance(ContainerLaunchContext.class);\n     amContainer.setResource(capability);             // Resource (mem) required\n     amContainer.setLocalResources(localResources);   // Local resources\n     amContainer.setEnvironment(environment);         // Environment\n     amContainer.setCommands(vargsFinal);             // Command for AM\n     amContainer.setContainerTokens(securityTokens);  // Security tokens\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,     \n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME, \n         YarnConfiguration.DEFAULT_APPLICATION_NAME));              \n     appContext.setAMContainerSpec(amContainer);         // AM Container \n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n    \n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.info(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n    \n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n    \n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      localResources.put(MRJobConfig.JOB_JAR,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n    \n    // TODO gross hack\n    for (String s : new String[] { \n        MRJobConfig.JOB_SPLIT, \n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext, \n              new Path(jobSubmitDir, s)));\n    }\n    \n    // Setup security tokens\n    ByteBuffer securityTokens \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      ts.writeTokenStorageToStream(dob);\n      securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n    }\n\n    // Setup the command to run the AM\n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    \n    long logSize \u003d TaskLog.getTaskLogLength(new JobConf(conf));\n    vargs.add(\"-Dlog4j.configuration\u003dcontainer-log4j.properties\");\n    vargs.add(\"-D\" + MRJobConfig.TASK_LOG_DIR + \"\u003d\"\n        + ApplicationConstants.LOG_DIR_EXPANSION_VAR);\n    vargs.add(\"-D\" + MRJobConfig.TASK_LOG_SIZE + \"\u003d\" + logSize);\n    \n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(String.valueOf(applicationId.getClusterTimestamp()));\n    vargs.add(String.valueOf(applicationId.getId()));\n    vargs.add(ApplicationConstants.AM_FAIL_COUNT_STRING);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.info(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n    \n    // Setup the CLASSPATH in environment \n    // i.e. add { job jar, CWD, Hadoop jars} to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment);\n    \n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        recordFactory.newRecordInstance(ContainerLaunchContext.class);\n    amContainer.setResource(capability);             // Resource (mem) required\n    amContainer.setLocalResources(localResources);   // Local resources\n    amContainer.setEnvironment(environment);         // Environment\n    amContainer.setCommands(vargsFinal);             // Command for AM\n    amContainer.setContainerTokens(securityTokens);  // Security tokens\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,     \n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME, \n        YarnConfiguration.DEFAULT_APPLICATION_NAME));              \n    appContext.setAMContainerSpec(amContainer);         // AM Container \n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "d00b3c49f6fb3f6a617add6203c6b55f6c345940": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2880. Improved classpath-construction for mapreduce AM and containers. Contributed by Arun C Murthy.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1173783 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/09/11 11:28 AM",
      "commitName": "d00b3c49f6fb3f6a617add6203c6b55f6c345940",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "19/09/11 5:46 PM",
      "commitNameOld": "f0fedda8eff23d012c385675c728705e2c479363",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 1.74,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,119 +1,121 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n     \n     // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n     LOG.info(\"AppMaster capability \u003d \" + capability);\n \n     // Setup LocalResources\n     Map\u003cString, LocalResource\u003e localResources \u003d\n         new HashMap\u003cString, LocalResource\u003e();\n     \n-    Path jobConfPath \u003d new Path(jobSubmitDir, MRConstants.JOB_CONF_FILE);\n+    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n     \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n-    localResources.put(MRConstants.JOB_CONF_FILE,\n+    localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n-      localResources.put(MRConstants.JOB_JAR,\n+      localResources.put(MRJobConfig.JOB_JAR,\n           createApplicationResource(defaultFileContext,\n-              new Path(jobSubmitDir, MRConstants.JOB_JAR)));\n+              new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n     \n     // TODO gross hack\n-    for (String s : new String[] { \"job.split\", \"job.splitmetainfo\",\n-        MRConstants.APPLICATION_TOKENS_FILE }) {\n+    for (String s : new String[] { \n+        MRJobConfig.JOB_SPLIT, \n+        MRJobConfig.JOB_SPLIT_METAINFO,\n+        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n       localResources.put(\n-          MRConstants.JOB_SUBMIT_DIR + \"/\" + s,\n+          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext, \n               new Path(jobSubmitDir, s)));\n     }\n     \n     // Setup security tokens\n     ByteBuffer securityTokens \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       ts.writeTokenStorageToStream(dob);\n       securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n     }\n \n     // Setup the command to run the AM\n-    String javaHome \u003d \"$JAVA_HOME\";\n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n-    vargs.add(javaHome + \"/bin/java\");\n+    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     vargs.add(\"-Dhadoop.root.logger\u003d\"\n         + conf.get(MRJobConfig.MR_AM_LOG_OPTS,\n             MRJobConfig.DEFAULT_MR_AM_LOG_OPTS) + \",console\");\n     \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n-    vargs.add(\"org.apache.hadoop.mapreduce.v2.app.MRAppMaster\");\n+    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n     vargs.add(String.valueOf(applicationId.getClusterTimestamp()));\n     vargs.add(String.valueOf(applicationId.getId()));\n     vargs.add(ApplicationConstants.AM_FAIL_COUNT_STRING);\n-    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stdout\");\n-    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stderr\");\n+    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \n+        Path.SEPARATOR + ApplicationConstants.STDOUT);\n+    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \n+        Path.SEPARATOR + ApplicationConstants.STDERR);\n+\n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final commmand\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.info(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n     \n-    // Setup the environment - Add { job jar, MR app jar } to classpath.\n+    // Setup the CLASSPATH in environment \n+    // i.e. add { job jar, CWD, Hadoop jars} to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n-    MRApps.setInitialClasspath(environment);\n-    MRApps.addToClassPath(environment, MRConstants.JOB_JAR);\n-    MRApps.addToClassPath(environment,\n-        MRConstants.YARN_MAPREDUCE_APP_JAR_PATH);\n-\n+    MRApps.setClasspath(environment);\n+    \n     // Parse distributed cache\n-    MRApps.setupDistributedCache(jobConf, localResources, environment);\n+    MRApps.setupDistributedCache(jobConf, localResources);\n \n     // Setup ContainerLaunchContext for AM container\n     ContainerLaunchContext amContainer \u003d\n         recordFactory.newRecordInstance(ContainerLaunchContext.class);\n     amContainer.setResource(capability);             // Resource (mem) required\n     amContainer.setLocalResources(localResources);   // Local resources\n     amContainer.setEnvironment(environment);         // Environment\n     amContainer.setCommands(vargsFinal);             // Command for AM\n     amContainer.setContainerTokens(securityTokens);  // Security tokens\n \n     // Set up the ApplicationSubmissionContext\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     appContext.setApplicationId(applicationId);                // ApplicationId\n     appContext.setUser(                                        // User name\n         UserGroupInformation.getCurrentUser().getShortUserName());\n     appContext.setQueue(                                       // Queue name\n         jobConf.get(JobContext.QUEUE_NAME,     \n         YarnConfiguration.DEFAULT_QUEUE_NAME));\n     appContext.setApplicationName(                             // Job name\n         jobConf.get(JobContext.JOB_NAME, \n         YarnConfiguration.DEFAULT_APPLICATION_NAME));              \n     appContext.setAMContainerSpec(amContainer);         // AM Container \n \n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n    \n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.info(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n    \n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n    \n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      localResources.put(MRJobConfig.JOB_JAR,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, MRJobConfig.JOB_JAR)));\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n    \n    // TODO gross hack\n    for (String s : new String[] { \n        MRJobConfig.JOB_SPLIT, \n        MRJobConfig.JOB_SPLIT_METAINFO,\n        MRJobConfig.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext, \n              new Path(jobSubmitDir, s)));\n    }\n    \n    // Setup security tokens\n    ByteBuffer securityTokens \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      ts.writeTokenStorageToStream(dob);\n      securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n    }\n\n    // Setup the command to run the AM\n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    vargs.add(\"-Dhadoop.root.logger\u003d\"\n        + conf.get(MRJobConfig.MR_AM_LOG_OPTS,\n            MRJobConfig.DEFAULT_MR_AM_LOG_OPTS) + \",console\");\n    \n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\n    vargs.add(String.valueOf(applicationId.getClusterTimestamp()));\n    vargs.add(String.valueOf(applicationId.getId()));\n    vargs.add(ApplicationConstants.AM_FAIL_COUNT_STRING);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \n        Path.SEPARATOR + ApplicationConstants.STDOUT);\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \n        Path.SEPARATOR + ApplicationConstants.STDERR);\n\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.info(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n    \n    // Setup the CLASSPATH in environment \n    // i.e. add { job jar, CWD, Hadoop jars} to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setClasspath(environment);\n    \n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources);\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        recordFactory.newRecordInstance(ContainerLaunchContext.class);\n    amContainer.setResource(capability);             // Resource (mem) required\n    amContainer.setLocalResources(localResources);   // Local resources\n    amContainer.setEnvironment(environment);         // Environment\n    amContainer.setCommands(vargsFinal);             // Command for AM\n    amContainer.setContainerTokens(securityTokens);  // Security tokens\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,     \n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME, \n        YarnConfiguration.DEFAULT_APPLICATION_NAME));              \n    appContext.setAMContainerSpec(amContainer);         // AM Container \n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "88b82a0f6687ce103817fbb460fd30d870f717a0": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2899. Replace major parts of ApplicationSubmissionContext with a ContainerLaunchContext (Arun Murthy via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1170459 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/09/11 12:26 AM",
      "commitName": "88b82a0f6687ce103817fbb460fd30d870f717a0",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "12/09/11 5:05 PM",
      "commitNameOld": "6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 1.31,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,119 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n-    ApplicationSubmissionContext appContext \u003d\n-        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n-    appContext.setApplicationId(applicationId);\n+    \n+    // Setup resource requirements\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n     LOG.info(\"AppMaster capability \u003d \" + capability);\n-    appContext.setMasterCapability(capability);\n \n+    // Setup LocalResources\n+    Map\u003cString, LocalResource\u003e localResources \u003d\n+        new HashMap\u003cString, LocalResource\u003e();\n+    \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRConstants.JOB_CONF_FILE);\n     \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n-    appContext.setResource(MRConstants.JOB_SUBMIT_DIR,\n-        yarnUrlForJobSubmitDir);\n-\n-    appContext.setResourceTodo(MRConstants.JOB_CONF_FILE,\n+    localResources.put(MRConstants.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n-      appContext.setResourceTodo(MRConstants.JOB_JAR,\n+      localResources.put(MRConstants.JOB_JAR,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, MRConstants.JOB_JAR)));\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n     \n     // TODO gross hack\n     for (String s : new String[] { \"job.split\", \"job.splitmetainfo\",\n         MRConstants.APPLICATION_TOKENS_FILE }) {\n-      appContext.setResourceTodo(\n+      localResources.put(\n           MRConstants.JOB_SUBMIT_DIR + \"/\" + s,\n-          createApplicationResource(defaultFileContext, new Path(jobSubmitDir, s)));\n-    }\n-\n-    // TODO: Only if security is on.\n-    List\u003cString\u003e fsTokens \u003d new ArrayList\u003cString\u003e();\n-    for (Token\u003c? extends TokenIdentifier\u003e token : ts.getAllTokens()) {\n-      fsTokens.add(token.encodeToUrlString());\n+          createApplicationResource(defaultFileContext, \n+              new Path(jobSubmitDir, s)));\n     }\n     \n-    // TODO - Remove this!\n-    appContext.addAllFsTokens(fsTokens);\n-    DataOutputBuffer dob \u003d new DataOutputBuffer();\n-    ts.writeTokenStorageToStream(dob);\n-    appContext.setFsTokensTodo(ByteBuffer.wrap(dob.getData(), 0, dob.getLength()));\n+    // Setup security tokens\n+    ByteBuffer securityTokens \u003d null;\n+    if (UserGroupInformation.isSecurityEnabled()) {\n+      DataOutputBuffer dob \u003d new DataOutputBuffer();\n+      ts.writeTokenStorageToStream(dob);\n+      securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n+    }\n \n-    // Add queue information\n-    appContext.setQueue(jobConf.get(JobContext.QUEUE_NAME, JobConf.DEFAULT_QUEUE_NAME));\n-    \n-    // Add job name\n-    appContext.setApplicationName(jobConf.get(JobContext.JOB_NAME, \"N/A\"));\n-    \n-    // Add the command line\n+    // Setup the command to run the AM\n     String javaHome \u003d \"$JAVA_HOME\";\n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n     vargs.add(javaHome + \"/bin/java\");\n     vargs.add(\"-Dhadoop.root.logger\u003d\"\n         + conf.get(MRJobConfig.MR_AM_LOG_OPTS,\n             MRJobConfig.DEFAULT_MR_AM_LOG_OPTS) + \",console\");\n     \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n-    // Add { job jar, MR app jar } to classpath.\n-    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n-    MRApps.setInitialClasspath(environment);\n-    MRApps.addToClassPath(environment, MRConstants.JOB_JAR);\n-    MRApps.addToClassPath(environment,\n-        MRConstants.YARN_MAPREDUCE_APP_JAR_PATH);\n-    appContext.addAllEnvironment(environment);\n     vargs.add(\"org.apache.hadoop.mapreduce.v2.app.MRAppMaster\");\n     vargs.add(String.valueOf(applicationId.getClusterTimestamp()));\n     vargs.add(String.valueOf(applicationId.getId()));\n     vargs.add(ApplicationConstants.AM_FAIL_COUNT_STRING);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stderr\");\n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final commmand\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.info(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n+    \n+    // Setup the environment - Add { job jar, MR app jar } to classpath.\n+    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n+    MRApps.setInitialClasspath(environment);\n+    MRApps.addToClassPath(environment, MRConstants.JOB_JAR);\n+    MRApps.addToClassPath(environment,\n+        MRConstants.YARN_MAPREDUCE_APP_JAR_PATH);\n \n-    appContext.addAllCommands(vargsFinal);\n-    // TODO: RM should get this from RPC.\n-    appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName());\n+    // Parse distributed cache\n+    MRApps.setupDistributedCache(jobConf, localResources, environment);\n+\n+    // Setup ContainerLaunchContext for AM container\n+    ContainerLaunchContext amContainer \u003d\n+        recordFactory.newRecordInstance(ContainerLaunchContext.class);\n+    amContainer.setResource(capability);             // Resource (mem) required\n+    amContainer.setLocalResources(localResources);   // Local resources\n+    amContainer.setEnvironment(environment);         // Environment\n+    amContainer.setCommands(vargsFinal);             // Command for AM\n+    amContainer.setContainerTokens(securityTokens);  // Security tokens\n+\n+    // Set up the ApplicationSubmissionContext\n+    ApplicationSubmissionContext appContext \u003d\n+        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n+    appContext.setApplicationId(applicationId);                // ApplicationId\n+    appContext.setUser(                                        // User name\n+        UserGroupInformation.getCurrentUser().getShortUserName());\n+    appContext.setQueue(                                       // Queue name\n+        jobConf.get(JobContext.QUEUE_NAME,     \n+        YarnConfiguration.DEFAULT_QUEUE_NAME));\n+    appContext.setApplicationName(                             // Job name\n+        jobConf.get(JobContext.JOB_NAME, \n+        YarnConfiguration.DEFAULT_APPLICATION_NAME));              \n+    appContext.setAMContainerSpec(amContainer);         // AM Container \n+\n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n    \n    // Setup resource requirements\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.info(\"AppMaster capability \u003d \" + capability);\n\n    // Setup LocalResources\n    Map\u003cString, LocalResource\u003e localResources \u003d\n        new HashMap\u003cString, LocalResource\u003e();\n    \n    Path jobConfPath \u003d new Path(jobSubmitDir, MRConstants.JOB_CONF_FILE);\n    \n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRConstants.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      localResources.put(MRConstants.JOB_JAR,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, MRConstants.JOB_JAR)));\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n    \n    // TODO gross hack\n    for (String s : new String[] { \"job.split\", \"job.splitmetainfo\",\n        MRConstants.APPLICATION_TOKENS_FILE }) {\n      localResources.put(\n          MRConstants.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext, \n              new Path(jobSubmitDir, s)));\n    }\n    \n    // Setup security tokens\n    ByteBuffer securityTokens \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      ts.writeTokenStorageToStream(dob);\n      securityTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n    }\n\n    // Setup the command to run the AM\n    String javaHome \u003d \"$JAVA_HOME\";\n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n    vargs.add(javaHome + \"/bin/java\");\n    vargs.add(\"-Dhadoop.root.logger\u003d\"\n        + conf.get(MRJobConfig.MR_AM_LOG_OPTS,\n            MRJobConfig.DEFAULT_MR_AM_LOG_OPTS) + \",console\");\n    \n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    vargs.add(\"org.apache.hadoop.mapreduce.v2.app.MRAppMaster\");\n    vargs.add(String.valueOf(applicationId.getClusterTimestamp()));\n    vargs.add(String.valueOf(applicationId.getId()));\n    vargs.add(ApplicationConstants.AM_FAIL_COUNT_STRING);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stderr\");\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.info(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n    \n    // Setup the environment - Add { job jar, MR app jar } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setInitialClasspath(environment);\n    MRApps.addToClassPath(environment, MRConstants.JOB_JAR);\n    MRApps.addToClassPath(environment,\n        MRConstants.YARN_MAPREDUCE_APP_JAR_PATH);\n\n    // Parse distributed cache\n    MRApps.setupDistributedCache(jobConf, localResources, environment);\n\n    // Setup ContainerLaunchContext for AM container\n    ContainerLaunchContext amContainer \u003d\n        recordFactory.newRecordInstance(ContainerLaunchContext.class);\n    amContainer.setResource(capability);             // Resource (mem) required\n    amContainer.setLocalResources(localResources);   // Local resources\n    amContainer.setEnvironment(environment);         // Environment\n    amContainer.setCommands(vargsFinal);             // Command for AM\n    amContainer.setContainerTokens(securityTokens);  // Security tokens\n\n    // Set up the ApplicationSubmissionContext\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    appContext.setApplicationId(applicationId);                // ApplicationId\n    appContext.setUser(                                        // User name\n        UserGroupInformation.getCurrentUser().getShortUserName());\n    appContext.setQueue(                                       // Queue name\n        jobConf.get(JobContext.QUEUE_NAME,     \n        YarnConfiguration.DEFAULT_QUEUE_NAME));\n    appContext.setApplicationName(                             // Job name\n        jobConf.get(JobContext.JOB_NAME, \n        YarnConfiguration.DEFAULT_APPLICATION_NAME));              \n    appContext.setAMContainerSpec(amContainer);         // AM Container \n\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2896. Simplify all apis to in org.apache.hadoop.yarn.api.records.* to be get/set only. Added javadocs to all public records.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1169980 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/09/11 5:05 PM",
      "commitName": "6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "09/09/11 3:42 PM",
      "commitNameOld": "b982e6205f255c62b281a82ccf95f239b4b44e04",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 3.06,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,107 +1,106 @@\n   public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n     appContext.setApplicationId(applicationId);\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n     LOG.info(\"AppMaster capability \u003d \" + capability);\n     appContext.setMasterCapability(capability);\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRConstants.JOB_CONF_FILE);\n     \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     appContext.setResource(MRConstants.JOB_SUBMIT_DIR,\n         yarnUrlForJobSubmitDir);\n \n     appContext.setResourceTodo(MRConstants.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       appContext.setResourceTodo(MRConstants.JOB_JAR,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, MRConstants.JOB_JAR)));\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n     \n     // TODO gross hack\n     for (String s : new String[] { \"job.split\", \"job.splitmetainfo\",\n         MRConstants.APPLICATION_TOKENS_FILE }) {\n       appContext.setResourceTodo(\n           MRConstants.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext, new Path(jobSubmitDir, s)));\n     }\n \n     // TODO: Only if security is on.\n     List\u003cString\u003e fsTokens \u003d new ArrayList\u003cString\u003e();\n     for (Token\u003c? extends TokenIdentifier\u003e token : ts.getAllTokens()) {\n       fsTokens.add(token.encodeToUrlString());\n     }\n     \n     // TODO - Remove this!\n     appContext.addAllFsTokens(fsTokens);\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     appContext.setFsTokensTodo(ByteBuffer.wrap(dob.getData(), 0, dob.getLength()));\n \n     // Add queue information\n     appContext.setQueue(jobConf.get(JobContext.QUEUE_NAME, JobConf.DEFAULT_QUEUE_NAME));\n     \n     // Add job name\n     appContext.setApplicationName(jobConf.get(JobContext.JOB_NAME, \"N/A\"));\n     \n     // Add the command line\n     String javaHome \u003d \"$JAVA_HOME\";\n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n     vargs.add(javaHome + \"/bin/java\");\n     vargs.add(\"-Dhadoop.root.logger\u003d\"\n         + conf.get(MRJobConfig.MR_AM_LOG_OPTS,\n             MRJobConfig.DEFAULT_MR_AM_LOG_OPTS) + \",console\");\n     \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     // Add { job jar, MR app jar } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n-//    appContext.environment \u003d new HashMap\u003cCharSequence, CharSequence\u003e();\n     MRApps.setInitialClasspath(environment);\n     MRApps.addToClassPath(environment, MRConstants.JOB_JAR);\n     MRApps.addToClassPath(environment,\n         MRConstants.YARN_MAPREDUCE_APP_JAR_PATH);\n     appContext.addAllEnvironment(environment);\n     vargs.add(\"org.apache.hadoop.mapreduce.v2.app.MRAppMaster\");\n     vargs.add(String.valueOf(applicationId.getClusterTimestamp()));\n     vargs.add(String.valueOf(applicationId.getId()));\n     vargs.add(ApplicationConstants.AM_FAIL_COUNT_STRING);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stderr\");\n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final commmand\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.info(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     appContext.addAllCommands(vargsFinal);\n     // TODO: RM should get this from RPC.\n     appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName());\n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n    appContext.setApplicationId(applicationId);\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.info(\"AppMaster capability \u003d \" + capability);\n    appContext.setMasterCapability(capability);\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRConstants.JOB_CONF_FILE);\n    \n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    appContext.setResource(MRConstants.JOB_SUBMIT_DIR,\n        yarnUrlForJobSubmitDir);\n\n    appContext.setResourceTodo(MRConstants.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      appContext.setResourceTodo(MRConstants.JOB_JAR,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, MRConstants.JOB_JAR)));\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n    \n    // TODO gross hack\n    for (String s : new String[] { \"job.split\", \"job.splitmetainfo\",\n        MRConstants.APPLICATION_TOKENS_FILE }) {\n      appContext.setResourceTodo(\n          MRConstants.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext, new Path(jobSubmitDir, s)));\n    }\n\n    // TODO: Only if security is on.\n    List\u003cString\u003e fsTokens \u003d new ArrayList\u003cString\u003e();\n    for (Token\u003c? extends TokenIdentifier\u003e token : ts.getAllTokens()) {\n      fsTokens.add(token.encodeToUrlString());\n    }\n    \n    // TODO - Remove this!\n    appContext.addAllFsTokens(fsTokens);\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    appContext.setFsTokensTodo(ByteBuffer.wrap(dob.getData(), 0, dob.getLength()));\n\n    // Add queue information\n    appContext.setQueue(jobConf.get(JobContext.QUEUE_NAME, JobConf.DEFAULT_QUEUE_NAME));\n    \n    // Add job name\n    appContext.setApplicationName(jobConf.get(JobContext.JOB_NAME, \"N/A\"));\n    \n    // Add the command line\n    String javaHome \u003d \"$JAVA_HOME\";\n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n    vargs.add(javaHome + \"/bin/java\");\n    vargs.add(\"-Dhadoop.root.logger\u003d\"\n        + conf.get(MRJobConfig.MR_AM_LOG_OPTS,\n            MRJobConfig.DEFAULT_MR_AM_LOG_OPTS) + \",console\");\n    \n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    // Add { job jar, MR app jar } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n    MRApps.setInitialClasspath(environment);\n    MRApps.addToClassPath(environment, MRConstants.JOB_JAR);\n    MRApps.addToClassPath(environment,\n        MRConstants.YARN_MAPREDUCE_APP_JAR_PATH);\n    appContext.addAllEnvironment(environment);\n    vargs.add(\"org.apache.hadoop.mapreduce.v2.app.MRAppMaster\");\n    vargs.add(String.valueOf(applicationId.getClusterTimestamp()));\n    vargs.add(String.valueOf(applicationId.getId()));\n    vargs.add(ApplicationConstants.AM_FAIL_COUNT_STRING);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stderr\");\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.info(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    appContext.addAllCommands(vargsFinal);\n    // TODO: RM should get this from RPC.\n    appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName());\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "a0ef2d7503669fe7fbbe0206ef0a41315925c150": {
      "type": "Ymodifierchange",
      "commitMessage": "MAPREDUCE-2937. Ensure reason for application failure is displayed to the user. Contributed by Mahadev Konar.  \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1166966 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/09/11 7:14 PM",
      "commitName": "a0ef2d7503669fe7fbbe0206ef0a41315925c150",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "08/09/11 6:44 PM",
      "commitNameOld": "fafe8cd28e726566509c679e19d7da622f29f90d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,107 +1,107 @@\n-  private ApplicationSubmissionContext createApplicationSubmissionContext(\n+  public ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n     appContext.setApplicationId(applicationId);\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n     capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n         MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n     LOG.info(\"AppMaster capability \u003d \" + capability);\n     appContext.setMasterCapability(capability);\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRConstants.JOB_CONF_FILE);\n     \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     appContext.setResource(MRConstants.JOB_SUBMIT_DIR,\n         yarnUrlForJobSubmitDir);\n \n     appContext.setResourceTodo(MRConstants.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       appContext.setResourceTodo(MRConstants.JOB_JAR,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, MRConstants.JOB_JAR)));\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n     \n     // TODO gross hack\n     for (String s : new String[] { \"job.split\", \"job.splitmetainfo\",\n         MRConstants.APPLICATION_TOKENS_FILE }) {\n       appContext.setResourceTodo(\n           MRConstants.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext, new Path(jobSubmitDir, s)));\n     }\n \n     // TODO: Only if security is on.\n     List\u003cString\u003e fsTokens \u003d new ArrayList\u003cString\u003e();\n     for (Token\u003c? extends TokenIdentifier\u003e token : ts.getAllTokens()) {\n       fsTokens.add(token.encodeToUrlString());\n     }\n     \n     // TODO - Remove this!\n     appContext.addAllFsTokens(fsTokens);\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     appContext.setFsTokensTodo(ByteBuffer.wrap(dob.getData(), 0, dob.getLength()));\n \n     // Add queue information\n     appContext.setQueue(jobConf.get(JobContext.QUEUE_NAME, JobConf.DEFAULT_QUEUE_NAME));\n     \n     // Add job name\n     appContext.setApplicationName(jobConf.get(JobContext.JOB_NAME, \"N/A\"));\n     \n     // Add the command line\n     String javaHome \u003d \"$JAVA_HOME\";\n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n     vargs.add(javaHome + \"/bin/java\");\n     vargs.add(\"-Dhadoop.root.logger\u003d\"\n         + conf.get(MRJobConfig.MR_AM_LOG_OPTS,\n             MRJobConfig.DEFAULT_MR_AM_LOG_OPTS) + \",console\");\n     \n     vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n         MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     // Add { job jar, MR app jar } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n //    appContext.environment \u003d new HashMap\u003cCharSequence, CharSequence\u003e();\n     MRApps.setInitialClasspath(environment);\n     MRApps.addToClassPath(environment, MRConstants.JOB_JAR);\n     MRApps.addToClassPath(environment,\n         MRConstants.YARN_MAPREDUCE_APP_JAR_PATH);\n     appContext.addAllEnvironment(environment);\n     vargs.add(\"org.apache.hadoop.mapreduce.v2.app.MRAppMaster\");\n     vargs.add(String.valueOf(applicationId.getClusterTimestamp()));\n     vargs.add(String.valueOf(applicationId.getId()));\n     vargs.add(ApplicationConstants.AM_FAIL_COUNT_STRING);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stderr\");\n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final commmand\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.info(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     appContext.addAllCommands(vargsFinal);\n     // TODO: RM should get this from RPC.\n     appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName());\n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n    appContext.setApplicationId(applicationId);\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.info(\"AppMaster capability \u003d \" + capability);\n    appContext.setMasterCapability(capability);\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRConstants.JOB_CONF_FILE);\n    \n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    appContext.setResource(MRConstants.JOB_SUBMIT_DIR,\n        yarnUrlForJobSubmitDir);\n\n    appContext.setResourceTodo(MRConstants.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      appContext.setResourceTodo(MRConstants.JOB_JAR,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, MRConstants.JOB_JAR)));\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n    \n    // TODO gross hack\n    for (String s : new String[] { \"job.split\", \"job.splitmetainfo\",\n        MRConstants.APPLICATION_TOKENS_FILE }) {\n      appContext.setResourceTodo(\n          MRConstants.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext, new Path(jobSubmitDir, s)));\n    }\n\n    // TODO: Only if security is on.\n    List\u003cString\u003e fsTokens \u003d new ArrayList\u003cString\u003e();\n    for (Token\u003c? extends TokenIdentifier\u003e token : ts.getAllTokens()) {\n      fsTokens.add(token.encodeToUrlString());\n    }\n    \n    // TODO - Remove this!\n    appContext.addAllFsTokens(fsTokens);\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    appContext.setFsTokensTodo(ByteBuffer.wrap(dob.getData(), 0, dob.getLength()));\n\n    // Add queue information\n    appContext.setQueue(jobConf.get(JobContext.QUEUE_NAME, JobConf.DEFAULT_QUEUE_NAME));\n    \n    // Add job name\n    appContext.setApplicationName(jobConf.get(JobContext.JOB_NAME, \"N/A\"));\n    \n    // Add the command line\n    String javaHome \u003d \"$JAVA_HOME\";\n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n    vargs.add(javaHome + \"/bin/java\");\n    vargs.add(\"-Dhadoop.root.logger\u003d\"\n        + conf.get(MRJobConfig.MR_AM_LOG_OPTS,\n            MRJobConfig.DEFAULT_MR_AM_LOG_OPTS) + \",console\");\n    \n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    // Add { job jar, MR app jar } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n//    appContext.environment \u003d new HashMap\u003cCharSequence, CharSequence\u003e();\n    MRApps.setInitialClasspath(environment);\n    MRApps.addToClassPath(environment, MRConstants.JOB_JAR);\n    MRApps.addToClassPath(environment,\n        MRConstants.YARN_MAPREDUCE_APP_JAR_PATH);\n    appContext.addAllEnvironment(environment);\n    vargs.add(\"org.apache.hadoop.mapreduce.v2.app.MRAppMaster\");\n    vargs.add(String.valueOf(applicationId.getClusterTimestamp()));\n    vargs.add(String.valueOf(applicationId.getId()));\n    vargs.add(ApplicationConstants.AM_FAIL_COUNT_STRING);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stderr\");\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.info(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    appContext.addAllCommands(vargsFinal);\n    // TODO: RM should get this from RPC.\n    appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName());\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {
        "oldValue": "[private]",
        "newValue": "[public]"
      }
    },
    "fafe8cd28e726566509c679e19d7da622f29f90d": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2864. Normalize configuration variable names for YARN. Contributed by Robert Evans.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1166955 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/09/11 6:44 PM",
      "commitName": "fafe8cd28e726566509c679e19d7da622f29f90d",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 11:35 PM",
      "commitNameOld": "f2b91a8367a762091482074505618b570a520b19",
      "commitAuthorOld": "Sharad Agarwal",
      "daysBetweenCommits": 14.8,
      "commitsBetweenForRepo": 84,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,107 @@\n   private ApplicationSubmissionContext createApplicationSubmissionContext(\n       Configuration jobConf,\n       String jobSubmitDir, Credentials ts) throws IOException {\n     ApplicationSubmissionContext appContext \u003d\n         recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n     ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n     appContext.setApplicationId(applicationId);\n     Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n-    capability.setMemory(conf.getInt(YARN_AM_VMEM_MB, DEFAULT_YARN_AM_VMEM_MB));\n+    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n+        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n     LOG.info(\"AppMaster capability \u003d \" + capability);\n     appContext.setMasterCapability(capability);\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRConstants.JOB_CONF_FILE);\n     \n     URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n         .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n             .resolvePath(\n                 defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     appContext.setResource(MRConstants.JOB_SUBMIT_DIR,\n         yarnUrlForJobSubmitDir);\n \n     appContext.setResourceTodo(MRConstants.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       appContext.setResourceTodo(MRConstants.JOB_JAR,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, MRConstants.JOB_JAR)));\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n     \n     // TODO gross hack\n     for (String s : new String[] { \"job.split\", \"job.splitmetainfo\",\n         MRConstants.APPLICATION_TOKENS_FILE }) {\n       appContext.setResourceTodo(\n           MRConstants.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext, new Path(jobSubmitDir, s)));\n     }\n \n     // TODO: Only if security is on.\n     List\u003cString\u003e fsTokens \u003d new ArrayList\u003cString\u003e();\n     for (Token\u003c? extends TokenIdentifier\u003e token : ts.getAllTokens()) {\n       fsTokens.add(token.encodeToUrlString());\n     }\n     \n     // TODO - Remove this!\n     appContext.addAllFsTokens(fsTokens);\n     DataOutputBuffer dob \u003d new DataOutputBuffer();\n     ts.writeTokenStorageToStream(dob);\n     appContext.setFsTokensTodo(ByteBuffer.wrap(dob.getData(), 0, dob.getLength()));\n \n     // Add queue information\n     appContext.setQueue(jobConf.get(JobContext.QUEUE_NAME, JobConf.DEFAULT_QUEUE_NAME));\n     \n     // Add job name\n     appContext.setApplicationName(jobConf.get(JobContext.JOB_NAME, \"N/A\"));\n     \n     // Add the command line\n     String javaHome \u003d \"$JAVA_HOME\";\n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n     vargs.add(javaHome + \"/bin/java\");\n     vargs.add(\"-Dhadoop.root.logger\u003d\"\n-        + conf.get(ClientConstants.MR_APPMASTER_LOG_OPTS,\n-            ClientConstants.DEFAULT_MR_APPMASTER_LOG_OPTS) + \",console\");\n+        + conf.get(MRJobConfig.MR_AM_LOG_OPTS,\n+            MRJobConfig.DEFAULT_MR_AM_LOG_OPTS) + \",console\");\n     \n-    vargs.add(conf.get(ClientConstants.MR_APPMASTER_COMMAND_OPTS,\n-        ClientConstants.DEFAULT_MR_APPMASTER_COMMAND_OPTS));\n+    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n+        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n \n     // Add { job jar, MR app jar } to classpath.\n     Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n //    appContext.environment \u003d new HashMap\u003cCharSequence, CharSequence\u003e();\n     MRApps.setInitialClasspath(environment);\n     MRApps.addToClassPath(environment, MRConstants.JOB_JAR);\n     MRApps.addToClassPath(environment,\n         MRConstants.YARN_MAPREDUCE_APP_JAR_PATH);\n     appContext.addAllEnvironment(environment);\n     vargs.add(\"org.apache.hadoop.mapreduce.v2.app.MRAppMaster\");\n     vargs.add(String.valueOf(applicationId.getClusterTimestamp()));\n     vargs.add(String.valueOf(applicationId.getId()));\n     vargs.add(ApplicationConstants.AM_FAIL_COUNT_STRING);\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stderr\");\n \n     Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n     // Final commmand\n     StringBuilder mergedCommand \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       mergedCommand.append(str).append(\" \");\n     }\n     vargsFinal.add(mergedCommand.toString());\n \n     LOG.info(\"Command to launch container for ApplicationMaster is : \"\n         + mergedCommand);\n \n     appContext.addAllCommands(vargsFinal);\n     // TODO: RM should get this from RPC.\n     appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName());\n     return appContext;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n    appContext.setApplicationId(applicationId);\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,\n        MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\n    LOG.info(\"AppMaster capability \u003d \" + capability);\n    appContext.setMasterCapability(capability);\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRConstants.JOB_CONF_FILE);\n    \n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    appContext.setResource(MRConstants.JOB_SUBMIT_DIR,\n        yarnUrlForJobSubmitDir);\n\n    appContext.setResourceTodo(MRConstants.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      appContext.setResourceTodo(MRConstants.JOB_JAR,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, MRConstants.JOB_JAR)));\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n    \n    // TODO gross hack\n    for (String s : new String[] { \"job.split\", \"job.splitmetainfo\",\n        MRConstants.APPLICATION_TOKENS_FILE }) {\n      appContext.setResourceTodo(\n          MRConstants.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext, new Path(jobSubmitDir, s)));\n    }\n\n    // TODO: Only if security is on.\n    List\u003cString\u003e fsTokens \u003d new ArrayList\u003cString\u003e();\n    for (Token\u003c? extends TokenIdentifier\u003e token : ts.getAllTokens()) {\n      fsTokens.add(token.encodeToUrlString());\n    }\n    \n    // TODO - Remove this!\n    appContext.addAllFsTokens(fsTokens);\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    appContext.setFsTokensTodo(ByteBuffer.wrap(dob.getData(), 0, dob.getLength()));\n\n    // Add queue information\n    appContext.setQueue(jobConf.get(JobContext.QUEUE_NAME, JobConf.DEFAULT_QUEUE_NAME));\n    \n    // Add job name\n    appContext.setApplicationName(jobConf.get(JobContext.JOB_NAME, \"N/A\"));\n    \n    // Add the command line\n    String javaHome \u003d \"$JAVA_HOME\";\n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n    vargs.add(javaHome + \"/bin/java\");\n    vargs.add(\"-Dhadoop.root.logger\u003d\"\n        + conf.get(MRJobConfig.MR_AM_LOG_OPTS,\n            MRJobConfig.DEFAULT_MR_AM_LOG_OPTS) + \",console\");\n    \n    vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,\n        MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));\n\n    // Add { job jar, MR app jar } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n//    appContext.environment \u003d new HashMap\u003cCharSequence, CharSequence\u003e();\n    MRApps.setInitialClasspath(environment);\n    MRApps.addToClassPath(environment, MRConstants.JOB_JAR);\n    MRApps.addToClassPath(environment,\n        MRConstants.YARN_MAPREDUCE_APP_JAR_PATH);\n    appContext.addAllEnvironment(environment);\n    vargs.add(\"org.apache.hadoop.mapreduce.v2.app.MRAppMaster\");\n    vargs.add(String.valueOf(applicationId.getClusterTimestamp()));\n    vargs.add(String.valueOf(applicationId.getId()));\n    vargs.add(ApplicationConstants.AM_FAIL_COUNT_STRING);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stderr\");\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.info(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    appContext.addAllCommands(vargsFinal);\n    // TODO: RM should get this from RPC.\n    appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName());\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n    appContext.setApplicationId(applicationId);\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(YARN_AM_VMEM_MB, DEFAULT_YARN_AM_VMEM_MB));\n    LOG.info(\"AppMaster capability \u003d \" + capability);\n    appContext.setMasterCapability(capability);\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRConstants.JOB_CONF_FILE);\n    \n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    appContext.setResource(MRConstants.JOB_SUBMIT_DIR,\n        yarnUrlForJobSubmitDir);\n\n    appContext.setResourceTodo(MRConstants.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      appContext.setResourceTodo(MRConstants.JOB_JAR,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, MRConstants.JOB_JAR)));\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n    \n    // TODO gross hack\n    for (String s : new String[] { \"job.split\", \"job.splitmetainfo\",\n        MRConstants.APPLICATION_TOKENS_FILE }) {\n      appContext.setResourceTodo(\n          MRConstants.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext, new Path(jobSubmitDir, s)));\n    }\n\n    // TODO: Only if security is on.\n    List\u003cString\u003e fsTokens \u003d new ArrayList\u003cString\u003e();\n    for (Token\u003c? extends TokenIdentifier\u003e token : ts.getAllTokens()) {\n      fsTokens.add(token.encodeToUrlString());\n    }\n    \n    // TODO - Remove this!\n    appContext.addAllFsTokens(fsTokens);\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    appContext.setFsTokensTodo(ByteBuffer.wrap(dob.getData(), 0, dob.getLength()));\n\n    // Add queue information\n    appContext.setQueue(jobConf.get(JobContext.QUEUE_NAME, JobConf.DEFAULT_QUEUE_NAME));\n    \n    // Add job name\n    appContext.setApplicationName(jobConf.get(JobContext.JOB_NAME, \"N/A\"));\n    \n    // Add the command line\n    String javaHome \u003d \"$JAVA_HOME\";\n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n    vargs.add(javaHome + \"/bin/java\");\n    vargs.add(\"-Dhadoop.root.logger\u003d\"\n        + conf.get(ClientConstants.MR_APPMASTER_LOG_OPTS,\n            ClientConstants.DEFAULT_MR_APPMASTER_LOG_OPTS) + \",console\");\n    \n    vargs.add(conf.get(ClientConstants.MR_APPMASTER_COMMAND_OPTS,\n        ClientConstants.DEFAULT_MR_APPMASTER_COMMAND_OPTS));\n\n    // Add { job jar, MR app jar } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n//    appContext.environment \u003d new HashMap\u003cCharSequence, CharSequence\u003e();\n    MRApps.setInitialClasspath(environment);\n    MRApps.addToClassPath(environment, MRConstants.JOB_JAR);\n    MRApps.addToClassPath(environment,\n        MRConstants.YARN_MAPREDUCE_APP_JAR_PATH);\n    appContext.addAllEnvironment(environment);\n    vargs.add(\"org.apache.hadoop.mapreduce.v2.app.MRAppMaster\");\n    vargs.add(String.valueOf(applicationId.getClusterTimestamp()));\n    vargs.add(String.valueOf(applicationId.getId()));\n    vargs.add(ApplicationConstants.AM_FAIL_COUNT_STRING);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stderr\");\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.info(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    appContext.addAllCommands(vargsFinal);\n    // TODO: RM should get this from RPC.\n    appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName());\n    return appContext;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,106 @@\n+  private ApplicationSubmissionContext createApplicationSubmissionContext(\n+      Configuration jobConf,\n+      String jobSubmitDir, Credentials ts) throws IOException {\n+    ApplicationSubmissionContext appContext \u003d\n+        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n+    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n+    appContext.setApplicationId(applicationId);\n+    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n+    capability.setMemory(conf.getInt(YARN_AM_VMEM_MB, DEFAULT_YARN_AM_VMEM_MB));\n+    LOG.info(\"AppMaster capability \u003d \" + capability);\n+    appContext.setMasterCapability(capability);\n+\n+    Path jobConfPath \u003d new Path(jobSubmitDir, MRConstants.JOB_CONF_FILE);\n+    \n+    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n+        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n+            .resolvePath(\n+                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n+    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n+        + yarnUrlForJobSubmitDir);\n+\n+    appContext.setResource(MRConstants.JOB_SUBMIT_DIR,\n+        yarnUrlForJobSubmitDir);\n+\n+    appContext.setResourceTodo(MRConstants.JOB_CONF_FILE,\n+        createApplicationResource(defaultFileContext,\n+            jobConfPath));\n+    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n+      appContext.setResourceTodo(MRConstants.JOB_JAR,\n+          createApplicationResource(defaultFileContext,\n+              new Path(jobSubmitDir, MRConstants.JOB_JAR)));\n+    } else {\n+      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n+      // mapreduce jar itself which is already on the classpath.\n+      LOG.info(\"Job jar is not present. \"\n+          + \"Not adding any jar to the list of resources.\");\n+    }\n+    \n+    // TODO gross hack\n+    for (String s : new String[] { \"job.split\", \"job.splitmetainfo\",\n+        MRConstants.APPLICATION_TOKENS_FILE }) {\n+      appContext.setResourceTodo(\n+          MRConstants.JOB_SUBMIT_DIR + \"/\" + s,\n+          createApplicationResource(defaultFileContext, new Path(jobSubmitDir, s)));\n+    }\n+\n+    // TODO: Only if security is on.\n+    List\u003cString\u003e fsTokens \u003d new ArrayList\u003cString\u003e();\n+    for (Token\u003c? extends TokenIdentifier\u003e token : ts.getAllTokens()) {\n+      fsTokens.add(token.encodeToUrlString());\n+    }\n+    \n+    // TODO - Remove this!\n+    appContext.addAllFsTokens(fsTokens);\n+    DataOutputBuffer dob \u003d new DataOutputBuffer();\n+    ts.writeTokenStorageToStream(dob);\n+    appContext.setFsTokensTodo(ByteBuffer.wrap(dob.getData(), 0, dob.getLength()));\n+\n+    // Add queue information\n+    appContext.setQueue(jobConf.get(JobContext.QUEUE_NAME, JobConf.DEFAULT_QUEUE_NAME));\n+    \n+    // Add job name\n+    appContext.setApplicationName(jobConf.get(JobContext.JOB_NAME, \"N/A\"));\n+    \n+    // Add the command line\n+    String javaHome \u003d \"$JAVA_HOME\";\n+    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n+    vargs.add(javaHome + \"/bin/java\");\n+    vargs.add(\"-Dhadoop.root.logger\u003d\"\n+        + conf.get(ClientConstants.MR_APPMASTER_LOG_OPTS,\n+            ClientConstants.DEFAULT_MR_APPMASTER_LOG_OPTS) + \",console\");\n+    \n+    vargs.add(conf.get(ClientConstants.MR_APPMASTER_COMMAND_OPTS,\n+        ClientConstants.DEFAULT_MR_APPMASTER_COMMAND_OPTS));\n+\n+    // Add { job jar, MR app jar } to classpath.\n+    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n+//    appContext.environment \u003d new HashMap\u003cCharSequence, CharSequence\u003e();\n+    MRApps.setInitialClasspath(environment);\n+    MRApps.addToClassPath(environment, MRConstants.JOB_JAR);\n+    MRApps.addToClassPath(environment,\n+        MRConstants.YARN_MAPREDUCE_APP_JAR_PATH);\n+    appContext.addAllEnvironment(environment);\n+    vargs.add(\"org.apache.hadoop.mapreduce.v2.app.MRAppMaster\");\n+    vargs.add(String.valueOf(applicationId.getClusterTimestamp()));\n+    vargs.add(String.valueOf(applicationId.getId()));\n+    vargs.add(ApplicationConstants.AM_FAIL_COUNT_STRING);\n+    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stdout\");\n+    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stderr\");\n+\n+    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n+    // Final commmand\n+    StringBuilder mergedCommand \u003d new StringBuilder();\n+    for (CharSequence str : vargs) {\n+      mergedCommand.append(str).append(\" \");\n+    }\n+    vargsFinal.add(mergedCommand.toString());\n+\n+    LOG.info(\"Command to launch container for ApplicationMaster is : \"\n+        + mergedCommand);\n+\n+    appContext.addAllCommands(vargsFinal);\n+    // TODO: RM should get this from RPC.\n+    appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName());\n+    return appContext;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private ApplicationSubmissionContext createApplicationSubmissionContext(\n      Configuration jobConf,\n      String jobSubmitDir, Credentials ts) throws IOException {\n    ApplicationSubmissionContext appContext \u003d\n        recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\n    ApplicationId applicationId \u003d resMgrDelegate.getApplicationId();\n    appContext.setApplicationId(applicationId);\n    Resource capability \u003d recordFactory.newRecordInstance(Resource.class);\n    capability.setMemory(conf.getInt(YARN_AM_VMEM_MB, DEFAULT_YARN_AM_VMEM_MB));\n    LOG.info(\"AppMaster capability \u003d \" + capability);\n    appContext.setMasterCapability(capability);\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRConstants.JOB_CONF_FILE);\n    \n    URL yarnUrlForJobSubmitDir \u003d ConverterUtils\n        .getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem()\n            .resolvePath(\n                defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    appContext.setResource(MRConstants.JOB_SUBMIT_DIR,\n        yarnUrlForJobSubmitDir);\n\n    appContext.setResourceTodo(MRConstants.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      appContext.setResourceTodo(MRConstants.JOB_JAR,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, MRConstants.JOB_JAR)));\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n    \n    // TODO gross hack\n    for (String s : new String[] { \"job.split\", \"job.splitmetainfo\",\n        MRConstants.APPLICATION_TOKENS_FILE }) {\n      appContext.setResourceTodo(\n          MRConstants.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext, new Path(jobSubmitDir, s)));\n    }\n\n    // TODO: Only if security is on.\n    List\u003cString\u003e fsTokens \u003d new ArrayList\u003cString\u003e();\n    for (Token\u003c? extends TokenIdentifier\u003e token : ts.getAllTokens()) {\n      fsTokens.add(token.encodeToUrlString());\n    }\n    \n    // TODO - Remove this!\n    appContext.addAllFsTokens(fsTokens);\n    DataOutputBuffer dob \u003d new DataOutputBuffer();\n    ts.writeTokenStorageToStream(dob);\n    appContext.setFsTokensTodo(ByteBuffer.wrap(dob.getData(), 0, dob.getLength()));\n\n    // Add queue information\n    appContext.setQueue(jobConf.get(JobContext.QUEUE_NAME, JobConf.DEFAULT_QUEUE_NAME));\n    \n    // Add job name\n    appContext.setApplicationName(jobConf.get(JobContext.JOB_NAME, \"N/A\"));\n    \n    // Add the command line\n    String javaHome \u003d \"$JAVA_HOME\";\n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(8);\n    vargs.add(javaHome + \"/bin/java\");\n    vargs.add(\"-Dhadoop.root.logger\u003d\"\n        + conf.get(ClientConstants.MR_APPMASTER_LOG_OPTS,\n            ClientConstants.DEFAULT_MR_APPMASTER_LOG_OPTS) + \",console\");\n    \n    vargs.add(conf.get(ClientConstants.MR_APPMASTER_COMMAND_OPTS,\n        ClientConstants.DEFAULT_MR_APPMASTER_COMMAND_OPTS));\n\n    // Add { job jar, MR app jar } to classpath.\n    Map\u003cString, String\u003e environment \u003d new HashMap\u003cString, String\u003e();\n//    appContext.environment \u003d new HashMap\u003cCharSequence, CharSequence\u003e();\n    MRApps.setInitialClasspath(environment);\n    MRApps.addToClassPath(environment, MRConstants.JOB_JAR);\n    MRApps.addToClassPath(environment,\n        MRConstants.YARN_MAPREDUCE_APP_JAR_PATH);\n    appContext.addAllEnvironment(environment);\n    vargs.add(\"org.apache.hadoop.mapreduce.v2.app.MRAppMaster\");\n    vargs.add(String.valueOf(applicationId.getClusterTimestamp()));\n    vargs.add(String.valueOf(applicationId.getId()));\n    vargs.add(ApplicationConstants.AM_FAIL_COUNT_STRING);\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/stderr\");\n\n    Vector\u003cString\u003e vargsFinal \u003d new Vector\u003cString\u003e(8);\n    // Final commmand\n    StringBuilder mergedCommand \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      mergedCommand.append(str).append(\" \");\n    }\n    vargsFinal.add(mergedCommand.toString());\n\n    LOG.info(\"Command to launch container for ApplicationMaster is : \"\n        + mergedCommand);\n\n    appContext.addAllCommands(vargsFinal);\n    // TODO: RM should get this from RPC.\n    appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName());\n    return appContext;\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java"
    }
  }
}