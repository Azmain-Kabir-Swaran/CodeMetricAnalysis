{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RMContainerAllocator.java",
  "functionName": "getResources",
  "functionId": "getResources",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
  "functionStartLine": 781,
  "functionEndLine": 892,
  "numCommitsSeen": 83,
  "timeTaken": 13131,
  "changeHistory": [
    "08f40bcc7f4174857bb1fc7c8eb1108d5caaafb3",
    "7594d1de7bbc34cd2e64202095a5e1757154d7d0",
    "4fa1afdb883dab8786d2fb5c72a195dd2e87d711",
    "a1b8251bf7a7e9b776c4483fa01f7d453420eba4",
    "1ff6833bbacf5c4eeaff5e70553ac083a691bb21",
    "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5",
    "9e792da01419998c2ebfafd7161070150d85d3ac",
    "cf953b6258b036fc482456b4591cfb98054f48f2",
    "4aa9b3e75ca86917125e56e1b438668273a5d87f",
    "8dfec7a1979e8f70f8355c096874921d368342ef",
    "30da99cbaf36aeef38a858251ce8ffa5eb657b38",
    "4228de94028f1e10ca59ce23e963e488fe566909",
    "d336d136785ef1e49e0a110a1b9f0d1824829877",
    "0f3b6900be1a3b2e4624f31f84656f4a32dadce9",
    "376233cdd4a4ddbde5a92a0627f78338cb4c38b7",
    "eeb4acd955802e2a84ea94cecf2e2341b83d5efb",
    "875592220fb250ff9d0bba73c8ace9858fd369fd",
    "9ca394d54dd24e67867c845a58150f6b51761512",
    "1a06175440eec7994d6b63b0e5ac8b6532870fb3",
    "243bcd367ff3130d74676280233041f88aca62a5",
    "9fcfbf5f51f2557566694377f94a556226585d68",
    "978012b9b6b18985fd60ec5b26c38693a6e86f9a",
    "a83fb61ac07c0468cbc7a38526e92683883dd932",
    "fc75d3f3dc2733d6c783eb4d4f1c5c6ae680f08e",
    "1bd345d6e3855ab330963efd32e0fac102e61d1a",
    "0b73dde6ce865ff94b483558ff0701de9932e211",
    "b2f7a66e50bd09d26b2ad22e66ced73a6254de77",
    "aac5c149c7ca500b8eb810b7d4b561ff1e38ea02",
    "eff9fa1aad7e22d445a11e4ba732b4d49cdaca65",
    "28a2eb9d722bb8cbbeee87a1c43b4dc4ef4467ce",
    "94242c93857a06fb9c56ee571a47d6ca18f00f48",
    "55e94dc5ef4171c4e7b57942f22ead9a01dd9012",
    "e7543b944c2b35d0a1ca0a92efeca47ad414ac7a",
    "b304062f1ffee078ea9575dcee5583d43e33508c",
    "817ead65b99f465fc2dfa18072cf23cadf5f05d0",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "08f40bcc7f4174857bb1fc7c8eb1108d5caaafb3": "Ybodychange",
    "7594d1de7bbc34cd2e64202095a5e1757154d7d0": "Ybodychange",
    "4fa1afdb883dab8786d2fb5c72a195dd2e87d711": "Ybodychange",
    "a1b8251bf7a7e9b776c4483fa01f7d453420eba4": "Ybodychange",
    "1ff6833bbacf5c4eeaff5e70553ac083a691bb21": "Ybodychange",
    "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5": "Ybodychange",
    "9e792da01419998c2ebfafd7161070150d85d3ac": "Ybodychange",
    "cf953b6258b036fc482456b4591cfb98054f48f2": "Ybodychange",
    "4aa9b3e75ca86917125e56e1b438668273a5d87f": "Ybodychange",
    "8dfec7a1979e8f70f8355c096874921d368342ef": "Ybodychange",
    "30da99cbaf36aeef38a858251ce8ffa5eb657b38": "Ybodychange",
    "4228de94028f1e10ca59ce23e963e488fe566909": "Ybodychange",
    "d336d136785ef1e49e0a110a1b9f0d1824829877": "Ybodychange",
    "0f3b6900be1a3b2e4624f31f84656f4a32dadce9": "Ybodychange",
    "376233cdd4a4ddbde5a92a0627f78338cb4c38b7": "Ybodychange",
    "eeb4acd955802e2a84ea94cecf2e2341b83d5efb": "Ybodychange",
    "875592220fb250ff9d0bba73c8ace9858fd369fd": "Ybodychange",
    "9ca394d54dd24e67867c845a58150f6b51761512": "Ybodychange",
    "1a06175440eec7994d6b63b0e5ac8b6532870fb3": "Ybodychange",
    "243bcd367ff3130d74676280233041f88aca62a5": "Ybodychange",
    "9fcfbf5f51f2557566694377f94a556226585d68": "Ybodychange",
    "978012b9b6b18985fd60ec5b26c38693a6e86f9a": "Ybodychange",
    "a83fb61ac07c0468cbc7a38526e92683883dd932": "Ybodychange",
    "fc75d3f3dc2733d6c783eb4d4f1c5c6ae680f08e": "Ybodychange",
    "1bd345d6e3855ab330963efd32e0fac102e61d1a": "Ybodychange",
    "0b73dde6ce865ff94b483558ff0701de9932e211": "Ybodychange",
    "b2f7a66e50bd09d26b2ad22e66ced73a6254de77": "Ybodychange",
    "aac5c149c7ca500b8eb810b7d4b561ff1e38ea02": "Ybodychange",
    "eff9fa1aad7e22d445a11e4ba732b4d49cdaca65": "Ybodychange",
    "28a2eb9d722bb8cbbeee87a1c43b4dc4ef4467ce": "Ybodychange",
    "94242c93857a06fb9c56ee571a47d6ca18f00f48": "Ybodychange",
    "55e94dc5ef4171c4e7b57942f22ead9a01dd9012": "Ybodychange",
    "e7543b944c2b35d0a1ca0a92efeca47ad414ac7a": "Ybodychange",
    "b304062f1ffee078ea9575dcee5583d43e33508c": "Ybodychange",
    "817ead65b99f465fc2dfa18072cf23cadf5f05d0": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "08f40bcc7f4174857bb1fc7c8eb1108d5caaafb3": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6838. [ATSv2 Security] Add timeline delegation token received in allocate response to UGI. Contributed by Varun Saxena\n",
      "commitDate": "29/08/17 10:59 PM",
      "commitName": "08f40bcc7f4174857bb1fc7c8eb1108d5caaafb3",
      "commitAuthor": "Jian He",
      "commitDateOld": "29/08/17 10:59 PM",
      "commitNameOld": "7594d1de7bbc34cd2e64202095a5e1757154d7d0",
      "commitAuthorOld": "Rohith Sharma K S",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,117 +1,112 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     applyConcurrentTaskLimits();\n \n     // will be null the first time\n     Resource headRoom \u003d Resources.clone(getAvailableResources());\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (ApplicationAttemptNotFoundException e ) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n         JobEventType.JOB_AM_REBOOT));\n       throw new RMContainerAllocationException(\n         \"Resource Manager doesn\u0027t recognize AttemptId: \"\n             + this.getContext().getApplicationAttemptId(), e);\n     } catch (ApplicationMasterNotRegisteredException e) {\n       LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n           + \" hence resync and send outstanding requests.\");\n       // RM may have restarted, re-register with RM.\n       lastResponseID \u003d 0;\n       register();\n       addOutstandingRequestOnResync();\n       return null;\n     } catch (InvalidLabelResourceRequestException e) {\n       // If Invalid label exception is received means the requested label doesnt\n       // have access so killing job in this case.\n       String diagMsg \u003d \"Requested node-label-expression is invalid: \"\n           + StringUtils.stringifyException(e);\n       LOG.info(diagMsg);\n       JobId jobId \u003d this.getJob().getID();\n       eventHandler.handle(new JobDiagnosticsUpdateEvent(jobId, diagMsg));\n       eventHandler.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n       throw e;\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.JOB_AM_REBOOT));\n         throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     Resource newHeadRoom \u003d getAvailableResources();\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n \n     // Setting AMRMToken\n     if (response.getAMRMToken() !\u003d null) {\n       updateAMRMToken(response.getAMRMToken());\n     }\n \n-    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n+    List\u003cContainerStatus\u003e finishedContainers \u003d\n+        response.getCompletedContainersStatuses();\n \n     // propagate preemption requests\n     final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n     if (preemptReq !\u003d null) {\n       preemptionPolicy.preempt(\n           new PreemptionContext(assignedRequests), preemptReq);\n     }\n \n     if (newContainers.size() + finishedContainers.size() \u003e 0\n         || !headRoom.equals(newHeadRoom)) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n     handleJobPriorityChange(response);\n-    // handle receiving the timeline collector address for this app\n-    String collectorAddr \u003d null;\n-    if (response.getCollectorInfo() !\u003d null) {\n-      collectorAddr \u003d response.getCollectorInfo().getCollectorAddr();\n-    }\n-\n+    // Handle receiving the timeline collector address and token for this app.\n     MRAppMaster.RunningAppContext appContext \u003d\n         (MRAppMaster.RunningAppContext)this.getContext();\n-    if (collectorAddr !\u003d null \u0026\u0026 !collectorAddr.isEmpty()\n-        \u0026\u0026 appContext.getTimelineV2Client() !\u003d null) {\n-      appContext.getTimelineV2Client().setTimelineServiceAddress(collectorAddr);\n+    if (appContext.getTimelineV2Client() !\u003d null) {\n+      appContext.getTimelineV2Client().\n+          setTimelineCollectorInfo(response.getCollectorInfo());\n     }\n-\n     for (ContainerStatus cont : finishedContainers) {\n       processFinishedContainer(cont);\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    applyConcurrentTaskLimits();\n\n    // will be null the first time\n    Resource headRoom \u003d Resources.clone(getAvailableResources());\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (ApplicationAttemptNotFoundException e ) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n        JobEventType.JOB_AM_REBOOT));\n      throw new RMContainerAllocationException(\n        \"Resource Manager doesn\u0027t recognize AttemptId: \"\n            + this.getContext().getApplicationAttemptId(), e);\n    } catch (ApplicationMasterNotRegisteredException e) {\n      LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n          + \" hence resync and send outstanding requests.\");\n      // RM may have restarted, re-register with RM.\n      lastResponseID \u003d 0;\n      register();\n      addOutstandingRequestOnResync();\n      return null;\n    } catch (InvalidLabelResourceRequestException e) {\n      // If Invalid label exception is received means the requested label doesnt\n      // have access so killing job in this case.\n      String diagMsg \u003d \"Requested node-label-expression is invalid: \"\n          + StringUtils.stringifyException(e);\n      LOG.info(diagMsg);\n      JobId jobId \u003d this.getJob().getID();\n      eventHandler.handle(new JobDiagnosticsUpdateEvent(jobId, diagMsg));\n      eventHandler.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n      throw e;\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    Resource newHeadRoom \u003d getAvailableResources();\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() !\u003d null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List\u003cContainerStatus\u003e finishedContainers \u003d\n        response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0\n        || !headRoom.equals(newHeadRoom)) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n    handleJobPriorityChange(response);\n    // Handle receiving the timeline collector address and token for this app.\n    MRAppMaster.RunningAppContext appContext \u003d\n        (MRAppMaster.RunningAppContext)this.getContext();\n    if (appContext.getTimelineV2Client() !\u003d null) {\n      appContext.getTimelineV2Client().\n          setTimelineCollectorInfo(response.getCollectorInfo());\n    }\n    for (ContainerStatus cont : finishedContainers) {\n      processFinishedContainer(cont);\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "7594d1de7bbc34cd2e64202095a5e1757154d7d0": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6130. [ATSv2 Security] Generate a delegation token for AM when app collector is created and pass it to AM via NM and RM. Contributed by Varun Saxena.\n",
      "commitDate": "29/08/17 10:59 PM",
      "commitName": "7594d1de7bbc34cd2e64202095a5e1757154d7d0",
      "commitAuthor": "Rohith Sharma K S",
      "commitDateOld": "27/06/17 6:50 PM",
      "commitNameOld": "a5c0476a990ec1e7eb34ce2462a45aa52cc1350d",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 63.17,
      "commitsBetweenForRepo": 441,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,114 +1,117 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     applyConcurrentTaskLimits();\n \n     // will be null the first time\n     Resource headRoom \u003d Resources.clone(getAvailableResources());\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (ApplicationAttemptNotFoundException e ) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n         JobEventType.JOB_AM_REBOOT));\n       throw new RMContainerAllocationException(\n         \"Resource Manager doesn\u0027t recognize AttemptId: \"\n             + this.getContext().getApplicationAttemptId(), e);\n     } catch (ApplicationMasterNotRegisteredException e) {\n       LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n           + \" hence resync and send outstanding requests.\");\n       // RM may have restarted, re-register with RM.\n       lastResponseID \u003d 0;\n       register();\n       addOutstandingRequestOnResync();\n       return null;\n     } catch (InvalidLabelResourceRequestException e) {\n       // If Invalid label exception is received means the requested label doesnt\n       // have access so killing job in this case.\n       String diagMsg \u003d \"Requested node-label-expression is invalid: \"\n           + StringUtils.stringifyException(e);\n       LOG.info(diagMsg);\n       JobId jobId \u003d this.getJob().getID();\n       eventHandler.handle(new JobDiagnosticsUpdateEvent(jobId, diagMsg));\n       eventHandler.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n       throw e;\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.JOB_AM_REBOOT));\n         throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     Resource newHeadRoom \u003d getAvailableResources();\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n \n     // Setting AMRMToken\n     if (response.getAMRMToken() !\u003d null) {\n       updateAMRMToken(response.getAMRMToken());\n     }\n \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n \n     // propagate preemption requests\n     final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n     if (preemptReq !\u003d null) {\n       preemptionPolicy.preempt(\n           new PreemptionContext(assignedRequests), preemptReq);\n     }\n \n     if (newContainers.size() + finishedContainers.size() \u003e 0\n         || !headRoom.equals(newHeadRoom)) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n     handleJobPriorityChange(response);\n     // handle receiving the timeline collector address for this app\n-    String collectorAddr \u003d response.getCollectorAddr();\n+    String collectorAddr \u003d null;\n+    if (response.getCollectorInfo() !\u003d null) {\n+      collectorAddr \u003d response.getCollectorInfo().getCollectorAddr();\n+    }\n+\n     MRAppMaster.RunningAppContext appContext \u003d\n         (MRAppMaster.RunningAppContext)this.getContext();\n     if (collectorAddr !\u003d null \u0026\u0026 !collectorAddr.isEmpty()\n         \u0026\u0026 appContext.getTimelineV2Client() !\u003d null) {\n-      appContext.getTimelineV2Client().setTimelineServiceAddress(\n-          response.getCollectorAddr());\n+      appContext.getTimelineV2Client().setTimelineServiceAddress(collectorAddr);\n     }\n \n     for (ContainerStatus cont : finishedContainers) {\n       processFinishedContainer(cont);\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    applyConcurrentTaskLimits();\n\n    // will be null the first time\n    Resource headRoom \u003d Resources.clone(getAvailableResources());\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (ApplicationAttemptNotFoundException e ) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n        JobEventType.JOB_AM_REBOOT));\n      throw new RMContainerAllocationException(\n        \"Resource Manager doesn\u0027t recognize AttemptId: \"\n            + this.getContext().getApplicationAttemptId(), e);\n    } catch (ApplicationMasterNotRegisteredException e) {\n      LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n          + \" hence resync and send outstanding requests.\");\n      // RM may have restarted, re-register with RM.\n      lastResponseID \u003d 0;\n      register();\n      addOutstandingRequestOnResync();\n      return null;\n    } catch (InvalidLabelResourceRequestException e) {\n      // If Invalid label exception is received means the requested label doesnt\n      // have access so killing job in this case.\n      String diagMsg \u003d \"Requested node-label-expression is invalid: \"\n          + StringUtils.stringifyException(e);\n      LOG.info(diagMsg);\n      JobId jobId \u003d this.getJob().getID();\n      eventHandler.handle(new JobDiagnosticsUpdateEvent(jobId, diagMsg));\n      eventHandler.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n      throw e;\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    Resource newHeadRoom \u003d getAvailableResources();\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() !\u003d null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0\n        || !headRoom.equals(newHeadRoom)) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n    handleJobPriorityChange(response);\n    // handle receiving the timeline collector address for this app\n    String collectorAddr \u003d null;\n    if (response.getCollectorInfo() !\u003d null) {\n      collectorAddr \u003d response.getCollectorInfo().getCollectorAddr();\n    }\n\n    MRAppMaster.RunningAppContext appContext \u003d\n        (MRAppMaster.RunningAppContext)this.getContext();\n    if (collectorAddr !\u003d null \u0026\u0026 !collectorAddr.isEmpty()\n        \u0026\u0026 appContext.getTimelineV2Client() !\u003d null) {\n      appContext.getTimelineV2Client().setTimelineServiceAddress(collectorAddr);\n    }\n\n    for (ContainerStatus cont : finishedContainers) {\n      processFinishedContainer(cont);\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "4fa1afdb883dab8786d2fb5c72a195dd2e87d711": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4675. Reorganize TimelineClient and TimelineClientImpl into separate classes for ATSv1.x and ATSv2. Contributed by Naganarasimha G R.\n",
      "commitDate": "16/02/17 11:41 AM",
      "commitName": "4fa1afdb883dab8786d2fb5c72a195dd2e87d711",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "08/01/17 9:04 AM",
      "commitNameOld": "85826f6ca5a6d06b711a6805f7a1a6788852db05",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 39.11,
      "commitsBetweenForRepo": 199,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,114 +1,114 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     applyConcurrentTaskLimits();\n \n     // will be null the first time\n     Resource headRoom \u003d Resources.clone(getAvailableResources());\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (ApplicationAttemptNotFoundException e ) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n         JobEventType.JOB_AM_REBOOT));\n       throw new RMContainerAllocationException(\n         \"Resource Manager doesn\u0027t recognize AttemptId: \"\n             + this.getContext().getApplicationAttemptId(), e);\n     } catch (ApplicationMasterNotRegisteredException e) {\n       LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n           + \" hence resync and send outstanding requests.\");\n       // RM may have restarted, re-register with RM.\n       lastResponseID \u003d 0;\n       register();\n       addOutstandingRequestOnResync();\n       return null;\n     } catch (InvalidLabelResourceRequestException e) {\n       // If Invalid label exception is received means the requested label doesnt\n       // have access so killing job in this case.\n       String diagMsg \u003d \"Requested node-label-expression is invalid: \"\n           + StringUtils.stringifyException(e);\n       LOG.info(diagMsg);\n       JobId jobId \u003d this.getJob().getID();\n       eventHandler.handle(new JobDiagnosticsUpdateEvent(jobId, diagMsg));\n       eventHandler.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n       throw e;\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.JOB_AM_REBOOT));\n         throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     Resource newHeadRoom \u003d getAvailableResources();\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n \n     // Setting AMRMToken\n     if (response.getAMRMToken() !\u003d null) {\n       updateAMRMToken(response.getAMRMToken());\n     }\n \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n \n     // propagate preemption requests\n     final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n     if (preemptReq !\u003d null) {\n       preemptionPolicy.preempt(\n           new PreemptionContext(assignedRequests), preemptReq);\n     }\n \n     if (newContainers.size() + finishedContainers.size() \u003e 0\n         || !headRoom.equals(newHeadRoom)) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n     handleJobPriorityChange(response);\n     // handle receiving the timeline collector address for this app\n     String collectorAddr \u003d response.getCollectorAddr();\n     MRAppMaster.RunningAppContext appContext \u003d\n         (MRAppMaster.RunningAppContext)this.getContext();\n     if (collectorAddr !\u003d null \u0026\u0026 !collectorAddr.isEmpty()\n-        \u0026\u0026 appContext.getTimelineClient() !\u003d null) {\n-      appContext.getTimelineClient().setTimelineServiceAddress(\n+        \u0026\u0026 appContext.getTimelineV2Client() !\u003d null) {\n+      appContext.getTimelineV2Client().setTimelineServiceAddress(\n           response.getCollectorAddr());\n     }\n \n     for (ContainerStatus cont : finishedContainers) {\n       processFinishedContainer(cont);\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    applyConcurrentTaskLimits();\n\n    // will be null the first time\n    Resource headRoom \u003d Resources.clone(getAvailableResources());\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (ApplicationAttemptNotFoundException e ) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n        JobEventType.JOB_AM_REBOOT));\n      throw new RMContainerAllocationException(\n        \"Resource Manager doesn\u0027t recognize AttemptId: \"\n            + this.getContext().getApplicationAttemptId(), e);\n    } catch (ApplicationMasterNotRegisteredException e) {\n      LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n          + \" hence resync and send outstanding requests.\");\n      // RM may have restarted, re-register with RM.\n      lastResponseID \u003d 0;\n      register();\n      addOutstandingRequestOnResync();\n      return null;\n    } catch (InvalidLabelResourceRequestException e) {\n      // If Invalid label exception is received means the requested label doesnt\n      // have access so killing job in this case.\n      String diagMsg \u003d \"Requested node-label-expression is invalid: \"\n          + StringUtils.stringifyException(e);\n      LOG.info(diagMsg);\n      JobId jobId \u003d this.getJob().getID();\n      eventHandler.handle(new JobDiagnosticsUpdateEvent(jobId, diagMsg));\n      eventHandler.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n      throw e;\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    Resource newHeadRoom \u003d getAvailableResources();\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() !\u003d null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0\n        || !headRoom.equals(newHeadRoom)) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n    handleJobPriorityChange(response);\n    // handle receiving the timeline collector address for this app\n    String collectorAddr \u003d response.getCollectorAddr();\n    MRAppMaster.RunningAppContext appContext \u003d\n        (MRAppMaster.RunningAppContext)this.getContext();\n    if (collectorAddr !\u003d null \u0026\u0026 !collectorAddr.isEmpty()\n        \u0026\u0026 appContext.getTimelineV2Client() !\u003d null) {\n      appContext.getTimelineV2Client().setTimelineServiceAddress(\n          response.getCollectorAddr());\n    }\n\n    for (ContainerStatus cont : finishedContainers) {\n      processFinishedContainer(cont);\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "a1b8251bf7a7e9b776c4483fa01f7d453420eba4": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6771. RMContainerAllocator sends container diagnostics event after corresponding completion event. Contributed by Haibo Chen\n",
      "commitDate": "29/09/16 8:27 AM",
      "commitName": "a1b8251bf7a7e9b776c4483fa01f7d453420eba4",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "11/07/16 10:36 PM",
      "commitNameOld": "819224dcf9c683aa52f58633ac8e13663f1916d8",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 79.41,
      "commitsBetweenForRepo": 512,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,132 +1,114 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     applyConcurrentTaskLimits();\n \n     // will be null the first time\n     Resource headRoom \u003d Resources.clone(getAvailableResources());\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (ApplicationAttemptNotFoundException e ) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n         JobEventType.JOB_AM_REBOOT));\n       throw new RMContainerAllocationException(\n         \"Resource Manager doesn\u0027t recognize AttemptId: \"\n             + this.getContext().getApplicationAttemptId(), e);\n     } catch (ApplicationMasterNotRegisteredException e) {\n       LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n           + \" hence resync and send outstanding requests.\");\n       // RM may have restarted, re-register with RM.\n       lastResponseID \u003d 0;\n       register();\n       addOutstandingRequestOnResync();\n       return null;\n     } catch (InvalidLabelResourceRequestException e) {\n       // If Invalid label exception is received means the requested label doesnt\n       // have access so killing job in this case.\n       String diagMsg \u003d \"Requested node-label-expression is invalid: \"\n           + StringUtils.stringifyException(e);\n       LOG.info(diagMsg);\n       JobId jobId \u003d this.getJob().getID();\n       eventHandler.handle(new JobDiagnosticsUpdateEvent(jobId, diagMsg));\n       eventHandler.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n       throw e;\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.JOB_AM_REBOOT));\n         throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     Resource newHeadRoom \u003d getAvailableResources();\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n \n     // Setting AMRMToken\n     if (response.getAMRMToken() !\u003d null) {\n       updateAMRMToken(response.getAMRMToken());\n     }\n \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n \n     // propagate preemption requests\n     final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n     if (preemptReq !\u003d null) {\n       preemptionPolicy.preempt(\n           new PreemptionContext(assignedRequests), preemptReq);\n     }\n \n     if (newContainers.size() + finishedContainers.size() \u003e 0\n         || !headRoom.equals(newHeadRoom)) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n     handleJobPriorityChange(response);\n     // handle receiving the timeline collector address for this app\n     String collectorAddr \u003d response.getCollectorAddr();\n     MRAppMaster.RunningAppContext appContext \u003d\n         (MRAppMaster.RunningAppContext)this.getContext();\n     if (collectorAddr !\u003d null \u0026\u0026 !collectorAddr.isEmpty()\n         \u0026\u0026 appContext.getTimelineClient() !\u003d null) {\n       appContext.getTimelineClient().setTimelineServiceAddress(\n           response.getCollectorAddr());\n     }\n \n     for (ContainerStatus cont : finishedContainers) {\n-      LOG.info(\"Received completed container \" + cont.getContainerId());\n-      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n-      if (attemptID \u003d\u003d null) {\n-        LOG.error(\"Container complete event for unknown container id \"\n-            + cont.getContainerId());\n-      } else {\n-        pendingRelease.remove(cont.getContainerId());\n-        assignedRequests.remove(attemptID);\n-        \n-        // send the container completed event to Task attempt\n-        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n-        \n-        // Send the diagnostics\n-        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n-        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n-            diagnostics));\n-\n-        preemptionPolicy.handleCompletedContainer(attemptID);\n-      }\n+      processFinishedContainer(cont);\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    applyConcurrentTaskLimits();\n\n    // will be null the first time\n    Resource headRoom \u003d Resources.clone(getAvailableResources());\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (ApplicationAttemptNotFoundException e ) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n        JobEventType.JOB_AM_REBOOT));\n      throw new RMContainerAllocationException(\n        \"Resource Manager doesn\u0027t recognize AttemptId: \"\n            + this.getContext().getApplicationAttemptId(), e);\n    } catch (ApplicationMasterNotRegisteredException e) {\n      LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n          + \" hence resync and send outstanding requests.\");\n      // RM may have restarted, re-register with RM.\n      lastResponseID \u003d 0;\n      register();\n      addOutstandingRequestOnResync();\n      return null;\n    } catch (InvalidLabelResourceRequestException e) {\n      // If Invalid label exception is received means the requested label doesnt\n      // have access so killing job in this case.\n      String diagMsg \u003d \"Requested node-label-expression is invalid: \"\n          + StringUtils.stringifyException(e);\n      LOG.info(diagMsg);\n      JobId jobId \u003d this.getJob().getID();\n      eventHandler.handle(new JobDiagnosticsUpdateEvent(jobId, diagMsg));\n      eventHandler.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n      throw e;\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    Resource newHeadRoom \u003d getAvailableResources();\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() !\u003d null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0\n        || !headRoom.equals(newHeadRoom)) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n    handleJobPriorityChange(response);\n    // handle receiving the timeline collector address for this app\n    String collectorAddr \u003d response.getCollectorAddr();\n    MRAppMaster.RunningAppContext appContext \u003d\n        (MRAppMaster.RunningAppContext)this.getContext();\n    if (collectorAddr !\u003d null \u0026\u0026 !collectorAddr.isEmpty()\n        \u0026\u0026 appContext.getTimelineClient() !\u003d null) {\n      appContext.getTimelineClient().setTimelineServiceAddress(\n          response.getCollectorAddr());\n    }\n\n    for (ContainerStatus cont : finishedContainers) {\n      processFinishedContainer(cont);\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "1ff6833bbacf5c4eeaff5e70553ac083a691bb21": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5243. fix several rebase and other miscellaneous issues before merge. (Sangjin Lee via Varun Saxena)\n",
      "commitDate": "10/07/16 8:46 AM",
      "commitName": "1ff6833bbacf5c4eeaff5e70553ac083a691bb21",
      "commitAuthor": "Varun Saxena",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 98,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,131 +1,132 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     applyConcurrentTaskLimits();\n \n     // will be null the first time\n     Resource headRoom \u003d Resources.clone(getAvailableResources());\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (ApplicationAttemptNotFoundException e ) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n         JobEventType.JOB_AM_REBOOT));\n       throw new RMContainerAllocationException(\n         \"Resource Manager doesn\u0027t recognize AttemptId: \"\n             + this.getContext().getApplicationAttemptId(), e);\n     } catch (ApplicationMasterNotRegisteredException e) {\n       LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n           + \" hence resync and send outstanding requests.\");\n       // RM may have restarted, re-register with RM.\n       lastResponseID \u003d 0;\n       register();\n       addOutstandingRequestOnResync();\n       return null;\n     } catch (InvalidLabelResourceRequestException e) {\n       // If Invalid label exception is received means the requested label doesnt\n       // have access so killing job in this case.\n       String diagMsg \u003d \"Requested node-label-expression is invalid: \"\n           + StringUtils.stringifyException(e);\n       LOG.info(diagMsg);\n       JobId jobId \u003d this.getJob().getID();\n       eventHandler.handle(new JobDiagnosticsUpdateEvent(jobId, diagMsg));\n       eventHandler.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n       throw e;\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.JOB_AM_REBOOT));\n         throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     Resource newHeadRoom \u003d getAvailableResources();\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n \n     // Setting AMRMToken\n     if (response.getAMRMToken() !\u003d null) {\n       updateAMRMToken(response.getAMRMToken());\n     }\n \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n \n     // propagate preemption requests\n     final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n     if (preemptReq !\u003d null) {\n       preemptionPolicy.preempt(\n           new PreemptionContext(assignedRequests), preemptReq);\n     }\n \n     if (newContainers.size() + finishedContainers.size() \u003e 0\n         || !headRoom.equals(newHeadRoom)) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n     handleJobPriorityChange(response);\n+    // handle receiving the timeline collector address for this app\n     String collectorAddr \u003d response.getCollectorAddr();\n-    MRAppMaster.RunningAppContext appContext \u003d \n+    MRAppMaster.RunningAppContext appContext \u003d\n         (MRAppMaster.RunningAppContext)this.getContext();\n     if (collectorAddr !\u003d null \u0026\u0026 !collectorAddr.isEmpty()\n         \u0026\u0026 appContext.getTimelineClient() !\u003d null) {\n       appContext.getTimelineClient().setTimelineServiceAddress(\n         response.getCollectorAddr());\n     }\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         pendingRelease.remove(cont.getContainerId());\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n \n         preemptionPolicy.handleCompletedContainer(attemptID);\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    applyConcurrentTaskLimits();\n\n    // will be null the first time\n    Resource headRoom \u003d Resources.clone(getAvailableResources());\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (ApplicationAttemptNotFoundException e ) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n        JobEventType.JOB_AM_REBOOT));\n      throw new RMContainerAllocationException(\n        \"Resource Manager doesn\u0027t recognize AttemptId: \"\n            + this.getContext().getApplicationAttemptId(), e);\n    } catch (ApplicationMasterNotRegisteredException e) {\n      LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n          + \" hence resync and send outstanding requests.\");\n      // RM may have restarted, re-register with RM.\n      lastResponseID \u003d 0;\n      register();\n      addOutstandingRequestOnResync();\n      return null;\n    } catch (InvalidLabelResourceRequestException e) {\n      // If Invalid label exception is received means the requested label doesnt\n      // have access so killing job in this case.\n      String diagMsg \u003d \"Requested node-label-expression is invalid: \"\n          + StringUtils.stringifyException(e);\n      LOG.info(diagMsg);\n      JobId jobId \u003d this.getJob().getID();\n      eventHandler.handle(new JobDiagnosticsUpdateEvent(jobId, diagMsg));\n      eventHandler.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n      throw e;\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    Resource newHeadRoom \u003d getAvailableResources();\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() !\u003d null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0\n        || !headRoom.equals(newHeadRoom)) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n    handleJobPriorityChange(response);\n    // handle receiving the timeline collector address for this app\n    String collectorAddr \u003d response.getCollectorAddr();\n    MRAppMaster.RunningAppContext appContext \u003d\n        (MRAppMaster.RunningAppContext)this.getContext();\n    if (collectorAddr !\u003d null \u0026\u0026 !collectorAddr.isEmpty()\n        \u0026\u0026 appContext.getTimelineClient() !\u003d null) {\n      appContext.getTimelineClient().setTimelineServiceAddress(\n        response.getCollectorAddr());\n    }\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        pendingRelease.remove(cont.getContainerId());\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n\n        preemptionPolicy.handleCompletedContainer(attemptID);\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6327. Made MR AM use timeline service v2 API to write history events and counters. Contributed by Junping Du.\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "29/05/16 8:54 AM",
      "commitNameOld": "42f90ab885d9693fcc1e52f9637f7de4111110ae",
      "commitAuthorOld": "Varun Vasudev",
      "daysBetweenCommits": 41.99,
      "commitsBetweenForRepo": 290,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,123 +1,131 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     applyConcurrentTaskLimits();\n \n     // will be null the first time\n     Resource headRoom \u003d Resources.clone(getAvailableResources());\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (ApplicationAttemptNotFoundException e ) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n         JobEventType.JOB_AM_REBOOT));\n       throw new RMContainerAllocationException(\n         \"Resource Manager doesn\u0027t recognize AttemptId: \"\n             + this.getContext().getApplicationAttemptId(), e);\n     } catch (ApplicationMasterNotRegisteredException e) {\n       LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n           + \" hence resync and send outstanding requests.\");\n       // RM may have restarted, re-register with RM.\n       lastResponseID \u003d 0;\n       register();\n       addOutstandingRequestOnResync();\n       return null;\n     } catch (InvalidLabelResourceRequestException e) {\n       // If Invalid label exception is received means the requested label doesnt\n       // have access so killing job in this case.\n       String diagMsg \u003d \"Requested node-label-expression is invalid: \"\n           + StringUtils.stringifyException(e);\n       LOG.info(diagMsg);\n       JobId jobId \u003d this.getJob().getID();\n       eventHandler.handle(new JobDiagnosticsUpdateEvent(jobId, diagMsg));\n       eventHandler.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n       throw e;\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.JOB_AM_REBOOT));\n         throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     Resource newHeadRoom \u003d getAvailableResources();\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n \n     // Setting AMRMToken\n     if (response.getAMRMToken() !\u003d null) {\n       updateAMRMToken(response.getAMRMToken());\n     }\n \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n \n     // propagate preemption requests\n     final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n     if (preemptReq !\u003d null) {\n       preemptionPolicy.preempt(\n           new PreemptionContext(assignedRequests), preemptReq);\n     }\n \n     if (newContainers.size() + finishedContainers.size() \u003e 0\n         || !headRoom.equals(newHeadRoom)) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n     handleJobPriorityChange(response);\n+    String collectorAddr \u003d response.getCollectorAddr();\n+    MRAppMaster.RunningAppContext appContext \u003d \n+        (MRAppMaster.RunningAppContext)this.getContext();\n+    if (collectorAddr !\u003d null \u0026\u0026 !collectorAddr.isEmpty()\n+        \u0026\u0026 appContext.getTimelineClient() !\u003d null) {\n+      appContext.getTimelineClient().setTimelineServiceAddress(\n+        response.getCollectorAddr());\n+    }\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         pendingRelease.remove(cont.getContainerId());\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n \n         preemptionPolicy.handleCompletedContainer(attemptID);\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    applyConcurrentTaskLimits();\n\n    // will be null the first time\n    Resource headRoom \u003d Resources.clone(getAvailableResources());\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (ApplicationAttemptNotFoundException e ) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n        JobEventType.JOB_AM_REBOOT));\n      throw new RMContainerAllocationException(\n        \"Resource Manager doesn\u0027t recognize AttemptId: \"\n            + this.getContext().getApplicationAttemptId(), e);\n    } catch (ApplicationMasterNotRegisteredException e) {\n      LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n          + \" hence resync and send outstanding requests.\");\n      // RM may have restarted, re-register with RM.\n      lastResponseID \u003d 0;\n      register();\n      addOutstandingRequestOnResync();\n      return null;\n    } catch (InvalidLabelResourceRequestException e) {\n      // If Invalid label exception is received means the requested label doesnt\n      // have access so killing job in this case.\n      String diagMsg \u003d \"Requested node-label-expression is invalid: \"\n          + StringUtils.stringifyException(e);\n      LOG.info(diagMsg);\n      JobId jobId \u003d this.getJob().getID();\n      eventHandler.handle(new JobDiagnosticsUpdateEvent(jobId, diagMsg));\n      eventHandler.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n      throw e;\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    Resource newHeadRoom \u003d getAvailableResources();\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() !\u003d null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0\n        || !headRoom.equals(newHeadRoom)) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n    handleJobPriorityChange(response);\n    String collectorAddr \u003d response.getCollectorAddr();\n    MRAppMaster.RunningAppContext appContext \u003d \n        (MRAppMaster.RunningAppContext)this.getContext();\n    if (collectorAddr !\u003d null \u0026\u0026 !collectorAddr.isEmpty()\n        \u0026\u0026 appContext.getTimelineClient() !\u003d null) {\n      appContext.getTimelineClient().setTimelineServiceAddress(\n        response.getCollectorAddr());\n    }\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        pendingRelease.remove(cont.getContainerId());\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n\n        preemptionPolicy.handleCompletedContainer(attemptID);\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "9e792da01419998c2ebfafd7161070150d85d3ac": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4582. Label-related invalid resource request exception should be able to properly handled by application. (Bibin A Chundatt via wangda)\n",
      "commitDate": "11/01/16 8:53 PM",
      "commitName": "9e792da01419998c2ebfafd7161070150d85d3ac",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "29/10/15 11:05 AM",
      "commitNameOld": "cf953b6258b036fc482456b4591cfb98054f48f2",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 74.45,
      "commitsBetweenForRepo": 443,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,113 +1,123 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     applyConcurrentTaskLimits();\n \n     // will be null the first time\n     Resource headRoom \u003d Resources.clone(getAvailableResources());\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (ApplicationAttemptNotFoundException e ) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n         JobEventType.JOB_AM_REBOOT));\n       throw new RMContainerAllocationException(\n         \"Resource Manager doesn\u0027t recognize AttemptId: \"\n             + this.getContext().getApplicationAttemptId(), e);\n     } catch (ApplicationMasterNotRegisteredException e) {\n       LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n           + \" hence resync and send outstanding requests.\");\n       // RM may have restarted, re-register with RM.\n       lastResponseID \u003d 0;\n       register();\n       addOutstandingRequestOnResync();\n       return null;\n+    } catch (InvalidLabelResourceRequestException e) {\n+      // If Invalid label exception is received means the requested label doesnt\n+      // have access so killing job in this case.\n+      String diagMsg \u003d \"Requested node-label-expression is invalid: \"\n+          + StringUtils.stringifyException(e);\n+      LOG.info(diagMsg);\n+      JobId jobId \u003d this.getJob().getID();\n+      eventHandler.handle(new JobDiagnosticsUpdateEvent(jobId, diagMsg));\n+      eventHandler.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n+      throw e;\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.JOB_AM_REBOOT));\n         throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     Resource newHeadRoom \u003d getAvailableResources();\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n \n     // Setting AMRMToken\n     if (response.getAMRMToken() !\u003d null) {\n       updateAMRMToken(response.getAMRMToken());\n     }\n \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n \n     // propagate preemption requests\n     final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n     if (preemptReq !\u003d null) {\n       preemptionPolicy.preempt(\n           new PreemptionContext(assignedRequests), preemptReq);\n     }\n \n     if (newContainers.size() + finishedContainers.size() \u003e 0\n         || !headRoom.equals(newHeadRoom)) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n     handleJobPriorityChange(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         pendingRelease.remove(cont.getContainerId());\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n \n         preemptionPolicy.handleCompletedContainer(attemptID);\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    applyConcurrentTaskLimits();\n\n    // will be null the first time\n    Resource headRoom \u003d Resources.clone(getAvailableResources());\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (ApplicationAttemptNotFoundException e ) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n        JobEventType.JOB_AM_REBOOT));\n      throw new RMContainerAllocationException(\n        \"Resource Manager doesn\u0027t recognize AttemptId: \"\n            + this.getContext().getApplicationAttemptId(), e);\n    } catch (ApplicationMasterNotRegisteredException e) {\n      LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n          + \" hence resync and send outstanding requests.\");\n      // RM may have restarted, re-register with RM.\n      lastResponseID \u003d 0;\n      register();\n      addOutstandingRequestOnResync();\n      return null;\n    } catch (InvalidLabelResourceRequestException e) {\n      // If Invalid label exception is received means the requested label doesnt\n      // have access so killing job in this case.\n      String diagMsg \u003d \"Requested node-label-expression is invalid: \"\n          + StringUtils.stringifyException(e);\n      LOG.info(diagMsg);\n      JobId jobId \u003d this.getJob().getID();\n      eventHandler.handle(new JobDiagnosticsUpdateEvent(jobId, diagMsg));\n      eventHandler.handle(new JobEvent(jobId, JobEventType.JOB_KILL));\n      throw e;\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    Resource newHeadRoom \u003d getAvailableResources();\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() !\u003d null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0\n        || !headRoom.equals(newHeadRoom)) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n    handleJobPriorityChange(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        pendingRelease.remove(cont.getContainerId());\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n\n        preemptionPolicy.handleCompletedContainer(attemptID);\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "cf953b6258b036fc482456b4591cfb98054f48f2": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6515. Update Application priority in AM side from AM-RM heartbeat. Contributed by Sunil G\n",
      "commitDate": "29/10/15 11:05 AM",
      "commitName": "cf953b6258b036fc482456b4591cfb98054f48f2",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "09/10/15 7:37 AM",
      "commitNameOld": "4aa9b3e75ca86917125e56e1b438668273a5d87f",
      "commitAuthorOld": "Karthik Kambatla",
      "daysBetweenCommits": 20.14,
      "commitsBetweenForRepo": 191,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,112 +1,113 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     applyConcurrentTaskLimits();\n \n     // will be null the first time\n     Resource headRoom \u003d Resources.clone(getAvailableResources());\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (ApplicationAttemptNotFoundException e ) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n         JobEventType.JOB_AM_REBOOT));\n       throw new RMContainerAllocationException(\n         \"Resource Manager doesn\u0027t recognize AttemptId: \"\n             + this.getContext().getApplicationAttemptId(), e);\n     } catch (ApplicationMasterNotRegisteredException e) {\n       LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n           + \" hence resync and send outstanding requests.\");\n       // RM may have restarted, re-register with RM.\n       lastResponseID \u003d 0;\n       register();\n       addOutstandingRequestOnResync();\n       return null;\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.JOB_AM_REBOOT));\n         throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     Resource newHeadRoom \u003d getAvailableResources();\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n \n     // Setting AMRMToken\n     if (response.getAMRMToken() !\u003d null) {\n       updateAMRMToken(response.getAMRMToken());\n     }\n \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n \n     // propagate preemption requests\n     final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n     if (preemptReq !\u003d null) {\n       preemptionPolicy.preempt(\n           new PreemptionContext(assignedRequests), preemptReq);\n     }\n \n     if (newContainers.size() + finishedContainers.size() \u003e 0\n         || !headRoom.equals(newHeadRoom)) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n+    handleJobPriorityChange(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         pendingRelease.remove(cont.getContainerId());\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n \n         preemptionPolicy.handleCompletedContainer(attemptID);\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    applyConcurrentTaskLimits();\n\n    // will be null the first time\n    Resource headRoom \u003d Resources.clone(getAvailableResources());\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (ApplicationAttemptNotFoundException e ) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n        JobEventType.JOB_AM_REBOOT));\n      throw new RMContainerAllocationException(\n        \"Resource Manager doesn\u0027t recognize AttemptId: \"\n            + this.getContext().getApplicationAttemptId(), e);\n    } catch (ApplicationMasterNotRegisteredException e) {\n      LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n          + \" hence resync and send outstanding requests.\");\n      // RM may have restarted, re-register with RM.\n      lastResponseID \u003d 0;\n      register();\n      addOutstandingRequestOnResync();\n      return null;\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    Resource newHeadRoom \u003d getAvailableResources();\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() !\u003d null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0\n        || !headRoom.equals(newHeadRoom)) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n    handleJobPriorityChange(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        pendingRelease.remove(cont.getContainerId());\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n\n        preemptionPolicy.handleCompletedContainer(attemptID);\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "4aa9b3e75ca86917125e56e1b438668273a5d87f": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6302. Incorrect headroom can lead to a deadlock between map and reduce allocations. (kasha)\n",
      "commitDate": "09/10/15 7:37 AM",
      "commitName": "4aa9b3e75ca86917125e56e1b438668273a5d87f",
      "commitAuthor": "Karthik Kambatla",
      "commitDateOld": "21/09/15 8:54 PM",
      "commitNameOld": "dfd807afab0fae3839c9cc5d552aa0304444f956",
      "commitAuthorOld": "Tsuyoshi Ozawa",
      "daysBetweenCommits": 17.45,
      "commitsBetweenForRepo": 132,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,116 +1,112 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     applyConcurrentTaskLimits();\n \n     // will be null the first time\n-    Resource headRoom \u003d\n-        getAvailableResources() \u003d\u003d null ? Resources.none() :\n-            Resources.clone(getAvailableResources());\n+    Resource headRoom \u003d Resources.clone(getAvailableResources());\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (ApplicationAttemptNotFoundException e ) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n         JobEventType.JOB_AM_REBOOT));\n       throw new RMContainerAllocationException(\n         \"Resource Manager doesn\u0027t recognize AttemptId: \"\n             + this.getContext().getApplicationAttemptId(), e);\n     } catch (ApplicationMasterNotRegisteredException e) {\n       LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n           + \" hence resync and send outstanding requests.\");\n       // RM may have restarted, re-register with RM.\n       lastResponseID \u003d 0;\n       register();\n       addOutstandingRequestOnResync();\n       return null;\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.JOB_AM_REBOOT));\n         throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n-    Resource newHeadRoom \u003d\n-        getAvailableResources() \u003d\u003d null ? Resources.none()\n-            : getAvailableResources();\n+    Resource newHeadRoom \u003d getAvailableResources();\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n \n     // Setting AMRMToken\n     if (response.getAMRMToken() !\u003d null) {\n       updateAMRMToken(response.getAMRMToken());\n     }\n \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n \n     // propagate preemption requests\n     final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n     if (preemptReq !\u003d null) {\n       preemptionPolicy.preempt(\n           new PreemptionContext(assignedRequests), preemptReq);\n     }\n \n     if (newContainers.size() + finishedContainers.size() \u003e 0\n         || !headRoom.equals(newHeadRoom)) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         pendingRelease.remove(cont.getContainerId());\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n \n         preemptionPolicy.handleCompletedContainer(attemptID);\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    applyConcurrentTaskLimits();\n\n    // will be null the first time\n    Resource headRoom \u003d Resources.clone(getAvailableResources());\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (ApplicationAttemptNotFoundException e ) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n        JobEventType.JOB_AM_REBOOT));\n      throw new RMContainerAllocationException(\n        \"Resource Manager doesn\u0027t recognize AttemptId: \"\n            + this.getContext().getApplicationAttemptId(), e);\n    } catch (ApplicationMasterNotRegisteredException e) {\n      LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n          + \" hence resync and send outstanding requests.\");\n      // RM may have restarted, re-register with RM.\n      lastResponseID \u003d 0;\n      register();\n      addOutstandingRequestOnResync();\n      return null;\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    Resource newHeadRoom \u003d getAvailableResources();\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() !\u003d null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0\n        || !headRoom.equals(newHeadRoom)) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        pendingRelease.remove(cont.getContainerId());\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n\n        preemptionPolicy.handleCompletedContainer(attemptID);\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "8dfec7a1979e8f70f8355c096874921d368342ef": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6439. AM may fail instead of retrying if RM shuts down during the allocate call. (Anubhav Dhoot via kasha)\n",
      "commitDate": "15/08/15 12:52 AM",
      "commitName": "8dfec7a1979e8f70f8355c096874921d368342ef",
      "commitAuthor": "Karthik Kambatla",
      "commitDateOld": "27/05/15 2:26 PM",
      "commitNameOld": "3164e7d83875aa6b7435d1dfe61ac280aa277f1c",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 79.43,
      "commitsBetweenForRepo": 508,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,116 +1,116 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     applyConcurrentTaskLimits();\n \n     // will be null the first time\n     Resource headRoom \u003d\n         getAvailableResources() \u003d\u003d null ? Resources.none() :\n             Resources.clone(getAvailableResources());\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (ApplicationAttemptNotFoundException e ) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n         JobEventType.JOB_AM_REBOOT));\n-      throw new YarnRuntimeException(\n+      throw new RMContainerAllocationException(\n         \"Resource Manager doesn\u0027t recognize AttemptId: \"\n             + this.getContext().getApplicationAttemptId(), e);\n     } catch (ApplicationMasterNotRegisteredException e) {\n       LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n           + \" hence resync and send outstanding requests.\");\n       // RM may have restarted, re-register with RM.\n       lastResponseID \u003d 0;\n       register();\n       addOutstandingRequestOnResync();\n       return null;\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.JOB_AM_REBOOT));\n-        throw new YarnRuntimeException(\"Could not contact RM after \" +\n+        throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     Resource newHeadRoom \u003d\n         getAvailableResources() \u003d\u003d null ? Resources.none()\n             : getAvailableResources();\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n \n     // Setting AMRMToken\n     if (response.getAMRMToken() !\u003d null) {\n       updateAMRMToken(response.getAMRMToken());\n     }\n \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n \n     // propagate preemption requests\n     final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n     if (preemptReq !\u003d null) {\n       preemptionPolicy.preempt(\n           new PreemptionContext(assignedRequests), preemptReq);\n     }\n \n     if (newContainers.size() + finishedContainers.size() \u003e 0\n         || !headRoom.equals(newHeadRoom)) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         pendingRelease.remove(cont.getContainerId());\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n \n         preemptionPolicy.handleCompletedContainer(attemptID);\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    applyConcurrentTaskLimits();\n\n    // will be null the first time\n    Resource headRoom \u003d\n        getAvailableResources() \u003d\u003d null ? Resources.none() :\n            Resources.clone(getAvailableResources());\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (ApplicationAttemptNotFoundException e ) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n        JobEventType.JOB_AM_REBOOT));\n      throw new RMContainerAllocationException(\n        \"Resource Manager doesn\u0027t recognize AttemptId: \"\n            + this.getContext().getApplicationAttemptId(), e);\n    } catch (ApplicationMasterNotRegisteredException e) {\n      LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n          + \" hence resync and send outstanding requests.\");\n      // RM may have restarted, re-register with RM.\n      lastResponseID \u003d 0;\n      register();\n      addOutstandingRequestOnResync();\n      return null;\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new RMContainerAllocationException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    Resource newHeadRoom \u003d\n        getAvailableResources() \u003d\u003d null ? Resources.none()\n            : getAvailableResources();\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() !\u003d null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0\n        || !headRoom.equals(newHeadRoom)) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        pendingRelease.remove(cont.getContainerId());\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n\n        preemptionPolicy.handleCompletedContainer(attemptID);\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "30da99cbaf36aeef38a858251ce8ffa5eb657b38": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6277. Job can post multiple history files if attempt loses connection to the RM. Contributed by Chang Li\n",
      "commitDate": "18/03/15 12:30 PM",
      "commitName": "30da99cbaf36aeef38a858251ce8ffa5eb657b38",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "03/03/15 2:02 AM",
      "commitNameOld": "4228de94028f1e10ca59ce23e963e488fe566909",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 15.39,
      "commitsBetweenForRepo": 123,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,116 +1,116 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     applyConcurrentTaskLimits();\n \n     // will be null the first time\n     Resource headRoom \u003d\n         getAvailableResources() \u003d\u003d null ? Resources.none() :\n             Resources.clone(getAvailableResources());\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (ApplicationAttemptNotFoundException e ) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n         JobEventType.JOB_AM_REBOOT));\n       throw new YarnRuntimeException(\n         \"Resource Manager doesn\u0027t recognize AttemptId: \"\n             + this.getContext().getApplicationAttemptId(), e);\n     } catch (ApplicationMasterNotRegisteredException e) {\n       LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n           + \" hence resync and send outstanding requests.\");\n       // RM may have restarted, re-register with RM.\n       lastResponseID \u003d 0;\n       register();\n       addOutstandingRequestOnResync();\n       return null;\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n-                                         JobEventType.INTERNAL_ERROR));\n+                                         JobEventType.JOB_AM_REBOOT));\n         throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     Resource newHeadRoom \u003d\n         getAvailableResources() \u003d\u003d null ? Resources.none()\n             : getAvailableResources();\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n \n     // Setting AMRMToken\n     if (response.getAMRMToken() !\u003d null) {\n       updateAMRMToken(response.getAMRMToken());\n     }\n \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n \n     // propagate preemption requests\n     final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n     if (preemptReq !\u003d null) {\n       preemptionPolicy.preempt(\n           new PreemptionContext(assignedRequests), preemptReq);\n     }\n \n     if (newContainers.size() + finishedContainers.size() \u003e 0\n         || !headRoom.equals(newHeadRoom)) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         pendingRelease.remove(cont.getContainerId());\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n \n         preemptionPolicy.handleCompletedContainer(attemptID);\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    applyConcurrentTaskLimits();\n\n    // will be null the first time\n    Resource headRoom \u003d\n        getAvailableResources() \u003d\u003d null ? Resources.none() :\n            Resources.clone(getAvailableResources());\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (ApplicationAttemptNotFoundException e ) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n        JobEventType.JOB_AM_REBOOT));\n      throw new YarnRuntimeException(\n        \"Resource Manager doesn\u0027t recognize AttemptId: \"\n            + this.getContext().getApplicationAttemptId(), e);\n    } catch (ApplicationMasterNotRegisteredException e) {\n      LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n          + \" hence resync and send outstanding requests.\");\n      // RM may have restarted, re-register with RM.\n      lastResponseID \u003d 0;\n      register();\n      addOutstandingRequestOnResync();\n      return null;\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    Resource newHeadRoom \u003d\n        getAvailableResources() \u003d\u003d null ? Resources.none()\n            : getAvailableResources();\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() !\u003d null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0\n        || !headRoom.equals(newHeadRoom)) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        pendingRelease.remove(cont.getContainerId());\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n\n        preemptionPolicy.handleCompletedContainer(attemptID);\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "4228de94028f1e10ca59ce23e963e488fe566909": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5583. Ability to limit running map and reduce tasks. Contributed by Jason Lowe.\n",
      "commitDate": "03/03/15 2:02 AM",
      "commitName": "4228de94028f1e10ca59ce23e963e488fe566909",
      "commitAuthor": "Junping Du",
      "commitDateOld": "28/01/15 3:51 PM",
      "commitNameOld": "cff05bff1fe24628677d41a0d537f2c383b44faf",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 33.42,
      "commitsBetweenForRepo": 336,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,114 +1,116 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n+    applyConcurrentTaskLimits();\n+\n     // will be null the first time\n     Resource headRoom \u003d\n         getAvailableResources() \u003d\u003d null ? Resources.none() :\n             Resources.clone(getAvailableResources());\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (ApplicationAttemptNotFoundException e ) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n         JobEventType.JOB_AM_REBOOT));\n       throw new YarnRuntimeException(\n         \"Resource Manager doesn\u0027t recognize AttemptId: \"\n             + this.getContext().getApplicationAttemptId(), e);\n     } catch (ApplicationMasterNotRegisteredException e) {\n       LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n           + \" hence resync and send outstanding requests.\");\n       // RM may have restarted, re-register with RM.\n       lastResponseID \u003d 0;\n       register();\n       addOutstandingRequestOnResync();\n       return null;\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     Resource newHeadRoom \u003d\n         getAvailableResources() \u003d\u003d null ? Resources.none()\n             : getAvailableResources();\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n \n     // Setting AMRMToken\n     if (response.getAMRMToken() !\u003d null) {\n       updateAMRMToken(response.getAMRMToken());\n     }\n \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n \n     // propagate preemption requests\n     final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n     if (preemptReq !\u003d null) {\n       preemptionPolicy.preempt(\n           new PreemptionContext(assignedRequests), preemptReq);\n     }\n \n     if (newContainers.size() + finishedContainers.size() \u003e 0\n         || !headRoom.equals(newHeadRoom)) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         pendingRelease.remove(cont.getContainerId());\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n \n         preemptionPolicy.handleCompletedContainer(attemptID);\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    applyConcurrentTaskLimits();\n\n    // will be null the first time\n    Resource headRoom \u003d\n        getAvailableResources() \u003d\u003d null ? Resources.none() :\n            Resources.clone(getAvailableResources());\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (ApplicationAttemptNotFoundException e ) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n        JobEventType.JOB_AM_REBOOT));\n      throw new YarnRuntimeException(\n        \"Resource Manager doesn\u0027t recognize AttemptId: \"\n            + this.getContext().getApplicationAttemptId(), e);\n    } catch (ApplicationMasterNotRegisteredException e) {\n      LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n          + \" hence resync and send outstanding requests.\");\n      // RM may have restarted, re-register with RM.\n      lastResponseID \u003d 0;\n      register();\n      addOutstandingRequestOnResync();\n      return null;\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    Resource newHeadRoom \u003d\n        getAvailableResources() \u003d\u003d null ? Resources.none()\n            : getAvailableResources();\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() !\u003d null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0\n        || !headRoom.equals(newHeadRoom)) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        pendingRelease.remove(cont.getContainerId());\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n\n        preemptionPolicy.handleCompletedContainer(attemptID);\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "d336d136785ef1e49e0a110a1b9f0d1824829877": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6210. Use getApplicationAttemptId() instead of getApplicationID() for logging AttemptId in RMContainerAllocator.java (Contributed by Leitao Guo)\n",
      "commitDate": "14/01/15 12:38 AM",
      "commitName": "d336d136785ef1e49e0a110a1b9f0d1824829877",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "23/10/14 9:56 PM",
      "commitNameOld": "0f3b6900be1a3b2e4624f31f84656f4a32dadce9",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 82.15,
      "commitsBetweenForRepo": 580,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,114 +1,114 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     // will be null the first time\n     Resource headRoom \u003d\n         getAvailableResources() \u003d\u003d null ? Resources.none() :\n             Resources.clone(getAvailableResources());\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (ApplicationAttemptNotFoundException e ) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n         JobEventType.JOB_AM_REBOOT));\n       throw new YarnRuntimeException(\n         \"Resource Manager doesn\u0027t recognize AttemptId: \"\n-            + this.getContext().getApplicationID(), e);\n+            + this.getContext().getApplicationAttemptId(), e);\n     } catch (ApplicationMasterNotRegisteredException e) {\n       LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n           + \" hence resync and send outstanding requests.\");\n       // RM may have restarted, re-register with RM.\n       lastResponseID \u003d 0;\n       register();\n       addOutstandingRequestOnResync();\n       return null;\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     Resource newHeadRoom \u003d\n         getAvailableResources() \u003d\u003d null ? Resources.none()\n             : getAvailableResources();\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n \n     // Setting AMRMToken\n     if (response.getAMRMToken() !\u003d null) {\n       updateAMRMToken(response.getAMRMToken());\n     }\n \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n \n     // propagate preemption requests\n     final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n     if (preemptReq !\u003d null) {\n       preemptionPolicy.preempt(\n           new PreemptionContext(assignedRequests), preemptReq);\n     }\n \n     if (newContainers.size() + finishedContainers.size() \u003e 0\n         || !headRoom.equals(newHeadRoom)) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         pendingRelease.remove(cont.getContainerId());\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n \n         preemptionPolicy.handleCompletedContainer(attemptID);\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    // will be null the first time\n    Resource headRoom \u003d\n        getAvailableResources() \u003d\u003d null ? Resources.none() :\n            Resources.clone(getAvailableResources());\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (ApplicationAttemptNotFoundException e ) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n        JobEventType.JOB_AM_REBOOT));\n      throw new YarnRuntimeException(\n        \"Resource Manager doesn\u0027t recognize AttemptId: \"\n            + this.getContext().getApplicationAttemptId(), e);\n    } catch (ApplicationMasterNotRegisteredException e) {\n      LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n          + \" hence resync and send outstanding requests.\");\n      // RM may have restarted, re-register with RM.\n      lastResponseID \u003d 0;\n      register();\n      addOutstandingRequestOnResync();\n      return null;\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    Resource newHeadRoom \u003d\n        getAvailableResources() \u003d\u003d null ? Resources.none()\n            : getAvailableResources();\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() !\u003d null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0\n        || !headRoom.equals(newHeadRoom)) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        pendingRelease.remove(cont.getContainerId());\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n\n        preemptionPolicy.handleCompletedContainer(attemptID);\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "0f3b6900be1a3b2e4624f31f84656f4a32dadce9": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2209. Replaced AM resync/shutdown command with corresponding exceptions and made related MR changes. Contributed by Jian He.\n",
      "commitDate": "23/10/14 9:56 PM",
      "commitName": "0f3b6900be1a3b2e4624f31f84656f4a32dadce9",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "22/09/14 9:28 AM",
      "commitNameOld": "376233cdd4a4ddbde5a92a0627f78338cb4c38b7",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 31.52,
      "commitsBetweenForRepo": 299,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,124 +1,114 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     // will be null the first time\n     Resource headRoom \u003d\n         getAvailableResources() \u003d\u003d null ? Resources.none() :\n             Resources.clone(getAvailableResources());\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n+    } catch (ApplicationAttemptNotFoundException e ) {\n+      // This can happen if the RM has been restarted. If it is in that state,\n+      // this application must clean itself up.\n+      eventHandler.handle(new JobEvent(this.getJob().getID(),\n+        JobEventType.JOB_AM_REBOOT));\n+      throw new YarnRuntimeException(\n+        \"Resource Manager doesn\u0027t recognize AttemptId: \"\n+            + this.getContext().getApplicationID(), e);\n+    } catch (ApplicationMasterNotRegisteredException e) {\n+      LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n+          + \" hence resync and send outstanding requests.\");\n+      // RM may have restarted, re-register with RM.\n+      lastResponseID \u003d 0;\n+      register();\n+      addOutstandingRequestOnResync();\n+      return null;\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n-    if (response.getAMCommand() !\u003d null) {\n-      switch(response.getAMCommand()) {\n-      case AM_RESYNC:\n-          LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n-              + \" hence resyncing.\");\n-          lastResponseID \u003d 0;\n-\n-          // Registering to allow RM to discover an active AM for this\n-          // application\n-          register();\n-          addOutstandingRequestOnResync();\n-          break;\n-      case AM_SHUTDOWN:\n-        // This can happen if the RM has been restarted. If it is in that state,\n-        // this application must clean itself up.\n-        eventHandler.handle(new JobEvent(this.getJob().getID(),\n-                                         JobEventType.JOB_AM_REBOOT));\n-        throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n-                                 this.getContext().getApplicationID());\n-      default:\n-        String msg \u003d\n-              \"Unhandled value of AMCommand: \" + response.getAMCommand();\n-        LOG.error(msg);\n-        throw new YarnRuntimeException(msg);\n-      }\n-    }\n     Resource newHeadRoom \u003d\n         getAvailableResources() \u003d\u003d null ? Resources.none()\n             : getAvailableResources();\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n \n     // Setting AMRMToken\n     if (response.getAMRMToken() !\u003d null) {\n       updateAMRMToken(response.getAMRMToken());\n     }\n \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n \n     // propagate preemption requests\n     final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n     if (preemptReq !\u003d null) {\n       preemptionPolicy.preempt(\n           new PreemptionContext(assignedRequests), preemptReq);\n     }\n \n     if (newContainers.size() + finishedContainers.size() \u003e 0\n         || !headRoom.equals(newHeadRoom)) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         pendingRelease.remove(cont.getContainerId());\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n \n         preemptionPolicy.handleCompletedContainer(attemptID);\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    // will be null the first time\n    Resource headRoom \u003d\n        getAvailableResources() \u003d\u003d null ? Resources.none() :\n            Resources.clone(getAvailableResources());\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (ApplicationAttemptNotFoundException e ) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n        JobEventType.JOB_AM_REBOOT));\n      throw new YarnRuntimeException(\n        \"Resource Manager doesn\u0027t recognize AttemptId: \"\n            + this.getContext().getApplicationID(), e);\n    } catch (ApplicationMasterNotRegisteredException e) {\n      LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n          + \" hence resync and send outstanding requests.\");\n      // RM may have restarted, re-register with RM.\n      lastResponseID \u003d 0;\n      register();\n      addOutstandingRequestOnResync();\n      return null;\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    Resource newHeadRoom \u003d\n        getAvailableResources() \u003d\u003d null ? Resources.none()\n            : getAvailableResources();\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() !\u003d null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0\n        || !headRoom.equals(newHeadRoom)) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        pendingRelease.remove(cont.getContainerId());\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n\n        preemptionPolicy.handleCompletedContainer(attemptID);\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "376233cdd4a4ddbde5a92a0627f78338cb4c38b7": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5279. Made MR headroom calculation honor cpu dimension when YARN scheduler resource type is memory plus cpu. Contributed by Peng Zhang and Varun Vasudev.\n",
      "commitDate": "22/09/14 9:28 AM",
      "commitName": "376233cdd4a4ddbde5a92a0627f78338cb4c38b7",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "08/08/14 2:38 PM",
      "commitNameOld": "eeb4acd955802e2a84ea94cecf2e2341b83d5efb",
      "commitAuthorOld": "Xuan Gong",
      "daysBetweenCommits": 44.78,
      "commitsBetweenForRepo": 414,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,119 +1,124 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n-    int headRoom \u003d getAvailableResources() !\u003d null\n-        ? getAvailableResources().getMemory() : 0;//first time it would be null\n+    // will be null the first time\n+    Resource headRoom \u003d\n+        getAvailableResources() \u003d\u003d null ? Resources.none() :\n+            Resources.clone(getAvailableResources());\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     if (response.getAMCommand() !\u003d null) {\n       switch(response.getAMCommand()) {\n       case AM_RESYNC:\n           LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n               + \" hence resyncing.\");\n           lastResponseID \u003d 0;\n \n           // Registering to allow RM to discover an active AM for this\n           // application\n           register();\n           addOutstandingRequestOnResync();\n           break;\n       case AM_SHUTDOWN:\n         // This can happen if the RM has been restarted. If it is in that state,\n         // this application must clean itself up.\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.JOB_AM_REBOOT));\n         throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                  this.getContext().getApplicationID());\n       default:\n         String msg \u003d\n               \"Unhandled value of AMCommand: \" + response.getAMCommand();\n         LOG.error(msg);\n         throw new YarnRuntimeException(msg);\n       }\n     }\n-    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n+    Resource newHeadRoom \u003d\n+        getAvailableResources() \u003d\u003d null ? Resources.none()\n+            : getAvailableResources();\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n \n     // Setting AMRMToken\n     if (response.getAMRMToken() !\u003d null) {\n       updateAMRMToken(response.getAMRMToken());\n     }\n \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n \n     // propagate preemption requests\n     final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n     if (preemptReq !\u003d null) {\n       preemptionPolicy.preempt(\n           new PreemptionContext(assignedRequests), preemptReq);\n     }\n \n-    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n+    if (newContainers.size() + finishedContainers.size() \u003e 0\n+        || !headRoom.equals(newHeadRoom)) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n-      if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n+      if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         pendingRelease.remove(cont.getContainerId());\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n \n         preemptionPolicy.handleCompletedContainer(attemptID);\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    // will be null the first time\n    Resource headRoom \u003d\n        getAvailableResources() \u003d\u003d null ? Resources.none() :\n            Resources.clone(getAvailableResources());\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getAMCommand() !\u003d null) {\n      switch(response.getAMCommand()) {\n      case AM_RESYNC:\n          LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n              + \" hence resyncing.\");\n          lastResponseID \u003d 0;\n\n          // Registering to allow RM to discover an active AM for this\n          // application\n          register();\n          addOutstandingRequestOnResync();\n          break;\n      case AM_SHUTDOWN:\n        // This can happen if the RM has been restarted. If it is in that state,\n        // this application must clean itself up.\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                 this.getContext().getApplicationID());\n      default:\n        String msg \u003d\n              \"Unhandled value of AMCommand: \" + response.getAMCommand();\n        LOG.error(msg);\n        throw new YarnRuntimeException(msg);\n      }\n    }\n    Resource newHeadRoom \u003d\n        getAvailableResources() \u003d\u003d null ? Resources.none()\n            : getAvailableResources();\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() !\u003d null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0\n        || !headRoom.equals(newHeadRoom)) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 !headRoom.equals(newHeadRoom)) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        pendingRelease.remove(cont.getContainerId());\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n\n        preemptionPolicy.handleCompletedContainer(attemptID);\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "eeb4acd955802e2a84ea94cecf2e2341b83d5efb": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2212: ApplicationMaster needs to find a way to update the AMRMToken periodically. Contributed by Xuan Gong\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616892 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/08/14 2:38 PM",
      "commitName": "eeb4acd955802e2a84ea94cecf2e2341b83d5efb",
      "commitAuthor": "Xuan Gong",
      "commitDateOld": "17/07/14 11:46 AM",
      "commitNameOld": "875592220fb250ff9d0bba73c8ace9858fd369fd",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 22.12,
      "commitsBetweenForRepo": 170,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,114 +1,119 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null\n         ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     if (response.getAMCommand() !\u003d null) {\n       switch(response.getAMCommand()) {\n       case AM_RESYNC:\n           LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n               + \" hence resyncing.\");\n           lastResponseID \u003d 0;\n \n           // Registering to allow RM to discover an active AM for this\n           // application\n           register();\n           addOutstandingRequestOnResync();\n           break;\n       case AM_SHUTDOWN:\n         // This can happen if the RM has been restarted. If it is in that state,\n         // this application must clean itself up.\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.JOB_AM_REBOOT));\n         throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                  this.getContext().getApplicationID());\n       default:\n         String msg \u003d\n               \"Unhandled value of AMCommand: \" + response.getAMCommand();\n         LOG.error(msg);\n         throw new YarnRuntimeException(msg);\n       }\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n-    \n+\n+    // Setting AMRMToken\n+    if (response.getAMRMToken() !\u003d null) {\n+      updateAMRMToken(response.getAMRMToken());\n+    }\n+\n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n \n     // propagate preemption requests\n     final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n     if (preemptReq !\u003d null) {\n       preemptionPolicy.preempt(\n           new PreemptionContext(assignedRequests), preemptReq);\n     }\n \n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         pendingRelease.remove(cont.getContainerId());\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n \n         preemptionPolicy.handleCompletedContainer(attemptID);\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null\n        ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getAMCommand() !\u003d null) {\n      switch(response.getAMCommand()) {\n      case AM_RESYNC:\n          LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n              + \" hence resyncing.\");\n          lastResponseID \u003d 0;\n\n          // Registering to allow RM to discover an active AM for this\n          // application\n          register();\n          addOutstandingRequestOnResync();\n          break;\n      case AM_SHUTDOWN:\n        // This can happen if the RM has been restarted. If it is in that state,\n        // this application must clean itself up.\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                 this.getContext().getApplicationID());\n      default:\n        String msg \u003d\n              \"Unhandled value of AMCommand: \" + response.getAMCommand();\n        LOG.error(msg);\n        throw new YarnRuntimeException(msg);\n      }\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n\n    // Setting AMRMToken\n    if (response.getAMRMToken() !\u003d null) {\n      updateAMRMToken(response.getAMRMToken());\n    }\n\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        pendingRelease.remove(cont.getContainerId());\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n\n        preemptionPolicy.handleCompletedContainer(attemptID);\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "875592220fb250ff9d0bba73c8ace9858fd369fd": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5910. Make MR AM resync with RM in case of work-preserving RM-restart. Contributed by Rohith\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1611434 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/07/14 11:46 AM",
      "commitName": "875592220fb250ff9d0bba73c8ace9858fd369fd",
      "commitAuthor": "Jian He",
      "commitDateOld": "02/07/14 6:43 PM",
      "commitNameOld": "c6a09d2110286632e6cfcee00abf8e79894381ec",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 14.71,
      "commitsBetweenForRepo": 100,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,104 +1,114 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null\n         ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     if (response.getAMCommand() !\u003d null) {\n       switch(response.getAMCommand()) {\n       case AM_RESYNC:\n+          LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n+              + \" hence resyncing.\");\n+          lastResponseID \u003d 0;\n+\n+          // Registering to allow RM to discover an active AM for this\n+          // application\n+          register();\n+          addOutstandingRequestOnResync();\n+          break;\n       case AM_SHUTDOWN:\n         // This can happen if the RM has been restarted. If it is in that state,\n         // this application must clean itself up.\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.JOB_AM_REBOOT));\n         throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                  this.getContext().getApplicationID());\n       default:\n         String msg \u003d\n               \"Unhandled value of AMCommand: \" + response.getAMCommand();\n         LOG.error(msg);\n         throw new YarnRuntimeException(msg);\n       }\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n     \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n \n     // propagate preemption requests\n     final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n     if (preemptReq !\u003d null) {\n       preemptionPolicy.preempt(\n           new PreemptionContext(assignedRequests), preemptReq);\n     }\n \n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n+        pendingRelease.remove(cont.getContainerId());\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n \n         preemptionPolicy.handleCompletedContainer(attemptID);\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null\n        ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getAMCommand() !\u003d null) {\n      switch(response.getAMCommand()) {\n      case AM_RESYNC:\n          LOG.info(\"ApplicationMaster is out of sync with ResourceManager,\"\n              + \" hence resyncing.\");\n          lastResponseID \u003d 0;\n\n          // Registering to allow RM to discover an active AM for this\n          // application\n          register();\n          addOutstandingRequestOnResync();\n          break;\n      case AM_SHUTDOWN:\n        // This can happen if the RM has been restarted. If it is in that state,\n        // this application must clean itself up.\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                 this.getContext().getApplicationID());\n      default:\n        String msg \u003d\n              \"Unhandled value of AMCommand: \" + response.getAMCommand();\n        LOG.error(msg);\n        throw new YarnRuntimeException(msg);\n      }\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n    \n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        pendingRelease.remove(cont.getContainerId());\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n\n        preemptionPolicy.handleCompletedContainer(attemptID);\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "9ca394d54dd24e67867c845a58150f6b51761512": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5189. Add policies and wiring to respond to preemption requests\nfrom YARN. Contributed by Carlo Curino.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1551748 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/12/13 2:54 PM",
      "commitName": "9ca394d54dd24e67867c845a58150f6b51761512",
      "commitAuthor": "Christopher Douglas",
      "commitDateOld": "18/07/13 5:57 PM",
      "commitNameOld": "ac914f79bc80b152e71e7de5497b73f22824f4a7",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 151.91,
      "commitsBetweenForRepo": 987,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,104 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null\n         ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     if (response.getAMCommand() !\u003d null) {\n       switch(response.getAMCommand()) {\n       case AM_RESYNC:\n       case AM_SHUTDOWN:\n         // This can happen if the RM has been restarted. If it is in that state,\n         // this application must clean itself up.\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.JOB_AM_REBOOT));\n         throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                  this.getContext().getApplicationID());\n       default:\n         String msg \u003d\n               \"Unhandled value of AMCommand: \" + response.getAMCommand();\n         LOG.error(msg);\n         throw new YarnRuntimeException(msg);\n       }\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n         NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n     \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n+\n+    // propagate preemption requests\n+    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n+    if (preemptReq !\u003d null) {\n+      preemptionPolicy.preempt(\n+          new PreemptionContext(assignedRequests), preemptReq);\n+    }\n+\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n-      }      \n+\n+        preemptionPolicy.handleCompletedContainer(attemptID);\n+      }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null\n        ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getAMCommand() !\u003d null) {\n      switch(response.getAMCommand()) {\n      case AM_RESYNC:\n      case AM_SHUTDOWN:\n        // This can happen if the RM has been restarted. If it is in that state,\n        // this application must clean itself up.\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                 this.getContext().getApplicationID());\n      default:\n        String msg \u003d\n              \"Unhandled value of AMCommand: \" + response.getAMCommand();\n        LOG.error(msg);\n        throw new YarnRuntimeException(msg);\n      }\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n    \n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n\n    // propagate preemption requests\n    final PreemptionMessage preemptReq \u003d response.getPreemptionMessage();\n    if (preemptReq !\u003d null) {\n      preemptionPolicy.preempt(\n          new PreemptionContext(assignedRequests), preemptReq);\n    }\n\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n\n        preemptionPolicy.handleCompletedContainer(attemptID);\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "1a06175440eec7994d6b63b0e5ac8b6532870fb3": {
      "type": "Ybodychange",
      "commitMessage": "YARN-851. Share NMTokens using NMTokenCache (api-based) between AMRMClient and NMClient instead of memory based approach which is used currently. Contributed by Omkar Vinit Joshi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1495247 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/06/13 5:08 PM",
      "commitName": "1a06175440eec7994d6b63b0e5ac8b6532870fb3",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "18/06/13 4:19 PM",
      "commitNameOld": "243bcd367ff3130d74676280233041f88aca62a5",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 2.03,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,94 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null\n         ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     if (response.getAMCommand() !\u003d null) {\n       switch(response.getAMCommand()) {\n       case AM_RESYNC:\n       case AM_SHUTDOWN:\n         // This can happen if the RM has been restarted. If it is in that state,\n         // this application must clean itself up.\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.JOB_AM_REBOOT));\n         throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                  this.getContext().getApplicationID());\n       default:\n         String msg \u003d\n               \"Unhandled value of AMCommand: \" + response.getAMCommand();\n         LOG.error(msg);\n         throw new YarnRuntimeException(msg);\n       }\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     // Setting NMTokens\n     if (response.getNMTokens() !\u003d null) {\n       for (NMToken nmToken : response.getNMTokens()) {\n-        getContext().getNMTokens().put(nmToken.getNodeId().toString(),\n+        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n             nmToken.getToken());\n       }\n     }\n     \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n       }      \n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null\n        ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getAMCommand() !\u003d null) {\n      switch(response.getAMCommand()) {\n      case AM_RESYNC:\n      case AM_SHUTDOWN:\n        // This can happen if the RM has been restarted. If it is in that state,\n        // this application must clean itself up.\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                 this.getContext().getApplicationID());\n      default:\n        String msg \u003d\n              \"Unhandled value of AMCommand: \" + response.getAMCommand();\n        LOG.error(msg);\n        throw new YarnRuntimeException(msg);\n      }\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        NMTokenCache.setNMToken(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n    \n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }      \n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "243bcd367ff3130d74676280233041f88aca62a5": {
      "type": "Ybodychange",
      "commitMessage": "YARN-694. Starting to use NMTokens to authenticate all communication with NodeManagers. Contributed by Omkar Vinit Joshi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1494369 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/06/13 4:19 PM",
      "commitName": "243bcd367ff3130d74676280233041f88aca62a5",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "14/06/13 12:06 PM",
      "commitNameOld": "079ed1c9e1ab0a902e183dca2a5a9d79a7201264",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 4.18,
      "commitsBetweenForRepo": 50,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,94 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null\n         ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     if (response.getAMCommand() !\u003d null) {\n       switch(response.getAMCommand()) {\n       case AM_RESYNC:\n       case AM_SHUTDOWN:\n         // This can happen if the RM has been restarted. If it is in that state,\n         // this application must clean itself up.\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.JOB_AM_REBOOT));\n         throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                  this.getContext().getApplicationID());\n       default:\n         String msg \u003d\n               \"Unhandled value of AMCommand: \" + response.getAMCommand();\n         LOG.error(msg);\n         throw new YarnRuntimeException(msg);\n       }\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n+    // Setting NMTokens\n+    if (response.getNMTokens() !\u003d null) {\n+      for (NMToken nmToken : response.getNMTokens()) {\n+        getContext().getNMTokens().put(nmToken.getNodeId().toString(),\n+            nmToken.getToken());\n+      }\n+    }\n+    \n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n       }      \n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null\n        ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getAMCommand() !\u003d null) {\n      switch(response.getAMCommand()) {\n      case AM_RESYNC:\n      case AM_SHUTDOWN:\n        // This can happen if the RM has been restarted. If it is in that state,\n        // this application must clean itself up.\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                 this.getContext().getApplicationID());\n      default:\n        String msg \u003d\n              \"Unhandled value of AMCommand: \" + response.getAMCommand();\n        LOG.error(msg);\n        throw new YarnRuntimeException(msg);\n      }\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    // Setting NMTokens\n    if (response.getNMTokens() !\u003d null) {\n      for (NMToken nmToken : response.getNMTokens()) {\n        getContext().getNMTokens().put(nmToken.getNodeId().toString(),\n            nmToken.getToken());\n      }\n    }\n    \n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }      \n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "9fcfbf5f51f2557566694377f94a556226585d68": {
      "type": "Ybodychange",
      "commitMessage": "YARN-759. Create Command enum in AllocateResponse (bikas)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1490470 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/06/13 4:33 PM",
      "commitName": "9fcfbf5f51f2557566694377f94a556226585d68",
      "commitAuthor": "Bikas Saha",
      "commitDateOld": "03/06/13 10:53 PM",
      "commitNameOld": "978012b9b6b18985fd60ec5b26c38693a6e86f9a",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 2.74,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,86 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null\n         ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n-    if (response.getResync()) {\n-      // This can happen if the RM has been restarted. If it is in that state,\n-      // this application must clean itself up.\n-      eventHandler.handle(new JobEvent(this.getJob().getID(),\n-                                       JobEventType.JOB_AM_REBOOT));\n-      throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n-                               this.getContext().getApplicationID());\n+    if (response.getAMCommand() !\u003d null) {\n+      switch(response.getAMCommand()) {\n+      case AM_RESYNC:\n+      case AM_SHUTDOWN:\n+        // This can happen if the RM has been restarted. If it is in that state,\n+        // this application must clean itself up.\n+        eventHandler.handle(new JobEvent(this.getJob().getID(),\n+                                         JobEventType.JOB_AM_REBOOT));\n+        throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n+                                 this.getContext().getApplicationID());\n+      default:\n+        String msg \u003d\n+              \"Unhandled value of AMCommand: \" + response.getAMCommand();\n+        LOG.error(msg);\n+        throw new YarnRuntimeException(msg);\n+      }\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n       }      \n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null\n        ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getAMCommand() !\u003d null) {\n      switch(response.getAMCommand()) {\n      case AM_RESYNC:\n      case AM_SHUTDOWN:\n        // This can happen if the RM has been restarted. If it is in that state,\n        // this application must clean itself up.\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.JOB_AM_REBOOT));\n        throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                 this.getContext().getApplicationID());\n      default:\n        String msg \u003d\n              \"Unhandled value of AMCommand: \" + response.getAMCommand();\n        LOG.error(msg);\n        throw new YarnRuntimeException(msg);\n      }\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }      \n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "978012b9b6b18985fd60ec5b26c38693a6e86f9a": {
      "type": "Ybodychange",
      "commitMessage": "YARN-755. Renamed AllocateResponse.reboot to AllocateResponse.resync. Contributed by Bikas Saha.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1489295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/06/13 10:53 PM",
      "commitName": "978012b9b6b18985fd60ec5b26c38693a6e86f9a",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "03/06/13 9:05 PM",
      "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.07,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,77 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null\n         ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n-    if (response.getReboot()) {\n+    if (response.getResync()) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                        JobEventType.JOB_AM_REBOOT));\n       throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                this.getContext().getApplicationID());\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n       }      \n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null\n        ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getResync()) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                       JobEventType.JOB_AM_REBOOT));\n      throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                               this.getContext().getApplicationID());\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }      \n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "a83fb61ac07c0468cbc7a38526e92683883dd932": {
      "type": "Ybodychange",
      "commitMessage": "YARN-635. Renamed YarnRemoteException to YarnException. Contributed by Siddharth Seth.\nMAPREDUCE-5301. Updated MR code to work with YARN-635 changes of renaming YarnRemoteException to YarnException. Contributed by Siddharth Seth\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1489283 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/06/13 9:05 PM",
      "commitName": "a83fb61ac07c0468cbc7a38526e92683883dd932",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "15/04/13 4:54 PM",
      "commitNameOld": "0e01f26821caa3bf8554afe422bb080abcfe1e83",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 49.17,
      "commitsBetweenForRepo": 314,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,77 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null\n         ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n-        throw new YarnException(\"Could not contact RM after \" +\n+        throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     if (response.getReboot()) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                        JobEventType.JOB_AM_REBOOT));\n-      throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n+      throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                this.getContext().getApplicationID());\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n       }      \n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null\n        ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnRuntimeException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getReboot()) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                       JobEventType.JOB_AM_REBOOT));\n      throw new YarnRuntimeException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                               this.getContext().getApplicationID());\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }      \n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "fc75d3f3dc2733d6c783eb4d4f1c5c6ae680f08e": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5086. MR app master deletes staging dir when sent a reboot command from the RM. Contributed by Jian He\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1464255 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/04/13 6:56 PM",
      "commitName": "fc75d3f3dc2733d6c783eb4d4f1c5c6ae680f08e",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "20/03/13 1:44 PM",
      "commitNameOld": "1bd345d6e3855ab330963efd32e0fac102e61d1a",
      "commitAuthorOld": "Hitesh Shah",
      "daysBetweenCommits": 14.22,
      "commitsBetweenForRepo": 85,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,77 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null\n         ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     if (response.getReboot()) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n-                                       JobEventType.INTERNAL_ERROR));\n+                                       JobEventType.JOB_AM_REBOOT));\n       throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                this.getContext().getApplicationID());\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n       }      \n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null\n        ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getReboot()) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                       JobEventType.JOB_AM_REBOOT));\n      throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                               this.getContext().getApplicationID());\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }      \n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "1bd345d6e3855ab330963efd32e0fac102e61d1a": {
      "type": "Ybodychange",
      "commitMessage": "YARN-396. Rationalize AllocateResponse in RM Scheduler API. Contributed by Zhijie Shen.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1459040 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/03/13 1:44 PM",
      "commitName": "1bd345d6e3855ab330963efd32e0fac102e61d1a",
      "commitAuthor": "Hitesh Shah",
      "commitDateOld": "21/02/13 3:56 AM",
      "commitNameOld": "0b73dde6ce865ff94b483558ff0701de9932e211",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 27.37,
      "commitsBetweenForRepo": 134,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,77 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n-    int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n-    AMResponse response;\n+    int headRoom \u003d getAvailableResources() !\u003d null\n+        ? getAvailableResources().getMemory() : 0;//first time it would be null\n+    AllocateResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     if (response.getReboot()) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                        JobEventType.INTERNAL_ERROR));\n       throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                this.getContext().getApplicationID());\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n         \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n       }      \n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null\n        ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AllocateResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getReboot()) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                       JobEventType.INTERNAL_ERROR));\n      throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                               this.getContext().getApplicationID());\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }      \n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "0b73dde6ce865ff94b483558ff0701de9932e211": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4951. Container preemption interpreted as task failure. Contributed by Sandy Ryza.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1448615 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/02/13 3:56 AM",
      "commitName": "0b73dde6ce865ff94b483558ff0701de9932e211",
      "commitAuthor": "Thomas White",
      "commitDateOld": "30/01/13 4:28 PM",
      "commitNameOld": "28c308d5e81432b79f9c9e14df316a52cc7ba48f",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 21.48,
      "commitsBetweenForRepo": 77,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,76 +1,76 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AMResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     if (response.getReboot()) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                        JobEventType.INTERNAL_ERROR));\n       throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                this.getContext().getApplicationID());\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n       if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n         LOG.debug(\"headroom\u003d\" + newHeadRoom);\n       }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n-        eventHandler.handle(new TaskAttemptEvent(attemptID,\n-            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n+        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n+        \n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n       }      \n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AMResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getReboot()) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                       JobEventType.INTERNAL_ERROR));\n      throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                               this.getContext().getApplicationID());\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(createContainerFinishedEvent(cont, attemptID));\n        \n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }      \n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "b2f7a66e50bd09d26b2ad22e66ced73a6254de77": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4517. Too many INFO messages written out during AM to RM heartbeat (Jason Lowe via tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1409032 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/11/12 3:47 PM",
      "commitName": "b2f7a66e50bd09d26b2ad22e66ced73a6254de77",
      "commitAuthor": "Thomas Graves",
      "commitDateOld": "31/10/12 7:57 AM",
      "commitNameOld": "aac5c149c7ca500b8eb810b7d4b561ff1e38ea02",
      "commitAuthorOld": "Thomas Graves",
      "daysBetweenCommits": 13.37,
      "commitsBetweenForRepo": 76,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,73 +1,76 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AMResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     if (response.getReboot()) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                        JobEventType.INTERNAL_ERROR));\n       throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                this.getContext().getApplicationID());\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n+      if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n+        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n+      }\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(new TaskAttemptEvent(attemptID,\n             TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n         // Send the diagnostics\n         String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n       }      \n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AMResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getReboot()) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                       JobEventType.INTERNAL_ERROR));\n      throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                               this.getContext().getApplicationID());\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n      if (LOG.isDebugEnabled() \u0026\u0026 headRoom !\u003d newHeadRoom) {\n        LOG.debug(\"headroom\u003d\" + newHeadRoom);\n      }\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(new TaskAttemptEvent(attemptID,\n            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }      \n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "aac5c149c7ca500b8eb810b7d4b561ff1e38ea02": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4752. Reduce MR AM memory usage through String Interning (Robert Evans via tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1404177 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/10/12 7:57 AM",
      "commitName": "aac5c149c7ca500b8eb810b7d4b561ff1e38ea02",
      "commitAuthor": "Thomas Graves",
      "commitDateOld": "24/10/12 8:45 AM",
      "commitNameOld": "1e45b1f1fd38543b0b1233f57fdee1ac4a365332",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 6.97,
      "commitsBetweenForRepo": 30,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,73 +1,73 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AMResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     if (response.getReboot()) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                        JobEventType.INTERNAL_ERROR));\n       throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                this.getContext().getApplicationID());\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n \n     handleUpdatedNodes(response);\n \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(new TaskAttemptEvent(attemptID,\n             TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n         // Send the diagnostics\n-        String diagnostics \u003d cont.getDiagnostics();\n+        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n       }      \n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AMResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getReboot()) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                       JobEventType.INTERNAL_ERROR));\n      throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                               this.getContext().getApplicationID());\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(new TaskAttemptEvent(attemptID,\n            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n        // Send the diagnostics\n        String diagnostics \u003d StringInterner.weakIntern(cont.getDiagnostics());\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }      \n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "eff9fa1aad7e22d445a11e4ba732b4d49cdaca65": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3921. MR AM should act on node health status changes. Contributed by Bikas Saha.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1349065 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/06/12 4:14 PM",
      "commitName": "eff9fa1aad7e22d445a11e4ba732b4d49cdaca65",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "06/02/12 2:01 PM",
      "commitNameOld": "28a2eb9d722bb8cbbeee87a1c43b4dc4ef4467ce",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 126.05,
      "commitsBetweenForRepo": 880,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,71 +1,73 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AMResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     if (response.getReboot()) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                        JobEventType.INTERNAL_ERROR));\n       throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                this.getContext().getApplicationID());\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n-    \n+\n+    handleUpdatedNodes(response);\n+\n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(new TaskAttemptEvent(attemptID,\n             TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n         // Send the diagnostics\n         String diagnostics \u003d cont.getDiagnostics();\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n-      }\n+      }      \n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AMResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getReboot()) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                       JobEventType.INTERNAL_ERROR));\n      throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                               this.getContext().getApplicationID());\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n\n    handleUpdatedNodes(response);\n\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(new TaskAttemptEvent(attemptID,\n            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n        // Send the diagnostics\n        String diagnostics \u003d cont.getDiagnostics();\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }      \n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "28a2eb9d722bb8cbbeee87a1c43b4dc4ef4467ce": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3810. Performance tweaks - reduced logging in AM and defined hascode/equals for ResourceRequest \u0026 Priority. Contributed by Vinod K V. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1241205 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/02/12 2:01 PM",
      "commitName": "28a2eb9d722bb8cbbeee87a1c43b4dc4ef4467ce",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "03/02/12 4:04 PM",
      "commitNameOld": "94242c93857a06fb9c56ee571a47d6ca18f00f48",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 2.91,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,71 +1,71 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AMResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     if (response.getReboot()) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                        JobEventType.INTERNAL_ERROR));\n       throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                this.getContext().getApplicationID());\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n     \n     for (ContainerStatus cont : finishedContainers) {\n-      LOG.info(\"Received completed container \" + cont);\n+      LOG.info(\"Received completed container \" + cont.getContainerId());\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(new TaskAttemptEvent(attemptID,\n             TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n         // Send the diagnostics\n         String diagnostics \u003d cont.getDiagnostics();\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AMResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getReboot()) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                       JobEventType.INTERNAL_ERROR));\n      throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                               this.getContext().getApplicationID());\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n    \n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont.getContainerId());\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(new TaskAttemptEvent(attemptID,\n            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n        // Send the diagnostics\n        String diagnostics \u003d cont.getDiagnostics();\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "94242c93857a06fb9c56ee571a47d6ca18f00f48": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3711. Fixed MR AM recovery so that only single selected task output is recovered and thus reduce the unnecessarily bloated recovery time. Contributed by Robert Joseph Evans.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1240413 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/02/12 4:04 PM",
      "commitName": "94242c93857a06fb9c56ee571a47d6ca18f00f48",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "04/01/12 5:37 PM",
      "commitNameOld": "08f8abf5639d39167952dc5120b44fe35c63ff7a",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 29.94,
      "commitsBetweenForRepo": 171,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,71 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AMResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n+        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     if (response.getReboot()) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                        JobEventType.INTERNAL_ERROR));\n       throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                this.getContext().getApplicationID());\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n     \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont);\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n         \n         // send the container completed event to Task attempt\n         eventHandler.handle(new TaskAttemptEvent(attemptID,\n             TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n         // Send the diagnostics\n         String diagnostics \u003d cont.getDiagnostics();\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AMResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        LOG.error(\"Could not contact RM after \" + retryInterval + \" milliseconds.\");\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getReboot()) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                       JobEventType.INTERNAL_ERROR));\n      throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                               this.getContext().getApplicationID());\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n    \n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont);\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(new TaskAttemptEvent(attemptID,\n            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n        // Send the diagnostics\n        String diagnostics \u003d cont.getDiagnostics();\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "55e94dc5ef4171c4e7b57942f22ead9a01dd9012": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3490. Fixed MapReduce AM to count failed maps also towards Reduce ramp up. Contributed by Sharad Agarwal and Arun C Murthy.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1227226 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/01/12 9:10 AM",
      "commitName": "55e94dc5ef4171c4e7b57942f22ead9a01dd9012",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "20/12/11 3:27 PM",
      "commitNameOld": "e7543b944c2b35d0a1ca0a92efeca47ad414ac7a",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 14.74,
      "commitsBetweenForRepo": 34,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,74 +1,70 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AMResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     if (response.getReboot()) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                        JobEventType.INTERNAL_ERROR));\n       throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                this.getContext().getApplicationID());\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n     }\n \n     if (LOG.isDebugEnabled()) {\n       for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n       }\n     }\n \n     //Called on each allocation. Will know about newly blacklisted/added hosts.\n     computeIgnoreBlacklisting();\n     \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont);\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n-        if (attemptID.getTaskId().getTaskType().equals(TaskType.MAP)) {\n-          completedMaps++;\n-        } else {\n-          completedReduces++;\n-        }\n+        \n         // send the container completed event to Task attempt\n         eventHandler.handle(new TaskAttemptEvent(attemptID,\n             TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n         // Send the diagnostics\n         String diagnostics \u003d cont.getDiagnostics();\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AMResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getReboot()) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                       JobEventType.INTERNAL_ERROR));\n      throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                               this.getContext().getApplicationID());\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n    \n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont);\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        \n        // send the container completed event to Task attempt\n        eventHandler.handle(new TaskAttemptEvent(attemptID,\n            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n        // Send the diagnostics\n        String diagnostics \u003d cont.getDiagnostics();\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "e7543b944c2b35d0a1ca0a92efeca47ad414ac7a": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3339. Fixed MR AM to stop considering node blacklisting after the number of nodes blacklisted crosses a threshold. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1221523 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/12/11 3:27 PM",
      "commitName": "e7543b944c2b35d0a1ca0a92efeca47ad414ac7a",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "02/12/11 2:18 PM",
      "commitNameOld": "a3f37e15f75d01bb342480b0b1035ea16c5fd9aa",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 18.05,
      "commitsBetweenForRepo": 119,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,70 +1,74 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AMResponse response;\n     /*\n      * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n      * milliseconds before aborting. During this interval, AM will still try\n      * to contact the RM.\n      */\n     try {\n       response \u003d makeRemoteRequest();\n       // Reset retry count if no exception occurred.\n       retrystartTime \u003d System.currentTimeMillis();\n     } catch (Exception e) {\n       // This can happen when the connection to the RM has gone down. Keep\n       // re-trying until the retryInterval has expired.\n       if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n         eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                          JobEventType.INTERNAL_ERROR));\n         throw new YarnException(\"Could not contact RM after \" +\n                                 retryInterval + \" milliseconds.\");\n       }\n       // Throw this up to the caller, which may decide to ignore it and\n       // continue to attempt to contact the RM.\n       throw e;\n     }\n     if (response.getReboot()) {\n       // This can happen if the RM has been restarted. If it is in that state,\n       // this application must clean itself up.\n       eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                        JobEventType.INTERNAL_ERROR));\n       throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                                this.getContext().getApplicationID());\n     }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n     }\n-    \n-    List\u003cContainer\u003e allocatedContainers \u003d new ArrayList\u003cContainer\u003e();\n-    for (Container cont : newContainers) {\n-        allocatedContainers.add(cont);\n+\n+    if (LOG.isDebugEnabled()) {\n+      for (Container cont : newContainers) {\n         LOG.debug(\"Received new Container :\" + cont);\n+      }\n     }\n+\n+    //Called on each allocation. Will know about newly blacklisted/added hosts.\n+    computeIgnoreBlacklisting();\n+    \n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont);\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n         if (attemptID.getTaskId().getTaskType().equals(TaskType.MAP)) {\n           completedMaps++;\n         } else {\n           completedReduces++;\n         }\n         // send the container completed event to Task attempt\n         eventHandler.handle(new TaskAttemptEvent(attemptID,\n             TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n         // Send the diagnostics\n         String diagnostics \u003d cont.getDiagnostics();\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AMResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getReboot()) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                       JobEventType.INTERNAL_ERROR));\n      throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                               this.getContext().getApplicationID());\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n    }\n\n    if (LOG.isDebugEnabled()) {\n      for (Container cont : newContainers) {\n        LOG.debug(\"Received new Container :\" + cont);\n      }\n    }\n\n    //Called on each allocation. Will know about newly blacklisted/added hosts.\n    computeIgnoreBlacklisting();\n    \n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont);\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        if (attemptID.getTaskId().getTaskType().equals(TaskType.MAP)) {\n          completedMaps++;\n        } else {\n          completedReduces++;\n        }\n        // send the container completed event to Task attempt\n        eventHandler.handle(new TaskAttemptEvent(attemptID,\n            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n        // Send the diagnostics\n        String diagnostics \u003d cont.getDiagnostics();\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "b304062f1ffee078ea9575dcee5583d43e33508c": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3186. User jobs are getting hanged if the Resource manager process goes down and comes up while job is getting executed. (Eric Payne via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1190122 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/10/11 6:40 PM",
      "commitName": "b304062f1ffee078ea9575dcee5583d43e33508c",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "24/10/11 11:26 PM",
      "commitNameOld": "fffdf661e30afd10331d2153ff052c141b7ebe4b",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 2.8,
      "commitsBetweenForRepo": 42,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,70 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n-    AMResponse response \u003d makeRemoteRequest();\n+    AMResponse response;\n+    /*\n+     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n+     * milliseconds before aborting. During this interval, AM will still try\n+     * to contact the RM.\n+     */\n+    try {\n+      response \u003d makeRemoteRequest();\n+      // Reset retry count if no exception occurred.\n+      retrystartTime \u003d System.currentTimeMillis();\n+    } catch (Exception e) {\n+      // This can happen when the connection to the RM has gone down. Keep\n+      // re-trying until the retryInterval has expired.\n+      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n+        eventHandler.handle(new JobEvent(this.getJob().getID(),\n+                                         JobEventType.INTERNAL_ERROR));\n+        throw new YarnException(\"Could not contact RM after \" +\n+                                retryInterval + \" milliseconds.\");\n+      }\n+      // Throw this up to the caller, which may decide to ignore it and\n+      // continue to attempt to contact the RM.\n+      throw e;\n+    }\n+    if (response.getReboot()) {\n+      // This can happen if the RM has been restarted. If it is in that state,\n+      // this application must clean itself up.\n+      eventHandler.handle(new JobEvent(this.getJob().getID(),\n+                                       JobEventType.INTERNAL_ERROR));\n+      throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n+                               this.getContext().getApplicationID());\n+    }\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n     List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n     List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n     }\n     \n     List\u003cContainer\u003e allocatedContainers \u003d new ArrayList\u003cContainer\u003e();\n     for (Container cont : newContainers) {\n         allocatedContainers.add(cont);\n         LOG.debug(\"Received new Container :\" + cont);\n     }\n     for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont);\n       TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n             + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n         if (attemptID.getTaskId().getTaskType().equals(TaskType.MAP)) {\n           completedMaps++;\n         } else {\n           completedReduces++;\n         }\n         // send the container completed event to Task attempt\n         eventHandler.handle(new TaskAttemptEvent(attemptID,\n             TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n         // Send the diagnostics\n         String diagnostics \u003d cont.getDiagnostics();\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AMResponse response;\n    /*\n     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS\n     * milliseconds before aborting. During this interval, AM will still try\n     * to contact the RM.\n     */\n    try {\n      response \u003d makeRemoteRequest();\n      // Reset retry count if no exception occurred.\n      retrystartTime \u003d System.currentTimeMillis();\n    } catch (Exception e) {\n      // This can happen when the connection to the RM has gone down. Keep\n      // re-trying until the retryInterval has expired.\n      if (System.currentTimeMillis() - retrystartTime \u003e\u003d retryInterval) {\n        eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                         JobEventType.INTERNAL_ERROR));\n        throw new YarnException(\"Could not contact RM after \" +\n                                retryInterval + \" milliseconds.\");\n      }\n      // Throw this up to the caller, which may decide to ignore it and\n      // continue to attempt to contact the RM.\n      throw e;\n    }\n    if (response.getReboot()) {\n      // This can happen if the RM has been restarted. If it is in that state,\n      // this application must clean itself up.\n      eventHandler.handle(new JobEvent(this.getJob().getID(),\n                                       JobEventType.INTERNAL_ERROR));\n      throw new YarnException(\"Resource Manager doesn\u0027t recognize AttemptId: \" +\n                               this.getContext().getApplicationID());\n    }\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n    }\n    \n    List\u003cContainer\u003e allocatedContainers \u003d new ArrayList\u003cContainer\u003e();\n    for (Container cont : newContainers) {\n        allocatedContainers.add(cont);\n        LOG.debug(\"Received new Container :\" + cont);\n    }\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont);\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        if (attemptID.getTaskId().getTaskType().equals(TaskType.MAP)) {\n          completedMaps++;\n        } else {\n          completedReduces++;\n        }\n        // send the container completed event to Task attempt\n        eventHandler.handle(new TaskAttemptEvent(attemptID,\n            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n        // Send the diagnostics\n        String diagnostics \u003d cont.getDiagnostics();\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "817ead65b99f465fc2dfa18072cf23cadf5f05d0": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2933. Change allocate call to return ContainerStatus for completed containers rather than Container.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1169484 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/09/11 10:26 AM",
      "commitName": "817ead65b99f465fc2dfa18072cf23cadf5f05d0",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "08/09/11 6:44 PM",
      "commitNameOld": "fafe8cd28e726566509c679e19d7da622f29f90d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 2.65,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,40 @@\n   private List\u003cContainer\u003e getResources() throws Exception {\n     int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n     AMResponse response \u003d makeRemoteRequest();\n     int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n-    List\u003cContainer\u003e newContainers \u003d response.getNewContainerList();\n-    List\u003cContainer\u003e finishedContainers \u003d response.getFinishedContainerList();\n+    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n+    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n     if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n       //something changed\n       recalculateReduceSchedule \u003d true;\n     }\n     \n     List\u003cContainer\u003e allocatedContainers \u003d new ArrayList\u003cContainer\u003e();\n     for (Container cont : newContainers) {\n         allocatedContainers.add(cont);\n         LOG.debug(\"Received new Container :\" + cont);\n     }\n-    for (Container cont : finishedContainers) {\n+    for (ContainerStatus cont : finishedContainers) {\n       LOG.info(\"Received completed container \" + cont);\n-      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getId());\n+      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n       if (attemptID \u003d\u003d null) {\n         LOG.error(\"Container complete event for unknown container id \"\n-            + cont.getId());\n+            + cont.getContainerId());\n       } else {\n         assignedRequests.remove(attemptID);\n         if (attemptID.getTaskId().getTaskType().equals(TaskType.MAP)) {\n           completedMaps++;\n         } else {\n           completedReduces++;\n         }\n         // send the container completed event to Task attempt\n         eventHandler.handle(new TaskAttemptEvent(attemptID,\n             TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n         // Send the diagnostics\n-        String diagnostics \u003d cont.getContainerStatus().getDiagnostics();\n+        String diagnostics \u003d cont.getDiagnostics();\n         eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n             diagnostics));\n       }\n     }\n     return newContainers;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AMResponse response \u003d makeRemoteRequest();\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getAllocatedContainers();\n    List\u003cContainerStatus\u003e finishedContainers \u003d response.getCompletedContainersStatuses();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n    }\n    \n    List\u003cContainer\u003e allocatedContainers \u003d new ArrayList\u003cContainer\u003e();\n    for (Container cont : newContainers) {\n        allocatedContainers.add(cont);\n        LOG.debug(\"Received new Container :\" + cont);\n    }\n    for (ContainerStatus cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont);\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getContainerId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getContainerId());\n      } else {\n        assignedRequests.remove(attemptID);\n        if (attemptID.getTaskId().getTaskType().equals(TaskType.MAP)) {\n          completedMaps++;\n        } else {\n          completedReduces++;\n        }\n        // send the container completed event to Task attempt\n        eventHandler.handle(new TaskAttemptEvent(attemptID,\n            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n        // Send the diagnostics\n        String diagnostics \u003d cont.getDiagnostics();\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AMResponse response \u003d makeRemoteRequest();\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getNewContainerList();\n    List\u003cContainer\u003e finishedContainers \u003d response.getFinishedContainerList();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n    }\n    \n    List\u003cContainer\u003e allocatedContainers \u003d new ArrayList\u003cContainer\u003e();\n    for (Container cont : newContainers) {\n        allocatedContainers.add(cont);\n        LOG.debug(\"Received new Container :\" + cont);\n    }\n    for (Container cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont);\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getId());\n      } else {\n        assignedRequests.remove(attemptID);\n        if (attemptID.getTaskId().getTaskType().equals(TaskType.MAP)) {\n          completedMaps++;\n        } else {\n          completedReduces++;\n        }\n        // send the container completed event to Task attempt\n        eventHandler.handle(new TaskAttemptEvent(attemptID,\n            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n        // Send the diagnostics\n        String diagnostics \u003d cont.getContainerStatus().getDiagnostics();\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,40 @@\n+  private List\u003cContainer\u003e getResources() throws Exception {\n+    int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n+    AMResponse response \u003d makeRemoteRequest();\n+    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n+    List\u003cContainer\u003e newContainers \u003d response.getNewContainerList();\n+    List\u003cContainer\u003e finishedContainers \u003d response.getFinishedContainerList();\n+    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n+      //something changed\n+      recalculateReduceSchedule \u003d true;\n+    }\n+    \n+    List\u003cContainer\u003e allocatedContainers \u003d new ArrayList\u003cContainer\u003e();\n+    for (Container cont : newContainers) {\n+        allocatedContainers.add(cont);\n+        LOG.debug(\"Received new Container :\" + cont);\n+    }\n+    for (Container cont : finishedContainers) {\n+      LOG.info(\"Received completed container \" + cont);\n+      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getId());\n+      if (attemptID \u003d\u003d null) {\n+        LOG.error(\"Container complete event for unknown container id \"\n+            + cont.getId());\n+      } else {\n+        assignedRequests.remove(attemptID);\n+        if (attemptID.getTaskId().getTaskType().equals(TaskType.MAP)) {\n+          completedMaps++;\n+        } else {\n+          completedReduces++;\n+        }\n+        // send the container completed event to Task attempt\n+        eventHandler.handle(new TaskAttemptEvent(attemptID,\n+            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n+        // Send the diagnostics\n+        String diagnostics \u003d cont.getContainerStatus().getDiagnostics();\n+        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n+            diagnostics));\n+      }\n+    }\n+    return newContainers;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private List\u003cContainer\u003e getResources() throws Exception {\n    int headRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;//first time it would be null\n    AMResponse response \u003d makeRemoteRequest();\n    int newHeadRoom \u003d getAvailableResources() !\u003d null ? getAvailableResources().getMemory() : 0;\n    List\u003cContainer\u003e newContainers \u003d response.getNewContainerList();\n    List\u003cContainer\u003e finishedContainers \u003d response.getFinishedContainerList();\n    if (newContainers.size() + finishedContainers.size() \u003e 0 || headRoom !\u003d newHeadRoom) {\n      //something changed\n      recalculateReduceSchedule \u003d true;\n    }\n    \n    List\u003cContainer\u003e allocatedContainers \u003d new ArrayList\u003cContainer\u003e();\n    for (Container cont : newContainers) {\n        allocatedContainers.add(cont);\n        LOG.debug(\"Received new Container :\" + cont);\n    }\n    for (Container cont : finishedContainers) {\n      LOG.info(\"Received completed container \" + cont);\n      TaskAttemptId attemptID \u003d assignedRequests.get(cont.getId());\n      if (attemptID \u003d\u003d null) {\n        LOG.error(\"Container complete event for unknown container id \"\n            + cont.getId());\n      } else {\n        assignedRequests.remove(attemptID);\n        if (attemptID.getTaskId().getTaskType().equals(TaskType.MAP)) {\n          completedMaps++;\n        } else {\n          completedReduces++;\n        }\n        // send the container completed event to Task attempt\n        eventHandler.handle(new TaskAttemptEvent(attemptID,\n            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n        // Send the diagnostics\n        String diagnostics \u003d cont.getContainerStatus().getDiagnostics();\n        eventHandler.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,\n            diagnostics));\n      }\n    }\n    return newContainers;\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java"
    }
  }
}