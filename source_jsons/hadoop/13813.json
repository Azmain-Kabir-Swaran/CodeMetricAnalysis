{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "markBlockAsCorrupt",
  "functionId": "markBlockAsCorrupt___b-BlockToMarkCorrupt__storageInfo-DatanodeStorageInfo__node-DatanodeDescriptor",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 1813,
  "functionEndLine": 1865,
  "numCommitsSeen": 617,
  "timeTaken": 19367,
  "changeHistory": [
    "d737bf99d44ce34cd01baad716d23df269267c95",
    "8c84a2a93c22a93b4ff46dd917f6efb995675fbd",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
    "715b9c649982bff91d1f9eae656ba3b82178e1a3",
    "6d12cd8d609dec26d44cece9937c35b7d72a3cd1",
    "035ed26147f10620fc6ed3a514d9ebbcc31304b5",
    "4e9307f26dd41270f95fb50166e1a091852e4d58",
    "745d04be59accf80feda0ad38efcc74ba362f2ca",
    "663eba0ab1c73b45f98e46ffc87ad8fd91584046",
    "d311a38a6b32bbb210bd8748cfb65463e9c0740e",
    "f32d9a175837c5b6c3d008089e46475d27a0935c",
    "bc99aaffe7b0ed13b1efc37b6a32cdbd344c2d75",
    "d62b63d297bff12d93de560dd50ddd48743b851d",
    "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5",
    "b008348dbf9bdd5070930be5d182116c5d370f6b",
    "abf833a7b228fff2bca4f69cd9df99d532380038",
    "1e1e93040748231dc913190aec1e031c379d8271",
    "ba9371492036983a9899398907ab41fe548f29b3",
    "6d5da9484185ca9f585195d6da069b9cd5be4044",
    "997408eaaceef20b053ee7344468e28cb9a1379b",
    "3ae38ec7dfa1aaf451cf889cec6cf862379af32a",
    "45db4d204b796eee6dd0e39d3cc94b70c47028d4",
    "be01103af7e60fededeb76fa60776edc3f7018fa",
    "e5d6fba47d9c6f4d984ca8295fcf5dee388e2241"
  ],
  "changeHistoryShort": {
    "d737bf99d44ce34cd01baad716d23df269267c95": "Ybodychange",
    "8c84a2a93c22a93b4ff46dd917f6efb995675fbd": "Ybodychange",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": "Ybodychange",
    "715b9c649982bff91d1f9eae656ba3b82178e1a3": "Ybodychange",
    "6d12cd8d609dec26d44cece9937c35b7d72a3cd1": "Ybodychange",
    "035ed26147f10620fc6ed3a514d9ebbcc31304b5": "Ybodychange",
    "4e9307f26dd41270f95fb50166e1a091852e4d58": "Ybodychange",
    "745d04be59accf80feda0ad38efcc74ba362f2ca": "Ybodychange",
    "663eba0ab1c73b45f98e46ffc87ad8fd91584046": "Ybodychange",
    "d311a38a6b32bbb210bd8748cfb65463e9c0740e": "Ybodychange",
    "f32d9a175837c5b6c3d008089e46475d27a0935c": "Ybodychange",
    "bc99aaffe7b0ed13b1efc37b6a32cdbd344c2d75": "Ybodychange",
    "d62b63d297bff12d93de560dd50ddd48743b851d": "Ybodychange",
    "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5": "Ybodychange",
    "b008348dbf9bdd5070930be5d182116c5d370f6b": "Ybodychange",
    "abf833a7b228fff2bca4f69cd9df99d532380038": "Ybodychange",
    "1e1e93040748231dc913190aec1e031c379d8271": "Ybodychange",
    "ba9371492036983a9899398907ab41fe548f29b3": "Ybodychange",
    "6d5da9484185ca9f585195d6da069b9cd5be4044": "Ybodychange",
    "997408eaaceef20b053ee7344468e28cb9a1379b": "Ybodychange",
    "3ae38ec7dfa1aaf451cf889cec6cf862379af32a": "Ybodychange",
    "45db4d204b796eee6dd0e39d3cc94b70c47028d4": "Ymultichange(Yparameterchange,Ybodychange)",
    "be01103af7e60fededeb76fa60776edc3f7018fa": "Ybodychange",
    "e5d6fba47d9c6f4d984ca8295fcf5dee388e2241": "Ybodychange"
  },
  "changeHistoryDetails": {
    "d737bf99d44ce34cd01baad716d23df269267c95": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13350. Negative legacy block ID will confuse Erasure Coding to be considered as striped block. (Contributed by Lei (Eddy) Xu).\n",
      "commitDate": "05/04/18 9:59 AM",
      "commitName": "d737bf99d44ce34cd01baad716d23df269267c95",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "16/03/18 10:29 AM",
      "commitNameOld": "08ff1586d5d3e39f546200f9e696f62ea4cf000d",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 19.98,
      "commitsBetweenForRepo": 236,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,53 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n     if (b.getStored().isDeleted()) {\n       blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.getCorrupted(), node);\n       return;\n     }\n     short expectedRedundancies \u003d\n         getExpectedRedundancyNum(b.getStored());\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n       storageInfo.addBlock(b.getStored(), b.getCorrupted());\n     }\n \n     // Add this replica to corruptReplicas Map. For striped blocks, we always\n     // use the id of whole striped block group when adding to corruptReplicas\n     Block corrupted \u003d new Block(b.getCorrupted());\n     if (b.getStored().isStriped()) {\n       corrupted.setBlockId(b.getStored().getBlockId());\n     }\n     corruptReplicas.addToCorruptReplicasMap(corrupted, node, b.getReason(),\n-        b.getReasonCode());\n+        b.getReasonCode(), b.getStored().isStriped());\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.getStored());\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedRedundancies;\n \n     boolean minReplicationSatisfied \u003d hasMinStorage(b.getStored(),\n         numberOfReplicas.liveReplicas());\n \n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedRedundancies;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         b.isCorruptedDuringWrite();\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node, numberOfReplicas);\n     } else if (isPopulatingReplQueues()) {\n       // add the block to neededReconstruction\n       updateNeededReconstructions(b.getStored(), -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n    if (b.getStored().isDeleted()) {\n      blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.getCorrupted(), node);\n      return;\n    }\n    short expectedRedundancies \u003d\n        getExpectedRedundancyNum(b.getStored());\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.getStored(), b.getCorrupted());\n    }\n\n    // Add this replica to corruptReplicas Map. For striped blocks, we always\n    // use the id of whole striped block group when adding to corruptReplicas\n    Block corrupted \u003d new Block(b.getCorrupted());\n    if (b.getStored().isStriped()) {\n      corrupted.setBlockId(b.getStored().getBlockId());\n    }\n    corruptReplicas.addToCorruptReplicasMap(corrupted, node, b.getReason(),\n        b.getReasonCode(), b.getStored().isStriped());\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.getStored());\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedRedundancies;\n\n    boolean minReplicationSatisfied \u003d hasMinStorage(b.getStored(),\n        numberOfReplicas.liveReplicas());\n\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedRedundancies;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        b.isCorruptedDuringWrite();\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node, numberOfReplicas);\n    } else if (isPopulatingReplQueues()) {\n      // add the block to neededReconstruction\n      updateNeededReconstructions(b.getStored(), -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "8c84a2a93c22a93b4ff46dd917f6efb995675fbd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10236. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-3]. Contributed by Rakesh R.\n",
      "commitDate": "26/05/16 4:50 PM",
      "commitName": "8c84a2a93c22a93b4ff46dd917f6efb995675fbd",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "28/04/16 10:44 AM",
      "commitNameOld": "6243eabb48390fffada2418ade5adf9e0766afbe",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 28.25,
      "commitsBetweenForRepo": 196,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,53 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n     if (b.getStored().isDeleted()) {\n       blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.getCorrupted(), node);\n       return;\n     }\n-    short expectedReplicas \u003d\n-        getExpectedReplicaNum(b.getStored());\n+    short expectedRedundancies \u003d\n+        getExpectedRedundancyNum(b.getStored());\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n       storageInfo.addBlock(b.getStored(), b.getCorrupted());\n     }\n \n     // Add this replica to corruptReplicas Map. For striped blocks, we always\n     // use the id of whole striped block group when adding to corruptReplicas\n     Block corrupted \u003d new Block(b.getCorrupted());\n     if (b.getStored().isStriped()) {\n       corrupted.setBlockId(b.getStored().getBlockId());\n     }\n     corruptReplicas.addToCorruptReplicasMap(corrupted, node, b.getReason(),\n         b.getReasonCode());\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.getStored());\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n-        expectedReplicas;\n+        expectedRedundancies;\n \n     boolean minReplicationSatisfied \u003d hasMinStorage(b.getStored(),\n         numberOfReplicas.liveReplicas());\n \n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n-        expectedReplicas;\n+        expectedRedundancies;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         b.isCorruptedDuringWrite();\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node, numberOfReplicas);\n     } else if (isPopulatingReplQueues()) {\n       // add the block to neededReconstruction\n       updateNeededReconstructions(b.getStored(), -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n    if (b.getStored().isDeleted()) {\n      blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.getCorrupted(), node);\n      return;\n    }\n    short expectedRedundancies \u003d\n        getExpectedRedundancyNum(b.getStored());\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.getStored(), b.getCorrupted());\n    }\n\n    // Add this replica to corruptReplicas Map. For striped blocks, we always\n    // use the id of whole striped block group when adding to corruptReplicas\n    Block corrupted \u003d new Block(b.getCorrupted());\n    if (b.getStored().isStriped()) {\n      corrupted.setBlockId(b.getStored().getBlockId());\n    }\n    corruptReplicas.addToCorruptReplicasMap(corrupted, node, b.getReason(),\n        b.getReasonCode());\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.getStored());\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedRedundancies;\n\n    boolean minReplicationSatisfied \u003d hasMinStorage(b.getStored(),\n        numberOfReplicas.liveReplicas());\n\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedRedundancies;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        b.isCorruptedDuringWrite();\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node, numberOfReplicas);\n    } else if (isPopulatingReplQueues()) {\n      // add the block to neededReconstruction\n      updateNeededReconstructions(b.getStored(), -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9857. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-1]. Contributed by Rakesh R.\n",
      "commitDate": "16/03/16 4:53 PM",
      "commitName": "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "10/03/16 7:03 PM",
      "commitNameOld": "e01c6ea688e62f25c4310e771a0cd85b53a5fb87",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 5.87,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,53 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n     if (b.getStored().isDeleted()) {\n       blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.getCorrupted(), node);\n       return;\n     }\n     short expectedReplicas \u003d\n         getExpectedReplicaNum(b.getStored());\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n       storageInfo.addBlock(b.getStored(), b.getCorrupted());\n     }\n \n     // Add this replica to corruptReplicas Map. For striped blocks, we always\n     // use the id of whole striped block group when adding to corruptReplicas\n     Block corrupted \u003d new Block(b.getCorrupted());\n     if (b.getStored().isStriped()) {\n       corrupted.setBlockId(b.getStored().getBlockId());\n     }\n     corruptReplicas.addToCorruptReplicasMap(corrupted, node, b.getReason(),\n         b.getReasonCode());\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.getStored());\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedReplicas;\n \n     boolean minReplicationSatisfied \u003d hasMinStorage(b.getStored(),\n         numberOfReplicas.liveReplicas());\n \n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         b.isCorruptedDuringWrite();\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node, numberOfReplicas);\n     } else if (isPopulatingReplQueues()) {\n-      // add the block to neededReplication\n-      updateNeededReplications(b.getStored(), -1, 0);\n+      // add the block to neededReconstruction\n+      updateNeededReconstructions(b.getStored(), -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n    if (b.getStored().isDeleted()) {\n      blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.getCorrupted(), node);\n      return;\n    }\n    short expectedReplicas \u003d\n        getExpectedReplicaNum(b.getStored());\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.getStored(), b.getCorrupted());\n    }\n\n    // Add this replica to corruptReplicas Map. For striped blocks, we always\n    // use the id of whole striped block group when adding to corruptReplicas\n    Block corrupted \u003d new Block(b.getCorrupted());\n    if (b.getStored().isStriped()) {\n      corrupted.setBlockId(b.getStored().getBlockId());\n    }\n    corruptReplicas.addToCorruptReplicasMap(corrupted, node, b.getReason(),\n        b.getReasonCode());\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.getStored());\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n\n    boolean minReplicationSatisfied \u003d hasMinStorage(b.getStored(),\n        numberOfReplicas.liveReplicas());\n\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        b.isCorruptedDuringWrite();\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node, numberOfReplicas);\n    } else if (isPopulatingReplQueues()) {\n      // add the block to neededReconstruction\n      updateNeededReconstructions(b.getStored(), -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "715b9c649982bff91d1f9eae656ba3b82178e1a3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8984. Move replication queues related methods in FSNamesystem to BlockManager. Contributed by Haohui Mai.\n",
      "commitDate": "04/09/15 11:45 AM",
      "commitName": "715b9c649982bff91d1f9eae656ba3b82178e1a3",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "02/09/15 1:46 PM",
      "commitNameOld": "afc88b396f06488c331564e0f6987013bb920d3e",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 1.92,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,46 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n     if (b.getCorrupted().isDeleted()) {\n       blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.getCorrupted(), node);\n       return;\n     } \n     short expectedReplicas \u003d b.getCorrupted().getReplication();\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n       storageInfo.addBlock(b.getStored());\n     }\n \n     // Add this replica to corruptReplicas Map\n     corruptReplicas.addToCorruptReplicasMap(b.getCorrupted(), node,\n         b.getReason(), b.getReasonCode());\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.getStored());\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedReplicas;\n     boolean minReplicationSatisfied \u003d\n         numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         b.isCorruptedDuringWrite();\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n-    } else if (namesystem.isPopulatingReplQueues()) {\n+    } else if (isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.getStored(), -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    if (b.getCorrupted().isDeleted()) {\n      blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.getCorrupted(), node);\n      return;\n    } \n    short expectedReplicas \u003d b.getCorrupted().getReplication();\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.getStored());\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.getCorrupted(), node,\n        b.getReason(), b.getReasonCode());\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.getStored());\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n    boolean minReplicationSatisfied \u003d\n        numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        b.isCorruptedDuringWrite();\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.getStored(), -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "6d12cd8d609dec26d44cece9937c35b7d72a3cd1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8938. Extract BlockToMarkCorrupt and ReplicationWork as standalone classes from BlockManager. Contributed by Mingliang Liu.\n",
      "commitDate": "28/08/15 2:14 PM",
      "commitName": "6d12cd8d609dec26d44cece9937c35b7d72a3cd1",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "27/08/15 4:09 PM",
      "commitNameOld": "035ed26147f10620fc6ed3a514d9ebbcc31304b5",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.92,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,46 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n-    if (b.corrupted.isDeleted()) {\n+    if (b.getCorrupted().isDeleted()) {\n       blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n-      addToInvalidates(b.corrupted, node);\n+      addToInvalidates(b.getCorrupted(), node);\n       return;\n     } \n-    short expectedReplicas \u003d b.corrupted.getReplication();\n+    short expectedReplicas \u003d b.getCorrupted().getReplication();\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n-      storageInfo.addBlock(b.stored);\n+      storageInfo.addBlock(b.getStored());\n     }\n \n     // Add this replica to corruptReplicas Map\n-    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n-        b.reasonCode);\n+    corruptReplicas.addToCorruptReplicasMap(b.getCorrupted(), node,\n+        b.getReason(), b.getReasonCode());\n \n-    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n+    NumberReplicas numberOfReplicas \u003d countNodes(b.getStored());\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedReplicas;\n     boolean minReplicationSatisfied \u003d\n         numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n-        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n+        b.isCorruptedDuringWrite();\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n-      updateNeededReplications(b.stored, -1, 0);\n+      updateNeededReplications(b.getStored(), -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    if (b.getCorrupted().isDeleted()) {\n      blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.getCorrupted(), node);\n      return;\n    } \n    short expectedReplicas \u003d b.getCorrupted().getReplication();\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.getStored());\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.getCorrupted(), node,\n        b.getReason(), b.getReasonCode());\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.getStored());\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n    boolean minReplicationSatisfied \u003d\n        numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        b.isCorruptedDuringWrite();\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.getStored(), -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "035ed26147f10620fc6ed3a514d9ebbcc31304b5": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-8938. Extract BlockToMarkCorrupt and ReplicationWork as standalone classes from BlockManager. Contributed by Mingliang Liu.\"\n\nThis reverts commit 4e9307f26dd41270f95fb50166e1a091852e4d58.\n",
      "commitDate": "27/08/15 4:09 PM",
      "commitName": "035ed26147f10620fc6ed3a514d9ebbcc31304b5",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "27/08/15 3:36 PM",
      "commitNameOld": "4e9307f26dd41270f95fb50166e1a091852e4d58",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,46 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n-    if (b.getCorrupted().isDeleted()) {\n+    if (b.corrupted.isDeleted()) {\n       blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n-      addToInvalidates(b.getCorrupted(), node);\n+      addToInvalidates(b.corrupted, node);\n       return;\n     } \n-    short expectedReplicas \u003d b.getCorrupted().getReplication();\n+    short expectedReplicas \u003d b.corrupted.getReplication();\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n-      storageInfo.addBlock(b.getStored());\n+      storageInfo.addBlock(b.stored);\n     }\n \n     // Add this replica to corruptReplicas Map\n-    corruptReplicas.addToCorruptReplicasMap(b.getCorrupted(), node,\n-        b.getReason(), b.getReasonCode());\n+    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n+        b.reasonCode);\n \n-    NumberReplicas numberOfReplicas \u003d countNodes(b.getStored());\n+    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedReplicas;\n     boolean minReplicationSatisfied \u003d\n         numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n-        b.isCorruptedDuringWrite();\n+        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n-      updateNeededReplications(b.getStored(), -1, 0);\n+      updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    if (b.corrupted.isDeleted()) {\n      blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n    short expectedReplicas \u003d b.corrupted.getReplication();\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.stored);\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n    boolean minReplicationSatisfied \u003d\n        numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "4e9307f26dd41270f95fb50166e1a091852e4d58": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8938. Extract BlockToMarkCorrupt and ReplicationWork as standalone classes from BlockManager. Contributed by Mingliang Liu.\n",
      "commitDate": "27/08/15 3:36 PM",
      "commitName": "4e9307f26dd41270f95fb50166e1a091852e4d58",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/08/15 6:14 PM",
      "commitNameOld": "4cbbfa2220e884e91bf18ad1cc2f3b11f895f8c9",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.89,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,46 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n-    if (b.corrupted.isDeleted()) {\n+    if (b.getCorrupted().isDeleted()) {\n       blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n-      addToInvalidates(b.corrupted, node);\n+      addToInvalidates(b.getCorrupted(), node);\n       return;\n     } \n-    short expectedReplicas \u003d b.corrupted.getReplication();\n+    short expectedReplicas \u003d b.getCorrupted().getReplication();\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n-      storageInfo.addBlock(b.stored);\n+      storageInfo.addBlock(b.getStored());\n     }\n \n     // Add this replica to corruptReplicas Map\n-    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n-        b.reasonCode);\n+    corruptReplicas.addToCorruptReplicasMap(b.getCorrupted(), node,\n+        b.getReason(), b.getReasonCode());\n \n-    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n+    NumberReplicas numberOfReplicas \u003d countNodes(b.getStored());\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedReplicas;\n     boolean minReplicationSatisfied \u003d\n         numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n-        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n+        b.isCorruptedDuringWrite();\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n-      updateNeededReplications(b.stored, -1, 0);\n+      updateNeededReplications(b.getStored(), -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    if (b.getCorrupted().isDeleted()) {\n      blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.getCorrupted(), node);\n      return;\n    } \n    short expectedReplicas \u003d b.getCorrupted().getReplication();\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.getStored());\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.getCorrupted(), node,\n        b.getReason(), b.getReasonCode());\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.getStored());\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n    boolean minReplicationSatisfied \u003d\n        numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        b.isCorruptedDuringWrite();\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.getStored(), -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "745d04be59accf80feda0ad38efcc74ba362f2ca": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8823. Move replication factor into individual blocks. Contributed by Haohui Mai.\n",
      "commitDate": "22/08/15 12:09 AM",
      "commitName": "745d04be59accf80feda0ad38efcc74ba362f2ca",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "19/08/15 3:11 PM",
      "commitNameOld": "4e14f7982a6e57bf08deb3b266806c2b779a157d",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 2.37,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,46 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n     if (b.corrupted.isDeleted()) {\n       blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n-    short expectedReplicas \u003d\n-        b.corrupted.getBlockCollection().getPreferredBlockReplication();\n+    short expectedReplicas \u003d b.corrupted.getReplication();\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n       storageInfo.addBlock(b.stored);\n     }\n \n     // Add this replica to corruptReplicas Map\n     corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n         b.reasonCode);\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedReplicas;\n     boolean minReplicationSatisfied \u003d\n         numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    if (b.corrupted.isDeleted()) {\n      blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n    short expectedReplicas \u003d b.corrupted.getReplication();\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.stored);\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n    boolean minReplicationSatisfied \u003d\n        numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "663eba0ab1c73b45f98e46ffc87ad8fd91584046": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-8623. Refactor NameNode handling of invalid, corrupt, and under-recovery blocks. Contributed by Zhe Zhang.\"\n\nThis reverts commit de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5.\n",
      "commitDate": "06/08/15 10:21 AM",
      "commitName": "663eba0ab1c73b45f98e46ffc87ad8fd91584046",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "31/07/15 4:15 PM",
      "commitNameOld": "d311a38a6b32bbb210bd8748cfb65463e9c0740e",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 5.75,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,47 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n-    if (b.stored.isDeleted()) {\n+    if (b.corrupted.isDeleted()) {\n       blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n     short expectedReplicas \u003d\n-        getExpectedReplicaNum(b.stored.getBlockCollection(), b.stored);\n+        b.corrupted.getBlockCollection().getPreferredBlockReplication();\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n-      storageInfo.addBlock(b.stored, b.corrupted);\n+      storageInfo.addBlock(b.stored);\n     }\n \n     // Add this replica to corruptReplicas Map\n     corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n         b.reasonCode);\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedReplicas;\n-    boolean minReplicationSatisfied \u003d hasMinStorage(b.stored,\n-        numberOfReplicas.liveReplicas());\n+    boolean minReplicationSatisfied \u003d\n+        numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    if (b.corrupted.isDeleted()) {\n      blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n    short expectedReplicas \u003d\n        b.corrupted.getBlockCollection().getPreferredBlockReplication();\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.stored);\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n    boolean minReplicationSatisfied \u003d\n        numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "d311a38a6b32bbb210bd8748cfb65463e9c0740e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6860. BlockStateChange logs are too noisy. Contributed by Chang Li and Xiaoyu Yao.\n",
      "commitDate": "31/07/15 4:15 PM",
      "commitName": "d311a38a6b32bbb210bd8748cfb65463e9c0740e",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "29/07/15 12:48 AM",
      "commitNameOld": "2a1d656196cf9750fa482cb10893684e8a2ce7c3",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 2.64,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,47 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n     if (b.stored.isDeleted()) {\n-      blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n+      blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n     short expectedReplicas \u003d\n         getExpectedReplicaNum(b.stored.getBlockCollection(), b.stored);\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n       storageInfo.addBlock(b.stored, b.corrupted);\n     }\n \n     // Add this replica to corruptReplicas Map\n     corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n         b.reasonCode);\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedReplicas;\n     boolean minReplicationSatisfied \u003d hasMinStorage(b.stored,\n         numberOfReplicas.liveReplicas());\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    if (b.stored.isDeleted()) {\n      blockLog.debug(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n    short expectedReplicas \u003d\n        getExpectedReplicaNum(b.stored.getBlockCollection(), b.stored);\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.stored, b.corrupted);\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n    boolean minReplicationSatisfied \u003d hasMinStorage(b.stored,\n        numberOfReplicas.liveReplicas());\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "f32d9a175837c5b6c3d008089e46475d27a0935c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8619. Erasure Coding: revisit replica counting for striped blocks. (Jing Zhao via yliu)\n",
      "commitDate": "15/07/15 7:35 AM",
      "commitName": "f32d9a175837c5b6c3d008089e46475d27a0935c",
      "commitAuthor": "yliu",
      "commitDateOld": "14/07/15 10:55 AM",
      "commitNameOld": "6ff957be88d48a8b41e9fcbe4cf466d672cd7bc1",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.86,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,54 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n     if (b.stored.isDeleted()) {\n       blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n     short expectedReplicas \u003d\n         getExpectedReplicaNum(b.stored.getBlockCollection(), b.stored);\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n       storageInfo.addBlock(b.stored, b.corrupted);\n     }\n \n-    // Add this replica to corruptReplicas Map\n-    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n+    // Add this replica to corruptReplicas Map. For striped blocks, we always\n+    // use the id of whole striped block group when adding to corruptReplicas\n+    Block corrupted \u003d new Block(b.corrupted);\n+    if (b.stored.isStriped()) {\n+      corrupted.setBlockId(b.stored.getBlockId());\n+    }\n+    corruptReplicas.addToCorruptReplicasMap(corrupted, node, b.reason,\n         b.reasonCode);\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedReplicas;\n \n     boolean minReplicationSatisfied \u003d hasMinStorage(b.stored,\n         numberOfReplicas.liveReplicas());\n \n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n-      invalidateBlock(b, node);\n+      invalidateBlock(b, node, numberOfReplicas);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    if (b.stored.isDeleted()) {\n      blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n    short expectedReplicas \u003d\n        getExpectedReplicaNum(b.stored.getBlockCollection(), b.stored);\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.stored, b.corrupted);\n    }\n\n    // Add this replica to corruptReplicas Map. For striped blocks, we always\n    // use the id of whole striped block group when adding to corruptReplicas\n    Block corrupted \u003d new Block(b.corrupted);\n    if (b.stored.isStriped()) {\n      corrupted.setBlockId(b.stored.getBlockId());\n    }\n    corruptReplicas.addToCorruptReplicasMap(corrupted, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n\n    boolean minReplicationSatisfied \u003d hasMinStorage(b.stored,\n        numberOfReplicas.liveReplicas());\n\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node, numberOfReplicas);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "bc99aaffe7b0ed13b1efc37b6a32cdbd344c2d75": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-8652. Track BlockInfo instead of Block in CorruptReplicasMap. Contributed by Jing Zhao.\"\n\nThis reverts commit d62b63d297bff12d93de560dd50ddd48743b851d.\n",
      "commitDate": "07/07/15 10:13 AM",
      "commitName": "bc99aaffe7b0ed13b1efc37b6a32cdbd344c2d75",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "06/07/15 3:54 PM",
      "commitNameOld": "d62b63d297bff12d93de560dd50ddd48743b851d",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.76,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,47 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n     if (b.stored.isDeleted()) {\n       blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n     short expectedReplicas \u003d\n         getExpectedReplicaNum(b.stored.getBlockCollection(), b.stored);\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n       storageInfo.addBlock(b.stored, b.corrupted);\n     }\n \n     // Add this replica to corruptReplicas Map\n-    corruptReplicas.addToCorruptReplicasMap(b.stored, node, b.reason,\n+    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n         b.reasonCode);\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedReplicas;\n     boolean minReplicationSatisfied \u003d hasMinStorage(b.stored,\n         numberOfReplicas.liveReplicas());\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n-      invalidateBlock(b, node, numberOfReplicas);\n+      invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    if (b.stored.isDeleted()) {\n      blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n    short expectedReplicas \u003d\n        getExpectedReplicaNum(b.stored.getBlockCollection(), b.stored);\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.stored, b.corrupted);\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n    boolean minReplicationSatisfied \u003d hasMinStorage(b.stored,\n        numberOfReplicas.liveReplicas());\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "d62b63d297bff12d93de560dd50ddd48743b851d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8652. Track BlockInfo instead of Block in CorruptReplicasMap. Contributed by Jing Zhao.\n",
      "commitDate": "06/07/15 3:54 PM",
      "commitName": "d62b63d297bff12d93de560dd50ddd48743b851d",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "29/06/15 11:00 AM",
      "commitNameOld": "d3fed8e653ed9e18d3a29a11c4b24a628ac770bb",
      "commitAuthorOld": "Benoy Antony",
      "daysBetweenCommits": 7.2,
      "commitsBetweenForRepo": 50,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,47 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n     if (b.stored.isDeleted()) {\n       blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n     short expectedReplicas \u003d\n         getExpectedReplicaNum(b.stored.getBlockCollection(), b.stored);\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n       storageInfo.addBlock(b.stored, b.corrupted);\n     }\n \n     // Add this replica to corruptReplicas Map\n-    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n+    corruptReplicas.addToCorruptReplicasMap(b.stored, node, b.reason,\n         b.reasonCode);\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedReplicas;\n     boolean minReplicationSatisfied \u003d hasMinStorage(b.stored,\n         numberOfReplicas.liveReplicas());\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n-      invalidateBlock(b, node);\n+      invalidateBlock(b, node, numberOfReplicas);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    if (b.stored.isDeleted()) {\n      blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n    short expectedReplicas \u003d\n        getExpectedReplicaNum(b.stored.getBlockCollection(), b.stored);\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.stored, b.corrupted);\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.stored, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n    boolean minReplicationSatisfied \u003d hasMinStorage(b.stored,\n        numberOfReplicas.liveReplicas());\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node, numberOfReplicas);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8623. Refactor NameNode handling of invalid, corrupt, and under-recovery blocks. Contributed by Zhe Zhang.\n",
      "commitDate": "26/06/15 10:49 AM",
      "commitName": "de480d6c8945bd8b5b00e8657b7a72ce8dd9b6b5",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "24/06/15 2:42 PM",
      "commitNameOld": "afe9ea3c12e1f5a71922400eadb642960bc87ca1",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 1.84,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,47 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n-    if (b.corrupted.isDeleted()) {\n+    if (b.stored.isDeleted()) {\n       blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n     short expectedReplicas \u003d\n-        b.corrupted.getBlockCollection().getPreferredBlockReplication();\n+        getExpectedReplicaNum(b.stored.getBlockCollection(), b.stored);\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n-      storageInfo.addBlock(b.stored);\n+      storageInfo.addBlock(b.stored, b.corrupted);\n     }\n \n     // Add this replica to corruptReplicas Map\n     corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n         b.reasonCode);\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedReplicas;\n-    boolean minReplicationSatisfied \u003d\n-        numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n+    boolean minReplicationSatisfied \u003d hasMinStorage(b.stored,\n+        numberOfReplicas.liveReplicas());\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    if (b.stored.isDeleted()) {\n      blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n    short expectedReplicas \u003d\n        getExpectedReplicaNum(b.stored.getBlockCollection(), b.stored);\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.stored, b.corrupted);\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n    boolean minReplicationSatisfied \u003d hasMinStorage(b.stored,\n        numberOfReplicas.liveReplicas());\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "b008348dbf9bdd5070930be5d182116c5d370f6b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8418. Fix the isNeededReplication calculation for Striped block in NN. Contributed by Yi Liu.\n",
      "commitDate": "26/05/15 12:02 PM",
      "commitName": "b008348dbf9bdd5070930be5d182116c5d370f6b",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "26/05/15 12:02 PM",
      "commitNameOld": "d8ea443af0b1c8289a1dd738945831ff8be0e9c1",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,49 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n     if (b.stored.isDeleted()) {\n       blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n     short expectedReplicas \u003d\n-        b.stored.getBlockCollection().getPreferredBlockReplication();\n+        getExpectedReplicaNum(b.stored.getBlockCollection(), b.stored);\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n       storageInfo.addBlock(b.stored, b.corrupted);\n     }\n \n     // Add this replica to corruptReplicas Map\n     corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n         b.reasonCode);\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedReplicas;\n \n     boolean minReplicationSatisfied \u003d hasMinStorage(b.stored,\n         numberOfReplicas.liveReplicas());\n \n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    if (b.stored.isDeleted()) {\n      blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n    short expectedReplicas \u003d\n        getExpectedReplicaNum(b.stored.getBlockCollection(), b.stored);\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.stored, b.corrupted);\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n\n    boolean minReplicationSatisfied \u003d hasMinStorage(b.stored,\n        numberOfReplicas.liveReplicas());\n\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "abf833a7b228fff2bca4f69cd9df99d532380038": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7907. Erasure Coding: track invalid, corrupt, and under-recovery striped blocks in NameNode. Contributed by Jing Zhao.\n",
      "commitDate": "26/05/15 11:43 AM",
      "commitName": "abf833a7b228fff2bca4f69cd9df99d532380038",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "26/05/15 11:43 AM",
      "commitNameOld": "ea2e60fbcc79c65ec571224bd3f57c262a5d9114",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,49 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n-    if (b.corrupted.isDeleted()) {\n+    if (b.stored.isDeleted()) {\n       blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n     short expectedReplicas \u003d\n-        b.corrupted.getBlockCollection().getPreferredBlockReplication();\n+        b.stored.getBlockCollection().getPreferredBlockReplication();\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n-      storageInfo.addBlock(b.stored, b.reportedBlock);\n+      storageInfo.addBlock(b.stored, b.corrupted);\n     }\n \n     // Add this replica to corruptReplicas Map\n     corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n         b.reasonCode);\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedReplicas;\n-    boolean minReplicationSatisfied \u003d checkMinStorage(b.stored,\n+\n+    boolean minReplicationSatisfied \u003d hasMinStorage(b.stored,\n         numberOfReplicas.liveReplicas());\n+\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    if (b.stored.isDeleted()) {\n      blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n    short expectedReplicas \u003d\n        b.stored.getBlockCollection().getPreferredBlockReplication();\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.stored, b.corrupted);\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n\n    boolean minReplicationSatisfied \u003d hasMinStorage(b.stored,\n        numberOfReplicas.liveReplicas());\n\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "1e1e93040748231dc913190aec1e031c379d8271": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7837. Erasure Coding: allocate and persist striped blocks in NameNode. Contributed by Jing Zhao.\n",
      "commitDate": "26/05/15 11:32 AM",
      "commitName": "1e1e93040748231dc913190aec1e031c379d8271",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "26/05/15 11:07 AM",
      "commitNameOld": "9f2f583f401189c3f4a2687795a9e3e0b288322b",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,47 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n     if (b.corrupted.isDeleted()) {\n       blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n     short expectedReplicas \u003d\n         b.corrupted.getBlockCollection().getPreferredBlockReplication();\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n       storageInfo.addBlock(b.stored, b.reportedBlock);\n     }\n \n     // Add this replica to corruptReplicas Map\n     corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n         b.reasonCode);\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedReplicas;\n-    boolean minReplicationSatisfied \u003d\n-        numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n+    boolean minReplicationSatisfied \u003d checkMinStorage(b.stored,\n+        numberOfReplicas.liveReplicas());\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    if (b.corrupted.isDeleted()) {\n      blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n    short expectedReplicas \u003d\n        b.corrupted.getBlockCollection().getPreferredBlockReplication();\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.stored, b.reportedBlock);\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n    boolean minReplicationSatisfied \u003d checkMinStorage(b.stored,\n        numberOfReplicas.liveReplicas());\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "ba9371492036983a9899398907ab41fe548f29b3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7716. Erasure Coding: extend BlockInfo to handle EC info. Contributed by Jing Zhao.\n",
      "commitDate": "26/05/15 11:07 AM",
      "commitName": "ba9371492036983a9899398907ab41fe548f29b3",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "26/05/15 11:03 AM",
      "commitNameOld": "0c1da5a0300f015a7e39f2b40a73fb06c65a78c8",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,47 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n     if (b.corrupted.isDeleted()) {\n       blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n     short expectedReplicas \u003d\n         b.corrupted.getBlockCollection().getPreferredBlockReplication();\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n-      storageInfo.addBlock(b.stored);\n+      storageInfo.addBlock(b.stored, b.reportedBlock);\n     }\n \n     // Add this replica to corruptReplicas Map\n     corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n         b.reasonCode);\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedReplicas;\n     boolean minReplicationSatisfied \u003d\n         numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    if (b.corrupted.isDeleted()) {\n      blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n    short expectedReplicas \u003d\n        b.corrupted.getBlockCollection().getPreferredBlockReplication();\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.stored, b.reportedBlock);\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n    boolean minReplicationSatisfied \u003d\n        numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "6d5da9484185ca9f585195d6da069b9cd5be4044": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8255. Rename getBlockReplication to getPreferredBlockReplication. (Contributed by Zhe Zhang)\n",
      "commitDate": "12/05/15 6:29 AM",
      "commitName": "6d5da9484185ca9f585195d6da069b9cd5be4044",
      "commitAuthor": "yliu",
      "commitDateOld": "08/05/15 2:36 PM",
      "commitNameOld": "2d4ae3d18bc530fa9f81ee616db8af3395705fb9",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 3.66,
      "commitsBetweenForRepo": 45,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,47 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n     if (b.corrupted.isDeleted()) {\n       blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n     short expectedReplicas \u003d\n-        b.corrupted.getBlockCollection().getBlockReplication();\n+        b.corrupted.getBlockCollection().getPreferredBlockReplication();\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n       storageInfo.addBlock(b.stored);\n     }\n \n     // Add this replica to corruptReplicas Map\n     corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n         b.reasonCode);\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n         expectedReplicas;\n     boolean minReplicationSatisfied \u003d\n         numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    if (b.corrupted.isDeleted()) {\n      blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n    short expectedReplicas \u003d\n        b.corrupted.getBlockCollection().getPreferredBlockReplication();\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.stored);\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n    boolean minReplicationSatisfied \u003d\n        numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "997408eaaceef20b053ee7344468e28cb9a1379b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8133. Improve readability of deleted block check (Daryn Sharp via Colin P. McCabe)\n",
      "commitDate": "21/04/15 11:43 AM",
      "commitName": "997408eaaceef20b053ee7344468e28cb9a1379b",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "20/04/15 12:36 AM",
      "commitNameOld": "5c97db07fb306842f49d73a67a90cecec19a7833",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 1.46,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,47 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n-    BlockCollection bc \u003d b.corrupted.getBlockCollection();\n-    if (bc \u003d\u003d null) {\n+    if (b.corrupted.isDeleted()) {\n       blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n           \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n+    short expectedReplicas \u003d\n+        b.corrupted.getBlockCollection().getBlockReplication();\n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n       storageInfo.addBlock(b.stored);\n     }\n \n     // Add this replica to corruptReplicas Map\n     corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n         b.reasonCode);\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n-    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d bc\n-        .getBlockReplication();\n+    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n+        expectedReplicas;\n     boolean minReplicationSatisfied \u003d\n         numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n-        bc.getBlockReplication();\n+        expectedReplicas;\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    if (b.corrupted.isDeleted()) {\n      blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n    short expectedReplicas \u003d\n        b.corrupted.getBlockCollection().getBlockReplication();\n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.stored);\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d\n        expectedReplicas;\n    boolean minReplicationSatisfied \u003d\n        numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        expectedReplicas;\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "3ae38ec7dfa1aaf451cf889cec6cf862379af32a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7712. Switch blockStateChangeLog to use slf4j.\n",
      "commitDate": "03/02/15 3:01 PM",
      "commitName": "3ae38ec7dfa1aaf451cf889cec6cf862379af32a",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "30/01/15 11:33 AM",
      "commitNameOld": "951b3608a8cb1d9063b9be9c740b524c137b816f",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 4.14,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,46 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeStorageInfo storageInfo,\n       DatanodeDescriptor node) throws IOException {\n \n     BlockCollection bc \u003d b.corrupted.getBlockCollection();\n     if (bc \u003d\u003d null) {\n-      blockLog.info(\"BLOCK markBlockAsCorrupt: \" + b\n-          + \" cannot be marked as corrupt as it does not belong to any file\");\n+      blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n+          \" corrupt as it does not belong to any file\", b);\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n \n     // Add replica to the data-node if it is not already there\n     if (storageInfo !\u003d null) {\n       storageInfo.addBlock(b.stored);\n     }\n \n     // Add this replica to corruptReplicas Map\n     corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n         b.reasonCode);\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d bc\n         .getBlockReplication();\n     boolean minReplicationSatisfied \u003d\n         numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         bc.getBlockReplication();\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    BlockCollection bc \u003d b.corrupted.getBlockCollection();\n    if (bc \u003d\u003d null) {\n      blockLog.info(\"BLOCK markBlockAsCorrupt: {} cannot be marked as\" +\n          \" corrupt as it does not belong to any file\", b);\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.stored);\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d bc\n        .getBlockReplication();\n    boolean minReplicationSatisfied \u003d\n        numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        bc.getBlockReplication();\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "45db4d204b796eee6dd0e39d3cc94b70c47028d4": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6794. Update BlockManager methods to use DatanodeStorageInfo where possible. (Arpit Agarwal)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1615169 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/08/14 9:58 AM",
      "commitName": "45db4d204b796eee6dd0e39d3cc94b70c47028d4",
      "commitAuthor": "Arpit Agarwal",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6794. Update BlockManager methods to use DatanodeStorageInfo where possible. (Arpit Agarwal)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1615169 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "01/08/14 9:58 AM",
          "commitName": "45db4d204b796eee6dd0e39d3cc94b70c47028d4",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "31/07/14 6:05 PM",
          "commitNameOld": "b8597e6a10b2e8df1bee4e8ce0c8be345f7e007d",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 0.66,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,49 +1,46 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n-      DatanodeInfo dn, String storageID) throws IOException {\n-    DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n-    if (node \u003d\u003d null) {\n-      throw new IOException(\"Cannot mark \" + b\n-          + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n-          + \") does not exist\");\n-    }\n+      DatanodeStorageInfo storageInfo,\n+      DatanodeDescriptor node) throws IOException {\n \n     BlockCollection bc \u003d b.corrupted.getBlockCollection();\n     if (bc \u003d\u003d null) {\n       blockLog.info(\"BLOCK markBlockAsCorrupt: \" + b\n           + \" cannot be marked as corrupt as it does not belong to any file\");\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n \n     // Add replica to the data-node if it is not already there\n-    node.addBlock(storageID, b.stored);\n+    if (storageInfo !\u003d null) {\n+      storageInfo.addBlock(b.stored);\n+    }\n \n     // Add this replica to corruptReplicas Map\n     corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n         b.reasonCode);\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d bc\n         .getBlockReplication();\n     boolean minReplicationSatisfied \u003d\n         numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         bc.getBlockReplication();\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    BlockCollection bc \u003d b.corrupted.getBlockCollection();\n    if (bc \u003d\u003d null) {\n      blockLog.info(\"BLOCK markBlockAsCorrupt: \" + b\n          + \" cannot be marked as corrupt as it does not belong to any file\");\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.stored);\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d bc\n        .getBlockReplication();\n    boolean minReplicationSatisfied \u003d\n        numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        bc.getBlockReplication();\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "[b-BlockToMarkCorrupt, dn-DatanodeInfo, storageID-String]",
            "newValue": "[b-BlockToMarkCorrupt, storageInfo-DatanodeStorageInfo, node-DatanodeDescriptor]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6794. Update BlockManager methods to use DatanodeStorageInfo where possible. (Arpit Agarwal)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1615169 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "01/08/14 9:58 AM",
          "commitName": "45db4d204b796eee6dd0e39d3cc94b70c47028d4",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "31/07/14 6:05 PM",
          "commitNameOld": "b8597e6a10b2e8df1bee4e8ce0c8be345f7e007d",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 0.66,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,49 +1,46 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n-      DatanodeInfo dn, String storageID) throws IOException {\n-    DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n-    if (node \u003d\u003d null) {\n-      throw new IOException(\"Cannot mark \" + b\n-          + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n-          + \") does not exist\");\n-    }\n+      DatanodeStorageInfo storageInfo,\n+      DatanodeDescriptor node) throws IOException {\n \n     BlockCollection bc \u003d b.corrupted.getBlockCollection();\n     if (bc \u003d\u003d null) {\n       blockLog.info(\"BLOCK markBlockAsCorrupt: \" + b\n           + \" cannot be marked as corrupt as it does not belong to any file\");\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n \n     // Add replica to the data-node if it is not already there\n-    node.addBlock(storageID, b.stored);\n+    if (storageInfo !\u003d null) {\n+      storageInfo.addBlock(b.stored);\n+    }\n \n     // Add this replica to corruptReplicas Map\n     corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n         b.reasonCode);\n \n     NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n     boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d bc\n         .getBlockReplication();\n     boolean minReplicationSatisfied \u003d\n         numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n     boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n         (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n         bc.getBlockReplication();\n     boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n         (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n     // case 1: have enough number of live replicas\n     // case 2: corrupted replicas + live replicas \u003e Replication factor\n     // case 3: Block is marked corrupt due to failure while writing. In this\n     //         case genstamp will be different than that of valid block.\n     // In all these cases we can delete the replica.\n     // In case of 3, rbw block will be deleted and valid block can be replicated\n     if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n         || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeStorageInfo storageInfo,\n      DatanodeDescriptor node) throws IOException {\n\n    BlockCollection bc \u003d b.corrupted.getBlockCollection();\n    if (bc \u003d\u003d null) {\n      blockLog.info(\"BLOCK markBlockAsCorrupt: \" + b\n          + \" cannot be marked as corrupt as it does not belong to any file\");\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n\n    // Add replica to the data-node if it is not already there\n    if (storageInfo !\u003d null) {\n      storageInfo.addBlock(b.stored);\n    }\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d bc\n        .getBlockReplication();\n    boolean minReplicationSatisfied \u003d\n        numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        bc.getBlockReplication();\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "be01103af7e60fededeb76fa60776edc3f7018fa": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3493. Invalidate corrupted blocks as long as minimum replication is satisfied. Contributed by Juan Yu and Vinayakumar B.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1602291 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/14 2:06 PM",
      "commitName": "be01103af7e60fededeb76fa60776edc3f7018fa",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "02/06/14 5:47 PM",
      "commitNameOld": "a29d2d337164de59375aa45d4fbb9a431facade7",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 9.85,
      "commitsBetweenForRepo": 55,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,49 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeInfo dn, String storageID) throws IOException {\n     DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n     if (node \u003d\u003d null) {\n       throw new IOException(\"Cannot mark \" + b\n           + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n           + \") does not exist\");\n     }\n \n     BlockCollection bc \u003d b.corrupted.getBlockCollection();\n     if (bc \u003d\u003d null) {\n       blockLog.info(\"BLOCK markBlockAsCorrupt: \" + b\n           + \" cannot be marked as corrupt as it does not belong to any file\");\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n \n     // Add replica to the data-node if it is not already there\n     node.addBlock(storageID, b.stored);\n \n     // Add this replica to corruptReplicas Map\n     corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n         b.reasonCode);\n-    if (countNodes(b.stored).liveReplicas() \u003e\u003d bc.getBlockReplication()) {\n+\n+    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n+    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d bc\n+        .getBlockReplication();\n+    boolean minReplicationSatisfied \u003d\n+        numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n+    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n+        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n+        bc.getBlockReplication();\n+    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n+        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n+    // case 1: have enough number of live replicas\n+    // case 2: corrupted replicas + live replicas \u003e Replication factor\n+    // case 3: Block is marked corrupt due to failure while writing. In this\n+    //         case genstamp will be different than that of valid block.\n+    // In all these cases we can delete the replica.\n+    // In case of 3, rbw block will be deleted and valid block can be replicated\n+    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n+        || corruptedDuringWrite) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeInfo dn, String storageID) throws IOException {\n    DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n    if (node \u003d\u003d null) {\n      throw new IOException(\"Cannot mark \" + b\n          + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n          + \") does not exist\");\n    }\n\n    BlockCollection bc \u003d b.corrupted.getBlockCollection();\n    if (bc \u003d\u003d null) {\n      blockLog.info(\"BLOCK markBlockAsCorrupt: \" + b\n          + \" cannot be marked as corrupt as it does not belong to any file\");\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n\n    // Add replica to the data-node if it is not already there\n    node.addBlock(storageID, b.stored);\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n        b.reasonCode);\n\n    NumberReplicas numberOfReplicas \u003d countNodes(b.stored);\n    boolean hasEnoughLiveReplicas \u003d numberOfReplicas.liveReplicas() \u003e\u003d bc\n        .getBlockReplication();\n    boolean minReplicationSatisfied \u003d\n        numberOfReplicas.liveReplicas() \u003e\u003d minReplication;\n    boolean hasMoreCorruptReplicas \u003d minReplicationSatisfied \u0026\u0026\n        (numberOfReplicas.liveReplicas() + numberOfReplicas.corruptReplicas()) \u003e\n        bc.getBlockReplication();\n    boolean corruptedDuringWrite \u003d minReplicationSatisfied \u0026\u0026\n        (b.stored.getGenerationStamp() \u003e b.corrupted.getGenerationStamp());\n    // case 1: have enough number of live replicas\n    // case 2: corrupted replicas + live replicas \u003e Replication factor\n    // case 3: Block is marked corrupt due to failure while writing. In this\n    //         case genstamp will be different than that of valid block.\n    // In all these cases we can delete the replica.\n    // In case of 3, rbw block will be deleted and valid block can be replicated\n    if (hasEnoughLiveReplicas || hasMoreCorruptReplicas\n        || corruptedDuringWrite) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "e5d6fba47d9c6f4d984ca8295fcf5dee388e2241": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6289. HA failover can fail if there are pending DN messages for DNs which no longer exist. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1591413 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/04/14 10:46 AM",
      "commitName": "e5d6fba47d9c6f4d984ca8295fcf5dee388e2241",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "24/04/14 12:24 AM",
      "commitNameOld": "24d1cf9ac681fadaf2a3614a24b06327d5d5f53e",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 6.43,
      "commitsBetweenForRepo": 35,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,31 @@\n   private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n       DatanodeInfo dn, String storageID) throws IOException {\n     DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n     if (node \u003d\u003d null) {\n       throw new IOException(\"Cannot mark \" + b\n-          + \" as corrupt because datanode \" + dn + \" does not exist\");\n+          + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n+          + \") does not exist\");\n     }\n \n     BlockCollection bc \u003d b.corrupted.getBlockCollection();\n     if (bc \u003d\u003d null) {\n       blockLog.info(\"BLOCK markBlockAsCorrupt: \" + b\n           + \" cannot be marked as corrupt as it does not belong to any file\");\n       addToInvalidates(b.corrupted, node);\n       return;\n     } \n \n     // Add replica to the data-node if it is not already there\n     node.addBlock(storageID, b.stored);\n \n     // Add this replica to corruptReplicas Map\n     corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n         b.reasonCode);\n     if (countNodes(b.stored).liveReplicas() \u003e\u003d bc.getBlockReplication()) {\n       // the block is over-replicated so invalidate the replicas immediately\n       invalidateBlock(b, node);\n     } else if (namesystem.isPopulatingReplQueues()) {\n       // add the block to neededReplication\n       updateNeededReplications(b.stored, -1, 0);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void markBlockAsCorrupt(BlockToMarkCorrupt b,\n      DatanodeInfo dn, String storageID) throws IOException {\n    DatanodeDescriptor node \u003d getDatanodeManager().getDatanode(dn);\n    if (node \u003d\u003d null) {\n      throw new IOException(\"Cannot mark \" + b\n          + \" as corrupt because datanode \" + dn + \" (\" + dn.getDatanodeUuid()\n          + \") does not exist\");\n    }\n\n    BlockCollection bc \u003d b.corrupted.getBlockCollection();\n    if (bc \u003d\u003d null) {\n      blockLog.info(\"BLOCK markBlockAsCorrupt: \" + b\n          + \" cannot be marked as corrupt as it does not belong to any file\");\n      addToInvalidates(b.corrupted, node);\n      return;\n    } \n\n    // Add replica to the data-node if it is not already there\n    node.addBlock(storageID, b.stored);\n\n    // Add this replica to corruptReplicas Map\n    corruptReplicas.addToCorruptReplicasMap(b.corrupted, node, b.reason,\n        b.reasonCode);\n    if (countNodes(b.stored).liveReplicas() \u003e\u003d bc.getBlockReplication()) {\n      // the block is over-replicated so invalidate the replicas immediately\n      invalidateBlock(b, node);\n    } else if (namesystem.isPopulatingReplQueues()) {\n      // add the block to neededReplication\n      updateNeededReplications(b.stored, -1, 0);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    }
  }
}