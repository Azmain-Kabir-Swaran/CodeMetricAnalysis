{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSTopologyNodeImpl.java",
  "functionName": "updateExistingDatanode",
  "functionId": "updateExistingDatanode___dnDescriptor-DatanodeDescriptor",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/net/DFSTopologyNodeImpl.java",
  "functionStartLine": 147,
  "functionEndLine": 189,
  "numCommitsSeen": 4,
  "timeTaken": 1163,
  "changeHistory": [
    "97c2e576c91c2316c2b52bfc948bae9bff8ca49f"
  ],
  "changeHistoryShort": {
    "97c2e576c91c2316c2b52bfc948bae9bff8ca49f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "97c2e576c91c2316c2b52bfc948bae9bff8ca49f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11530. Use HDFS specific network topology to choose datanode in BlockPlacementPolicyDefault. Contributed by Yiqun Lin and Chen Liang.\n",
      "commitDate": "04/05/17 8:54 PM",
      "commitName": "97c2e576c91c2316c2b52bfc948bae9bff8ca49f",
      "commitAuthor": "Yiqun Lin",
      "diff": "@@ -0,0 +1,43 @@\n+  private void updateExistingDatanode(DatanodeDescriptor dnDescriptor) {\n+    if (childrenStorageInfo.containsKey(dnDescriptor.getName())) {\n+      // all existing node should have an entry in childrenStorageInfo\n+      boolean same \u003d dnDescriptor.getStorageTypes().size()\n+          \u003d\u003d childrenStorageInfo.get(dnDescriptor.getName()).keySet().size();\n+      for (StorageType type :\n+          childrenStorageInfo.get(dnDescriptor.getName()).keySet()) {\n+        same \u003d same \u0026\u0026 dnDescriptor.hasStorageType(type);\n+      }\n+      if (same) {\n+        // if the storage type hasn\u0027t been changed, do nothing.\n+        return;\n+      }\n+      // not same means we need to update the storage info.\n+      DFSTopologyNodeImpl parent \u003d (DFSTopologyNodeImpl)getParent();\n+      for (StorageType type :\n+          childrenStorageInfo.get(dnDescriptor.getName()).keySet()) {\n+        if (!dnDescriptor.hasStorageType(type)) {\n+          // remove this type, because the new storage info does not have it.\n+          // also need to remove decrement the count for all the ancestors.\n+          // since this is the parent of n, where n is a datanode,\n+          // the map must have 1 as the value of all keys\n+          childrenStorageInfo.get(dnDescriptor.getName()).remove(type);\n+          decStorageTypeCount(type);\n+          if (parent !\u003d null) {\n+            parent.childRemoveStorage(getName(), type);\n+          }\n+        }\n+      }\n+      for (StorageType type : dnDescriptor.getStorageTypes()) {\n+        if (!childrenStorageInfo.get(dnDescriptor.getName())\n+            .containsKey(type)) {\n+          // there is a new type in new storage info, add this locally,\n+          // as well as all ancestors.\n+          childrenStorageInfo.get(dnDescriptor.getName()).put(type, 1);\n+          incStorageTypeCount(type);\n+          if (parent !\u003d null) {\n+            parent.childAddStorage(getName(), type);\n+          }\n+        }\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void updateExistingDatanode(DatanodeDescriptor dnDescriptor) {\n    if (childrenStorageInfo.containsKey(dnDescriptor.getName())) {\n      // all existing node should have an entry in childrenStorageInfo\n      boolean same \u003d dnDescriptor.getStorageTypes().size()\n          \u003d\u003d childrenStorageInfo.get(dnDescriptor.getName()).keySet().size();\n      for (StorageType type :\n          childrenStorageInfo.get(dnDescriptor.getName()).keySet()) {\n        same \u003d same \u0026\u0026 dnDescriptor.hasStorageType(type);\n      }\n      if (same) {\n        // if the storage type hasn\u0027t been changed, do nothing.\n        return;\n      }\n      // not same means we need to update the storage info.\n      DFSTopologyNodeImpl parent \u003d (DFSTopologyNodeImpl)getParent();\n      for (StorageType type :\n          childrenStorageInfo.get(dnDescriptor.getName()).keySet()) {\n        if (!dnDescriptor.hasStorageType(type)) {\n          // remove this type, because the new storage info does not have it.\n          // also need to remove decrement the count for all the ancestors.\n          // since this is the parent of n, where n is a datanode,\n          // the map must have 1 as the value of all keys\n          childrenStorageInfo.get(dnDescriptor.getName()).remove(type);\n          decStorageTypeCount(type);\n          if (parent !\u003d null) {\n            parent.childRemoveStorage(getName(), type);\n          }\n        }\n      }\n      for (StorageType type : dnDescriptor.getStorageTypes()) {\n        if (!childrenStorageInfo.get(dnDescriptor.getName())\n            .containsKey(type)) {\n          // there is a new type in new storage info, add this locally,\n          // as well as all ancestors.\n          childrenStorageInfo.get(dnDescriptor.getName()).put(type, 1);\n          incStorageTypeCount(type);\n          if (parent !\u003d null) {\n            parent.childAddStorage(getName(), type);\n          }\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/net/DFSTopologyNodeImpl.java"
    }
  }
}