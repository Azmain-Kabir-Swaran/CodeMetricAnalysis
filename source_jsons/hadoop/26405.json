{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "MRAppMaster.java",
  "functionName": "cleanUpPreviousJobOutput",
  "functionId": "cleanUpPreviousJobOutput",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
  "functionStartLine": 1401,
  "functionEndLine": 1419,
  "numCommitsSeen": 124,
  "timeTaken": 1456,
  "changeHistory": [
    "cc10852252c2d69294eabc68bd032cc630a53b18",
    "cce71dceef9e82d31fe8ec59648b2a4a50c8869a"
  ],
  "changeHistoryShort": {
    "cc10852252c2d69294eabc68bd032cc630a53b18": "Ybodychange",
    "cce71dceef9e82d31fe8ec59648b2a4a50c8869a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "cc10852252c2d69294eabc68bd032cc630a53b18": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-7041. MR should not try to clean up at first job attempt. (Gergo Repas via Haibo Chen)\n",
      "commitDate": "25/01/18 4:11 PM",
      "commitName": "cc10852252c2d69294eabc68bd032cc630a53b18",
      "commitAuthor": "Haibo Chen",
      "commitDateOld": "19/01/18 12:56 PM",
      "commitNameOld": "cce71dceef9e82d31fe8ec59648b2a4a50c8869a",
      "commitAuthorOld": "Haibo Chen",
      "daysBetweenCommits": 6.14,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n   private void cleanUpPreviousJobOutput() {\n     // recovered application masters should not remove data from previous job\n-    if (!recovered()) {\n+    if (!isFirstAttempt() \u0026\u0026 !recovered()) {\n       JobContext jobContext \u003d getJobContextFromConf(getConfig());\n       try {\n         LOG.info(\"Starting to clean up previous job\u0027s temporary files\");\n         this.committer.abortJob(jobContext, State.FAILED);\n         LOG.info(\"Finished cleaning up previous job temporary files\");\n       } catch (FileNotFoundException e) {\n         LOG.info(\"Previous job temporary files do not exist, \" +\n             \"no clean up was necessary.\");\n       } catch (Exception e) {\n         // the clean up of a previous attempt is not critical to the success\n         // of this job - only logging the error\n         LOG.error(\"Error while trying to clean up previous job\u0027s temporary \" +\n             \"files\", e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void cleanUpPreviousJobOutput() {\n    // recovered application masters should not remove data from previous job\n    if (!isFirstAttempt() \u0026\u0026 !recovered()) {\n      JobContext jobContext \u003d getJobContextFromConf(getConfig());\n      try {\n        LOG.info(\"Starting to clean up previous job\u0027s temporary files\");\n        this.committer.abortJob(jobContext, State.FAILED);\n        LOG.info(\"Finished cleaning up previous job temporary files\");\n      } catch (FileNotFoundException e) {\n        LOG.info(\"Previous job temporary files do not exist, \" +\n            \"no clean up was necessary.\");\n      } catch (Exception e) {\n        // the clean up of a previous attempt is not critical to the success\n        // of this job - only logging the error\n        LOG.error(\"Error while trying to clean up previous job\u0027s temporary \" +\n            \"files\", e);\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java",
      "extendedDetails": {}
    },
    "cce71dceef9e82d31fe8ec59648b2a4a50c8869a": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-6984. MR AM to clean up temporary files from previous attempt in case of no recovery. (Gergo Repas via Haibo Chen)\n",
      "commitDate": "19/01/18 12:56 PM",
      "commitName": "cce71dceef9e82d31fe8ec59648b2a4a50c8869a",
      "commitAuthor": "Haibo Chen",
      "diff": "@@ -0,0 +1,19 @@\n+  private void cleanUpPreviousJobOutput() {\n+    // recovered application masters should not remove data from previous job\n+    if (!recovered()) {\n+      JobContext jobContext \u003d getJobContextFromConf(getConfig());\n+      try {\n+        LOG.info(\"Starting to clean up previous job\u0027s temporary files\");\n+        this.committer.abortJob(jobContext, State.FAILED);\n+        LOG.info(\"Finished cleaning up previous job temporary files\");\n+      } catch (FileNotFoundException e) {\n+        LOG.info(\"Previous job temporary files do not exist, \" +\n+            \"no clean up was necessary.\");\n+      } catch (Exception e) {\n+        // the clean up of a previous attempt is not critical to the success\n+        // of this job - only logging the error\n+        LOG.error(\"Error while trying to clean up previous job\u0027s temporary \" +\n+            \"files\", e);\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void cleanUpPreviousJobOutput() {\n    // recovered application masters should not remove data from previous job\n    if (!recovered()) {\n      JobContext jobContext \u003d getJobContextFromConf(getConfig());\n      try {\n        LOG.info(\"Starting to clean up previous job\u0027s temporary files\");\n        this.committer.abortJob(jobContext, State.FAILED);\n        LOG.info(\"Finished cleaning up previous job temporary files\");\n      } catch (FileNotFoundException e) {\n        LOG.info(\"Previous job temporary files do not exist, \" +\n            \"no clean up was necessary.\");\n      } catch (Exception e) {\n        // the clean up of a previous attempt is not critical to the success\n        // of this job - only logging the error\n        LOG.error(\"Error while trying to clean up previous job\u0027s temporary \" +\n            \"files\", e);\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/MRAppMaster.java"
    }
  }
}