{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeManager.java",
  "functionName": "refreshNodes",
  "functionId": "refreshNodes___conf-Configuration(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
  "functionStartLine": 1211,
  "functionEndLine": 1220,
  "numCommitsSeen": 204,
  "timeTaken": 8115,
  "changeHistory": [
    "39252995c4d734e993e3fa5338e1a7816aee86fc",
    "cd271773ac45d36875862d771b05476ce1f23c1f",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "5d5b1c6c10c66c6a17b483a3e1a98d59d3d0bdee",
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "39252995c4d734e993e3fa5338e1a7816aee86fc": "Ybodychange",
    "cd271773ac45d36875862d771b05476ce1f23c1f": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "5d5b1c6c10c66c6a17b483a3e1a98d59d3d0bdee": "Ymultichange(Ymovefromfile,Ybodychange,Yparametermetachange)",
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "39252995c4d734e993e3fa5338e1a7816aee86fc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3245. Add metrics and web UI for cluster version summary. Contributed by Ravi Prakash.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1517937 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/08/13 12:21 PM",
      "commitName": "39252995c4d734e993e3fa5338e1a7816aee86fc",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "07/06/13 1:01 PM",
      "commitNameOld": "2a76cddcd53ab10a79372b09595bb6df4bb44e01",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 80.97,
      "commitsBetweenForRepo": 489,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,10 @@\n   public void refreshNodes(final Configuration conf) throws IOException {\n     refreshHostsReader(conf);\n     namesystem.writeLock();\n     try {\n       refreshDatanodes();\n+      countSoftwareVersions();\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void refreshNodes(final Configuration conf) throws IOException {\n    refreshHostsReader(conf);\n    namesystem.writeLock();\n    try {\n      refreshDatanodes();\n      countSoftwareVersions();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "cd271773ac45d36875862d771b05476ce1f23c1f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3331. In namenode, check superuser privilege for setBalancerBandwidth and acquire the write lock for finalizeUpgrade.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1331598 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/04/12 2:17 PM",
      "commitName": "cd271773ac45d36875862d771b05476ce1f23c1f",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "12/04/12 2:28 PM",
      "commitNameOld": "4f230adc13c70b09083a928b9dc65fa404e6d177",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 14.99,
      "commitsBetweenForRepo": 95,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,9 @@\n   public void refreshNodes(final Configuration conf) throws IOException {\n-    namesystem.checkSuperuserPrivilege();\n     refreshHostsReader(conf);\n     namesystem.writeLock();\n     try {\n       refreshDatanodes();\n     } finally {\n       namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void refreshNodes(final Configuration conf) throws IOException {\n    refreshHostsReader(conf);\n    namesystem.writeLock();\n    try {\n      refreshDatanodes();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void refreshNodes(final Configuration conf) throws IOException {\n    namesystem.checkSuperuserPrivilege();\n    refreshHostsReader(conf);\n    namesystem.writeLock();\n    try {\n      refreshDatanodes();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void refreshNodes(final Configuration conf) throws IOException {\n    namesystem.checkSuperuserPrivilege();\n    refreshHostsReader(conf);\n    namesystem.writeLock();\n    try {\n      refreshDatanodes();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java"
      }
    },
    "5d5b1c6c10c66c6a17b483a3e1a98d59d3d0bdee": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange,Yparametermetachange)",
      "commitMessage": "HDFS-2239. Reduce access levels of the fields and methods in FSNamesystem.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1155998 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/08/11 6:50 PM",
      "commitName": "5d5b1c6c10c66c6a17b483a3e1a98d59d3d0bdee",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-2239. Reduce access levels of the fields and methods in FSNamesystem.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1155998 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "09/08/11 6:50 PM",
          "commitName": "5d5b1c6c10c66c6a17b483a3e1a98d59d3d0bdee",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "09/08/11 5:01 PM",
          "commitNameOld": "eb6e44b1ba58ed971360a39ea5d5ce02ae65aa0f",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,10 +1,10 @@\n-  public void refreshNodes(Configuration conf) throws IOException {\n-    checkSuperuserPrivilege();\n-    getBlockManager().getDatanodeManager().refreshHostsReader(conf);\n-    writeLock();\n+  public void refreshNodes(final Configuration conf) throws IOException {\n+    namesystem.checkSuperuserPrivilege();\n+    refreshHostsReader(conf);\n+    namesystem.writeLock();\n     try {\n-      getBlockManager().getDatanodeManager().refreshDatanodes();\n+      refreshDatanodes();\n     } finally {\n-      writeUnlock();\n+      namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void refreshNodes(final Configuration conf) throws IOException {\n    namesystem.checkSuperuserPrivilege();\n    refreshHostsReader(conf);\n    namesystem.writeLock();\n    try {\n      refreshDatanodes();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {
            "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
            "newPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
            "oldMethodName": "refreshNodes",
            "newMethodName": "refreshNodes"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2239. Reduce access levels of the fields and methods in FSNamesystem.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1155998 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "09/08/11 6:50 PM",
          "commitName": "5d5b1c6c10c66c6a17b483a3e1a98d59d3d0bdee",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "09/08/11 5:01 PM",
          "commitNameOld": "eb6e44b1ba58ed971360a39ea5d5ce02ae65aa0f",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,10 +1,10 @@\n-  public void refreshNodes(Configuration conf) throws IOException {\n-    checkSuperuserPrivilege();\n-    getBlockManager().getDatanodeManager().refreshHostsReader(conf);\n-    writeLock();\n+  public void refreshNodes(final Configuration conf) throws IOException {\n+    namesystem.checkSuperuserPrivilege();\n+    refreshHostsReader(conf);\n+    namesystem.writeLock();\n     try {\n-      getBlockManager().getDatanodeManager().refreshDatanodes();\n+      refreshDatanodes();\n     } finally {\n-      writeUnlock();\n+      namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void refreshNodes(final Configuration conf) throws IOException {\n    namesystem.checkSuperuserPrivilege();\n    refreshHostsReader(conf);\n    namesystem.writeLock();\n    try {\n      refreshDatanodes();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparametermetachange",
          "commitMessage": "HDFS-2239. Reduce access levels of the fields and methods in FSNamesystem.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1155998 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "09/08/11 6:50 PM",
          "commitName": "5d5b1c6c10c66c6a17b483a3e1a98d59d3d0bdee",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "09/08/11 5:01 PM",
          "commitNameOld": "eb6e44b1ba58ed971360a39ea5d5ce02ae65aa0f",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,10 +1,10 @@\n-  public void refreshNodes(Configuration conf) throws IOException {\n-    checkSuperuserPrivilege();\n-    getBlockManager().getDatanodeManager().refreshHostsReader(conf);\n-    writeLock();\n+  public void refreshNodes(final Configuration conf) throws IOException {\n+    namesystem.checkSuperuserPrivilege();\n+    refreshHostsReader(conf);\n+    namesystem.writeLock();\n     try {\n-      getBlockManager().getDatanodeManager().refreshDatanodes();\n+      refreshDatanodes();\n     } finally {\n-      writeUnlock();\n+      namesystem.writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void refreshNodes(final Configuration conf) throws IOException {\n    namesystem.checkSuperuserPrivilege();\n    refreshHostsReader(conf);\n    namesystem.writeLock();\n    try {\n      refreshDatanodes();\n    } finally {\n      namesystem.writeUnlock();\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {
            "oldValue": "[conf-Configuration]",
            "newValue": "[conf-Configuration(modifiers-final)]"
          }
        }
      ]
    },
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2167.  Move dnsToSwitchMapping and hostsReader from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149455 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/07/11 9:20 PM",
      "commitName": "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "20/07/11 4:35 PM",
      "commitNameOld": "08928d067bb9e1d38b5e7db9e23fcf20fe161435",
      "commitAuthorOld": "Matthew Foley",
      "daysBetweenCommits": 1.2,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,10 @@\n   public void refreshNodes(Configuration conf) throws IOException {\n     checkSuperuserPrivilege();\n-    // Reread the config to get dfs.hosts and dfs.hosts.exclude filenames.\n-    // Update the file names and refresh internal includes and excludes list\n-    if (conf \u003d\u003d null)\n-      conf \u003d new HdfsConfiguration();\n-    hostsReader.updateFileNames(conf.get(DFSConfigKeys.DFS_HOSTS,\"\"), \n-                                conf.get(DFSConfigKeys.DFS_HOSTS_EXCLUDE, \"\"));\n-    hostsReader.refresh();\n+    getBlockManager().getDatanodeManager().refreshHostsReader(conf);\n     writeLock();\n     try {\n-      for (Iterator\u003cDatanodeDescriptor\u003e it \u003d datanodeMap.values().iterator();\n-           it.hasNext();) {\n-        DatanodeDescriptor node \u003d it.next();\n-        // Check if not include.\n-        if (!inHostsList(node, null)) {\n-          node.setDisallowed(true);  // case 2.\n-        } else {\n-          if (inExcludedHostsList(node, null)) {\n-            startDecommission(node);   // case 3.\n-          } else {\n-            stopDecommission(node);   // case 4.\n-          }\n-        }\n-      }\n+      getBlockManager().getDatanodeManager().refreshDatanodes();\n     } finally {\n       writeUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void refreshNodes(Configuration conf) throws IOException {\n    checkSuperuserPrivilege();\n    getBlockManager().getDatanodeManager().refreshHostsReader(conf);\n    writeLock();\n    try {\n      getBlockManager().getDatanodeManager().refreshDatanodes();\n    } finally {\n      writeUnlock();\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,29 @@\n+  public void refreshNodes(Configuration conf) throws IOException {\n+    checkSuperuserPrivilege();\n+    // Reread the config to get dfs.hosts and dfs.hosts.exclude filenames.\n+    // Update the file names and refresh internal includes and excludes list\n+    if (conf \u003d\u003d null)\n+      conf \u003d new HdfsConfiguration();\n+    hostsReader.updateFileNames(conf.get(DFSConfigKeys.DFS_HOSTS,\"\"), \n+                                conf.get(DFSConfigKeys.DFS_HOSTS_EXCLUDE, \"\"));\n+    hostsReader.refresh();\n+    writeLock();\n+    try {\n+      for (Iterator\u003cDatanodeDescriptor\u003e it \u003d datanodeMap.values().iterator();\n+           it.hasNext();) {\n+        DatanodeDescriptor node \u003d it.next();\n+        // Check if not include.\n+        if (!inHostsList(node, null)) {\n+          node.setDisallowed(true);  // case 2.\n+        } else {\n+          if (inExcludedHostsList(node, null)) {\n+            startDecommission(node);   // case 3.\n+          } else {\n+            stopDecommission(node);   // case 4.\n+          }\n+        }\n+      }\n+    } finally {\n+      writeUnlock();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void refreshNodes(Configuration conf) throws IOException {\n    checkSuperuserPrivilege();\n    // Reread the config to get dfs.hosts and dfs.hosts.exclude filenames.\n    // Update the file names and refresh internal includes and excludes list\n    if (conf \u003d\u003d null)\n      conf \u003d new HdfsConfiguration();\n    hostsReader.updateFileNames(conf.get(DFSConfigKeys.DFS_HOSTS,\"\"), \n                                conf.get(DFSConfigKeys.DFS_HOSTS_EXCLUDE, \"\"));\n    hostsReader.refresh();\n    writeLock();\n    try {\n      for (Iterator\u003cDatanodeDescriptor\u003e it \u003d datanodeMap.values().iterator();\n           it.hasNext();) {\n        DatanodeDescriptor node \u003d it.next();\n        // Check if not include.\n        if (!inHostsList(node, null)) {\n          node.setDisallowed(true);  // case 2.\n        } else {\n          if (inExcludedHostsList(node, null)) {\n            startDecommission(node);   // case 3.\n          } else {\n            stopDecommission(node);   // case 4.\n          }\n        }\n      }\n    } finally {\n      writeUnlock();\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}