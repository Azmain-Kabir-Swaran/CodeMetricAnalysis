{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LocalDirAllocator.java",
  "functionName": "confChanged",
  "functionId": "confChanged___conf-Configuration",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java",
  "functionStartLine": 306,
  "functionEndLine": 357,
  "numCommitsSeen": 26,
  "timeTaken": 2703,
  "changeHistory": [
    "e6873dfde057e63ce5efa91f3061db3ee1b2e236",
    "c14c1b298e29e799f7c8f15ff24d7eba6e0cd39b",
    "fd026f535cc09e99a7d4d5d2a8c13eabe8865315",
    "a7e450c7cc0adef3ff832368a2a041bb51396945",
    "42900bd080ef466c4298631bcf0d16414cf101bf",
    "d50ecc38a3e0f5405bcf14b22934e7a89a190f6e",
    "c2e1756d7a604b64a3fbeba955754a8f844af70a",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
    "341b4a444efba9910331180155c41406be599644",
    "1191be630ff05c9f1a540b952a8e34665f7fc181",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
    "96a1477d02e29b3002678f4da9ca55184888a54c",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36"
  ],
  "changeHistoryShort": {
    "e6873dfde057e63ce5efa91f3061db3ee1b2e236": "Ybodychange",
    "c14c1b298e29e799f7c8f15ff24d7eba6e0cd39b": "Ymultichange(Yreturntypechange,Ymodifierchange,Ybodychange)",
    "fd026f535cc09e99a7d4d5d2a8c13eabe8865315": "Ybodychange",
    "a7e450c7cc0adef3ff832368a2a041bb51396945": "Ybodychange",
    "42900bd080ef466c4298631bcf0d16414cf101bf": "Ybodychange",
    "d50ecc38a3e0f5405bcf14b22934e7a89a190f6e": "Ybodychange",
    "c2e1756d7a604b64a3fbeba955754a8f844af70a": "Ymodifierchange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": "Yfilerename",
    "341b4a444efba9910331180155c41406be599644": "Ybodychange",
    "1191be630ff05c9f1a540b952a8e34665f7fc181": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yfilerename",
    "96a1477d02e29b3002678f4da9ca55184888a54c": "Ybodychange",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": "Yintroduced"
  },
  "changeHistoryDetails": {
    "e6873dfde057e63ce5efa91f3061db3ee1b2e236": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7300. DiskValidator is not used in LocalDirAllocator. (Szilard Nemeth via Haibo Chen)\n",
      "commitDate": "19/07/18 4:27 PM",
      "commitName": "e6873dfde057e63ce5efa91f3061db3ee1b2e236",
      "commitAuthor": "Haibo Chen",
      "commitDateOld": "29/06/18 11:18 AM",
      "commitNameOld": "d36f6b9e93e4c30d24d0e837cb00bd24ffa8f274",
      "commitAuthorOld": "Eric E Payne",
      "daysBetweenCommits": 20.21,
      "commitsBetweenForRepo": 113,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,52 +1,52 @@\n     private Context confChanged(Configuration conf)\n         throws IOException {\n       Context ctx \u003d currentContext.get();\n       String newLocalDirs \u003d conf.get(contextCfgItemName);\n       if (null \u003d\u003d newLocalDirs) {\n         throw new IOException(contextCfgItemName + \" not configured\");\n       }\n       if (!newLocalDirs.equals(ctx.savedLocalDirs)) {\n         ctx \u003d new Context();\n         String[] dirStrings \u003d StringUtils.getTrimmedStrings(newLocalDirs);\n         ctx.localFS \u003d FileSystem.getLocal(conf);\n         int numDirs \u003d dirStrings.length;\n         ArrayList\u003cPath\u003e dirs \u003d new ArrayList\u003cPath\u003e(numDirs);\n         ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n         for (int i \u003d 0; i \u003c numDirs; i++) {\n           try {\n             // filter problematic directories\n             Path tmpDir \u003d new Path(dirStrings[i]);\n             if(ctx.localFS.mkdirs(tmpDir)|| ctx.localFS.exists(tmpDir)) {\n               try {\n                 File tmpFile \u003d tmpDir.isAbsolute()\n                     ? new File(ctx.localFS.makeQualified(tmpDir).toUri())\n                     : new File(dirStrings[i]);\n \n-                DiskChecker.checkDir(tmpFile);\n+                diskValidator.checkStatus(tmpFile);\n                 dirs.add(new Path(tmpFile.getPath()));\n                 dfList.add(new DF(tmpFile, 30000));\n               } catch (DiskErrorException de) {\n                 LOG.warn(dirStrings[i] + \" is not writable\\n\", de);\n               }\n             } else {\n               LOG.warn(\"Failed to create \" + dirStrings[i]);\n             }\n           } catch (IOException ie) { \n             LOG.warn(\"Failed to create \" + dirStrings[i] + \": \" +\n                 ie.getMessage() + \"\\n\", ie);\n           } //ignore\n         }\n         ctx.localDirs \u003d dirs.toArray(new Path[dirs.size()]);\n         ctx.dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n         ctx.savedLocalDirs \u003d newLocalDirs;\n \n         if (dirs.size() \u003e 0) {\n           // randomize the first disk picked in the round-robin selection\n           ctx.dirNumLastAccessed.set(dirIndexRandomizer.nextInt(dirs.size()));\n         }\n \n         currentContext.set(ctx);\n       }\n \n       return ctx;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private Context confChanged(Configuration conf)\n        throws IOException {\n      Context ctx \u003d currentContext.get();\n      String newLocalDirs \u003d conf.get(contextCfgItemName);\n      if (null \u003d\u003d newLocalDirs) {\n        throw new IOException(contextCfgItemName + \" not configured\");\n      }\n      if (!newLocalDirs.equals(ctx.savedLocalDirs)) {\n        ctx \u003d new Context();\n        String[] dirStrings \u003d StringUtils.getTrimmedStrings(newLocalDirs);\n        ctx.localFS \u003d FileSystem.getLocal(conf);\n        int numDirs \u003d dirStrings.length;\n        ArrayList\u003cPath\u003e dirs \u003d new ArrayList\u003cPath\u003e(numDirs);\n        ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n        for (int i \u003d 0; i \u003c numDirs; i++) {\n          try {\n            // filter problematic directories\n            Path tmpDir \u003d new Path(dirStrings[i]);\n            if(ctx.localFS.mkdirs(tmpDir)|| ctx.localFS.exists(tmpDir)) {\n              try {\n                File tmpFile \u003d tmpDir.isAbsolute()\n                    ? new File(ctx.localFS.makeQualified(tmpDir).toUri())\n                    : new File(dirStrings[i]);\n\n                diskValidator.checkStatus(tmpFile);\n                dirs.add(new Path(tmpFile.getPath()));\n                dfList.add(new DF(tmpFile, 30000));\n              } catch (DiskErrorException de) {\n                LOG.warn(dirStrings[i] + \" is not writable\\n\", de);\n              }\n            } else {\n              LOG.warn(\"Failed to create \" + dirStrings[i]);\n            }\n          } catch (IOException ie) { \n            LOG.warn(\"Failed to create \" + dirStrings[i] + \": \" +\n                ie.getMessage() + \"\\n\", ie);\n          } //ignore\n        }\n        ctx.localDirs \u003d dirs.toArray(new Path[dirs.size()]);\n        ctx.dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n        ctx.savedLocalDirs \u003d newLocalDirs;\n\n        if (dirs.size() \u003e 0) {\n          // randomize the first disk picked in the round-robin selection\n          ctx.dirNumLastAccessed.set(dirIndexRandomizer.nextInt(dirs.size()));\n        }\n\n        currentContext.set(ctx);\n      }\n\n      return ctx;\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java",
      "extendedDetails": {}
    },
    "c14c1b298e29e799f7c8f15ff24d7eba6e0cd39b": {
      "type": "Ymultichange(Yreturntypechange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HADOOP-10048. LocalDirAllocator should avoid holding locks while accessing the filesystem. Contributed by Jason Lowe.\n",
      "commitDate": "07/06/16 9:18 AM",
      "commitName": "c14c1b298e29e799f7c8f15ff24d7eba6e0cd39b",
      "commitAuthor": "Junping Du",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HADOOP-10048. LocalDirAllocator should avoid holding locks while accessing the filesystem. Contributed by Jason Lowe.\n",
          "commitDate": "07/06/16 9:18 AM",
          "commitName": "c14c1b298e29e799f7c8f15ff24d7eba6e0cd39b",
          "commitAuthor": "Junping Du",
          "commitDateOld": "01/10/15 11:56 AM",
          "commitNameOld": "fd026f535cc09e99a7d4d5d2a8c13eabe8865315",
          "commitAuthorOld": "Zhihai Xu",
          "daysBetweenCommits": 249.89,
          "commitsBetweenForRepo": 1655,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,48 +1,52 @@\n-    private synchronized void confChanged(Configuration conf) \n+    private Context confChanged(Configuration conf)\n         throws IOException {\n+      Context ctx \u003d currentContext.get();\n       String newLocalDirs \u003d conf.get(contextCfgItemName);\n       if (null \u003d\u003d newLocalDirs) {\n         throw new IOException(contextCfgItemName + \" not configured\");\n       }\n-      if (!newLocalDirs.equals(savedLocalDirs)) {\n-        localDirs \u003d StringUtils.getTrimmedStrings(newLocalDirs);\n-        localFS \u003d FileSystem.getLocal(conf);\n-        int numDirs \u003d localDirs.length;\n-        ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n+      if (!newLocalDirs.equals(ctx.savedLocalDirs)) {\n+        ctx \u003d new Context();\n+        String[] dirStrings \u003d StringUtils.getTrimmedStrings(newLocalDirs);\n+        ctx.localFS \u003d FileSystem.getLocal(conf);\n+        int numDirs \u003d dirStrings.length;\n+        ArrayList\u003cPath\u003e dirs \u003d new ArrayList\u003cPath\u003e(numDirs);\n         ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n         for (int i \u003d 0; i \u003c numDirs; i++) {\n           try {\n             // filter problematic directories\n-            Path tmpDir \u003d new Path(localDirs[i]);\n-            if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n+            Path tmpDir \u003d new Path(dirStrings[i]);\n+            if(ctx.localFS.mkdirs(tmpDir)|| ctx.localFS.exists(tmpDir)) {\n               try {\n-\n                 File tmpFile \u003d tmpDir.isAbsolute()\n-                  ? new File(localFS.makeQualified(tmpDir).toUri())\n-                  : new File(localDirs[i]);\n+                    ? new File(ctx.localFS.makeQualified(tmpDir).toUri())\n+                    : new File(dirStrings[i]);\n \n                 DiskChecker.checkDir(tmpFile);\n-                dirs.add(tmpFile.getPath());\n+                dirs.add(new Path(tmpFile.getPath()));\n                 dfList.add(new DF(tmpFile, 30000));\n-\n               } catch (DiskErrorException de) {\n-                LOG.warn( localDirs[i] + \" is not writable\\n\", de);\n+                LOG.warn(dirStrings[i] + \" is not writable\\n\", de);\n               }\n             } else {\n-              LOG.warn( \"Failed to create \" + localDirs[i]);\n+              LOG.warn(\"Failed to create \" + dirStrings[i]);\n             }\n           } catch (IOException ie) { \n-            LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n+            LOG.warn(\"Failed to create \" + dirStrings[i] + \": \" +\n                 ie.getMessage() + \"\\n\", ie);\n           } //ignore\n         }\n-        localDirs \u003d dirs.toArray(new String[dirs.size()]);\n-        dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n-        savedLocalDirs \u003d newLocalDirs;\n-        \n+        ctx.localDirs \u003d dirs.toArray(new Path[dirs.size()]);\n+        ctx.dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n+        ctx.savedLocalDirs \u003d newLocalDirs;\n+\n         if (dirs.size() \u003e 0) {\n           // randomize the first disk picked in the round-robin selection\n-          dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n+          ctx.dirNumLastAccessed.set(dirIndexRandomizer.nextInt(dirs.size()));\n         }\n+\n+        currentContext.set(ctx);\n       }\n+\n+      return ctx;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private Context confChanged(Configuration conf)\n        throws IOException {\n      Context ctx \u003d currentContext.get();\n      String newLocalDirs \u003d conf.get(contextCfgItemName);\n      if (null \u003d\u003d newLocalDirs) {\n        throw new IOException(contextCfgItemName + \" not configured\");\n      }\n      if (!newLocalDirs.equals(ctx.savedLocalDirs)) {\n        ctx \u003d new Context();\n        String[] dirStrings \u003d StringUtils.getTrimmedStrings(newLocalDirs);\n        ctx.localFS \u003d FileSystem.getLocal(conf);\n        int numDirs \u003d dirStrings.length;\n        ArrayList\u003cPath\u003e dirs \u003d new ArrayList\u003cPath\u003e(numDirs);\n        ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n        for (int i \u003d 0; i \u003c numDirs; i++) {\n          try {\n            // filter problematic directories\n            Path tmpDir \u003d new Path(dirStrings[i]);\n            if(ctx.localFS.mkdirs(tmpDir)|| ctx.localFS.exists(tmpDir)) {\n              try {\n                File tmpFile \u003d tmpDir.isAbsolute()\n                    ? new File(ctx.localFS.makeQualified(tmpDir).toUri())\n                    : new File(dirStrings[i]);\n\n                DiskChecker.checkDir(tmpFile);\n                dirs.add(new Path(tmpFile.getPath()));\n                dfList.add(new DF(tmpFile, 30000));\n              } catch (DiskErrorException de) {\n                LOG.warn(dirStrings[i] + \" is not writable\\n\", de);\n              }\n            } else {\n              LOG.warn(\"Failed to create \" + dirStrings[i]);\n            }\n          } catch (IOException ie) { \n            LOG.warn(\"Failed to create \" + dirStrings[i] + \": \" +\n                ie.getMessage() + \"\\n\", ie);\n          } //ignore\n        }\n        ctx.localDirs \u003d dirs.toArray(new Path[dirs.size()]);\n        ctx.dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n        ctx.savedLocalDirs \u003d newLocalDirs;\n\n        if (dirs.size() \u003e 0) {\n          // randomize the first disk picked in the round-robin selection\n          ctx.dirNumLastAccessed.set(dirIndexRandomizer.nextInt(dirs.size()));\n        }\n\n        currentContext.set(ctx);\n      }\n\n      return ctx;\n    }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java",
          "extendedDetails": {
            "oldValue": "void",
            "newValue": "Context"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HADOOP-10048. LocalDirAllocator should avoid holding locks while accessing the filesystem. Contributed by Jason Lowe.\n",
          "commitDate": "07/06/16 9:18 AM",
          "commitName": "c14c1b298e29e799f7c8f15ff24d7eba6e0cd39b",
          "commitAuthor": "Junping Du",
          "commitDateOld": "01/10/15 11:56 AM",
          "commitNameOld": "fd026f535cc09e99a7d4d5d2a8c13eabe8865315",
          "commitAuthorOld": "Zhihai Xu",
          "daysBetweenCommits": 249.89,
          "commitsBetweenForRepo": 1655,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,48 +1,52 @@\n-    private synchronized void confChanged(Configuration conf) \n+    private Context confChanged(Configuration conf)\n         throws IOException {\n+      Context ctx \u003d currentContext.get();\n       String newLocalDirs \u003d conf.get(contextCfgItemName);\n       if (null \u003d\u003d newLocalDirs) {\n         throw new IOException(contextCfgItemName + \" not configured\");\n       }\n-      if (!newLocalDirs.equals(savedLocalDirs)) {\n-        localDirs \u003d StringUtils.getTrimmedStrings(newLocalDirs);\n-        localFS \u003d FileSystem.getLocal(conf);\n-        int numDirs \u003d localDirs.length;\n-        ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n+      if (!newLocalDirs.equals(ctx.savedLocalDirs)) {\n+        ctx \u003d new Context();\n+        String[] dirStrings \u003d StringUtils.getTrimmedStrings(newLocalDirs);\n+        ctx.localFS \u003d FileSystem.getLocal(conf);\n+        int numDirs \u003d dirStrings.length;\n+        ArrayList\u003cPath\u003e dirs \u003d new ArrayList\u003cPath\u003e(numDirs);\n         ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n         for (int i \u003d 0; i \u003c numDirs; i++) {\n           try {\n             // filter problematic directories\n-            Path tmpDir \u003d new Path(localDirs[i]);\n-            if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n+            Path tmpDir \u003d new Path(dirStrings[i]);\n+            if(ctx.localFS.mkdirs(tmpDir)|| ctx.localFS.exists(tmpDir)) {\n               try {\n-\n                 File tmpFile \u003d tmpDir.isAbsolute()\n-                  ? new File(localFS.makeQualified(tmpDir).toUri())\n-                  : new File(localDirs[i]);\n+                    ? new File(ctx.localFS.makeQualified(tmpDir).toUri())\n+                    : new File(dirStrings[i]);\n \n                 DiskChecker.checkDir(tmpFile);\n-                dirs.add(tmpFile.getPath());\n+                dirs.add(new Path(tmpFile.getPath()));\n                 dfList.add(new DF(tmpFile, 30000));\n-\n               } catch (DiskErrorException de) {\n-                LOG.warn( localDirs[i] + \" is not writable\\n\", de);\n+                LOG.warn(dirStrings[i] + \" is not writable\\n\", de);\n               }\n             } else {\n-              LOG.warn( \"Failed to create \" + localDirs[i]);\n+              LOG.warn(\"Failed to create \" + dirStrings[i]);\n             }\n           } catch (IOException ie) { \n-            LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n+            LOG.warn(\"Failed to create \" + dirStrings[i] + \": \" +\n                 ie.getMessage() + \"\\n\", ie);\n           } //ignore\n         }\n-        localDirs \u003d dirs.toArray(new String[dirs.size()]);\n-        dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n-        savedLocalDirs \u003d newLocalDirs;\n-        \n+        ctx.localDirs \u003d dirs.toArray(new Path[dirs.size()]);\n+        ctx.dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n+        ctx.savedLocalDirs \u003d newLocalDirs;\n+\n         if (dirs.size() \u003e 0) {\n           // randomize the first disk picked in the round-robin selection\n-          dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n+          ctx.dirNumLastAccessed.set(dirIndexRandomizer.nextInt(dirs.size()));\n         }\n+\n+        currentContext.set(ctx);\n       }\n+\n+      return ctx;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private Context confChanged(Configuration conf)\n        throws IOException {\n      Context ctx \u003d currentContext.get();\n      String newLocalDirs \u003d conf.get(contextCfgItemName);\n      if (null \u003d\u003d newLocalDirs) {\n        throw new IOException(contextCfgItemName + \" not configured\");\n      }\n      if (!newLocalDirs.equals(ctx.savedLocalDirs)) {\n        ctx \u003d new Context();\n        String[] dirStrings \u003d StringUtils.getTrimmedStrings(newLocalDirs);\n        ctx.localFS \u003d FileSystem.getLocal(conf);\n        int numDirs \u003d dirStrings.length;\n        ArrayList\u003cPath\u003e dirs \u003d new ArrayList\u003cPath\u003e(numDirs);\n        ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n        for (int i \u003d 0; i \u003c numDirs; i++) {\n          try {\n            // filter problematic directories\n            Path tmpDir \u003d new Path(dirStrings[i]);\n            if(ctx.localFS.mkdirs(tmpDir)|| ctx.localFS.exists(tmpDir)) {\n              try {\n                File tmpFile \u003d tmpDir.isAbsolute()\n                    ? new File(ctx.localFS.makeQualified(tmpDir).toUri())\n                    : new File(dirStrings[i]);\n\n                DiskChecker.checkDir(tmpFile);\n                dirs.add(new Path(tmpFile.getPath()));\n                dfList.add(new DF(tmpFile, 30000));\n              } catch (DiskErrorException de) {\n                LOG.warn(dirStrings[i] + \" is not writable\\n\", de);\n              }\n            } else {\n              LOG.warn(\"Failed to create \" + dirStrings[i]);\n            }\n          } catch (IOException ie) { \n            LOG.warn(\"Failed to create \" + dirStrings[i] + \": \" +\n                ie.getMessage() + \"\\n\", ie);\n          } //ignore\n        }\n        ctx.localDirs \u003d dirs.toArray(new Path[dirs.size()]);\n        ctx.dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n        ctx.savedLocalDirs \u003d newLocalDirs;\n\n        if (dirs.size() \u003e 0) {\n          // randomize the first disk picked in the round-robin selection\n          ctx.dirNumLastAccessed.set(dirIndexRandomizer.nextInt(dirs.size()));\n        }\n\n        currentContext.set(ctx);\n      }\n\n      return ctx;\n    }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java",
          "extendedDetails": {
            "oldValue": "[private, synchronized]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-10048. LocalDirAllocator should avoid holding locks while accessing the filesystem. Contributed by Jason Lowe.\n",
          "commitDate": "07/06/16 9:18 AM",
          "commitName": "c14c1b298e29e799f7c8f15ff24d7eba6e0cd39b",
          "commitAuthor": "Junping Du",
          "commitDateOld": "01/10/15 11:56 AM",
          "commitNameOld": "fd026f535cc09e99a7d4d5d2a8c13eabe8865315",
          "commitAuthorOld": "Zhihai Xu",
          "daysBetweenCommits": 249.89,
          "commitsBetweenForRepo": 1655,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,48 +1,52 @@\n-    private synchronized void confChanged(Configuration conf) \n+    private Context confChanged(Configuration conf)\n         throws IOException {\n+      Context ctx \u003d currentContext.get();\n       String newLocalDirs \u003d conf.get(contextCfgItemName);\n       if (null \u003d\u003d newLocalDirs) {\n         throw new IOException(contextCfgItemName + \" not configured\");\n       }\n-      if (!newLocalDirs.equals(savedLocalDirs)) {\n-        localDirs \u003d StringUtils.getTrimmedStrings(newLocalDirs);\n-        localFS \u003d FileSystem.getLocal(conf);\n-        int numDirs \u003d localDirs.length;\n-        ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n+      if (!newLocalDirs.equals(ctx.savedLocalDirs)) {\n+        ctx \u003d new Context();\n+        String[] dirStrings \u003d StringUtils.getTrimmedStrings(newLocalDirs);\n+        ctx.localFS \u003d FileSystem.getLocal(conf);\n+        int numDirs \u003d dirStrings.length;\n+        ArrayList\u003cPath\u003e dirs \u003d new ArrayList\u003cPath\u003e(numDirs);\n         ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n         for (int i \u003d 0; i \u003c numDirs; i++) {\n           try {\n             // filter problematic directories\n-            Path tmpDir \u003d new Path(localDirs[i]);\n-            if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n+            Path tmpDir \u003d new Path(dirStrings[i]);\n+            if(ctx.localFS.mkdirs(tmpDir)|| ctx.localFS.exists(tmpDir)) {\n               try {\n-\n                 File tmpFile \u003d tmpDir.isAbsolute()\n-                  ? new File(localFS.makeQualified(tmpDir).toUri())\n-                  : new File(localDirs[i]);\n+                    ? new File(ctx.localFS.makeQualified(tmpDir).toUri())\n+                    : new File(dirStrings[i]);\n \n                 DiskChecker.checkDir(tmpFile);\n-                dirs.add(tmpFile.getPath());\n+                dirs.add(new Path(tmpFile.getPath()));\n                 dfList.add(new DF(tmpFile, 30000));\n-\n               } catch (DiskErrorException de) {\n-                LOG.warn( localDirs[i] + \" is not writable\\n\", de);\n+                LOG.warn(dirStrings[i] + \" is not writable\\n\", de);\n               }\n             } else {\n-              LOG.warn( \"Failed to create \" + localDirs[i]);\n+              LOG.warn(\"Failed to create \" + dirStrings[i]);\n             }\n           } catch (IOException ie) { \n-            LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n+            LOG.warn(\"Failed to create \" + dirStrings[i] + \": \" +\n                 ie.getMessage() + \"\\n\", ie);\n           } //ignore\n         }\n-        localDirs \u003d dirs.toArray(new String[dirs.size()]);\n-        dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n-        savedLocalDirs \u003d newLocalDirs;\n-        \n+        ctx.localDirs \u003d dirs.toArray(new Path[dirs.size()]);\n+        ctx.dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n+        ctx.savedLocalDirs \u003d newLocalDirs;\n+\n         if (dirs.size() \u003e 0) {\n           // randomize the first disk picked in the round-robin selection\n-          dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n+          ctx.dirNumLastAccessed.set(dirIndexRandomizer.nextInt(dirs.size()));\n         }\n+\n+        currentContext.set(ctx);\n       }\n+\n+      return ctx;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private Context confChanged(Configuration conf)\n        throws IOException {\n      Context ctx \u003d currentContext.get();\n      String newLocalDirs \u003d conf.get(contextCfgItemName);\n      if (null \u003d\u003d newLocalDirs) {\n        throw new IOException(contextCfgItemName + \" not configured\");\n      }\n      if (!newLocalDirs.equals(ctx.savedLocalDirs)) {\n        ctx \u003d new Context();\n        String[] dirStrings \u003d StringUtils.getTrimmedStrings(newLocalDirs);\n        ctx.localFS \u003d FileSystem.getLocal(conf);\n        int numDirs \u003d dirStrings.length;\n        ArrayList\u003cPath\u003e dirs \u003d new ArrayList\u003cPath\u003e(numDirs);\n        ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n        for (int i \u003d 0; i \u003c numDirs; i++) {\n          try {\n            // filter problematic directories\n            Path tmpDir \u003d new Path(dirStrings[i]);\n            if(ctx.localFS.mkdirs(tmpDir)|| ctx.localFS.exists(tmpDir)) {\n              try {\n                File tmpFile \u003d tmpDir.isAbsolute()\n                    ? new File(ctx.localFS.makeQualified(tmpDir).toUri())\n                    : new File(dirStrings[i]);\n\n                DiskChecker.checkDir(tmpFile);\n                dirs.add(new Path(tmpFile.getPath()));\n                dfList.add(new DF(tmpFile, 30000));\n              } catch (DiskErrorException de) {\n                LOG.warn(dirStrings[i] + \" is not writable\\n\", de);\n              }\n            } else {\n              LOG.warn(\"Failed to create \" + dirStrings[i]);\n            }\n          } catch (IOException ie) { \n            LOG.warn(\"Failed to create \" + dirStrings[i] + \": \" +\n                ie.getMessage() + \"\\n\", ie);\n          } //ignore\n        }\n        ctx.localDirs \u003d dirs.toArray(new Path[dirs.size()]);\n        ctx.dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n        ctx.savedLocalDirs \u003d newLocalDirs;\n\n        if (dirs.size() \u003e 0) {\n          // randomize the first disk picked in the round-robin selection\n          ctx.dirNumLastAccessed.set(dirIndexRandomizer.nextInt(dirs.size()));\n        }\n\n        currentContext.set(ctx);\n      }\n\n      return ctx;\n    }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java",
          "extendedDetails": {}
        }
      ]
    },
    "fd026f535cc09e99a7d4d5d2a8c13eabe8865315": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-8437. getLocalPathForWrite should throw IOException for invalid paths. Contributed by Brahma Reddy Battula\n",
      "commitDate": "01/10/15 11:56 AM",
      "commitName": "fd026f535cc09e99a7d4d5d2a8c13eabe8865315",
      "commitAuthor": "Zhihai Xu",
      "commitDateOld": "24/09/15 11:51 AM",
      "commitNameOld": "52c1f272ecb6c29c81898a1ff50d03a1296df1f7",
      "commitAuthorOld": "Zhihai Xu",
      "daysBetweenCommits": 7.0,
      "commitsBetweenForRepo": 50,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,48 @@\n     private synchronized void confChanged(Configuration conf) \n         throws IOException {\n       String newLocalDirs \u003d conf.get(contextCfgItemName);\n       if (null \u003d\u003d newLocalDirs) {\n         throw new IOException(contextCfgItemName + \" not configured\");\n       }\n       if (!newLocalDirs.equals(savedLocalDirs)) {\n         localDirs \u003d StringUtils.getTrimmedStrings(newLocalDirs);\n         localFS \u003d FileSystem.getLocal(conf);\n         int numDirs \u003d localDirs.length;\n         ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n         ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n         for (int i \u003d 0; i \u003c numDirs; i++) {\n           try {\n             // filter problematic directories\n             Path tmpDir \u003d new Path(localDirs[i]);\n             if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n               try {\n \n                 File tmpFile \u003d tmpDir.isAbsolute()\n                   ? new File(localFS.makeQualified(tmpDir).toUri())\n                   : new File(localDirs[i]);\n \n                 DiskChecker.checkDir(tmpFile);\n                 dirs.add(tmpFile.getPath());\n                 dfList.add(new DF(tmpFile, 30000));\n \n               } catch (DiskErrorException de) {\n                 LOG.warn( localDirs[i] + \" is not writable\\n\", de);\n               }\n             } else {\n               LOG.warn( \"Failed to create \" + localDirs[i]);\n             }\n           } catch (IOException ie) { \n             LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                 ie.getMessage() + \"\\n\", ie);\n           } //ignore\n         }\n         localDirs \u003d dirs.toArray(new String[dirs.size()]);\n         dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n         savedLocalDirs \u003d newLocalDirs;\n         \n-        // randomize the first disk picked in the round-robin selection \n-        dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n+        if (dirs.size() \u003e 0) {\n+          // randomize the first disk picked in the round-robin selection\n+          dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n+        }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private synchronized void confChanged(Configuration conf) \n        throws IOException {\n      String newLocalDirs \u003d conf.get(contextCfgItemName);\n      if (null \u003d\u003d newLocalDirs) {\n        throw new IOException(contextCfgItemName + \" not configured\");\n      }\n      if (!newLocalDirs.equals(savedLocalDirs)) {\n        localDirs \u003d StringUtils.getTrimmedStrings(newLocalDirs);\n        localFS \u003d FileSystem.getLocal(conf);\n        int numDirs \u003d localDirs.length;\n        ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n        ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n        for (int i \u003d 0; i \u003c numDirs; i++) {\n          try {\n            // filter problematic directories\n            Path tmpDir \u003d new Path(localDirs[i]);\n            if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n              try {\n\n                File tmpFile \u003d tmpDir.isAbsolute()\n                  ? new File(localFS.makeQualified(tmpDir).toUri())\n                  : new File(localDirs[i]);\n\n                DiskChecker.checkDir(tmpFile);\n                dirs.add(tmpFile.getPath());\n                dfList.add(new DF(tmpFile, 30000));\n\n              } catch (DiskErrorException de) {\n                LOG.warn( localDirs[i] + \" is not writable\\n\", de);\n              }\n            } else {\n              LOG.warn( \"Failed to create \" + localDirs[i]);\n            }\n          } catch (IOException ie) { \n            LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                ie.getMessage() + \"\\n\", ie);\n          } //ignore\n        }\n        localDirs \u003d dirs.toArray(new String[dirs.size()]);\n        dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n        savedLocalDirs \u003d newLocalDirs;\n        \n        if (dirs.size() \u003e 0) {\n          // randomize the first disk picked in the round-robin selection\n          dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n        }\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java",
      "extendedDetails": {}
    },
    "a7e450c7cc0adef3ff832368a2a041bb51396945": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-8436. NPE In getLocalPathForWrite ( path, conf ) when the required context item is not configured. Contributed by Brahma Reddy Battula. (harsh)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1389799 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/09/12 4:10 AM",
      "commitName": "a7e450c7cc0adef3ff832368a2a041bb51396945",
      "commitAuthor": "Harsh J",
      "commitDateOld": "06/07/12 10:19 AM",
      "commitNameOld": "0e7204c9e740bfbe13b0128f7612e616e30c1970",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 80.74,
      "commitsBetweenForRepo": 454,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,46 @@\n     private synchronized void confChanged(Configuration conf) \n         throws IOException {\n       String newLocalDirs \u003d conf.get(contextCfgItemName);\n+      if (null \u003d\u003d newLocalDirs) {\n+        throw new IOException(contextCfgItemName + \" not configured\");\n+      }\n       if (!newLocalDirs.equals(savedLocalDirs)) {\n         localDirs \u003d StringUtils.getTrimmedStrings(newLocalDirs);\n         localFS \u003d FileSystem.getLocal(conf);\n         int numDirs \u003d localDirs.length;\n         ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n         ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n         for (int i \u003d 0; i \u003c numDirs; i++) {\n           try {\n             // filter problematic directories\n             Path tmpDir \u003d new Path(localDirs[i]);\n             if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n               try {\n \n                 File tmpFile \u003d tmpDir.isAbsolute()\n                   ? new File(localFS.makeQualified(tmpDir).toUri())\n                   : new File(localDirs[i]);\n \n                 DiskChecker.checkDir(tmpFile);\n                 dirs.add(tmpFile.getPath());\n                 dfList.add(new DF(tmpFile, 30000));\n \n               } catch (DiskErrorException de) {\n                 LOG.warn( localDirs[i] + \" is not writable\\n\", de);\n               }\n             } else {\n               LOG.warn( \"Failed to create \" + localDirs[i]);\n             }\n           } catch (IOException ie) { \n             LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                 ie.getMessage() + \"\\n\", ie);\n           } //ignore\n         }\n         localDirs \u003d dirs.toArray(new String[dirs.size()]);\n         dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n         savedLocalDirs \u003d newLocalDirs;\n         \n         // randomize the first disk picked in the round-robin selection \n         dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private synchronized void confChanged(Configuration conf) \n        throws IOException {\n      String newLocalDirs \u003d conf.get(contextCfgItemName);\n      if (null \u003d\u003d newLocalDirs) {\n        throw new IOException(contextCfgItemName + \" not configured\");\n      }\n      if (!newLocalDirs.equals(savedLocalDirs)) {\n        localDirs \u003d StringUtils.getTrimmedStrings(newLocalDirs);\n        localFS \u003d FileSystem.getLocal(conf);\n        int numDirs \u003d localDirs.length;\n        ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n        ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n        for (int i \u003d 0; i \u003c numDirs; i++) {\n          try {\n            // filter problematic directories\n            Path tmpDir \u003d new Path(localDirs[i]);\n            if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n              try {\n\n                File tmpFile \u003d tmpDir.isAbsolute()\n                  ? new File(localFS.makeQualified(tmpDir).toUri())\n                  : new File(localDirs[i]);\n\n                DiskChecker.checkDir(tmpFile);\n                dirs.add(tmpFile.getPath());\n                dfList.add(new DF(tmpFile, 30000));\n\n              } catch (DiskErrorException de) {\n                LOG.warn( localDirs[i] + \" is not writable\\n\", de);\n              }\n            } else {\n              LOG.warn( \"Failed to create \" + localDirs[i]);\n            }\n          } catch (IOException ie) { \n            LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                ie.getMessage() + \"\\n\", ie);\n          } //ignore\n        }\n        localDirs \u003d dirs.toArray(new String[dirs.size()]);\n        dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n        savedLocalDirs \u003d newLocalDirs;\n        \n        // randomize the first disk picked in the round-robin selection \n        dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java",
      "extendedDetails": {}
    },
    "42900bd080ef466c4298631bcf0d16414cf101bf": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-7900. LocalDirAllocator confChanged() accesses conf.get() twice. Contributed by Ravi Gummadi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1299434 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/03/12 12:23 PM",
      "commitName": "42900bd080ef466c4298631bcf0d16414cf101bf",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "21/09/11 6:26 AM",
      "commitNameOld": "d50ecc38a3e0f5405bcf14b22934e7a89a190f6e",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 172.25,
      "commitsBetweenForRepo": 1260,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,43 @@\n     private synchronized void confChanged(Configuration conf) \n         throws IOException {\n       String newLocalDirs \u003d conf.get(contextCfgItemName);\n       if (!newLocalDirs.equals(savedLocalDirs)) {\n-        localDirs \u003d conf.getTrimmedStrings(contextCfgItemName);\n+        localDirs \u003d StringUtils.getTrimmedStrings(newLocalDirs);\n         localFS \u003d FileSystem.getLocal(conf);\n         int numDirs \u003d localDirs.length;\n         ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n         ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n         for (int i \u003d 0; i \u003c numDirs; i++) {\n           try {\n             // filter problematic directories\n             Path tmpDir \u003d new Path(localDirs[i]);\n             if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n               try {\n \n                 File tmpFile \u003d tmpDir.isAbsolute()\n                   ? new File(localFS.makeQualified(tmpDir).toUri())\n                   : new File(localDirs[i]);\n \n                 DiskChecker.checkDir(tmpFile);\n                 dirs.add(tmpFile.getPath());\n                 dfList.add(new DF(tmpFile, 30000));\n \n               } catch (DiskErrorException de) {\n                 LOG.warn( localDirs[i] + \" is not writable\\n\", de);\n               }\n             } else {\n               LOG.warn( \"Failed to create \" + localDirs[i]);\n             }\n           } catch (IOException ie) { \n             LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                 ie.getMessage() + \"\\n\", ie);\n           } //ignore\n         }\n         localDirs \u003d dirs.toArray(new String[dirs.size()]);\n         dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n         savedLocalDirs \u003d newLocalDirs;\n         \n         // randomize the first disk picked in the round-robin selection \n         dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private synchronized void confChanged(Configuration conf) \n        throws IOException {\n      String newLocalDirs \u003d conf.get(contextCfgItemName);\n      if (!newLocalDirs.equals(savedLocalDirs)) {\n        localDirs \u003d StringUtils.getTrimmedStrings(newLocalDirs);\n        localFS \u003d FileSystem.getLocal(conf);\n        int numDirs \u003d localDirs.length;\n        ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n        ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n        for (int i \u003d 0; i \u003c numDirs; i++) {\n          try {\n            // filter problematic directories\n            Path tmpDir \u003d new Path(localDirs[i]);\n            if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n              try {\n\n                File tmpFile \u003d tmpDir.isAbsolute()\n                  ? new File(localFS.makeQualified(tmpDir).toUri())\n                  : new File(localDirs[i]);\n\n                DiskChecker.checkDir(tmpFile);\n                dirs.add(tmpFile.getPath());\n                dfList.add(new DF(tmpFile, 30000));\n\n              } catch (DiskErrorException de) {\n                LOG.warn( localDirs[i] + \" is not writable\\n\", de);\n              }\n            } else {\n              LOG.warn( \"Failed to create \" + localDirs[i]);\n            }\n          } catch (IOException ie) { \n            LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                ie.getMessage() + \"\\n\", ie);\n          } //ignore\n        }\n        localDirs \u003d dirs.toArray(new String[dirs.size()]);\n        dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n        savedLocalDirs \u003d newLocalDirs;\n        \n        // randomize the first disk picked in the round-robin selection \n        dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java",
      "extendedDetails": {}
    },
    "d50ecc38a3e0f5405bcf14b22934e7a89a190f6e": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-7575. Enhanced LocalDirAllocator to support fully-qualified paths. Contributed by Jonathan Eagles.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1173623 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/09/11 6:26 AM",
      "commitName": "d50ecc38a3e0f5405bcf14b22934e7a89a190f6e",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "05/09/11 6:36 PM",
      "commitNameOld": "c2e1756d7a604b64a3fbeba955754a8f844af70a",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 15.49,
      "commitsBetweenForRepo": 110,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,43 @@\n     private synchronized void confChanged(Configuration conf) \n         throws IOException {\n       String newLocalDirs \u003d conf.get(contextCfgItemName);\n       if (!newLocalDirs.equals(savedLocalDirs)) {\n         localDirs \u003d conf.getTrimmedStrings(contextCfgItemName);\n         localFS \u003d FileSystem.getLocal(conf);\n         int numDirs \u003d localDirs.length;\n         ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n         ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n         for (int i \u003d 0; i \u003c numDirs; i++) {\n           try {\n             // filter problematic directories\n             Path tmpDir \u003d new Path(localDirs[i]);\n             if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n               try {\n-                DiskChecker.checkDir(new File(localDirs[i]));\n-                dirs.add(localDirs[i]);\n-                dfList.add(new DF(new File(localDirs[i]), 30000));\n+\n+                File tmpFile \u003d tmpDir.isAbsolute()\n+                  ? new File(localFS.makeQualified(tmpDir).toUri())\n+                  : new File(localDirs[i]);\n+\n+                DiskChecker.checkDir(tmpFile);\n+                dirs.add(tmpFile.getPath());\n+                dfList.add(new DF(tmpFile, 30000));\n+\n               } catch (DiskErrorException de) {\n                 LOG.warn( localDirs[i] + \" is not writable\\n\", de);\n               }\n             } else {\n               LOG.warn( \"Failed to create \" + localDirs[i]);\n             }\n           } catch (IOException ie) { \n             LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                 ie.getMessage() + \"\\n\", ie);\n           } //ignore\n         }\n         localDirs \u003d dirs.toArray(new String[dirs.size()]);\n         dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n         savedLocalDirs \u003d newLocalDirs;\n         \n         // randomize the first disk picked in the round-robin selection \n         dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private synchronized void confChanged(Configuration conf) \n        throws IOException {\n      String newLocalDirs \u003d conf.get(contextCfgItemName);\n      if (!newLocalDirs.equals(savedLocalDirs)) {\n        localDirs \u003d conf.getTrimmedStrings(contextCfgItemName);\n        localFS \u003d FileSystem.getLocal(conf);\n        int numDirs \u003d localDirs.length;\n        ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n        ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n        for (int i \u003d 0; i \u003c numDirs; i++) {\n          try {\n            // filter problematic directories\n            Path tmpDir \u003d new Path(localDirs[i]);\n            if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n              try {\n\n                File tmpFile \u003d tmpDir.isAbsolute()\n                  ? new File(localFS.makeQualified(tmpDir).toUri())\n                  : new File(localDirs[i]);\n\n                DiskChecker.checkDir(tmpFile);\n                dirs.add(tmpFile.getPath());\n                dfList.add(new DF(tmpFile, 30000));\n\n              } catch (DiskErrorException de) {\n                LOG.warn( localDirs[i] + \" is not writable\\n\", de);\n              }\n            } else {\n              LOG.warn( \"Failed to create \" + localDirs[i]);\n            }\n          } catch (IOException ie) { \n            LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                ie.getMessage() + \"\\n\", ie);\n          } //ignore\n        }\n        localDirs \u003d dirs.toArray(new String[dirs.size()]);\n        dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n        savedLocalDirs \u003d newLocalDirs;\n        \n        // randomize the first disk picked in the round-robin selection \n        dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java",
      "extendedDetails": {}
    },
    "c2e1756d7a604b64a3fbeba955754a8f844af70a": {
      "type": "Ymodifierchange",
      "commitMessage": "HADOOP-7580. Add a version of getLocalPathForWrite to LocalDirAllocator which doesn\u0027t create dirs. Contributed by Chris Douglas \u0026 Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1165473 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/09/11 6:36 PM",
      "commitName": "c2e1756d7a604b64a3fbeba955754a8f844af70a",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 12.06,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,37 @@\n-    private void confChanged(Configuration conf) throws IOException {\n+    private synchronized void confChanged(Configuration conf) \n+        throws IOException {\n       String newLocalDirs \u003d conf.get(contextCfgItemName);\n       if (!newLocalDirs.equals(savedLocalDirs)) {\n         localDirs \u003d conf.getTrimmedStrings(contextCfgItemName);\n         localFS \u003d FileSystem.getLocal(conf);\n         int numDirs \u003d localDirs.length;\n         ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n         ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n         for (int i \u003d 0; i \u003c numDirs; i++) {\n           try {\n             // filter problematic directories\n             Path tmpDir \u003d new Path(localDirs[i]);\n             if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n               try {\n                 DiskChecker.checkDir(new File(localDirs[i]));\n                 dirs.add(localDirs[i]);\n                 dfList.add(new DF(new File(localDirs[i]), 30000));\n               } catch (DiskErrorException de) {\n                 LOG.warn( localDirs[i] + \" is not writable\\n\", de);\n               }\n             } else {\n               LOG.warn( \"Failed to create \" + localDirs[i]);\n             }\n           } catch (IOException ie) { \n             LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                 ie.getMessage() + \"\\n\", ie);\n           } //ignore\n         }\n         localDirs \u003d dirs.toArray(new String[dirs.size()]);\n         dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n         savedLocalDirs \u003d newLocalDirs;\n         \n         // randomize the first disk picked in the round-robin selection \n         dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private synchronized void confChanged(Configuration conf) \n        throws IOException {\n      String newLocalDirs \u003d conf.get(contextCfgItemName);\n      if (!newLocalDirs.equals(savedLocalDirs)) {\n        localDirs \u003d conf.getTrimmedStrings(contextCfgItemName);\n        localFS \u003d FileSystem.getLocal(conf);\n        int numDirs \u003d localDirs.length;\n        ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n        ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n        for (int i \u003d 0; i \u003c numDirs; i++) {\n          try {\n            // filter problematic directories\n            Path tmpDir \u003d new Path(localDirs[i]);\n            if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n              try {\n                DiskChecker.checkDir(new File(localDirs[i]));\n                dirs.add(localDirs[i]);\n                dfList.add(new DF(new File(localDirs[i]), 30000));\n              } catch (DiskErrorException de) {\n                LOG.warn( localDirs[i] + \" is not writable\\n\", de);\n              }\n            } else {\n              LOG.warn( \"Failed to create \" + localDirs[i]);\n            }\n          } catch (IOException ie) { \n            LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                ie.getMessage() + \"\\n\", ie);\n          } //ignore\n        }\n        localDirs \u003d dirs.toArray(new String[dirs.size()]);\n        dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n        savedLocalDirs \u003d newLocalDirs;\n        \n        // randomize the first disk picked in the round-robin selection \n        dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java",
      "extendedDetails": {
        "oldValue": "[private]",
        "newValue": "[private, synchronized]"
      }
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void confChanged(Configuration conf) throws IOException {\n      String newLocalDirs \u003d conf.get(contextCfgItemName);\n      if (!newLocalDirs.equals(savedLocalDirs)) {\n        localDirs \u003d conf.getTrimmedStrings(contextCfgItemName);\n        localFS \u003d FileSystem.getLocal(conf);\n        int numDirs \u003d localDirs.length;\n        ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n        ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n        for (int i \u003d 0; i \u003c numDirs; i++) {\n          try {\n            // filter problematic directories\n            Path tmpDir \u003d new Path(localDirs[i]);\n            if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n              try {\n                DiskChecker.checkDir(new File(localDirs[i]));\n                dirs.add(localDirs[i]);\n                dfList.add(new DF(new File(localDirs[i]), 30000));\n              } catch (DiskErrorException de) {\n                LOG.warn( localDirs[i] + \" is not writable\\n\", de);\n              }\n            } else {\n              LOG.warn( \"Failed to create \" + localDirs[i]);\n            }\n          } catch (IOException ie) { \n            LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                ie.getMessage() + \"\\n\", ie);\n          } //ignore\n        }\n        localDirs \u003d dirs.toArray(new String[dirs.size()]);\n        dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n        savedLocalDirs \u003d newLocalDirs;\n        \n        // randomize the first disk picked in the round-robin selection \n        dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java",
      "extendedDetails": {
        "oldPath": "hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java"
      }
    },
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-6671. Use maven for hadoop common builds. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1153184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/08/11 9:37 AM",
      "commitName": "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
      "commitAuthor": "Thomas White",
      "commitDateOld": "01/08/11 3:53 PM",
      "commitNameOld": "9bac807cedbcff34e1a144fb475eff267e5ed86d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void confChanged(Configuration conf) throws IOException {\n      String newLocalDirs \u003d conf.get(contextCfgItemName);\n      if (!newLocalDirs.equals(savedLocalDirs)) {\n        localDirs \u003d conf.getTrimmedStrings(contextCfgItemName);\n        localFS \u003d FileSystem.getLocal(conf);\n        int numDirs \u003d localDirs.length;\n        ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n        ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n        for (int i \u003d 0; i \u003c numDirs; i++) {\n          try {\n            // filter problematic directories\n            Path tmpDir \u003d new Path(localDirs[i]);\n            if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n              try {\n                DiskChecker.checkDir(new File(localDirs[i]));\n                dirs.add(localDirs[i]);\n                dfList.add(new DF(new File(localDirs[i]), 30000));\n              } catch (DiskErrorException de) {\n                LOG.warn( localDirs[i] + \" is not writable\\n\", de);\n              }\n            } else {\n              LOG.warn( \"Failed to create \" + localDirs[i]);\n            }\n          } catch (IOException ie) { \n            LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                ie.getMessage() + \"\\n\", ie);\n          } //ignore\n        }\n        localDirs \u003d dirs.toArray(new String[dirs.size()]);\n        dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n        savedLocalDirs \u003d newLocalDirs;\n        \n        // randomize the first disk picked in the round-robin selection \n        dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n      }\n    }",
      "path": "hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java",
      "extendedDetails": {
        "oldPath": "common/src/java/org/apache/hadoop/fs/LocalDirAllocator.java",
        "newPath": "hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java"
      }
    },
    "341b4a444efba9910331180155c41406be599644": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-7465. A several tiny improvements for the LOG format. Contributed by Xie Xianshan\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1147952 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/07/11 9:24 AM",
      "commitName": "341b4a444efba9910331180155c41406be599644",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "23/06/11 4:55 PM",
      "commitNameOld": "1191be630ff05c9f1a540b952a8e34665f7fc181",
      "commitAuthorOld": "Tanping Wang",
      "daysBetweenCommits": 24.69,
      "commitsBetweenForRepo": 76,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,36 @@\n     private void confChanged(Configuration conf) throws IOException {\n       String newLocalDirs \u003d conf.get(contextCfgItemName);\n       if (!newLocalDirs.equals(savedLocalDirs)) {\n         localDirs \u003d conf.getTrimmedStrings(contextCfgItemName);\n         localFS \u003d FileSystem.getLocal(conf);\n         int numDirs \u003d localDirs.length;\n         ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n         ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n         for (int i \u003d 0; i \u003c numDirs; i++) {\n           try {\n             // filter problematic directories\n             Path tmpDir \u003d new Path(localDirs[i]);\n             if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n               try {\n                 DiskChecker.checkDir(new File(localDirs[i]));\n                 dirs.add(localDirs[i]);\n                 dfList.add(new DF(new File(localDirs[i]), 30000));\n               } catch (DiskErrorException de) {\n-                LOG.warn( localDirs[i] + \"is not writable\\n\", de);\n+                LOG.warn( localDirs[i] + \" is not writable\\n\", de);\n               }\n             } else {\n               LOG.warn( \"Failed to create \" + localDirs[i]);\n             }\n           } catch (IOException ie) { \n             LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                 ie.getMessage() + \"\\n\", ie);\n           } //ignore\n         }\n         localDirs \u003d dirs.toArray(new String[dirs.size()]);\n         dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n         savedLocalDirs \u003d newLocalDirs;\n         \n         // randomize the first disk picked in the round-robin selection \n         dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void confChanged(Configuration conf) throws IOException {\n      String newLocalDirs \u003d conf.get(contextCfgItemName);\n      if (!newLocalDirs.equals(savedLocalDirs)) {\n        localDirs \u003d conf.getTrimmedStrings(contextCfgItemName);\n        localFS \u003d FileSystem.getLocal(conf);\n        int numDirs \u003d localDirs.length;\n        ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n        ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n        for (int i \u003d 0; i \u003c numDirs; i++) {\n          try {\n            // filter problematic directories\n            Path tmpDir \u003d new Path(localDirs[i]);\n            if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n              try {\n                DiskChecker.checkDir(new File(localDirs[i]));\n                dirs.add(localDirs[i]);\n                dfList.add(new DF(new File(localDirs[i]), 30000));\n              } catch (DiskErrorException de) {\n                LOG.warn( localDirs[i] + \" is not writable\\n\", de);\n              }\n            } else {\n              LOG.warn( \"Failed to create \" + localDirs[i]);\n            }\n          } catch (IOException ie) { \n            LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                ie.getMessage() + \"\\n\", ie);\n          } //ignore\n        }\n        localDirs \u003d dirs.toArray(new String[dirs.size()]);\n        dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n        savedLocalDirs \u003d newLocalDirs;\n        \n        // randomize the first disk picked in the round-robin selection \n        dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n      }\n    }",
      "path": "common/src/java/org/apache/hadoop/fs/LocalDirAllocator.java",
      "extendedDetails": {}
    },
    "1191be630ff05c9f1a540b952a8e34665f7fc181": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-7385 Remove StringUtils.stringifyException(ie) in logger functions.  Contributed by Bharath Mundlapudi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1139123 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/06/11 4:55 PM",
      "commitName": "1191be630ff05c9f1a540b952a8e34665f7fc181",
      "commitAuthor": "Tanping Wang",
      "commitDateOld": "12/06/11 3:00 PM",
      "commitNameOld": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 11.08,
      "commitsBetweenForRepo": 37,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,36 @@\n     private void confChanged(Configuration conf) throws IOException {\n       String newLocalDirs \u003d conf.get(contextCfgItemName);\n       if (!newLocalDirs.equals(savedLocalDirs)) {\n         localDirs \u003d conf.getTrimmedStrings(contextCfgItemName);\n         localFS \u003d FileSystem.getLocal(conf);\n         int numDirs \u003d localDirs.length;\n         ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n         ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n         for (int i \u003d 0; i \u003c numDirs; i++) {\n           try {\n             // filter problematic directories\n             Path tmpDir \u003d new Path(localDirs[i]);\n             if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n               try {\n                 DiskChecker.checkDir(new File(localDirs[i]));\n                 dirs.add(localDirs[i]);\n                 dfList.add(new DF(new File(localDirs[i]), 30000));\n               } catch (DiskErrorException de) {\n-                LOG.warn( localDirs[i] + \"is not writable\\n\" +\n-                    StringUtils.stringifyException(de));\n+                LOG.warn( localDirs[i] + \"is not writable\\n\", de);\n               }\n             } else {\n               LOG.warn( \"Failed to create \" + localDirs[i]);\n             }\n           } catch (IOException ie) { \n             LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n-                ie.getMessage() + \"\\n\" + StringUtils.stringifyException(ie));\n+                ie.getMessage() + \"\\n\", ie);\n           } //ignore\n         }\n         localDirs \u003d dirs.toArray(new String[dirs.size()]);\n         dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n         savedLocalDirs \u003d newLocalDirs;\n         \n         // randomize the first disk picked in the round-robin selection \n         dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void confChanged(Configuration conf) throws IOException {\n      String newLocalDirs \u003d conf.get(contextCfgItemName);\n      if (!newLocalDirs.equals(savedLocalDirs)) {\n        localDirs \u003d conf.getTrimmedStrings(contextCfgItemName);\n        localFS \u003d FileSystem.getLocal(conf);\n        int numDirs \u003d localDirs.length;\n        ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n        ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n        for (int i \u003d 0; i \u003c numDirs; i++) {\n          try {\n            // filter problematic directories\n            Path tmpDir \u003d new Path(localDirs[i]);\n            if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n              try {\n                DiskChecker.checkDir(new File(localDirs[i]));\n                dirs.add(localDirs[i]);\n                dfList.add(new DF(new File(localDirs[i]), 30000));\n              } catch (DiskErrorException de) {\n                LOG.warn( localDirs[i] + \"is not writable\\n\", de);\n              }\n            } else {\n              LOG.warn( \"Failed to create \" + localDirs[i]);\n            }\n          } catch (IOException ie) { \n            LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                ie.getMessage() + \"\\n\", ie);\n          } //ignore\n        }\n        localDirs \u003d dirs.toArray(new String[dirs.size()]);\n        dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n        savedLocalDirs \u003d newLocalDirs;\n        \n        // randomize the first disk picked in the round-robin selection \n        dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n      }\n    }",
      "path": "common/src/java/org/apache/hadoop/fs/LocalDirAllocator.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "11/06/11 9:13 PM",
      "commitNameOld": "a285fb5effe9ba3be4ec5f942afaf5ddd1186151",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void confChanged(Configuration conf) throws IOException {\n      String newLocalDirs \u003d conf.get(contextCfgItemName);\n      if (!newLocalDirs.equals(savedLocalDirs)) {\n        localDirs \u003d conf.getTrimmedStrings(contextCfgItemName);\n        localFS \u003d FileSystem.getLocal(conf);\n        int numDirs \u003d localDirs.length;\n        ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n        ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n        for (int i \u003d 0; i \u003c numDirs; i++) {\n          try {\n            // filter problematic directories\n            Path tmpDir \u003d new Path(localDirs[i]);\n            if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n              try {\n                DiskChecker.checkDir(new File(localDirs[i]));\n                dirs.add(localDirs[i]);\n                dfList.add(new DF(new File(localDirs[i]), 30000));\n              } catch (DiskErrorException de) {\n                LOG.warn( localDirs[i] + \"is not writable\\n\" +\n                    StringUtils.stringifyException(de));\n              }\n            } else {\n              LOG.warn( \"Failed to create \" + localDirs[i]);\n            }\n          } catch (IOException ie) { \n            LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                ie.getMessage() + \"\\n\" + StringUtils.stringifyException(ie));\n          } //ignore\n        }\n        localDirs \u003d dirs.toArray(new String[dirs.size()]);\n        dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n        savedLocalDirs \u003d newLocalDirs;\n        \n        // randomize the first disk picked in the round-robin selection \n        dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n      }\n    }",
      "path": "common/src/java/org/apache/hadoop/fs/LocalDirAllocator.java",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/hadoop/fs/LocalDirAllocator.java",
        "newPath": "common/src/java/org/apache/hadoop/fs/LocalDirAllocator.java"
      }
    },
    "96a1477d02e29b3002678f4da9ca55184888a54c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-6534. Trim whitespace from directory lists initializing\nLocalDirAllocator. Contributed by Todd Lipcon\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@909806 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/02/10 4:46 AM",
      "commitName": "96a1477d02e29b3002678f4da9ca55184888a54c",
      "commitAuthor": "Christopher Douglas",
      "commitDateOld": "17/06/09 1:55 PM",
      "commitNameOld": "b12d765467fd9a4447c473d613d92883fb09c76b",
      "commitAuthorOld": "Owen O\u0027Malley",
      "daysBetweenCommits": 240.66,
      "commitsBetweenForRepo": 223,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,37 @@\n     private void confChanged(Configuration conf) throws IOException {\n       String newLocalDirs \u003d conf.get(contextCfgItemName);\n       if (!newLocalDirs.equals(savedLocalDirs)) {\n-        localDirs \u003d conf.getStrings(contextCfgItemName);\n+        localDirs \u003d conf.getTrimmedStrings(contextCfgItemName);\n         localFS \u003d FileSystem.getLocal(conf);\n         int numDirs \u003d localDirs.length;\n         ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n         ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n         for (int i \u003d 0; i \u003c numDirs; i++) {\n           try {\n             // filter problematic directories\n             Path tmpDir \u003d new Path(localDirs[i]);\n             if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n               try {\n                 DiskChecker.checkDir(new File(localDirs[i]));\n                 dirs.add(localDirs[i]);\n                 dfList.add(new DF(new File(localDirs[i]), 30000));\n               } catch (DiskErrorException de) {\n                 LOG.warn( localDirs[i] + \"is not writable\\n\" +\n                     StringUtils.stringifyException(de));\n               }\n             } else {\n               LOG.warn( \"Failed to create \" + localDirs[i]);\n             }\n           } catch (IOException ie) { \n             LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                 ie.getMessage() + \"\\n\" + StringUtils.stringifyException(ie));\n           } //ignore\n         }\n         localDirs \u003d dirs.toArray(new String[dirs.size()]);\n         dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n         savedLocalDirs \u003d newLocalDirs;\n         \n         // randomize the first disk picked in the round-robin selection \n         dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void confChanged(Configuration conf) throws IOException {\n      String newLocalDirs \u003d conf.get(contextCfgItemName);\n      if (!newLocalDirs.equals(savedLocalDirs)) {\n        localDirs \u003d conf.getTrimmedStrings(contextCfgItemName);\n        localFS \u003d FileSystem.getLocal(conf);\n        int numDirs \u003d localDirs.length;\n        ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n        ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n        for (int i \u003d 0; i \u003c numDirs; i++) {\n          try {\n            // filter problematic directories\n            Path tmpDir \u003d new Path(localDirs[i]);\n            if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n              try {\n                DiskChecker.checkDir(new File(localDirs[i]));\n                dirs.add(localDirs[i]);\n                dfList.add(new DF(new File(localDirs[i]), 30000));\n              } catch (DiskErrorException de) {\n                LOG.warn( localDirs[i] + \"is not writable\\n\" +\n                    StringUtils.stringifyException(de));\n              }\n            } else {\n              LOG.warn( \"Failed to create \" + localDirs[i]);\n            }\n          } catch (IOException ie) { \n            LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                ie.getMessage() + \"\\n\" + StringUtils.stringifyException(ie));\n          } //ignore\n        }\n        localDirs \u003d dirs.toArray(new String[dirs.size()]);\n        dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n        savedLocalDirs \u003d newLocalDirs;\n        \n        // randomize the first disk picked in the round-robin selection \n        dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n      }\n    }",
      "path": "src/java/org/apache/hadoop/fs/LocalDirAllocator.java",
      "extendedDetails": {}
    },
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-4687 Moving src directories on branch\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/core/branches/HADOOP-4687/core@776174 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/05/09 9:20 PM",
      "commitName": "5128a9a453d64bfe1ed978cf9ffed27985eeef36",
      "commitAuthor": "Owen O\u0027Malley",
      "diff": "@@ -0,0 +1,37 @@\n+    private void confChanged(Configuration conf) throws IOException {\n+      String newLocalDirs \u003d conf.get(contextCfgItemName);\n+      if (!newLocalDirs.equals(savedLocalDirs)) {\n+        localDirs \u003d conf.getStrings(contextCfgItemName);\n+        localFS \u003d FileSystem.getLocal(conf);\n+        int numDirs \u003d localDirs.length;\n+        ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n+        ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n+        for (int i \u003d 0; i \u003c numDirs; i++) {\n+          try {\n+            // filter problematic directories\n+            Path tmpDir \u003d new Path(localDirs[i]);\n+            if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n+              try {\n+                DiskChecker.checkDir(new File(localDirs[i]));\n+                dirs.add(localDirs[i]);\n+                dfList.add(new DF(new File(localDirs[i]), 30000));\n+              } catch (DiskErrorException de) {\n+                LOG.warn( localDirs[i] + \"is not writable\\n\" +\n+                    StringUtils.stringifyException(de));\n+              }\n+            } else {\n+              LOG.warn( \"Failed to create \" + localDirs[i]);\n+            }\n+          } catch (IOException ie) { \n+            LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n+                ie.getMessage() + \"\\n\" + StringUtils.stringifyException(ie));\n+          } //ignore\n+        }\n+        localDirs \u003d dirs.toArray(new String[dirs.size()]);\n+        dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n+        savedLocalDirs \u003d newLocalDirs;\n+        \n+        // randomize the first disk picked in the round-robin selection \n+        dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private void confChanged(Configuration conf) throws IOException {\n      String newLocalDirs \u003d conf.get(contextCfgItemName);\n      if (!newLocalDirs.equals(savedLocalDirs)) {\n        localDirs \u003d conf.getStrings(contextCfgItemName);\n        localFS \u003d FileSystem.getLocal(conf);\n        int numDirs \u003d localDirs.length;\n        ArrayList\u003cString\u003e dirs \u003d new ArrayList\u003cString\u003e(numDirs);\n        ArrayList\u003cDF\u003e dfList \u003d new ArrayList\u003cDF\u003e(numDirs);\n        for (int i \u003d 0; i \u003c numDirs; i++) {\n          try {\n            // filter problematic directories\n            Path tmpDir \u003d new Path(localDirs[i]);\n            if(localFS.mkdirs(tmpDir)|| localFS.exists(tmpDir)) {\n              try {\n                DiskChecker.checkDir(new File(localDirs[i]));\n                dirs.add(localDirs[i]);\n                dfList.add(new DF(new File(localDirs[i]), 30000));\n              } catch (DiskErrorException de) {\n                LOG.warn( localDirs[i] + \"is not writable\\n\" +\n                    StringUtils.stringifyException(de));\n              }\n            } else {\n              LOG.warn( \"Failed to create \" + localDirs[i]);\n            }\n          } catch (IOException ie) { \n            LOG.warn( \"Failed to create \" + localDirs[i] + \": \" +\n                ie.getMessage() + \"\\n\" + StringUtils.stringifyException(ie));\n          } //ignore\n        }\n        localDirs \u003d dirs.toArray(new String[dirs.size()]);\n        dirDF \u003d dfList.toArray(new DF[dirs.size()]);\n        savedLocalDirs \u003d newLocalDirs;\n        \n        // randomize the first disk picked in the round-robin selection \n        dirNumLastAccessed \u003d dirIndexRandomizer.nextInt(dirs.size());\n      }\n    }",
      "path": "src/java/org/apache/hadoop/fs/LocalDirAllocator.java"
    }
  }
}