{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Server.java",
  "functionName": "doAccept",
  "functionId": "doAccept___key-SelectionKey",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
  "functionStartLine": 1388,
  "functionEndLine": 1411,
  "numCommitsSeen": 205,
  "timeTaken": 7845,
  "changeHistory": [
    "ce7b8b5634ef84602019cac4ce52337fbe4f9d42",
    "4050471b45da569d7dc4f724b613ee2879c0ec2a",
    "635786a511344b53b1d3f25c2f29ab5298f6ac74",
    "abdd609e51a80388493417126c3bc9b1badc0ac1",
    "8dc59cb9e0f8d300991a437c1b42f1e4e495cfe4",
    "1da81363fac49152ef34d2fcc536935bda0ba990",
    "e43255302aa7c5a493a3795ec40832994a2dfb19",
    "9aa2f51812e28c0f30299b17f6bbc181fbfa30d4",
    "4a5ba3b7bd2360fd9605863630b477d362874e1e",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
    "b212ed99c5933d2fd6a6259698b00a544e432361",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36"
  ],
  "changeHistoryShort": {
    "ce7b8b5634ef84602019cac4ce52337fbe4f9d42": "Ybodychange",
    "4050471b45da569d7dc4f724b613ee2879c0ec2a": "Ybodychange",
    "635786a511344b53b1d3f25c2f29ab5298f6ac74": "Ybodychange",
    "abdd609e51a80388493417126c3bc9b1badc0ac1": "Ybodychange",
    "8dc59cb9e0f8d300991a437c1b42f1e4e495cfe4": "Ybodychange",
    "1da81363fac49152ef34d2fcc536935bda0ba990": "Ymultichange(Yexceptionschange,Ybodychange)",
    "e43255302aa7c5a493a3795ec40832994a2dfb19": "Ybodychange",
    "9aa2f51812e28c0f30299b17f6bbc181fbfa30d4": "Ybodychange",
    "4a5ba3b7bd2360fd9605863630b477d362874e1e": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yfilerename",
    "b212ed99c5933d2fd6a6259698b00a544e432361": "Ybodychange",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": "Yintroduced"
  },
  "changeHistoryDetails": {
    "ce7b8b5634ef84602019cac4ce52337fbe4f9d42": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15148. dfs.namenode.send.qop.enabled should not apply to primary NN port. Contributed by Chen Liang.\n",
      "commitDate": "04/02/20 12:12 PM",
      "commitName": "ce7b8b5634ef84602019cac4ce52337fbe4f9d42",
      "commitAuthor": "Chen Liang",
      "commitDateOld": "20/11/19 7:56 AM",
      "commitNameOld": "be77231452baee2c3dd68f7c0991411cae2eea1b",
      "commitAuthorOld": "Erik Krogen",
      "daysBetweenCommits": 76.18,
      "commitsBetweenForRepo": 256,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,24 @@\n     void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n       ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n       SocketChannel channel;\n       while ((channel \u003d server.accept()) !\u003d null) {\n \n         channel.configureBlocking(false);\n         channel.socket().setTcpNoDelay(tcpNoDelay);\n         channel.socket().setKeepAlive(true);\n         \n         Reader reader \u003d getReader();\n-        Connection c \u003d connectionManager.register(channel, this.listenPort);\n+        Connection c \u003d connectionManager.register(channel,\n+            this.listenPort, this.isOnAuxiliaryPort);\n         // If the connectionManager can\u0027t take it, close the connection.\n         if (c \u003d\u003d null) {\n           if (channel.isOpen()) {\n             IOUtils.cleanupWithLogger(LOG, channel);\n           }\n           connectionManager.droppedConnections.getAndIncrement();\n           continue;\n         }\n         key.attach(c);  // so closeCurrentConnection can get the object\n         reader.addConnection(c);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n      ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel \u003d server.accept()) !\u003d null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        channel.socket().setKeepAlive(true);\n        \n        Reader reader \u003d getReader();\n        Connection c \u003d connectionManager.register(channel,\n            this.listenPort, this.isOnAuxiliaryPort);\n        // If the connectionManager can\u0027t take it, close the connection.\n        if (c \u003d\u003d null) {\n          if (channel.isOpen()) {\n            IOUtils.cleanupWithLogger(LOG, channel);\n          }\n          connectionManager.droppedConnections.getAndIncrement();\n          continue;\n        }\n        key.attach(c);  // so closeCurrentConnection can get the object\n        reader.addConnection(c);\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "4050471b45da569d7dc4f724b613ee2879c0ec2a": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16657. Move remaining log4j APIs over to slf4j in hadoop-common. Contributed by Minni Mittal.\n",
      "commitDate": "18/11/19 6:31 PM",
      "commitName": "4050471b45da569d7dc4f724b613ee2879c0ec2a",
      "commitAuthor": "Abhishek Modi",
      "commitDateOld": "20/09/19 3:38 AM",
      "commitNameOld": "1654497f98fb7f2de8214d2fbad305b7a2854816",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 59.66,
      "commitsBetweenForRepo": 314,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,23 @@\n     void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n       ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n       SocketChannel channel;\n       while ((channel \u003d server.accept()) !\u003d null) {\n \n         channel.configureBlocking(false);\n         channel.socket().setTcpNoDelay(tcpNoDelay);\n         channel.socket().setKeepAlive(true);\n         \n         Reader reader \u003d getReader();\n         Connection c \u003d connectionManager.register(channel, this.listenPort);\n         // If the connectionManager can\u0027t take it, close the connection.\n         if (c \u003d\u003d null) {\n           if (channel.isOpen()) {\n-            IOUtils.cleanup(null, channel);\n+            IOUtils.cleanupWithLogger(LOG, channel);\n           }\n           connectionManager.droppedConnections.getAndIncrement();\n           continue;\n         }\n         key.attach(c);  // so closeCurrentConnection can get the object\n         reader.addConnection(c);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n      ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel \u003d server.accept()) !\u003d null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        channel.socket().setKeepAlive(true);\n        \n        Reader reader \u003d getReader();\n        Connection c \u003d connectionManager.register(channel, this.listenPort);\n        // If the connectionManager can\u0027t take it, close the connection.\n        if (c \u003d\u003d null) {\n          if (channel.isOpen()) {\n            IOUtils.cleanupWithLogger(LOG, channel);\n          }\n          connectionManager.droppedConnections.getAndIncrement();\n          continue;\n        }\n        key.attach(c);  // so closeCurrentConnection can get the object\n        reader.addConnection(c);\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "635786a511344b53b1d3f25c2f29ab5298f6ac74": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13566. Add configurable additional RPC listener to NameNode. Contributed by Chen Liang.\n",
      "commitDate": "23/10/18 2:53 PM",
      "commitName": "635786a511344b53b1d3f25c2f29ab5298f6ac74",
      "commitAuthor": "Chen Liang",
      "commitDateOld": "10/10/18 9:51 PM",
      "commitNameOld": "7b57f2f71fbaa5af4897309597cca70a95b04edd",
      "commitAuthorOld": "Takanobu Asanuma",
      "daysBetweenCommits": 12.71,
      "commitsBetweenForRepo": 158,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,23 @@\n     void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n       ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n       SocketChannel channel;\n       while ((channel \u003d server.accept()) !\u003d null) {\n \n         channel.configureBlocking(false);\n         channel.socket().setTcpNoDelay(tcpNoDelay);\n         channel.socket().setKeepAlive(true);\n         \n         Reader reader \u003d getReader();\n-        Connection c \u003d connectionManager.register(channel);\n+        Connection c \u003d connectionManager.register(channel, this.listenPort);\n         // If the connectionManager can\u0027t take it, close the connection.\n         if (c \u003d\u003d null) {\n           if (channel.isOpen()) {\n             IOUtils.cleanup(null, channel);\n           }\n           connectionManager.droppedConnections.getAndIncrement();\n           continue;\n         }\n         key.attach(c);  // so closeCurrentConnection can get the object\n         reader.addConnection(c);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n      ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel \u003d server.accept()) !\u003d null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        channel.socket().setKeepAlive(true);\n        \n        Reader reader \u003d getReader();\n        Connection c \u003d connectionManager.register(channel, this.listenPort);\n        // If the connectionManager can\u0027t take it, close the connection.\n        if (c \u003d\u003d null) {\n          if (channel.isOpen()) {\n            IOUtils.cleanup(null, channel);\n          }\n          connectionManager.droppedConnections.getAndIncrement();\n          continue;\n        }\n        key.attach(c);  // so closeCurrentConnection can get the object\n        reader.addConnection(c);\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "abdd609e51a80388493417126c3bc9b1badc0ac1": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14440. Add metrics for connections dropped. Contributed by Eric Badger.\n",
      "commitDate": "05/06/17 9:21 AM",
      "commitName": "abdd609e51a80388493417126c3bc9b1badc0ac1",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "30/05/17 10:07 AM",
      "commitNameOld": "62857be2110aaded84a93fc9891742a1271b2b85",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 5.97,
      "commitsBetweenForRepo": 24,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,23 @@\n     void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n       ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n       SocketChannel channel;\n       while ((channel \u003d server.accept()) !\u003d null) {\n \n         channel.configureBlocking(false);\n         channel.socket().setTcpNoDelay(tcpNoDelay);\n         channel.socket().setKeepAlive(true);\n         \n         Reader reader \u003d getReader();\n         Connection c \u003d connectionManager.register(channel);\n         // If the connectionManager can\u0027t take it, close the connection.\n         if (c \u003d\u003d null) {\n           if (channel.isOpen()) {\n             IOUtils.cleanup(null, channel);\n           }\n+          connectionManager.droppedConnections.getAndIncrement();\n           continue;\n         }\n         key.attach(c);  // so closeCurrentConnection can get the object\n         reader.addConnection(c);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n      ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel \u003d server.accept()) !\u003d null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        channel.socket().setKeepAlive(true);\n        \n        Reader reader \u003d getReader();\n        Connection c \u003d connectionManager.register(channel);\n        // If the connectionManager can\u0027t take it, close the connection.\n        if (c \u003d\u003d null) {\n          if (channel.isOpen()) {\n            IOUtils.cleanup(null, channel);\n          }\n          connectionManager.droppedConnections.getAndIncrement();\n          continue;\n        }\n        key.attach(c);  // so closeCurrentConnection can get the object\n        reader.addConnection(c);\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "8dc59cb9e0f8d300991a437c1b42f1e4e495cfe4": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9137. Support connection limiting in IPC server. Contributed by Kihwal Lee.\n",
      "commitDate": "30/01/15 3:21 PM",
      "commitName": "8dc59cb9e0f8d300991a437c1b42f1e4e495cfe4",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "11/12/14 4:42 PM",
      "commitNameOld": "5b9fcedb4d116d91d70aaad6cbf59093eeee36df",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 49.94,
      "commitsBetweenForRepo": 295,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,22 @@\n     void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n       ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n       SocketChannel channel;\n       while ((channel \u003d server.accept()) !\u003d null) {\n \n         channel.configureBlocking(false);\n         channel.socket().setTcpNoDelay(tcpNoDelay);\n         channel.socket().setKeepAlive(true);\n         \n         Reader reader \u003d getReader();\n         Connection c \u003d connectionManager.register(channel);\n+        // If the connectionManager can\u0027t take it, close the connection.\n+        if (c \u003d\u003d null) {\n+          if (channel.isOpen()) {\n+            IOUtils.cleanup(null, channel);\n+          }\n+          continue;\n+        }\n         key.attach(c);  // so closeCurrentConnection can get the object\n         reader.addConnection(c);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n      ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel \u003d server.accept()) !\u003d null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        channel.socket().setKeepAlive(true);\n        \n        Reader reader \u003d getReader();\n        Connection c \u003d connectionManager.register(channel);\n        // If the connectionManager can\u0027t take it, close the connection.\n        if (c \u003d\u003d null) {\n          if (channel.isOpen()) {\n            IOUtils.cleanup(null, channel);\n          }\n          continue;\n        }\n        key.attach(c);  // so closeCurrentConnection can get the object\n        reader.addConnection(c);\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "1da81363fac49152ef34d2fcc536935bda0ba990": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HADOOP-9955. RPC idle connection closing is extremely inefficient (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1542111 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/11/13 2:55 PM",
      "commitName": "1da81363fac49152ef34d2fcc536935bda0ba990",
      "commitAuthor": "Daryn Sharp",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HADOOP-9955. RPC idle connection closing is extremely inefficient (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1542111 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/11/13 2:55 PM",
          "commitName": "1da81363fac49152ef34d2fcc536935bda0ba990",
          "commitAuthor": "Daryn Sharp",
          "commitDateOld": "13/11/13 1:37 PM",
          "commitNameOld": "e43255302aa7c5a493a3795ec40832994a2dfb19",
          "commitAuthorOld": "Daryn Sharp",
          "daysBetweenCommits": 1.05,
          "commitsBetweenForRepo": 18,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,32 +1,15 @@\n-    void doAccept(SelectionKey key) throws IOException,  OutOfMemoryError {\n-      Connection c \u003d null;\n+    void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n       ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n       SocketChannel channel;\n       while ((channel \u003d server.accept()) !\u003d null) {\n \n         channel.configureBlocking(false);\n         channel.socket().setTcpNoDelay(tcpNoDelay);\n         channel.socket().setKeepAlive(true);\n         \n         Reader reader \u003d getReader();\n-        try {\n-          c \u003d new Connection(channel, Time.now());\n-          synchronized (connectionList) {\n-            connectionList.add(numConnections, c);\n-            numConnections++;\n-          }\n-          reader.addConnection(c);\n-          if (LOG.isDebugEnabled())\n-            LOG.debug(\"Server connection from \" + c.toString() +\n-                \"; # active connections: \" + numConnections +\n-                \"; # queued calls: \" + callQueue.size());          \n-        } catch (InterruptedException ie) {\n-          if (running) {\n-            LOG.info(\n-                getName() + \": disconnecting client \" + c.getHostAddress() +\n-                \" due to unexpected interrupt\");\n-          }\n-          closeConnection(c);\n-        }\n+        Connection c \u003d connectionManager.register(channel);\n+        key.attach(c);  // so closeCurrentConnection can get the object\n+        reader.addConnection(c);\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n      ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel \u003d server.accept()) !\u003d null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        channel.socket().setKeepAlive(true);\n        \n        Reader reader \u003d getReader();\n        Connection c \u003d connectionManager.register(channel);\n        key.attach(c);  // so closeCurrentConnection can get the object\n        reader.addConnection(c);\n      }\n    }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
          "extendedDetails": {
            "oldValue": "[IOException, OutOfMemoryError]",
            "newValue": "[InterruptedException, IOException, OutOfMemoryError]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-9955. RPC idle connection closing is extremely inefficient (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1542111 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/11/13 2:55 PM",
          "commitName": "1da81363fac49152ef34d2fcc536935bda0ba990",
          "commitAuthor": "Daryn Sharp",
          "commitDateOld": "13/11/13 1:37 PM",
          "commitNameOld": "e43255302aa7c5a493a3795ec40832994a2dfb19",
          "commitAuthorOld": "Daryn Sharp",
          "daysBetweenCommits": 1.05,
          "commitsBetweenForRepo": 18,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,32 +1,15 @@\n-    void doAccept(SelectionKey key) throws IOException,  OutOfMemoryError {\n-      Connection c \u003d null;\n+    void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n       ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n       SocketChannel channel;\n       while ((channel \u003d server.accept()) !\u003d null) {\n \n         channel.configureBlocking(false);\n         channel.socket().setTcpNoDelay(tcpNoDelay);\n         channel.socket().setKeepAlive(true);\n         \n         Reader reader \u003d getReader();\n-        try {\n-          c \u003d new Connection(channel, Time.now());\n-          synchronized (connectionList) {\n-            connectionList.add(numConnections, c);\n-            numConnections++;\n-          }\n-          reader.addConnection(c);\n-          if (LOG.isDebugEnabled())\n-            LOG.debug(\"Server connection from \" + c.toString() +\n-                \"; # active connections: \" + numConnections +\n-                \"; # queued calls: \" + callQueue.size());          \n-        } catch (InterruptedException ie) {\n-          if (running) {\n-            LOG.info(\n-                getName() + \": disconnecting client \" + c.getHostAddress() +\n-                \" due to unexpected interrupt\");\n-          }\n-          closeConnection(c);\n-        }\n+        Connection c \u003d connectionManager.register(channel);\n+        key.attach(c);  // so closeCurrentConnection can get the object\n+        reader.addConnection(c);\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    void doAccept(SelectionKey key) throws InterruptedException, IOException,  OutOfMemoryError {\n      ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel \u003d server.accept()) !\u003d null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        channel.socket().setKeepAlive(true);\n        \n        Reader reader \u003d getReader();\n        Connection c \u003d connectionManager.register(channel);\n        key.attach(c);  // so closeCurrentConnection can get the object\n        reader.addConnection(c);\n      }\n    }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
          "extendedDetails": {}
        }
      ]
    },
    "e43255302aa7c5a493a3795ec40832994a2dfb19": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9956. RPC listener inefficiently assigns connections to readers (daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541736 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/11/13 1:37 PM",
      "commitName": "e43255302aa7c5a493a3795ec40832994a2dfb19",
      "commitAuthor": "Daryn Sharp",
      "commitDateOld": "31/10/13 1:55 PM",
      "commitNameOld": "9aa2f51812e28c0f30299b17f6bbc181fbfa30d4",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 13.03,
      "commitsBetweenForRepo": 61,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,32 @@\n     void doAccept(SelectionKey key) throws IOException,  OutOfMemoryError {\n       Connection c \u003d null;\n       ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n       SocketChannel channel;\n       while ((channel \u003d server.accept()) !\u003d null) {\n \n         channel.configureBlocking(false);\n         channel.socket().setTcpNoDelay(tcpNoDelay);\n         channel.socket().setKeepAlive(true);\n         \n         Reader reader \u003d getReader();\n         try {\n-          reader.startAdd();\n-          SelectionKey readKey \u003d reader.registerChannel(channel);\n-          c \u003d new Connection(readKey, channel, Time.now());\n-          readKey.attach(c);\n+          c \u003d new Connection(channel, Time.now());\n           synchronized (connectionList) {\n             connectionList.add(numConnections, c);\n             numConnections++;\n           }\n+          reader.addConnection(c);\n           if (LOG.isDebugEnabled())\n             LOG.debug(\"Server connection from \" + c.toString() +\n                 \"; # active connections: \" + numConnections +\n                 \"; # queued calls: \" + callQueue.size());          \n-        } finally {\n-          reader.finishAdd(); \n+        } catch (InterruptedException ie) {\n+          if (running) {\n+            LOG.info(\n+                getName() + \": disconnecting client \" + c.getHostAddress() +\n+                \" due to unexpected interrupt\");\n+          }\n+          closeConnection(c);\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void doAccept(SelectionKey key) throws IOException,  OutOfMemoryError {\n      Connection c \u003d null;\n      ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel \u003d server.accept()) !\u003d null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        channel.socket().setKeepAlive(true);\n        \n        Reader reader \u003d getReader();\n        try {\n          c \u003d new Connection(channel, Time.now());\n          synchronized (connectionList) {\n            connectionList.add(numConnections, c);\n            numConnections++;\n          }\n          reader.addConnection(c);\n          if (LOG.isDebugEnabled())\n            LOG.debug(\"Server connection from \" + c.toString() +\n                \"; # active connections: \" + numConnections +\n                \"; # queued calls: \" + callQueue.size());          \n        } catch (InterruptedException ie) {\n          if (running) {\n            LOG.info(\n                getName() + \": disconnecting client \" + c.getHostAddress() +\n                \" due to unexpected interrupt\");\n          }\n          closeConnection(c);\n        }\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "9aa2f51812e28c0f30299b17f6bbc181fbfa30d4": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9898. Set SO_KEEPALIVE on all our sockets. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1537637 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/10/13 1:55 PM",
      "commitName": "9aa2f51812e28c0f30299b17f6bbc181fbfa30d4",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "11/10/13 2:49 PM",
      "commitNameOld": "f7eaacc103344f5fd81dd69584c93fb99d8b94c9",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 19.96,
      "commitsBetweenForRepo": 118,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,29 @@\n     void doAccept(SelectionKey key) throws IOException,  OutOfMemoryError {\n       Connection c \u003d null;\n       ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n       SocketChannel channel;\n       while ((channel \u003d server.accept()) !\u003d null) {\n \n         channel.configureBlocking(false);\n         channel.socket().setTcpNoDelay(tcpNoDelay);\n+        channel.socket().setKeepAlive(true);\n         \n         Reader reader \u003d getReader();\n         try {\n           reader.startAdd();\n           SelectionKey readKey \u003d reader.registerChannel(channel);\n           c \u003d new Connection(readKey, channel, Time.now());\n           readKey.attach(c);\n           synchronized (connectionList) {\n             connectionList.add(numConnections, c);\n             numConnections++;\n           }\n           if (LOG.isDebugEnabled())\n             LOG.debug(\"Server connection from \" + c.toString() +\n                 \"; # active connections: \" + numConnections +\n                 \"; # queued calls: \" + callQueue.size());          \n         } finally {\n           reader.finishAdd(); \n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void doAccept(SelectionKey key) throws IOException,  OutOfMemoryError {\n      Connection c \u003d null;\n      ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel \u003d server.accept()) !\u003d null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        channel.socket().setKeepAlive(true);\n        \n        Reader reader \u003d getReader();\n        try {\n          reader.startAdd();\n          SelectionKey readKey \u003d reader.registerChannel(channel);\n          c \u003d new Connection(readKey, channel, Time.now());\n          readKey.attach(c);\n          synchronized (connectionList) {\n            connectionList.add(numConnections, c);\n            numConnections++;\n          }\n          if (LOG.isDebugEnabled())\n            LOG.debug(\"Server connection from \" + c.toString() +\n                \"; # active connections: \" + numConnections +\n                \"; # queued calls: \" + callQueue.size());          \n        } finally {\n          reader.finishAdd(); \n        }\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "4a5ba3b7bd2360fd9605863630b477d362874e1e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3641. Move server Util time methods to common and use now instead of System#currentTimeMillis. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1360858 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/07/12 12:01 PM",
      "commitName": "4a5ba3b7bd2360fd9605863630b477d362874e1e",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "11/05/12 9:56 AM",
      "commitNameOld": "2116f28d9e95896b54f4dc60336dc3f6ac7d64f3",
      "commitAuthorOld": "Sanjay Radia",
      "daysBetweenCommits": 62.09,
      "commitsBetweenForRepo": 300,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n     void doAccept(SelectionKey key) throws IOException,  OutOfMemoryError {\n       Connection c \u003d null;\n       ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n       SocketChannel channel;\n       while ((channel \u003d server.accept()) !\u003d null) {\n \n         channel.configureBlocking(false);\n         channel.socket().setTcpNoDelay(tcpNoDelay);\n         \n         Reader reader \u003d getReader();\n         try {\n           reader.startAdd();\n           SelectionKey readKey \u003d reader.registerChannel(channel);\n-          c \u003d new Connection(readKey, channel, System.currentTimeMillis());\n+          c \u003d new Connection(readKey, channel, Time.now());\n           readKey.attach(c);\n           synchronized (connectionList) {\n             connectionList.add(numConnections, c);\n             numConnections++;\n           }\n           if (LOG.isDebugEnabled())\n             LOG.debug(\"Server connection from \" + c.toString() +\n                 \"; # active connections: \" + numConnections +\n                 \"; # queued calls: \" + callQueue.size());          \n         } finally {\n           reader.finishAdd(); \n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void doAccept(SelectionKey key) throws IOException,  OutOfMemoryError {\n      Connection c \u003d null;\n      ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel \u003d server.accept()) !\u003d null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        \n        Reader reader \u003d getReader();\n        try {\n          reader.startAdd();\n          SelectionKey readKey \u003d reader.registerChannel(channel);\n          c \u003d new Connection(readKey, channel, Time.now());\n          readKey.attach(c);\n          synchronized (connectionList) {\n            connectionList.add(numConnections, c);\n            numConnections++;\n          }\n          if (LOG.isDebugEnabled())\n            LOG.debug(\"Server connection from \" + c.toString() +\n                \"; # active connections: \" + numConnections +\n                \"; # queued calls: \" + callQueue.size());          \n        } finally {\n          reader.finishAdd(); \n        }\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    void doAccept(SelectionKey key) throws IOException,  OutOfMemoryError {\n      Connection c \u003d null;\n      ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel \u003d server.accept()) !\u003d null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        \n        Reader reader \u003d getReader();\n        try {\n          reader.startAdd();\n          SelectionKey readKey \u003d reader.registerChannel(channel);\n          c \u003d new Connection(readKey, channel, System.currentTimeMillis());\n          readKey.attach(c);\n          synchronized (connectionList) {\n            connectionList.add(numConnections, c);\n            numConnections++;\n          }\n          if (LOG.isDebugEnabled())\n            LOG.debug(\"Server connection from \" + c.toString() +\n                \"; # active connections: \" + numConnections +\n                \"; # queued calls: \" + callQueue.size());          \n        } finally {\n          reader.finishAdd(); \n        }\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {
        "oldPath": "hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java"
      }
    },
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-6671. Use maven for hadoop common builds. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1153184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/08/11 9:37 AM",
      "commitName": "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
      "commitAuthor": "Thomas White",
      "commitDateOld": "01/08/11 3:53 PM",
      "commitNameOld": "9bac807cedbcff34e1a144fb475eff267e5ed86d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    void doAccept(SelectionKey key) throws IOException,  OutOfMemoryError {\n      Connection c \u003d null;\n      ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel \u003d server.accept()) !\u003d null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        \n        Reader reader \u003d getReader();\n        try {\n          reader.startAdd();\n          SelectionKey readKey \u003d reader.registerChannel(channel);\n          c \u003d new Connection(readKey, channel, System.currentTimeMillis());\n          readKey.attach(c);\n          synchronized (connectionList) {\n            connectionList.add(numConnections, c);\n            numConnections++;\n          }\n          if (LOG.isDebugEnabled())\n            LOG.debug(\"Server connection from \" + c.toString() +\n                \"; # active connections: \" + numConnections +\n                \"; # queued calls: \" + callQueue.size());          \n        } finally {\n          reader.finishAdd(); \n        }\n      }\n    }",
      "path": "hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {
        "oldPath": "common/src/java/org/apache/hadoop/ipc/Server.java",
        "newPath": "hadoop-common/src/main/java/org/apache/hadoop/ipc/Server.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "11/06/11 9:13 PM",
      "commitNameOld": "a285fb5effe9ba3be4ec5f942afaf5ddd1186151",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    void doAccept(SelectionKey key) throws IOException,  OutOfMemoryError {\n      Connection c \u003d null;\n      ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel \u003d server.accept()) !\u003d null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        \n        Reader reader \u003d getReader();\n        try {\n          reader.startAdd();\n          SelectionKey readKey \u003d reader.registerChannel(channel);\n          c \u003d new Connection(readKey, channel, System.currentTimeMillis());\n          readKey.attach(c);\n          synchronized (connectionList) {\n            connectionList.add(numConnections, c);\n            numConnections++;\n          }\n          if (LOG.isDebugEnabled())\n            LOG.debug(\"Server connection from \" + c.toString() +\n                \"; # active connections: \" + numConnections +\n                \"; # queued calls: \" + callQueue.size());          \n        } finally {\n          reader.finishAdd(); \n        }\n      }\n    }",
      "path": "common/src/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/hadoop/ipc/Server.java",
        "newPath": "common/src/java/org/apache/hadoop/ipc/Server.java"
      }
    },
    "b212ed99c5933d2fd6a6259698b00a544e432361": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-6713. The RPC server Listener thread is a scalability bottleneck. Contributed by Dmytro Molkov.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@938590 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/04/10 11:13 AM",
      "commitName": "b212ed99c5933d2fd6a6259698b00a544e432361",
      "commitAuthor": "Hairong Kuang",
      "commitDateOld": "23/04/10 1:05 AM",
      "commitNameOld": "50f24d774e0ca5906535519ada6afc94432ef771",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 4.42,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,28 @@\n     void doAccept(SelectionKey key) throws IOException,  OutOfMemoryError {\n       Connection c \u003d null;\n       ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n-      // accept up to 10 connections\n-      for (int i\u003d0; i\u003c10; i++) {\n-        SocketChannel channel \u003d server.accept();\n-        if (channel\u003d\u003dnull) return;\n+      SocketChannel channel;\n+      while ((channel \u003d server.accept()) !\u003d null) {\n \n         channel.configureBlocking(false);\n         channel.socket().setTcpNoDelay(tcpNoDelay);\n-        SelectionKey readKey \u003d channel.register(getSelector(), \n-          SelectionKey.OP_READ);\n-        c \u003d new Connection(readKey, channel, System.currentTimeMillis());\n-        readKey.attach(c);\n-        synchronized (connectionList) {\n-          connectionList.add(numConnections, c);\n-          numConnections++;\n+        \n+        Reader reader \u003d getReader();\n+        try {\n+          reader.startAdd();\n+          SelectionKey readKey \u003d reader.registerChannel(channel);\n+          c \u003d new Connection(readKey, channel, System.currentTimeMillis());\n+          readKey.attach(c);\n+          synchronized (connectionList) {\n+            connectionList.add(numConnections, c);\n+            numConnections++;\n+          }\n+          if (LOG.isDebugEnabled())\n+            LOG.debug(\"Server connection from \" + c.toString() +\n+                \"; # active connections: \" + numConnections +\n+                \"; # queued calls: \" + callQueue.size());          \n+        } finally {\n+          reader.finishAdd(); \n         }\n-        if (LOG.isDebugEnabled())\n-          LOG.debug(\"Server connection from \" + c.toString() +\n-              \"; # active connections: \" + numConnections +\n-              \"; # queued calls: \" + callQueue.size());\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void doAccept(SelectionKey key) throws IOException,  OutOfMemoryError {\n      Connection c \u003d null;\n      ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n      SocketChannel channel;\n      while ((channel \u003d server.accept()) !\u003d null) {\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        \n        Reader reader \u003d getReader();\n        try {\n          reader.startAdd();\n          SelectionKey readKey \u003d reader.registerChannel(channel);\n          c \u003d new Connection(readKey, channel, System.currentTimeMillis());\n          readKey.attach(c);\n          synchronized (connectionList) {\n            connectionList.add(numConnections, c);\n            numConnections++;\n          }\n          if (LOG.isDebugEnabled())\n            LOG.debug(\"Server connection from \" + c.toString() +\n                \"; # active connections: \" + numConnections +\n                \"; # queued calls: \" + callQueue.size());          \n        } finally {\n          reader.finishAdd(); \n        }\n      }\n    }",
      "path": "src/java/org/apache/hadoop/ipc/Server.java",
      "extendedDetails": {}
    },
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-4687 Moving src directories on branch\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/core/branches/HADOOP-4687/core@776174 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/05/09 9:20 PM",
      "commitName": "5128a9a453d64bfe1ed978cf9ffed27985eeef36",
      "commitAuthor": "Owen O\u0027Malley",
      "diff": "@@ -0,0 +1,24 @@\n+    void doAccept(SelectionKey key) throws IOException,  OutOfMemoryError {\n+      Connection c \u003d null;\n+      ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n+      // accept up to 10 connections\n+      for (int i\u003d0; i\u003c10; i++) {\n+        SocketChannel channel \u003d server.accept();\n+        if (channel\u003d\u003dnull) return;\n+\n+        channel.configureBlocking(false);\n+        channel.socket().setTcpNoDelay(tcpNoDelay);\n+        SelectionKey readKey \u003d channel.register(getSelector(), \n+          SelectionKey.OP_READ);\n+        c \u003d new Connection(readKey, channel, System.currentTimeMillis());\n+        readKey.attach(c);\n+        synchronized (connectionList) {\n+          connectionList.add(numConnections, c);\n+          numConnections++;\n+        }\n+        if (LOG.isDebugEnabled())\n+          LOG.debug(\"Server connection from \" + c.toString() +\n+              \"; # active connections: \" + numConnections +\n+              \"; # queued calls: \" + callQueue.size());\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    void doAccept(SelectionKey key) throws IOException,  OutOfMemoryError {\n      Connection c \u003d null;\n      ServerSocketChannel server \u003d (ServerSocketChannel) key.channel();\n      // accept up to 10 connections\n      for (int i\u003d0; i\u003c10; i++) {\n        SocketChannel channel \u003d server.accept();\n        if (channel\u003d\u003dnull) return;\n\n        channel.configureBlocking(false);\n        channel.socket().setTcpNoDelay(tcpNoDelay);\n        SelectionKey readKey \u003d channel.register(getSelector(), \n          SelectionKey.OP_READ);\n        c \u003d new Connection(readKey, channel, System.currentTimeMillis());\n        readKey.attach(c);\n        synchronized (connectionList) {\n          connectionList.add(numConnections, c);\n          numConnections++;\n        }\n        if (LOG.isDebugEnabled())\n          LOG.debug(\"Server connection from \" + c.toString() +\n              \"; # active connections: \" + numConnections +\n              \"; # queued calls: \" + callQueue.size());\n      }\n    }",
      "path": "src/java/org/apache/hadoop/ipc/Server.java"
    }
  }
}