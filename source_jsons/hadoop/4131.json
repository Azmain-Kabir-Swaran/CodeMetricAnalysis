{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NameNodeProxiesClient.java",
  "functionName": "createFailoverProxyProvider",
  "functionId": "createFailoverProxyProvider___conf-Configuration__nameNodeUri-URI__xface-Class__T____checkPort-boolean__fallbackToSimpleAuth-AtomicBoolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/NameNodeProxiesClient.java",
  "functionStartLine": 221,
  "functionEndLine": 226,
  "numCommitsSeen": 123,
  "timeTaken": 4857,
  "changeHistory": [
    "9e0e430f18d45cfe125dda8d85916edddf79e8d6",
    "63d9f1596c92206cce3b72e3214d2fb5f6242b90",
    "76957a485b526468498f93e443544131a88b5684",
    "f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5",
    "33ade356b35223654a077103ed7fbed89f3f2321",
    "8c7a7e619699386f9e6991842558d78aa0c8053d",
    "a690a215dba6180090214675393431a589c37f24",
    "c69dfdd5e14af490790dff8227b11962ec816577",
    "481f84597bf842df45b068cc24c328112e8bcf40",
    "6122357da51bc447391a464a8f7b4de1bae2d8cf",
    "02919e61f6935813bc3dbe23cc89e00e0cb02918",
    "212678f036f4f96493bc14a584e758f97cf65573"
  ],
  "changeHistoryShort": {
    "9e0e430f18d45cfe125dda8d85916edddf79e8d6": "Ybodychange",
    "63d9f1596c92206cce3b72e3214d2fb5f6242b90": "Ymultichange(Ymovefromfile,Ybodychange)",
    "76957a485b526468498f93e443544131a88b5684": "Ybodychange",
    "f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5": "Ymultichange(Yparameterchange,Ybodychange)",
    "33ade356b35223654a077103ed7fbed89f3f2321": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
    "8c7a7e619699386f9e6991842558d78aa0c8053d": "Ymodifierchange",
    "a690a215dba6180090214675393431a589c37f24": "Ybodychange",
    "c69dfdd5e14af490790dff8227b11962ec816577": "Ymovefromfile",
    "481f84597bf842df45b068cc24c328112e8bcf40": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
    "6122357da51bc447391a464a8f7b4de1bae2d8cf": "Ybodychange",
    "02919e61f6935813bc3dbe23cc89e00e0cb02918": "Ymultichange(Yparameterchange,Ybodychange)",
    "212678f036f4f96493bc14a584e758f97cf65573": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9e0e430f18d45cfe125dda8d85916edddf79e8d6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11538. Move ClientProtocol HA proxies into hadoop-hdfs-client. Contributed by Huafeng Wang.\n",
      "commitDate": "04/04/17 11:05 PM",
      "commitName": "9e0e430f18d45cfe125dda8d85916edddf79e8d6",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "10/11/15 9:55 AM",
      "commitNameOld": "73b94d789969354bb9a6872d99976763ca8470d7",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 511.51,
      "commitsBetweenForRepo": 3367,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,6 @@\n   public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n       Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort,\n       AtomicBoolean fallbackToSimpleAuth) throws IOException {\n-    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d null;\n-    AbstractNNFailoverProxyProvider\u003cT\u003e providerNN;\n-    try {\n-      // Obtain the class of the proxy provider\n-      failoverProxyProviderClass \u003d getFailoverProxyProviderClass(conf,\n-          nameNodeUri);\n-      if (failoverProxyProviderClass \u003d\u003d null) {\n-        return null;\n-      }\n-      // Create a proxy provider instance.\n-      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n-          .getConstructor(Configuration.class, URI.class, Class.class);\n-      FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n-          xface);\n-\n-      // If the proxy provider is of an old implementation, wrap it.\n-      if (!(provider instanceof AbstractNNFailoverProxyProvider)) {\n-        providerNN \u003d new WrappedFailoverProxyProvider\u003c\u003e(provider);\n-      } else {\n-        providerNN \u003d (AbstractNNFailoverProxyProvider\u003cT\u003e)provider;\n-      }\n-    } catch (Exception e) {\n-      final String message \u003d \"Couldn\u0027t create proxy provider \" +\n-          failoverProxyProviderClass;\n-      LOG.debug(message, e);\n-      if (e.getCause() instanceof IOException) {\n-        throw (IOException) e.getCause();\n-      } else {\n-        throw new IOException(message, e);\n-      }\n-    }\n-\n-    // Check the port in the URI, if it is logical.\n-    if (checkPort \u0026\u0026 providerNN.useLogicalURI()) {\n-      int port \u003d nameNodeUri.getPort();\n-      if (port \u003e 0 \u0026\u0026\n-          port !\u003d HdfsClientConfigKeys.DFS_NAMENODE_RPC_PORT_DEFAULT) {\n-        // Throwing here without any cleanup is fine since we have not\n-        // actually created the underlying proxies yet.\n-        throw new IOException(\"Port \" + port + \" specified in URI \"\n-            + nameNodeUri + \" but host \u0027\" + nameNodeUri.getHost()\n-            + \"\u0027 is a logical (HA) namenode\"\n-            + \" and does not use port information.\");\n-      }\n-    }\n-    providerNN.setFallbackToSimpleAuth(fallbackToSimpleAuth);\n-    return providerNN;\n+    return createFailoverProxyProvider(conf, nameNodeUri, xface, checkPort,\n+      fallbackToSimpleAuth, new ClientHAProxyFactory\u003cT\u003e());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort,\n      AtomicBoolean fallbackToSimpleAuth) throws IOException {\n    return createFailoverProxyProvider(conf, nameNodeUri, xface, checkPort,\n      fallbackToSimpleAuth, new ClientHAProxyFactory\u003cT\u003e());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/NameNodeProxiesClient.java",
      "extendedDetails": {}
    },
    "63d9f1596c92206cce3b72e3214d2fb5f6242b90": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-9039. Separate client and server side methods of o.a.h.hdfs.NameNodeProxies. Contributed by Mingliang Liu.\n",
      "commitDate": "22/09/15 8:52 PM",
      "commitName": "63d9f1596c92206cce3b72e3214d2fb5f6242b90",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-9039. Separate client and server side methods of o.a.h.hdfs.NameNodeProxies. Contributed by Mingliang Liu.\n",
          "commitDate": "22/09/15 8:52 PM",
          "commitName": "63d9f1596c92206cce3b72e3214d2fb5f6242b90",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "22/09/15 9:08 AM",
          "commitNameOld": "cc2b4739902df60254dce2ddb23ef8f6ff2a3495",
          "commitAuthorOld": "Harsh J",
          "daysBetweenCommits": 0.49,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,55 +1,51 @@\n   public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n       Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort,\n       AtomicBoolean fallbackToSimpleAuth) throws IOException {\n     Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d null;\n     AbstractNNFailoverProxyProvider\u003cT\u003e providerNN;\n-    Preconditions.checkArgument(\n-        xface.isAssignableFrom(NamenodeProtocols.class),\n-        \"Interface %s is not a NameNode protocol\", xface);\n     try {\n       // Obtain the class of the proxy provider\n       failoverProxyProviderClass \u003d getFailoverProxyProviderClass(conf,\n           nameNodeUri);\n       if (failoverProxyProviderClass \u003d\u003d null) {\n         return null;\n       }\n       // Create a proxy provider instance.\n       Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n           .getConstructor(Configuration.class, URI.class, Class.class);\n       FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n           xface);\n \n       // If the proxy provider is of an old implementation, wrap it.\n       if (!(provider instanceof AbstractNNFailoverProxyProvider)) {\n-        providerNN \u003d new WrappedFailoverProxyProvider\u003cT\u003e(provider);\n+        providerNN \u003d new WrappedFailoverProxyProvider\u003c\u003e(provider);\n       } else {\n         providerNN \u003d (AbstractNNFailoverProxyProvider\u003cT\u003e)provider;\n       }\n     } catch (Exception e) {\n-      String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(message, e);\n-      }\n+      final String message \u003d \"Couldn\u0027t create proxy provider \" +\n+          failoverProxyProviderClass;\n+      LOG.debug(message, e);\n       if (e.getCause() instanceof IOException) {\n         throw (IOException) e.getCause();\n       } else {\n         throw new IOException(message, e);\n       }\n     }\n \n     // Check the port in the URI, if it is logical.\n     if (checkPort \u0026\u0026 providerNN.useLogicalURI()) {\n       int port \u003d nameNodeUri.getPort();\n       if (port \u003e 0 \u0026\u0026\n           port !\u003d HdfsClientConfigKeys.DFS_NAMENODE_RPC_PORT_DEFAULT) {\n         // Throwing here without any cleanup is fine since we have not\n         // actually created the underlying proxies yet.\n         throw new IOException(\"Port \" + port + \" specified in URI \"\n             + nameNodeUri + \" but host \u0027\" + nameNodeUri.getHost()\n             + \"\u0027 is a logical (HA) namenode\"\n             + \" and does not use port information.\");\n       }\n     }\n     providerNN.setFallbackToSimpleAuth(fallbackToSimpleAuth);\n     return providerNN;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort,\n      AtomicBoolean fallbackToSimpleAuth) throws IOException {\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d null;\n    AbstractNNFailoverProxyProvider\u003cT\u003e providerNN;\n    try {\n      // Obtain the class of the proxy provider\n      failoverProxyProviderClass \u003d getFailoverProxyProviderClass(conf,\n          nameNodeUri);\n      if (failoverProxyProviderClass \u003d\u003d null) {\n        return null;\n      }\n      // Create a proxy provider instance.\n      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Configuration.class, URI.class, Class.class);\n      FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n          xface);\n\n      // If the proxy provider is of an old implementation, wrap it.\n      if (!(provider instanceof AbstractNNFailoverProxyProvider)) {\n        providerNN \u003d new WrappedFailoverProxyProvider\u003c\u003e(provider);\n      } else {\n        providerNN \u003d (AbstractNNFailoverProxyProvider\u003cT\u003e)provider;\n      }\n    } catch (Exception e) {\n      final String message \u003d \"Couldn\u0027t create proxy provider \" +\n          failoverProxyProviderClass;\n      LOG.debug(message, e);\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(message, e);\n      }\n    }\n\n    // Check the port in the URI, if it is logical.\n    if (checkPort \u0026\u0026 providerNN.useLogicalURI()) {\n      int port \u003d nameNodeUri.getPort();\n      if (port \u003e 0 \u0026\u0026\n          port !\u003d HdfsClientConfigKeys.DFS_NAMENODE_RPC_PORT_DEFAULT) {\n        // Throwing here without any cleanup is fine since we have not\n        // actually created the underlying proxies yet.\n        throw new IOException(\"Port \" + port + \" specified in URI \"\n            + nameNodeUri + \" but host \u0027\" + nameNodeUri.getHost()\n            + \"\u0027 is a logical (HA) namenode\"\n            + \" and does not use port information.\");\n      }\n    }\n    providerNN.setFallbackToSimpleAuth(fallbackToSimpleAuth);\n    return providerNN;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/NameNodeProxiesClient.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/NameNodeProxiesClient.java",
            "oldMethodName": "createFailoverProxyProvider",
            "newMethodName": "createFailoverProxyProvider"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9039. Separate client and server side methods of o.a.h.hdfs.NameNodeProxies. Contributed by Mingliang Liu.\n",
          "commitDate": "22/09/15 8:52 PM",
          "commitName": "63d9f1596c92206cce3b72e3214d2fb5f6242b90",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "22/09/15 9:08 AM",
          "commitNameOld": "cc2b4739902df60254dce2ddb23ef8f6ff2a3495",
          "commitAuthorOld": "Harsh J",
          "daysBetweenCommits": 0.49,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,55 +1,51 @@\n   public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n       Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort,\n       AtomicBoolean fallbackToSimpleAuth) throws IOException {\n     Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d null;\n     AbstractNNFailoverProxyProvider\u003cT\u003e providerNN;\n-    Preconditions.checkArgument(\n-        xface.isAssignableFrom(NamenodeProtocols.class),\n-        \"Interface %s is not a NameNode protocol\", xface);\n     try {\n       // Obtain the class of the proxy provider\n       failoverProxyProviderClass \u003d getFailoverProxyProviderClass(conf,\n           nameNodeUri);\n       if (failoverProxyProviderClass \u003d\u003d null) {\n         return null;\n       }\n       // Create a proxy provider instance.\n       Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n           .getConstructor(Configuration.class, URI.class, Class.class);\n       FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n           xface);\n \n       // If the proxy provider is of an old implementation, wrap it.\n       if (!(provider instanceof AbstractNNFailoverProxyProvider)) {\n-        providerNN \u003d new WrappedFailoverProxyProvider\u003cT\u003e(provider);\n+        providerNN \u003d new WrappedFailoverProxyProvider\u003c\u003e(provider);\n       } else {\n         providerNN \u003d (AbstractNNFailoverProxyProvider\u003cT\u003e)provider;\n       }\n     } catch (Exception e) {\n-      String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(message, e);\n-      }\n+      final String message \u003d \"Couldn\u0027t create proxy provider \" +\n+          failoverProxyProviderClass;\n+      LOG.debug(message, e);\n       if (e.getCause() instanceof IOException) {\n         throw (IOException) e.getCause();\n       } else {\n         throw new IOException(message, e);\n       }\n     }\n \n     // Check the port in the URI, if it is logical.\n     if (checkPort \u0026\u0026 providerNN.useLogicalURI()) {\n       int port \u003d nameNodeUri.getPort();\n       if (port \u003e 0 \u0026\u0026\n           port !\u003d HdfsClientConfigKeys.DFS_NAMENODE_RPC_PORT_DEFAULT) {\n         // Throwing here without any cleanup is fine since we have not\n         // actually created the underlying proxies yet.\n         throw new IOException(\"Port \" + port + \" specified in URI \"\n             + nameNodeUri + \" but host \u0027\" + nameNodeUri.getHost()\n             + \"\u0027 is a logical (HA) namenode\"\n             + \" and does not use port information.\");\n       }\n     }\n     providerNN.setFallbackToSimpleAuth(fallbackToSimpleAuth);\n     return providerNN;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort,\n      AtomicBoolean fallbackToSimpleAuth) throws IOException {\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d null;\n    AbstractNNFailoverProxyProvider\u003cT\u003e providerNN;\n    try {\n      // Obtain the class of the proxy provider\n      failoverProxyProviderClass \u003d getFailoverProxyProviderClass(conf,\n          nameNodeUri);\n      if (failoverProxyProviderClass \u003d\u003d null) {\n        return null;\n      }\n      // Create a proxy provider instance.\n      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Configuration.class, URI.class, Class.class);\n      FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n          xface);\n\n      // If the proxy provider is of an old implementation, wrap it.\n      if (!(provider instanceof AbstractNNFailoverProxyProvider)) {\n        providerNN \u003d new WrappedFailoverProxyProvider\u003c\u003e(provider);\n      } else {\n        providerNN \u003d (AbstractNNFailoverProxyProvider\u003cT\u003e)provider;\n      }\n    } catch (Exception e) {\n      final String message \u003d \"Couldn\u0027t create proxy provider \" +\n          failoverProxyProviderClass;\n      LOG.debug(message, e);\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(message, e);\n      }\n    }\n\n    // Check the port in the URI, if it is logical.\n    if (checkPort \u0026\u0026 providerNN.useLogicalURI()) {\n      int port \u003d nameNodeUri.getPort();\n      if (port \u003e 0 \u0026\u0026\n          port !\u003d HdfsClientConfigKeys.DFS_NAMENODE_RPC_PORT_DEFAULT) {\n        // Throwing here without any cleanup is fine since we have not\n        // actually created the underlying proxies yet.\n        throw new IOException(\"Port \" + port + \" specified in URI \"\n            + nameNodeUri + \" but host \u0027\" + nameNodeUri.getHost()\n            + \"\u0027 is a logical (HA) namenode\"\n            + \" and does not use port information.\");\n      }\n    }\n    providerNN.setFallbackToSimpleAuth(fallbackToSimpleAuth);\n    return providerNN;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/NameNodeProxiesClient.java",
          "extendedDetails": {}
        }
      ]
    },
    "76957a485b526468498f93e443544131a88b5684": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9010. Replace NameNode.DEFAULT_PORT with HdfsClientConfigKeys.DFS_NAMENODE_RPC_PORT_DEFAULT config key. Contributed by Mingliang Liu.\n",
      "commitDate": "14/09/15 6:22 PM",
      "commitName": "76957a485b526468498f93e443544131a88b5684",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "02/06/15 11:41 PM",
      "commitNameOld": "54f83d9bd917e8641e902c5f0695e65ded472f9a",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 103.78,
      "commitsBetweenForRepo": 621,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,55 @@\n   public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n       Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort,\n       AtomicBoolean fallbackToSimpleAuth) throws IOException {\n     Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d null;\n     AbstractNNFailoverProxyProvider\u003cT\u003e providerNN;\n     Preconditions.checkArgument(\n         xface.isAssignableFrom(NamenodeProtocols.class),\n         \"Interface %s is not a NameNode protocol\", xface);\n     try {\n       // Obtain the class of the proxy provider\n       failoverProxyProviderClass \u003d getFailoverProxyProviderClass(conf,\n           nameNodeUri);\n       if (failoverProxyProviderClass \u003d\u003d null) {\n         return null;\n       }\n       // Create a proxy provider instance.\n       Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n           .getConstructor(Configuration.class, URI.class, Class.class);\n       FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n           xface);\n \n       // If the proxy provider is of an old implementation, wrap it.\n       if (!(provider instanceof AbstractNNFailoverProxyProvider)) {\n         providerNN \u003d new WrappedFailoverProxyProvider\u003cT\u003e(provider);\n       } else {\n         providerNN \u003d (AbstractNNFailoverProxyProvider\u003cT\u003e)provider;\n       }\n     } catch (Exception e) {\n       String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(message, e);\n       }\n       if (e.getCause() instanceof IOException) {\n         throw (IOException) e.getCause();\n       } else {\n         throw new IOException(message, e);\n       }\n     }\n \n     // Check the port in the URI, if it is logical.\n     if (checkPort \u0026\u0026 providerNN.useLogicalURI()) {\n       int port \u003d nameNodeUri.getPort();\n-      if (port \u003e 0 \u0026\u0026 port !\u003d NameNode.DEFAULT_PORT) {\n+      if (port \u003e 0 \u0026\u0026\n+          port !\u003d HdfsClientConfigKeys.DFS_NAMENODE_RPC_PORT_DEFAULT) {\n         // Throwing here without any cleanup is fine since we have not\n         // actually created the underlying proxies yet.\n         throw new IOException(\"Port \" + port + \" specified in URI \"\n             + nameNodeUri + \" but host \u0027\" + nameNodeUri.getHost()\n             + \"\u0027 is a logical (HA) namenode\"\n             + \" and does not use port information.\");\n       }\n     }\n     providerNN.setFallbackToSimpleAuth(fallbackToSimpleAuth);\n     return providerNN;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort,\n      AtomicBoolean fallbackToSimpleAuth) throws IOException {\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d null;\n    AbstractNNFailoverProxyProvider\u003cT\u003e providerNN;\n    Preconditions.checkArgument(\n        xface.isAssignableFrom(NamenodeProtocols.class),\n        \"Interface %s is not a NameNode protocol\", xface);\n    try {\n      // Obtain the class of the proxy provider\n      failoverProxyProviderClass \u003d getFailoverProxyProviderClass(conf,\n          nameNodeUri);\n      if (failoverProxyProviderClass \u003d\u003d null) {\n        return null;\n      }\n      // Create a proxy provider instance.\n      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Configuration.class, URI.class, Class.class);\n      FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n          xface);\n\n      // If the proxy provider is of an old implementation, wrap it.\n      if (!(provider instanceof AbstractNNFailoverProxyProvider)) {\n        providerNN \u003d new WrappedFailoverProxyProvider\u003cT\u003e(provider);\n      } else {\n        providerNN \u003d (AbstractNNFailoverProxyProvider\u003cT\u003e)provider;\n      }\n    } catch (Exception e) {\n      String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(message, e);\n      }\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(message, e);\n      }\n    }\n\n    // Check the port in the URI, if it is logical.\n    if (checkPort \u0026\u0026 providerNN.useLogicalURI()) {\n      int port \u003d nameNodeUri.getPort();\n      if (port \u003e 0 \u0026\u0026\n          port !\u003d HdfsClientConfigKeys.DFS_NAMENODE_RPC_PORT_DEFAULT) {\n        // Throwing here without any cleanup is fine since we have not\n        // actually created the underlying proxies yet.\n        throw new IOException(\"Port \" + port + \" specified in URI \"\n            + nameNodeUri + \" but host \u0027\" + nameNodeUri.getHost()\n            + \"\u0027 is a logical (HA) namenode\"\n            + \" and does not use port information.\");\n      }\n    }\n    providerNN.setFallbackToSimpleAuth(fallbackToSimpleAuth);\n    return providerNN;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7073. Allow falling back to a non-SASL connection on DataTransferProtocol in several edge cases. Contributed by Chris Nauroth.\n",
      "commitDate": "19/09/14 9:23 PM",
      "commitName": "f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5",
      "commitAuthor": "cnauroth",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7073. Allow falling back to a non-SASL connection on DataTransferProtocol in several edge cases. Contributed by Chris Nauroth.\n",
          "commitDate": "19/09/14 9:23 PM",
          "commitName": "f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5",
          "commitAuthor": "cnauroth",
          "commitDateOld": "17/07/14 4:11 PM",
          "commitNameOld": "7ba5913797c49d5001ad95558eadd119c3361060",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 64.22,
          "commitsBetweenForRepo": 611,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,53 +1,54 @@\n   public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n-      Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort)\n-      throws IOException {\n+      Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort,\n+      AtomicBoolean fallbackToSimpleAuth) throws IOException {\n     Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d null;\n     AbstractNNFailoverProxyProvider\u003cT\u003e providerNN;\n     Preconditions.checkArgument(\n         xface.isAssignableFrom(NamenodeProtocols.class),\n         \"Interface %s is not a NameNode protocol\", xface);\n     try {\n       // Obtain the class of the proxy provider\n       failoverProxyProviderClass \u003d getFailoverProxyProviderClass(conf,\n           nameNodeUri);\n       if (failoverProxyProviderClass \u003d\u003d null) {\n         return null;\n       }\n       // Create a proxy provider instance.\n       Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n           .getConstructor(Configuration.class, URI.class, Class.class);\n       FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n           xface);\n \n       // If the proxy provider is of an old implementation, wrap it.\n       if (!(provider instanceof AbstractNNFailoverProxyProvider)) {\n         providerNN \u003d new WrappedFailoverProxyProvider\u003cT\u003e(provider);\n       } else {\n         providerNN \u003d (AbstractNNFailoverProxyProvider\u003cT\u003e)provider;\n       }\n     } catch (Exception e) {\n       String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(message, e);\n       }\n       if (e.getCause() instanceof IOException) {\n         throw (IOException) e.getCause();\n       } else {\n         throw new IOException(message, e);\n       }\n     }\n \n     // Check the port in the URI, if it is logical.\n     if (checkPort \u0026\u0026 providerNN.useLogicalURI()) {\n       int port \u003d nameNodeUri.getPort();\n       if (port \u003e 0 \u0026\u0026 port !\u003d NameNode.DEFAULT_PORT) {\n         // Throwing here without any cleanup is fine since we have not\n         // actually created the underlying proxies yet.\n         throw new IOException(\"Port \" + port + \" specified in URI \"\n             + nameNodeUri + \" but host \u0027\" + nameNodeUri.getHost()\n             + \"\u0027 is a logical (HA) namenode\"\n             + \" and does not use port information.\");\n       }\n     }\n+    providerNN.setFallbackToSimpleAuth(fallbackToSimpleAuth);\n     return providerNN;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort,\n      AtomicBoolean fallbackToSimpleAuth) throws IOException {\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d null;\n    AbstractNNFailoverProxyProvider\u003cT\u003e providerNN;\n    Preconditions.checkArgument(\n        xface.isAssignableFrom(NamenodeProtocols.class),\n        \"Interface %s is not a NameNode protocol\", xface);\n    try {\n      // Obtain the class of the proxy provider\n      failoverProxyProviderClass \u003d getFailoverProxyProviderClass(conf,\n          nameNodeUri);\n      if (failoverProxyProviderClass \u003d\u003d null) {\n        return null;\n      }\n      // Create a proxy provider instance.\n      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Configuration.class, URI.class, Class.class);\n      FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n          xface);\n\n      // If the proxy provider is of an old implementation, wrap it.\n      if (!(provider instanceof AbstractNNFailoverProxyProvider)) {\n        providerNN \u003d new WrappedFailoverProxyProvider\u003cT\u003e(provider);\n      } else {\n        providerNN \u003d (AbstractNNFailoverProxyProvider\u003cT\u003e)provider;\n      }\n    } catch (Exception e) {\n      String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(message, e);\n      }\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(message, e);\n      }\n    }\n\n    // Check the port in the URI, if it is logical.\n    if (checkPort \u0026\u0026 providerNN.useLogicalURI()) {\n      int port \u003d nameNodeUri.getPort();\n      if (port \u003e 0 \u0026\u0026 port !\u003d NameNode.DEFAULT_PORT) {\n        // Throwing here without any cleanup is fine since we have not\n        // actually created the underlying proxies yet.\n        throw new IOException(\"Port \" + port + \" specified in URI \"\n            + nameNodeUri + \" but host \u0027\" + nameNodeUri.getHost()\n            + \"\u0027 is a logical (HA) namenode\"\n            + \" and does not use port information.\");\n      }\n    }\n    providerNN.setFallbackToSimpleAuth(fallbackToSimpleAuth);\n    return providerNN;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
          "extendedDetails": {
            "oldValue": "[conf-Configuration, nameNodeUri-URI, xface-Class\u003cT\u003e, checkPort-boolean]",
            "newValue": "[conf-Configuration, nameNodeUri-URI, xface-Class\u003cT\u003e, checkPort-boolean, fallbackToSimpleAuth-AtomicBoolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7073. Allow falling back to a non-SASL connection on DataTransferProtocol in several edge cases. Contributed by Chris Nauroth.\n",
          "commitDate": "19/09/14 9:23 PM",
          "commitName": "f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5",
          "commitAuthor": "cnauroth",
          "commitDateOld": "17/07/14 4:11 PM",
          "commitNameOld": "7ba5913797c49d5001ad95558eadd119c3361060",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 64.22,
          "commitsBetweenForRepo": 611,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,53 +1,54 @@\n   public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n-      Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort)\n-      throws IOException {\n+      Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort,\n+      AtomicBoolean fallbackToSimpleAuth) throws IOException {\n     Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d null;\n     AbstractNNFailoverProxyProvider\u003cT\u003e providerNN;\n     Preconditions.checkArgument(\n         xface.isAssignableFrom(NamenodeProtocols.class),\n         \"Interface %s is not a NameNode protocol\", xface);\n     try {\n       // Obtain the class of the proxy provider\n       failoverProxyProviderClass \u003d getFailoverProxyProviderClass(conf,\n           nameNodeUri);\n       if (failoverProxyProviderClass \u003d\u003d null) {\n         return null;\n       }\n       // Create a proxy provider instance.\n       Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n           .getConstructor(Configuration.class, URI.class, Class.class);\n       FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n           xface);\n \n       // If the proxy provider is of an old implementation, wrap it.\n       if (!(provider instanceof AbstractNNFailoverProxyProvider)) {\n         providerNN \u003d new WrappedFailoverProxyProvider\u003cT\u003e(provider);\n       } else {\n         providerNN \u003d (AbstractNNFailoverProxyProvider\u003cT\u003e)provider;\n       }\n     } catch (Exception e) {\n       String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(message, e);\n       }\n       if (e.getCause() instanceof IOException) {\n         throw (IOException) e.getCause();\n       } else {\n         throw new IOException(message, e);\n       }\n     }\n \n     // Check the port in the URI, if it is logical.\n     if (checkPort \u0026\u0026 providerNN.useLogicalURI()) {\n       int port \u003d nameNodeUri.getPort();\n       if (port \u003e 0 \u0026\u0026 port !\u003d NameNode.DEFAULT_PORT) {\n         // Throwing here without any cleanup is fine since we have not\n         // actually created the underlying proxies yet.\n         throw new IOException(\"Port \" + port + \" specified in URI \"\n             + nameNodeUri + \" but host \u0027\" + nameNodeUri.getHost()\n             + \"\u0027 is a logical (HA) namenode\"\n             + \" and does not use port information.\");\n       }\n     }\n+    providerNN.setFallbackToSimpleAuth(fallbackToSimpleAuth);\n     return providerNN;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort,\n      AtomicBoolean fallbackToSimpleAuth) throws IOException {\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d null;\n    AbstractNNFailoverProxyProvider\u003cT\u003e providerNN;\n    Preconditions.checkArgument(\n        xface.isAssignableFrom(NamenodeProtocols.class),\n        \"Interface %s is not a NameNode protocol\", xface);\n    try {\n      // Obtain the class of the proxy provider\n      failoverProxyProviderClass \u003d getFailoverProxyProviderClass(conf,\n          nameNodeUri);\n      if (failoverProxyProviderClass \u003d\u003d null) {\n        return null;\n      }\n      // Create a proxy provider instance.\n      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Configuration.class, URI.class, Class.class);\n      FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n          xface);\n\n      // If the proxy provider is of an old implementation, wrap it.\n      if (!(provider instanceof AbstractNNFailoverProxyProvider)) {\n        providerNN \u003d new WrappedFailoverProxyProvider\u003cT\u003e(provider);\n      } else {\n        providerNN \u003d (AbstractNNFailoverProxyProvider\u003cT\u003e)provider;\n      }\n    } catch (Exception e) {\n      String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(message, e);\n      }\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(message, e);\n      }\n    }\n\n    // Check the port in the URI, if it is logical.\n    if (checkPort \u0026\u0026 providerNN.useLogicalURI()) {\n      int port \u003d nameNodeUri.getPort();\n      if (port \u003e 0 \u0026\u0026 port !\u003d NameNode.DEFAULT_PORT) {\n        // Throwing here without any cleanup is fine since we have not\n        // actually created the underlying proxies yet.\n        throw new IOException(\"Port \" + port + \" specified in URI \"\n            + nameNodeUri + \" but host \u0027\" + nameNodeUri.getHost()\n            + \"\u0027 is a logical (HA) namenode\"\n            + \" and does not use port information.\");\n      }\n    }\n    providerNN.setFallbackToSimpleAuth(fallbackToSimpleAuth);\n    return providerNN;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
          "extendedDetails": {}
        }
      ]
    },
    "33ade356b35223654a077103ed7fbed89f3f2321": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-6334. Client failover proxy provider for IP failover based NN HA. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594263 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/05/14 9:19 AM",
      "commitName": "33ade356b35223654a077103ed7fbed89f3f2321",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6334. Client failover proxy provider for IP failover based NN HA. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594263 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/05/14 9:19 AM",
          "commitName": "33ade356b35223654a077103ed7fbed89f3f2321",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "28/02/14 11:48 AM",
          "commitNameOld": "d00605f8f0214ed8e2304db8688e140f0a1d62d8",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 73.85,
          "commitsBetweenForRepo": 483,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,53 @@\n-  public static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n-      Configuration conf, Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass,\n-      Class\u003cT\u003e xface, URI nameNodeUri) throws IOException {\n+  public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n+      Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort)\n+      throws IOException {\n+    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d null;\n+    AbstractNNFailoverProxyProvider\u003cT\u003e providerNN;\n     Preconditions.checkArgument(\n         xface.isAssignableFrom(NamenodeProtocols.class),\n         \"Interface %s is not a NameNode protocol\", xface);\n     try {\n+      // Obtain the class of the proxy provider\n+      failoverProxyProviderClass \u003d getFailoverProxyProviderClass(conf,\n+          nameNodeUri);\n+      if (failoverProxyProviderClass \u003d\u003d null) {\n+        return null;\n+      }\n+      // Create a proxy provider instance.\n       Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n           .getConstructor(Configuration.class, URI.class, Class.class);\n       FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n           xface);\n-      return provider;\n+\n+      // If the proxy provider is of an old implementation, wrap it.\n+      if (!(provider instanceof AbstractNNFailoverProxyProvider)) {\n+        providerNN \u003d new WrappedFailoverProxyProvider\u003cT\u003e(provider);\n+      } else {\n+        providerNN \u003d (AbstractNNFailoverProxyProvider\u003cT\u003e)provider;\n+      }\n     } catch (Exception e) {\n       String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(message, e);\n       }\n       if (e.getCause() instanceof IOException) {\n         throw (IOException) e.getCause();\n       } else {\n         throw new IOException(message, e);\n       }\n     }\n+\n+    // Check the port in the URI, if it is logical.\n+    if (checkPort \u0026\u0026 providerNN.useLogicalURI()) {\n+      int port \u003d nameNodeUri.getPort();\n+      if (port \u003e 0 \u0026\u0026 port !\u003d NameNode.DEFAULT_PORT) {\n+        // Throwing here without any cleanup is fine since we have not\n+        // actually created the underlying proxies yet.\n+        throw new IOException(\"Port \" + port + \" specified in URI \"\n+            + nameNodeUri + \" but host \u0027\" + nameNodeUri.getHost()\n+            + \"\u0027 is a logical (HA) namenode\"\n+            + \" and does not use port information.\");\n+      }\n+    }\n+    return providerNN;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort)\n      throws IOException {\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d null;\n    AbstractNNFailoverProxyProvider\u003cT\u003e providerNN;\n    Preconditions.checkArgument(\n        xface.isAssignableFrom(NamenodeProtocols.class),\n        \"Interface %s is not a NameNode protocol\", xface);\n    try {\n      // Obtain the class of the proxy provider\n      failoverProxyProviderClass \u003d getFailoverProxyProviderClass(conf,\n          nameNodeUri);\n      if (failoverProxyProviderClass \u003d\u003d null) {\n        return null;\n      }\n      // Create a proxy provider instance.\n      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Configuration.class, URI.class, Class.class);\n      FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n          xface);\n\n      // If the proxy provider is of an old implementation, wrap it.\n      if (!(provider instanceof AbstractNNFailoverProxyProvider)) {\n        providerNN \u003d new WrappedFailoverProxyProvider\u003cT\u003e(provider);\n      } else {\n        providerNN \u003d (AbstractNNFailoverProxyProvider\u003cT\u003e)provider;\n      }\n    } catch (Exception e) {\n      String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(message, e);\n      }\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(message, e);\n      }\n    }\n\n    // Check the port in the URI, if it is logical.\n    if (checkPort \u0026\u0026 providerNN.useLogicalURI()) {\n      int port \u003d nameNodeUri.getPort();\n      if (port \u003e 0 \u0026\u0026 port !\u003d NameNode.DEFAULT_PORT) {\n        // Throwing here without any cleanup is fine since we have not\n        // actually created the underlying proxies yet.\n        throw new IOException(\"Port \" + port + \" specified in URI \"\n            + nameNodeUri + \" but host \u0027\" + nameNodeUri.getHost()\n            + \"\u0027 is a logical (HA) namenode\"\n            + \" and does not use port information.\");\n      }\n    }\n    return providerNN;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
          "extendedDetails": {
            "oldValue": "[conf-Configuration, failoverProxyProviderClass-Class\u003cFailoverProxyProvider\u003cT\u003e\u003e, xface-Class\u003cT\u003e, nameNodeUri-URI]",
            "newValue": "[conf-Configuration, nameNodeUri-URI, xface-Class\u003cT\u003e, checkPort-boolean]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-6334. Client failover proxy provider for IP failover based NN HA. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594263 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/05/14 9:19 AM",
          "commitName": "33ade356b35223654a077103ed7fbed89f3f2321",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "28/02/14 11:48 AM",
          "commitNameOld": "d00605f8f0214ed8e2304db8688e140f0a1d62d8",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 73.85,
          "commitsBetweenForRepo": 483,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,53 @@\n-  public static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n-      Configuration conf, Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass,\n-      Class\u003cT\u003e xface, URI nameNodeUri) throws IOException {\n+  public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n+      Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort)\n+      throws IOException {\n+    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d null;\n+    AbstractNNFailoverProxyProvider\u003cT\u003e providerNN;\n     Preconditions.checkArgument(\n         xface.isAssignableFrom(NamenodeProtocols.class),\n         \"Interface %s is not a NameNode protocol\", xface);\n     try {\n+      // Obtain the class of the proxy provider\n+      failoverProxyProviderClass \u003d getFailoverProxyProviderClass(conf,\n+          nameNodeUri);\n+      if (failoverProxyProviderClass \u003d\u003d null) {\n+        return null;\n+      }\n+      // Create a proxy provider instance.\n       Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n           .getConstructor(Configuration.class, URI.class, Class.class);\n       FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n           xface);\n-      return provider;\n+\n+      // If the proxy provider is of an old implementation, wrap it.\n+      if (!(provider instanceof AbstractNNFailoverProxyProvider)) {\n+        providerNN \u003d new WrappedFailoverProxyProvider\u003cT\u003e(provider);\n+      } else {\n+        providerNN \u003d (AbstractNNFailoverProxyProvider\u003cT\u003e)provider;\n+      }\n     } catch (Exception e) {\n       String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(message, e);\n       }\n       if (e.getCause() instanceof IOException) {\n         throw (IOException) e.getCause();\n       } else {\n         throw new IOException(message, e);\n       }\n     }\n+\n+    // Check the port in the URI, if it is logical.\n+    if (checkPort \u0026\u0026 providerNN.useLogicalURI()) {\n+      int port \u003d nameNodeUri.getPort();\n+      if (port \u003e 0 \u0026\u0026 port !\u003d NameNode.DEFAULT_PORT) {\n+        // Throwing here without any cleanup is fine since we have not\n+        // actually created the underlying proxies yet.\n+        throw new IOException(\"Port \" + port + \" specified in URI \"\n+            + nameNodeUri + \" but host \u0027\" + nameNodeUri.getHost()\n+            + \"\u0027 is a logical (HA) namenode\"\n+            + \" and does not use port information.\");\n+      }\n+    }\n+    return providerNN;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort)\n      throws IOException {\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d null;\n    AbstractNNFailoverProxyProvider\u003cT\u003e providerNN;\n    Preconditions.checkArgument(\n        xface.isAssignableFrom(NamenodeProtocols.class),\n        \"Interface %s is not a NameNode protocol\", xface);\n    try {\n      // Obtain the class of the proxy provider\n      failoverProxyProviderClass \u003d getFailoverProxyProviderClass(conf,\n          nameNodeUri);\n      if (failoverProxyProviderClass \u003d\u003d null) {\n        return null;\n      }\n      // Create a proxy provider instance.\n      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Configuration.class, URI.class, Class.class);\n      FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n          xface);\n\n      // If the proxy provider is of an old implementation, wrap it.\n      if (!(provider instanceof AbstractNNFailoverProxyProvider)) {\n        providerNN \u003d new WrappedFailoverProxyProvider\u003cT\u003e(provider);\n      } else {\n        providerNN \u003d (AbstractNNFailoverProxyProvider\u003cT\u003e)provider;\n      }\n    } catch (Exception e) {\n      String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(message, e);\n      }\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(message, e);\n      }\n    }\n\n    // Check the port in the URI, if it is logical.\n    if (checkPort \u0026\u0026 providerNN.useLogicalURI()) {\n      int port \u003d nameNodeUri.getPort();\n      if (port \u003e 0 \u0026\u0026 port !\u003d NameNode.DEFAULT_PORT) {\n        // Throwing here without any cleanup is fine since we have not\n        // actually created the underlying proxies yet.\n        throw new IOException(\"Port \" + port + \" specified in URI \"\n            + nameNodeUri + \" but host \u0027\" + nameNodeUri.getHost()\n            + \"\u0027 is a logical (HA) namenode\"\n            + \" and does not use port information.\");\n      }\n    }\n    return providerNN;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
          "extendedDetails": {
            "oldValue": "FailoverProxyProvider\u003cT\u003e",
            "newValue": "AbstractNNFailoverProxyProvider\u003cT\u003e"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6334. Client failover proxy provider for IP failover based NN HA. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594263 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/05/14 9:19 AM",
          "commitName": "33ade356b35223654a077103ed7fbed89f3f2321",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "28/02/14 11:48 AM",
          "commitNameOld": "d00605f8f0214ed8e2304db8688e140f0a1d62d8",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 73.85,
          "commitsBetweenForRepo": 483,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,53 @@\n-  public static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n-      Configuration conf, Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass,\n-      Class\u003cT\u003e xface, URI nameNodeUri) throws IOException {\n+  public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n+      Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort)\n+      throws IOException {\n+    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d null;\n+    AbstractNNFailoverProxyProvider\u003cT\u003e providerNN;\n     Preconditions.checkArgument(\n         xface.isAssignableFrom(NamenodeProtocols.class),\n         \"Interface %s is not a NameNode protocol\", xface);\n     try {\n+      // Obtain the class of the proxy provider\n+      failoverProxyProviderClass \u003d getFailoverProxyProviderClass(conf,\n+          nameNodeUri);\n+      if (failoverProxyProviderClass \u003d\u003d null) {\n+        return null;\n+      }\n+      // Create a proxy provider instance.\n       Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n           .getConstructor(Configuration.class, URI.class, Class.class);\n       FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n           xface);\n-      return provider;\n+\n+      // If the proxy provider is of an old implementation, wrap it.\n+      if (!(provider instanceof AbstractNNFailoverProxyProvider)) {\n+        providerNN \u003d new WrappedFailoverProxyProvider\u003cT\u003e(provider);\n+      } else {\n+        providerNN \u003d (AbstractNNFailoverProxyProvider\u003cT\u003e)provider;\n+      }\n     } catch (Exception e) {\n       String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(message, e);\n       }\n       if (e.getCause() instanceof IOException) {\n         throw (IOException) e.getCause();\n       } else {\n         throw new IOException(message, e);\n       }\n     }\n+\n+    // Check the port in the URI, if it is logical.\n+    if (checkPort \u0026\u0026 providerNN.useLogicalURI()) {\n+      int port \u003d nameNodeUri.getPort();\n+      if (port \u003e 0 \u0026\u0026 port !\u003d NameNode.DEFAULT_PORT) {\n+        // Throwing here without any cleanup is fine since we have not\n+        // actually created the underlying proxies yet.\n+        throw new IOException(\"Port \" + port + \" specified in URI \"\n+            + nameNodeUri + \" but host \u0027\" + nameNodeUri.getHost()\n+            + \"\u0027 is a logical (HA) namenode\"\n+            + \" and does not use port information.\");\n+      }\n+    }\n+    return providerNN;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e AbstractNNFailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, URI nameNodeUri, Class\u003cT\u003e xface, boolean checkPort)\n      throws IOException {\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d null;\n    AbstractNNFailoverProxyProvider\u003cT\u003e providerNN;\n    Preconditions.checkArgument(\n        xface.isAssignableFrom(NamenodeProtocols.class),\n        \"Interface %s is not a NameNode protocol\", xface);\n    try {\n      // Obtain the class of the proxy provider\n      failoverProxyProviderClass \u003d getFailoverProxyProviderClass(conf,\n          nameNodeUri);\n      if (failoverProxyProviderClass \u003d\u003d null) {\n        return null;\n      }\n      // Create a proxy provider instance.\n      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Configuration.class, URI.class, Class.class);\n      FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n          xface);\n\n      // If the proxy provider is of an old implementation, wrap it.\n      if (!(provider instanceof AbstractNNFailoverProxyProvider)) {\n        providerNN \u003d new WrappedFailoverProxyProvider\u003cT\u003e(provider);\n      } else {\n        providerNN \u003d (AbstractNNFailoverProxyProvider\u003cT\u003e)provider;\n      }\n    } catch (Exception e) {\n      String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(message, e);\n      }\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(message, e);\n      }\n    }\n\n    // Check the port in the URI, if it is logical.\n    if (checkPort \u0026\u0026 providerNN.useLogicalURI()) {\n      int port \u003d nameNodeUri.getPort();\n      if (port \u003e 0 \u0026\u0026 port !\u003d NameNode.DEFAULT_PORT) {\n        // Throwing here without any cleanup is fine since we have not\n        // actually created the underlying proxies yet.\n        throw new IOException(\"Port \" + port + \" specified in URI \"\n            + nameNodeUri + \" but host \u0027\" + nameNodeUri.getHost()\n            + \"\u0027 is a logical (HA) namenode\"\n            + \" and does not use port information.\");\n      }\n    }\n    return providerNN;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
          "extendedDetails": {}
        }
      ]
    },
    "8c7a7e619699386f9e6991842558d78aa0c8053d": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-5025. Record ClientId and CallId in EditLog to enable rebuilding retry cache in case of HA failover. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1508332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/07/13 12:51 AM",
      "commitName": "8c7a7e619699386f9e6991842558d78aa0c8053d",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "26/07/13 3:59 AM",
      "commitNameOld": "a690a215dba6180090214675393431a589c37f24",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 3.87,
      "commitsBetweenForRepo": 29,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n-  private static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n+  public static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n       Configuration conf, Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass,\n       Class\u003cT\u003e xface, URI nameNodeUri) throws IOException {\n     Preconditions.checkArgument(\n         xface.isAssignableFrom(NamenodeProtocols.class),\n         \"Interface %s is not a NameNode protocol\", xface);\n     try {\n       Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n           .getConstructor(Configuration.class, URI.class, Class.class);\n       FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n           xface);\n       return provider;\n     } catch (Exception e) {\n       String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(message, e);\n       }\n       if (e.getCause() instanceof IOException) {\n         throw (IOException) e.getCause();\n       } else {\n         throw new IOException(message, e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass,\n      Class\u003cT\u003e xface, URI nameNodeUri) throws IOException {\n    Preconditions.checkArgument(\n        xface.isAssignableFrom(NamenodeProtocols.class),\n        \"Interface %s is not a NameNode protocol\", xface);\n    try {\n      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Configuration.class, URI.class, Class.class);\n      FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n          xface);\n      return provider;\n    } catch (Exception e) {\n      String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(message, e);\n      }\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(message, e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {
        "oldValue": "[private, static]",
        "newValue": "[public, static]"
      }
    },
    "a690a215dba6180090214675393431a589c37f24": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9756. Remove the deprecated getServer(..) methods from RPC.  Contributed by Junping Du\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1507259 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/07/13 3:59 AM",
      "commitName": "a690a215dba6180090214675393431a589c37f24",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "22/07/13 12:22 AM",
      "commitNameOld": "3eb61be352589491117ac2781bb18f55988a8084",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 4.15,
      "commitsBetweenForRepo": 30,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   private static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n       Configuration conf, Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass,\n       Class\u003cT\u003e xface, URI nameNodeUri) throws IOException {\n     Preconditions.checkArgument(\n         xface.isAssignableFrom(NamenodeProtocols.class),\n         \"Interface %s is not a NameNode protocol\", xface);\n     try {\n       Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n           .getConstructor(Configuration.class, URI.class, Class.class);\n-      FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n+      FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n           xface);\n-      return (FailoverProxyProvider\u003cT\u003e) provider;\n+      return provider;\n     } catch (Exception e) {\n       String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(message, e);\n       }\n       if (e.getCause() instanceof IOException) {\n         throw (IOException) e.getCause();\n       } else {\n         throw new IOException(message, e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass,\n      Class\u003cT\u003e xface, URI nameNodeUri) throws IOException {\n    Preconditions.checkArgument(\n        xface.isAssignableFrom(NamenodeProtocols.class),\n        \"Interface %s is not a NameNode protocol\", xface);\n    try {\n      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Configuration.class, URI.class, Class.class);\n      FailoverProxyProvider\u003cT\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n          xface);\n      return provider;\n    } catch (Exception e) {\n      String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(message, e);\n      }\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(message, e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "c69dfdd5e14af490790dff8227b11962ec816577": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-2958. Sweep for remaining proxy construction which doesn\u0027t go through failover path.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1294811 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/02/12 12:09 PM",
      "commitName": "c69dfdd5e14af490790dff8227b11962ec816577",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "28/02/12 10:38 AM",
      "commitNameOld": "1ab31b1715e9db498847725dadfb82b16f71143b",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.06,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass,\n      Class\u003cT\u003e xface, URI nameNodeUri) throws IOException {\n    Preconditions.checkArgument(\n        xface.isAssignableFrom(NamenodeProtocols.class),\n        \"Interface %s is not a NameNode protocol\", xface);\n    try {\n      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Configuration.class, URI.class, Class.class);\n      FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n          xface);\n      return (FailoverProxyProvider\u003cT\u003e) provider;\n    } catch (Exception e) {\n      String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(message, e);\n      }\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(message, e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
        "oldMethodName": "createFailoverProxyProvider",
        "newMethodName": "createFailoverProxyProvider"
      }
    },
    "481f84597bf842df45b068cc24c328112e8bcf40": {
      "type": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-2904. Client support for getting delegation tokens. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1293486 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/02/12 4:03 PM",
      "commitName": "481f84597bf842df45b068cc24c328112e8bcf40",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2904. Client support for getting delegation tokens. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1293486 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/02/12 4:03 PM",
          "commitName": "481f84597bf842df45b068cc24c328112e8bcf40",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "06/02/12 12:21 AM",
          "commitNameOld": "c17b4f8eefe5b77b77761a0bb46b49cd1ea6965d",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 18.65,
          "commitsBetweenForRepo": 159,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,24 @@\n-  public static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n-      Configuration conf, Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass,\n-      Class xface, URI nameNodeUri) throws IOException {\n+  private static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n+      Configuration conf, Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass,\n+      Class\u003cT\u003e xface, URI nameNodeUri) throws IOException {\n     Preconditions.checkArgument(\n         xface.isAssignableFrom(NamenodeProtocols.class),\n         \"Interface %s is not a NameNode protocol\", xface);\n     try {\n-      Constructor\u003cFailoverProxyProvider\u003c?\u003e\u003e ctor \u003d failoverProxyProviderClass\n+      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n           .getConstructor(Configuration.class, URI.class, Class.class);\n       FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n           xface);\n       return (FailoverProxyProvider\u003cT\u003e) provider;\n     } catch (Exception e) {\n       String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(message, e);\n       }\n       if (e.getCause() instanceof IOException) {\n         throw (IOException) e.getCause();\n       } else {\n         throw new IOException(message, e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass,\n      Class\u003cT\u003e xface, URI nameNodeUri) throws IOException {\n    Preconditions.checkArgument(\n        xface.isAssignableFrom(NamenodeProtocols.class),\n        \"Interface %s is not a NameNode protocol\", xface);\n    try {\n      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Configuration.class, URI.class, Class.class);\n      FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n          xface);\n      return (FailoverProxyProvider\u003cT\u003e) provider;\n    } catch (Exception e) {\n      String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(message, e);\n      }\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(message, e);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
          "extendedDetails": {
            "oldValue": "[conf-Configuration, failoverProxyProviderClass-Class\u003cFailoverProxyProvider\u003c?\u003e\u003e, xface-Class, nameNodeUri-URI]",
            "newValue": "[conf-Configuration, failoverProxyProviderClass-Class\u003cFailoverProxyProvider\u003cT\u003e\u003e, xface-Class\u003cT\u003e, nameNodeUri-URI]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-2904. Client support for getting delegation tokens. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1293486 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/02/12 4:03 PM",
          "commitName": "481f84597bf842df45b068cc24c328112e8bcf40",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "06/02/12 12:21 AM",
          "commitNameOld": "c17b4f8eefe5b77b77761a0bb46b49cd1ea6965d",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 18.65,
          "commitsBetweenForRepo": 159,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,24 @@\n-  public static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n-      Configuration conf, Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass,\n-      Class xface, URI nameNodeUri) throws IOException {\n+  private static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n+      Configuration conf, Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass,\n+      Class\u003cT\u003e xface, URI nameNodeUri) throws IOException {\n     Preconditions.checkArgument(\n         xface.isAssignableFrom(NamenodeProtocols.class),\n         \"Interface %s is not a NameNode protocol\", xface);\n     try {\n-      Constructor\u003cFailoverProxyProvider\u003c?\u003e\u003e ctor \u003d failoverProxyProviderClass\n+      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n           .getConstructor(Configuration.class, URI.class, Class.class);\n       FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n           xface);\n       return (FailoverProxyProvider\u003cT\u003e) provider;\n     } catch (Exception e) {\n       String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(message, e);\n       }\n       if (e.getCause() instanceof IOException) {\n         throw (IOException) e.getCause();\n       } else {\n         throw new IOException(message, e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass,\n      Class\u003cT\u003e xface, URI nameNodeUri) throws IOException {\n    Preconditions.checkArgument(\n        xface.isAssignableFrom(NamenodeProtocols.class),\n        \"Interface %s is not a NameNode protocol\", xface);\n    try {\n      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Configuration.class, URI.class, Class.class);\n      FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n          xface);\n      return (FailoverProxyProvider\u003cT\u003e) provider;\n    } catch (Exception e) {\n      String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(message, e);\n      }\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(message, e);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
          "extendedDetails": {
            "oldValue": "[public, static]",
            "newValue": "[private, static]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2904. Client support for getting delegation tokens. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1293486 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "24/02/12 4:03 PM",
          "commitName": "481f84597bf842df45b068cc24c328112e8bcf40",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "06/02/12 12:21 AM",
          "commitNameOld": "c17b4f8eefe5b77b77761a0bb46b49cd1ea6965d",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 18.65,
          "commitsBetweenForRepo": 159,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,24 @@\n-  public static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n-      Configuration conf, Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass,\n-      Class xface, URI nameNodeUri) throws IOException {\n+  private static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n+      Configuration conf, Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass,\n+      Class\u003cT\u003e xface, URI nameNodeUri) throws IOException {\n     Preconditions.checkArgument(\n         xface.isAssignableFrom(NamenodeProtocols.class),\n         \"Interface %s is not a NameNode protocol\", xface);\n     try {\n-      Constructor\u003cFailoverProxyProvider\u003c?\u003e\u003e ctor \u003d failoverProxyProviderClass\n+      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n           .getConstructor(Configuration.class, URI.class, Class.class);\n       FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n           xface);\n       return (FailoverProxyProvider\u003cT\u003e) provider;\n     } catch (Exception e) {\n       String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(message, e);\n       }\n       if (e.getCause() instanceof IOException) {\n         throw (IOException) e.getCause();\n       } else {\n         throw new IOException(message, e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass,\n      Class\u003cT\u003e xface, URI nameNodeUri) throws IOException {\n    Preconditions.checkArgument(\n        xface.isAssignableFrom(NamenodeProtocols.class),\n        \"Interface %s is not a NameNode protocol\", xface);\n    try {\n      Constructor\u003cFailoverProxyProvider\u003cT\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Configuration.class, URI.class, Class.class);\n      FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n          xface);\n      return (FailoverProxyProvider\u003cT\u003e) provider;\n    } catch (Exception e) {\n      String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(message, e);\n      }\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(message, e);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
          "extendedDetails": {}
        }
      ]
    },
    "6122357da51bc447391a464a8f7b4de1bae2d8cf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2841. HAAdmin does not work if security is enabled. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1237534 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/01/12 6:52 PM",
      "commitName": "6122357da51bc447391a464a8f7b4de1bae2d8cf",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "20/01/12 7:17 PM",
      "commitNameOld": "c3e62de9ce952aa8572b3cae6a8497b8fdef40aa",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 8.98,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,24 @@\n   public static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n       Configuration conf, Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass,\n       Class xface, URI nameNodeUri) throws IOException {\n     Preconditions.checkArgument(\n         xface.isAssignableFrom(NamenodeProtocols.class),\n         \"Interface %s is not a NameNode protocol\", xface);\n     try {\n       Constructor\u003cFailoverProxyProvider\u003c?\u003e\u003e ctor \u003d failoverProxyProviderClass\n           .getConstructor(Configuration.class, URI.class, Class.class);\n       FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n           xface);\n       return (FailoverProxyProvider\u003cT\u003e) provider;\n     } catch (Exception e) {\n+      String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(message, e);\n+      }\n       if (e.getCause() instanceof IOException) {\n         throw (IOException) e.getCause();\n       } else {\n-        throw new IOException(\n-            \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass, e);\n+        throw new IOException(message, e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass,\n      Class xface, URI nameNodeUri) throws IOException {\n    Preconditions.checkArgument(\n        xface.isAssignableFrom(NamenodeProtocols.class),\n        \"Interface %s is not a NameNode protocol\", xface);\n    try {\n      Constructor\u003cFailoverProxyProvider\u003c?\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Configuration.class, URI.class, Class.class);\n      FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n          xface);\n      return (FailoverProxyProvider\u003cT\u003e) provider;\n    } catch (Exception e) {\n      String message \u003d \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(message, e);\n      }\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(message, e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
      "extendedDetails": {}
    },
    "02919e61f6935813bc3dbe23cc89e00e0cb02918": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-2367. Enable the configuration of multiple HA cluster addresses. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1233549 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/01/12 11:41 AM",
      "commitName": "02919e61f6935813bc3dbe23cc89e00e0cb02918",
      "commitAuthor": "Aaron Myers",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2367. Enable the configuration of multiple HA cluster addresses. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1233549 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "19/01/12 11:41 AM",
          "commitName": "02919e61f6935813bc3dbe23cc89e00e0cb02918",
          "commitAuthor": "Aaron Myers",
          "commitDateOld": "16/01/12 7:10 PM",
          "commitNameOld": "212678f036f4f96493bc14a584e758f97cf65573",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 2.69,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,21 @@\n   public static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n       Configuration conf, Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass,\n-      Class xface) throws IOException {\n+      Class xface, URI nameNodeUri) throws IOException {\n     Preconditions.checkArgument(\n         xface.isAssignableFrom(NamenodeProtocols.class),\n         \"Interface %s is not a NameNode protocol\", xface);\n     try {\n       Constructor\u003cFailoverProxyProvider\u003c?\u003e\u003e ctor \u003d failoverProxyProviderClass\n-          .getConstructor(Class.class);\n-      FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(xface);\n-      ReflectionUtils.setConf(provider, conf);\n+          .getConstructor(Configuration.class, URI.class, Class.class);\n+      FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n+          xface);\n       return (FailoverProxyProvider\u003cT\u003e) provider;\n     } catch (Exception e) {\n       if (e.getCause() instanceof IOException) {\n         throw (IOException) e.getCause();\n       } else {\n         throw new IOException(\n             \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass, e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass,\n      Class xface, URI nameNodeUri) throws IOException {\n    Preconditions.checkArgument(\n        xface.isAssignableFrom(NamenodeProtocols.class),\n        \"Interface %s is not a NameNode protocol\", xface);\n    try {\n      Constructor\u003cFailoverProxyProvider\u003c?\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Configuration.class, URI.class, Class.class);\n      FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n          xface);\n      return (FailoverProxyProvider\u003cT\u003e) provider;\n    } catch (Exception e) {\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(\n            \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass, e);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
          "extendedDetails": {
            "oldValue": "[conf-Configuration, failoverProxyProviderClass-Class\u003cFailoverProxyProvider\u003c?\u003e\u003e, xface-Class]",
            "newValue": "[conf-Configuration, failoverProxyProviderClass-Class\u003cFailoverProxyProvider\u003c?\u003e\u003e, xface-Class, nameNodeUri-URI]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2367. Enable the configuration of multiple HA cluster addresses. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1233549 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "19/01/12 11:41 AM",
          "commitName": "02919e61f6935813bc3dbe23cc89e00e0cb02918",
          "commitAuthor": "Aaron Myers",
          "commitDateOld": "16/01/12 7:10 PM",
          "commitNameOld": "212678f036f4f96493bc14a584e758f97cf65573",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 2.69,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,21 @@\n   public static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n       Configuration conf, Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass,\n-      Class xface) throws IOException {\n+      Class xface, URI nameNodeUri) throws IOException {\n     Preconditions.checkArgument(\n         xface.isAssignableFrom(NamenodeProtocols.class),\n         \"Interface %s is not a NameNode protocol\", xface);\n     try {\n       Constructor\u003cFailoverProxyProvider\u003c?\u003e\u003e ctor \u003d failoverProxyProviderClass\n-          .getConstructor(Class.class);\n-      FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(xface);\n-      ReflectionUtils.setConf(provider, conf);\n+          .getConstructor(Configuration.class, URI.class, Class.class);\n+      FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n+          xface);\n       return (FailoverProxyProvider\u003cT\u003e) provider;\n     } catch (Exception e) {\n       if (e.getCause() instanceof IOException) {\n         throw (IOException) e.getCause();\n       } else {\n         throw new IOException(\n             \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass, e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass,\n      Class xface, URI nameNodeUri) throws IOException {\n    Preconditions.checkArgument(\n        xface.isAssignableFrom(NamenodeProtocols.class),\n        \"Interface %s is not a NameNode protocol\", xface);\n    try {\n      Constructor\u003cFailoverProxyProvider\u003c?\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Configuration.class, URI.class, Class.class);\n      FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(conf, nameNodeUri,\n          xface);\n      return (FailoverProxyProvider\u003cT\u003e) provider;\n    } catch (Exception e) {\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(\n            \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass, e);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
          "extendedDetails": {}
        }
      ]
    },
    "212678f036f4f96493bc14a584e758f97cf65573": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2767. ConfiguredFailoverProxyProvider should support NameNodeProtocol. Contributed by Uma Maheswara Rao G.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1232284 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/01/12 7:10 PM",
      "commitName": "212678f036f4f96493bc14a584e758f97cf65573",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,21 @@\n+  public static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n+      Configuration conf, Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass,\n+      Class xface) throws IOException {\n+    Preconditions.checkArgument(\n+        xface.isAssignableFrom(NamenodeProtocols.class),\n+        \"Interface %s is not a NameNode protocol\", xface);\n+    try {\n+      Constructor\u003cFailoverProxyProvider\u003c?\u003e\u003e ctor \u003d failoverProxyProviderClass\n+          .getConstructor(Class.class);\n+      FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(xface);\n+      ReflectionUtils.setConf(provider, conf);\n+      return (FailoverProxyProvider\u003cT\u003e) provider;\n+    } catch (Exception e) {\n+      if (e.getCause() instanceof IOException) {\n+        throw (IOException) e.getCause();\n+      } else {\n+        throw new IOException(\n+            \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass, e);\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e FailoverProxyProvider\u003cT\u003e createFailoverProxyProvider(\n      Configuration conf, Class\u003cFailoverProxyProvider\u003c?\u003e\u003e failoverProxyProviderClass,\n      Class xface) throws IOException {\n    Preconditions.checkArgument(\n        xface.isAssignableFrom(NamenodeProtocols.class),\n        \"Interface %s is not a NameNode protocol\", xface);\n    try {\n      Constructor\u003cFailoverProxyProvider\u003c?\u003e\u003e ctor \u003d failoverProxyProviderClass\n          .getConstructor(Class.class);\n      FailoverProxyProvider\u003c?\u003e provider \u003d ctor.newInstance(xface);\n      ReflectionUtils.setConf(provider, conf);\n      return (FailoverProxyProvider\u003cT\u003e) provider;\n    } catch (Exception e) {\n      if (e.getCause() instanceof IOException) {\n        throw (IOException) e.getCause();\n      } else {\n        throw new IOException(\n            \"Couldn\u0027t create proxy provider \" + failoverProxyProviderClass, e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java"
    }
  }
}