{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Fetcher.java",
  "functionName": "copyMapOutput",
  "functionId": "copyMapOutput___host-MapHost__input-DataInputStream__remaining-Set__TaskAttemptID____canRetry-boolean",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
  "functionStartLine": 487,
  "functionEndLine": 602,
  "numCommitsSeen": 59,
  "timeTaken": 7227,
  "changeHistory": [
    "1fec06e037d2b22dafc64f33d4f1231bef4ceba8",
    "bc1bd7e5c4047b374420683d36a8c30eda6d75b6",
    "b9edad64034a9c8a121ec2b37792c190ba561e26",
    "2c3da25fd718b3a9c1ed67f05b577975ae613f4e",
    "95986dd2fb4527c43fa4c088c61fb7b4bd794d23",
    "b9b2647ebc7ae2c513a7be58ba16c9232a845fb4",
    "523d3daac0db8cfcbcfba67f3bbdc4eaf61b136f",
    "73fd247c7649919350ecfd16806af57ffe554649",
    "d87b545165f9442f614665521ce04424af1490e8",
    "d45922de2c5645e11339b94e4c31935ead66fefc",
    "8e69f883a0ac407781fa09328d9fb87faf5a8d0a",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "1fec06e037d2b22dafc64f33d4f1231bef4ceba8": "Ybodychange",
    "bc1bd7e5c4047b374420683d36a8c30eda6d75b6": "Ybodychange",
    "b9edad64034a9c8a121ec2b37792c190ba561e26": "Ybodychange",
    "2c3da25fd718b3a9c1ed67f05b577975ae613f4e": "Ymultichange(Yparameterchange,Yexceptionschange,Ybodychange)",
    "95986dd2fb4527c43fa4c088c61fb7b4bd794d23": "Ybodychange",
    "b9b2647ebc7ae2c513a7be58ba16c9232a845fb4": "Ybodychange",
    "523d3daac0db8cfcbcfba67f3bbdc4eaf61b136f": "Ybodychange",
    "73fd247c7649919350ecfd16806af57ffe554649": "Ybodychange",
    "d87b545165f9442f614665521ce04424af1490e8": "Ymultichange(Yreturntypechange,Ybodychange)",
    "d45922de2c5645e11339b94e4c31935ead66fefc": "Ymultichange(Yreturntypechange,Ybodychange)",
    "8e69f883a0ac407781fa09328d9fb87faf5a8d0a": "Ymultichange(Yreturntypechange,Ybodychange)",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1fec06e037d2b22dafc64f33d4f1231bef4ceba8": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6633. AM should retry map attempts if the reduce task encounters commpression related errors. Contributed by Rushabh Shah\n",
      "commitDate": "09/04/16 9:51 AM",
      "commitName": "1fec06e037d2b22dafc64f33d4f1231bef4ceba8",
      "commitAuthor": "Eric Payne",
      "commitDateOld": "24/06/15 8:29 AM",
      "commitNameOld": "72d08a0e41efda635baa985d55d67cb059a7c07c",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 290.06,
      "commitsBetweenForRepo": 1926,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,116 +1,116 @@\n   private TaskAttemptID[] copyMapOutput(MapHost host,\n                                 DataInputStream input,\n                                 Set\u003cTaskAttemptID\u003e remaining,\n                                 boolean canRetry) throws IOException {\n     MapOutput\u003cK,V\u003e mapOutput \u003d null;\n     TaskAttemptID mapId \u003d null;\n     long decompressedLength \u003d -1;\n     long compressedLength \u003d -1;\n     \n     try {\n       long startTime \u003d Time.monotonicNow();\n       int forReduce \u003d -1;\n       //Read the shuffle header\n       try {\n         ShuffleHeader header \u003d new ShuffleHeader();\n         header.readFields(input);\n         mapId \u003d TaskAttemptID.forName(header.mapId);\n         compressedLength \u003d header.compressedLength;\n         decompressedLength \u003d header.uncompressedLength;\n         forReduce \u003d header.forReduce;\n       } catch (IllegalArgumentException e) {\n         badIdErrs.increment(1);\n         LOG.warn(\"Invalid map id \", e);\n         //Don\u0027t know which one was bad, so consider all of them as bad\n         return remaining.toArray(new TaskAttemptID[remaining.size()]);\n       }\n \n       InputStream is \u003d input;\n       is \u003d CryptoUtils.wrapIfNecessary(jobConf, is, compressedLength);\n       compressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n       decompressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n       \n       // Do some basic sanity verification\n       if (!verifySanity(compressedLength, decompressedLength, forReduce,\n           remaining, mapId)) {\n         return new TaskAttemptID[] {mapId};\n       }\n       \n       if(LOG.isDebugEnabled()) {\n         LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n             \", decomp len: \" + decompressedLength);\n       }\n       \n       // Get the location for the map output - either in-memory or on-disk\n       try {\n         mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n       } catch (IOException ioe) {\n         // kill this reduce attempt\n         ioErrs.increment(1);\n         scheduler.reportLocalError(ioe);\n         return EMPTY_ATTEMPT_ID_ARRAY;\n       }\n       \n       // Check if we can shuffle *now* ...\n       if (mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n         //Not an error but wait to process data.\n         return EMPTY_ATTEMPT_ID_ARRAY;\n       } \n       \n       // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n       // on decompression failures. Catching and re-throwing as IOException\n       // to allow fetch failure logic to be processed\n       try {\n         // Go!\n         LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n             + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n             + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n         mapOutput.shuffle(host, is, compressedLength, decompressedLength,\n             metrics, reporter);\n-      } catch (java.lang.InternalError e) {\n+      } catch (java.lang.InternalError | Exception e) {\n         LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n         throw new IOException(e);\n       }\n       \n       // Inform the shuffle scheduler\n       long endTime \u003d Time.monotonicNow();\n       // Reset retryStartTime as map task make progress if retried before.\n       retryStartTime \u003d 0;\n       \n       scheduler.copySucceeded(mapId, host, compressedLength, \n                               startTime, endTime, mapOutput);\n       // Note successful shuffle\n       remaining.remove(mapId);\n       metrics.successFetch();\n       return null;\n     } catch (IOException ioe) {\n       if (mapOutput !\u003d null) {\n         mapOutput.abort();\n       }\n \n       if (canRetry) {\n         checkTimeoutOrRetry(host, ioe);\n       } \n       \n       ioErrs.increment(1);\n       if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n         LOG.warn(\"fetcher#\" + id + \" failed to read map header\" + \n                  mapId + \" decomp: \" + \n                  decompressedLength + \", \" + compressedLength, ioe);\n         if(mapId \u003d\u003d null) {\n           return remaining.toArray(new TaskAttemptID[remaining.size()]);\n         } else {\n           return new TaskAttemptID[] {mapId};\n         }\n       }\n         \n       LOG.warn(\"Failed to shuffle output of \" + mapId + \n                \" from \" + host.getHostName(), ioe); \n \n       // Inform the shuffle-scheduler\n       metrics.failedFetch();\n       return new TaskAttemptID[] {mapId};\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining,\n                                boolean canRetry) throws IOException {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d Time.monotonicNow();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        //Don\u0027t know which one was bad, so consider all of them as bad\n        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n      }\n\n      InputStream is \u003d input;\n      is \u003d CryptoUtils.wrapIfNecessary(jobConf, is, compressedLength);\n      compressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n      decompressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n      \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return new TaskAttemptID[] {mapId};\n      }\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n            \", decomp len: \" + decompressedLength);\n      }\n      \n      // Get the location for the map output - either in-memory or on-disk\n      try {\n        mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      } catch (IOException ioe) {\n        // kill this reduce attempt\n        ioErrs.increment(1);\n        scheduler.reportLocalError(ioe);\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      }\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n        //Not an error but wait to process data.\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      } \n      \n      // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n      // on decompression failures. Catching and re-throwing as IOException\n      // to allow fetch failure logic to be processed\n      try {\n        // Go!\n        LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n            + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n            + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n        mapOutput.shuffle(host, is, compressedLength, decompressedLength,\n            metrics, reporter);\n      } catch (java.lang.InternalError | Exception e) {\n        LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n        throw new IOException(e);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d Time.monotonicNow();\n      // Reset retryStartTime as map task make progress if retried before.\n      retryStartTime \u003d 0;\n      \n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              startTime, endTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return null;\n    } catch (IOException ioe) {\n      if (mapOutput !\u003d null) {\n        mapOutput.abort();\n      }\n\n      if (canRetry) {\n        checkTimeoutOrRetry(host, ioe);\n      } \n      \n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.warn(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        if(mapId \u003d\u003d null) {\n          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n        } else {\n          return new TaskAttemptID[] {mapId};\n        }\n      }\n        \n      LOG.warn(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      metrics.failedFetch();\n      return new TaskAttemptID[] {mapId};\n    }\n\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
      "extendedDetails": {}
    },
    "bc1bd7e5c4047b374420683d36a8c30eda6d75b6": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6334. Fetcher#copyMapOutput is leaking usedMemory upon IOException during InMemoryMapOutput shuffle handler. Contributed by Eric Payne\n",
      "commitDate": "28/04/15 1:19 PM",
      "commitName": "bc1bd7e5c4047b374420683d36a8c30eda6d75b6",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "02/04/15 12:13 PM",
      "commitNameOld": "eccb7d46efbf07abcc6a01bd5e7d682f6815b824",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 26.05,
      "commitsBetweenForRepo": 217,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,114 +1,116 @@\n   private TaskAttemptID[] copyMapOutput(MapHost host,\n                                 DataInputStream input,\n                                 Set\u003cTaskAttemptID\u003e remaining,\n                                 boolean canRetry) throws IOException {\n     MapOutput\u003cK,V\u003e mapOutput \u003d null;\n     TaskAttemptID mapId \u003d null;\n     long decompressedLength \u003d -1;\n     long compressedLength \u003d -1;\n     \n     try {\n       long startTime \u003d Time.monotonicNow();\n       int forReduce \u003d -1;\n       //Read the shuffle header\n       try {\n         ShuffleHeader header \u003d new ShuffleHeader();\n         header.readFields(input);\n         mapId \u003d TaskAttemptID.forName(header.mapId);\n         compressedLength \u003d header.compressedLength;\n         decompressedLength \u003d header.uncompressedLength;\n         forReduce \u003d header.forReduce;\n       } catch (IllegalArgumentException e) {\n         badIdErrs.increment(1);\n         LOG.warn(\"Invalid map id \", e);\n         //Don\u0027t know which one was bad, so consider all of them as bad\n         return remaining.toArray(new TaskAttemptID[remaining.size()]);\n       }\n \n       InputStream is \u003d input;\n       is \u003d CryptoUtils.wrapIfNecessary(jobConf, is, compressedLength);\n       compressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n       decompressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n       \n       // Do some basic sanity verification\n       if (!verifySanity(compressedLength, decompressedLength, forReduce,\n           remaining, mapId)) {\n         return new TaskAttemptID[] {mapId};\n       }\n       \n       if(LOG.isDebugEnabled()) {\n         LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n             \", decomp len: \" + decompressedLength);\n       }\n       \n       // Get the location for the map output - either in-memory or on-disk\n       try {\n         mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n       } catch (IOException ioe) {\n         // kill this reduce attempt\n         ioErrs.increment(1);\n         scheduler.reportLocalError(ioe);\n         return EMPTY_ATTEMPT_ID_ARRAY;\n       }\n       \n       // Check if we can shuffle *now* ...\n       if (mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n         //Not an error but wait to process data.\n         return EMPTY_ATTEMPT_ID_ARRAY;\n       } \n       \n       // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n       // on decompression failures. Catching and re-throwing as IOException\n       // to allow fetch failure logic to be processed\n       try {\n         // Go!\n         LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n             + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n             + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n         mapOutput.shuffle(host, is, compressedLength, decompressedLength,\n             metrics, reporter);\n       } catch (java.lang.InternalError e) {\n         LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n         throw new IOException(e);\n       }\n       \n       // Inform the shuffle scheduler\n       long endTime \u003d Time.monotonicNow();\n       // Reset retryStartTime as map task make progress if retried before.\n       retryStartTime \u003d 0;\n       \n       scheduler.copySucceeded(mapId, host, compressedLength, \n                               startTime, endTime, mapOutput);\n       // Note successful shuffle\n       remaining.remove(mapId);\n       metrics.successFetch();\n       return null;\n     } catch (IOException ioe) {\n-      \n+      if (mapOutput !\u003d null) {\n+        mapOutput.abort();\n+      }\n+\n       if (canRetry) {\n         checkTimeoutOrRetry(host, ioe);\n       } \n       \n       ioErrs.increment(1);\n       if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n         LOG.warn(\"fetcher#\" + id + \" failed to read map header\" + \n                  mapId + \" decomp: \" + \n                  decompressedLength + \", \" + compressedLength, ioe);\n         if(mapId \u003d\u003d null) {\n           return remaining.toArray(new TaskAttemptID[remaining.size()]);\n         } else {\n           return new TaskAttemptID[] {mapId};\n         }\n       }\n         \n       LOG.warn(\"Failed to shuffle output of \" + mapId + \n                \" from \" + host.getHostName(), ioe); \n \n       // Inform the shuffle-scheduler\n-      mapOutput.abort();\n       metrics.failedFetch();\n       return new TaskAttemptID[] {mapId};\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining,\n                                boolean canRetry) throws IOException {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d Time.monotonicNow();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        //Don\u0027t know which one was bad, so consider all of them as bad\n        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n      }\n\n      InputStream is \u003d input;\n      is \u003d CryptoUtils.wrapIfNecessary(jobConf, is, compressedLength);\n      compressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n      decompressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n      \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return new TaskAttemptID[] {mapId};\n      }\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n            \", decomp len: \" + decompressedLength);\n      }\n      \n      // Get the location for the map output - either in-memory or on-disk\n      try {\n        mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      } catch (IOException ioe) {\n        // kill this reduce attempt\n        ioErrs.increment(1);\n        scheduler.reportLocalError(ioe);\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      }\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n        //Not an error but wait to process data.\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      } \n      \n      // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n      // on decompression failures. Catching and re-throwing as IOException\n      // to allow fetch failure logic to be processed\n      try {\n        // Go!\n        LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n            + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n            + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n        mapOutput.shuffle(host, is, compressedLength, decompressedLength,\n            metrics, reporter);\n      } catch (java.lang.InternalError e) {\n        LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n        throw new IOException(e);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d Time.monotonicNow();\n      // Reset retryStartTime as map task make progress if retried before.\n      retryStartTime \u003d 0;\n      \n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              startTime, endTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return null;\n    } catch (IOException ioe) {\n      if (mapOutput !\u003d null) {\n        mapOutput.abort();\n      }\n\n      if (canRetry) {\n        checkTimeoutOrRetry(host, ioe);\n      } \n      \n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.warn(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        if(mapId \u003d\u003d null) {\n          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n        } else {\n          return new TaskAttemptID[] {mapId};\n        }\n      }\n        \n      LOG.warn(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      metrics.failedFetch();\n      return new TaskAttemptID[] {mapId};\n    }\n\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
      "extendedDetails": {}
    },
    "b9edad64034a9c8a121ec2b37792c190ba561e26": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5873. Shuffle bandwidth computation includes time spent waiting for maps. Contributed by Siqi Li\n",
      "commitDate": "15/10/14 8:52 AM",
      "commitName": "b9edad64034a9c8a121ec2b37792c190ba561e26",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "18/09/14 3:00 PM",
      "commitNameOld": "2c3da25fd718b3a9c1ed67f05b577975ae613f4e",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 26.74,
      "commitsBetweenForRepo": 269,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,114 +1,114 @@\n   private TaskAttemptID[] copyMapOutput(MapHost host,\n                                 DataInputStream input,\n                                 Set\u003cTaskAttemptID\u003e remaining,\n                                 boolean canRetry) throws IOException {\n     MapOutput\u003cK,V\u003e mapOutput \u003d null;\n     TaskAttemptID mapId \u003d null;\n     long decompressedLength \u003d -1;\n     long compressedLength \u003d -1;\n     \n     try {\n       long startTime \u003d Time.monotonicNow();\n       int forReduce \u003d -1;\n       //Read the shuffle header\n       try {\n         ShuffleHeader header \u003d new ShuffleHeader();\n         header.readFields(input);\n         mapId \u003d TaskAttemptID.forName(header.mapId);\n         compressedLength \u003d header.compressedLength;\n         decompressedLength \u003d header.uncompressedLength;\n         forReduce \u003d header.forReduce;\n       } catch (IllegalArgumentException e) {\n         badIdErrs.increment(1);\n         LOG.warn(\"Invalid map id \", e);\n         //Don\u0027t know which one was bad, so consider all of them as bad\n         return remaining.toArray(new TaskAttemptID[remaining.size()]);\n       }\n \n       InputStream is \u003d input;\n       is \u003d CryptoUtils.wrapIfNecessary(jobConf, is, compressedLength);\n       compressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n       decompressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n       \n       // Do some basic sanity verification\n       if (!verifySanity(compressedLength, decompressedLength, forReduce,\n           remaining, mapId)) {\n         return new TaskAttemptID[] {mapId};\n       }\n       \n       if(LOG.isDebugEnabled()) {\n         LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n             \", decomp len: \" + decompressedLength);\n       }\n       \n       // Get the location for the map output - either in-memory or on-disk\n       try {\n         mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n       } catch (IOException ioe) {\n         // kill this reduce attempt\n         ioErrs.increment(1);\n         scheduler.reportLocalError(ioe);\n         return EMPTY_ATTEMPT_ID_ARRAY;\n       }\n       \n       // Check if we can shuffle *now* ...\n       if (mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n         //Not an error but wait to process data.\n         return EMPTY_ATTEMPT_ID_ARRAY;\n       } \n       \n       // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n       // on decompression failures. Catching and re-throwing as IOException\n       // to allow fetch failure logic to be processed\n       try {\n         // Go!\n         LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n             + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n             + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n         mapOutput.shuffle(host, is, compressedLength, decompressedLength,\n             metrics, reporter);\n       } catch (java.lang.InternalError e) {\n         LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n         throw new IOException(e);\n       }\n       \n       // Inform the shuffle scheduler\n       long endTime \u003d Time.monotonicNow();\n       // Reset retryStartTime as map task make progress if retried before.\n       retryStartTime \u003d 0;\n       \n       scheduler.copySucceeded(mapId, host, compressedLength, \n-                              endTime - startTime, mapOutput);\n+                              startTime, endTime, mapOutput);\n       // Note successful shuffle\n       remaining.remove(mapId);\n       metrics.successFetch();\n       return null;\n     } catch (IOException ioe) {\n       \n       if (canRetry) {\n         checkTimeoutOrRetry(host, ioe);\n       } \n       \n       ioErrs.increment(1);\n       if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n         LOG.warn(\"fetcher#\" + id + \" failed to read map header\" + \n                  mapId + \" decomp: \" + \n                  decompressedLength + \", \" + compressedLength, ioe);\n         if(mapId \u003d\u003d null) {\n           return remaining.toArray(new TaskAttemptID[remaining.size()]);\n         } else {\n           return new TaskAttemptID[] {mapId};\n         }\n       }\n         \n       LOG.warn(\"Failed to shuffle output of \" + mapId + \n                \" from \" + host.getHostName(), ioe); \n \n       // Inform the shuffle-scheduler\n       mapOutput.abort();\n       metrics.failedFetch();\n       return new TaskAttemptID[] {mapId};\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining,\n                                boolean canRetry) throws IOException {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d Time.monotonicNow();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        //Don\u0027t know which one was bad, so consider all of them as bad\n        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n      }\n\n      InputStream is \u003d input;\n      is \u003d CryptoUtils.wrapIfNecessary(jobConf, is, compressedLength);\n      compressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n      decompressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n      \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return new TaskAttemptID[] {mapId};\n      }\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n            \", decomp len: \" + decompressedLength);\n      }\n      \n      // Get the location for the map output - either in-memory or on-disk\n      try {\n        mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      } catch (IOException ioe) {\n        // kill this reduce attempt\n        ioErrs.increment(1);\n        scheduler.reportLocalError(ioe);\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      }\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n        //Not an error but wait to process data.\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      } \n      \n      // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n      // on decompression failures. Catching and re-throwing as IOException\n      // to allow fetch failure logic to be processed\n      try {\n        // Go!\n        LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n            + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n            + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n        mapOutput.shuffle(host, is, compressedLength, decompressedLength,\n            metrics, reporter);\n      } catch (java.lang.InternalError e) {\n        LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n        throw new IOException(e);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d Time.monotonicNow();\n      // Reset retryStartTime as map task make progress if retried before.\n      retryStartTime \u003d 0;\n      \n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              startTime, endTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return null;\n    } catch (IOException ioe) {\n      \n      if (canRetry) {\n        checkTimeoutOrRetry(host, ioe);\n      } \n      \n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.warn(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        if(mapId \u003d\u003d null) {\n          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n        } else {\n          return new TaskAttemptID[] {mapId};\n        }\n      }\n        \n      LOG.warn(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      mapOutput.abort();\n      metrics.failedFetch();\n      return new TaskAttemptID[] {mapId};\n    }\n\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
      "extendedDetails": {}
    },
    "2c3da25fd718b3a9c1ed67f05b577975ae613f4e": {
      "type": "Ymultichange(Yparameterchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "MAPREDUCE-5891. Improved shuffle error handling across NM restarts. Contributed by Junping Du\n",
      "commitDate": "18/09/14 3:00 PM",
      "commitName": "2c3da25fd718b3a9c1ed67f05b577975ae613f4e",
      "commitAuthor": "Jason Lowe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-5891. Improved shuffle error handling across NM restarts. Contributed by Junping Du\n",
          "commitDate": "18/09/14 3:00 PM",
          "commitName": "2c3da25fd718b3a9c1ed67f05b577975ae613f4e",
          "commitAuthor": "Jason Lowe",
          "commitDateOld": "18/08/14 11:41 AM",
          "commitNameOld": "0cc08f6da4d299141b19b07147e39caef050faf6",
          "commitAuthorOld": "",
          "daysBetweenCommits": 31.14,
          "commitsBetweenForRepo": 258,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,105 +1,114 @@\n   private TaskAttemptID[] copyMapOutput(MapHost host,\n                                 DataInputStream input,\n-                                Set\u003cTaskAttemptID\u003e remaining) {\n+                                Set\u003cTaskAttemptID\u003e remaining,\n+                                boolean canRetry) throws IOException {\n     MapOutput\u003cK,V\u003e mapOutput \u003d null;\n     TaskAttemptID mapId \u003d null;\n     long decompressedLength \u003d -1;\n     long compressedLength \u003d -1;\n     \n     try {\n-      long startTime \u003d System.currentTimeMillis();\n+      long startTime \u003d Time.monotonicNow();\n       int forReduce \u003d -1;\n       //Read the shuffle header\n       try {\n         ShuffleHeader header \u003d new ShuffleHeader();\n         header.readFields(input);\n         mapId \u003d TaskAttemptID.forName(header.mapId);\n         compressedLength \u003d header.compressedLength;\n         decompressedLength \u003d header.uncompressedLength;\n         forReduce \u003d header.forReduce;\n       } catch (IllegalArgumentException e) {\n         badIdErrs.increment(1);\n         LOG.warn(\"Invalid map id \", e);\n         //Don\u0027t know which one was bad, so consider all of them as bad\n         return remaining.toArray(new TaskAttemptID[remaining.size()]);\n       }\n \n       InputStream is \u003d input;\n       is \u003d CryptoUtils.wrapIfNecessary(jobConf, is, compressedLength);\n       compressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n       decompressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n       \n       // Do some basic sanity verification\n       if (!verifySanity(compressedLength, decompressedLength, forReduce,\n           remaining, mapId)) {\n         return new TaskAttemptID[] {mapId};\n       }\n       \n       if(LOG.isDebugEnabled()) {\n         LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n             \", decomp len: \" + decompressedLength);\n       }\n       \n       // Get the location for the map output - either in-memory or on-disk\n       try {\n         mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n       } catch (IOException ioe) {\n         // kill this reduce attempt\n         ioErrs.increment(1);\n         scheduler.reportLocalError(ioe);\n         return EMPTY_ATTEMPT_ID_ARRAY;\n       }\n       \n       // Check if we can shuffle *now* ...\n       if (mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n         //Not an error but wait to process data.\n         return EMPTY_ATTEMPT_ID_ARRAY;\n       } \n       \n       // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n       // on decompression failures. Catching and re-throwing as IOException\n       // to allow fetch failure logic to be processed\n       try {\n         // Go!\n         LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n             + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n             + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n         mapOutput.shuffle(host, is, compressedLength, decompressedLength,\n             metrics, reporter);\n       } catch (java.lang.InternalError e) {\n         LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n         throw new IOException(e);\n       }\n       \n       // Inform the shuffle scheduler\n-      long endTime \u003d System.currentTimeMillis();\n+      long endTime \u003d Time.monotonicNow();\n+      // Reset retryStartTime as map task make progress if retried before.\n+      retryStartTime \u003d 0;\n+      \n       scheduler.copySucceeded(mapId, host, compressedLength, \n                               endTime - startTime, mapOutput);\n       // Note successful shuffle\n       remaining.remove(mapId);\n       metrics.successFetch();\n       return null;\n     } catch (IOException ioe) {\n+      \n+      if (canRetry) {\n+        checkTimeoutOrRetry(host, ioe);\n+      } \n+      \n       ioErrs.increment(1);\n       if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n-        LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n+        LOG.warn(\"fetcher#\" + id + \" failed to read map header\" + \n                  mapId + \" decomp: \" + \n                  decompressedLength + \", \" + compressedLength, ioe);\n         if(mapId \u003d\u003d null) {\n           return remaining.toArray(new TaskAttemptID[remaining.size()]);\n         } else {\n           return new TaskAttemptID[] {mapId};\n         }\n       }\n-      \n+        \n       LOG.warn(\"Failed to shuffle output of \" + mapId + \n                \" from \" + host.getHostName(), ioe); \n \n       // Inform the shuffle-scheduler\n       mapOutput.abort();\n       metrics.failedFetch();\n       return new TaskAttemptID[] {mapId};\n     }\n \n   }\n\\ No newline at end of file\n",
          "actualSource": "  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining,\n                                boolean canRetry) throws IOException {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d Time.monotonicNow();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        //Don\u0027t know which one was bad, so consider all of them as bad\n        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n      }\n\n      InputStream is \u003d input;\n      is \u003d CryptoUtils.wrapIfNecessary(jobConf, is, compressedLength);\n      compressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n      decompressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n      \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return new TaskAttemptID[] {mapId};\n      }\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n            \", decomp len: \" + decompressedLength);\n      }\n      \n      // Get the location for the map output - either in-memory or on-disk\n      try {\n        mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      } catch (IOException ioe) {\n        // kill this reduce attempt\n        ioErrs.increment(1);\n        scheduler.reportLocalError(ioe);\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      }\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n        //Not an error but wait to process data.\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      } \n      \n      // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n      // on decompression failures. Catching and re-throwing as IOException\n      // to allow fetch failure logic to be processed\n      try {\n        // Go!\n        LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n            + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n            + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n        mapOutput.shuffle(host, is, compressedLength, decompressedLength,\n            metrics, reporter);\n      } catch (java.lang.InternalError e) {\n        LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n        throw new IOException(e);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d Time.monotonicNow();\n      // Reset retryStartTime as map task make progress if retried before.\n      retryStartTime \u003d 0;\n      \n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              endTime - startTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return null;\n    } catch (IOException ioe) {\n      \n      if (canRetry) {\n        checkTimeoutOrRetry(host, ioe);\n      } \n      \n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.warn(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        if(mapId \u003d\u003d null) {\n          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n        } else {\n          return new TaskAttemptID[] {mapId};\n        }\n      }\n        \n      LOG.warn(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      mapOutput.abort();\n      metrics.failedFetch();\n      return new TaskAttemptID[] {mapId};\n    }\n\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
          "extendedDetails": {
            "oldValue": "[host-MapHost, input-DataInputStream, remaining-Set\u003cTaskAttemptID\u003e]",
            "newValue": "[host-MapHost, input-DataInputStream, remaining-Set\u003cTaskAttemptID\u003e, canRetry-boolean]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "MAPREDUCE-5891. Improved shuffle error handling across NM restarts. Contributed by Junping Du\n",
          "commitDate": "18/09/14 3:00 PM",
          "commitName": "2c3da25fd718b3a9c1ed67f05b577975ae613f4e",
          "commitAuthor": "Jason Lowe",
          "commitDateOld": "18/08/14 11:41 AM",
          "commitNameOld": "0cc08f6da4d299141b19b07147e39caef050faf6",
          "commitAuthorOld": "",
          "daysBetweenCommits": 31.14,
          "commitsBetweenForRepo": 258,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,105 +1,114 @@\n   private TaskAttemptID[] copyMapOutput(MapHost host,\n                                 DataInputStream input,\n-                                Set\u003cTaskAttemptID\u003e remaining) {\n+                                Set\u003cTaskAttemptID\u003e remaining,\n+                                boolean canRetry) throws IOException {\n     MapOutput\u003cK,V\u003e mapOutput \u003d null;\n     TaskAttemptID mapId \u003d null;\n     long decompressedLength \u003d -1;\n     long compressedLength \u003d -1;\n     \n     try {\n-      long startTime \u003d System.currentTimeMillis();\n+      long startTime \u003d Time.monotonicNow();\n       int forReduce \u003d -1;\n       //Read the shuffle header\n       try {\n         ShuffleHeader header \u003d new ShuffleHeader();\n         header.readFields(input);\n         mapId \u003d TaskAttemptID.forName(header.mapId);\n         compressedLength \u003d header.compressedLength;\n         decompressedLength \u003d header.uncompressedLength;\n         forReduce \u003d header.forReduce;\n       } catch (IllegalArgumentException e) {\n         badIdErrs.increment(1);\n         LOG.warn(\"Invalid map id \", e);\n         //Don\u0027t know which one was bad, so consider all of them as bad\n         return remaining.toArray(new TaskAttemptID[remaining.size()]);\n       }\n \n       InputStream is \u003d input;\n       is \u003d CryptoUtils.wrapIfNecessary(jobConf, is, compressedLength);\n       compressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n       decompressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n       \n       // Do some basic sanity verification\n       if (!verifySanity(compressedLength, decompressedLength, forReduce,\n           remaining, mapId)) {\n         return new TaskAttemptID[] {mapId};\n       }\n       \n       if(LOG.isDebugEnabled()) {\n         LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n             \", decomp len: \" + decompressedLength);\n       }\n       \n       // Get the location for the map output - either in-memory or on-disk\n       try {\n         mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n       } catch (IOException ioe) {\n         // kill this reduce attempt\n         ioErrs.increment(1);\n         scheduler.reportLocalError(ioe);\n         return EMPTY_ATTEMPT_ID_ARRAY;\n       }\n       \n       // Check if we can shuffle *now* ...\n       if (mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n         //Not an error but wait to process data.\n         return EMPTY_ATTEMPT_ID_ARRAY;\n       } \n       \n       // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n       // on decompression failures. Catching and re-throwing as IOException\n       // to allow fetch failure logic to be processed\n       try {\n         // Go!\n         LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n             + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n             + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n         mapOutput.shuffle(host, is, compressedLength, decompressedLength,\n             metrics, reporter);\n       } catch (java.lang.InternalError e) {\n         LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n         throw new IOException(e);\n       }\n       \n       // Inform the shuffle scheduler\n-      long endTime \u003d System.currentTimeMillis();\n+      long endTime \u003d Time.monotonicNow();\n+      // Reset retryStartTime as map task make progress if retried before.\n+      retryStartTime \u003d 0;\n+      \n       scheduler.copySucceeded(mapId, host, compressedLength, \n                               endTime - startTime, mapOutput);\n       // Note successful shuffle\n       remaining.remove(mapId);\n       metrics.successFetch();\n       return null;\n     } catch (IOException ioe) {\n+      \n+      if (canRetry) {\n+        checkTimeoutOrRetry(host, ioe);\n+      } \n+      \n       ioErrs.increment(1);\n       if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n-        LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n+        LOG.warn(\"fetcher#\" + id + \" failed to read map header\" + \n                  mapId + \" decomp: \" + \n                  decompressedLength + \", \" + compressedLength, ioe);\n         if(mapId \u003d\u003d null) {\n           return remaining.toArray(new TaskAttemptID[remaining.size()]);\n         } else {\n           return new TaskAttemptID[] {mapId};\n         }\n       }\n-      \n+        \n       LOG.warn(\"Failed to shuffle output of \" + mapId + \n                \" from \" + host.getHostName(), ioe); \n \n       // Inform the shuffle-scheduler\n       mapOutput.abort();\n       metrics.failedFetch();\n       return new TaskAttemptID[] {mapId};\n     }\n \n   }\n\\ No newline at end of file\n",
          "actualSource": "  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining,\n                                boolean canRetry) throws IOException {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d Time.monotonicNow();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        //Don\u0027t know which one was bad, so consider all of them as bad\n        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n      }\n\n      InputStream is \u003d input;\n      is \u003d CryptoUtils.wrapIfNecessary(jobConf, is, compressedLength);\n      compressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n      decompressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n      \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return new TaskAttemptID[] {mapId};\n      }\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n            \", decomp len: \" + decompressedLength);\n      }\n      \n      // Get the location for the map output - either in-memory or on-disk\n      try {\n        mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      } catch (IOException ioe) {\n        // kill this reduce attempt\n        ioErrs.increment(1);\n        scheduler.reportLocalError(ioe);\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      }\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n        //Not an error but wait to process data.\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      } \n      \n      // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n      // on decompression failures. Catching and re-throwing as IOException\n      // to allow fetch failure logic to be processed\n      try {\n        // Go!\n        LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n            + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n            + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n        mapOutput.shuffle(host, is, compressedLength, decompressedLength,\n            metrics, reporter);\n      } catch (java.lang.InternalError e) {\n        LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n        throw new IOException(e);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d Time.monotonicNow();\n      // Reset retryStartTime as map task make progress if retried before.\n      retryStartTime \u003d 0;\n      \n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              endTime - startTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return null;\n    } catch (IOException ioe) {\n      \n      if (canRetry) {\n        checkTimeoutOrRetry(host, ioe);\n      } \n      \n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.warn(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        if(mapId \u003d\u003d null) {\n          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n        } else {\n          return new TaskAttemptID[] {mapId};\n        }\n      }\n        \n      LOG.warn(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      mapOutput.abort();\n      metrics.failedFetch();\n      return new TaskAttemptID[] {mapId};\n    }\n\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-5891. Improved shuffle error handling across NM restarts. Contributed by Junping Du\n",
          "commitDate": "18/09/14 3:00 PM",
          "commitName": "2c3da25fd718b3a9c1ed67f05b577975ae613f4e",
          "commitAuthor": "Jason Lowe",
          "commitDateOld": "18/08/14 11:41 AM",
          "commitNameOld": "0cc08f6da4d299141b19b07147e39caef050faf6",
          "commitAuthorOld": "",
          "daysBetweenCommits": 31.14,
          "commitsBetweenForRepo": 258,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,105 +1,114 @@\n   private TaskAttemptID[] copyMapOutput(MapHost host,\n                                 DataInputStream input,\n-                                Set\u003cTaskAttemptID\u003e remaining) {\n+                                Set\u003cTaskAttemptID\u003e remaining,\n+                                boolean canRetry) throws IOException {\n     MapOutput\u003cK,V\u003e mapOutput \u003d null;\n     TaskAttemptID mapId \u003d null;\n     long decompressedLength \u003d -1;\n     long compressedLength \u003d -1;\n     \n     try {\n-      long startTime \u003d System.currentTimeMillis();\n+      long startTime \u003d Time.monotonicNow();\n       int forReduce \u003d -1;\n       //Read the shuffle header\n       try {\n         ShuffleHeader header \u003d new ShuffleHeader();\n         header.readFields(input);\n         mapId \u003d TaskAttemptID.forName(header.mapId);\n         compressedLength \u003d header.compressedLength;\n         decompressedLength \u003d header.uncompressedLength;\n         forReduce \u003d header.forReduce;\n       } catch (IllegalArgumentException e) {\n         badIdErrs.increment(1);\n         LOG.warn(\"Invalid map id \", e);\n         //Don\u0027t know which one was bad, so consider all of them as bad\n         return remaining.toArray(new TaskAttemptID[remaining.size()]);\n       }\n \n       InputStream is \u003d input;\n       is \u003d CryptoUtils.wrapIfNecessary(jobConf, is, compressedLength);\n       compressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n       decompressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n       \n       // Do some basic sanity verification\n       if (!verifySanity(compressedLength, decompressedLength, forReduce,\n           remaining, mapId)) {\n         return new TaskAttemptID[] {mapId};\n       }\n       \n       if(LOG.isDebugEnabled()) {\n         LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n             \", decomp len: \" + decompressedLength);\n       }\n       \n       // Get the location for the map output - either in-memory or on-disk\n       try {\n         mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n       } catch (IOException ioe) {\n         // kill this reduce attempt\n         ioErrs.increment(1);\n         scheduler.reportLocalError(ioe);\n         return EMPTY_ATTEMPT_ID_ARRAY;\n       }\n       \n       // Check if we can shuffle *now* ...\n       if (mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n         //Not an error but wait to process data.\n         return EMPTY_ATTEMPT_ID_ARRAY;\n       } \n       \n       // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n       // on decompression failures. Catching and re-throwing as IOException\n       // to allow fetch failure logic to be processed\n       try {\n         // Go!\n         LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n             + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n             + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n         mapOutput.shuffle(host, is, compressedLength, decompressedLength,\n             metrics, reporter);\n       } catch (java.lang.InternalError e) {\n         LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n         throw new IOException(e);\n       }\n       \n       // Inform the shuffle scheduler\n-      long endTime \u003d System.currentTimeMillis();\n+      long endTime \u003d Time.monotonicNow();\n+      // Reset retryStartTime as map task make progress if retried before.\n+      retryStartTime \u003d 0;\n+      \n       scheduler.copySucceeded(mapId, host, compressedLength, \n                               endTime - startTime, mapOutput);\n       // Note successful shuffle\n       remaining.remove(mapId);\n       metrics.successFetch();\n       return null;\n     } catch (IOException ioe) {\n+      \n+      if (canRetry) {\n+        checkTimeoutOrRetry(host, ioe);\n+      } \n+      \n       ioErrs.increment(1);\n       if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n-        LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n+        LOG.warn(\"fetcher#\" + id + \" failed to read map header\" + \n                  mapId + \" decomp: \" + \n                  decompressedLength + \", \" + compressedLength, ioe);\n         if(mapId \u003d\u003d null) {\n           return remaining.toArray(new TaskAttemptID[remaining.size()]);\n         } else {\n           return new TaskAttemptID[] {mapId};\n         }\n       }\n-      \n+        \n       LOG.warn(\"Failed to shuffle output of \" + mapId + \n                \" from \" + host.getHostName(), ioe); \n \n       // Inform the shuffle-scheduler\n       mapOutput.abort();\n       metrics.failedFetch();\n       return new TaskAttemptID[] {mapId};\n     }\n \n   }\n\\ No newline at end of file\n",
          "actualSource": "  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining,\n                                boolean canRetry) throws IOException {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d Time.monotonicNow();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        //Don\u0027t know which one was bad, so consider all of them as bad\n        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n      }\n\n      InputStream is \u003d input;\n      is \u003d CryptoUtils.wrapIfNecessary(jobConf, is, compressedLength);\n      compressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n      decompressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n      \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return new TaskAttemptID[] {mapId};\n      }\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n            \", decomp len: \" + decompressedLength);\n      }\n      \n      // Get the location for the map output - either in-memory or on-disk\n      try {\n        mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      } catch (IOException ioe) {\n        // kill this reduce attempt\n        ioErrs.increment(1);\n        scheduler.reportLocalError(ioe);\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      }\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n        //Not an error but wait to process data.\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      } \n      \n      // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n      // on decompression failures. Catching and re-throwing as IOException\n      // to allow fetch failure logic to be processed\n      try {\n        // Go!\n        LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n            + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n            + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n        mapOutput.shuffle(host, is, compressedLength, decompressedLength,\n            metrics, reporter);\n      } catch (java.lang.InternalError e) {\n        LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n        throw new IOException(e);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d Time.monotonicNow();\n      // Reset retryStartTime as map task make progress if retried before.\n      retryStartTime \u003d 0;\n      \n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              endTime - startTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return null;\n    } catch (IOException ioe) {\n      \n      if (canRetry) {\n        checkTimeoutOrRetry(host, ioe);\n      } \n      \n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.warn(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        if(mapId \u003d\u003d null) {\n          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n        } else {\n          return new TaskAttemptID[] {mapId};\n        }\n      }\n        \n      LOG.warn(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      mapOutput.abort();\n      metrics.failedFetch();\n      return new TaskAttemptID[] {mapId};\n    }\n\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
          "extendedDetails": {}
        }
      ]
    },
    "95986dd2fb4527c43fa4c088c61fb7b4bd794d23": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5890. Support for encrypting Intermediate data and spills in local filesystem. (asuresh via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/fs-encryption@1609597 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/07/14 5:43 PM",
      "commitName": "95986dd2fb4527c43fa4c088c61fb7b4bd794d23",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "05/08/13 11:36 PM",
      "commitNameOld": "0cb2fdc3b4fbbaa6153b6421a63082dc006f8eb4",
      "commitAuthorOld": "Sanford Ryza",
      "daysBetweenCommits": 338.75,
      "commitsBetweenForRepo": 2256,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,101 +1,105 @@\n   private TaskAttemptID[] copyMapOutput(MapHost host,\n                                 DataInputStream input,\n                                 Set\u003cTaskAttemptID\u003e remaining) {\n     MapOutput\u003cK,V\u003e mapOutput \u003d null;\n     TaskAttemptID mapId \u003d null;\n     long decompressedLength \u003d -1;\n     long compressedLength \u003d -1;\n     \n     try {\n       long startTime \u003d System.currentTimeMillis();\n       int forReduce \u003d -1;\n       //Read the shuffle header\n       try {\n         ShuffleHeader header \u003d new ShuffleHeader();\n         header.readFields(input);\n         mapId \u003d TaskAttemptID.forName(header.mapId);\n         compressedLength \u003d header.compressedLength;\n         decompressedLength \u003d header.uncompressedLength;\n         forReduce \u003d header.forReduce;\n       } catch (IllegalArgumentException e) {\n         badIdErrs.increment(1);\n         LOG.warn(\"Invalid map id \", e);\n         //Don\u0027t know which one was bad, so consider all of them as bad\n         return remaining.toArray(new TaskAttemptID[remaining.size()]);\n       }\n \n- \n+      InputStream is \u003d input;\n+      is \u003d CryptoUtils.wrapIfNecessary(jobConf, is, compressedLength);\n+      compressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n+      decompressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n+      \n       // Do some basic sanity verification\n       if (!verifySanity(compressedLength, decompressedLength, forReduce,\n           remaining, mapId)) {\n         return new TaskAttemptID[] {mapId};\n       }\n       \n       if(LOG.isDebugEnabled()) {\n         LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n             \", decomp len: \" + decompressedLength);\n       }\n       \n       // Get the location for the map output - either in-memory or on-disk\n       try {\n         mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n       } catch (IOException ioe) {\n         // kill this reduce attempt\n         ioErrs.increment(1);\n         scheduler.reportLocalError(ioe);\n         return EMPTY_ATTEMPT_ID_ARRAY;\n       }\n       \n       // Check if we can shuffle *now* ...\n       if (mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n         //Not an error but wait to process data.\n         return EMPTY_ATTEMPT_ID_ARRAY;\n       } \n       \n       // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n       // on decompression failures. Catching and re-throwing as IOException\n       // to allow fetch failure logic to be processed\n       try {\n         // Go!\n         LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n             + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n             + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n-        mapOutput.shuffle(host, input, compressedLength, decompressedLength,\n+        mapOutput.shuffle(host, is, compressedLength, decompressedLength,\n             metrics, reporter);\n       } catch (java.lang.InternalError e) {\n         LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n         throw new IOException(e);\n       }\n       \n       // Inform the shuffle scheduler\n       long endTime \u003d System.currentTimeMillis();\n       scheduler.copySucceeded(mapId, host, compressedLength, \n                               endTime - startTime, mapOutput);\n       // Note successful shuffle\n       remaining.remove(mapId);\n       metrics.successFetch();\n       return null;\n     } catch (IOException ioe) {\n       ioErrs.increment(1);\n       if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                  mapId + \" decomp: \" + \n                  decompressedLength + \", \" + compressedLength, ioe);\n         if(mapId \u003d\u003d null) {\n           return remaining.toArray(new TaskAttemptID[remaining.size()]);\n         } else {\n           return new TaskAttemptID[] {mapId};\n         }\n       }\n       \n       LOG.warn(\"Failed to shuffle output of \" + mapId + \n                \" from \" + host.getHostName(), ioe); \n \n       // Inform the shuffle-scheduler\n       mapOutput.abort();\n       metrics.failedFetch();\n       return new TaskAttemptID[] {mapId};\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining) {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d System.currentTimeMillis();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        //Don\u0027t know which one was bad, so consider all of them as bad\n        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n      }\n\n      InputStream is \u003d input;\n      is \u003d CryptoUtils.wrapIfNecessary(jobConf, is, compressedLength);\n      compressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n      decompressedLength -\u003d CryptoUtils.cryptoPadding(jobConf);\n      \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return new TaskAttemptID[] {mapId};\n      }\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n            \", decomp len: \" + decompressedLength);\n      }\n      \n      // Get the location for the map output - either in-memory or on-disk\n      try {\n        mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      } catch (IOException ioe) {\n        // kill this reduce attempt\n        ioErrs.increment(1);\n        scheduler.reportLocalError(ioe);\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      }\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n        //Not an error but wait to process data.\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      } \n      \n      // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n      // on decompression failures. Catching and re-throwing as IOException\n      // to allow fetch failure logic to be processed\n      try {\n        // Go!\n        LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n            + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n            + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n        mapOutput.shuffle(host, is, compressedLength, decompressedLength,\n            metrics, reporter);\n      } catch (java.lang.InternalError e) {\n        LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n        throw new IOException(e);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d System.currentTimeMillis();\n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              endTime - startTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return null;\n    } catch (IOException ioe) {\n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        if(mapId \u003d\u003d null) {\n          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n        } else {\n          return new TaskAttemptID[] {mapId};\n        }\n      }\n      \n      LOG.warn(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      mapOutput.abort();\n      metrics.failedFetch();\n      return new TaskAttemptID[] {mapId};\n    }\n\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
      "extendedDetails": {}
    },
    "b9b2647ebc7ae2c513a7be58ba16c9232a845fb4": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5251. Reducer should not implicate map attempt if it has insufficient space to fetch map output. Contributed by Ashwin Shankar\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1507104 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/07/13 12:38 PM",
      "commitName": "b9b2647ebc7ae2c513a7be58ba16c9232a845fb4",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "25/06/13 10:49 PM",
      "commitNameOld": "11bcd2ed12f7f0e02fdaefaefea56929b32d5ee6",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 29.58,
      "commitsBetweenForRepo": 151,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,101 @@\n   private TaskAttemptID[] copyMapOutput(MapHost host,\n                                 DataInputStream input,\n                                 Set\u003cTaskAttemptID\u003e remaining) {\n     MapOutput\u003cK,V\u003e mapOutput \u003d null;\n     TaskAttemptID mapId \u003d null;\n     long decompressedLength \u003d -1;\n     long compressedLength \u003d -1;\n     \n     try {\n       long startTime \u003d System.currentTimeMillis();\n       int forReduce \u003d -1;\n       //Read the shuffle header\n       try {\n         ShuffleHeader header \u003d new ShuffleHeader();\n         header.readFields(input);\n         mapId \u003d TaskAttemptID.forName(header.mapId);\n         compressedLength \u003d header.compressedLength;\n         decompressedLength \u003d header.uncompressedLength;\n         forReduce \u003d header.forReduce;\n       } catch (IllegalArgumentException e) {\n         badIdErrs.increment(1);\n         LOG.warn(\"Invalid map id \", e);\n         //Don\u0027t know which one was bad, so consider all of them as bad\n         return remaining.toArray(new TaskAttemptID[remaining.size()]);\n       }\n \n  \n       // Do some basic sanity verification\n       if (!verifySanity(compressedLength, decompressedLength, forReduce,\n           remaining, mapId)) {\n         return new TaskAttemptID[] {mapId};\n       }\n       \n       if(LOG.isDebugEnabled()) {\n         LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n             \", decomp len: \" + decompressedLength);\n       }\n       \n       // Get the location for the map output - either in-memory or on-disk\n-      mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n+      try {\n+        mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n+      } catch (IOException ioe) {\n+        // kill this reduce attempt\n+        ioErrs.increment(1);\n+        scheduler.reportLocalError(ioe);\n+        return EMPTY_ATTEMPT_ID_ARRAY;\n+      }\n       \n       // Check if we can shuffle *now* ...\n       if (mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n         //Not an error but wait to process data.\n         return EMPTY_ATTEMPT_ID_ARRAY;\n       } \n       \n       // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n       // on decompression failures. Catching and re-throwing as IOException\n       // to allow fetch failure logic to be processed\n       try {\n         // Go!\n         LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n             + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n             + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n         mapOutput.shuffle(host, input, compressedLength, decompressedLength,\n             metrics, reporter);\n       } catch (java.lang.InternalError e) {\n         LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n         throw new IOException(e);\n       }\n       \n       // Inform the shuffle scheduler\n       long endTime \u003d System.currentTimeMillis();\n       scheduler.copySucceeded(mapId, host, compressedLength, \n                               endTime - startTime, mapOutput);\n       // Note successful shuffle\n       remaining.remove(mapId);\n       metrics.successFetch();\n       return null;\n     } catch (IOException ioe) {\n       ioErrs.increment(1);\n       if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                  mapId + \" decomp: \" + \n                  decompressedLength + \", \" + compressedLength, ioe);\n         if(mapId \u003d\u003d null) {\n           return remaining.toArray(new TaskAttemptID[remaining.size()]);\n         } else {\n           return new TaskAttemptID[] {mapId};\n         }\n       }\n       \n       LOG.warn(\"Failed to shuffle output of \" + mapId + \n                \" from \" + host.getHostName(), ioe); \n \n       // Inform the shuffle-scheduler\n       mapOutput.abort();\n       metrics.failedFetch();\n       return new TaskAttemptID[] {mapId};\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining) {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d System.currentTimeMillis();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        //Don\u0027t know which one was bad, so consider all of them as bad\n        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n      }\n\n \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return new TaskAttemptID[] {mapId};\n      }\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n            \", decomp len: \" + decompressedLength);\n      }\n      \n      // Get the location for the map output - either in-memory or on-disk\n      try {\n        mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      } catch (IOException ioe) {\n        // kill this reduce attempt\n        ioErrs.increment(1);\n        scheduler.reportLocalError(ioe);\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      }\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n        //Not an error but wait to process data.\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      } \n      \n      // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n      // on decompression failures. Catching and re-throwing as IOException\n      // to allow fetch failure logic to be processed\n      try {\n        // Go!\n        LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n            + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n            + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n        mapOutput.shuffle(host, input, compressedLength, decompressedLength,\n            metrics, reporter);\n      } catch (java.lang.InternalError e) {\n        LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n        throw new IOException(e);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d System.currentTimeMillis();\n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              endTime - startTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return null;\n    } catch (IOException ioe) {\n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        if(mapId \u003d\u003d null) {\n          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n        } else {\n          return new TaskAttemptID[] {mapId};\n        }\n      }\n      \n      LOG.warn(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      mapOutput.abort();\n      metrics.failedFetch();\n      return new TaskAttemptID[] {mapId};\n    }\n\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
      "extendedDetails": {}
    },
    "523d3daac0db8cfcbcfba67f3bbdc4eaf61b136f": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5053. java.lang.InternalError from decompression codec cause reducer to fail (Robert Parker via jeagles)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1458350 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/03/13 8:45 AM",
      "commitName": "523d3daac0db8cfcbcfba67f3bbdc4eaf61b136f",
      "commitAuthor": "Jonathan Turner Eagles",
      "commitDateOld": "15/03/13 2:09 PM",
      "commitNameOld": "7d7553c4eb7d9a282410a3213d26a89fea9b7865",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 3.78,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,94 @@\n   private TaskAttemptID[] copyMapOutput(MapHost host,\n                                 DataInputStream input,\n                                 Set\u003cTaskAttemptID\u003e remaining) {\n     MapOutput\u003cK,V\u003e mapOutput \u003d null;\n     TaskAttemptID mapId \u003d null;\n     long decompressedLength \u003d -1;\n     long compressedLength \u003d -1;\n     \n     try {\n       long startTime \u003d System.currentTimeMillis();\n       int forReduce \u003d -1;\n       //Read the shuffle header\n       try {\n         ShuffleHeader header \u003d new ShuffleHeader();\n         header.readFields(input);\n         mapId \u003d TaskAttemptID.forName(header.mapId);\n         compressedLength \u003d header.compressedLength;\n         decompressedLength \u003d header.uncompressedLength;\n         forReduce \u003d header.forReduce;\n       } catch (IllegalArgumentException e) {\n         badIdErrs.increment(1);\n         LOG.warn(\"Invalid map id \", e);\n         //Don\u0027t know which one was bad, so consider all of them as bad\n         return remaining.toArray(new TaskAttemptID[remaining.size()]);\n       }\n \n  \n       // Do some basic sanity verification\n       if (!verifySanity(compressedLength, decompressedLength, forReduce,\n           remaining, mapId)) {\n         return new TaskAttemptID[] {mapId};\n       }\n       \n       if(LOG.isDebugEnabled()) {\n         LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n             \", decomp len: \" + decompressedLength);\n       }\n       \n       // Get the location for the map output - either in-memory or on-disk\n       mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n       \n       // Check if we can shuffle *now* ...\n       if (mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n         //Not an error but wait to process data.\n         return EMPTY_ATTEMPT_ID_ARRAY;\n       } \n       \n-      // Go!\n-      LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n-               mapOutput.getMapId() + \" decomp: \" +\n-               decompressedLength + \" len: \" + compressedLength + \" to \" +\n-               mapOutput.getDescription());\n-      mapOutput.shuffle(host, input, compressedLength, decompressedLength,\n-                        metrics, reporter);\n+      // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n+      // on decompression failures. Catching and re-throwing as IOException\n+      // to allow fetch failure logic to be processed\n+      try {\n+        // Go!\n+        LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n+            + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n+            + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n+        mapOutput.shuffle(host, input, compressedLength, decompressedLength,\n+            metrics, reporter);\n+      } catch (java.lang.InternalError e) {\n+        LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n+        throw new IOException(e);\n+      }\n       \n       // Inform the shuffle scheduler\n       long endTime \u003d System.currentTimeMillis();\n       scheduler.copySucceeded(mapId, host, compressedLength, \n                               endTime - startTime, mapOutput);\n       // Note successful shuffle\n       remaining.remove(mapId);\n       metrics.successFetch();\n       return null;\n     } catch (IOException ioe) {\n       ioErrs.increment(1);\n       if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                  mapId + \" decomp: \" + \n                  decompressedLength + \", \" + compressedLength, ioe);\n         if(mapId \u003d\u003d null) {\n           return remaining.toArray(new TaskAttemptID[remaining.size()]);\n         } else {\n           return new TaskAttemptID[] {mapId};\n         }\n       }\n       \n       LOG.warn(\"Failed to shuffle output of \" + mapId + \n                \" from \" + host.getHostName(), ioe); \n \n       // Inform the shuffle-scheduler\n       mapOutput.abort();\n       metrics.failedFetch();\n       return new TaskAttemptID[] {mapId};\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining) {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d System.currentTimeMillis();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        //Don\u0027t know which one was bad, so consider all of them as bad\n        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n      }\n\n \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return new TaskAttemptID[] {mapId};\n      }\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n            \", decomp len: \" + decompressedLength);\n      }\n      \n      // Get the location for the map output - either in-memory or on-disk\n      mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n        //Not an error but wait to process data.\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      } \n      \n      // The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError\n      // on decompression failures. Catching and re-throwing as IOException\n      // to allow fetch failure logic to be processed\n      try {\n        // Go!\n        LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \"\n            + mapOutput.getMapId() + \" decomp: \" + decompressedLength\n            + \" len: \" + compressedLength + \" to \" + mapOutput.getDescription());\n        mapOutput.shuffle(host, input, compressedLength, decompressedLength,\n            metrics, reporter);\n      } catch (java.lang.InternalError e) {\n        LOG.warn(\"Failed to shuffle for fetcher#\"+id, e);\n        throw new IOException(e);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d System.currentTimeMillis();\n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              endTime - startTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return null;\n    } catch (IOException ioe) {\n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        if(mapId \u003d\u003d null) {\n          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n        } else {\n          return new TaskAttemptID[] {mapId};\n        }\n      }\n      \n      LOG.warn(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      mapOutput.abort();\n      metrics.failedFetch();\n      return new TaskAttemptID[] {mapId};\n    }\n\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
      "extendedDetails": {}
    },
    "73fd247c7649919350ecfd16806af57ffe554649": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4808. Refactor MapOutput and MergeManager to facilitate reuse by Shuffle implementations. (masokan via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1436936 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/01/13 6:10 AM",
      "commitName": "73fd247c7649919350ecfd16806af57ffe554649",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "26/12/12 12:47 PM",
      "commitNameOld": "a7d444d002c664208669ec6ddf3bcb1db71e3741",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 26.72,
      "commitsBetweenForRepo": 131,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,91 +1,87 @@\n   private TaskAttemptID[] copyMapOutput(MapHost host,\n                                 DataInputStream input,\n                                 Set\u003cTaskAttemptID\u003e remaining) {\n     MapOutput\u003cK,V\u003e mapOutput \u003d null;\n     TaskAttemptID mapId \u003d null;\n     long decompressedLength \u003d -1;\n     long compressedLength \u003d -1;\n     \n     try {\n       long startTime \u003d System.currentTimeMillis();\n       int forReduce \u003d -1;\n       //Read the shuffle header\n       try {\n         ShuffleHeader header \u003d new ShuffleHeader();\n         header.readFields(input);\n         mapId \u003d TaskAttemptID.forName(header.mapId);\n         compressedLength \u003d header.compressedLength;\n         decompressedLength \u003d header.uncompressedLength;\n         forReduce \u003d header.forReduce;\n       } catch (IllegalArgumentException e) {\n         badIdErrs.increment(1);\n         LOG.warn(\"Invalid map id \", e);\n         //Don\u0027t know which one was bad, so consider all of them as bad\n         return remaining.toArray(new TaskAttemptID[remaining.size()]);\n       }\n \n  \n       // Do some basic sanity verification\n       if (!verifySanity(compressedLength, decompressedLength, forReduce,\n           remaining, mapId)) {\n         return new TaskAttemptID[] {mapId};\n       }\n       \n       if(LOG.isDebugEnabled()) {\n         LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n             \", decomp len: \" + decompressedLength);\n       }\n       \n       // Get the location for the map output - either in-memory or on-disk\n       mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n       \n       // Check if we can shuffle *now* ...\n-      if (mapOutput.getType() \u003d\u003d Type.WAIT) {\n-        LOG.info(\"fetcher#\" + id + \" - MergerManager returned Status.WAIT ...\");\n+      if (mapOutput \u003d\u003d null) {\n+        LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n         //Not an error but wait to process data.\n         return EMPTY_ATTEMPT_ID_ARRAY;\n       } \n       \n       // Go!\n       LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n                mapOutput.getMapId() + \" decomp: \" +\n                decompressedLength + \" len: \" + compressedLength + \" to \" +\n-               mapOutput.getType());\n-      if (mapOutput.getType() \u003d\u003d Type.MEMORY) {\n-        shuffleToMemory(host, mapOutput, input, \n-                        (int) decompressedLength, (int) compressedLength);\n-      } else {\n-        shuffleToDisk(host, mapOutput, input, compressedLength);\n-      }\n+               mapOutput.getDescription());\n+      mapOutput.shuffle(host, input, compressedLength, decompressedLength,\n+                        metrics, reporter);\n       \n       // Inform the shuffle scheduler\n       long endTime \u003d System.currentTimeMillis();\n       scheduler.copySucceeded(mapId, host, compressedLength, \n                               endTime - startTime, mapOutput);\n       // Note successful shuffle\n       remaining.remove(mapId);\n       metrics.successFetch();\n       return null;\n     } catch (IOException ioe) {\n       ioErrs.increment(1);\n       if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                  mapId + \" decomp: \" + \n                  decompressedLength + \", \" + compressedLength, ioe);\n         if(mapId \u003d\u003d null) {\n           return remaining.toArray(new TaskAttemptID[remaining.size()]);\n         } else {\n           return new TaskAttemptID[] {mapId};\n         }\n       }\n       \n       LOG.warn(\"Failed to shuffle output of \" + mapId + \n                \" from \" + host.getHostName(), ioe); \n \n       // Inform the shuffle-scheduler\n       mapOutput.abort();\n       metrics.failedFetch();\n       return new TaskAttemptID[] {mapId};\n     }\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining) {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d System.currentTimeMillis();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        //Don\u0027t know which one was bad, so consider all of them as bad\n        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n      }\n\n \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return new TaskAttemptID[] {mapId};\n      }\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n            \", decomp len: \" + decompressedLength);\n      }\n      \n      // Get the location for the map output - either in-memory or on-disk\n      mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" - MergeManager returned status WAIT ...\");\n        //Not an error but wait to process data.\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      } \n      \n      // Go!\n      LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n               mapOutput.getMapId() + \" decomp: \" +\n               decompressedLength + \" len: \" + compressedLength + \" to \" +\n               mapOutput.getDescription());\n      mapOutput.shuffle(host, input, compressedLength, decompressedLength,\n                        metrics, reporter);\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d System.currentTimeMillis();\n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              endTime - startTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return null;\n    } catch (IOException ioe) {\n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        if(mapId \u003d\u003d null) {\n          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n        } else {\n          return new TaskAttemptID[] {mapId};\n        }\n      }\n      \n      LOG.warn(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      mapOutput.abort();\n      metrics.failedFetch();\n      return new TaskAttemptID[] {mapId};\n    }\n\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
      "extendedDetails": {}
    },
    "d87b545165f9442f614665521ce04424af1490e8": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": " MAPREDUCE-4423. Potential infinite fetching of map output (Robert Evans via tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1366258 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/07/12 6:48 PM",
      "commitName": "d87b545165f9442f614665521ce04424af1490e8",
      "commitAuthor": "Thomas Graves",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": " MAPREDUCE-4423. Potential infinite fetching of map output (Robert Evans via tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1366258 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "26/07/12 6:48 PM",
          "commitName": "d87b545165f9442f614665521ce04424af1490e8",
          "commitAuthor": "Thomas Graves",
          "commitDateOld": "26/07/12 6:23 AM",
          "commitNameOld": "9d16c9354b0c05edb30d23003dcdec4cc44ed925",
          "commitAuthorOld": "Alejandro Abdelnur",
          "daysBetweenCommits": 0.52,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,84 +1,91 @@\n-  private boolean copyMapOutput(MapHost host,\n+  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                 DataInputStream input,\n                                 Set\u003cTaskAttemptID\u003e remaining) {\n     MapOutput\u003cK,V\u003e mapOutput \u003d null;\n     TaskAttemptID mapId \u003d null;\n     long decompressedLength \u003d -1;\n     long compressedLength \u003d -1;\n     \n     try {\n       long startTime \u003d System.currentTimeMillis();\n       int forReduce \u003d -1;\n       //Read the shuffle header\n       try {\n         ShuffleHeader header \u003d new ShuffleHeader();\n         header.readFields(input);\n         mapId \u003d TaskAttemptID.forName(header.mapId);\n         compressedLength \u003d header.compressedLength;\n         decompressedLength \u003d header.uncompressedLength;\n         forReduce \u003d header.forReduce;\n       } catch (IllegalArgumentException e) {\n         badIdErrs.increment(1);\n         LOG.warn(\"Invalid map id \", e);\n-        return false;\n+        //Don\u0027t know which one was bad, so consider all of them as bad\n+        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n       }\n \n  \n       // Do some basic sanity verification\n       if (!verifySanity(compressedLength, decompressedLength, forReduce,\n           remaining, mapId)) {\n-        return false;\n+        return new TaskAttemptID[] {mapId};\n       }\n       \n-      LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n-               \", decomp len: \" + decompressedLength);\n+      if(LOG.isDebugEnabled()) {\n+        LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n+            \", decomp len: \" + decompressedLength);\n+      }\n       \n       // Get the location for the map output - either in-memory or on-disk\n       mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n       \n       // Check if we can shuffle *now* ...\n       if (mapOutput.getType() \u003d\u003d Type.WAIT) {\n         LOG.info(\"fetcher#\" + id + \" - MergerManager returned Status.WAIT ...\");\n-        return false;\n+        //Not an error but wait to process data.\n+        return EMPTY_ATTEMPT_ID_ARRAY;\n       } \n       \n       // Go!\n       LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n                mapOutput.getMapId() + \" decomp: \" +\n                decompressedLength + \" len: \" + compressedLength + \" to \" +\n                mapOutput.getType());\n       if (mapOutput.getType() \u003d\u003d Type.MEMORY) {\n         shuffleToMemory(host, mapOutput, input, \n                         (int) decompressedLength, (int) compressedLength);\n       } else {\n         shuffleToDisk(host, mapOutput, input, compressedLength);\n       }\n       \n       // Inform the shuffle scheduler\n       long endTime \u003d System.currentTimeMillis();\n       scheduler.copySucceeded(mapId, host, compressedLength, \n                               endTime - startTime, mapOutput);\n       // Note successful shuffle\n       remaining.remove(mapId);\n       metrics.successFetch();\n-      return true;\n+      return null;\n     } catch (IOException ioe) {\n       ioErrs.increment(1);\n       if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                  mapId + \" decomp: \" + \n                  decompressedLength + \", \" + compressedLength, ioe);\n-        return false;\n+        if(mapId \u003d\u003d null) {\n+          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n+        } else {\n+          return new TaskAttemptID[] {mapId};\n+        }\n       }\n       \n-      LOG.info(\"Failed to shuffle output of \" + mapId + \n+      LOG.warn(\"Failed to shuffle output of \" + mapId + \n                \" from \" + host.getHostName(), ioe); \n \n       // Inform the shuffle-scheduler\n       mapOutput.abort();\n-      scheduler.copyFailed(mapId, host, true);\n       metrics.failedFetch();\n-      return false;\n+      return new TaskAttemptID[] {mapId};\n     }\n \n   }\n\\ No newline at end of file\n",
          "actualSource": "  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining) {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d System.currentTimeMillis();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        //Don\u0027t know which one was bad, so consider all of them as bad\n        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n      }\n\n \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return new TaskAttemptID[] {mapId};\n      }\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n            \", decomp len: \" + decompressedLength);\n      }\n      \n      // Get the location for the map output - either in-memory or on-disk\n      mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput.getType() \u003d\u003d Type.WAIT) {\n        LOG.info(\"fetcher#\" + id + \" - MergerManager returned Status.WAIT ...\");\n        //Not an error but wait to process data.\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      } \n      \n      // Go!\n      LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n               mapOutput.getMapId() + \" decomp: \" +\n               decompressedLength + \" len: \" + compressedLength + \" to \" +\n               mapOutput.getType());\n      if (mapOutput.getType() \u003d\u003d Type.MEMORY) {\n        shuffleToMemory(host, mapOutput, input, \n                        (int) decompressedLength, (int) compressedLength);\n      } else {\n        shuffleToDisk(host, mapOutput, input, compressedLength);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d System.currentTimeMillis();\n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              endTime - startTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return null;\n    } catch (IOException ioe) {\n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        if(mapId \u003d\u003d null) {\n          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n        } else {\n          return new TaskAttemptID[] {mapId};\n        }\n      }\n      \n      LOG.warn(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      mapOutput.abort();\n      metrics.failedFetch();\n      return new TaskAttemptID[] {mapId};\n    }\n\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
          "extendedDetails": {
            "oldValue": "boolean",
            "newValue": "TaskAttemptID[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": " MAPREDUCE-4423. Potential infinite fetching of map output (Robert Evans via tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1366258 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "26/07/12 6:48 PM",
          "commitName": "d87b545165f9442f614665521ce04424af1490e8",
          "commitAuthor": "Thomas Graves",
          "commitDateOld": "26/07/12 6:23 AM",
          "commitNameOld": "9d16c9354b0c05edb30d23003dcdec4cc44ed925",
          "commitAuthorOld": "Alejandro Abdelnur",
          "daysBetweenCommits": 0.52,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,84 +1,91 @@\n-  private boolean copyMapOutput(MapHost host,\n+  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                 DataInputStream input,\n                                 Set\u003cTaskAttemptID\u003e remaining) {\n     MapOutput\u003cK,V\u003e mapOutput \u003d null;\n     TaskAttemptID mapId \u003d null;\n     long decompressedLength \u003d -1;\n     long compressedLength \u003d -1;\n     \n     try {\n       long startTime \u003d System.currentTimeMillis();\n       int forReduce \u003d -1;\n       //Read the shuffle header\n       try {\n         ShuffleHeader header \u003d new ShuffleHeader();\n         header.readFields(input);\n         mapId \u003d TaskAttemptID.forName(header.mapId);\n         compressedLength \u003d header.compressedLength;\n         decompressedLength \u003d header.uncompressedLength;\n         forReduce \u003d header.forReduce;\n       } catch (IllegalArgumentException e) {\n         badIdErrs.increment(1);\n         LOG.warn(\"Invalid map id \", e);\n-        return false;\n+        //Don\u0027t know which one was bad, so consider all of them as bad\n+        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n       }\n \n  \n       // Do some basic sanity verification\n       if (!verifySanity(compressedLength, decompressedLength, forReduce,\n           remaining, mapId)) {\n-        return false;\n+        return new TaskAttemptID[] {mapId};\n       }\n       \n-      LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n-               \", decomp len: \" + decompressedLength);\n+      if(LOG.isDebugEnabled()) {\n+        LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n+            \", decomp len: \" + decompressedLength);\n+      }\n       \n       // Get the location for the map output - either in-memory or on-disk\n       mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n       \n       // Check if we can shuffle *now* ...\n       if (mapOutput.getType() \u003d\u003d Type.WAIT) {\n         LOG.info(\"fetcher#\" + id + \" - MergerManager returned Status.WAIT ...\");\n-        return false;\n+        //Not an error but wait to process data.\n+        return EMPTY_ATTEMPT_ID_ARRAY;\n       } \n       \n       // Go!\n       LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n                mapOutput.getMapId() + \" decomp: \" +\n                decompressedLength + \" len: \" + compressedLength + \" to \" +\n                mapOutput.getType());\n       if (mapOutput.getType() \u003d\u003d Type.MEMORY) {\n         shuffleToMemory(host, mapOutput, input, \n                         (int) decompressedLength, (int) compressedLength);\n       } else {\n         shuffleToDisk(host, mapOutput, input, compressedLength);\n       }\n       \n       // Inform the shuffle scheduler\n       long endTime \u003d System.currentTimeMillis();\n       scheduler.copySucceeded(mapId, host, compressedLength, \n                               endTime - startTime, mapOutput);\n       // Note successful shuffle\n       remaining.remove(mapId);\n       metrics.successFetch();\n-      return true;\n+      return null;\n     } catch (IOException ioe) {\n       ioErrs.increment(1);\n       if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                  mapId + \" decomp: \" + \n                  decompressedLength + \", \" + compressedLength, ioe);\n-        return false;\n+        if(mapId \u003d\u003d null) {\n+          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n+        } else {\n+          return new TaskAttemptID[] {mapId};\n+        }\n       }\n       \n-      LOG.info(\"Failed to shuffle output of \" + mapId + \n+      LOG.warn(\"Failed to shuffle output of \" + mapId + \n                \" from \" + host.getHostName(), ioe); \n \n       // Inform the shuffle-scheduler\n       mapOutput.abort();\n-      scheduler.copyFailed(mapId, host, true);\n       metrics.failedFetch();\n-      return false;\n+      return new TaskAttemptID[] {mapId};\n     }\n \n   }\n\\ No newline at end of file\n",
          "actualSource": "  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining) {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d System.currentTimeMillis();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        //Don\u0027t know which one was bad, so consider all of them as bad\n        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n      }\n\n \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return new TaskAttemptID[] {mapId};\n      }\n      \n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n            \", decomp len: \" + decompressedLength);\n      }\n      \n      // Get the location for the map output - either in-memory or on-disk\n      mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput.getType() \u003d\u003d Type.WAIT) {\n        LOG.info(\"fetcher#\" + id + \" - MergerManager returned Status.WAIT ...\");\n        //Not an error but wait to process data.\n        return EMPTY_ATTEMPT_ID_ARRAY;\n      } \n      \n      // Go!\n      LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n               mapOutput.getMapId() + \" decomp: \" +\n               decompressedLength + \" len: \" + compressedLength + \" to \" +\n               mapOutput.getType());\n      if (mapOutput.getType() \u003d\u003d Type.MEMORY) {\n        shuffleToMemory(host, mapOutput, input, \n                        (int) decompressedLength, (int) compressedLength);\n      } else {\n        shuffleToDisk(host, mapOutput, input, compressedLength);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d System.currentTimeMillis();\n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              endTime - startTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return null;\n    } catch (IOException ioe) {\n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        if(mapId \u003d\u003d null) {\n          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n        } else {\n          return new TaskAttemptID[] {mapId};\n        }\n      }\n      \n      LOG.warn(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      mapOutput.abort();\n      metrics.failedFetch();\n      return new TaskAttemptID[] {mapId};\n    }\n\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
          "extendedDetails": {}
        }
      ]
    },
    "d45922de2c5645e11339b94e4c31935ead66fefc": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "svn merge --change -1363454 for reverting MAPREDUCE-4423\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1363935 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/07/12 1:18 PM",
      "commitName": "d45922de2c5645e11339b94e4c31935ead66fefc",
      "commitAuthor": "Thomas Graves",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "svn merge --change -1363454 for reverting MAPREDUCE-4423\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1363935 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/07/12 1:18 PM",
          "commitName": "d45922de2c5645e11339b94e4c31935ead66fefc",
          "commitAuthor": "Thomas Graves",
          "commitDateOld": "19/07/12 11:19 AM",
          "commitNameOld": "8e69f883a0ac407781fa09328d9fb87faf5a8d0a",
          "commitAuthorOld": "Thomas Graves",
          "daysBetweenCommits": 1.08,
          "commitsBetweenForRepo": 9,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,88 +1,84 @@\n-  private TaskAttemptID[] copyMapOutput(MapHost host,\n+  private boolean copyMapOutput(MapHost host,\n                                 DataInputStream input,\n                                 Set\u003cTaskAttemptID\u003e remaining) {\n     MapOutput\u003cK,V\u003e mapOutput \u003d null;\n     TaskAttemptID mapId \u003d null;\n     long decompressedLength \u003d -1;\n     long compressedLength \u003d -1;\n     \n     try {\n       long startTime \u003d System.currentTimeMillis();\n       int forReduce \u003d -1;\n       //Read the shuffle header\n       try {\n         ShuffleHeader header \u003d new ShuffleHeader();\n         header.readFields(input);\n         mapId \u003d TaskAttemptID.forName(header.mapId);\n         compressedLength \u003d header.compressedLength;\n         decompressedLength \u003d header.uncompressedLength;\n         forReduce \u003d header.forReduce;\n       } catch (IllegalArgumentException e) {\n         badIdErrs.increment(1);\n         LOG.warn(\"Invalid map id \", e);\n-        //Don\u0027t know which one was bad, so consider all of them as bad\n-        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n+        return false;\n       }\n \n  \n       // Do some basic sanity verification\n       if (!verifySanity(compressedLength, decompressedLength, forReduce,\n           remaining, mapId)) {\n-        return new TaskAttemptID[] {mapId};\n+        return false;\n       }\n       \n       LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n                \", decomp len: \" + decompressedLength);\n       \n       // Get the location for the map output - either in-memory or on-disk\n       mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n       \n       // Check if we can shuffle *now* ...\n       if (mapOutput.getType() \u003d\u003d Type.WAIT) {\n         LOG.info(\"fetcher#\" + id + \" - MergerManager returned Status.WAIT ...\");\n-        return new TaskAttemptID[] {mapId};\n+        return false;\n       } \n       \n       // Go!\n       LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n                mapOutput.getMapId() + \" decomp: \" +\n                decompressedLength + \" len: \" + compressedLength + \" to \" +\n                mapOutput.getType());\n       if (mapOutput.getType() \u003d\u003d Type.MEMORY) {\n         shuffleToMemory(host, mapOutput, input, \n                         (int) decompressedLength, (int) compressedLength);\n       } else {\n         shuffleToDisk(host, mapOutput, input, compressedLength);\n       }\n       \n       // Inform the shuffle scheduler\n       long endTime \u003d System.currentTimeMillis();\n       scheduler.copySucceeded(mapId, host, compressedLength, \n                               endTime - startTime, mapOutput);\n       // Note successful shuffle\n       remaining.remove(mapId);\n       metrics.successFetch();\n-      return null;\n+      return true;\n     } catch (IOException ioe) {\n       ioErrs.increment(1);\n       if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                  mapId + \" decomp: \" + \n                  decompressedLength + \", \" + compressedLength, ioe);\n-        if(mapId \u003d\u003d null) {\n-          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n-        } else {\n-          return new TaskAttemptID[] {mapId};\n-        }\n+        return false;\n       }\n       \n       LOG.info(\"Failed to shuffle output of \" + mapId + \n                \" from \" + host.getHostName(), ioe); \n \n       // Inform the shuffle-scheduler\n       mapOutput.abort();\n+      scheduler.copyFailed(mapId, host, true);\n       metrics.failedFetch();\n-      return new TaskAttemptID[] {mapId};\n+      return false;\n     }\n \n   }\n\\ No newline at end of file\n",
          "actualSource": "  private boolean copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining) {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d System.currentTimeMillis();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        return false;\n      }\n\n \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return false;\n      }\n      \n      LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n               \", decomp len: \" + decompressedLength);\n      \n      // Get the location for the map output - either in-memory or on-disk\n      mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput.getType() \u003d\u003d Type.WAIT) {\n        LOG.info(\"fetcher#\" + id + \" - MergerManager returned Status.WAIT ...\");\n        return false;\n      } \n      \n      // Go!\n      LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n               mapOutput.getMapId() + \" decomp: \" +\n               decompressedLength + \" len: \" + compressedLength + \" to \" +\n               mapOutput.getType());\n      if (mapOutput.getType() \u003d\u003d Type.MEMORY) {\n        shuffleToMemory(host, mapOutput, input, \n                        (int) decompressedLength, (int) compressedLength);\n      } else {\n        shuffleToDisk(host, mapOutput, input, compressedLength);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d System.currentTimeMillis();\n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              endTime - startTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return true;\n    } catch (IOException ioe) {\n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        return false;\n      }\n      \n      LOG.info(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      mapOutput.abort();\n      scheduler.copyFailed(mapId, host, true);\n      metrics.failedFetch();\n      return false;\n    }\n\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
          "extendedDetails": {
            "oldValue": "TaskAttemptID[]",
            "newValue": "boolean"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "svn merge --change -1363454 for reverting MAPREDUCE-4423\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1363935 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/07/12 1:18 PM",
          "commitName": "d45922de2c5645e11339b94e4c31935ead66fefc",
          "commitAuthor": "Thomas Graves",
          "commitDateOld": "19/07/12 11:19 AM",
          "commitNameOld": "8e69f883a0ac407781fa09328d9fb87faf5a8d0a",
          "commitAuthorOld": "Thomas Graves",
          "daysBetweenCommits": 1.08,
          "commitsBetweenForRepo": 9,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,88 +1,84 @@\n-  private TaskAttemptID[] copyMapOutput(MapHost host,\n+  private boolean copyMapOutput(MapHost host,\n                                 DataInputStream input,\n                                 Set\u003cTaskAttemptID\u003e remaining) {\n     MapOutput\u003cK,V\u003e mapOutput \u003d null;\n     TaskAttemptID mapId \u003d null;\n     long decompressedLength \u003d -1;\n     long compressedLength \u003d -1;\n     \n     try {\n       long startTime \u003d System.currentTimeMillis();\n       int forReduce \u003d -1;\n       //Read the shuffle header\n       try {\n         ShuffleHeader header \u003d new ShuffleHeader();\n         header.readFields(input);\n         mapId \u003d TaskAttemptID.forName(header.mapId);\n         compressedLength \u003d header.compressedLength;\n         decompressedLength \u003d header.uncompressedLength;\n         forReduce \u003d header.forReduce;\n       } catch (IllegalArgumentException e) {\n         badIdErrs.increment(1);\n         LOG.warn(\"Invalid map id \", e);\n-        //Don\u0027t know which one was bad, so consider all of them as bad\n-        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n+        return false;\n       }\n \n  \n       // Do some basic sanity verification\n       if (!verifySanity(compressedLength, decompressedLength, forReduce,\n           remaining, mapId)) {\n-        return new TaskAttemptID[] {mapId};\n+        return false;\n       }\n       \n       LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n                \", decomp len: \" + decompressedLength);\n       \n       // Get the location for the map output - either in-memory or on-disk\n       mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n       \n       // Check if we can shuffle *now* ...\n       if (mapOutput.getType() \u003d\u003d Type.WAIT) {\n         LOG.info(\"fetcher#\" + id + \" - MergerManager returned Status.WAIT ...\");\n-        return new TaskAttemptID[] {mapId};\n+        return false;\n       } \n       \n       // Go!\n       LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n                mapOutput.getMapId() + \" decomp: \" +\n                decompressedLength + \" len: \" + compressedLength + \" to \" +\n                mapOutput.getType());\n       if (mapOutput.getType() \u003d\u003d Type.MEMORY) {\n         shuffleToMemory(host, mapOutput, input, \n                         (int) decompressedLength, (int) compressedLength);\n       } else {\n         shuffleToDisk(host, mapOutput, input, compressedLength);\n       }\n       \n       // Inform the shuffle scheduler\n       long endTime \u003d System.currentTimeMillis();\n       scheduler.copySucceeded(mapId, host, compressedLength, \n                               endTime - startTime, mapOutput);\n       // Note successful shuffle\n       remaining.remove(mapId);\n       metrics.successFetch();\n-      return null;\n+      return true;\n     } catch (IOException ioe) {\n       ioErrs.increment(1);\n       if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                  mapId + \" decomp: \" + \n                  decompressedLength + \", \" + compressedLength, ioe);\n-        if(mapId \u003d\u003d null) {\n-          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n-        } else {\n-          return new TaskAttemptID[] {mapId};\n-        }\n+        return false;\n       }\n       \n       LOG.info(\"Failed to shuffle output of \" + mapId + \n                \" from \" + host.getHostName(), ioe); \n \n       // Inform the shuffle-scheduler\n       mapOutput.abort();\n+      scheduler.copyFailed(mapId, host, true);\n       metrics.failedFetch();\n-      return new TaskAttemptID[] {mapId};\n+      return false;\n     }\n \n   }\n\\ No newline at end of file\n",
          "actualSource": "  private boolean copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining) {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d System.currentTimeMillis();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        return false;\n      }\n\n \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return false;\n      }\n      \n      LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n               \", decomp len: \" + decompressedLength);\n      \n      // Get the location for the map output - either in-memory or on-disk\n      mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput.getType() \u003d\u003d Type.WAIT) {\n        LOG.info(\"fetcher#\" + id + \" - MergerManager returned Status.WAIT ...\");\n        return false;\n      } \n      \n      // Go!\n      LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n               mapOutput.getMapId() + \" decomp: \" +\n               decompressedLength + \" len: \" + compressedLength + \" to \" +\n               mapOutput.getType());\n      if (mapOutput.getType() \u003d\u003d Type.MEMORY) {\n        shuffleToMemory(host, mapOutput, input, \n                        (int) decompressedLength, (int) compressedLength);\n      } else {\n        shuffleToDisk(host, mapOutput, input, compressedLength);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d System.currentTimeMillis();\n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              endTime - startTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return true;\n    } catch (IOException ioe) {\n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        return false;\n      }\n      \n      LOG.info(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      mapOutput.abort();\n      scheduler.copyFailed(mapId, host, true);\n      metrics.failedFetch();\n      return false;\n    }\n\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
          "extendedDetails": {}
        }
      ]
    },
    "8e69f883a0ac407781fa09328d9fb87faf5a8d0a": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "MAPREDUCE-4423. Potential infinite fetching of map output (Robert Evans via tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1363454 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/07/12 11:19 AM",
      "commitName": "8e69f883a0ac407781fa09328d9fb87faf5a8d0a",
      "commitAuthor": "Thomas Graves",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "MAPREDUCE-4423. Potential infinite fetching of map output (Robert Evans via tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1363454 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "19/07/12 11:19 AM",
          "commitName": "8e69f883a0ac407781fa09328d9fb87faf5a8d0a",
          "commitAuthor": "Thomas Graves",
          "commitDateOld": "19/03/12 7:28 PM",
          "commitNameOld": "04a47dea7489e3f860b0ab7b8f3ab1fc5a395426",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 121.66,
          "commitsBetweenForRepo": 769,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,84 +1,88 @@\n-  private boolean copyMapOutput(MapHost host,\n+  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                 DataInputStream input,\n                                 Set\u003cTaskAttemptID\u003e remaining) {\n     MapOutput\u003cK,V\u003e mapOutput \u003d null;\n     TaskAttemptID mapId \u003d null;\n     long decompressedLength \u003d -1;\n     long compressedLength \u003d -1;\n     \n     try {\n       long startTime \u003d System.currentTimeMillis();\n       int forReduce \u003d -1;\n       //Read the shuffle header\n       try {\n         ShuffleHeader header \u003d new ShuffleHeader();\n         header.readFields(input);\n         mapId \u003d TaskAttemptID.forName(header.mapId);\n         compressedLength \u003d header.compressedLength;\n         decompressedLength \u003d header.uncompressedLength;\n         forReduce \u003d header.forReduce;\n       } catch (IllegalArgumentException e) {\n         badIdErrs.increment(1);\n         LOG.warn(\"Invalid map id \", e);\n-        return false;\n+        //Don\u0027t know which one was bad, so consider all of them as bad\n+        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n       }\n \n  \n       // Do some basic sanity verification\n       if (!verifySanity(compressedLength, decompressedLength, forReduce,\n           remaining, mapId)) {\n-        return false;\n+        return new TaskAttemptID[] {mapId};\n       }\n       \n       LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n                \", decomp len: \" + decompressedLength);\n       \n       // Get the location for the map output - either in-memory or on-disk\n       mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n       \n       // Check if we can shuffle *now* ...\n       if (mapOutput.getType() \u003d\u003d Type.WAIT) {\n         LOG.info(\"fetcher#\" + id + \" - MergerManager returned Status.WAIT ...\");\n-        return false;\n+        return new TaskAttemptID[] {mapId};\n       } \n       \n       // Go!\n       LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n                mapOutput.getMapId() + \" decomp: \" +\n                decompressedLength + \" len: \" + compressedLength + \" to \" +\n                mapOutput.getType());\n       if (mapOutput.getType() \u003d\u003d Type.MEMORY) {\n         shuffleToMemory(host, mapOutput, input, \n                         (int) decompressedLength, (int) compressedLength);\n       } else {\n         shuffleToDisk(host, mapOutput, input, compressedLength);\n       }\n       \n       // Inform the shuffle scheduler\n       long endTime \u003d System.currentTimeMillis();\n       scheduler.copySucceeded(mapId, host, compressedLength, \n                               endTime - startTime, mapOutput);\n       // Note successful shuffle\n       remaining.remove(mapId);\n       metrics.successFetch();\n-      return true;\n+      return null;\n     } catch (IOException ioe) {\n       ioErrs.increment(1);\n       if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                  mapId + \" decomp: \" + \n                  decompressedLength + \", \" + compressedLength, ioe);\n-        return false;\n+        if(mapId \u003d\u003d null) {\n+          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n+        } else {\n+          return new TaskAttemptID[] {mapId};\n+        }\n       }\n       \n       LOG.info(\"Failed to shuffle output of \" + mapId + \n                \" from \" + host.getHostName(), ioe); \n \n       // Inform the shuffle-scheduler\n       mapOutput.abort();\n-      scheduler.copyFailed(mapId, host, true);\n       metrics.failedFetch();\n-      return false;\n+      return new TaskAttemptID[] {mapId};\n     }\n \n   }\n\\ No newline at end of file\n",
          "actualSource": "  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining) {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d System.currentTimeMillis();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        //Don\u0027t know which one was bad, so consider all of them as bad\n        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n      }\n\n \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return new TaskAttemptID[] {mapId};\n      }\n      \n      LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n               \", decomp len: \" + decompressedLength);\n      \n      // Get the location for the map output - either in-memory or on-disk\n      mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput.getType() \u003d\u003d Type.WAIT) {\n        LOG.info(\"fetcher#\" + id + \" - MergerManager returned Status.WAIT ...\");\n        return new TaskAttemptID[] {mapId};\n      } \n      \n      // Go!\n      LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n               mapOutput.getMapId() + \" decomp: \" +\n               decompressedLength + \" len: \" + compressedLength + \" to \" +\n               mapOutput.getType());\n      if (mapOutput.getType() \u003d\u003d Type.MEMORY) {\n        shuffleToMemory(host, mapOutput, input, \n                        (int) decompressedLength, (int) compressedLength);\n      } else {\n        shuffleToDisk(host, mapOutput, input, compressedLength);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d System.currentTimeMillis();\n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              endTime - startTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return null;\n    } catch (IOException ioe) {\n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        if(mapId \u003d\u003d null) {\n          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n        } else {\n          return new TaskAttemptID[] {mapId};\n        }\n      }\n      \n      LOG.info(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      mapOutput.abort();\n      metrics.failedFetch();\n      return new TaskAttemptID[] {mapId};\n    }\n\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
          "extendedDetails": {
            "oldValue": "boolean",
            "newValue": "TaskAttemptID[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-4423. Potential infinite fetching of map output (Robert Evans via tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1363454 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "19/07/12 11:19 AM",
          "commitName": "8e69f883a0ac407781fa09328d9fb87faf5a8d0a",
          "commitAuthor": "Thomas Graves",
          "commitDateOld": "19/03/12 7:28 PM",
          "commitNameOld": "04a47dea7489e3f860b0ab7b8f3ab1fc5a395426",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 121.66,
          "commitsBetweenForRepo": 769,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,84 +1,88 @@\n-  private boolean copyMapOutput(MapHost host,\n+  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                 DataInputStream input,\n                                 Set\u003cTaskAttemptID\u003e remaining) {\n     MapOutput\u003cK,V\u003e mapOutput \u003d null;\n     TaskAttemptID mapId \u003d null;\n     long decompressedLength \u003d -1;\n     long compressedLength \u003d -1;\n     \n     try {\n       long startTime \u003d System.currentTimeMillis();\n       int forReduce \u003d -1;\n       //Read the shuffle header\n       try {\n         ShuffleHeader header \u003d new ShuffleHeader();\n         header.readFields(input);\n         mapId \u003d TaskAttemptID.forName(header.mapId);\n         compressedLength \u003d header.compressedLength;\n         decompressedLength \u003d header.uncompressedLength;\n         forReduce \u003d header.forReduce;\n       } catch (IllegalArgumentException e) {\n         badIdErrs.increment(1);\n         LOG.warn(\"Invalid map id \", e);\n-        return false;\n+        //Don\u0027t know which one was bad, so consider all of them as bad\n+        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n       }\n \n  \n       // Do some basic sanity verification\n       if (!verifySanity(compressedLength, decompressedLength, forReduce,\n           remaining, mapId)) {\n-        return false;\n+        return new TaskAttemptID[] {mapId};\n       }\n       \n       LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n                \", decomp len: \" + decompressedLength);\n       \n       // Get the location for the map output - either in-memory or on-disk\n       mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n       \n       // Check if we can shuffle *now* ...\n       if (mapOutput.getType() \u003d\u003d Type.WAIT) {\n         LOG.info(\"fetcher#\" + id + \" - MergerManager returned Status.WAIT ...\");\n-        return false;\n+        return new TaskAttemptID[] {mapId};\n       } \n       \n       // Go!\n       LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n                mapOutput.getMapId() + \" decomp: \" +\n                decompressedLength + \" len: \" + compressedLength + \" to \" +\n                mapOutput.getType());\n       if (mapOutput.getType() \u003d\u003d Type.MEMORY) {\n         shuffleToMemory(host, mapOutput, input, \n                         (int) decompressedLength, (int) compressedLength);\n       } else {\n         shuffleToDisk(host, mapOutput, input, compressedLength);\n       }\n       \n       // Inform the shuffle scheduler\n       long endTime \u003d System.currentTimeMillis();\n       scheduler.copySucceeded(mapId, host, compressedLength, \n                               endTime - startTime, mapOutput);\n       // Note successful shuffle\n       remaining.remove(mapId);\n       metrics.successFetch();\n-      return true;\n+      return null;\n     } catch (IOException ioe) {\n       ioErrs.increment(1);\n       if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n         LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                  mapId + \" decomp: \" + \n                  decompressedLength + \", \" + compressedLength, ioe);\n-        return false;\n+        if(mapId \u003d\u003d null) {\n+          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n+        } else {\n+          return new TaskAttemptID[] {mapId};\n+        }\n       }\n       \n       LOG.info(\"Failed to shuffle output of \" + mapId + \n                \" from \" + host.getHostName(), ioe); \n \n       // Inform the shuffle-scheduler\n       mapOutput.abort();\n-      scheduler.copyFailed(mapId, host, true);\n       metrics.failedFetch();\n-      return false;\n+      return new TaskAttemptID[] {mapId};\n     }\n \n   }\n\\ No newline at end of file\n",
          "actualSource": "  private TaskAttemptID[] copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining) {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d System.currentTimeMillis();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        //Don\u0027t know which one was bad, so consider all of them as bad\n        return remaining.toArray(new TaskAttemptID[remaining.size()]);\n      }\n\n \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return new TaskAttemptID[] {mapId};\n      }\n      \n      LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n               \", decomp len: \" + decompressedLength);\n      \n      // Get the location for the map output - either in-memory or on-disk\n      mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput.getType() \u003d\u003d Type.WAIT) {\n        LOG.info(\"fetcher#\" + id + \" - MergerManager returned Status.WAIT ...\");\n        return new TaskAttemptID[] {mapId};\n      } \n      \n      // Go!\n      LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n               mapOutput.getMapId() + \" decomp: \" +\n               decompressedLength + \" len: \" + compressedLength + \" to \" +\n               mapOutput.getType());\n      if (mapOutput.getType() \u003d\u003d Type.MEMORY) {\n        shuffleToMemory(host, mapOutput, input, \n                        (int) decompressedLength, (int) compressedLength);\n      } else {\n        shuffleToDisk(host, mapOutput, input, compressedLength);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d System.currentTimeMillis();\n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              endTime - startTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return null;\n    } catch (IOException ioe) {\n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        if(mapId \u003d\u003d null) {\n          return remaining.toArray(new TaskAttemptID[remaining.size()]);\n        } else {\n          return new TaskAttemptID[] {mapId};\n        }\n      }\n      \n      LOG.info(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      mapOutput.abort();\n      metrics.failedFetch();\n      return new TaskAttemptID[] {mapId};\n    }\n\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
          "extendedDetails": {}
        }
      ]
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private boolean copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining) {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d System.currentTimeMillis();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        return false;\n      }\n\n \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return false;\n      }\n      \n      LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n               \", decomp len: \" + decompressedLength);\n      \n      // Get the location for the map output - either in-memory or on-disk\n      mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput.getType() \u003d\u003d Type.WAIT) {\n        LOG.info(\"fetcher#\" + id + \" - MergerManager returned Status.WAIT ...\");\n        return false;\n      } \n      \n      // Go!\n      LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n               mapOutput.getMapId() + \" decomp: \" +\n               decompressedLength + \" len: \" + compressedLength + \" to \" +\n               mapOutput.getType());\n      if (mapOutput.getType() \u003d\u003d Type.MEMORY) {\n        shuffleToMemory(host, mapOutput, input, \n                        (int) decompressedLength, (int) compressedLength);\n      } else {\n        shuffleToDisk(host, mapOutput, input, compressedLength);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d System.currentTimeMillis();\n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              endTime - startTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return true;\n    } catch (IOException ioe) {\n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        return false;\n      }\n      \n      LOG.info(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      mapOutput.abort();\n      scheduler.copyFailed(mapId, host, true);\n      metrics.failedFetch();\n      return false;\n    }\n\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private boolean copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining) {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d System.currentTimeMillis();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        return false;\n      }\n\n \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return false;\n      }\n      \n      LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n               \", decomp len: \" + decompressedLength);\n      \n      // Get the location for the map output - either in-memory or on-disk\n      mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput.getType() \u003d\u003d Type.WAIT) {\n        LOG.info(\"fetcher#\" + id + \" - MergerManager returned Status.WAIT ...\");\n        return false;\n      } \n      \n      // Go!\n      LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n               mapOutput.getMapId() + \" decomp: \" +\n               decompressedLength + \" len: \" + compressedLength + \" to \" +\n               mapOutput.getType());\n      if (mapOutput.getType() \u003d\u003d Type.MEMORY) {\n        shuffleToMemory(host, mapOutput, input, \n                        (int) decompressedLength, (int) compressedLength);\n      } else {\n        shuffleToDisk(host, mapOutput, input, compressedLength);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d System.currentTimeMillis();\n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              endTime - startTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return true;\n    } catch (IOException ioe) {\n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        return false;\n      }\n      \n      LOG.info(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      mapOutput.abort();\n      scheduler.copyFailed(mapId, host, true);\n      metrics.failedFetch();\n      return false;\n    }\n\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java",
        "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,84 @@\n+  private boolean copyMapOutput(MapHost host,\n+                                DataInputStream input,\n+                                Set\u003cTaskAttemptID\u003e remaining) {\n+    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n+    TaskAttemptID mapId \u003d null;\n+    long decompressedLength \u003d -1;\n+    long compressedLength \u003d -1;\n+    \n+    try {\n+      long startTime \u003d System.currentTimeMillis();\n+      int forReduce \u003d -1;\n+      //Read the shuffle header\n+      try {\n+        ShuffleHeader header \u003d new ShuffleHeader();\n+        header.readFields(input);\n+        mapId \u003d TaskAttemptID.forName(header.mapId);\n+        compressedLength \u003d header.compressedLength;\n+        decompressedLength \u003d header.uncompressedLength;\n+        forReduce \u003d header.forReduce;\n+      } catch (IllegalArgumentException e) {\n+        badIdErrs.increment(1);\n+        LOG.warn(\"Invalid map id \", e);\n+        return false;\n+      }\n+\n+ \n+      // Do some basic sanity verification\n+      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n+          remaining, mapId)) {\n+        return false;\n+      }\n+      \n+      LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n+               \", decomp len: \" + decompressedLength);\n+      \n+      // Get the location for the map output - either in-memory or on-disk\n+      mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n+      \n+      // Check if we can shuffle *now* ...\n+      if (mapOutput.getType() \u003d\u003d Type.WAIT) {\n+        LOG.info(\"fetcher#\" + id + \" - MergerManager returned Status.WAIT ...\");\n+        return false;\n+      } \n+      \n+      // Go!\n+      LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n+               mapOutput.getMapId() + \" decomp: \" +\n+               decompressedLength + \" len: \" + compressedLength + \" to \" +\n+               mapOutput.getType());\n+      if (mapOutput.getType() \u003d\u003d Type.MEMORY) {\n+        shuffleToMemory(host, mapOutput, input, \n+                        (int) decompressedLength, (int) compressedLength);\n+      } else {\n+        shuffleToDisk(host, mapOutput, input, compressedLength);\n+      }\n+      \n+      // Inform the shuffle scheduler\n+      long endTime \u003d System.currentTimeMillis();\n+      scheduler.copySucceeded(mapId, host, compressedLength, \n+                              endTime - startTime, mapOutput);\n+      // Note successful shuffle\n+      remaining.remove(mapId);\n+      metrics.successFetch();\n+      return true;\n+    } catch (IOException ioe) {\n+      ioErrs.increment(1);\n+      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n+        LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n+                 mapId + \" decomp: \" + \n+                 decompressedLength + \", \" + compressedLength, ioe);\n+        return false;\n+      }\n+      \n+      LOG.info(\"Failed to shuffle output of \" + mapId + \n+               \" from \" + host.getHostName(), ioe); \n+\n+      // Inform the shuffle-scheduler\n+      mapOutput.abort();\n+      scheduler.copyFailed(mapId, host, true);\n+      metrics.failedFetch();\n+      return false;\n+    }\n+\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean copyMapOutput(MapHost host,\n                                DataInputStream input,\n                                Set\u003cTaskAttemptID\u003e remaining) {\n    MapOutput\u003cK,V\u003e mapOutput \u003d null;\n    TaskAttemptID mapId \u003d null;\n    long decompressedLength \u003d -1;\n    long compressedLength \u003d -1;\n    \n    try {\n      long startTime \u003d System.currentTimeMillis();\n      int forReduce \u003d -1;\n      //Read the shuffle header\n      try {\n        ShuffleHeader header \u003d new ShuffleHeader();\n        header.readFields(input);\n        mapId \u003d TaskAttemptID.forName(header.mapId);\n        compressedLength \u003d header.compressedLength;\n        decompressedLength \u003d header.uncompressedLength;\n        forReduce \u003d header.forReduce;\n      } catch (IllegalArgumentException e) {\n        badIdErrs.increment(1);\n        LOG.warn(\"Invalid map id \", e);\n        return false;\n      }\n\n \n      // Do some basic sanity verification\n      if (!verifySanity(compressedLength, decompressedLength, forReduce,\n          remaining, mapId)) {\n        return false;\n      }\n      \n      LOG.debug(\"header: \" + mapId + \", len: \" + compressedLength + \n               \", decomp len: \" + decompressedLength);\n      \n      // Get the location for the map output - either in-memory or on-disk\n      mapOutput \u003d merger.reserve(mapId, decompressedLength, id);\n      \n      // Check if we can shuffle *now* ...\n      if (mapOutput.getType() \u003d\u003d Type.WAIT) {\n        LOG.info(\"fetcher#\" + id + \" - MergerManager returned Status.WAIT ...\");\n        return false;\n      } \n      \n      // Go!\n      LOG.info(\"fetcher#\" + id + \" about to shuffle output of map \" + \n               mapOutput.getMapId() + \" decomp: \" +\n               decompressedLength + \" len: \" + compressedLength + \" to \" +\n               mapOutput.getType());\n      if (mapOutput.getType() \u003d\u003d Type.MEMORY) {\n        shuffleToMemory(host, mapOutput, input, \n                        (int) decompressedLength, (int) compressedLength);\n      } else {\n        shuffleToDisk(host, mapOutput, input, compressedLength);\n      }\n      \n      // Inform the shuffle scheduler\n      long endTime \u003d System.currentTimeMillis();\n      scheduler.copySucceeded(mapId, host, compressedLength, \n                              endTime - startTime, mapOutput);\n      // Note successful shuffle\n      remaining.remove(mapId);\n      metrics.successFetch();\n      return true;\n    } catch (IOException ioe) {\n      ioErrs.increment(1);\n      if (mapId \u003d\u003d null || mapOutput \u003d\u003d null) {\n        LOG.info(\"fetcher#\" + id + \" failed to read map header\" + \n                 mapId + \" decomp: \" + \n                 decompressedLength + \", \" + compressedLength, ioe);\n        return false;\n      }\n      \n      LOG.info(\"Failed to shuffle output of \" + mapId + \n               \" from \" + host.getHostName(), ioe); \n\n      // Inform the shuffle-scheduler\n      mapOutput.abort();\n      scheduler.copyFailed(mapId, host, true);\n      metrics.failedFetch();\n      return false;\n    }\n\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java"
    }
  }
}