{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CodecPool.java",
  "functionName": "borrow",
  "functionId": "borrow___pool-Map__Class__T__,Set__T______codecClass-Class__? extends T__",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CodecPool.java",
  "functionStartLine": 83,
  "functionEndLine": 103,
  "numCommitsSeen": 17,
  "timeTaken": 1521,
  "changeHistory": [
    "1a1dcce827d8747a5629151afa335598fbc94f9e",
    "3727ac9bde3454019cd10afbb74d764e97e02e09",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36"
  ],
  "changeHistoryShort": {
    "1a1dcce827d8747a5629151afa335598fbc94f9e": "Ymultichange(Yparameterchange,Ybodychange)",
    "3727ac9bde3454019cd10afbb74d764e97e02e09": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yfilerename",
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1a1dcce827d8747a5629151afa335598fbc94f9e": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "MAPREDUCE-5918. LineRecordReader can return the same decompressor to CodecPool multiple times (Sergey Murylev via raviprak)\n",
      "commitDate": "14/11/14 3:45 AM",
      "commitName": "1a1dcce827d8747a5629151afa335598fbc94f9e",
      "commitAuthor": "Ravi Prakash",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-5918. LineRecordReader can return the same decompressor to CodecPool multiple times (Sergey Murylev via raviprak)\n",
          "commitDate": "14/11/14 3:45 AM",
          "commitName": "1a1dcce827d8747a5629151afa335598fbc94f9e",
          "commitAuthor": "Ravi Prakash",
          "commitDateOld": "13/11/13 2:50 PM",
          "commitNameOld": "3727ac9bde3454019cd10afbb74d764e97e02e09",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 365.54,
          "commitsBetweenForRepo": 2869,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,21 @@\n-  private static \u003cT\u003e T borrow(Map\u003cClass\u003cT\u003e, List\u003cT\u003e\u003e pool,\n+  private static \u003cT\u003e T borrow(Map\u003cClass\u003cT\u003e, Set\u003cT\u003e\u003e pool,\n                              Class\u003c? extends T\u003e codecClass) {\n     T codec \u003d null;\n     \n     // Check if an appropriate codec is available\n-    List\u003cT\u003e codecList;\n+    Set\u003cT\u003e codecSet;\n     synchronized (pool) {\n-      codecList \u003d pool.get(codecClass);\n+      codecSet \u003d pool.get(codecClass);\n     }\n \n-    if (codecList !\u003d null) {\n-      synchronized (codecList) {\n-        if (!codecList.isEmpty()) {\n-          codec \u003d codecList.remove(codecList.size() - 1);\n+    if (codecSet !\u003d null) {\n+      synchronized (codecSet) {\n+        if (!codecSet.isEmpty()) {\n+          codec \u003d codecSet.iterator().next();\n+          codecSet.remove(codec);\n         }\n       }\n     }\n     \n     return codec;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static \u003cT\u003e T borrow(Map\u003cClass\u003cT\u003e, Set\u003cT\u003e\u003e pool,\n                             Class\u003c? extends T\u003e codecClass) {\n    T codec \u003d null;\n    \n    // Check if an appropriate codec is available\n    Set\u003cT\u003e codecSet;\n    synchronized (pool) {\n      codecSet \u003d pool.get(codecClass);\n    }\n\n    if (codecSet !\u003d null) {\n      synchronized (codecSet) {\n        if (!codecSet.isEmpty()) {\n          codec \u003d codecSet.iterator().next();\n          codecSet.remove(codec);\n        }\n      }\n    }\n    \n    return codec;\n  }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CodecPool.java",
          "extendedDetails": {
            "oldValue": "[pool-Map\u003cClass\u003cT\u003e,List\u003cT\u003e\u003e, codecClass-Class\u003c? extends T\u003e]",
            "newValue": "[pool-Map\u003cClass\u003cT\u003e,Set\u003cT\u003e\u003e, codecClass-Class\u003c? extends T\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-5918. LineRecordReader can return the same decompressor to CodecPool multiple times (Sergey Murylev via raviprak)\n",
          "commitDate": "14/11/14 3:45 AM",
          "commitName": "1a1dcce827d8747a5629151afa335598fbc94f9e",
          "commitAuthor": "Ravi Prakash",
          "commitDateOld": "13/11/13 2:50 PM",
          "commitNameOld": "3727ac9bde3454019cd10afbb74d764e97e02e09",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 365.54,
          "commitsBetweenForRepo": 2869,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,21 @@\n-  private static \u003cT\u003e T borrow(Map\u003cClass\u003cT\u003e, List\u003cT\u003e\u003e pool,\n+  private static \u003cT\u003e T borrow(Map\u003cClass\u003cT\u003e, Set\u003cT\u003e\u003e pool,\n                              Class\u003c? extends T\u003e codecClass) {\n     T codec \u003d null;\n     \n     // Check if an appropriate codec is available\n-    List\u003cT\u003e codecList;\n+    Set\u003cT\u003e codecSet;\n     synchronized (pool) {\n-      codecList \u003d pool.get(codecClass);\n+      codecSet \u003d pool.get(codecClass);\n     }\n \n-    if (codecList !\u003d null) {\n-      synchronized (codecList) {\n-        if (!codecList.isEmpty()) {\n-          codec \u003d codecList.remove(codecList.size() - 1);\n+    if (codecSet !\u003d null) {\n+      synchronized (codecSet) {\n+        if (!codecSet.isEmpty()) {\n+          codec \u003d codecSet.iterator().next();\n+          codecSet.remove(codec);\n         }\n       }\n     }\n     \n     return codec;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static \u003cT\u003e T borrow(Map\u003cClass\u003cT\u003e, Set\u003cT\u003e\u003e pool,\n                             Class\u003c? extends T\u003e codecClass) {\n    T codec \u003d null;\n    \n    // Check if an appropriate codec is available\n    Set\u003cT\u003e codecSet;\n    synchronized (pool) {\n      codecSet \u003d pool.get(codecClass);\n    }\n\n    if (codecSet !\u003d null) {\n      synchronized (codecSet) {\n        if (!codecSet.isEmpty()) {\n          codec \u003d codecSet.iterator().next();\n          codecSet.remove(codec);\n        }\n      }\n    }\n    \n    return codec;\n  }",
          "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CodecPool.java",
          "extendedDetails": {}
        }
      ]
    },
    "3727ac9bde3454019cd10afbb74d764e97e02e09": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10095. In CodecPool, synchronize pool and codecList separately in order to reduce lock contention.  Contributed by Nicolas Liochon\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541750 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/11/13 2:50 PM",
      "commitName": "3727ac9bde3454019cd10afbb74d764e97e02e09",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "03/04/13 3:26 PM",
      "commitNameOld": "da0e779e4b14c7307483b7d8f639c596e54af9ff",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 224.02,
      "commitsBetweenForRepo": 1396,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,20 @@\n   private static \u003cT\u003e T borrow(Map\u003cClass\u003cT\u003e, List\u003cT\u003e\u003e pool,\n                              Class\u003c? extends T\u003e codecClass) {\n     T codec \u003d null;\n     \n     // Check if an appropriate codec is available\n+    List\u003cT\u003e codecList;\n     synchronized (pool) {\n-      if (pool.containsKey(codecClass)) {\n-        List\u003cT\u003e codecList \u003d pool.get(codecClass);\n-        \n-        if (codecList !\u003d null) {\n-          synchronized (codecList) {\n-            if (!codecList.isEmpty()) {\n-              codec \u003d codecList.remove(codecList.size()-1);\n-            }\n-          }\n+      codecList \u003d pool.get(codecClass);\n+    }\n+\n+    if (codecList !\u003d null) {\n+      synchronized (codecList) {\n+        if (!codecList.isEmpty()) {\n+          codec \u003d codecList.remove(codecList.size() - 1);\n         }\n       }\n     }\n     \n     return codec;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static \u003cT\u003e T borrow(Map\u003cClass\u003cT\u003e, List\u003cT\u003e\u003e pool,\n                             Class\u003c? extends T\u003e codecClass) {\n    T codec \u003d null;\n    \n    // Check if an appropriate codec is available\n    List\u003cT\u003e codecList;\n    synchronized (pool) {\n      codecList \u003d pool.get(codecClass);\n    }\n\n    if (codecList !\u003d null) {\n      synchronized (codecList) {\n        if (!codecList.isEmpty()) {\n          codec \u003d codecList.remove(codecList.size() - 1);\n        }\n      }\n    }\n    \n    return codec;\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CodecPool.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private static \u003cT\u003e T borrow(Map\u003cClass\u003cT\u003e, List\u003cT\u003e\u003e pool,\n                             Class\u003c? extends T\u003e codecClass) {\n    T codec \u003d null;\n    \n    // Check if an appropriate codec is available\n    synchronized (pool) {\n      if (pool.containsKey(codecClass)) {\n        List\u003cT\u003e codecList \u003d pool.get(codecClass);\n        \n        if (codecList !\u003d null) {\n          synchronized (codecList) {\n            if (!codecList.isEmpty()) {\n              codec \u003d codecList.remove(codecList.size()-1);\n            }\n          }\n        }\n      }\n    }\n    \n    return codec;\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CodecPool.java",
      "extendedDetails": {
        "oldPath": "hadoop-common/src/main/java/org/apache/hadoop/io/compress/CodecPool.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CodecPool.java"
      }
    },
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-6671. Use maven for hadoop common builds. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1153184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/08/11 9:37 AM",
      "commitName": "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
      "commitAuthor": "Thomas White",
      "commitDateOld": "01/08/11 3:53 PM",
      "commitNameOld": "9bac807cedbcff34e1a144fb475eff267e5ed86d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private static \u003cT\u003e T borrow(Map\u003cClass\u003cT\u003e, List\u003cT\u003e\u003e pool,\n                             Class\u003c? extends T\u003e codecClass) {\n    T codec \u003d null;\n    \n    // Check if an appropriate codec is available\n    synchronized (pool) {\n      if (pool.containsKey(codecClass)) {\n        List\u003cT\u003e codecList \u003d pool.get(codecClass);\n        \n        if (codecList !\u003d null) {\n          synchronized (codecList) {\n            if (!codecList.isEmpty()) {\n              codec \u003d codecList.remove(codecList.size()-1);\n            }\n          }\n        }\n      }\n    }\n    \n    return codec;\n  }",
      "path": "hadoop-common/src/main/java/org/apache/hadoop/io/compress/CodecPool.java",
      "extendedDetails": {
        "oldPath": "common/src/java/org/apache/hadoop/io/compress/CodecPool.java",
        "newPath": "hadoop-common/src/main/java/org/apache/hadoop/io/compress/CodecPool.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "11/06/11 9:13 PM",
      "commitNameOld": "a285fb5effe9ba3be4ec5f942afaf5ddd1186151",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private static \u003cT\u003e T borrow(Map\u003cClass\u003cT\u003e, List\u003cT\u003e\u003e pool,\n                             Class\u003c? extends T\u003e codecClass) {\n    T codec \u003d null;\n    \n    // Check if an appropriate codec is available\n    synchronized (pool) {\n      if (pool.containsKey(codecClass)) {\n        List\u003cT\u003e codecList \u003d pool.get(codecClass);\n        \n        if (codecList !\u003d null) {\n          synchronized (codecList) {\n            if (!codecList.isEmpty()) {\n              codec \u003d codecList.remove(codecList.size()-1);\n            }\n          }\n        }\n      }\n    }\n    \n    return codec;\n  }",
      "path": "common/src/java/org/apache/hadoop/io/compress/CodecPool.java",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/hadoop/io/compress/CodecPool.java",
        "newPath": "common/src/java/org/apache/hadoop/io/compress/CodecPool.java"
      }
    },
    "5128a9a453d64bfe1ed978cf9ffed27985eeef36": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-4687 Moving src directories on branch\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/core/branches/HADOOP-4687/core@776174 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/05/09 9:20 PM",
      "commitName": "5128a9a453d64bfe1ed978cf9ffed27985eeef36",
      "commitAuthor": "Owen O\u0027Malley",
      "diff": "@@ -0,0 +1,21 @@\n+  private static \u003cT\u003e T borrow(Map\u003cClass\u003cT\u003e, List\u003cT\u003e\u003e pool,\n+                             Class\u003c? extends T\u003e codecClass) {\n+    T codec \u003d null;\n+    \n+    // Check if an appropriate codec is available\n+    synchronized (pool) {\n+      if (pool.containsKey(codecClass)) {\n+        List\u003cT\u003e codecList \u003d pool.get(codecClass);\n+        \n+        if (codecList !\u003d null) {\n+          synchronized (codecList) {\n+            if (!codecList.isEmpty()) {\n+              codec \u003d codecList.remove(codecList.size()-1);\n+            }\n+          }\n+        }\n+      }\n+    }\n+    \n+    return codec;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static \u003cT\u003e T borrow(Map\u003cClass\u003cT\u003e, List\u003cT\u003e\u003e pool,\n                             Class\u003c? extends T\u003e codecClass) {\n    T codec \u003d null;\n    \n    // Check if an appropriate codec is available\n    synchronized (pool) {\n      if (pool.containsKey(codecClass)) {\n        List\u003cT\u003e codecList \u003d pool.get(codecClass);\n        \n        if (codecList !\u003d null) {\n          synchronized (codecList) {\n            if (!codecList.isEmpty()) {\n              codec \u003d codecList.remove(codecList.size()-1);\n            }\n          }\n        }\n      }\n    }\n    \n    return codec;\n  }",
      "path": "src/java/org/apache/hadoop/io/compress/CodecPool.java"
    }
  }
}