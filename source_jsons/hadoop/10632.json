{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockChecksumHelper.java",
  "functionName": "checksumPartialBlock",
  "functionId": "checksumPartialBlock",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockChecksumHelper.java",
  "functionStartLine": 335,
  "functionEndLine": 356,
  "numCommitsSeen": 8,
  "timeTaken": 1033,
  "changeHistory": [
    "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6"
  ],
  "changeHistoryShort": {
    "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6": "Yintroduced"
  },
  "changeHistoryDetails": {
    "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9733. Refactor DFSClient#getFileChecksum and DataXceiver#blockChecksum. Contributed by Kai Zheng\n",
      "commitDate": "29/02/16 9:52 PM",
      "commitName": "307ec80acae3b4a41d21b2d4b3a55032e55fcdc6",
      "commitAuthor": "Uma Maheswara Rao G",
      "diff": "@@ -0,0 +1,22 @@\n+    private MD5Hash checksumPartialBlock() throws IOException {\n+      byte[] buffer \u003d new byte[4*1024];\n+      MessageDigest digester \u003d MD5Hash.getDigester();\n+\n+      long remaining \u003d (getRequestLength() / getBytesPerCRC())\n+          * getChecksumSize();\n+      for (int toDigest \u003d 0; remaining \u003e 0; remaining -\u003d toDigest) {\n+        toDigest \u003d getChecksumIn().read(buffer, 0,\n+            (int) Math.min(remaining, buffer.length));\n+        if (toDigest \u003c 0) {\n+          break;\n+        }\n+        digester.update(buffer, 0, toDigest);\n+      }\n+\n+      byte[] partialCrc \u003d crcPartialBlock();\n+      if (partialCrc !\u003d null) {\n+        digester.update(partialCrc);\n+      }\n+\n+      return new MD5Hash(digester.digest());\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private MD5Hash checksumPartialBlock() throws IOException {\n      byte[] buffer \u003d new byte[4*1024];\n      MessageDigest digester \u003d MD5Hash.getDigester();\n\n      long remaining \u003d (getRequestLength() / getBytesPerCRC())\n          * getChecksumSize();\n      for (int toDigest \u003d 0; remaining \u003e 0; remaining -\u003d toDigest) {\n        toDigest \u003d getChecksumIn().read(buffer, 0,\n            (int) Math.min(remaining, buffer.length));\n        if (toDigest \u003c 0) {\n          break;\n        }\n        digester.update(buffer, 0, toDigest);\n      }\n\n      byte[] partialCrc \u003d crcPartialBlock();\n      if (partialCrc !\u003d null) {\n        digester.update(partialCrc);\n      }\n\n      return new MD5Hash(digester.digest());\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockChecksumHelper.java"
    }
  }
}