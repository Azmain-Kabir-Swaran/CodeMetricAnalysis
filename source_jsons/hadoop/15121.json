{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "OfflineImageReconstructor.java",
  "functionName": "writeStringTableSection",
  "functionId": "writeStringTableSection",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/OfflineImageReconstructor.java",
  "functionStartLine": 1719,
  "functionEndLine": 1744,
  "numCommitsSeen": 15,
  "timeTaken": 1134,
  "changeHistory": [
    "700b0e4019cf483f7532609711812150b8c44742"
  ],
  "changeHistoryShort": {
    "700b0e4019cf483f7532609711812150b8c44742": "Yintroduced"
  },
  "changeHistoryDetails": {
    "700b0e4019cf483f7532609711812150b8c44742": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9835. OIV: add ReverseXML processor which reconstructs an fsimage from an XML file (cmccabe)\n",
      "commitDate": "02/03/16 5:56 PM",
      "commitName": "700b0e4019cf483f7532609711812150b8c44742",
      "commitAuthor": "Colin Patrick Mccabe",
      "diff": "@@ -0,0 +1,26 @@\n+  private void writeStringTableSection() throws IOException {\n+    FsImageProto.StringTableSection sectionHeader \u003d\n+        FsImageProto.StringTableSection.newBuilder().\n+        setNumEntry(stringTable.size()).build();\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(SectionName.STRING_TABLE.name() + \" writing header: {\" +\n+            TextFormat.printToString(sectionHeader) + \"}\");\n+    }\n+    sectionHeader.writeDelimitedTo(out);\n+\n+    // The entries don\u0027t have to be in any particular order, so iterating\n+    // over the hash table is fine.\n+    for (Map.Entry\u003cString, Integer\u003e entry : stringTable.entrySet()) {\n+      FsImageProto.StringTableSection.Entry stEntry \u003d\n+          FsImageProto.StringTableSection.Entry.newBuilder().\n+          setStr(entry.getKey()).\n+          setId(entry.getValue()).\n+          build();\n+      if (LOG.isTraceEnabled()) {\n+        LOG.trace(\"Writing string table entry: {\" +\n+            TextFormat.printToString(stEntry) + \"}\");\n+      }\n+      stEntry.writeDelimitedTo(out);\n+    }\n+    recordSectionLength(SectionName.STRING_TABLE.name());\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void writeStringTableSection() throws IOException {\n    FsImageProto.StringTableSection sectionHeader \u003d\n        FsImageProto.StringTableSection.newBuilder().\n        setNumEntry(stringTable.size()).build();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(SectionName.STRING_TABLE.name() + \" writing header: {\" +\n            TextFormat.printToString(sectionHeader) + \"}\");\n    }\n    sectionHeader.writeDelimitedTo(out);\n\n    // The entries don\u0027t have to be in any particular order, so iterating\n    // over the hash table is fine.\n    for (Map.Entry\u003cString, Integer\u003e entry : stringTable.entrySet()) {\n      FsImageProto.StringTableSection.Entry stEntry \u003d\n          FsImageProto.StringTableSection.Entry.newBuilder().\n          setStr(entry.getKey()).\n          setId(entry.getValue()).\n          build();\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"Writing string table entry: {\" +\n            TextFormat.printToString(stEntry) + \"}\");\n      }\n      stEntry.writeDelimitedTo(out);\n    }\n    recordSectionLength(SectionName.STRING_TABLE.name());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/OfflineImageReconstructor.java"
    }
  }
}