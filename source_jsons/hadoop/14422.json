{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Journal.java",
  "functionName": "getSegmentInfo",
  "functionId": "getSegmentInfo___segmentTxId-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
  "functionStartLine": 786,
  "functionEndLine": 809,
  "numCommitsSeen": 64,
  "timeTaken": 3210,
  "changeHistory": [
    "6beb25ab7e4f5454dba0315a296081e61753f301",
    "53bad4eb008ec553dcdbe01e7ae975dcecde6590",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
    "9dab514b22f49322738935cfd915c2b4eba50b88",
    "83c14fbd24353b5e882f065faec81e58449afed3",
    "c95a1674b61ef2a6963dc64604986ef90a8c636d",
    "74d4573a23db5586c6e47ff2277aa7c35237da34"
  ],
  "changeHistoryShort": {
    "6beb25ab7e4f5454dba0315a296081e61753f301": "Ybodychange",
    "53bad4eb008ec553dcdbe01e7ae975dcecde6590": "Ybodychange",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": "Ybodychange",
    "9dab514b22f49322738935cfd915c2b4eba50b88": "Ymultichange(Ymodifierchange,Ybodychange)",
    "83c14fbd24353b5e882f065faec81e58449afed3": "Ybodychange",
    "c95a1674b61ef2a6963dc64604986ef90a8c636d": "Ybodychange",
    "74d4573a23db5586c6e47ff2277aa7c35237da34": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6beb25ab7e4f5454dba0315a296081e61753f301": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13544. Improve logging for JournalNode in federated cluster.\n",
      "commitDate": "14/05/18 10:12 AM",
      "commitName": "6beb25ab7e4f5454dba0315a296081e61753f301",
      "commitAuthor": "Hanisha Koneru",
      "commitDateOld": "13/10/17 2:22 PM",
      "commitNameOld": "8dd1eeb94fef59feaf19182dd8f1fcf1389c7f34",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 212.83,
      "commitsBetweenForRepo": 2051,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   SegmentStateProto getSegmentInfo(long segmentTxId)\n       throws IOException {\n     EditLogFile elf \u003d fjm.getLogFile(segmentTxId);\n     if (elf \u003d\u003d null) {\n       return null;\n     }\n     if (elf.isInProgress()) {\n       elf.scanLog(Long.MAX_VALUE, false);\n     }\n     if (elf.getLastTxId() \u003d\u003d HdfsServerConstants.INVALID_TXID) {\n       LOG.info(\"Edit log file \" + elf + \" appears to be empty. \" +\n-          \"Moving it aside...\");\n+          \"Moving it aside...\" + \" ; journal id: \" + journalId);\n       elf.moveAsideEmptyFile();\n       return null;\n     }\n     SegmentStateProto ret \u003d SegmentStateProto.newBuilder()\n         .setStartTxId(segmentTxId)\n         .setEndTxId(elf.getLastTxId())\n         .setIsInProgress(elf.isInProgress())\n         .build();\n     LOG.info(\"getSegmentInfo(\" + segmentTxId + \"): \" + elf + \" -\u003e \" +\n-        TextFormat.shortDebugString(ret));\n+        TextFormat.shortDebugString(ret) + \" ; journal id: \" + journalId);\n     return ret;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  SegmentStateProto getSegmentInfo(long segmentTxId)\n      throws IOException {\n    EditLogFile elf \u003d fjm.getLogFile(segmentTxId);\n    if (elf \u003d\u003d null) {\n      return null;\n    }\n    if (elf.isInProgress()) {\n      elf.scanLog(Long.MAX_VALUE, false);\n    }\n    if (elf.getLastTxId() \u003d\u003d HdfsServerConstants.INVALID_TXID) {\n      LOG.info(\"Edit log file \" + elf + \" appears to be empty. \" +\n          \"Moving it aside...\" + \" ; journal id: \" + journalId);\n      elf.moveAsideEmptyFile();\n      return null;\n    }\n    SegmentStateProto ret \u003d SegmentStateProto.newBuilder()\n        .setStartTxId(segmentTxId)\n        .setEndTxId(elf.getLastTxId())\n        .setIsInProgress(elf.isInProgress())\n        .build();\n    LOG.info(\"getSegmentInfo(\" + segmentTxId + \"): \" + elf + \" -\u003e \" +\n        TextFormat.shortDebugString(ret) + \" ; journal id: \" + journalId);\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "53bad4eb008ec553dcdbe01e7ae975dcecde6590": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8996. Consolidate validateLog and scanLog in FJM#EditLogFile (Zhe Zhang via Colin P. McCabe)\n",
      "commitDate": "14/09/15 3:22 PM",
      "commitName": "53bad4eb008ec553dcdbe01e7ae975dcecde6590",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "08/09/15 10:33 PM",
      "commitNameOld": "94cf7ab9d28a885181afeb2c181dfe857d158254",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 5.7,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   SegmentStateProto getSegmentInfo(long segmentTxId)\n       throws IOException {\n     EditLogFile elf \u003d fjm.getLogFile(segmentTxId);\n     if (elf \u003d\u003d null) {\n       return null;\n     }\n     if (elf.isInProgress()) {\n-      elf.scanLog();\n+      elf.scanLog(Long.MAX_VALUE, false);\n     }\n     if (elf.getLastTxId() \u003d\u003d HdfsServerConstants.INVALID_TXID) {\n       LOG.info(\"Edit log file \" + elf + \" appears to be empty. \" +\n           \"Moving it aside...\");\n       elf.moveAsideEmptyFile();\n       return null;\n     }\n     SegmentStateProto ret \u003d SegmentStateProto.newBuilder()\n         .setStartTxId(segmentTxId)\n         .setEndTxId(elf.getLastTxId())\n         .setIsInProgress(elf.isInProgress())\n         .build();\n     LOG.info(\"getSegmentInfo(\" + segmentTxId + \"): \" + elf + \" -\u003e \" +\n         TextFormat.shortDebugString(ret));\n     return ret;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  SegmentStateProto getSegmentInfo(long segmentTxId)\n      throws IOException {\n    EditLogFile elf \u003d fjm.getLogFile(segmentTxId);\n    if (elf \u003d\u003d null) {\n      return null;\n    }\n    if (elf.isInProgress()) {\n      elf.scanLog(Long.MAX_VALUE, false);\n    }\n    if (elf.getLastTxId() \u003d\u003d HdfsServerConstants.INVALID_TXID) {\n      LOG.info(\"Edit log file \" + elf + \" appears to be empty. \" +\n          \"Moving it aside...\");\n      elf.moveAsideEmptyFile();\n      return null;\n    }\n    SegmentStateProto ret \u003d SegmentStateProto.newBuilder()\n        .setStartTxId(segmentTxId)\n        .setEndTxId(elf.getLastTxId())\n        .setIsInProgress(elf.isInProgress())\n        .build();\n    LOG.info(\"getSegmentInfo(\" + segmentTxId + \"): \" + elf + \" -\u003e \" +\n        TextFormat.shortDebugString(ret));\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8249. Separate HdfsConstants into the client and the server side class. Contributed by Haohui Mai.\n",
      "commitDate": "02/05/15 10:03 AM",
      "commitName": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "08/01/15 4:09 PM",
      "commitNameOld": "ae91b13a4b1896b893268253104f935c3078d345",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 113.7,
      "commitsBetweenForRepo": 1004,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   SegmentStateProto getSegmentInfo(long segmentTxId)\n       throws IOException {\n     EditLogFile elf \u003d fjm.getLogFile(segmentTxId);\n     if (elf \u003d\u003d null) {\n       return null;\n     }\n     if (elf.isInProgress()) {\n       elf.scanLog();\n     }\n-    if (elf.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n+    if (elf.getLastTxId() \u003d\u003d HdfsServerConstants.INVALID_TXID) {\n       LOG.info(\"Edit log file \" + elf + \" appears to be empty. \" +\n           \"Moving it aside...\");\n       elf.moveAsideEmptyFile();\n       return null;\n     }\n     SegmentStateProto ret \u003d SegmentStateProto.newBuilder()\n         .setStartTxId(segmentTxId)\n         .setEndTxId(elf.getLastTxId())\n         .setIsInProgress(elf.isInProgress())\n         .build();\n     LOG.info(\"getSegmentInfo(\" + segmentTxId + \"): \" + elf + \" -\u003e \" +\n         TextFormat.shortDebugString(ret));\n     return ret;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  SegmentStateProto getSegmentInfo(long segmentTxId)\n      throws IOException {\n    EditLogFile elf \u003d fjm.getLogFile(segmentTxId);\n    if (elf \u003d\u003d null) {\n      return null;\n    }\n    if (elf.isInProgress()) {\n      elf.scanLog();\n    }\n    if (elf.getLastTxId() \u003d\u003d HdfsServerConstants.INVALID_TXID) {\n      LOG.info(\"Edit log file \" + elf + \" appears to be empty. \" +\n          \"Moving it aside...\");\n      elf.moveAsideEmptyFile();\n      return null;\n    }\n    SegmentStateProto ret \u003d SegmentStateProto.newBuilder()\n        .setStartTxId(segmentTxId)\n        .setEndTxId(elf.getLastTxId())\n        .setIsInProgress(elf.isInProgress())\n        .build();\n    LOG.info(\"getSegmentInfo(\" + segmentTxId + \"): \" + elf + \" -\u003e \" +\n        TextFormat.shortDebugString(ret));\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "9dab514b22f49322738935cfd915c2b4eba50b88": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-6038. Allow JournalNode to handle editlog produced by new release with future layoutversion. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1579813 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/03/14 4:06 PM",
      "commitName": "9dab514b22f49322738935cfd915c2b4eba50b88",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-6038. Allow JournalNode to handle editlog produced by new release with future layoutversion. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1579813 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/03/14 4:06 PM",
          "commitName": "9dab514b22f49322738935cfd915c2b4eba50b88",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "20/02/14 3:21 PM",
          "commitNameOld": "329c7051817c956bfc64661f4e1349b7009a2747",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 27.99,
          "commitsBetweenForRepo": 248,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,24 @@\n-  private SegmentStateProto getSegmentInfo(long segmentTxId)\n+  SegmentStateProto getSegmentInfo(long segmentTxId)\n       throws IOException {\n     EditLogFile elf \u003d fjm.getLogFile(segmentTxId);\n     if (elf \u003d\u003d null) {\n       return null;\n     }\n     if (elf.isInProgress()) {\n-      elf.validateLog();\n+      elf.scanLog();\n     }\n     if (elf.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n       LOG.info(\"Edit log file \" + elf + \" appears to be empty. \" +\n           \"Moving it aside...\");\n       elf.moveAsideEmptyFile();\n       return null;\n     }\n     SegmentStateProto ret \u003d SegmentStateProto.newBuilder()\n         .setStartTxId(segmentTxId)\n         .setEndTxId(elf.getLastTxId())\n         .setIsInProgress(elf.isInProgress())\n         .build();\n     LOG.info(\"getSegmentInfo(\" + segmentTxId + \"): \" + elf + \" -\u003e \" +\n         TextFormat.shortDebugString(ret));\n     return ret;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  SegmentStateProto getSegmentInfo(long segmentTxId)\n      throws IOException {\n    EditLogFile elf \u003d fjm.getLogFile(segmentTxId);\n    if (elf \u003d\u003d null) {\n      return null;\n    }\n    if (elf.isInProgress()) {\n      elf.scanLog();\n    }\n    if (elf.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n      LOG.info(\"Edit log file \" + elf + \" appears to be empty. \" +\n          \"Moving it aside...\");\n      elf.moveAsideEmptyFile();\n      return null;\n    }\n    SegmentStateProto ret \u003d SegmentStateProto.newBuilder()\n        .setStartTxId(segmentTxId)\n        .setEndTxId(elf.getLastTxId())\n        .setIsInProgress(elf.isInProgress())\n        .build();\n    LOG.info(\"getSegmentInfo(\" + segmentTxId + \"): \" + elf + \" -\u003e \" +\n        TextFormat.shortDebugString(ret));\n    return ret;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6038. Allow JournalNode to handle editlog produced by new release with future layoutversion. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1579813 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "20/03/14 4:06 PM",
          "commitName": "9dab514b22f49322738935cfd915c2b4eba50b88",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "20/02/14 3:21 PM",
          "commitNameOld": "329c7051817c956bfc64661f4e1349b7009a2747",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 27.99,
          "commitsBetweenForRepo": 248,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,24 @@\n-  private SegmentStateProto getSegmentInfo(long segmentTxId)\n+  SegmentStateProto getSegmentInfo(long segmentTxId)\n       throws IOException {\n     EditLogFile elf \u003d fjm.getLogFile(segmentTxId);\n     if (elf \u003d\u003d null) {\n       return null;\n     }\n     if (elf.isInProgress()) {\n-      elf.validateLog();\n+      elf.scanLog();\n     }\n     if (elf.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n       LOG.info(\"Edit log file \" + elf + \" appears to be empty. \" +\n           \"Moving it aside...\");\n       elf.moveAsideEmptyFile();\n       return null;\n     }\n     SegmentStateProto ret \u003d SegmentStateProto.newBuilder()\n         .setStartTxId(segmentTxId)\n         .setEndTxId(elf.getLastTxId())\n         .setIsInProgress(elf.isInProgress())\n         .build();\n     LOG.info(\"getSegmentInfo(\" + segmentTxId + \"): \" + elf + \" -\u003e \" +\n         TextFormat.shortDebugString(ret));\n     return ret;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  SegmentStateProto getSegmentInfo(long segmentTxId)\n      throws IOException {\n    EditLogFile elf \u003d fjm.getLogFile(segmentTxId);\n    if (elf \u003d\u003d null) {\n      return null;\n    }\n    if (elf.isInProgress()) {\n      elf.scanLog();\n    }\n    if (elf.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n      LOG.info(\"Edit log file \" + elf + \" appears to be empty. \" +\n          \"Moving it aside...\");\n      elf.moveAsideEmptyFile();\n      return null;\n    }\n    SegmentStateProto ret \u003d SegmentStateProto.newBuilder()\n        .setStartTxId(segmentTxId)\n        .setEndTxId(elf.getLastTxId())\n        .setIsInProgress(elf.isInProgress())\n        .build();\n    LOG.info(\"getSegmentInfo(\" + segmentTxId + \"): \" + elf + \" -\u003e \" +\n        TextFormat.shortDebugString(ret));\n    return ret;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
          "extendedDetails": {}
        }
      ]
    },
    "83c14fbd24353b5e882f065faec81e58449afed3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3943. QJM: remove currently-unused md5sum field. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1386863 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/09/12 2:51 PM",
      "commitName": "83c14fbd24353b5e882f065faec81e58449afed3",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "10/09/12 11:33 PM",
      "commitNameOld": "a93ba1648ac78ae0ad9e7c75c35e8594d8c48af4",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 6.64,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,24 @@\n   private SegmentStateProto getSegmentInfo(long segmentTxId)\n       throws IOException {\n     EditLogFile elf \u003d fjm.getLogFile(segmentTxId);\n     if (elf \u003d\u003d null) {\n       return null;\n     }\n     if (elf.isInProgress()) {\n       elf.validateLog();\n     }\n     if (elf.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n       LOG.info(\"Edit log file \" + elf + \" appears to be empty. \" +\n           \"Moving it aside...\");\n       elf.moveAsideEmptyFile();\n       return null;\n     }\n     SegmentStateProto ret \u003d SegmentStateProto.newBuilder()\n         .setStartTxId(segmentTxId)\n         .setEndTxId(elf.getLastTxId())\n         .setIsInProgress(elf.isInProgress())\n-        .setMd5Sum(ByteString.EMPTY) // TODO\n         .build();\n     LOG.info(\"getSegmentInfo(\" + segmentTxId + \"): \" + elf + \" -\u003e \" +\n         TextFormat.shortDebugString(ret));\n     return ret;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private SegmentStateProto getSegmentInfo(long segmentTxId)\n      throws IOException {\n    EditLogFile elf \u003d fjm.getLogFile(segmentTxId);\n    if (elf \u003d\u003d null) {\n      return null;\n    }\n    if (elf.isInProgress()) {\n      elf.validateLog();\n    }\n    if (elf.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n      LOG.info(\"Edit log file \" + elf + \" appears to be empty. \" +\n          \"Moving it aside...\");\n      elf.moveAsideEmptyFile();\n      return null;\n    }\n    SegmentStateProto ret \u003d SegmentStateProto.newBuilder()\n        .setStartTxId(segmentTxId)\n        .setEndTxId(elf.getLastTxId())\n        .setIsInProgress(elf.isInProgress())\n        .build();\n    LOG.info(\"getSegmentInfo(\" + segmentTxId + \"): \" + elf + \" -\u003e \" +\n        TextFormat.shortDebugString(ret));\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "c95a1674b61ef2a6963dc64604986ef90a8c636d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3799. QJM: handle empty log segments during recovery. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1373183 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/08/12 5:57 PM",
      "commitName": "c95a1674b61ef2a6963dc64604986ef90a8c636d",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "14/08/12 5:54 PM",
      "commitNameOld": "4a9b3c693def87579298fb59b7df0b8892a3508e",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,25 @@\n   private SegmentStateProto getSegmentInfo(long segmentTxId)\n       throws IOException {\n     EditLogFile elf \u003d fjm.getLogFile(segmentTxId);\n     if (elf \u003d\u003d null) {\n       return null;\n     }\n     if (elf.isInProgress()) {\n       elf.validateLog();\n     }\n     if (elf.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n-      // no transactions in file\n-      throw new AssertionError(\"TODO: no transactions in file \" +\n-          elf);\n+      LOG.info(\"Edit log file \" + elf + \" appears to be empty. \" +\n+          \"Moving it aside...\");\n+      elf.moveAsideEmptyFile();\n+      return null;\n     }\n     SegmentStateProto ret \u003d SegmentStateProto.newBuilder()\n         .setStartTxId(segmentTxId)\n         .setEndTxId(elf.getLastTxId())\n         .setIsInProgress(elf.isInProgress())\n         .setMd5Sum(ByteString.EMPTY) // TODO\n         .build();\n     LOG.info(\"getSegmentInfo(\" + segmentTxId + \"): \" + elf + \" -\u003e \" +\n         TextFormat.shortDebugString(ret));\n     return ret;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private SegmentStateProto getSegmentInfo(long segmentTxId)\n      throws IOException {\n    EditLogFile elf \u003d fjm.getLogFile(segmentTxId);\n    if (elf \u003d\u003d null) {\n      return null;\n    }\n    if (elf.isInProgress()) {\n      elf.validateLog();\n    }\n    if (elf.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n      LOG.info(\"Edit log file \" + elf + \" appears to be empty. \" +\n          \"Moving it aside...\");\n      elf.moveAsideEmptyFile();\n      return null;\n    }\n    SegmentStateProto ret \u003d SegmentStateProto.newBuilder()\n        .setStartTxId(segmentTxId)\n        .setEndTxId(elf.getLastTxId())\n        .setIsInProgress(elf.isInProgress())\n        .setMd5Sum(ByteString.EMPTY) // TODO\n        .build();\n    LOG.info(\"getSegmentInfo(\" + segmentTxId + \"): \" + elf + \" -\u003e \" +\n        TextFormat.shortDebugString(ret));\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java",
      "extendedDetails": {}
    },
    "74d4573a23db5586c6e47ff2277aa7c35237da34": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1363596 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/07/12 5:25 PM",
      "commitName": "74d4573a23db5586c6e47ff2277aa7c35237da34",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,24 @@\n+  private SegmentStateProto getSegmentInfo(long segmentTxId)\n+      throws IOException {\n+    EditLogFile elf \u003d fjm.getLogFile(segmentTxId);\n+    if (elf \u003d\u003d null) {\n+      return null;\n+    }\n+    if (elf.isInProgress()) {\n+      elf.validateLog();\n+    }\n+    if (elf.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n+      // no transactions in file\n+      throw new AssertionError(\"TODO: no transactions in file \" +\n+          elf);\n+    }\n+    SegmentStateProto ret \u003d SegmentStateProto.newBuilder()\n+        .setStartTxId(segmentTxId)\n+        .setEndTxId(elf.getLastTxId())\n+        .setIsInProgress(elf.isInProgress())\n+        .setMd5Sum(ByteString.EMPTY) // TODO\n+        .build();\n+    LOG.info(\"getSegmentInfo(\" + segmentTxId + \"): \" + elf + \" -\u003e \" +\n+        TextFormat.shortDebugString(ret));\n+    return ret;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private SegmentStateProto getSegmentInfo(long segmentTxId)\n      throws IOException {\n    EditLogFile elf \u003d fjm.getLogFile(segmentTxId);\n    if (elf \u003d\u003d null) {\n      return null;\n    }\n    if (elf.isInProgress()) {\n      elf.validateLog();\n    }\n    if (elf.getLastTxId() \u003d\u003d HdfsConstants.INVALID_TXID) {\n      // no transactions in file\n      throw new AssertionError(\"TODO: no transactions in file \" +\n          elf);\n    }\n    SegmentStateProto ret \u003d SegmentStateProto.newBuilder()\n        .setStartTxId(segmentTxId)\n        .setEndTxId(elf.getLastTxId())\n        .setIsInProgress(elf.isInProgress())\n        .setMd5Sum(ByteString.EMPTY) // TODO\n        .build();\n    LOG.info(\"getSegmentInfo(\" + segmentTxId + \"): \" + elf + \" -\u003e \" +\n        TextFormat.shortDebugString(ret));\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/Journal.java"
    }
  }
}