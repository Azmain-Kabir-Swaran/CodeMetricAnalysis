{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "OpenFileCtx.java",
  "functionName": "cleanup",
  "functionId": "cleanup",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
  "functionStartLine": 1218,
  "functionEndLine": 1282,
  "numCommitsSeen": 105,
  "timeTaken": 4665,
  "changeHistory": [
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
    "7b1fa5693efc687492776d43ab482601cbb30dfd",
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
    "151fca5032719e561226ef278e002739073c23ec",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f",
    "d71d40a63d198991077d5babd70be5e9787a53f1",
    "875aa797caee96572162ff59bc50cf97d1195348",
    "3bfd18c6b0483ae27eff6d53bda934e67dda5464",
    "3fccdec6e0a8e9305fc75921211c3745eddb9c45",
    "28e3d09230971b32f74284311931525cb7ad1b7c",
    "5e18410e06dd63113c49029894007e0878312903",
    "a56a4b6ef06602312144783b7507bf2b82821e4f",
    "37f587563a943a827fbff865f5302bac6d202415"
  ],
  "changeHistoryShort": {
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568": "Yrename",
    "7b1fa5693efc687492776d43ab482601cbb30dfd": "Yrename",
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": "Ybodychange",
    "151fca5032719e561226ef278e002739073c23ec": "Ybodychange",
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": "Ybodychange",
    "d71d40a63d198991077d5babd70be5e9787a53f1": "Ybodychange",
    "875aa797caee96572162ff59bc50cf97d1195348": "Ybodychange",
    "3bfd18c6b0483ae27eff6d53bda934e67dda5464": "Ybodychange",
    "3fccdec6e0a8e9305fc75921211c3745eddb9c45": "Ymultichange(Ymodifierchange,Ybodychange)",
    "28e3d09230971b32f74284311931525cb7ad1b7c": "Ymultichange(Ymodifierchange,Ybodychange)",
    "5e18410e06dd63113c49029894007e0878312903": "Ybodychange",
    "a56a4b6ef06602312144783b7507bf2b82821e4f": "Ybodychange",
    "37f587563a943a827fbff865f5302bac6d202415": "Yintroduced"
  },
  "changeHistoryDetails": {
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568": {
      "type": "Yrename",
      "commitMessage": "HDFS-13695. Move logging to slf4j in HDFS package. Contributed by Ian Pickering.\n",
      "commitDate": "06/09/18 2:48 PM",
      "commitName": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "27/08/18 10:18 AM",
      "commitNameOld": "7b1fa5693efc687492776d43ab482601cbb30dfd",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 10.19,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,65 @@\n-  synchronized void cleanupWithLogger() {\n+  synchronized void cleanup() {\n     if (!activeState) {\n       LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n       return;\n     }\n     activeState \u003d false;\n \n     // stop the dump thread\n     if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n       dumpThread.interrupt();\n       try {\n         dumpThread.join(3000);\n       } catch (InterruptedException ignored) {\n       }\n     }\n     \n     // Close stream\n     try {\n       if (fos !\u003d null) {\n         fos.close();\n       }\n     } catch (IOException e) {\n       LOG.info(\"Can\u0027t close stream for fileId: {}, error: {}\",\n           latestAttr.getFileId(), e.toString());\n     }\n     \n     // Reply error for pending writes\n     LOG.info(\"There are {} pending writes.\", pendingWrites.size());\n     WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n     while (!pendingWrites.isEmpty()) {\n       OffsetRange key \u003d pendingWrites.firstKey();\n       LOG.info(\"Fail pending write: {}, nextOffset\u003d{}\", key, nextOffset.get());\n       \n       WriteCtx writeCtx \u003d pendingWrites.remove(key);\n       if (!writeCtx.getReplied()) {\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n             .serialize(new XDR(), writeCtx.getXid(),\n                 new VerifierNone()), writeCtx.getXid());\n       }\n     }\n     \n     // Cleanup dump file\n     if (dumpOut !\u003d null) {\n       try {\n         dumpOut.close();\n       } catch (IOException e) {\n         LOG.error(\"Failed to close outputstream of dump file {}\",\n             dumpFilePath, e);\n       }\n       File dumpFile \u003d new File(dumpFilePath);\n       if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n         LOG.error(\"Failed to delete dumpfile: {}\", dumpFile);\n       }\n     }\n     if (raf !\u003d null) {\n       try {\n         raf.close();\n       } catch (IOException e) {\n         LOG.error(\"Got exception when closing input stream of dump file.\", e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void cleanup() {\n    if (!activeState) {\n      LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n      return;\n    }\n    activeState \u003d false;\n\n    // stop the dump thread\n    if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n      dumpThread.interrupt();\n      try {\n        dumpThread.join(3000);\n      } catch (InterruptedException ignored) {\n      }\n    }\n    \n    // Close stream\n    try {\n      if (fos !\u003d null) {\n        fos.close();\n      }\n    } catch (IOException e) {\n      LOG.info(\"Can\u0027t close stream for fileId: {}, error: {}\",\n          latestAttr.getFileId(), e.toString());\n    }\n    \n    // Reply error for pending writes\n    LOG.info(\"There are {} pending writes.\", pendingWrites.size());\n    WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n    while (!pendingWrites.isEmpty()) {\n      OffsetRange key \u003d pendingWrites.firstKey();\n      LOG.info(\"Fail pending write: {}, nextOffset\u003d{}\", key, nextOffset.get());\n      \n      WriteCtx writeCtx \u003d pendingWrites.remove(key);\n      if (!writeCtx.getReplied()) {\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n            .serialize(new XDR(), writeCtx.getXid(),\n                new VerifierNone()), writeCtx.getXid());\n      }\n    }\n    \n    // Cleanup dump file\n    if (dumpOut !\u003d null) {\n      try {\n        dumpOut.close();\n      } catch (IOException e) {\n        LOG.error(\"Failed to close outputstream of dump file {}\",\n            dumpFilePath, e);\n      }\n      File dumpFile \u003d new File(dumpFilePath);\n      if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n        LOG.error(\"Failed to delete dumpfile: {}\", dumpFile);\n      }\n    }\n    if (raf !\u003d null) {\n      try {\n        raf.close();\n      } catch (IOException e) {\n        LOG.error(\"Got exception when closing input stream of dump file.\", e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {
        "oldValue": "cleanupWithLogger",
        "newValue": "cleanup"
      }
    },
    "7b1fa5693efc687492776d43ab482601cbb30dfd": {
      "type": "Yrename",
      "commitMessage": "HDFS-13849. Migrate logging to slf4j in hadoop-hdfs-httpfs, hadoop-hdfs-nfs, hadoop-hdfs-rbf, hadoop-hdfs-native-client. Contributed by Ian Pickering.\n",
      "commitDate": "27/08/18 10:18 AM",
      "commitName": "7b1fa5693efc687492776d43ab482601cbb30dfd",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "14/02/18 8:20 AM",
      "commitNameOld": "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 194.04,
      "commitsBetweenForRepo": 2013,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,65 @@\n-  synchronized void cleanup() {\n+  synchronized void cleanupWithLogger() {\n     if (!activeState) {\n       LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n       return;\n     }\n     activeState \u003d false;\n \n     // stop the dump thread\n     if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n       dumpThread.interrupt();\n       try {\n         dumpThread.join(3000);\n       } catch (InterruptedException ignored) {\n       }\n     }\n     \n     // Close stream\n     try {\n       if (fos !\u003d null) {\n         fos.close();\n       }\n     } catch (IOException e) {\n       LOG.info(\"Can\u0027t close stream for fileId: {}, error: {}\",\n           latestAttr.getFileId(), e.toString());\n     }\n     \n     // Reply error for pending writes\n     LOG.info(\"There are {} pending writes.\", pendingWrites.size());\n     WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n     while (!pendingWrites.isEmpty()) {\n       OffsetRange key \u003d pendingWrites.firstKey();\n       LOG.info(\"Fail pending write: {}, nextOffset\u003d{}\", key, nextOffset.get());\n       \n       WriteCtx writeCtx \u003d pendingWrites.remove(key);\n       if (!writeCtx.getReplied()) {\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n             .serialize(new XDR(), writeCtx.getXid(),\n                 new VerifierNone()), writeCtx.getXid());\n       }\n     }\n     \n     // Cleanup dump file\n     if (dumpOut !\u003d null) {\n       try {\n         dumpOut.close();\n       } catch (IOException e) {\n         LOG.error(\"Failed to close outputstream of dump file {}\",\n             dumpFilePath, e);\n       }\n       File dumpFile \u003d new File(dumpFilePath);\n       if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n         LOG.error(\"Failed to delete dumpfile: {}\", dumpFile);\n       }\n     }\n     if (raf !\u003d null) {\n       try {\n         raf.close();\n       } catch (IOException e) {\n         LOG.error(\"Got exception when closing input stream of dump file.\", e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void cleanupWithLogger() {\n    if (!activeState) {\n      LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n      return;\n    }\n    activeState \u003d false;\n\n    // stop the dump thread\n    if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n      dumpThread.interrupt();\n      try {\n        dumpThread.join(3000);\n      } catch (InterruptedException ignored) {\n      }\n    }\n    \n    // Close stream\n    try {\n      if (fos !\u003d null) {\n        fos.close();\n      }\n    } catch (IOException e) {\n      LOG.info(\"Can\u0027t close stream for fileId: {}, error: {}\",\n          latestAttr.getFileId(), e.toString());\n    }\n    \n    // Reply error for pending writes\n    LOG.info(\"There are {} pending writes.\", pendingWrites.size());\n    WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n    while (!pendingWrites.isEmpty()) {\n      OffsetRange key \u003d pendingWrites.firstKey();\n      LOG.info(\"Fail pending write: {}, nextOffset\u003d{}\", key, nextOffset.get());\n      \n      WriteCtx writeCtx \u003d pendingWrites.remove(key);\n      if (!writeCtx.getReplied()) {\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n            .serialize(new XDR(), writeCtx.getXid(),\n                new VerifierNone()), writeCtx.getXid());\n      }\n    }\n    \n    // Cleanup dump file\n    if (dumpOut !\u003d null) {\n      try {\n        dumpOut.close();\n      } catch (IOException e) {\n        LOG.error(\"Failed to close outputstream of dump file {}\",\n            dumpFilePath, e);\n      }\n      File dumpFile \u003d new File(dumpFilePath);\n      if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n        LOG.error(\"Failed to delete dumpfile: {}\", dumpFile);\n      }\n    }\n    if (raf !\u003d null) {\n      try {\n        raf.close();\n      } catch (IOException e) {\n        LOG.error(\"Got exception when closing input stream of dump file.\", e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {
        "oldValue": "cleanup",
        "newValue": "cleanupWithLogger"
      }
    },
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10571. Use Log.*(Object, Throwable) overload to log exceptions.\nContributed by Andras Bokor.\n",
      "commitDate": "14/02/18 8:20 AM",
      "commitName": "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "10/10/17 10:38 AM",
      "commitNameOld": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
      "commitAuthorOld": "Jitendra Pandey",
      "daysBetweenCommits": 126.95,
      "commitsBetweenForRepo": 833,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,65 @@\n   synchronized void cleanup() {\n     if (!activeState) {\n       LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n       return;\n     }\n     activeState \u003d false;\n \n     // stop the dump thread\n     if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n       dumpThread.interrupt();\n       try {\n         dumpThread.join(3000);\n       } catch (InterruptedException ignored) {\n       }\n     }\n     \n     // Close stream\n     try {\n       if (fos !\u003d null) {\n         fos.close();\n       }\n     } catch (IOException e) {\n-      LOG.info(\"Can\u0027t close stream for fileId: \" + latestAttr.getFileId()\n-          + \", error: \" + e);\n+      LOG.info(\"Can\u0027t close stream for fileId: {}, error: {}\",\n+          latestAttr.getFileId(), e.toString());\n     }\n     \n     // Reply error for pending writes\n-    LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n+    LOG.info(\"There are {} pending writes.\", pendingWrites.size());\n     WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n     while (!pendingWrites.isEmpty()) {\n       OffsetRange key \u003d pendingWrites.firstKey();\n-      LOG.info(\"Fail pending write: \" + key.toString()\n-          + \", nextOffset\u003d\" + nextOffset.get());\n+      LOG.info(\"Fail pending write: {}, nextOffset\u003d{}\", key, nextOffset.get());\n       \n       WriteCtx writeCtx \u003d pendingWrites.remove(key);\n       if (!writeCtx.getReplied()) {\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n             .serialize(new XDR(), writeCtx.getXid(),\n                 new VerifierNone()), writeCtx.getXid());\n       }\n     }\n     \n     // Cleanup dump file\n     if (dumpOut !\u003d null) {\n       try {\n         dumpOut.close();\n       } catch (IOException e) {\n-        LOG.error(\"Failed to close outputstream of dump file\" + dumpFilePath, e);\n+        LOG.error(\"Failed to close outputstream of dump file {}\",\n+            dumpFilePath, e);\n       }\n       File dumpFile \u003d new File(dumpFilePath);\n       if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n-        LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n+        LOG.error(\"Failed to delete dumpfile: {}\", dumpFile);\n       }\n     }\n     if (raf !\u003d null) {\n       try {\n         raf.close();\n       } catch (IOException e) {\n         LOG.error(\"Got exception when closing input stream of dump file.\", e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void cleanup() {\n    if (!activeState) {\n      LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n      return;\n    }\n    activeState \u003d false;\n\n    // stop the dump thread\n    if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n      dumpThread.interrupt();\n      try {\n        dumpThread.join(3000);\n      } catch (InterruptedException ignored) {\n      }\n    }\n    \n    // Close stream\n    try {\n      if (fos !\u003d null) {\n        fos.close();\n      }\n    } catch (IOException e) {\n      LOG.info(\"Can\u0027t close stream for fileId: {}, error: {}\",\n          latestAttr.getFileId(), e.toString());\n    }\n    \n    // Reply error for pending writes\n    LOG.info(\"There are {} pending writes.\", pendingWrites.size());\n    WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n    while (!pendingWrites.isEmpty()) {\n      OffsetRange key \u003d pendingWrites.firstKey();\n      LOG.info(\"Fail pending write: {}, nextOffset\u003d{}\", key, nextOffset.get());\n      \n      WriteCtx writeCtx \u003d pendingWrites.remove(key);\n      if (!writeCtx.getReplied()) {\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n            .serialize(new XDR(), writeCtx.getXid(),\n                new VerifierNone()), writeCtx.getXid());\n      }\n    }\n    \n    // Cleanup dump file\n    if (dumpOut !\u003d null) {\n      try {\n        dumpOut.close();\n      } catch (IOException e) {\n        LOG.error(\"Failed to close outputstream of dump file {}\",\n            dumpFilePath, e);\n      }\n      File dumpFile \u003d new File(dumpFilePath);\n      if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n        LOG.error(\"Failed to delete dumpfile: {}\", dumpFile);\n      }\n    }\n    if (raf !\u003d null) {\n      try {\n        raf.close();\n      } catch (IOException e) {\n        LOG.error(\"Got exception when closing input stream of dump file.\", e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "151fca5032719e561226ef278e002739073c23ec": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9092. Nfs silently drops overlapping write requests and causes data copying to fail. Contributed by Yongjun Zhang.\n",
      "commitDate": "28/09/15 6:45 PM",
      "commitName": "151fca5032719e561226ef278e002739073c23ec",
      "commitAuthor": "Yongjun Zhang",
      "commitDateOld": "28/01/15 12:56 PM",
      "commitNameOld": "f37849188b05a6251584de1aed5e66d5dfa7da4f",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 243.2,
      "commitsBetweenForRepo": 1923,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,65 @@\n   synchronized void cleanup() {\n     if (!activeState) {\n       LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n       return;\n     }\n     activeState \u003d false;\n \n     // stop the dump thread\n     if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n       dumpThread.interrupt();\n       try {\n         dumpThread.join(3000);\n       } catch (InterruptedException ignored) {\n       }\n     }\n     \n     // Close stream\n     try {\n       if (fos !\u003d null) {\n         fos.close();\n       }\n     } catch (IOException e) {\n       LOG.info(\"Can\u0027t close stream for fileId: \" + latestAttr.getFileId()\n           + \", error: \" + e);\n     }\n     \n     // Reply error for pending writes\n     LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n     WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n     while (!pendingWrites.isEmpty()) {\n       OffsetRange key \u003d pendingWrites.firstKey();\n-      LOG.info(\"Fail pending write: (\" + key.getMin() + \", \" + key.getMax()\n-          + \"), nextOffset\u003d\" + nextOffset.get());\n+      LOG.info(\"Fail pending write: \" + key.toString()\n+          + \", nextOffset\u003d\" + nextOffset.get());\n       \n       WriteCtx writeCtx \u003d pendingWrites.remove(key);\n       if (!writeCtx.getReplied()) {\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n             .serialize(new XDR(), writeCtx.getXid(),\n                 new VerifierNone()), writeCtx.getXid());\n       }\n     }\n     \n     // Cleanup dump file\n     if (dumpOut !\u003d null) {\n       try {\n         dumpOut.close();\n       } catch (IOException e) {\n         LOG.error(\"Failed to close outputstream of dump file\" + dumpFilePath, e);\n       }\n       File dumpFile \u003d new File(dumpFilePath);\n       if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n         LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n       }\n     }\n     if (raf !\u003d null) {\n       try {\n         raf.close();\n       } catch (IOException e) {\n         LOG.error(\"Got exception when closing input stream of dump file.\", e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void cleanup() {\n    if (!activeState) {\n      LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n      return;\n    }\n    activeState \u003d false;\n\n    // stop the dump thread\n    if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n      dumpThread.interrupt();\n      try {\n        dumpThread.join(3000);\n      } catch (InterruptedException ignored) {\n      }\n    }\n    \n    // Close stream\n    try {\n      if (fos !\u003d null) {\n        fos.close();\n      }\n    } catch (IOException e) {\n      LOG.info(\"Can\u0027t close stream for fileId: \" + latestAttr.getFileId()\n          + \", error: \" + e);\n    }\n    \n    // Reply error for pending writes\n    LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n    WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n    while (!pendingWrites.isEmpty()) {\n      OffsetRange key \u003d pendingWrites.firstKey();\n      LOG.info(\"Fail pending write: \" + key.toString()\n          + \", nextOffset\u003d\" + nextOffset.get());\n      \n      WriteCtx writeCtx \u003d pendingWrites.remove(key);\n      if (!writeCtx.getReplied()) {\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n            .serialize(new XDR(), writeCtx.getXid(),\n                new VerifierNone()), writeCtx.getXid());\n      }\n    }\n    \n    // Cleanup dump file\n    if (dumpOut !\u003d null) {\n      try {\n        dumpOut.close();\n      } catch (IOException e) {\n        LOG.error(\"Failed to close outputstream of dump file\" + dumpFilePath, e);\n      }\n      File dumpFile \u003d new File(dumpFilePath);\n      if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n        LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n      }\n    }\n    if (raf !\u003d null) {\n      try {\n        raf.close();\n      } catch (IOException e) {\n        LOG.error(\"Got exception when closing input stream of dump file.\", e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "f37849188b05a6251584de1aed5e66d5dfa7da4f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7423. various typos and message formatting fixes in nfs daemon and doc. (Charles Lamb via yliu)\n",
      "commitDate": "28/01/15 12:56 PM",
      "commitName": "f37849188b05a6251584de1aed5e66d5dfa7da4f",
      "commitAuthor": "yliu",
      "commitDateOld": "11/12/14 3:40 PM",
      "commitNameOld": "f6f2a3f1c73266bfedd802eacde60d8b19b81015",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 47.89,
      "commitsBetweenForRepo": 279,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,65 @@\n   synchronized void cleanup() {\n     if (!activeState) {\n       LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n       return;\n     }\n     activeState \u003d false;\n \n     // stop the dump thread\n     if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n       dumpThread.interrupt();\n       try {\n         dumpThread.join(3000);\n       } catch (InterruptedException ignored) {\n       }\n     }\n     \n     // Close stream\n     try {\n       if (fos !\u003d null) {\n         fos.close();\n       }\n     } catch (IOException e) {\n-      LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileId()\n-          + \", error:\" + e);\n+      LOG.info(\"Can\u0027t close stream for fileId: \" + latestAttr.getFileId()\n+          + \", error: \" + e);\n     }\n     \n     // Reply error for pending writes\n     LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n     WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n     while (!pendingWrites.isEmpty()) {\n       OffsetRange key \u003d pendingWrites.firstKey();\n-      LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n+      LOG.info(\"Fail pending write: (\" + key.getMin() + \", \" + key.getMax()\n           + \"), nextOffset\u003d\" + nextOffset.get());\n       \n       WriteCtx writeCtx \u003d pendingWrites.remove(key);\n       if (!writeCtx.getReplied()) {\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n             .serialize(new XDR(), writeCtx.getXid(),\n                 new VerifierNone()), writeCtx.getXid());\n       }\n     }\n     \n     // Cleanup dump file\n     if (dumpOut !\u003d null) {\n       try {\n         dumpOut.close();\n       } catch (IOException e) {\n         LOG.error(\"Failed to close outputstream of dump file\" + dumpFilePath, e);\n       }\n       File dumpFile \u003d new File(dumpFilePath);\n       if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n         LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n       }\n     }\n     if (raf !\u003d null) {\n       try {\n         raf.close();\n       } catch (IOException e) {\n         LOG.error(\"Got exception when closing input stream of dump file.\", e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void cleanup() {\n    if (!activeState) {\n      LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n      return;\n    }\n    activeState \u003d false;\n\n    // stop the dump thread\n    if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n      dumpThread.interrupt();\n      try {\n        dumpThread.join(3000);\n      } catch (InterruptedException ignored) {\n      }\n    }\n    \n    // Close stream\n    try {\n      if (fos !\u003d null) {\n        fos.close();\n      }\n    } catch (IOException e) {\n      LOG.info(\"Can\u0027t close stream for fileId: \" + latestAttr.getFileId()\n          + \", error: \" + e);\n    }\n    \n    // Reply error for pending writes\n    LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n    WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n    while (!pendingWrites.isEmpty()) {\n      OffsetRange key \u003d pendingWrites.firstKey();\n      LOG.info(\"Fail pending write: (\" + key.getMin() + \", \" + key.getMax()\n          + \"), nextOffset\u003d\" + nextOffset.get());\n      \n      WriteCtx writeCtx \u003d pendingWrites.remove(key);\n      if (!writeCtx.getReplied()) {\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n            .serialize(new XDR(), writeCtx.getXid(),\n                new VerifierNone()), writeCtx.getXid());\n      }\n    }\n    \n    // Cleanup dump file\n    if (dumpOut !\u003d null) {\n      try {\n        dumpOut.close();\n      } catch (IOException e) {\n        LOG.error(\"Failed to close outputstream of dump file\" + dumpFilePath, e);\n      }\n      File dumpFile \u003d new File(dumpFilePath);\n      if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n        LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n      }\n    }\n    if (raf !\u003d null) {\n      try {\n        raf.close();\n      } catch (IOException e) {\n        LOG.error(\"Got exception when closing input stream of dump file.\", e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "d71d40a63d198991077d5babd70be5e9787a53f1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7180. NFSv3 gateway frequently gets stuck due to GC. Contributed by Brandon Li\n",
      "commitDate": "22/10/14 9:27 PM",
      "commitName": "d71d40a63d198991077d5babd70be5e9787a53f1",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "21/10/14 10:20 AM",
      "commitNameOld": "b6f9d5538cf2b425652687e99503f3d566b2056a",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 1.46,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,65 @@\n   synchronized void cleanup() {\n     if (!activeState) {\n       LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n       return;\n     }\n     activeState \u003d false;\n \n     // stop the dump thread\n     if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n       dumpThread.interrupt();\n       try {\n         dumpThread.join(3000);\n-      } catch (InterruptedException e) {\n+      } catch (InterruptedException ignored) {\n       }\n     }\n     \n     // Close stream\n     try {\n       if (fos !\u003d null) {\n         fos.close();\n       }\n     } catch (IOException e) {\n       LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileId()\n           + \", error:\" + e);\n     }\n     \n     // Reply error for pending writes\n     LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n     WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n     while (!pendingWrites.isEmpty()) {\n       OffsetRange key \u003d pendingWrites.firstKey();\n       LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n           + \"), nextOffset\u003d\" + nextOffset.get());\n       \n       WriteCtx writeCtx \u003d pendingWrites.remove(key);\n       if (!writeCtx.getReplied()) {\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n             .serialize(new XDR(), writeCtx.getXid(),\n                 new VerifierNone()), writeCtx.getXid());\n       }\n     }\n     \n     // Cleanup dump file\n     if (dumpOut !\u003d null) {\n       try {\n         dumpOut.close();\n       } catch (IOException e) {\n         LOG.error(\"Failed to close outputstream of dump file\" + dumpFilePath, e);\n       }\n       File dumpFile \u003d new File(dumpFilePath);\n       if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n         LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n       }\n     }\n     if (raf !\u003d null) {\n       try {\n         raf.close();\n       } catch (IOException e) {\n         LOG.error(\"Got exception when closing input stream of dump file.\", e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void cleanup() {\n    if (!activeState) {\n      LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n      return;\n    }\n    activeState \u003d false;\n\n    // stop the dump thread\n    if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n      dumpThread.interrupt();\n      try {\n        dumpThread.join(3000);\n      } catch (InterruptedException ignored) {\n      }\n    }\n    \n    // Close stream\n    try {\n      if (fos !\u003d null) {\n        fos.close();\n      }\n    } catch (IOException e) {\n      LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileId()\n          + \", error:\" + e);\n    }\n    \n    // Reply error for pending writes\n    LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n    WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n    while (!pendingWrites.isEmpty()) {\n      OffsetRange key \u003d pendingWrites.firstKey();\n      LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n          + \"), nextOffset\u003d\" + nextOffset.get());\n      \n      WriteCtx writeCtx \u003d pendingWrites.remove(key);\n      if (!writeCtx.getReplied()) {\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n            .serialize(new XDR(), writeCtx.getXid(),\n                new VerifierNone()), writeCtx.getXid());\n      }\n    }\n    \n    // Cleanup dump file\n    if (dumpOut !\u003d null) {\n      try {\n        dumpOut.close();\n      } catch (IOException e) {\n        LOG.error(\"Failed to close outputstream of dump file\" + dumpFilePath, e);\n      }\n      File dumpFile \u003d new File(dumpFilePath);\n      if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n        LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n      }\n    }\n    if (raf !\u003d null) {\n      try {\n        raf.close();\n      } catch (IOException e) {\n        LOG.error(\"Got exception when closing input stream of dump file.\", e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "875aa797caee96572162ff59bc50cf97d1195348": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6894. Add XDR parser method for each NFS response. Contributed by Brandon Li.\n",
      "commitDate": "01/10/14 1:18 PM",
      "commitName": "875aa797caee96572162ff59bc50cf97d1195348",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "18/09/14 2:57 PM",
      "commitNameOld": "70be56d093022de9953e14a92dfa1a146bd9a290",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 12.93,
      "commitsBetweenForRepo": 154,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,65 @@\n   synchronized void cleanup() {\n     if (!activeState) {\n       LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n       return;\n     }\n     activeState \u003d false;\n \n     // stop the dump thread\n     if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n       dumpThread.interrupt();\n       try {\n         dumpThread.join(3000);\n       } catch (InterruptedException e) {\n       }\n     }\n     \n     // Close stream\n     try {\n       if (fos !\u003d null) {\n         fos.close();\n       }\n     } catch (IOException e) {\n       LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileId()\n           + \", error:\" + e);\n     }\n     \n     // Reply error for pending writes\n     LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n     WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n     while (!pendingWrites.isEmpty()) {\n       OffsetRange key \u003d pendingWrites.firstKey();\n       LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n           + \"), nextOffset\u003d\" + nextOffset.get());\n       \n       WriteCtx writeCtx \u003d pendingWrites.remove(key);\n       if (!writeCtx.getReplied()) {\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n-            .writeHeaderAndResponse(new XDR(), writeCtx.getXid(),\n+            .serialize(new XDR(), writeCtx.getXid(),\n                 new VerifierNone()), writeCtx.getXid());\n       }\n     }\n     \n     // Cleanup dump file\n     if (dumpOut !\u003d null) {\n       try {\n         dumpOut.close();\n       } catch (IOException e) {\n         LOG.error(\"Failed to close outputstream of dump file\" + dumpFilePath, e);\n       }\n       File dumpFile \u003d new File(dumpFilePath);\n       if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n         LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n       }\n     }\n     if (raf !\u003d null) {\n       try {\n         raf.close();\n       } catch (IOException e) {\n         LOG.error(\"Got exception when closing input stream of dump file.\", e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void cleanup() {\n    if (!activeState) {\n      LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n      return;\n    }\n    activeState \u003d false;\n\n    // stop the dump thread\n    if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n      dumpThread.interrupt();\n      try {\n        dumpThread.join(3000);\n      } catch (InterruptedException e) {\n      }\n    }\n    \n    // Close stream\n    try {\n      if (fos !\u003d null) {\n        fos.close();\n      }\n    } catch (IOException e) {\n      LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileId()\n          + \", error:\" + e);\n    }\n    \n    // Reply error for pending writes\n    LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n    WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n    while (!pendingWrites.isEmpty()) {\n      OffsetRange key \u003d pendingWrites.firstKey();\n      LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n          + \"), nextOffset\u003d\" + nextOffset.get());\n      \n      WriteCtx writeCtx \u003d pendingWrites.remove(key);\n      if (!writeCtx.getReplied()) {\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n            .serialize(new XDR(), writeCtx.getXid(),\n                new VerifierNone()), writeCtx.getXid());\n      }\n    }\n    \n    // Cleanup dump file\n    if (dumpOut !\u003d null) {\n      try {\n        dumpOut.close();\n      } catch (IOException e) {\n        LOG.error(\"Failed to close outputstream of dump file\" + dumpFilePath, e);\n      }\n      File dumpFile \u003d new File(dumpFilePath);\n      if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n        LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n      }\n    }\n    if (raf !\u003d null) {\n      try {\n        raf.close();\n      } catch (IOException e) {\n        LOG.error(\"Got exception when closing input stream of dump file.\", e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "3bfd18c6b0483ae27eff6d53bda934e67dda5464": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6050. NFS does not handle exceptions correctly in a few places. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1581055 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/03/14 1:49 PM",
      "commitName": "3bfd18c6b0483ae27eff6d53bda934e67dda5464",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "17/12/13 12:40 PM",
      "commitNameOld": "5792d59da390842caec86ccaa8472d5be7933837",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 97.01,
      "commitsBetweenForRepo": 719,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,65 @@\n   synchronized void cleanup() {\n     if (!activeState) {\n       LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n       return;\n     }\n     activeState \u003d false;\n \n     // stop the dump thread\n     if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n       dumpThread.interrupt();\n       try {\n         dumpThread.join(3000);\n       } catch (InterruptedException e) {\n       }\n     }\n     \n     // Close stream\n     try {\n       if (fos !\u003d null) {\n         fos.close();\n       }\n     } catch (IOException e) {\n-      LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileid()\n+      LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileId()\n           + \", error:\" + e);\n     }\n     \n     // Reply error for pending writes\n     LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n     WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n     while (!pendingWrites.isEmpty()) {\n       OffsetRange key \u003d pendingWrites.firstKey();\n       LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n           + \"), nextOffset\u003d\" + nextOffset.get());\n       \n       WriteCtx writeCtx \u003d pendingWrites.remove(key);\n       if (!writeCtx.getReplied()) {\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n             .writeHeaderAndResponse(new XDR(), writeCtx.getXid(),\n                 new VerifierNone()), writeCtx.getXid());\n       }\n     }\n     \n     // Cleanup dump file\n     if (dumpOut !\u003d null) {\n       try {\n         dumpOut.close();\n       } catch (IOException e) {\n-        e.printStackTrace();\n+        LOG.error(\"Failed to close outputstream of dump file\" + dumpFilePath, e);\n       }\n       File dumpFile \u003d new File(dumpFilePath);\n       if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n         LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n       }\n     }\n     if (raf !\u003d null) {\n       try {\n         raf.close();\n       } catch (IOException e) {\n-        e.printStackTrace();\n+        LOG.error(\"Got exception when closing input stream of dump file.\", e);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void cleanup() {\n    if (!activeState) {\n      LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n      return;\n    }\n    activeState \u003d false;\n\n    // stop the dump thread\n    if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n      dumpThread.interrupt();\n      try {\n        dumpThread.join(3000);\n      } catch (InterruptedException e) {\n      }\n    }\n    \n    // Close stream\n    try {\n      if (fos !\u003d null) {\n        fos.close();\n      }\n    } catch (IOException e) {\n      LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileId()\n          + \", error:\" + e);\n    }\n    \n    // Reply error for pending writes\n    LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n    WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n    while (!pendingWrites.isEmpty()) {\n      OffsetRange key \u003d pendingWrites.firstKey();\n      LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n          + \"), nextOffset\u003d\" + nextOffset.get());\n      \n      WriteCtx writeCtx \u003d pendingWrites.remove(key);\n      if (!writeCtx.getReplied()) {\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n            .writeHeaderAndResponse(new XDR(), writeCtx.getXid(),\n                new VerifierNone()), writeCtx.getXid());\n      }\n    }\n    \n    // Cleanup dump file\n    if (dumpOut !\u003d null) {\n      try {\n        dumpOut.close();\n      } catch (IOException e) {\n        LOG.error(\"Failed to close outputstream of dump file\" + dumpFilePath, e);\n      }\n      File dumpFile \u003d new File(dumpFilePath);\n      if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n        LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n      }\n    }\n    if (raf !\u003d null) {\n      try {\n        raf.close();\n      } catch (IOException e) {\n        LOG.error(\"Got exception when closing input stream of dump file.\", e);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "3fccdec6e0a8e9305fc75921211c3745eddb9c45": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-5364. Add OpenFileCtx cache. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1539834 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/11/13 1:49 PM",
      "commitName": "3fccdec6e0a8e9305fc75921211c3745eddb9c45",
      "commitAuthor": "Brandon Li",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-5364. Add OpenFileCtx cache. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1539834 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/11/13 1:49 PM",
          "commitName": "3fccdec6e0a8e9305fc75921211c3745eddb9c45",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "07/11/13 10:02 AM",
          "commitNameOld": "16c6755554cc5ecd9d4e0ba74b75b10c74bb0ab4",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 0.16,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,65 +1,65 @@\n-  private synchronized void cleanup() {\n+  synchronized void cleanup() {\n     if (!activeState) {\n       LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n       return;\n     }\n     activeState \u003d false;\n \n     // stop the dump thread\n-    if (dumpThread !\u003d null) {\n+    if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n       dumpThread.interrupt();\n       try {\n         dumpThread.join(3000);\n       } catch (InterruptedException e) {\n       }\n     }\n     \n     // Close stream\n     try {\n       if (fos !\u003d null) {\n         fos.close();\n       }\n     } catch (IOException e) {\n       LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileid()\n           + \", error:\" + e);\n     }\n     \n     // Reply error for pending writes\n     LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n     WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n     while (!pendingWrites.isEmpty()) {\n       OffsetRange key \u003d pendingWrites.firstKey();\n       LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n           + \"), nextOffset\u003d\" + nextOffset.get());\n       \n       WriteCtx writeCtx \u003d pendingWrites.remove(key);\n       if (!writeCtx.getReplied()) {\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n             .writeHeaderAndResponse(new XDR(), writeCtx.getXid(),\n                 new VerifierNone()), writeCtx.getXid());\n       }\n     }\n     \n     // Cleanup dump file\n     if (dumpOut !\u003d null) {\n       try {\n         dumpOut.close();\n       } catch (IOException e) {\n         e.printStackTrace();\n       }\n       File dumpFile \u003d new File(dumpFilePath);\n       if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n         LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n       }\n     }\n     if (raf !\u003d null) {\n       try {\n         raf.close();\n       } catch (IOException e) {\n         e.printStackTrace();\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void cleanup() {\n    if (!activeState) {\n      LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n      return;\n    }\n    activeState \u003d false;\n\n    // stop the dump thread\n    if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n      dumpThread.interrupt();\n      try {\n        dumpThread.join(3000);\n      } catch (InterruptedException e) {\n      }\n    }\n    \n    // Close stream\n    try {\n      if (fos !\u003d null) {\n        fos.close();\n      }\n    } catch (IOException e) {\n      LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileid()\n          + \", error:\" + e);\n    }\n    \n    // Reply error for pending writes\n    LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n    WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n    while (!pendingWrites.isEmpty()) {\n      OffsetRange key \u003d pendingWrites.firstKey();\n      LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n          + \"), nextOffset\u003d\" + nextOffset.get());\n      \n      WriteCtx writeCtx \u003d pendingWrites.remove(key);\n      if (!writeCtx.getReplied()) {\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n            .writeHeaderAndResponse(new XDR(), writeCtx.getXid(),\n                new VerifierNone()), writeCtx.getXid());\n      }\n    }\n    \n    // Cleanup dump file\n    if (dumpOut !\u003d null) {\n      try {\n        dumpOut.close();\n      } catch (IOException e) {\n        e.printStackTrace();\n      }\n      File dumpFile \u003d new File(dumpFilePath);\n      if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n        LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n      }\n    }\n    if (raf !\u003d null) {\n      try {\n        raf.close();\n      } catch (IOException e) {\n        e.printStackTrace();\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
          "extendedDetails": {
            "oldValue": "[private, synchronized]",
            "newValue": "[synchronized]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5364. Add OpenFileCtx cache. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1539834 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "07/11/13 1:49 PM",
          "commitName": "3fccdec6e0a8e9305fc75921211c3745eddb9c45",
          "commitAuthor": "Brandon Li",
          "commitDateOld": "07/11/13 10:02 AM",
          "commitNameOld": "16c6755554cc5ecd9d4e0ba74b75b10c74bb0ab4",
          "commitAuthorOld": "Brandon Li",
          "daysBetweenCommits": 0.16,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,65 +1,65 @@\n-  private synchronized void cleanup() {\n+  synchronized void cleanup() {\n     if (!activeState) {\n       LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n       return;\n     }\n     activeState \u003d false;\n \n     // stop the dump thread\n-    if (dumpThread !\u003d null) {\n+    if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n       dumpThread.interrupt();\n       try {\n         dumpThread.join(3000);\n       } catch (InterruptedException e) {\n       }\n     }\n     \n     // Close stream\n     try {\n       if (fos !\u003d null) {\n         fos.close();\n       }\n     } catch (IOException e) {\n       LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileid()\n           + \", error:\" + e);\n     }\n     \n     // Reply error for pending writes\n     LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n     WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n     while (!pendingWrites.isEmpty()) {\n       OffsetRange key \u003d pendingWrites.firstKey();\n       LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n           + \"), nextOffset\u003d\" + nextOffset.get());\n       \n       WriteCtx writeCtx \u003d pendingWrites.remove(key);\n       if (!writeCtx.getReplied()) {\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n             .writeHeaderAndResponse(new XDR(), writeCtx.getXid(),\n                 new VerifierNone()), writeCtx.getXid());\n       }\n     }\n     \n     // Cleanup dump file\n     if (dumpOut !\u003d null) {\n       try {\n         dumpOut.close();\n       } catch (IOException e) {\n         e.printStackTrace();\n       }\n       File dumpFile \u003d new File(dumpFilePath);\n       if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n         LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n       }\n     }\n     if (raf !\u003d null) {\n       try {\n         raf.close();\n       } catch (IOException e) {\n         e.printStackTrace();\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void cleanup() {\n    if (!activeState) {\n      LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n      return;\n    }\n    activeState \u003d false;\n\n    // stop the dump thread\n    if (dumpThread !\u003d null \u0026\u0026 dumpThread.isAlive()) {\n      dumpThread.interrupt();\n      try {\n        dumpThread.join(3000);\n      } catch (InterruptedException e) {\n      }\n    }\n    \n    // Close stream\n    try {\n      if (fos !\u003d null) {\n        fos.close();\n      }\n    } catch (IOException e) {\n      LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileid()\n          + \", error:\" + e);\n    }\n    \n    // Reply error for pending writes\n    LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n    WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n    while (!pendingWrites.isEmpty()) {\n      OffsetRange key \u003d pendingWrites.firstKey();\n      LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n          + \"), nextOffset\u003d\" + nextOffset.get());\n      \n      WriteCtx writeCtx \u003d pendingWrites.remove(key);\n      if (!writeCtx.getReplied()) {\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n            .writeHeaderAndResponse(new XDR(), writeCtx.getXid(),\n                new VerifierNone()), writeCtx.getXid());\n      }\n    }\n    \n    // Cleanup dump file\n    if (dumpOut !\u003d null) {\n      try {\n        dumpOut.close();\n      } catch (IOException e) {\n        e.printStackTrace();\n      }\n      File dumpFile \u003d new File(dumpFilePath);\n      if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n        LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n      }\n    }\n    if (raf !\u003d null) {\n      try {\n        raf.close();\n      } catch (IOException e) {\n        e.printStackTrace();\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
          "extendedDetails": {}
        }
      ]
    },
    "28e3d09230971b32f74284311931525cb7ad1b7c": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-4971. Move IO operations out of locking in OpenFileCtx. Contributed by Jing Zhao and Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1525681 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/09/13 1:02 PM",
      "commitName": "28e3d09230971b32f74284311931525cb7ad1b7c",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-4971. Move IO operations out of locking in OpenFileCtx. Contributed by Jing Zhao and Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1525681 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/09/13 1:02 PM",
          "commitName": "28e3d09230971b32f74284311931525cb7ad1b7c",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "17/09/13 11:08 PM",
          "commitNameOld": "5e18410e06dd63113c49029894007e0878312903",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 5.58,
          "commitsBetweenForRepo": 25,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,53 +1,65 @@\n-  private void cleanup() {\n-    assert(ctxLock.isLocked());\n+  private synchronized void cleanup() {\n+    if (!activeState) {\n+      LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n+      return;\n+    }\n     activeState \u003d false;\n+\n+    // stop the dump thread\n+    if (dumpThread !\u003d null) {\n+      dumpThread.interrupt();\n+      try {\n+        dumpThread.join(3000);\n+      } catch (InterruptedException e) {\n+      }\n+    }\n     \n     // Close stream\n     try {\n       if (fos !\u003d null) {\n         fos.close();\n       }\n     } catch (IOException e) {\n       LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileid()\n           + \", error:\" + e);\n     }\n     \n     // Reply error for pending writes\n     LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n     WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n     while (!pendingWrites.isEmpty()) {\n       OffsetRange key \u003d pendingWrites.firstKey();\n       LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n-          + \"), nextOffset\u003d\" + getNextOffsetUnprotected());\n+          + \"), nextOffset\u003d\" + nextOffset.get());\n       \n       WriteCtx writeCtx \u003d pendingWrites.remove(key);\n       if (!writeCtx.getReplied()) {\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n             .writeHeaderAndResponse(new XDR(), writeCtx.getXid(),\n                 new VerifierNone()), writeCtx.getXid());\n       }\n     }\n     \n     // Cleanup dump file\n-    if (dumpOut!\u003dnull){\n+    if (dumpOut !\u003d null) {\n       try {\n         dumpOut.close();\n       } catch (IOException e) {\n         e.printStackTrace();\n       }\n+      File dumpFile \u003d new File(dumpFilePath);\n+      if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n+        LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n+      }\n     }\n-    if (raf!\u003dnull) {\n+    if (raf !\u003d null) {\n       try {\n         raf.close();\n       } catch (IOException e) {\n         e.printStackTrace();\n       }\n     }\n-    File dumpFile \u003d new File(dumpFilePath);\n-    if (dumpFile.delete()) {\n-      LOG.error(\"Failed to delete dumpfile: \"+ dumpFile);\n-    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private synchronized void cleanup() {\n    if (!activeState) {\n      LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n      return;\n    }\n    activeState \u003d false;\n\n    // stop the dump thread\n    if (dumpThread !\u003d null) {\n      dumpThread.interrupt();\n      try {\n        dumpThread.join(3000);\n      } catch (InterruptedException e) {\n      }\n    }\n    \n    // Close stream\n    try {\n      if (fos !\u003d null) {\n        fos.close();\n      }\n    } catch (IOException e) {\n      LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileid()\n          + \", error:\" + e);\n    }\n    \n    // Reply error for pending writes\n    LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n    WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n    while (!pendingWrites.isEmpty()) {\n      OffsetRange key \u003d pendingWrites.firstKey();\n      LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n          + \"), nextOffset\u003d\" + nextOffset.get());\n      \n      WriteCtx writeCtx \u003d pendingWrites.remove(key);\n      if (!writeCtx.getReplied()) {\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n            .writeHeaderAndResponse(new XDR(), writeCtx.getXid(),\n                new VerifierNone()), writeCtx.getXid());\n      }\n    }\n    \n    // Cleanup dump file\n    if (dumpOut !\u003d null) {\n      try {\n        dumpOut.close();\n      } catch (IOException e) {\n        e.printStackTrace();\n      }\n      File dumpFile \u003d new File(dumpFilePath);\n      if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n        LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n      }\n    }\n    if (raf !\u003d null) {\n      try {\n        raf.close();\n      } catch (IOException e) {\n        e.printStackTrace();\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[private, synchronized]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4971. Move IO operations out of locking in OpenFileCtx. Contributed by Jing Zhao and Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1525681 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/09/13 1:02 PM",
          "commitName": "28e3d09230971b32f74284311931525cb7ad1b7c",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "17/09/13 11:08 PM",
          "commitNameOld": "5e18410e06dd63113c49029894007e0878312903",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 5.58,
          "commitsBetweenForRepo": 25,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,53 +1,65 @@\n-  private void cleanup() {\n-    assert(ctxLock.isLocked());\n+  private synchronized void cleanup() {\n+    if (!activeState) {\n+      LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n+      return;\n+    }\n     activeState \u003d false;\n+\n+    // stop the dump thread\n+    if (dumpThread !\u003d null) {\n+      dumpThread.interrupt();\n+      try {\n+        dumpThread.join(3000);\n+      } catch (InterruptedException e) {\n+      }\n+    }\n     \n     // Close stream\n     try {\n       if (fos !\u003d null) {\n         fos.close();\n       }\n     } catch (IOException e) {\n       LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileid()\n           + \", error:\" + e);\n     }\n     \n     // Reply error for pending writes\n     LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n     WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n     while (!pendingWrites.isEmpty()) {\n       OffsetRange key \u003d pendingWrites.firstKey();\n       LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n-          + \"), nextOffset\u003d\" + getNextOffsetUnprotected());\n+          + \"), nextOffset\u003d\" + nextOffset.get());\n       \n       WriteCtx writeCtx \u003d pendingWrites.remove(key);\n       if (!writeCtx.getReplied()) {\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n             .writeHeaderAndResponse(new XDR(), writeCtx.getXid(),\n                 new VerifierNone()), writeCtx.getXid());\n       }\n     }\n     \n     // Cleanup dump file\n-    if (dumpOut!\u003dnull){\n+    if (dumpOut !\u003d null) {\n       try {\n         dumpOut.close();\n       } catch (IOException e) {\n         e.printStackTrace();\n       }\n+      File dumpFile \u003d new File(dumpFilePath);\n+      if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n+        LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n+      }\n     }\n-    if (raf!\u003dnull) {\n+    if (raf !\u003d null) {\n       try {\n         raf.close();\n       } catch (IOException e) {\n         e.printStackTrace();\n       }\n     }\n-    File dumpFile \u003d new File(dumpFilePath);\n-    if (dumpFile.delete()) {\n-      LOG.error(\"Failed to delete dumpfile: \"+ dumpFile);\n-    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private synchronized void cleanup() {\n    if (!activeState) {\n      LOG.info(\"Current OpenFileCtx is already inactive, no need to cleanup.\");\n      return;\n    }\n    activeState \u003d false;\n\n    // stop the dump thread\n    if (dumpThread !\u003d null) {\n      dumpThread.interrupt();\n      try {\n        dumpThread.join(3000);\n      } catch (InterruptedException e) {\n      }\n    }\n    \n    // Close stream\n    try {\n      if (fos !\u003d null) {\n        fos.close();\n      }\n    } catch (IOException e) {\n      LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileid()\n          + \", error:\" + e);\n    }\n    \n    // Reply error for pending writes\n    LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n    WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n    while (!pendingWrites.isEmpty()) {\n      OffsetRange key \u003d pendingWrites.firstKey();\n      LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n          + \"), nextOffset\u003d\" + nextOffset.get());\n      \n      WriteCtx writeCtx \u003d pendingWrites.remove(key);\n      if (!writeCtx.getReplied()) {\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n            .writeHeaderAndResponse(new XDR(), writeCtx.getXid(),\n                new VerifierNone()), writeCtx.getXid());\n      }\n    }\n    \n    // Cleanup dump file\n    if (dumpOut !\u003d null) {\n      try {\n        dumpOut.close();\n      } catch (IOException e) {\n        e.printStackTrace();\n      }\n      File dumpFile \u003d new File(dumpFilePath);\n      if (dumpFile.exists() \u0026\u0026 !dumpFile.delete()) {\n        LOG.error(\"Failed to delete dumpfile: \" + dumpFile);\n      }\n    }\n    if (raf !\u003d null) {\n      try {\n        raf.close();\n      } catch (IOException e) {\n        e.printStackTrace();\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
          "extendedDetails": {}
        }
      ]
    },
    "5e18410e06dd63113c49029894007e0878312903": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5212. Refactor RpcMessage and NFS3Response to support different types of authentication information. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1524298 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/09/13 11:08 PM",
      "commitName": "5e18410e06dd63113c49029894007e0878312903",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "13/09/13 4:14 PM",
      "commitNameOld": "a56a4b6ef06602312144783b7507bf2b82821e4f",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 4.29,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,52 +1,53 @@\n   private void cleanup() {\n     assert(ctxLock.isLocked());\n     activeState \u003d false;\n     \n     // Close stream\n     try {\n       if (fos !\u003d null) {\n         fos.close();\n       }\n     } catch (IOException e) {\n       LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileid()\n           + \", error:\" + e);\n     }\n     \n     // Reply error for pending writes\n     LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n     WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n     while (!pendingWrites.isEmpty()) {\n       OffsetRange key \u003d pendingWrites.firstKey();\n       LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n           + \"), nextOffset\u003d\" + getNextOffsetUnprotected());\n       \n       WriteCtx writeCtx \u003d pendingWrites.remove(key);\n       if (!writeCtx.getReplied()) {\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n-        Nfs3Utils.writeChannel(writeCtx.getChannel(),\n-            response.send(new XDR(), writeCtx.getXid()), writeCtx.getXid());\n+        Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n+            .writeHeaderAndResponse(new XDR(), writeCtx.getXid(),\n+                new VerifierNone()), writeCtx.getXid());\n       }\n     }\n     \n     // Cleanup dump file\n     if (dumpOut!\u003dnull){\n       try {\n         dumpOut.close();\n       } catch (IOException e) {\n         e.printStackTrace();\n       }\n     }\n     if (raf!\u003dnull) {\n       try {\n         raf.close();\n       } catch (IOException e) {\n         e.printStackTrace();\n       }\n     }\n     File dumpFile \u003d new File(dumpFilePath);\n     if (dumpFile.delete()) {\n       LOG.error(\"Failed to delete dumpfile: \"+ dumpFile);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void cleanup() {\n    assert(ctxLock.isLocked());\n    activeState \u003d false;\n    \n    // Close stream\n    try {\n      if (fos !\u003d null) {\n        fos.close();\n      }\n    } catch (IOException e) {\n      LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileid()\n          + \", error:\" + e);\n    }\n    \n    // Reply error for pending writes\n    LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n    WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n    while (!pendingWrites.isEmpty()) {\n      OffsetRange key \u003d pendingWrites.firstKey();\n      LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n          + \"), nextOffset\u003d\" + getNextOffsetUnprotected());\n      \n      WriteCtx writeCtx \u003d pendingWrites.remove(key);\n      if (!writeCtx.getReplied()) {\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(writeCtx.getChannel(), response\n            .writeHeaderAndResponse(new XDR(), writeCtx.getXid(),\n                new VerifierNone()), writeCtx.getXid());\n      }\n    }\n    \n    // Cleanup dump file\n    if (dumpOut!\u003dnull){\n      try {\n        dumpOut.close();\n      } catch (IOException e) {\n        e.printStackTrace();\n      }\n    }\n    if (raf!\u003dnull) {\n      try {\n        raf.close();\n      } catch (IOException e) {\n        e.printStackTrace();\n      }\n    }\n    File dumpFile \u003d new File(dumpFilePath);\n    if (dumpFile.delete()) {\n      LOG.error(\"Failed to delete dumpfile: \"+ dumpFile);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "a56a4b6ef06602312144783b7507bf2b82821e4f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5199 Add more debug trace for NFS READ and WRITE. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1523140 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/09/13 4:14 PM",
      "commitName": "a56a4b6ef06602312144783b7507bf2b82821e4f",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "28/08/13 10:23 AM",
      "commitNameOld": "30b8ef91a32ddf1fe3756bae6d7dc538a150bdc4",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 16.24,
      "commitsBetweenForRepo": 77,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,52 +1,52 @@\n   private void cleanup() {\n     assert(ctxLock.isLocked());\n     activeState \u003d false;\n     \n     // Close stream\n     try {\n       if (fos !\u003d null) {\n         fos.close();\n       }\n     } catch (IOException e) {\n       LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileid()\n           + \", error:\" + e);\n     }\n     \n     // Reply error for pending writes\n     LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n     WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n     while (!pendingWrites.isEmpty()) {\n       OffsetRange key \u003d pendingWrites.firstKey();\n       LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n           + \"), nextOffset\u003d\" + getNextOffsetUnprotected());\n       \n       WriteCtx writeCtx \u003d pendingWrites.remove(key);\n       if (!writeCtx.getReplied()) {\n         WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n         WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n             fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n         Nfs3Utils.writeChannel(writeCtx.getChannel(),\n-            response.send(new XDR(), writeCtx.getXid()));\n+            response.send(new XDR(), writeCtx.getXid()), writeCtx.getXid());\n       }\n     }\n     \n     // Cleanup dump file\n     if (dumpOut!\u003dnull){\n       try {\n         dumpOut.close();\n       } catch (IOException e) {\n         e.printStackTrace();\n       }\n     }\n     if (raf!\u003dnull) {\n       try {\n         raf.close();\n       } catch (IOException e) {\n         e.printStackTrace();\n       }\n     }\n     File dumpFile \u003d new File(dumpFilePath);\n     if (dumpFile.delete()) {\n       LOG.error(\"Failed to delete dumpfile: \"+ dumpFile);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void cleanup() {\n    assert(ctxLock.isLocked());\n    activeState \u003d false;\n    \n    // Close stream\n    try {\n      if (fos !\u003d null) {\n        fos.close();\n      }\n    } catch (IOException e) {\n      LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileid()\n          + \", error:\" + e);\n    }\n    \n    // Reply error for pending writes\n    LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n    WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n    while (!pendingWrites.isEmpty()) {\n      OffsetRange key \u003d pendingWrites.firstKey();\n      LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n          + \"), nextOffset\u003d\" + getNextOffsetUnprotected());\n      \n      WriteCtx writeCtx \u003d pendingWrites.remove(key);\n      if (!writeCtx.getReplied()) {\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(writeCtx.getChannel(),\n            response.send(new XDR(), writeCtx.getXid()), writeCtx.getXid());\n      }\n    }\n    \n    // Cleanup dump file\n    if (dumpOut!\u003dnull){\n      try {\n        dumpOut.close();\n      } catch (IOException e) {\n        e.printStackTrace();\n      }\n    }\n    if (raf!\u003dnull) {\n      try {\n        raf.close();\n      } catch (IOException e) {\n        e.printStackTrace();\n      }\n    }\n    File dumpFile \u003d new File(dumpFilePath);\n    if (dumpFile.delete()) {\n      LOG.error(\"Failed to delete dumpfile: \"+ dumpFile);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "37f587563a943a827fbff865f5302bac6d202415": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4762 Provide HDFS based NFSv3 and Mountd implementation. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1499029 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/07/13 10:31 AM",
      "commitName": "37f587563a943a827fbff865f5302bac6d202415",
      "commitAuthor": "Brandon Li",
      "diff": "@@ -0,0 +1,52 @@\n+  private void cleanup() {\n+    assert(ctxLock.isLocked());\n+    activeState \u003d false;\n+    \n+    // Close stream\n+    try {\n+      if (fos !\u003d null) {\n+        fos.close();\n+      }\n+    } catch (IOException e) {\n+      LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileid()\n+          + \", error:\" + e);\n+    }\n+    \n+    // Reply error for pending writes\n+    LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n+    WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n+    while (!pendingWrites.isEmpty()) {\n+      OffsetRange key \u003d pendingWrites.firstKey();\n+      LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n+          + \"), nextOffset\u003d\" + getNextOffsetUnprotected());\n+      \n+      WriteCtx writeCtx \u003d pendingWrites.remove(key);\n+      if (!writeCtx.getReplied()) {\n+        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n+        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n+            fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n+        Nfs3Utils.writeChannel(writeCtx.getChannel(),\n+            response.send(new XDR(), writeCtx.getXid()));\n+      }\n+    }\n+    \n+    // Cleanup dump file\n+    if (dumpOut!\u003dnull){\n+      try {\n+        dumpOut.close();\n+      } catch (IOException e) {\n+        e.printStackTrace();\n+      }\n+    }\n+    if (raf!\u003dnull) {\n+      try {\n+        raf.close();\n+      } catch (IOException e) {\n+        e.printStackTrace();\n+      }\n+    }\n+    File dumpFile \u003d new File(dumpFilePath);\n+    if (dumpFile.delete()) {\n+      LOG.error(\"Failed to delete dumpfile: \"+ dumpFile);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void cleanup() {\n    assert(ctxLock.isLocked());\n    activeState \u003d false;\n    \n    // Close stream\n    try {\n      if (fos !\u003d null) {\n        fos.close();\n      }\n    } catch (IOException e) {\n      LOG.info(\"Can\u0027t close stream for fileId:\" + latestAttr.getFileid()\n          + \", error:\" + e);\n    }\n    \n    // Reply error for pending writes\n    LOG.info(\"There are \" + pendingWrites.size() + \" pending writes.\");\n    WccAttr preOpAttr \u003d latestAttr.getWccAttr();\n    while (!pendingWrites.isEmpty()) {\n      OffsetRange key \u003d pendingWrites.firstKey();\n      LOG.info(\"Fail pending write: (\" + key.getMin() + \",\" + key.getMax()\n          + \"), nextOffset\u003d\" + getNextOffsetUnprotected());\n      \n      WriteCtx writeCtx \u003d pendingWrites.remove(key);\n      if (!writeCtx.getReplied()) {\n        WccData fileWcc \u003d new WccData(preOpAttr, latestAttr);\n        WRITE3Response response \u003d new WRITE3Response(Nfs3Status.NFS3ERR_IO,\n            fileWcc, 0, writeCtx.getStableHow(), Nfs3Constant.WRITE_COMMIT_VERF);\n        Nfs3Utils.writeChannel(writeCtx.getChannel(),\n            response.send(new XDR(), writeCtx.getXid()));\n      }\n    }\n    \n    // Cleanup dump file\n    if (dumpOut!\u003dnull){\n      try {\n        dumpOut.close();\n      } catch (IOException e) {\n        e.printStackTrace();\n      }\n    }\n    if (raf!\u003dnull) {\n      try {\n        raf.close();\n      } catch (IOException e) {\n        e.printStackTrace();\n      }\n    }\n    File dumpFile \u003d new File(dumpFilePath);\n    if (dumpFile.delete()) {\n      LOG.error(\"Failed to delete dumpfile: \"+ dumpFile);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java"
    }
  }
}