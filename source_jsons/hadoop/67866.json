{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "SimpleCopyListing.java",
  "functionName": "validatePaths",
  "functionId": "validatePaths___context-DistCpContext",
  "sourceFilePath": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/SimpleCopyListing.java",
  "functionStartLine": 126,
  "functionEndLine": 201,
  "numCommitsSeen": 51,
  "timeTaken": 2016,
  "changeHistory": [
    "26172a94d6431e70d7fe15d66be9a7e195f79f60",
    "5af572b6443715b7a741296c1bd520a1840f9a7c",
    "041b8326a1511b721958792a6b94ecfe27d7a1fb",
    "d06948002fb0cabf72cc0d46bf2fa67d45370f67"
  ],
  "changeHistoryShort": {
    "26172a94d6431e70d7fe15d66be9a7e195f79f60": "Ymultichange(Yparameterchange,Ybodychange)",
    "5af572b6443715b7a741296c1bd520a1840f9a7c": "Ybodychange",
    "041b8326a1511b721958792a6b94ecfe27d7a1fb": "Ybodychange",
    "d06948002fb0cabf72cc0d46bf2fa67d45370f67": "Yintroduced"
  },
  "changeHistoryDetails": {
    "26172a94d6431e70d7fe15d66be9a7e195f79f60": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HADOOP-14267. Make DistCpOptions immutable. Contributed by Mingliang Liu\n",
      "commitDate": "31/03/17 8:04 PM",
      "commitName": "26172a94d6431e70d7fe15d66be9a7e195f79f60",
      "commitAuthor": "Mingliang Liu",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-14267. Make DistCpOptions immutable. Contributed by Mingliang Liu\n",
          "commitDate": "31/03/17 8:04 PM",
          "commitName": "26172a94d6431e70d7fe15d66be9a7e195f79f60",
          "commitAuthor": "Mingliang Liu",
          "commitDateOld": "30/03/17 5:38 PM",
          "commitNameOld": "bf3fb585aaf2b179836e139c041fc87920a3c886",
          "commitAuthorOld": "Yongjun Zhang",
          "daysBetweenCommits": 1.1,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,75 +1,76 @@\n-  protected void validatePaths(DistCpOptions options)\n+  protected void validatePaths(DistCpContext context)\n       throws IOException, InvalidInputException {\n \n-    Path targetPath \u003d options.getTargetPath();\n+    Path targetPath \u003d context.getTargetPath();\n     FileSystem targetFS \u003d targetPath.getFileSystem(getConf());\n     boolean targetExists \u003d false;\n     boolean targetIsFile \u003d false;\n     try {\n       targetIsFile \u003d targetFS.getFileStatus(targetPath).isFile();\n       targetExists \u003d true;\n     } catch (FileNotFoundException ignored) {\n     }\n     targetPath \u003d targetFS.makeQualified(targetPath);\n     final boolean targetIsReservedRaw \u003d\n         Path.getPathWithoutSchemeAndAuthority(targetPath).toString().\n             startsWith(HDFS_RESERVED_RAW_DIRECTORY_NAME);\n \n     //If target is a file, then source has to be single file\n     if (targetIsFile) {\n-      if (options.getSourcePaths().size() \u003e 1) {\n+      if (context.getSourcePaths().size() \u003e 1) {\n         throw new InvalidInputException(\"Multiple source being copied to a file: \" +\n             targetPath);\n       }\n \n-      Path srcPath \u003d options.getSourcePaths().get(0);\n+      Path srcPath \u003d context.getSourcePaths().get(0);\n       FileSystem sourceFS \u003d srcPath.getFileSystem(getConf());\n       if (!sourceFS.isFile(srcPath)) {\n         throw new InvalidInputException(\"Cannot copy \" + srcPath +\n             \", which is not a file to \" + targetPath);\n       }\n     }\n \n-    if (options.shouldAtomicCommit() \u0026\u0026 targetExists) {\n+    if (context.shouldAtomicCommit() \u0026\u0026 targetExists) {\n       throw new InvalidInputException(\"Target path for atomic-commit already exists: \" +\n         targetPath + \". Cannot atomic-commit to pre-existing target-path.\");\n     }\n \n-    for (Path path: options.getSourcePaths()) {\n+    for (Path path: context.getSourcePaths()) {\n       FileSystem fs \u003d path.getFileSystem(getConf());\n       if (!fs.exists(path)) {\n         throw new InvalidInputException(path + \" doesn\u0027t exist\");\n       }\n       if (Path.getPathWithoutSchemeAndAuthority(path).toString().\n           startsWith(HDFS_RESERVED_RAW_DIRECTORY_NAME)) {\n         if (!targetIsReservedRaw) {\n           final String msg \u003d \"The source path \u0027\" + path + \"\u0027 starts with \" +\n               HDFS_RESERVED_RAW_DIRECTORY_NAME + \" but the target path \u0027\" +\n               targetPath + \"\u0027 does not. Either all or none of the paths must \" +\n               \"have this prefix.\";\n           throw new InvalidInputException(msg);\n         }\n       } else if (targetIsReservedRaw) {\n         final String msg \u003d \"The target path \u0027\" + targetPath + \"\u0027 starts with \" +\n                 HDFS_RESERVED_RAW_DIRECTORY_NAME + \" but the source path \u0027\" +\n                 path + \"\u0027 does not. Either all or none of the paths must \" +\n                 \"have this prefix.\";\n         throw new InvalidInputException(msg);\n       }\n     }\n \n     if (targetIsReservedRaw) {\n-      options.preserveRawXattrs();\n+      context.setPreserveRawXattrs(true);\n       getConf().setBoolean(DistCpConstants.CONF_LABEL_PRESERVE_RAWXATTRS, true);\n     }\n \n     /* This is requires to allow map tasks to access each of the source\n        clusters. This would retrieve the delegation token for each unique\n        file system and add them to job\u0027s private credential store\n      */\n     Credentials credentials \u003d getCredentials();\n     if (credentials !\u003d null) {\n-      Path[] inputPaths \u003d options.getSourcePaths().toArray(new Path[1]);\n+      Path[] inputPaths \u003d context.getSourcePaths()\n+          .toArray(new Path[1]);\n       TokenCache.obtainTokensForNamenodes(credentials, inputPaths, getConf());\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void validatePaths(DistCpContext context)\n      throws IOException, InvalidInputException {\n\n    Path targetPath \u003d context.getTargetPath();\n    FileSystem targetFS \u003d targetPath.getFileSystem(getConf());\n    boolean targetExists \u003d false;\n    boolean targetIsFile \u003d false;\n    try {\n      targetIsFile \u003d targetFS.getFileStatus(targetPath).isFile();\n      targetExists \u003d true;\n    } catch (FileNotFoundException ignored) {\n    }\n    targetPath \u003d targetFS.makeQualified(targetPath);\n    final boolean targetIsReservedRaw \u003d\n        Path.getPathWithoutSchemeAndAuthority(targetPath).toString().\n            startsWith(HDFS_RESERVED_RAW_DIRECTORY_NAME);\n\n    //If target is a file, then source has to be single file\n    if (targetIsFile) {\n      if (context.getSourcePaths().size() \u003e 1) {\n        throw new InvalidInputException(\"Multiple source being copied to a file: \" +\n            targetPath);\n      }\n\n      Path srcPath \u003d context.getSourcePaths().get(0);\n      FileSystem sourceFS \u003d srcPath.getFileSystem(getConf());\n      if (!sourceFS.isFile(srcPath)) {\n        throw new InvalidInputException(\"Cannot copy \" + srcPath +\n            \", which is not a file to \" + targetPath);\n      }\n    }\n\n    if (context.shouldAtomicCommit() \u0026\u0026 targetExists) {\n      throw new InvalidInputException(\"Target path for atomic-commit already exists: \" +\n        targetPath + \". Cannot atomic-commit to pre-existing target-path.\");\n    }\n\n    for (Path path: context.getSourcePaths()) {\n      FileSystem fs \u003d path.getFileSystem(getConf());\n      if (!fs.exists(path)) {\n        throw new InvalidInputException(path + \" doesn\u0027t exist\");\n      }\n      if (Path.getPathWithoutSchemeAndAuthority(path).toString().\n          startsWith(HDFS_RESERVED_RAW_DIRECTORY_NAME)) {\n        if (!targetIsReservedRaw) {\n          final String msg \u003d \"The source path \u0027\" + path + \"\u0027 starts with \" +\n              HDFS_RESERVED_RAW_DIRECTORY_NAME + \" but the target path \u0027\" +\n              targetPath + \"\u0027 does not. Either all or none of the paths must \" +\n              \"have this prefix.\";\n          throw new InvalidInputException(msg);\n        }\n      } else if (targetIsReservedRaw) {\n        final String msg \u003d \"The target path \u0027\" + targetPath + \"\u0027 starts with \" +\n                HDFS_RESERVED_RAW_DIRECTORY_NAME + \" but the source path \u0027\" +\n                path + \"\u0027 does not. Either all or none of the paths must \" +\n                \"have this prefix.\";\n        throw new InvalidInputException(msg);\n      }\n    }\n\n    if (targetIsReservedRaw) {\n      context.setPreserveRawXattrs(true);\n      getConf().setBoolean(DistCpConstants.CONF_LABEL_PRESERVE_RAWXATTRS, true);\n    }\n\n    /* This is requires to allow map tasks to access each of the source\n       clusters. This would retrieve the delegation token for each unique\n       file system and add them to job\u0027s private credential store\n     */\n    Credentials credentials \u003d getCredentials();\n    if (credentials !\u003d null) {\n      Path[] inputPaths \u003d context.getSourcePaths()\n          .toArray(new Path[1]);\n      TokenCache.obtainTokensForNamenodes(credentials, inputPaths, getConf());\n    }\n  }",
          "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/SimpleCopyListing.java",
          "extendedDetails": {
            "oldValue": "[options-DistCpOptions]",
            "newValue": "[context-DistCpContext]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-14267. Make DistCpOptions immutable. Contributed by Mingliang Liu\n",
          "commitDate": "31/03/17 8:04 PM",
          "commitName": "26172a94d6431e70d7fe15d66be9a7e195f79f60",
          "commitAuthor": "Mingliang Liu",
          "commitDateOld": "30/03/17 5:38 PM",
          "commitNameOld": "bf3fb585aaf2b179836e139c041fc87920a3c886",
          "commitAuthorOld": "Yongjun Zhang",
          "daysBetweenCommits": 1.1,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,75 +1,76 @@\n-  protected void validatePaths(DistCpOptions options)\n+  protected void validatePaths(DistCpContext context)\n       throws IOException, InvalidInputException {\n \n-    Path targetPath \u003d options.getTargetPath();\n+    Path targetPath \u003d context.getTargetPath();\n     FileSystem targetFS \u003d targetPath.getFileSystem(getConf());\n     boolean targetExists \u003d false;\n     boolean targetIsFile \u003d false;\n     try {\n       targetIsFile \u003d targetFS.getFileStatus(targetPath).isFile();\n       targetExists \u003d true;\n     } catch (FileNotFoundException ignored) {\n     }\n     targetPath \u003d targetFS.makeQualified(targetPath);\n     final boolean targetIsReservedRaw \u003d\n         Path.getPathWithoutSchemeAndAuthority(targetPath).toString().\n             startsWith(HDFS_RESERVED_RAW_DIRECTORY_NAME);\n \n     //If target is a file, then source has to be single file\n     if (targetIsFile) {\n-      if (options.getSourcePaths().size() \u003e 1) {\n+      if (context.getSourcePaths().size() \u003e 1) {\n         throw new InvalidInputException(\"Multiple source being copied to a file: \" +\n             targetPath);\n       }\n \n-      Path srcPath \u003d options.getSourcePaths().get(0);\n+      Path srcPath \u003d context.getSourcePaths().get(0);\n       FileSystem sourceFS \u003d srcPath.getFileSystem(getConf());\n       if (!sourceFS.isFile(srcPath)) {\n         throw new InvalidInputException(\"Cannot copy \" + srcPath +\n             \", which is not a file to \" + targetPath);\n       }\n     }\n \n-    if (options.shouldAtomicCommit() \u0026\u0026 targetExists) {\n+    if (context.shouldAtomicCommit() \u0026\u0026 targetExists) {\n       throw new InvalidInputException(\"Target path for atomic-commit already exists: \" +\n         targetPath + \". Cannot atomic-commit to pre-existing target-path.\");\n     }\n \n-    for (Path path: options.getSourcePaths()) {\n+    for (Path path: context.getSourcePaths()) {\n       FileSystem fs \u003d path.getFileSystem(getConf());\n       if (!fs.exists(path)) {\n         throw new InvalidInputException(path + \" doesn\u0027t exist\");\n       }\n       if (Path.getPathWithoutSchemeAndAuthority(path).toString().\n           startsWith(HDFS_RESERVED_RAW_DIRECTORY_NAME)) {\n         if (!targetIsReservedRaw) {\n           final String msg \u003d \"The source path \u0027\" + path + \"\u0027 starts with \" +\n               HDFS_RESERVED_RAW_DIRECTORY_NAME + \" but the target path \u0027\" +\n               targetPath + \"\u0027 does not. Either all or none of the paths must \" +\n               \"have this prefix.\";\n           throw new InvalidInputException(msg);\n         }\n       } else if (targetIsReservedRaw) {\n         final String msg \u003d \"The target path \u0027\" + targetPath + \"\u0027 starts with \" +\n                 HDFS_RESERVED_RAW_DIRECTORY_NAME + \" but the source path \u0027\" +\n                 path + \"\u0027 does not. Either all or none of the paths must \" +\n                 \"have this prefix.\";\n         throw new InvalidInputException(msg);\n       }\n     }\n \n     if (targetIsReservedRaw) {\n-      options.preserveRawXattrs();\n+      context.setPreserveRawXattrs(true);\n       getConf().setBoolean(DistCpConstants.CONF_LABEL_PRESERVE_RAWXATTRS, true);\n     }\n \n     /* This is requires to allow map tasks to access each of the source\n        clusters. This would retrieve the delegation token for each unique\n        file system and add them to job\u0027s private credential store\n      */\n     Credentials credentials \u003d getCredentials();\n     if (credentials !\u003d null) {\n-      Path[] inputPaths \u003d options.getSourcePaths().toArray(new Path[1]);\n+      Path[] inputPaths \u003d context.getSourcePaths()\n+          .toArray(new Path[1]);\n       TokenCache.obtainTokensForNamenodes(credentials, inputPaths, getConf());\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void validatePaths(DistCpContext context)\n      throws IOException, InvalidInputException {\n\n    Path targetPath \u003d context.getTargetPath();\n    FileSystem targetFS \u003d targetPath.getFileSystem(getConf());\n    boolean targetExists \u003d false;\n    boolean targetIsFile \u003d false;\n    try {\n      targetIsFile \u003d targetFS.getFileStatus(targetPath).isFile();\n      targetExists \u003d true;\n    } catch (FileNotFoundException ignored) {\n    }\n    targetPath \u003d targetFS.makeQualified(targetPath);\n    final boolean targetIsReservedRaw \u003d\n        Path.getPathWithoutSchemeAndAuthority(targetPath).toString().\n            startsWith(HDFS_RESERVED_RAW_DIRECTORY_NAME);\n\n    //If target is a file, then source has to be single file\n    if (targetIsFile) {\n      if (context.getSourcePaths().size() \u003e 1) {\n        throw new InvalidInputException(\"Multiple source being copied to a file: \" +\n            targetPath);\n      }\n\n      Path srcPath \u003d context.getSourcePaths().get(0);\n      FileSystem sourceFS \u003d srcPath.getFileSystem(getConf());\n      if (!sourceFS.isFile(srcPath)) {\n        throw new InvalidInputException(\"Cannot copy \" + srcPath +\n            \", which is not a file to \" + targetPath);\n      }\n    }\n\n    if (context.shouldAtomicCommit() \u0026\u0026 targetExists) {\n      throw new InvalidInputException(\"Target path for atomic-commit already exists: \" +\n        targetPath + \". Cannot atomic-commit to pre-existing target-path.\");\n    }\n\n    for (Path path: context.getSourcePaths()) {\n      FileSystem fs \u003d path.getFileSystem(getConf());\n      if (!fs.exists(path)) {\n        throw new InvalidInputException(path + \" doesn\u0027t exist\");\n      }\n      if (Path.getPathWithoutSchemeAndAuthority(path).toString().\n          startsWith(HDFS_RESERVED_RAW_DIRECTORY_NAME)) {\n        if (!targetIsReservedRaw) {\n          final String msg \u003d \"The source path \u0027\" + path + \"\u0027 starts with \" +\n              HDFS_RESERVED_RAW_DIRECTORY_NAME + \" but the target path \u0027\" +\n              targetPath + \"\u0027 does not. Either all or none of the paths must \" +\n              \"have this prefix.\";\n          throw new InvalidInputException(msg);\n        }\n      } else if (targetIsReservedRaw) {\n        final String msg \u003d \"The target path \u0027\" + targetPath + \"\u0027 starts with \" +\n                HDFS_RESERVED_RAW_DIRECTORY_NAME + \" but the source path \u0027\" +\n                path + \"\u0027 does not. Either all or none of the paths must \" +\n                \"have this prefix.\";\n        throw new InvalidInputException(msg);\n      }\n    }\n\n    if (targetIsReservedRaw) {\n      context.setPreserveRawXattrs(true);\n      getConf().setBoolean(DistCpConstants.CONF_LABEL_PRESERVE_RAWXATTRS, true);\n    }\n\n    /* This is requires to allow map tasks to access each of the source\n       clusters. This would retrieve the delegation token for each unique\n       file system and add them to job\u0027s private credential store\n     */\n    Credentials credentials \u003d getCredentials();\n    if (credentials !\u003d null) {\n      Path[] inputPaths \u003d context.getSourcePaths()\n          .toArray(new Path[1]);\n      TokenCache.obtainTokensForNamenodes(credentials, inputPaths, getConf());\n    }\n  }",
          "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/SimpleCopyListing.java",
          "extendedDetails": {}
        }
      ]
    },
    "5af572b6443715b7a741296c1bd520a1840f9a7c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13427. Eliminate needless uses of FileSystem#{exists(), isFile(), isDirectory()}. Contributed by Steve Loughran and Mingliang Liu\n",
      "commitDate": "15/11/16 10:57 AM",
      "commitName": "5af572b6443715b7a741296c1bd520a1840f9a7c",
      "commitAuthor": "Mingliang Liu",
      "commitDateOld": "19/10/16 5:37 PM",
      "commitNameOld": "8650cc84f20e7d8c32dcdcd91c94372d476e2276",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 26.76,
      "commitsBetweenForRepo": 265,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,75 @@\n   protected void validatePaths(DistCpOptions options)\n       throws IOException, InvalidInputException {\n \n     Path targetPath \u003d options.getTargetPath();\n     FileSystem targetFS \u003d targetPath.getFileSystem(getConf());\n-    boolean targetIsFile \u003d targetFS.isFile(targetPath);\n+    boolean targetExists \u003d false;\n+    boolean targetIsFile \u003d false;\n+    try {\n+      targetIsFile \u003d targetFS.getFileStatus(targetPath).isFile();\n+      targetExists \u003d true;\n+    } catch (FileNotFoundException ignored) {\n+    }\n     targetPath \u003d targetFS.makeQualified(targetPath);\n     final boolean targetIsReservedRaw \u003d\n         Path.getPathWithoutSchemeAndAuthority(targetPath).toString().\n             startsWith(HDFS_RESERVED_RAW_DIRECTORY_NAME);\n \n     //If target is a file, then source has to be single file\n     if (targetIsFile) {\n       if (options.getSourcePaths().size() \u003e 1) {\n         throw new InvalidInputException(\"Multiple source being copied to a file: \" +\n             targetPath);\n       }\n \n       Path srcPath \u003d options.getSourcePaths().get(0);\n       FileSystem sourceFS \u003d srcPath.getFileSystem(getConf());\n       if (!sourceFS.isFile(srcPath)) {\n         throw new InvalidInputException(\"Cannot copy \" + srcPath +\n             \", which is not a file to \" + targetPath);\n       }\n     }\n \n-    if (options.shouldAtomicCommit() \u0026\u0026 targetFS.exists(targetPath)) {\n+    if (options.shouldAtomicCommit() \u0026\u0026 targetExists) {\n       throw new InvalidInputException(\"Target path for atomic-commit already exists: \" +\n         targetPath + \". Cannot atomic-commit to pre-existing target-path.\");\n     }\n \n     for (Path path: options.getSourcePaths()) {\n       FileSystem fs \u003d path.getFileSystem(getConf());\n       if (!fs.exists(path)) {\n         throw new InvalidInputException(path + \" doesn\u0027t exist\");\n       }\n       if (Path.getPathWithoutSchemeAndAuthority(path).toString().\n           startsWith(HDFS_RESERVED_RAW_DIRECTORY_NAME)) {\n         if (!targetIsReservedRaw) {\n           final String msg \u003d \"The source path \u0027\" + path + \"\u0027 starts with \" +\n               HDFS_RESERVED_RAW_DIRECTORY_NAME + \" but the target path \u0027\" +\n               targetPath + \"\u0027 does not. Either all or none of the paths must \" +\n               \"have this prefix.\";\n           throw new InvalidInputException(msg);\n         }\n       } else if (targetIsReservedRaw) {\n         final String msg \u003d \"The target path \u0027\" + targetPath + \"\u0027 starts with \" +\n                 HDFS_RESERVED_RAW_DIRECTORY_NAME + \" but the source path \u0027\" +\n                 path + \"\u0027 does not. Either all or none of the paths must \" +\n                 \"have this prefix.\";\n         throw new InvalidInputException(msg);\n       }\n     }\n \n     if (targetIsReservedRaw) {\n       options.preserveRawXattrs();\n       getConf().setBoolean(DistCpConstants.CONF_LABEL_PRESERVE_RAWXATTRS, true);\n     }\n \n     /* This is requires to allow map tasks to access each of the source\n        clusters. This would retrieve the delegation token for each unique\n        file system and add them to job\u0027s private credential store\n      */\n     Credentials credentials \u003d getCredentials();\n     if (credentials !\u003d null) {\n       Path[] inputPaths \u003d options.getSourcePaths().toArray(new Path[1]);\n       TokenCache.obtainTokensForNamenodes(credentials, inputPaths, getConf());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void validatePaths(DistCpOptions options)\n      throws IOException, InvalidInputException {\n\n    Path targetPath \u003d options.getTargetPath();\n    FileSystem targetFS \u003d targetPath.getFileSystem(getConf());\n    boolean targetExists \u003d false;\n    boolean targetIsFile \u003d false;\n    try {\n      targetIsFile \u003d targetFS.getFileStatus(targetPath).isFile();\n      targetExists \u003d true;\n    } catch (FileNotFoundException ignored) {\n    }\n    targetPath \u003d targetFS.makeQualified(targetPath);\n    final boolean targetIsReservedRaw \u003d\n        Path.getPathWithoutSchemeAndAuthority(targetPath).toString().\n            startsWith(HDFS_RESERVED_RAW_DIRECTORY_NAME);\n\n    //If target is a file, then source has to be single file\n    if (targetIsFile) {\n      if (options.getSourcePaths().size() \u003e 1) {\n        throw new InvalidInputException(\"Multiple source being copied to a file: \" +\n            targetPath);\n      }\n\n      Path srcPath \u003d options.getSourcePaths().get(0);\n      FileSystem sourceFS \u003d srcPath.getFileSystem(getConf());\n      if (!sourceFS.isFile(srcPath)) {\n        throw new InvalidInputException(\"Cannot copy \" + srcPath +\n            \", which is not a file to \" + targetPath);\n      }\n    }\n\n    if (options.shouldAtomicCommit() \u0026\u0026 targetExists) {\n      throw new InvalidInputException(\"Target path for atomic-commit already exists: \" +\n        targetPath + \". Cannot atomic-commit to pre-existing target-path.\");\n    }\n\n    for (Path path: options.getSourcePaths()) {\n      FileSystem fs \u003d path.getFileSystem(getConf());\n      if (!fs.exists(path)) {\n        throw new InvalidInputException(path + \" doesn\u0027t exist\");\n      }\n      if (Path.getPathWithoutSchemeAndAuthority(path).toString().\n          startsWith(HDFS_RESERVED_RAW_DIRECTORY_NAME)) {\n        if (!targetIsReservedRaw) {\n          final String msg \u003d \"The source path \u0027\" + path + \"\u0027 starts with \" +\n              HDFS_RESERVED_RAW_DIRECTORY_NAME + \" but the target path \u0027\" +\n              targetPath + \"\u0027 does not. Either all or none of the paths must \" +\n              \"have this prefix.\";\n          throw new InvalidInputException(msg);\n        }\n      } else if (targetIsReservedRaw) {\n        final String msg \u003d \"The target path \u0027\" + targetPath + \"\u0027 starts with \" +\n                HDFS_RESERVED_RAW_DIRECTORY_NAME + \" but the source path \u0027\" +\n                path + \"\u0027 does not. Either all or none of the paths must \" +\n                \"have this prefix.\";\n        throw new InvalidInputException(msg);\n      }\n    }\n\n    if (targetIsReservedRaw) {\n      options.preserveRawXattrs();\n      getConf().setBoolean(DistCpConstants.CONF_LABEL_PRESERVE_RAWXATTRS, true);\n    }\n\n    /* This is requires to allow map tasks to access each of the source\n       clusters. This would retrieve the delegation token for each unique\n       file system and add them to job\u0027s private credential store\n     */\n    Credentials credentials \u003d getCredentials();\n    if (credentials !\u003d null) {\n      Path[] inputPaths \u003d options.getSourcePaths().toArray(new Path[1]);\n      TokenCache.obtainTokensForNamenodes(credentials, inputPaths, getConf());\n    }\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/SimpleCopyListing.java",
      "extendedDetails": {}
    },
    "041b8326a1511b721958792a6b94ecfe27d7a1fb": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6007. Add support to distcp to preserve raw.* namespace extended attributes. (clamb)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/fs-encryption@1616657 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/14 6:32 PM",
      "commitName": "041b8326a1511b721958792a6b94ecfe27d7a1fb",
      "commitAuthor": "Charles Lamb",
      "commitDateOld": "06/06/14 7:45 AM",
      "commitNameOld": "f81c7b0252839ae0dcd92fe2dc626ff9f87cd2c9",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 62.45,
      "commitsBetweenForRepo": 482,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,69 @@\n   protected void validatePaths(DistCpOptions options)\n       throws IOException, InvalidInputException {\n \n     Path targetPath \u003d options.getTargetPath();\n     FileSystem targetFS \u003d targetPath.getFileSystem(getConf());\n     boolean targetIsFile \u003d targetFS.isFile(targetPath);\n+    targetPath \u003d targetFS.makeQualified(targetPath);\n+    final boolean targetIsReservedRaw \u003d\n+        Path.getPathWithoutSchemeAndAuthority(targetPath).toString().\n+            startsWith(HDFS_RESERVED_RAW_DIRECTORY_NAME);\n \n     //If target is a file, then source has to be single file\n     if (targetIsFile) {\n       if (options.getSourcePaths().size() \u003e 1) {\n         throw new InvalidInputException(\"Multiple source being copied to a file: \" +\n             targetPath);\n       }\n \n       Path srcPath \u003d options.getSourcePaths().get(0);\n       FileSystem sourceFS \u003d srcPath.getFileSystem(getConf());\n       if (!sourceFS.isFile(srcPath)) {\n         throw new InvalidInputException(\"Cannot copy \" + srcPath +\n             \", which is not a file to \" + targetPath);\n       }\n     }\n \n     if (options.shouldAtomicCommit() \u0026\u0026 targetFS.exists(targetPath)) {\n       throw new InvalidInputException(\"Target path for atomic-commit already exists: \" +\n         targetPath + \". Cannot atomic-commit to pre-existing target-path.\");\n     }\n \n     for (Path path: options.getSourcePaths()) {\n       FileSystem fs \u003d path.getFileSystem(getConf());\n       if (!fs.exists(path)) {\n         throw new InvalidInputException(path + \" doesn\u0027t exist\");\n       }\n+      if (Path.getPathWithoutSchemeAndAuthority(path).toString().\n+          startsWith(HDFS_RESERVED_RAW_DIRECTORY_NAME)) {\n+        if (!targetIsReservedRaw) {\n+          final String msg \u003d \"The source path \u0027\" + path + \"\u0027 starts with \" +\n+              HDFS_RESERVED_RAW_DIRECTORY_NAME + \" but the target path \u0027\" +\n+              targetPath + \"\u0027 does not. Either all or none of the paths must \" +\n+              \"have this prefix.\";\n+          throw new InvalidInputException(msg);\n+        }\n+      } else if (targetIsReservedRaw) {\n+        final String msg \u003d \"The target path \u0027\" + targetPath + \"\u0027 starts with \" +\n+                HDFS_RESERVED_RAW_DIRECTORY_NAME + \" but the source path \u0027\" +\n+                path + \"\u0027 does not. Either all or none of the paths must \" +\n+                \"have this prefix.\";\n+        throw new InvalidInputException(msg);\n+      }\n+    }\n+\n+    if (targetIsReservedRaw) {\n+      options.preserveRawXattrs();\n+      getConf().setBoolean(DistCpConstants.CONF_LABEL_PRESERVE_RAWXATTRS, true);\n     }\n \n     /* This is requires to allow map tasks to access each of the source\n        clusters. This would retrieve the delegation token for each unique\n        file system and add them to job\u0027s private credential store\n      */\n     Credentials credentials \u003d getCredentials();\n     if (credentials !\u003d null) {\n       Path[] inputPaths \u003d options.getSourcePaths().toArray(new Path[1]);\n       TokenCache.obtainTokensForNamenodes(credentials, inputPaths, getConf());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void validatePaths(DistCpOptions options)\n      throws IOException, InvalidInputException {\n\n    Path targetPath \u003d options.getTargetPath();\n    FileSystem targetFS \u003d targetPath.getFileSystem(getConf());\n    boolean targetIsFile \u003d targetFS.isFile(targetPath);\n    targetPath \u003d targetFS.makeQualified(targetPath);\n    final boolean targetIsReservedRaw \u003d\n        Path.getPathWithoutSchemeAndAuthority(targetPath).toString().\n            startsWith(HDFS_RESERVED_RAW_DIRECTORY_NAME);\n\n    //If target is a file, then source has to be single file\n    if (targetIsFile) {\n      if (options.getSourcePaths().size() \u003e 1) {\n        throw new InvalidInputException(\"Multiple source being copied to a file: \" +\n            targetPath);\n      }\n\n      Path srcPath \u003d options.getSourcePaths().get(0);\n      FileSystem sourceFS \u003d srcPath.getFileSystem(getConf());\n      if (!sourceFS.isFile(srcPath)) {\n        throw new InvalidInputException(\"Cannot copy \" + srcPath +\n            \", which is not a file to \" + targetPath);\n      }\n    }\n\n    if (options.shouldAtomicCommit() \u0026\u0026 targetFS.exists(targetPath)) {\n      throw new InvalidInputException(\"Target path for atomic-commit already exists: \" +\n        targetPath + \". Cannot atomic-commit to pre-existing target-path.\");\n    }\n\n    for (Path path: options.getSourcePaths()) {\n      FileSystem fs \u003d path.getFileSystem(getConf());\n      if (!fs.exists(path)) {\n        throw new InvalidInputException(path + \" doesn\u0027t exist\");\n      }\n      if (Path.getPathWithoutSchemeAndAuthority(path).toString().\n          startsWith(HDFS_RESERVED_RAW_DIRECTORY_NAME)) {\n        if (!targetIsReservedRaw) {\n          final String msg \u003d \"The source path \u0027\" + path + \"\u0027 starts with \" +\n              HDFS_RESERVED_RAW_DIRECTORY_NAME + \" but the target path \u0027\" +\n              targetPath + \"\u0027 does not. Either all or none of the paths must \" +\n              \"have this prefix.\";\n          throw new InvalidInputException(msg);\n        }\n      } else if (targetIsReservedRaw) {\n        final String msg \u003d \"The target path \u0027\" + targetPath + \"\u0027 starts with \" +\n                HDFS_RESERVED_RAW_DIRECTORY_NAME + \" but the source path \u0027\" +\n                path + \"\u0027 does not. Either all or none of the paths must \" +\n                \"have this prefix.\";\n        throw new InvalidInputException(msg);\n      }\n    }\n\n    if (targetIsReservedRaw) {\n      options.preserveRawXattrs();\n      getConf().setBoolean(DistCpConstants.CONF_LABEL_PRESERVE_RAWXATTRS, true);\n    }\n\n    /* This is requires to allow map tasks to access each of the source\n       clusters. This would retrieve the delegation token for each unique\n       file system and add them to job\u0027s private credential store\n     */\n    Credentials credentials \u003d getCredentials();\n    if (credentials !\u003d null) {\n      Path[] inputPaths \u003d options.getSourcePaths().toArray(new Path[1]);\n      TokenCache.obtainTokensForNamenodes(credentials, inputPaths, getConf());\n    }\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/SimpleCopyListing.java",
      "extendedDetails": {}
    },
    "d06948002fb0cabf72cc0d46bf2fa67d45370f67": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-2765. DistCp Rewrite. (Mithun Radhakrishnan via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1236045 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/01/12 10:36 PM",
      "commitName": "d06948002fb0cabf72cc0d46bf2fa67d45370f67",
      "commitAuthor": "Mahadev Konar",
      "diff": "@@ -0,0 +1,44 @@\n+  protected void validatePaths(DistCpOptions options)\n+      throws IOException, InvalidInputException {\n+\n+    Path targetPath \u003d options.getTargetPath();\n+    FileSystem targetFS \u003d targetPath.getFileSystem(getConf());\n+    boolean targetIsFile \u003d targetFS.isFile(targetPath);\n+\n+    //If target is a file, then source has to be single file\n+    if (targetIsFile) {\n+      if (options.getSourcePaths().size() \u003e 1) {\n+        throw new InvalidInputException(\"Multiple source being copied to a file: \" +\n+            targetPath);\n+      }\n+\n+      Path srcPath \u003d options.getSourcePaths().get(0);\n+      FileSystem sourceFS \u003d srcPath.getFileSystem(getConf());\n+      if (!sourceFS.isFile(srcPath)) {\n+        throw new InvalidInputException(\"Cannot copy \" + srcPath +\n+            \", which is not a file to \" + targetPath);\n+      }\n+    }\n+\n+    if (options.shouldAtomicCommit() \u0026\u0026 targetFS.exists(targetPath)) {\n+      throw new InvalidInputException(\"Target path for atomic-commit already exists: \" +\n+        targetPath + \". Cannot atomic-commit to pre-existing target-path.\");\n+    }\n+\n+    for (Path path: options.getSourcePaths()) {\n+      FileSystem fs \u003d path.getFileSystem(getConf());\n+      if (!fs.exists(path)) {\n+        throw new InvalidInputException(path + \" doesn\u0027t exist\");\n+      }\n+    }\n+\n+    /* This is requires to allow map tasks to access each of the source\n+       clusters. This would retrieve the delegation token for each unique\n+       file system and add them to job\u0027s private credential store\n+     */\n+    Credentials credentials \u003d getCredentials();\n+    if (credentials !\u003d null) {\n+      Path[] inputPaths \u003d options.getSourcePaths().toArray(new Path[1]);\n+      TokenCache.obtainTokensForNamenodes(credentials, inputPaths, getConf());\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected void validatePaths(DistCpOptions options)\n      throws IOException, InvalidInputException {\n\n    Path targetPath \u003d options.getTargetPath();\n    FileSystem targetFS \u003d targetPath.getFileSystem(getConf());\n    boolean targetIsFile \u003d targetFS.isFile(targetPath);\n\n    //If target is a file, then source has to be single file\n    if (targetIsFile) {\n      if (options.getSourcePaths().size() \u003e 1) {\n        throw new InvalidInputException(\"Multiple source being copied to a file: \" +\n            targetPath);\n      }\n\n      Path srcPath \u003d options.getSourcePaths().get(0);\n      FileSystem sourceFS \u003d srcPath.getFileSystem(getConf());\n      if (!sourceFS.isFile(srcPath)) {\n        throw new InvalidInputException(\"Cannot copy \" + srcPath +\n            \", which is not a file to \" + targetPath);\n      }\n    }\n\n    if (options.shouldAtomicCommit() \u0026\u0026 targetFS.exists(targetPath)) {\n      throw new InvalidInputException(\"Target path for atomic-commit already exists: \" +\n        targetPath + \". Cannot atomic-commit to pre-existing target-path.\");\n    }\n\n    for (Path path: options.getSourcePaths()) {\n      FileSystem fs \u003d path.getFileSystem(getConf());\n      if (!fs.exists(path)) {\n        throw new InvalidInputException(path + \" doesn\u0027t exist\");\n      }\n    }\n\n    /* This is requires to allow map tasks to access each of the source\n       clusters. This would retrieve the delegation token for each unique\n       file system and add them to job\u0027s private credential store\n     */\n    Credentials credentials \u003d getCredentials();\n    if (credentials !\u003d null) {\n      Path[] inputPaths \u003d options.getSourcePaths().toArray(new Path[1]);\n      TokenCache.obtainTokensForNamenodes(credentials, inputPaths, getConf());\n    }\n  }",
      "path": "hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/SimpleCopyListing.java"
    }
  }
}