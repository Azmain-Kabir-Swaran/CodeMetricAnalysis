{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockReceiver.java",
  "functionName": "receiveBlock",
  "functionId": "receiveBlock___mirrOut-DataOutputStream__mirrIn-DataInputStream__replyOut-DataOutputStream__mirrAddr-String__throttlerArg-DataTransferThrottler__downstreams-DatanodeInfo[]__isReplaceBlock-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
  "functionStartLine": 953,
  "functionEndLine": 1084,
  "numCommitsSeen": 240,
  "timeTaken": 14015,
  "changeHistory": [
    "e1dfc060f8f0247f97127c75c9284a068fc93907",
    "1543d0f5be6a02ad00e7a33e35d78af8516043e3",
    "5485d93bda3329a7c80767c3723cc6e1a9233dbc",
    "b57368b6f893cb27d77fc9425e116f1312f4790f",
    "4e9029653dfa7a803d73c173cb7044f7e0dc1eb1",
    "df983b524ab68ea0c70cee9033bfff2d28052cbf",
    "dcedb72af468128458e597f08d22f5c34b744ae5",
    "aeecfa24f4fb6af289920cbf8830c394e66bd78e",
    "176ff5ce90f2cbcd8342016d0f5570337d2ff79f",
    "b258b344bb76af6492828201959e36b45f0f75b8",
    "608c4998419c18fd95019b28cc56b5bd5aa4cc01",
    "023133cef9a7ca05364cefbcead57c921589eda7",
    "b9f6d0c956f0278c8b9b83e05b523a442a730ebb",
    "b6b95ff66700e4db1d8d59a31c3048cb10504262",
    "2fb04d2a30919bde350f566a39faa7085f1a1d7b",
    "195961a7c1da86421761162836766b1de07930fd",
    "6554994fab2d8a2a139fb71ed54be144f4057e08",
    "471b1368e2a81b4d9850f0f4d98d31df1451354c",
    "c8182ea76412e49c0c98ee252321c584fabb4c59",
    "57b28693ee295746c6d168d37dd05eaf7b601b87",
    "6780b086d8378a75614e2d4563ad5784233356dc",
    "1c6b5d2b5841e5219a98937088cde4ae63869f80",
    "7723b139d55fc2c3954939559cb4914046a0f81c",
    "7e56bfe40589a1aa9b5ef20b342e421823cd0592",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
    "d4fb8821630f2da107b6c438a449c35df3686595",
    "83cf475050dba27e72b4e399491638c670621175",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "e1dfc060f8f0247f97127c75c9284a068fc93907": "Ybodychange",
    "1543d0f5be6a02ad00e7a33e35d78af8516043e3": "Ybodychange",
    "5485d93bda3329a7c80767c3723cc6e1a9233dbc": "Ybodychange",
    "b57368b6f893cb27d77fc9425e116f1312f4790f": "Ybodychange",
    "4e9029653dfa7a803d73c173cb7044f7e0dc1eb1": "Ybodychange",
    "df983b524ab68ea0c70cee9033bfff2d28052cbf": "Ybodychange",
    "dcedb72af468128458e597f08d22f5c34b744ae5": "Ybodychange",
    "aeecfa24f4fb6af289920cbf8830c394e66bd78e": "Ybodychange",
    "176ff5ce90f2cbcd8342016d0f5570337d2ff79f": "Ybodychange",
    "b258b344bb76af6492828201959e36b45f0f75b8": "Ybodychange",
    "608c4998419c18fd95019b28cc56b5bd5aa4cc01": "Ybodychange",
    "023133cef9a7ca05364cefbcead57c921589eda7": "Ybodychange",
    "b9f6d0c956f0278c8b9b83e05b523a442a730ebb": "Ybodychange",
    "b6b95ff66700e4db1d8d59a31c3048cb10504262": "Ybodychange",
    "2fb04d2a30919bde350f566a39faa7085f1a1d7b": "Ybodychange",
    "195961a7c1da86421761162836766b1de07930fd": "Ymultichange(Yparameterchange,Ybodychange)",
    "6554994fab2d8a2a139fb71ed54be144f4057e08": "Ymultichange(Yparameterchange,Ybodychange)",
    "471b1368e2a81b4d9850f0f4d98d31df1451354c": "Ymultichange(Yparameterchange,Ybodychange)",
    "c8182ea76412e49c0c98ee252321c584fabb4c59": "Ybodychange",
    "57b28693ee295746c6d168d37dd05eaf7b601b87": "Ybodychange",
    "6780b086d8378a75614e2d4563ad5784233356dc": "Ybodychange",
    "1c6b5d2b5841e5219a98937088cde4ae63869f80": "Ybodychange",
    "7723b139d55fc2c3954939559cb4914046a0f81c": "Ybodychange",
    "7e56bfe40589a1aa9b5ef20b342e421823cd0592": "Ybodychange",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": "Ybodychange",
    "d4fb8821630f2da107b6c438a449c35df3686595": "Ybodychange",
    "83cf475050dba27e72b4e399491638c670621175": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "e1dfc060f8f0247f97127c75c9284a068fc93907": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14486. The exception classes in some throw statements do not accurately describe why they are thrown. Contributed by Ayush Saxena.\n",
      "commitDate": "06/06/19 11:59 AM",
      "commitName": "e1dfc060f8f0247f97127c75c9284a068fc93907",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "11/02/19 10:09 AM",
      "commitNameOld": "0ceb1b70f3200873fe1f40c264b91051b4a3d721",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 115.03,
      "commitsBetweenForRepo": 827,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,132 +1,132 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams,\n       boolean isReplaceBlock) throws IOException {\n \n     syncOnClose \u003d datanode.getDnConf().syncOnClose;\n     dirSyncOnFinalize \u003d syncOnClose;\n     boolean responderClosed \u003d false;\n     mirrorOut \u003d mirrOut;\n     mirrorAddr \u003d mirrAddr;\n     initPerfMonitoring(downstreams);\n     throttler \u003d throttlerArg;\n \n     this.replyOut \u003d replyOut;\n     this.isReplaceBlock \u003d isReplaceBlock;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // Hold a volume reference to finalize block.\n         try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n           // close the block/crc files\n           close();\n           block.setNumBytes(replicaInfo.getNumBytes());\n \n           if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n             // for TRANSFER_RBW, convert temporary to RBW\n             datanode.data.convertTemporaryToRbw(block);\n           } else {\n             // for isDatnode or TRANSFER_FINALIZED\n             // Finalize the block.\n             datanode.data.finalizeBlock(block, dirSyncOnFinalize);\n           }\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       replicaInfo.releaseAllBytesReserved();\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             try (Writer out \u003d new OutputStreamWriter(\n                 replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             } finally {\n               IOUtils.closeStream(streams.getDataOut());\n             }\n             try {              \n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n-            throw new IOException(\"Interrupted receiveBlock\");\n+            throw new InterruptedIOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n    syncOnClose \u003d datanode.getDnConf().syncOnClose;\n    dirSyncOnFinalize \u003d syncOnClose;\n    boolean responderClosed \u003d false;\n    mirrorOut \u003d mirrOut;\n    mirrorAddr \u003d mirrAddr;\n    initPerfMonitoring(downstreams);\n    throttler \u003d throttlerArg;\n\n    this.replyOut \u003d replyOut;\n    this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // Hold a volume reference to finalize block.\n        try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n          // close the block/crc files\n          close();\n          block.setNumBytes(replicaInfo.getNumBytes());\n\n          if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n            // for TRANSFER_RBW, convert temporary to RBW\n            datanode.data.convertTemporaryToRbw(block);\n          } else {\n            // for isDatnode or TRANSFER_FINALIZED\n            // Finalize the block.\n            datanode.data.finalizeBlock(block, dirSyncOnFinalize);\n          }\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      replicaInfo.releaseAllBytesReserved();\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            try (Writer out \u003d new OutputStreamWriter(\n                replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            } finally {\n              IOUtils.closeStream(streams.getDataOut());\n            }\n            try {              \n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new InterruptedIOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "1543d0f5be6a02ad00e7a33e35d78af8516043e3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5042. Completed files lost after power failure. Contributed by Vinayakumar B.\n",
      "commitDate": "31/05/17 8:55 AM",
      "commitName": "1543d0f5be6a02ad00e7a33e35d78af8516043e3",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "31/05/17 8:09 AM",
      "commitNameOld": "13de636b4079b077890ad10389ff350dcf8086a2",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 0.03,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,131 +1,132 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams,\n       boolean isReplaceBlock) throws IOException {\n \n     syncOnClose \u003d datanode.getDnConf().syncOnClose;\n+    dirSyncOnFinalize \u003d syncOnClose;\n     boolean responderClosed \u003d false;\n     mirrorOut \u003d mirrOut;\n     mirrorAddr \u003d mirrAddr;\n     initPerfMonitoring(downstreams);\n     throttler \u003d throttlerArg;\n \n     this.replyOut \u003d replyOut;\n     this.isReplaceBlock \u003d isReplaceBlock;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // Hold a volume reference to finalize block.\n         try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n           // close the block/crc files\n           close();\n           block.setNumBytes(replicaInfo.getNumBytes());\n \n           if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n             // for TRANSFER_RBW, convert temporary to RBW\n             datanode.data.convertTemporaryToRbw(block);\n           } else {\n             // for isDatnode or TRANSFER_FINALIZED\n             // Finalize the block.\n-            datanode.data.finalizeBlock(block);\n+            datanode.data.finalizeBlock(block, dirSyncOnFinalize);\n           }\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       replicaInfo.releaseAllBytesReserved();\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             try (Writer out \u003d new OutputStreamWriter(\n                 replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             } finally {\n               IOUtils.closeStream(streams.getDataOut());\n             }\n             try {              \n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n    syncOnClose \u003d datanode.getDnConf().syncOnClose;\n    dirSyncOnFinalize \u003d syncOnClose;\n    boolean responderClosed \u003d false;\n    mirrorOut \u003d mirrOut;\n    mirrorAddr \u003d mirrAddr;\n    initPerfMonitoring(downstreams);\n    throttler \u003d throttlerArg;\n\n    this.replyOut \u003d replyOut;\n    this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // Hold a volume reference to finalize block.\n        try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n          // close the block/crc files\n          close();\n          block.setNumBytes(replicaInfo.getNumBytes());\n\n          if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n            // for TRANSFER_RBW, convert temporary to RBW\n            datanode.data.convertTemporaryToRbw(block);\n          } else {\n            // for isDatnode or TRANSFER_FINALIZED\n            // Finalize the block.\n            datanode.data.finalizeBlock(block, dirSyncOnFinalize);\n          }\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      replicaInfo.releaseAllBytesReserved();\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            try (Writer out \u003d new OutputStreamWriter(\n                replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            } finally {\n              IOUtils.closeStream(streams.getDataOut());\n            }\n            try {              \n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "5485d93bda3329a7c80767c3723cc6e1a9233dbc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11603. Improve slow mirror/disk warnings in BlockReceiver.\n",
      "commitDate": "31/03/17 12:10 PM",
      "commitName": "5485d93bda3329a7c80767c3723cc6e1a9233dbc",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "17/03/17 7:02 PM",
      "commitNameOld": "ffa160ddb824cbcb8ab6b10ee1414507686e3c63",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 13.71,
      "commitsBetweenForRepo": 83,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,137 +1,131 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams,\n       boolean isReplaceBlock) throws IOException {\n \n     syncOnClose \u003d datanode.getDnConf().syncOnClose;\n     boolean responderClosed \u003d false;\n     mirrorOut \u003d mirrOut;\n     mirrorAddr \u003d mirrAddr;\n-    isPenultimateNode \u003d ((downstreams !\u003d null) \u0026\u0026 (downstreams.length \u003d\u003d 1));\n-    if (isPenultimateNode) {\n-      mirrorNameForMetrics \u003d (downstreams[0].getInfoSecurePort() !\u003d 0 ?\n-          downstreams[0].getInfoSecureAddr() : downstreams[0].getInfoAddr());\n-      LOG.debug(\"Will collect peer metrics for downstream node {}\",\n-          mirrorNameForMetrics);\n-    }\n+    initPerfMonitoring(downstreams);\n     throttler \u003d throttlerArg;\n \n     this.replyOut \u003d replyOut;\n     this.isReplaceBlock \u003d isReplaceBlock;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // Hold a volume reference to finalize block.\n         try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n           // close the block/crc files\n           close();\n           block.setNumBytes(replicaInfo.getNumBytes());\n \n           if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n             // for TRANSFER_RBW, convert temporary to RBW\n             datanode.data.convertTemporaryToRbw(block);\n           } else {\n             // for isDatnode or TRANSFER_FINALIZED\n             // Finalize the block.\n             datanode.data.finalizeBlock(block);\n           }\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       replicaInfo.releaseAllBytesReserved();\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             try (Writer out \u003d new OutputStreamWriter(\n                 replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             } finally {\n               IOUtils.closeStream(streams.getDataOut());\n             }\n             try {              \n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n    syncOnClose \u003d datanode.getDnConf().syncOnClose;\n    boolean responderClosed \u003d false;\n    mirrorOut \u003d mirrOut;\n    mirrorAddr \u003d mirrAddr;\n    initPerfMonitoring(downstreams);\n    throttler \u003d throttlerArg;\n\n    this.replyOut \u003d replyOut;\n    this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // Hold a volume reference to finalize block.\n        try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n          // close the block/crc files\n          close();\n          block.setNumBytes(replicaInfo.getNumBytes());\n\n          if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n            // for TRANSFER_RBW, convert temporary to RBW\n            datanode.data.convertTemporaryToRbw(block);\n          } else {\n            // for isDatnode or TRANSFER_FINALIZED\n            // Finalize the block.\n            datanode.data.finalizeBlock(block);\n          }\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      replicaInfo.releaseAllBytesReserved();\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            try (Writer out \u003d new OutputStreamWriter(\n                replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            } finally {\n              IOUtils.closeStream(streams.getDataOut());\n            }\n            try {              \n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "b57368b6f893cb27d77fc9425e116f1312f4790f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11194. Maintain aggregated peer performance metrics on NameNode.\n",
      "commitDate": "24/01/17 4:58 PM",
      "commitName": "b57368b6f893cb27d77fc9425e116f1312f4790f",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "28/12/16 10:08 PM",
      "commitNameOld": "603f3ef1386048111940b66f3a0750ab84d0588f",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 26.78,
      "commitsBetweenForRepo": 129,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,132 +1,137 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams,\n       boolean isReplaceBlock) throws IOException {\n \n     syncOnClose \u003d datanode.getDnConf().syncOnClose;\n     boolean responderClosed \u003d false;\n     mirrorOut \u003d mirrOut;\n     mirrorAddr \u003d mirrAddr;\n-    bracketedMirrorAddr \u003d \"[\" + mirrAddr + \"]\";\n     isPenultimateNode \u003d ((downstreams !\u003d null) \u0026\u0026 (downstreams.length \u003d\u003d 1));\n+    if (isPenultimateNode) {\n+      mirrorNameForMetrics \u003d (downstreams[0].getInfoSecurePort() !\u003d 0 ?\n+          downstreams[0].getInfoSecureAddr() : downstreams[0].getInfoAddr());\n+      LOG.debug(\"Will collect peer metrics for downstream node {}\",\n+          mirrorNameForMetrics);\n+    }\n     throttler \u003d throttlerArg;\n \n     this.replyOut \u003d replyOut;\n     this.isReplaceBlock \u003d isReplaceBlock;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // Hold a volume reference to finalize block.\n         try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n           // close the block/crc files\n           close();\n           block.setNumBytes(replicaInfo.getNumBytes());\n \n           if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n             // for TRANSFER_RBW, convert temporary to RBW\n             datanode.data.convertTemporaryToRbw(block);\n           } else {\n             // for isDatnode or TRANSFER_FINALIZED\n             // Finalize the block.\n             datanode.data.finalizeBlock(block);\n           }\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       replicaInfo.releaseAllBytesReserved();\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             try (Writer out \u003d new OutputStreamWriter(\n                 replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             } finally {\n               IOUtils.closeStream(streams.getDataOut());\n             }\n             try {              \n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n    syncOnClose \u003d datanode.getDnConf().syncOnClose;\n    boolean responderClosed \u003d false;\n    mirrorOut \u003d mirrOut;\n    mirrorAddr \u003d mirrAddr;\n    isPenultimateNode \u003d ((downstreams !\u003d null) \u0026\u0026 (downstreams.length \u003d\u003d 1));\n    if (isPenultimateNode) {\n      mirrorNameForMetrics \u003d (downstreams[0].getInfoSecurePort() !\u003d 0 ?\n          downstreams[0].getInfoSecureAddr() : downstreams[0].getInfoAddr());\n      LOG.debug(\"Will collect peer metrics for downstream node {}\",\n          mirrorNameForMetrics);\n    }\n    throttler \u003d throttlerArg;\n\n    this.replyOut \u003d replyOut;\n    this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // Hold a volume reference to finalize block.\n        try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n          // close the block/crc files\n          close();\n          block.setNumBytes(replicaInfo.getNumBytes());\n\n          if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n            // for TRANSFER_RBW, convert temporary to RBW\n            datanode.data.convertTemporaryToRbw(block);\n          } else {\n            // for isDatnode or TRANSFER_FINALIZED\n            // Finalize the block.\n            datanode.data.finalizeBlock(block);\n          }\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      replicaInfo.releaseAllBytesReserved();\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            try (Writer out \u003d new OutputStreamWriter(\n                replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            } finally {\n              IOUtils.closeStream(streams.getDataOut());\n            }\n            try {              \n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "4e9029653dfa7a803d73c173cb7044f7e0dc1eb1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10917. Collect peer performance statistics on DataNode. Contributed by Xiaobing Zhou.\n",
      "commitDate": "22/12/16 11:46 PM",
      "commitName": "4e9029653dfa7a803d73c173cb7044f7e0dc1eb1",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "20/12/16 1:17 PM",
      "commitNameOld": "5daa8d8631835de97d4e4979e507a080017ca159",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 2.44,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,130 +1,132 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams,\n       boolean isReplaceBlock) throws IOException {\n \n-      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n-      boolean responderClosed \u003d false;\n-      mirrorOut \u003d mirrOut;\n-      mirrorAddr \u003d mirrAddr;\n-      throttler \u003d throttlerArg;\n+    syncOnClose \u003d datanode.getDnConf().syncOnClose;\n+    boolean responderClosed \u003d false;\n+    mirrorOut \u003d mirrOut;\n+    mirrorAddr \u003d mirrAddr;\n+    bracketedMirrorAddr \u003d \"[\" + mirrAddr + \"]\";\n+    isPenultimateNode \u003d ((downstreams !\u003d null) \u0026\u0026 (downstreams.length \u003d\u003d 1));\n+    throttler \u003d throttlerArg;\n \n-      this.replyOut \u003d replyOut;\n-      this.isReplaceBlock \u003d isReplaceBlock;\n+    this.replyOut \u003d replyOut;\n+    this.isReplaceBlock \u003d isReplaceBlock;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // Hold a volume reference to finalize block.\n         try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n           // close the block/crc files\n           close();\n           block.setNumBytes(replicaInfo.getNumBytes());\n \n           if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n             // for TRANSFER_RBW, convert temporary to RBW\n             datanode.data.convertTemporaryToRbw(block);\n           } else {\n             // for isDatnode or TRANSFER_FINALIZED\n             // Finalize the block.\n             datanode.data.finalizeBlock(block);\n           }\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       replicaInfo.releaseAllBytesReserved();\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             try (Writer out \u003d new OutputStreamWriter(\n                 replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             } finally {\n               IOUtils.closeStream(streams.getDataOut());\n             }\n             try {              \n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n    syncOnClose \u003d datanode.getDnConf().syncOnClose;\n    boolean responderClosed \u003d false;\n    mirrorOut \u003d mirrOut;\n    mirrorAddr \u003d mirrAddr;\n    bracketedMirrorAddr \u003d \"[\" + mirrAddr + \"]\";\n    isPenultimateNode \u003d ((downstreams !\u003d null) \u0026\u0026 (downstreams.length \u003d\u003d 1));\n    throttler \u003d throttlerArg;\n\n    this.replyOut \u003d replyOut;\n    this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // Hold a volume reference to finalize block.\n        try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n          // close the block/crc files\n          close();\n          block.setNumBytes(replicaInfo.getNumBytes());\n\n          if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n            // for TRANSFER_RBW, convert temporary to RBW\n            datanode.data.convertTemporaryToRbw(block);\n          } else {\n            // for isDatnode or TRANSFER_FINALIZED\n            // Finalize the block.\n            datanode.data.finalizeBlock(block);\n          }\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      replicaInfo.releaseAllBytesReserved();\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            try (Writer out \u003d new OutputStreamWriter(\n                replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            } finally {\n              IOUtils.closeStream(streams.getDataOut());\n            }\n            try {              \n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "df983b524ab68ea0c70cee9033bfff2d28052cbf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10930. Refactor: Wrap Datanode IO related operations. Contributed by Xiaoyu Yao.\n",
      "commitDate": "06/12/16 11:05 AM",
      "commitName": "df983b524ab68ea0c70cee9033bfff2d28052cbf",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "05/12/16 12:44 PM",
      "commitNameOld": "dcedb72af468128458e597f08d22f5c34b744ae5",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 0.93,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,130 +1,130 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams,\n       boolean isReplaceBlock) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n       this.replyOut \u003d replyOut;\n       this.isReplaceBlock \u003d isReplaceBlock;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // Hold a volume reference to finalize block.\n         try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n           // close the block/crc files\n           close();\n           block.setNumBytes(replicaInfo.getNumBytes());\n \n           if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n             // for TRANSFER_RBW, convert temporary to RBW\n             datanode.data.convertTemporaryToRbw(block);\n           } else {\n             // for isDatnode or TRANSFER_FINALIZED\n             // Finalize the block.\n             datanode.data.finalizeBlock(block);\n           }\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       replicaInfo.releaseAllBytesReserved();\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             try (Writer out \u003d new OutputStreamWriter(\n                 replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             } finally {\n-              IOUtils.closeStream(out);\n+              IOUtils.closeStream(streams.getDataOut());\n             }\n             try {              \n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n      this.replyOut \u003d replyOut;\n      this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // Hold a volume reference to finalize block.\n        try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n          // close the block/crc files\n          close();\n          block.setNumBytes(replicaInfo.getNumBytes());\n\n          if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n            // for TRANSFER_RBW, convert temporary to RBW\n            datanode.data.convertTemporaryToRbw(block);\n          } else {\n            // for isDatnode or TRANSFER_FINALIZED\n            // Finalize the block.\n            datanode.data.finalizeBlock(block);\n          }\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      replicaInfo.releaseAllBytesReserved();\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            try (Writer out \u003d new OutputStreamWriter(\n                replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            } finally {\n              IOUtils.closeStream(streams.getDataOut());\n            }\n            try {              \n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "dcedb72af468128458e597f08d22f5c34b744ae5": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HADOOP-10930. Refactor: Wrap Datanode IO related operations. Contributed by Xiaoyu Yao.\"\n\nThis reverts commit aeecfa24f4fb6af289920cbf8830c394e66bd78e.\n",
      "commitDate": "05/12/16 12:44 PM",
      "commitName": "dcedb72af468128458e597f08d22f5c34b744ae5",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "29/11/16 8:52 PM",
      "commitNameOld": "aeecfa24f4fb6af289920cbf8830c394e66bd78e",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 5.66,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,130 +1,130 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams,\n       boolean isReplaceBlock) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n       this.replyOut \u003d replyOut;\n       this.isReplaceBlock \u003d isReplaceBlock;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // Hold a volume reference to finalize block.\n         try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n           // close the block/crc files\n           close();\n           block.setNumBytes(replicaInfo.getNumBytes());\n \n           if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n             // for TRANSFER_RBW, convert temporary to RBW\n             datanode.data.convertTemporaryToRbw(block);\n           } else {\n             // for isDatnode or TRANSFER_FINALIZED\n             // Finalize the block.\n             datanode.data.finalizeBlock(block);\n           }\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       replicaInfo.releaseAllBytesReserved();\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             try (Writer out \u003d new OutputStreamWriter(\n                 replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             } finally {\n-              IOUtils.closeStream(streams.getDataOut());\n+              IOUtils.closeStream(out);\n             }\n             try {              \n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n      this.replyOut \u003d replyOut;\n      this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // Hold a volume reference to finalize block.\n        try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n          // close the block/crc files\n          close();\n          block.setNumBytes(replicaInfo.getNumBytes());\n\n          if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n            // for TRANSFER_RBW, convert temporary to RBW\n            datanode.data.convertTemporaryToRbw(block);\n          } else {\n            // for isDatnode or TRANSFER_FINALIZED\n            // Finalize the block.\n            datanode.data.finalizeBlock(block);\n          }\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      replicaInfo.releaseAllBytesReserved();\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            try (Writer out \u003d new OutputStreamWriter(\n                replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            } finally {\n              IOUtils.closeStream(out);\n            }\n            try {              \n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "aeecfa24f4fb6af289920cbf8830c394e66bd78e": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10930. Refactor: Wrap Datanode IO related operations. Contributed by Xiaoyu Yao.\n",
      "commitDate": "29/11/16 8:52 PM",
      "commitName": "aeecfa24f4fb6af289920cbf8830c394e66bd78e",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "13/09/16 12:54 PM",
      "commitNameOld": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 77.37,
      "commitsBetweenForRepo": 595,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,130 +1,130 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams,\n       boolean isReplaceBlock) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n       this.replyOut \u003d replyOut;\n       this.isReplaceBlock \u003d isReplaceBlock;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // Hold a volume reference to finalize block.\n         try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n           // close the block/crc files\n           close();\n           block.setNumBytes(replicaInfo.getNumBytes());\n \n           if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n             // for TRANSFER_RBW, convert temporary to RBW\n             datanode.data.convertTemporaryToRbw(block);\n           } else {\n             // for isDatnode or TRANSFER_FINALIZED\n             // Finalize the block.\n             datanode.data.finalizeBlock(block);\n           }\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       replicaInfo.releaseAllBytesReserved();\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             try (Writer out \u003d new OutputStreamWriter(\n                 replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             } finally {\n-              IOUtils.closeStream(out);\n+              IOUtils.closeStream(streams.getDataOut());\n             }\n             try {              \n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n      this.replyOut \u003d replyOut;\n      this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // Hold a volume reference to finalize block.\n        try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n          // close the block/crc files\n          close();\n          block.setNumBytes(replicaInfo.getNumBytes());\n\n          if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n            // for TRANSFER_RBW, convert temporary to RBW\n            datanode.data.convertTemporaryToRbw(block);\n          } else {\n            // for isDatnode or TRANSFER_FINALIZED\n            // Finalize the block.\n            datanode.data.finalizeBlock(block);\n          }\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      replicaInfo.releaseAllBytesReserved();\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            try (Writer out \u003d new OutputStreamWriter(\n                replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            } finally {\n              IOUtils.closeStream(streams.getDataOut());\n            }\n            try {              \n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "176ff5ce90f2cbcd8342016d0f5570337d2ff79f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9402. Switch DataNode.LOG to use slf4j. Contributed by Walter Su.\n",
      "commitDate": "22/11/15 3:54 PM",
      "commitName": "176ff5ce90f2cbcd8342016d0f5570337d2ff79f",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "15/10/15 9:24 AM",
      "commitNameOld": "c7c36cbd6218f46c33d7fb2f60cd52cb29e6d720",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 38.31,
      "commitsBetweenForRepo": 280,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,130 +1,130 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams,\n       boolean isReplaceBlock) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n       this.replyOut \u003d replyOut;\n       this.isReplaceBlock \u003d isReplaceBlock;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // Hold a volume reference to finalize block.\n         try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n           // close the block/crc files\n           close();\n           block.setNumBytes(replicaInfo.getNumBytes());\n \n           if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n             // for TRANSFER_RBW, convert temporary to RBW\n             datanode.data.convertTemporaryToRbw(block);\n           } else {\n             // for isDatnode or TRANSFER_FINALIZED\n             // Finalize the block.\n             datanode.data.finalizeBlock(block);\n           }\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       replicaInfo.releaseAllBytesReserved();\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             try (Writer out \u003d new OutputStreamWriter(\n                 replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             } finally {\n-              IOUtils.cleanup(LOG, out);\n+              IOUtils.closeStream(out);\n             }\n             try {              \n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n      this.replyOut \u003d replyOut;\n      this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // Hold a volume reference to finalize block.\n        try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n          // close the block/crc files\n          close();\n          block.setNumBytes(replicaInfo.getNumBytes());\n\n          if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n            // for TRANSFER_RBW, convert temporary to RBW\n            datanode.data.convertTemporaryToRbw(block);\n          } else {\n            // for isDatnode or TRANSFER_FINALIZED\n            // Finalize the block.\n            datanode.data.finalizeBlock(block);\n          }\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      replicaInfo.releaseAllBytesReserved();\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            try (Writer out \u003d new OutputStreamWriter(\n                replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            } finally {\n              IOUtils.closeStream(out);\n            }\n            try {              \n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "b258b344bb76af6492828201959e36b45f0f75b8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8573. Move creation of restartMeta file logic from BlockReceiver to ReplicaInPipeline. Contributed by Eddy Xu.\n",
      "commitDate": "11/06/15 10:12 AM",
      "commitName": "b258b344bb76af6492828201959e36b45f0f75b8",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "08/05/15 4:52 AM",
      "commitNameOld": "7b1ea9c481fb8c13fc7b64eb1894d96ddfbf4b5b",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 34.22,
      "commitsBetweenForRepo": 289,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,137 +1,130 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams,\n       boolean isReplaceBlock) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n       this.replyOut \u003d replyOut;\n       this.isReplaceBlock \u003d isReplaceBlock;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // Hold a volume reference to finalize block.\n         try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n           // close the block/crc files\n           close();\n           block.setNumBytes(replicaInfo.getNumBytes());\n \n           if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n             // for TRANSFER_RBW, convert temporary to RBW\n             datanode.data.convertTemporaryToRbw(block);\n           } else {\n             // for isDatnode or TRANSFER_FINALIZED\n             // Finalize the block.\n             datanode.data.finalizeBlock(block);\n           }\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       replicaInfo.releaseAllBytesReserved();\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n-            File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n-            File restartMeta \u003d new File(blockFile.getParent()  + \n-                File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n-            if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n-              LOG.warn(\"Failed to delete restart meta file: \" +\n-                  restartMeta.getPath());\n-            }\n             try (Writer out \u003d new OutputStreamWriter(\n-                new FileOutputStream(restartMeta), \"UTF-8\")) {\n+                replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             } finally {\n               IOUtils.cleanup(LOG, out);\n             }\n             try {              \n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n      this.replyOut \u003d replyOut;\n      this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // Hold a volume reference to finalize block.\n        try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n          // close the block/crc files\n          close();\n          block.setNumBytes(replicaInfo.getNumBytes());\n\n          if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n            // for TRANSFER_RBW, convert temporary to RBW\n            datanode.data.convertTemporaryToRbw(block);\n          } else {\n            // for isDatnode or TRANSFER_FINALIZED\n            // Finalize the block.\n            datanode.data.finalizeBlock(block);\n          }\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      replicaInfo.releaseAllBytesReserved();\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            try (Writer out \u003d new OutputStreamWriter(\n                replicaInfo.createRestartMetaStream(), \"UTF-8\")) {\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            } finally {\n              IOUtils.cleanup(LOG, out);\n            }\n            try {              \n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "608c4998419c18fd95019b28cc56b5bd5aa4cc01": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8072. Reserved RBW space is not released if client terminates while writing block. (Arpit Agarwal)\n",
      "commitDate": "08/04/15 11:38 AM",
      "commitName": "608c4998419c18fd95019b28cc56b5bd5aa4cc01",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "03/04/15 2:19 PM",
      "commitNameOld": "023133cef9a7ca05364cefbcead57c921589eda7",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 4.89,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,136 +1,137 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams,\n       boolean isReplaceBlock) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n       this.replyOut \u003d replyOut;\n       this.isReplaceBlock \u003d isReplaceBlock;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // Hold a volume reference to finalize block.\n         try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n           // close the block/crc files\n           close();\n           block.setNumBytes(replicaInfo.getNumBytes());\n \n           if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n             // for TRANSFER_RBW, convert temporary to RBW\n             datanode.data.convertTemporaryToRbw(block);\n           } else {\n             // for isDatnode or TRANSFER_FINALIZED\n             // Finalize the block.\n             datanode.data.finalizeBlock(block);\n           }\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n+      replicaInfo.releaseAllBytesReserved();\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n             File restartMeta \u003d new File(blockFile.getParent()  + \n                 File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n             if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n               LOG.warn(\"Failed to delete restart meta file: \" +\n                   restartMeta.getPath());\n             }\n             try (Writer out \u003d new OutputStreamWriter(\n                 new FileOutputStream(restartMeta), \"UTF-8\")) {\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             } finally {\n               IOUtils.cleanup(LOG, out);\n             }\n             try {              \n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n      this.replyOut \u003d replyOut;\n      this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // Hold a volume reference to finalize block.\n        try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n          // close the block/crc files\n          close();\n          block.setNumBytes(replicaInfo.getNumBytes());\n\n          if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n            // for TRANSFER_RBW, convert temporary to RBW\n            datanode.data.convertTemporaryToRbw(block);\n          } else {\n            // for isDatnode or TRANSFER_FINALIZED\n            // Finalize the block.\n            datanode.data.finalizeBlock(block);\n          }\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      replicaInfo.releaseAllBytesReserved();\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n            File restartMeta \u003d new File(blockFile.getParent()  + \n                File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n            if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n              LOG.warn(\"Failed to delete restart meta file: \" +\n                  restartMeta.getPath());\n            }\n            try (Writer out \u003d new OutputStreamWriter(\n                new FileOutputStream(restartMeta), \"UTF-8\")) {\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            } finally {\n              IOUtils.cleanup(LOG, out);\n            }\n            try {              \n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "023133cef9a7ca05364cefbcead57c921589eda7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7996. After swapping a volume, BlockReceiver reports ReplicaNotFoundException (Lei (Eddy) Xu via Colin P. McCabe)\n",
      "commitDate": "03/04/15 2:19 PM",
      "commitName": "023133cef9a7ca05364cefbcead57c921589eda7",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "30/03/15 11:59 AM",
      "commitNameOld": "b80457158daf0dc712fbe5695625cc17d70d4bb4",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 4.1,
      "commitsBetweenForRepo": 49,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,133 +1,136 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams,\n       boolean isReplaceBlock) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n       this.replyOut \u003d replyOut;\n       this.isReplaceBlock \u003d isReplaceBlock;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n-        // close the block/crc files\n-        close();\n-        block.setNumBytes(replicaInfo.getNumBytes());\n+        // Hold a volume reference to finalize block.\n+        try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n+          // close the block/crc files\n+          close();\n+          block.setNumBytes(replicaInfo.getNumBytes());\n \n-        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n-          // for TRANSFER_RBW, convert temporary to RBW\n-          datanode.data.convertTemporaryToRbw(block);\n-        } else {\n-          // for isDatnode or TRANSFER_FINALIZED\n-          // Finalize the block.\n-          datanode.data.finalizeBlock(block);\n+          if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n+            // for TRANSFER_RBW, convert temporary to RBW\n+            datanode.data.convertTemporaryToRbw(block);\n+          } else {\n+            // for isDatnode or TRANSFER_FINALIZED\n+            // Finalize the block.\n+            datanode.data.finalizeBlock(block);\n+          }\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n             File restartMeta \u003d new File(blockFile.getParent()  + \n                 File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n             if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n               LOG.warn(\"Failed to delete restart meta file: \" +\n                   restartMeta.getPath());\n             }\n             try (Writer out \u003d new OutputStreamWriter(\n                 new FileOutputStream(restartMeta), \"UTF-8\")) {\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             } finally {\n               IOUtils.cleanup(LOG, out);\n             }\n             try {              \n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n      this.replyOut \u003d replyOut;\n      this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // Hold a volume reference to finalize block.\n        try (ReplicaHandler handler \u003d claimReplicaHandler()) {\n          // close the block/crc files\n          close();\n          block.setNumBytes(replicaInfo.getNumBytes());\n\n          if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n            // for TRANSFER_RBW, convert temporary to RBW\n            datanode.data.convertTemporaryToRbw(block);\n          } else {\n            // for isDatnode or TRANSFER_FINALIZED\n            // Finalize the block.\n            datanode.data.finalizeBlock(block);\n          }\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n            File restartMeta \u003d new File(blockFile.getParent()  + \n                File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n            if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n              LOG.warn(\"Failed to delete restart meta file: \" +\n                  restartMeta.getPath());\n            }\n            try (Writer out \u003d new OutputStreamWriter(\n                new FileOutputStream(restartMeta), \"UTF-8\")) {\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            } finally {\n              IOUtils.cleanup(LOG, out);\n            }\n            try {              \n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "b9f6d0c956f0278c8b9b83e05b523a442a730ebb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7515. Fix new findbugs warnings in hadoop-hdfs. Contributed by Haohui Mai.\n",
      "commitDate": "11/12/14 12:36 PM",
      "commitName": "b9f6d0c956f0278c8b9b83e05b523a442a730ebb",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "27/10/14 9:38 AM",
      "commitNameOld": "463aec11718e47d4aabb86a7a539cb973460aae6",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 45.17,
      "commitsBetweenForRepo": 388,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,134 +1,133 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams,\n       boolean isReplaceBlock) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n       this.replyOut \u003d replyOut;\n       this.isReplaceBlock \u003d isReplaceBlock;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n           // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n             File restartMeta \u003d new File(blockFile.getParent()  + \n                 File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n             if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n               LOG.warn(\"Failed to delete restart meta file: \" +\n                   restartMeta.getPath());\n             }\n-            FileWriter out \u003d null;\n-            try {\n-              out \u003d new FileWriter(restartMeta);\n+            try (Writer out \u003d new OutputStreamWriter(\n+                new FileOutputStream(restartMeta), \"UTF-8\")) {\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             } finally {\n               IOUtils.cleanup(LOG, out);\n             }\n             try {              \n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n      this.replyOut \u003d replyOut;\n      this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n            File restartMeta \u003d new File(blockFile.getParent()  + \n                File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n            if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n              LOG.warn(\"Failed to delete restart meta file: \" +\n                  restartMeta.getPath());\n            }\n            try (Writer out \u003d new OutputStreamWriter(\n                new FileOutputStream(restartMeta), \"UTF-8\")) {\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            } finally {\n              IOUtils.cleanup(LOG, out);\n            }\n            try {              \n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "b6b95ff66700e4db1d8d59a31c3048cb10504262": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6902. FileWriter should be closed in finally block in BlockReceiver#receiveBlock() (Tsuyoshi OZAWA via Colin Patrick McCabe)\n",
      "commitDate": "27/08/14 1:49 PM",
      "commitName": "b6b95ff66700e4db1d8d59a31c3048cb10504262",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "18/08/14 2:23 PM",
      "commitNameOld": "2fb04d2a30919bde350f566a39faa7085f1a1d7b",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 8.98,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,132 +1,134 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams,\n       boolean isReplaceBlock) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n       this.replyOut \u003d replyOut;\n       this.isReplaceBlock \u003d isReplaceBlock;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n           // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n             File restartMeta \u003d new File(blockFile.getParent()  + \n                 File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n             if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n               LOG.warn(\"Failed to delete restart meta file: \" +\n                   restartMeta.getPath());\n             }\n+            FileWriter out \u003d null;\n             try {\n-              FileWriter out \u003d new FileWriter(restartMeta);\n+              out \u003d new FileWriter(restartMeta);\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n-              out.close();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n+            } finally {\n+              IOUtils.cleanup(LOG, out);\n             }\n             try {              \n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n      this.replyOut \u003d replyOut;\n      this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n            File restartMeta \u003d new File(blockFile.getParent()  + \n                File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n            if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n              LOG.warn(\"Failed to delete restart meta file: \" +\n                  restartMeta.getPath());\n            }\n            FileWriter out \u003d null;\n            try {\n              out \u003d new FileWriter(restartMeta);\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            } finally {\n              IOUtils.cleanup(LOG, out);\n            }\n            try {              \n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "2fb04d2a30919bde350f566a39faa7085f1a1d7b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6569. OOB message can\u0027t be sent to the client when DataNode shuts down for upgrade. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1618742 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/14 2:23 PM",
      "commitName": "2fb04d2a30919bde350f566a39faa7085f1a1d7b",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "13/08/14 11:43 AM",
      "commitNameOld": "195961a7c1da86421761162836766b1de07930fd",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 5.11,
      "commitsBetweenForRepo": 56,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,136 +1,132 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams,\n       boolean isReplaceBlock) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n       this.replyOut \u003d replyOut;\n       this.isReplaceBlock \u003d isReplaceBlock;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n           // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n             File restartMeta \u003d new File(blockFile.getParent()  + \n                 File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n             if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n               LOG.warn(\"Failed to delete restart meta file: \" +\n                   restartMeta.getPath());\n             }\n             try {\n               FileWriter out \u003d new FileWriter(restartMeta);\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n               out.close();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             }\n-            try {\n-              ((PacketResponder) responder.getRunnable()).\n-                  sendOOBResponse(PipelineAck.getRestartOOBStatus());\n+            try {              \n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n-            } catch (IOException ioe) {\n-              LOG.info(\"Error sending OOB Ack.\", ioe);\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n      this.replyOut \u003d replyOut;\n      this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n            File restartMeta \u003d new File(blockFile.getParent()  + \n                File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n            if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n              LOG.warn(\"Failed to delete restart meta file: \" +\n                  restartMeta.getPath());\n            }\n            try {\n              FileWriter out \u003d new FileWriter(restartMeta);\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n              out.close();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            }\n            try {              \n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "195961a7c1da86421761162836766b1de07930fd": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6247. Avoid timeouts for replaceBlock() call by sending intermediate responses to Balancer (vinayakumarb)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1617799 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/08/14 11:43 AM",
      "commitName": "195961a7c1da86421761162836766b1de07930fd",
      "commitAuthor": "Vinayakumar B",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6247. Avoid timeouts for replaceBlock() call by sending intermediate responses to Balancer (vinayakumarb)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1617799 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/08/14 11:43 AM",
          "commitName": "195961a7c1da86421761162836766b1de07930fd",
          "commitAuthor": "Vinayakumar B",
          "commitDateOld": "13/08/14 11:36 AM",
          "commitNameOld": "6554994fab2d8a2a139fb71ed54be144f4057e08",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,132 +1,136 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n-      DatanodeInfo[] downstreams) throws IOException {\n+      DatanodeInfo[] downstreams,\n+      boolean isReplaceBlock) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n+      this.replyOut \u003d replyOut;\n+      this.isReplaceBlock \u003d isReplaceBlock;\n+\n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n           // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n             File restartMeta \u003d new File(blockFile.getParent()  + \n                 File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n             if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n               LOG.warn(\"Failed to delete restart meta file: \" +\n                   restartMeta.getPath());\n             }\n             try {\n               FileWriter out \u003d new FileWriter(restartMeta);\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n               out.close();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             }\n             try {\n               ((PacketResponder) responder.getRunnable()).\n                   sendOOBResponse(PipelineAck.getRestartOOBStatus());\n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             } catch (IOException ioe) {\n               LOG.info(\"Error sending OOB Ack.\", ioe);\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n      this.replyOut \u003d replyOut;\n      this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n            File restartMeta \u003d new File(blockFile.getParent()  + \n                File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n            if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n              LOG.warn(\"Failed to delete restart meta file: \" +\n                  restartMeta.getPath());\n            }\n            try {\n              FileWriter out \u003d new FileWriter(restartMeta);\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n              out.close();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            }\n            try {\n              ((PacketResponder) responder.getRunnable()).\n                  sendOOBResponse(PipelineAck.getRestartOOBStatus());\n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            } catch (IOException ioe) {\n              LOG.info(\"Error sending OOB Ack.\", ioe);\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
          "extendedDetails": {
            "oldValue": "[mirrOut-DataOutputStream, mirrIn-DataInputStream, replyOut-DataOutputStream, mirrAddr-String, throttlerArg-DataTransferThrottler, downstreams-DatanodeInfo[]]",
            "newValue": "[mirrOut-DataOutputStream, mirrIn-DataInputStream, replyOut-DataOutputStream, mirrAddr-String, throttlerArg-DataTransferThrottler, downstreams-DatanodeInfo[], isReplaceBlock-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6247. Avoid timeouts for replaceBlock() call by sending intermediate responses to Balancer (vinayakumarb)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1617799 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/08/14 11:43 AM",
          "commitName": "195961a7c1da86421761162836766b1de07930fd",
          "commitAuthor": "Vinayakumar B",
          "commitDateOld": "13/08/14 11:36 AM",
          "commitNameOld": "6554994fab2d8a2a139fb71ed54be144f4057e08",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,132 +1,136 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n-      DatanodeInfo[] downstreams) throws IOException {\n+      DatanodeInfo[] downstreams,\n+      boolean isReplaceBlock) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n+      this.replyOut \u003d replyOut;\n+      this.isReplaceBlock \u003d isReplaceBlock;\n+\n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n           // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n             File restartMeta \u003d new File(blockFile.getParent()  + \n                 File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n             if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n               LOG.warn(\"Failed to delete restart meta file: \" +\n                   restartMeta.getPath());\n             }\n             try {\n               FileWriter out \u003d new FileWriter(restartMeta);\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n               out.close();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             }\n             try {\n               ((PacketResponder) responder.getRunnable()).\n                   sendOOBResponse(PipelineAck.getRestartOOBStatus());\n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             } catch (IOException ioe) {\n               LOG.info(\"Error sending OOB Ack.\", ioe);\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n      this.replyOut \u003d replyOut;\n      this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n            File restartMeta \u003d new File(blockFile.getParent()  + \n                File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n            if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n              LOG.warn(\"Failed to delete restart meta file: \" +\n                  restartMeta.getPath());\n            }\n            try {\n              FileWriter out \u003d new FileWriter(restartMeta);\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n              out.close();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            }\n            try {\n              ((PacketResponder) responder.getRunnable()).\n                  sendOOBResponse(PipelineAck.getRestartOOBStatus());\n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            } catch (IOException ioe) {\n              LOG.info(\"Error sending OOB Ack.\", ioe);\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
          "extendedDetails": {}
        }
      ]
    },
    "6554994fab2d8a2a139fb71ed54be144f4057e08": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "Reverted\nMerged revision(s) 1617784 from hadoop/common/trunk:\nHDFS-6847. Avoid timeouts for replaceBlock() call by sending intermediate responses to Balancer (Contributed by Vinayakumar B.)\n........\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1617794 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/08/14 11:36 AM",
      "commitName": "6554994fab2d8a2a139fb71ed54be144f4057e08",
      "commitAuthor": "Vinayakumar B",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "Reverted\nMerged revision(s) 1617784 from hadoop/common/trunk:\nHDFS-6847. Avoid timeouts for replaceBlock() call by sending intermediate responses to Balancer (Contributed by Vinayakumar B.)\n........\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1617794 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/08/14 11:36 AM",
          "commitName": "6554994fab2d8a2a139fb71ed54be144f4057e08",
          "commitAuthor": "Vinayakumar B",
          "commitDateOld": "13/08/14 11:06 AM",
          "commitNameOld": "471b1368e2a81b4d9850f0f4d98d31df1451354c",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 0.02,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,136 +1,132 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n-      DatanodeInfo[] downstreams,\n-      boolean isReplaceBlock) throws IOException {\n+      DatanodeInfo[] downstreams) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n-      this.replyOut \u003d replyOut;\n-      this.isReplaceBlock \u003d isReplaceBlock;\n-\n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n           // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n             File restartMeta \u003d new File(blockFile.getParent()  + \n                 File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n             if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n               LOG.warn(\"Failed to delete restart meta file: \" +\n                   restartMeta.getPath());\n             }\n             try {\n               FileWriter out \u003d new FileWriter(restartMeta);\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n               out.close();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             }\n             try {\n               ((PacketResponder) responder.getRunnable()).\n                   sendOOBResponse(PipelineAck.getRestartOOBStatus());\n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             } catch (IOException ioe) {\n               LOG.info(\"Error sending OOB Ack.\", ioe);\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n            File restartMeta \u003d new File(blockFile.getParent()  + \n                File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n            if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n              LOG.warn(\"Failed to delete restart meta file: \" +\n                  restartMeta.getPath());\n            }\n            try {\n              FileWriter out \u003d new FileWriter(restartMeta);\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n              out.close();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            }\n            try {\n              ((PacketResponder) responder.getRunnable()).\n                  sendOOBResponse(PipelineAck.getRestartOOBStatus());\n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            } catch (IOException ioe) {\n              LOG.info(\"Error sending OOB Ack.\", ioe);\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
          "extendedDetails": {
            "oldValue": "[mirrOut-DataOutputStream, mirrIn-DataInputStream, replyOut-DataOutputStream, mirrAddr-String, throttlerArg-DataTransferThrottler, downstreams-DatanodeInfo[], isReplaceBlock-boolean]",
            "newValue": "[mirrOut-DataOutputStream, mirrIn-DataInputStream, replyOut-DataOutputStream, mirrAddr-String, throttlerArg-DataTransferThrottler, downstreams-DatanodeInfo[]]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "Reverted\nMerged revision(s) 1617784 from hadoop/common/trunk:\nHDFS-6847. Avoid timeouts for replaceBlock() call by sending intermediate responses to Balancer (Contributed by Vinayakumar B.)\n........\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1617794 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/08/14 11:36 AM",
          "commitName": "6554994fab2d8a2a139fb71ed54be144f4057e08",
          "commitAuthor": "Vinayakumar B",
          "commitDateOld": "13/08/14 11:06 AM",
          "commitNameOld": "471b1368e2a81b4d9850f0f4d98d31df1451354c",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 0.02,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,136 +1,132 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n-      DatanodeInfo[] downstreams,\n-      boolean isReplaceBlock) throws IOException {\n+      DatanodeInfo[] downstreams) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n-      this.replyOut \u003d replyOut;\n-      this.isReplaceBlock \u003d isReplaceBlock;\n-\n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n           // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n             File restartMeta \u003d new File(blockFile.getParent()  + \n                 File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n             if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n               LOG.warn(\"Failed to delete restart meta file: \" +\n                   restartMeta.getPath());\n             }\n             try {\n               FileWriter out \u003d new FileWriter(restartMeta);\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n               out.close();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             }\n             try {\n               ((PacketResponder) responder.getRunnable()).\n                   sendOOBResponse(PipelineAck.getRestartOOBStatus());\n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             } catch (IOException ioe) {\n               LOG.info(\"Error sending OOB Ack.\", ioe);\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n            File restartMeta \u003d new File(blockFile.getParent()  + \n                File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n            if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n              LOG.warn(\"Failed to delete restart meta file: \" +\n                  restartMeta.getPath());\n            }\n            try {\n              FileWriter out \u003d new FileWriter(restartMeta);\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n              out.close();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            }\n            try {\n              ((PacketResponder) responder.getRunnable()).\n                  sendOOBResponse(PipelineAck.getRestartOOBStatus());\n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            } catch (IOException ioe) {\n              LOG.info(\"Error sending OOB Ack.\", ioe);\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
          "extendedDetails": {}
        }
      ]
    },
    "471b1368e2a81b4d9850f0f4d98d31df1451354c": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6847. Avoid timeouts for replaceBlock() call by sending intermediate responses to Balancer (Contributed by Vinayakumar B.)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1617784 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/08/14 11:06 AM",
      "commitName": "471b1368e2a81b4d9850f0f4d98d31df1451354c",
      "commitAuthor": "Vinayakumar B",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6847. Avoid timeouts for replaceBlock() call by sending intermediate responses to Balancer (Contributed by Vinayakumar B.)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1617784 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/08/14 11:06 AM",
          "commitName": "471b1368e2a81b4d9850f0f4d98d31df1451354c",
          "commitAuthor": "Vinayakumar B",
          "commitDateOld": "04/08/14 1:43 AM",
          "commitNameOld": "33518e561368c372bf9254b6b55a9b0c499fbd4d",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 9.39,
          "commitsBetweenForRepo": 79,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,132 +1,136 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n-      DatanodeInfo[] downstreams) throws IOException {\n+      DatanodeInfo[] downstreams,\n+      boolean isReplaceBlock) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n+      this.replyOut \u003d replyOut;\n+      this.isReplaceBlock \u003d isReplaceBlock;\n+\n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n           // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n             File restartMeta \u003d new File(blockFile.getParent()  + \n                 File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n             if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n               LOG.warn(\"Failed to delete restart meta file: \" +\n                   restartMeta.getPath());\n             }\n             try {\n               FileWriter out \u003d new FileWriter(restartMeta);\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n               out.close();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             }\n             try {\n               ((PacketResponder) responder.getRunnable()).\n                   sendOOBResponse(PipelineAck.getRestartOOBStatus());\n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             } catch (IOException ioe) {\n               LOG.info(\"Error sending OOB Ack.\", ioe);\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n      this.replyOut \u003d replyOut;\n      this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n            File restartMeta \u003d new File(blockFile.getParent()  + \n                File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n            if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n              LOG.warn(\"Failed to delete restart meta file: \" +\n                  restartMeta.getPath());\n            }\n            try {\n              FileWriter out \u003d new FileWriter(restartMeta);\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n              out.close();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            }\n            try {\n              ((PacketResponder) responder.getRunnable()).\n                  sendOOBResponse(PipelineAck.getRestartOOBStatus());\n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            } catch (IOException ioe) {\n              LOG.info(\"Error sending OOB Ack.\", ioe);\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
          "extendedDetails": {
            "oldValue": "[mirrOut-DataOutputStream, mirrIn-DataInputStream, replyOut-DataOutputStream, mirrAddr-String, throttlerArg-DataTransferThrottler, downstreams-DatanodeInfo[]]",
            "newValue": "[mirrOut-DataOutputStream, mirrIn-DataInputStream, replyOut-DataOutputStream, mirrAddr-String, throttlerArg-DataTransferThrottler, downstreams-DatanodeInfo[], isReplaceBlock-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6847. Avoid timeouts for replaceBlock() call by sending intermediate responses to Balancer (Contributed by Vinayakumar B.)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1617784 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/08/14 11:06 AM",
          "commitName": "471b1368e2a81b4d9850f0f4d98d31df1451354c",
          "commitAuthor": "Vinayakumar B",
          "commitDateOld": "04/08/14 1:43 AM",
          "commitNameOld": "33518e561368c372bf9254b6b55a9b0c499fbd4d",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 9.39,
          "commitsBetweenForRepo": 79,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,132 +1,136 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n-      DatanodeInfo[] downstreams) throws IOException {\n+      DatanodeInfo[] downstreams,\n+      boolean isReplaceBlock) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n+      this.replyOut \u003d replyOut;\n+      this.isReplaceBlock \u003d isReplaceBlock;\n+\n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n           // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n             File restartMeta \u003d new File(blockFile.getParent()  + \n                 File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n             if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n               LOG.warn(\"Failed to delete restart meta file: \" +\n                   restartMeta.getPath());\n             }\n             try {\n               FileWriter out \u003d new FileWriter(restartMeta);\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n               out.close();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             }\n             try {\n               ((PacketResponder) responder.getRunnable()).\n                   sendOOBResponse(PipelineAck.getRestartOOBStatus());\n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             } catch (IOException ioe) {\n               LOG.info(\"Error sending OOB Ack.\", ioe);\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams,\n      boolean isReplaceBlock) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n      this.replyOut \u003d replyOut;\n      this.isReplaceBlock \u003d isReplaceBlock;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n            File restartMeta \u003d new File(blockFile.getParent()  + \n                File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n            if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n              LOG.warn(\"Failed to delete restart meta file: \" +\n                  restartMeta.getPath());\n            }\n            try {\n              FileWriter out \u003d new FileWriter(restartMeta);\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n              out.close();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            }\n            try {\n              ((PacketResponder) responder.getRunnable()).\n                  sendOOBResponse(PipelineAck.getRestartOOBStatus());\n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            } catch (IOException ioe) {\n              LOG.info(\"Error sending OOB Ack.\", ioe);\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
          "extendedDetails": {}
        }
      ]
    },
    "c8182ea76412e49c0c98ee252321c584fabb4c59": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6020. Fix the five findbugs warnings. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1572165 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/02/14 9:07 AM",
      "commitName": "c8182ea76412e49c0c98ee252321c584fabb4c59",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "25/02/14 11:24 AM",
      "commitNameOld": "57b28693ee295746c6d168d37dd05eaf7b601b87",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.91,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,131 +1,132 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n           // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n             File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n             File restartMeta \u003d new File(blockFile.getParent()  + \n                 File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n-            if (restartMeta.exists()) {\n-              restartMeta.delete();\n+            if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n+              LOG.warn(\"Failed to delete restart meta file: \" +\n+                  restartMeta.getPath());\n             }\n             try {\n               FileWriter out \u003d new FileWriter(restartMeta);\n               // write out the current time.\n               out.write(Long.toString(Time.now() + restartBudget));\n               out.flush();\n               out.close();\n             } catch (IOException ioe) {\n               // The worst case is not recovering this RBW replica. \n               // Client will fall back to regular pipeline recovery.\n             }\n             try {\n               ((PacketResponder) responder.getRunnable()).\n                   sendOOBResponse(PipelineAck.getRestartOOBStatus());\n               // Even if the connection is closed after the ack packet is\n               // flushed, the client can react to the connection closure \n               // first. Insert a delay to lower the chance of client \n               // missing the OOB ack.\n               Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             } catch (IOException ioe) {\n               LOG.info(\"Error sending OOB Ack.\", ioe);\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n            File restartMeta \u003d new File(blockFile.getParent()  + \n                File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n            if (restartMeta.exists() \u0026\u0026 !restartMeta.delete()) {\n              LOG.warn(\"Failed to delete restart meta file: \" +\n                  restartMeta.getPath());\n            }\n            try {\n              FileWriter out \u003d new FileWriter(restartMeta);\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n              out.close();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            }\n            try {\n              ((PacketResponder) responder.getRunnable()).\n                  sendOOBResponse(PipelineAck.getRestartOOBStatus());\n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            } catch (IOException ioe) {\n              LOG.info(\"Error sending OOB Ack.\", ioe);\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "57b28693ee295746c6d168d37dd05eaf7b601b87": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5924. Utilize OOB upgrade message processing for writes. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1571792 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/02/14 11:24 AM",
      "commitName": "57b28693ee295746c6d168d37dd05eaf7b601b87",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "25/02/14 10:51 AM",
      "commitNameOld": "6780b086d8378a75614e2d4563ad5784233356dc",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,112 +1,131 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n           // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n-          if (datanode.isRestarting()) {\n+          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n+            File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n+            File restartMeta \u003d new File(blockFile.getParent()  + \n+                File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n+            if (restartMeta.exists()) {\n+              restartMeta.delete();\n+            }\n+            try {\n+              FileWriter out \u003d new FileWriter(restartMeta);\n+              // write out the current time.\n+              out.write(Long.toString(Time.now() + restartBudget));\n+              out.flush();\n+              out.close();\n+            } catch (IOException ioe) {\n+              // The worst case is not recovering this RBW replica. \n+              // Client will fall back to regular pipeline recovery.\n+            }\n             try {\n               ((PacketResponder) responder.getRunnable()).\n                   sendOOBResponse(PipelineAck.getRestartOOBStatus());\n+              // Even if the connection is closed after the ack packet is\n+              // flushed, the client can react to the connection closure \n+              // first. Insert a delay to lower the chance of client \n+              // missing the OOB ack.\n+              Thread.sleep(1000);\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             } catch (IOException ioe) {\n               LOG.info(\"Error sending OOB Ack.\", ioe);\n-              // The OOB ack could not be sent. Since the datanode is going\n-              // down, this is ignored.\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.interrupt();\n           // join() on the responder should timeout a bit earlier than the\n           // configured deadline. Otherwise, the join() on this thread will\n           // likely timeout as well.\n           long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n           joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n           responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting() \u0026\u0026 isClient \u0026\u0026 !isTransfer) {\n            File blockFile \u003d ((ReplicaInPipeline)replicaInfo).getBlockFile();\n            File restartMeta \u003d new File(blockFile.getParent()  + \n                File.pathSeparator + \".\" + blockFile.getName() + \".restart\");\n            if (restartMeta.exists()) {\n              restartMeta.delete();\n            }\n            try {\n              FileWriter out \u003d new FileWriter(restartMeta);\n              // write out the current time.\n              out.write(Long.toString(Time.now() + restartBudget));\n              out.flush();\n              out.close();\n            } catch (IOException ioe) {\n              // The worst case is not recovering this RBW replica. \n              // Client will fall back to regular pipeline recovery.\n            }\n            try {\n              ((PacketResponder) responder.getRunnable()).\n                  sendOOBResponse(PipelineAck.getRestartOOBStatus());\n              // Even if the connection is closed after the ack packet is\n              // flushed, the client can react to the connection closure \n              // first. Insert a delay to lower the chance of client \n              // missing the OOB ack.\n              Thread.sleep(1000);\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            } catch (IOException ioe) {\n              LOG.info(\"Error sending OOB Ack.\", ioe);\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "6780b086d8378a75614e2d4563ad5784233356dc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6015. Fix TestBlockRecovery#testRaceBetweenReplicaRecoveryAndFinalizeBlock. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1571785 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/02/14 10:51 AM",
      "commitName": "6780b086d8378a75614e2d4563ad5784233356dc",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "25/02/14 10:48 AM",
      "commitNameOld": "f52fe68a2b5dd451e0e9954b8d7462f0e0cf01f9",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,106 +1,112 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n           // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       if (datanode.isRestarting()) {\n         // Do not throw if shutting down for restart. Otherwise, it will cause\n         // premature termination of responder.\n         LOG.info(\"Shutting down for restart (\" + block + \").\");\n       } else {\n         LOG.info(\"Exception for \" + block, ioe);\n         throw ioe;\n       }\n     } finally {\n       // Clear the previous interrupt state of this thread.\n       Thread.interrupted();\n \n       // If a shutdown for restart was initiated, upstream needs to be notified.\n       // There is no need to do anything special if the responder was closed\n       // normally.\n       if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n           // In case this datanode is shutting down for quick restart,\n           // send a special ack upstream.\n           if (datanode.isRestarting()) {\n             try {\n               ((PacketResponder) responder.getRunnable()).\n                   sendOOBResponse(PipelineAck.getRestartOOBStatus());\n             } catch (InterruptedException ie) {\n               // It is already going down. Ignore this.\n             } catch (IOException ioe) {\n               LOG.info(\"Error sending OOB Ack.\", ioe);\n               // The OOB ack could not be sent. Since the datanode is going\n               // down, this is ignored.\n             }\n           }\n           responder.interrupt();\n         }\n         IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n-          responder.join(datanode.getDnConf().getXceiverStopTimeout());\n+          responder.interrupt();\n+          // join() on the responder should timeout a bit earlier than the\n+          // configured deadline. Otherwise, the join() on this thread will\n+          // likely timeout as well.\n+          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n+          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n+          responder.join(joinTimeout);\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           // do not throw if shutting down for restart.\n           if (!datanode.isRestarting()) {\n             throw new IOException(\"Interrupted receiveBlock\");\n           }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting()) {\n            try {\n              ((PacketResponder) responder.getRunnable()).\n                  sendOOBResponse(PipelineAck.getRestartOOBStatus());\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            } catch (IOException ioe) {\n              LOG.info(\"Error sending OOB Ack.\", ioe);\n              // The OOB ack could not be sent. Since the datanode is going\n              // down, this is ignored.\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.interrupt();\n          // join() on the responder should timeout a bit earlier than the\n          // configured deadline. Otherwise, the join() on this thread will\n          // likely timeout as well.\n          long joinTimeout \u003d datanode.getDnConf().getXceiverStopTimeout();\n          joinTimeout \u003d joinTimeout \u003e 1  ? joinTimeout*8/10 : joinTimeout;\n          responder.join(joinTimeout);\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "1c6b5d2b5841e5219a98937088cde4ae63869f80": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5583. Make DN send an OOB Ack on shutdown before restarting. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1571491 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/02/14 3:38 PM",
      "commitName": "1c6b5d2b5841e5219a98937088cde4ae63869f80",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "19/02/14 3:38 PM",
      "commitNameOld": "0369aff403012f8dd02486a3dd2f8e346ad23b03",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 5.0,
      "commitsBetweenForRepo": 39,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,106 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n           // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n-      LOG.info(\"Exception for \" + block, ioe);\n-      throw ioe;\n+      if (datanode.isRestarting()) {\n+        // Do not throw if shutting down for restart. Otherwise, it will cause\n+        // premature termination of responder.\n+        LOG.info(\"Shutting down for restart (\" + block + \").\");\n+      } else {\n+        LOG.info(\"Exception for \" + block, ioe);\n+        throw ioe;\n+      }\n     } finally {\n-      if (!responderClosed) { // Abnormal termination of the flow above\n-        IOUtils.closeStream(this);\n+      // Clear the previous interrupt state of this thread.\n+      Thread.interrupted();\n+\n+      // If a shutdown for restart was initiated, upstream needs to be notified.\n+      // There is no need to do anything special if the responder was closed\n+      // normally.\n+      if (!responderClosed) { // Data transfer was not complete.\n         if (responder !\u003d null) {\n+          // In case this datanode is shutting down for quick restart,\n+          // send a special ack upstream.\n+          if (datanode.isRestarting()) {\n+            try {\n+              ((PacketResponder) responder.getRunnable()).\n+                  sendOOBResponse(PipelineAck.getRestartOOBStatus());\n+            } catch (InterruptedException ie) {\n+              // It is already going down. Ignore this.\n+            } catch (IOException ioe) {\n+              LOG.info(\"Error sending OOB Ack.\", ioe);\n+              // The OOB ack could not be sent. Since the datanode is going\n+              // down, this is ignored.\n+            }\n+          }\n           responder.interrupt();\n         }\n+        IOUtils.closeStream(this);\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.join(datanode.getDnConf().getXceiverStopTimeout());\n           if (responder.isAlive()) {\n             String msg \u003d \"Join on responder thread \" + responder\n                 + \" timed out\";\n             LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n             throw new IOException(msg);\n           }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n-          throw new IOException(\"Interrupted receiveBlock\");\n+          // do not throw if shutting down for restart.\n+          if (!datanode.isRestarting()) {\n+            throw new IOException(\"Interrupted receiveBlock\");\n+          }\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      if (datanode.isRestarting()) {\n        // Do not throw if shutting down for restart. Otherwise, it will cause\n        // premature termination of responder.\n        LOG.info(\"Shutting down for restart (\" + block + \").\");\n      } else {\n        LOG.info(\"Exception for \" + block, ioe);\n        throw ioe;\n      }\n    } finally {\n      // Clear the previous interrupt state of this thread.\n      Thread.interrupted();\n\n      // If a shutdown for restart was initiated, upstream needs to be notified.\n      // There is no need to do anything special if the responder was closed\n      // normally.\n      if (!responderClosed) { // Data transfer was not complete.\n        if (responder !\u003d null) {\n          // In case this datanode is shutting down for quick restart,\n          // send a special ack upstream.\n          if (datanode.isRestarting()) {\n            try {\n              ((PacketResponder) responder.getRunnable()).\n                  sendOOBResponse(PipelineAck.getRestartOOBStatus());\n            } catch (InterruptedException ie) {\n              // It is already going down. Ignore this.\n            } catch (IOException ioe) {\n              LOG.info(\"Error sending OOB Ack.\", ioe);\n              // The OOB ack could not be sent. Since the datanode is going\n              // down, this is ignored.\n            }\n          }\n          responder.interrupt();\n        }\n        IOUtils.closeStream(this);\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.join(datanode.getDnConf().getXceiverStopTimeout());\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          // do not throw if shutting down for restart.\n          if (!datanode.isRestarting()) {\n            throw new IOException(\"Interrupted receiveBlock\");\n          }\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "7723b139d55fc2c3954939559cb4914046a0f81c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5016. Deadlock in pipeline recovery causes Datanode to be marked dead. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1507189 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/07/13 9:42 PM",
      "commitName": "7723b139d55fc2c3954939559cb4914046a0f81c",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "22/07/13 11:15 AM",
      "commitNameOld": "c1314eb2a382bd9ce045a2fcc4a9e5c1fc368a24",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 3.44,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,71 +1,77 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n           // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       LOG.info(\"Exception for \" + block, ioe);\n       throw ioe;\n     } finally {\n       if (!responderClosed) { // Abnormal termination of the flow above\n         IOUtils.closeStream(this);\n         if (responder !\u003d null) {\n           responder.interrupt();\n         }\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n-          responder.join();\n+          responder.join(datanode.getDnConf().getXceiverStopTimeout());\n+          if (responder.isAlive()) {\n+            String msg \u003d \"Join on responder thread \" + responder\n+                + \" timed out\";\n+            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n+            throw new IOException(msg);\n+          }\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           throw new IOException(\"Interrupted receiveBlock\");\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      LOG.info(\"Exception for \" + block, ioe);\n      throw ioe;\n    } finally {\n      if (!responderClosed) { // Abnormal termination of the flow above\n        IOUtils.closeStream(this);\n        if (responder !\u003d null) {\n          responder.interrupt();\n        }\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.join(datanode.getDnConf().getXceiverStopTimeout());\n          if (responder.isAlive()) {\n            String msg \u003d \"Join on responder thread \" + responder\n                + \" timed out\";\n            LOG.warn(msg + \"\\n\" + StringUtils.getStackTrace(responder));\n            throw new IOException(msg);\n          }\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          throw new IOException(\"Interrupted receiveBlock\");\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "7e56bfe40589a1aa9b5ef20b342e421823cd0592": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4200. Reduce the size of synchronized sections in PacketResponder. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1413826 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/11/12 12:47 PM",
      "commitName": "7e56bfe40589a1aa9b5ef20b342e421823cd0592",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "06/11/12 2:34 PM",
      "commitNameOld": "1e7010cf38115604d6fa3aa5728362c86644e66a",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 19.93,
      "commitsBetweenForRepo": 99,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,74 +1,71 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n-      /* \n-       * Receive until the last packet.\n-       */\n-      while (receivePacket() \u003e\u003d 0) {}\n+      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n           // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       LOG.info(\"Exception for \" + block, ioe);\n       throw ioe;\n     } finally {\n       if (!responderClosed) { // Abnormal termination of the flow above\n         IOUtils.closeStream(this);\n         if (responder !\u003d null) {\n           responder.interrupt();\n         }\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.join();\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           throw new IOException(\"Interrupted receiveBlock\");\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      while (receivePacket() \u003e\u003d 0) { /* Receive until the last packet */ }\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      LOG.info(\"Exception for \" + block, ioe);\n      throw ioe;\n    } finally {\n      if (!responderClosed) { // Abnormal termination of the flow above\n        IOUtils.closeStream(this);\n        if (responder !\u003d null) {\n          responder.interrupt();\n        }\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.join();\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          throw new IOException(\"Interrupted receiveBlock\");\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4122. Cleanup HDFS logs and reduce the size of logged messages. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1403120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/10/12 4:10 PM",
      "commitName": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "09/08/12 2:31 PM",
      "commitNameOld": "9ea7c06468d236452f03c38a31d1a45f7f09dc50",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 80.07,
      "commitsBetweenForRepo": 496,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,74 +1,74 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       /* \n        * Receive until the last packet.\n        */\n       while (receivePacket() \u003e\u003d 0) {}\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n           // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n-      LOG.info(\"Exception in receiveBlock for \" + block, ioe);\n+      LOG.info(\"Exception for \" + block, ioe);\n       throw ioe;\n     } finally {\n       if (!responderClosed) { // Abnormal termination of the flow above\n         IOUtils.closeStream(this);\n         if (responder !\u003d null) {\n           responder.interrupt();\n         }\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.join();\n         } catch (InterruptedException e) {\n           responder.interrupt();\n           throw new IOException(\"Interrupted receiveBlock\");\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      /* \n       * Receive until the last packet.\n       */\n      while (receivePacket() \u003e\u003d 0) {}\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      LOG.info(\"Exception for \" + block, ioe);\n      throw ioe;\n    } finally {\n      if (!responderClosed) { // Abnormal termination of the flow above\n        IOUtils.closeStream(this);\n        if (responder !\u003d null) {\n          responder.interrupt();\n        }\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.join();\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          throw new IOException(\"Interrupted receiveBlock\");\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "d4fb8821630f2da107b6c438a449c35df3686595": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3541. Deadlock between recovery, xceiver and packet responder. Contributed by Vinay.\n\nSubmitted by:\tVinay\nReviewed by:\tUma Maheswara Rao G\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1358794 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/07/12 10:42 AM",
      "commitName": "d4fb8821630f2da107b6c438a449c35df3686595",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "05/07/12 3:18 PM",
      "commitNameOld": "e0ef844280b98dc699ed3f9d948b83828bb8d297",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 2.81,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,73 +1,74 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams) throws IOException {\n \n       syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       /* \n        * Receive until the last packet.\n        */\n       while (receivePacket() \u003e\u003d 0) {}\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n           // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       LOG.info(\"Exception in receiveBlock for \" + block, ioe);\n       throw ioe;\n     } finally {\n       if (!responderClosed) { // Abnormal termination of the flow above\n         IOUtils.closeStream(this);\n         if (responder !\u003d null) {\n           responder.interrupt();\n         }\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.join();\n         } catch (InterruptedException e) {\n+          responder.interrupt();\n           throw new IOException(\"Interrupted receiveBlock\");\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      /* \n       * Receive until the last packet.\n       */\n      while (receivePacket() \u003e\u003d 0) {}\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      LOG.info(\"Exception in receiveBlock for \" + block, ioe);\n      throw ioe;\n    } finally {\n      if (!responderClosed) { // Abnormal termination of the flow above\n        IOUtils.closeStream(this);\n        if (responder !\u003d null) {\n          responder.interrupt();\n        }\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.join();\n        } catch (InterruptedException e) {\n          responder.interrupt();\n          throw new IOException(\"Interrupted receiveBlock\");\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "83cf475050dba27e72b4e399491638c670621175": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-744. Support hsync in HDFS. Contributed by Lars Hofhans\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1344419 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/05/12 12:10 PM",
      "commitName": "83cf475050dba27e72b4e399491638c670621175",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "28/03/12 1:37 PM",
      "commitNameOld": "99a68a14237b4cd1936ba5e9468d25d35dad594c",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 62.94,
      "commitsBetweenForRepo": 450,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,72 +1,73 @@\n   void receiveBlock(\n       DataOutputStream mirrOut, // output to next datanode\n       DataInputStream mirrIn,   // input from next datanode\n       DataOutputStream replyOut,  // output to previous datanode\n       String mirrAddr, DataTransferThrottler throttlerArg,\n       DatanodeInfo[] downstreams) throws IOException {\n \n+      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n       boolean responderClosed \u003d false;\n       mirrorOut \u003d mirrOut;\n       mirrorAddr \u003d mirrAddr;\n       throttler \u003d throttlerArg;\n \n     try {\n       if (isClient \u0026\u0026 !isTransfer) {\n         responder \u003d new Daemon(datanode.threadGroup, \n             new PacketResponder(replyOut, mirrIn, downstreams));\n         responder.start(); // start thread to processes responses\n       }\n \n       /* \n        * Receive until the last packet.\n        */\n       while (receivePacket() \u003e\u003d 0) {}\n \n       // wait for all outstanding packet responses. And then\n       // indicate responder to gracefully shutdown.\n       // Mark that responder has been closed for future processing\n       if (responder !\u003d null) {\n         ((PacketResponder)responder.getRunnable()).close();\n         responderClosed \u003d true;\n       }\n \n       // If this write is for a replication or transfer-RBW/Finalized,\n       // then finalize block or convert temporary to RBW.\n       // For client-writes, the block is finalized in the PacketResponder.\n       if (isDatanode || isTransfer) {\n         // close the block/crc files\n         close();\n         block.setNumBytes(replicaInfo.getNumBytes());\n \n         if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n           // for TRANSFER_RBW, convert temporary to RBW\n           datanode.data.convertTemporaryToRbw(block);\n         } else {\n           // for isDatnode or TRANSFER_FINALIZED\n-          // Finalize the block. Does this fsync()?\n+          // Finalize the block.\n           datanode.data.finalizeBlock(block);\n         }\n         datanode.metrics.incrBlocksWritten();\n       }\n \n     } catch (IOException ioe) {\n       LOG.info(\"Exception in receiveBlock for \" + block, ioe);\n       throw ioe;\n     } finally {\n       if (!responderClosed) { // Abnormal termination of the flow above\n         IOUtils.closeStream(this);\n         if (responder !\u003d null) {\n           responder.interrupt();\n         }\n         cleanupBlock();\n       }\n       if (responder !\u003d null) {\n         try {\n           responder.join();\n         } catch (InterruptedException e) {\n           throw new IOException(\"Interrupted receiveBlock\");\n         }\n         responder \u003d null;\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams) throws IOException {\n\n      syncOnClose \u003d datanode.getDnConf().syncOnClose;\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      /* \n       * Receive until the last packet.\n       */\n      while (receivePacket() \u003e\u003d 0) {}\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block.\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      LOG.info(\"Exception in receiveBlock for \" + block, ioe);\n      throw ioe;\n    } finally {\n      if (!responderClosed) { // Abnormal termination of the flow above\n        IOUtils.closeStream(this);\n        if (responder !\u003d null) {\n          responder.interrupt();\n        }\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.join();\n        } catch (InterruptedException e) {\n          throw new IOException(\"Interrupted receiveBlock\");\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams) throws IOException {\n\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      /* \n       * Receive until the last packet.\n       */\n      while (receivePacket() \u003e\u003d 0) {}\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block. Does this fsync()?\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      LOG.info(\"Exception in receiveBlock for \" + block, ioe);\n      throw ioe;\n    } finally {\n      if (!responderClosed) { // Abnormal termination of the flow above\n        IOUtils.closeStream(this);\n        if (responder !\u003d null) {\n          responder.interrupt();\n        }\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.join();\n        } catch (InterruptedException e) {\n          throw new IOException(\"Interrupted receiveBlock\");\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams) throws IOException {\n\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      /* \n       * Receive until the last packet.\n       */\n      while (receivePacket() \u003e\u003d 0) {}\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block. Does this fsync()?\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      LOG.info(\"Exception in receiveBlock for \" + block, ioe);\n      throw ioe;\n    } finally {\n      if (!responderClosed) { // Abnormal termination of the flow above\n        IOUtils.closeStream(this);\n        if (responder !\u003d null) {\n          responder.interrupt();\n        }\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.join();\n        } catch (InterruptedException e) {\n          throw new IOException(\"Interrupted receiveBlock\");\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,72 @@\n+  void receiveBlock(\n+      DataOutputStream mirrOut, // output to next datanode\n+      DataInputStream mirrIn,   // input from next datanode\n+      DataOutputStream replyOut,  // output to previous datanode\n+      String mirrAddr, DataTransferThrottler throttlerArg,\n+      DatanodeInfo[] downstreams) throws IOException {\n+\n+      boolean responderClosed \u003d false;\n+      mirrorOut \u003d mirrOut;\n+      mirrorAddr \u003d mirrAddr;\n+      throttler \u003d throttlerArg;\n+\n+    try {\n+      if (isClient \u0026\u0026 !isTransfer) {\n+        responder \u003d new Daemon(datanode.threadGroup, \n+            new PacketResponder(replyOut, mirrIn, downstreams));\n+        responder.start(); // start thread to processes responses\n+      }\n+\n+      /* \n+       * Receive until the last packet.\n+       */\n+      while (receivePacket() \u003e\u003d 0) {}\n+\n+      // wait for all outstanding packet responses. And then\n+      // indicate responder to gracefully shutdown.\n+      // Mark that responder has been closed for future processing\n+      if (responder !\u003d null) {\n+        ((PacketResponder)responder.getRunnable()).close();\n+        responderClosed \u003d true;\n+      }\n+\n+      // If this write is for a replication or transfer-RBW/Finalized,\n+      // then finalize block or convert temporary to RBW.\n+      // For client-writes, the block is finalized in the PacketResponder.\n+      if (isDatanode || isTransfer) {\n+        // close the block/crc files\n+        close();\n+        block.setNumBytes(replicaInfo.getNumBytes());\n+\n+        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n+          // for TRANSFER_RBW, convert temporary to RBW\n+          datanode.data.convertTemporaryToRbw(block);\n+        } else {\n+          // for isDatnode or TRANSFER_FINALIZED\n+          // Finalize the block. Does this fsync()?\n+          datanode.data.finalizeBlock(block);\n+        }\n+        datanode.metrics.incrBlocksWritten();\n+      }\n+\n+    } catch (IOException ioe) {\n+      LOG.info(\"Exception in receiveBlock for \" + block, ioe);\n+      throw ioe;\n+    } finally {\n+      if (!responderClosed) { // Abnormal termination of the flow above\n+        IOUtils.closeStream(this);\n+        if (responder !\u003d null) {\n+          responder.interrupt();\n+        }\n+        cleanupBlock();\n+      }\n+      if (responder !\u003d null) {\n+        try {\n+          responder.join();\n+        } catch (InterruptedException e) {\n+          throw new IOException(\"Interrupted receiveBlock\");\n+        }\n+        responder \u003d null;\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void receiveBlock(\n      DataOutputStream mirrOut, // output to next datanode\n      DataInputStream mirrIn,   // input from next datanode\n      DataOutputStream replyOut,  // output to previous datanode\n      String mirrAddr, DataTransferThrottler throttlerArg,\n      DatanodeInfo[] downstreams) throws IOException {\n\n      boolean responderClosed \u003d false;\n      mirrorOut \u003d mirrOut;\n      mirrorAddr \u003d mirrAddr;\n      throttler \u003d throttlerArg;\n\n    try {\n      if (isClient \u0026\u0026 !isTransfer) {\n        responder \u003d new Daemon(datanode.threadGroup, \n            new PacketResponder(replyOut, mirrIn, downstreams));\n        responder.start(); // start thread to processes responses\n      }\n\n      /* \n       * Receive until the last packet.\n       */\n      while (receivePacket() \u003e\u003d 0) {}\n\n      // wait for all outstanding packet responses. And then\n      // indicate responder to gracefully shutdown.\n      // Mark that responder has been closed for future processing\n      if (responder !\u003d null) {\n        ((PacketResponder)responder.getRunnable()).close();\n        responderClosed \u003d true;\n      }\n\n      // If this write is for a replication or transfer-RBW/Finalized,\n      // then finalize block or convert temporary to RBW.\n      // For client-writes, the block is finalized in the PacketResponder.\n      if (isDatanode || isTransfer) {\n        // close the block/crc files\n        close();\n        block.setNumBytes(replicaInfo.getNumBytes());\n\n        if (stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW) {\n          // for TRANSFER_RBW, convert temporary to RBW\n          datanode.data.convertTemporaryToRbw(block);\n        } else {\n          // for isDatnode or TRANSFER_FINALIZED\n          // Finalize the block. Does this fsync()?\n          datanode.data.finalizeBlock(block);\n        }\n        datanode.metrics.incrBlocksWritten();\n      }\n\n    } catch (IOException ioe) {\n      LOG.info(\"Exception in receiveBlock for \" + block, ioe);\n      throw ioe;\n    } finally {\n      if (!responderClosed) { // Abnormal termination of the flow above\n        IOUtils.closeStream(this);\n        if (responder !\u003d null) {\n          responder.interrupt();\n        }\n        cleanupBlock();\n      }\n      if (responder !\u003d null) {\n        try {\n          responder.join();\n        } catch (InterruptedException e) {\n          throw new IOException(\"Interrupted receiveBlock\");\n        }\n        responder \u003d null;\n      }\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/BlockReceiver.java"
    }
  }
}