{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JobHistoryEventHandler.java",
  "functionName": "publishConfigsOnJobSubmittedEvent",
  "functionId": "publishConfigsOnJobSubmittedEvent___event-JobSubmittedEvent__jobId-JobId",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
  "functionStartLine": 1235,
  "functionEndLine": 1273,
  "numCommitsSeen": 69,
  "timeTaken": 1452,
  "changeHistory": [
    "4fa1afdb883dab8786d2fb5c72a195dd2e87d711",
    "000a4d8e133920d71af304f2015d3674daed74fa"
  ],
  "changeHistoryShort": {
    "4fa1afdb883dab8786d2fb5c72a195dd2e87d711": "Ybodychange",
    "000a4d8e133920d71af304f2015d3674daed74fa": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4fa1afdb883dab8786d2fb5c72a195dd2e87d711": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4675. Reorganize TimelineClient and TimelineClientImpl into separate classes for ATSv1.x and ATSv2. Contributed by Naganarasimha G R.\n",
      "commitDate": "16/02/17 11:41 AM",
      "commitName": "4fa1afdb883dab8786d2fb5c72a195dd2e87d711",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "15/11/16 10:57 AM",
      "commitNameOld": "5af572b6443715b7a741296c1bd520a1840f9a7c",
      "commitAuthorOld": "Mingliang Liu",
      "daysBetweenCommits": 93.03,
      "commitsBetweenForRepo": 475,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,39 @@\n   private void publishConfigsOnJobSubmittedEvent(JobSubmittedEvent event,\n       JobId jobId) {\n     if (event.getJobConf() \u003d\u003d null) {\n       return;\n     }\n     // Publish job configurations both as job and app entity.\n     // Configs are split into multiple entities if they exceed 100kb in size.\n     org.apache.hadoop.yarn.api.records.timelineservice.\n         TimelineEntity jobEntityForConfigs \u003d createJobEntity(jobId);\n     ApplicationEntity appEntityForConfigs \u003d new ApplicationEntity();\n     String appId \u003d jobId.getAppId().toString();\n     appEntityForConfigs.setId(appId);\n     try {\n       int configSize \u003d 0;\n       for (Map.Entry\u003cString, String\u003e entry : event.getJobConf()) {\n         int size \u003d entry.getKey().length() + entry.getValue().length();\n         configSize +\u003d size;\n         if (configSize \u003e JobHistoryEventUtils.ATS_CONFIG_PUBLISH_SIZE_BYTES) {\n           if (jobEntityForConfigs.getConfigs().size() \u003e 0) {\n-            timelineClient.putEntities(jobEntityForConfigs);\n-            timelineClient.putEntities(appEntityForConfigs);\n+            timelineV2Client.putEntities(jobEntityForConfigs);\n+            timelineV2Client.putEntities(appEntityForConfigs);\n             jobEntityForConfigs \u003d createJobEntity(jobId);\n             appEntityForConfigs \u003d new ApplicationEntity();\n             appEntityForConfigs.setId(appId);\n           }\n           configSize \u003d size;\n         }\n         jobEntityForConfigs.addConfig(entry.getKey(), entry.getValue());\n         appEntityForConfigs.addConfig(entry.getKey(), entry.getValue());\n       }\n       if (configSize \u003e 0) {\n-        timelineClient.putEntities(jobEntityForConfigs);\n-        timelineClient.putEntities(appEntityForConfigs);\n+        timelineV2Client.putEntities(jobEntityForConfigs);\n+        timelineV2Client.putEntities(appEntityForConfigs);\n       }\n     } catch (IOException | YarnException e) {\n       LOG.error(\"Exception while publishing configs on JOB_SUBMITTED Event \" +\n           \" for the job : \" + jobId, e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void publishConfigsOnJobSubmittedEvent(JobSubmittedEvent event,\n      JobId jobId) {\n    if (event.getJobConf() \u003d\u003d null) {\n      return;\n    }\n    // Publish job configurations both as job and app entity.\n    // Configs are split into multiple entities if they exceed 100kb in size.\n    org.apache.hadoop.yarn.api.records.timelineservice.\n        TimelineEntity jobEntityForConfigs \u003d createJobEntity(jobId);\n    ApplicationEntity appEntityForConfigs \u003d new ApplicationEntity();\n    String appId \u003d jobId.getAppId().toString();\n    appEntityForConfigs.setId(appId);\n    try {\n      int configSize \u003d 0;\n      for (Map.Entry\u003cString, String\u003e entry : event.getJobConf()) {\n        int size \u003d entry.getKey().length() + entry.getValue().length();\n        configSize +\u003d size;\n        if (configSize \u003e JobHistoryEventUtils.ATS_CONFIG_PUBLISH_SIZE_BYTES) {\n          if (jobEntityForConfigs.getConfigs().size() \u003e 0) {\n            timelineV2Client.putEntities(jobEntityForConfigs);\n            timelineV2Client.putEntities(appEntityForConfigs);\n            jobEntityForConfigs \u003d createJobEntity(jobId);\n            appEntityForConfigs \u003d new ApplicationEntity();\n            appEntityForConfigs.setId(appId);\n          }\n          configSize \u003d size;\n        }\n        jobEntityForConfigs.addConfig(entry.getKey(), entry.getValue());\n        appEntityForConfigs.addConfig(entry.getKey(), entry.getValue());\n      }\n      if (configSize \u003e 0) {\n        timelineV2Client.putEntities(jobEntityForConfigs);\n        timelineV2Client.putEntities(appEntityForConfigs);\n      }\n    } catch (IOException | YarnException e) {\n      LOG.error(\"Exception while publishing configs on JOB_SUBMITTED Event \" +\n          \" for the job : \" + jobId, e);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "000a4d8e133920d71af304f2015d3674daed74fa": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-6688. Store job configurations in Timeline Service v2 (Varun Saxena via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "000a4d8e133920d71af304f2015d3674daed74fa",
      "commitAuthor": "Sangjin Lee",
      "diff": "@@ -0,0 +1,39 @@\n+  private void publishConfigsOnJobSubmittedEvent(JobSubmittedEvent event,\n+      JobId jobId) {\n+    if (event.getJobConf() \u003d\u003d null) {\n+      return;\n+    }\n+    // Publish job configurations both as job and app entity.\n+    // Configs are split into multiple entities if they exceed 100kb in size.\n+    org.apache.hadoop.yarn.api.records.timelineservice.\n+        TimelineEntity jobEntityForConfigs \u003d createJobEntity(jobId);\n+    ApplicationEntity appEntityForConfigs \u003d new ApplicationEntity();\n+    String appId \u003d jobId.getAppId().toString();\n+    appEntityForConfigs.setId(appId);\n+    try {\n+      int configSize \u003d 0;\n+      for (Map.Entry\u003cString, String\u003e entry : event.getJobConf()) {\n+        int size \u003d entry.getKey().length() + entry.getValue().length();\n+        configSize +\u003d size;\n+        if (configSize \u003e JobHistoryEventUtils.ATS_CONFIG_PUBLISH_SIZE_BYTES) {\n+          if (jobEntityForConfigs.getConfigs().size() \u003e 0) {\n+            timelineClient.putEntities(jobEntityForConfigs);\n+            timelineClient.putEntities(appEntityForConfigs);\n+            jobEntityForConfigs \u003d createJobEntity(jobId);\n+            appEntityForConfigs \u003d new ApplicationEntity();\n+            appEntityForConfigs.setId(appId);\n+          }\n+          configSize \u003d size;\n+        }\n+        jobEntityForConfigs.addConfig(entry.getKey(), entry.getValue());\n+        appEntityForConfigs.addConfig(entry.getKey(), entry.getValue());\n+      }\n+      if (configSize \u003e 0) {\n+        timelineClient.putEntities(jobEntityForConfigs);\n+        timelineClient.putEntities(appEntityForConfigs);\n+      }\n+    } catch (IOException | YarnException e) {\n+      LOG.error(\"Exception while publishing configs on JOB_SUBMITTED Event \" +\n+          \" for the job : \" + jobId, e);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void publishConfigsOnJobSubmittedEvent(JobSubmittedEvent event,\n      JobId jobId) {\n    if (event.getJobConf() \u003d\u003d null) {\n      return;\n    }\n    // Publish job configurations both as job and app entity.\n    // Configs are split into multiple entities if they exceed 100kb in size.\n    org.apache.hadoop.yarn.api.records.timelineservice.\n        TimelineEntity jobEntityForConfigs \u003d createJobEntity(jobId);\n    ApplicationEntity appEntityForConfigs \u003d new ApplicationEntity();\n    String appId \u003d jobId.getAppId().toString();\n    appEntityForConfigs.setId(appId);\n    try {\n      int configSize \u003d 0;\n      for (Map.Entry\u003cString, String\u003e entry : event.getJobConf()) {\n        int size \u003d entry.getKey().length() + entry.getValue().length();\n        configSize +\u003d size;\n        if (configSize \u003e JobHistoryEventUtils.ATS_CONFIG_PUBLISH_SIZE_BYTES) {\n          if (jobEntityForConfigs.getConfigs().size() \u003e 0) {\n            timelineClient.putEntities(jobEntityForConfigs);\n            timelineClient.putEntities(appEntityForConfigs);\n            jobEntityForConfigs \u003d createJobEntity(jobId);\n            appEntityForConfigs \u003d new ApplicationEntity();\n            appEntityForConfigs.setId(appId);\n          }\n          configSize \u003d size;\n        }\n        jobEntityForConfigs.addConfig(entry.getKey(), entry.getValue());\n        appEntityForConfigs.addConfig(entry.getKey(), entry.getValue());\n      }\n      if (configSize \u003e 0) {\n        timelineClient.putEntities(jobEntityForConfigs);\n        timelineClient.putEntities(appEntityForConfigs);\n      }\n    } catch (IOException | YarnException e) {\n      LOG.error(\"Exception while publishing configs on JOB_SUBMITTED Event \" +\n          \" for the job : \" + jobId, e);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java"
    }
  }
}