{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "reportDiffSortedInner",
  "functionId": "reportDiffSortedInner___storageInfo-DatanodeStorageInfo(modifiers-final)__replica-BlockReportReplica(modifiers-final)__reportedState-ReplicaState(modifiers-final)__storedBlock-BlockInfo(modifiers-final)__toAdd-Collection__BlockInfoToAdd__(modifiers-final)__toCorrupt-Collection__BlockToMarkCorrupt__(modifiers-final)__toUC-Collection__StatefulBlockInfo__(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 3130,
  "functionEndLine": 3177,
  "numCommitsSeen": 791,
  "timeTaken": 10722,
  "changeHistory": [
    "a7f085d6bf499edf23e650a4f7211c53a442da0e",
    "72dfb048a9a7be64b371b74478b90150bf300d35",
    "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a"
  ],
  "changeHistoryShort": {
    "a7f085d6bf499edf23e650a4f7211c53a442da0e": "Ybodychange",
    "72dfb048a9a7be64b371b74478b90150bf300d35": "Ybodychange",
    "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a": "Ymultichange(Yrename,Yparameterchange,Ybodychange,Yparametermetachange)"
  },
  "changeHistoryDetails": {
    "a7f085d6bf499edf23e650a4f7211c53a442da0e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11832. Switch leftover logs to slf4j format in BlockManager.java. Contributed by Hui Xu and Chen Liang.\n",
      "commitDate": "29/05/17 1:30 AM",
      "commitName": "a7f085d6bf499edf23e650a4f7211c53a442da0e",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "25/05/17 7:35 AM",
      "commitNameOld": "2e41f8803dd46d1bab16c1b206c71be72ea260a1",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 3.75,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,48 @@\n   private void reportDiffSortedInner(\n       final DatanodeStorageInfo storageInfo,\n       final BlockReportReplica replica, final ReplicaState reportedState,\n       final BlockInfo storedBlock,\n       final Collection\u003cBlockInfoToAdd\u003e toAdd,\n       final Collection\u003cBlockToMarkCorrupt\u003e toCorrupt,\n       final Collection\u003cStatefulBlockInfo\u003e toUC) {\n \n     assert replica !\u003d null;\n     assert storedBlock !\u003d null;\n \n     DatanodeDescriptor dn \u003d storageInfo.getDatanodeDescriptor();\n     BlockUCState ucState \u003d storedBlock.getBlockUCState();\n \n     // Block is on the NN\n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"In memory blockUCState \u003d \" + ucState);\n-    }\n+    LOG.debug(\"In memory blockUCState \u003d {}\", ucState);\n \n     // Ignore replicas already scheduled to be removed from the DN\n     if (invalidateBlocks.contains(dn, replica)) {\n       return;\n     }\n \n     BlockToMarkCorrupt c \u003d checkReplicaCorrupt(replica, reportedState,\n                                                storedBlock, ucState, dn);\n     if (c !\u003d null) {\n       if (shouldPostponeBlocksFromFuture) {\n         // If the block is an out-of-date generation stamp or state,\n         // but we\u0027re the standby, we shouldn\u0027t treat it as corrupt,\n         // but instead just queue it for later processing.\n         // TODO: Pretty confident this should be s/storedBlock/block below,\n         // since we should be postponing the info of the reported block, not\n         // the stored block. See HDFS-6289 for more context.\n         queueReportedBlock(storageInfo, storedBlock, reportedState,\n             QUEUE_REASON_CORRUPT_STATE);\n       } else {\n         toCorrupt.add(c);\n       }\n     } else if (isBlockUnderConstruction(storedBlock, ucState, reportedState)) {\n       toUC.add(new StatefulBlockInfo(storedBlock, new Block(replica),\n           reportedState));\n     } else if (reportedState \u003d\u003d ReplicaState.FINALIZED \u0026\u0026\n                (storedBlock.findStorageInfo(storageInfo) \u003d\u003d -1 ||\n                 corruptReplicas.isReplicaCorrupt(storedBlock, dn))) {\n       // Add replica if appropriate. If the replica was previously corrupt\n       // but now okay, it might need to be updated.\n       toAdd.add(new BlockInfoToAdd(storedBlock, new Block(replica)));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void reportDiffSortedInner(\n      final DatanodeStorageInfo storageInfo,\n      final BlockReportReplica replica, final ReplicaState reportedState,\n      final BlockInfo storedBlock,\n      final Collection\u003cBlockInfoToAdd\u003e toAdd,\n      final Collection\u003cBlockToMarkCorrupt\u003e toCorrupt,\n      final Collection\u003cStatefulBlockInfo\u003e toUC) {\n\n    assert replica !\u003d null;\n    assert storedBlock !\u003d null;\n\n    DatanodeDescriptor dn \u003d storageInfo.getDatanodeDescriptor();\n    BlockUCState ucState \u003d storedBlock.getBlockUCState();\n\n    // Block is on the NN\n    LOG.debug(\"In memory blockUCState \u003d {}\", ucState);\n\n    // Ignore replicas already scheduled to be removed from the DN\n    if (invalidateBlocks.contains(dn, replica)) {\n      return;\n    }\n\n    BlockToMarkCorrupt c \u003d checkReplicaCorrupt(replica, reportedState,\n                                               storedBlock, ucState, dn);\n    if (c !\u003d null) {\n      if (shouldPostponeBlocksFromFuture) {\n        // If the block is an out-of-date generation stamp or state,\n        // but we\u0027re the standby, we shouldn\u0027t treat it as corrupt,\n        // but instead just queue it for later processing.\n        // TODO: Pretty confident this should be s/storedBlock/block below,\n        // since we should be postponing the info of the reported block, not\n        // the stored block. See HDFS-6289 for more context.\n        queueReportedBlock(storageInfo, storedBlock, reportedState,\n            QUEUE_REASON_CORRUPT_STATE);\n      } else {\n        toCorrupt.add(c);\n      }\n    } else if (isBlockUnderConstruction(storedBlock, ucState, reportedState)) {\n      toUC.add(new StatefulBlockInfo(storedBlock, new Block(replica),\n          reportedState));\n    } else if (reportedState \u003d\u003d ReplicaState.FINALIZED \u0026\u0026\n               (storedBlock.findStorageInfo(storageInfo) \u003d\u003d -1 ||\n                corruptReplicas.isReplicaCorrupt(storedBlock, dn))) {\n      // Add replica if appropriate. If the replica was previously corrupt\n      // but now okay, it might need to be updated.\n      toAdd.add(new BlockInfoToAdd(storedBlock, new Block(replica)));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "72dfb048a9a7be64b371b74478b90150bf300d35": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10858. FBR processing may generate incorrect reportedBlock-blockGroup mapping. Contributed by Jing Zhao.\n",
      "commitDate": "12/09/16 4:40 PM",
      "commitName": "72dfb048a9a7be64b371b74478b90150bf300d35",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "06/09/16 10:38 AM",
      "commitNameOld": "d37dc5d1b8e022a7085118a2e7066623483c293f",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 6.25,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,50 @@\n   private void reportDiffSortedInner(\n       final DatanodeStorageInfo storageInfo,\n       final BlockReportReplica replica, final ReplicaState reportedState,\n       final BlockInfo storedBlock,\n       final Collection\u003cBlockInfoToAdd\u003e toAdd,\n       final Collection\u003cBlockToMarkCorrupt\u003e toCorrupt,\n       final Collection\u003cStatefulBlockInfo\u003e toUC) {\n \n     assert replica !\u003d null;\n     assert storedBlock !\u003d null;\n \n     DatanodeDescriptor dn \u003d storageInfo.getDatanodeDescriptor();\n     BlockUCState ucState \u003d storedBlock.getBlockUCState();\n \n     // Block is on the NN\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"In memory blockUCState \u003d \" + ucState);\n     }\n \n     // Ignore replicas already scheduled to be removed from the DN\n     if (invalidateBlocks.contains(dn, replica)) {\n       return;\n     }\n \n     BlockToMarkCorrupt c \u003d checkReplicaCorrupt(replica, reportedState,\n                                                storedBlock, ucState, dn);\n     if (c !\u003d null) {\n       if (shouldPostponeBlocksFromFuture) {\n         // If the block is an out-of-date generation stamp or state,\n         // but we\u0027re the standby, we shouldn\u0027t treat it as corrupt,\n         // but instead just queue it for later processing.\n         // TODO: Pretty confident this should be s/storedBlock/block below,\n         // since we should be postponing the info of the reported block, not\n         // the stored block. See HDFS-6289 for more context.\n         queueReportedBlock(storageInfo, storedBlock, reportedState,\n             QUEUE_REASON_CORRUPT_STATE);\n       } else {\n         toCorrupt.add(c);\n       }\n     } else if (isBlockUnderConstruction(storedBlock, ucState, reportedState)) {\n       toUC.add(new StatefulBlockInfo(storedBlock, new Block(replica),\n           reportedState));\n     } else if (reportedState \u003d\u003d ReplicaState.FINALIZED \u0026\u0026\n                (storedBlock.findStorageInfo(storageInfo) \u003d\u003d -1 ||\n                 corruptReplicas.isReplicaCorrupt(storedBlock, dn))) {\n       // Add replica if appropriate. If the replica was previously corrupt\n       // but now okay, it might need to be updated.\n-      toAdd.add(new BlockInfoToAdd(storedBlock, replica));\n+      toAdd.add(new BlockInfoToAdd(storedBlock, new Block(replica)));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void reportDiffSortedInner(\n      final DatanodeStorageInfo storageInfo,\n      final BlockReportReplica replica, final ReplicaState reportedState,\n      final BlockInfo storedBlock,\n      final Collection\u003cBlockInfoToAdd\u003e toAdd,\n      final Collection\u003cBlockToMarkCorrupt\u003e toCorrupt,\n      final Collection\u003cStatefulBlockInfo\u003e toUC) {\n\n    assert replica !\u003d null;\n    assert storedBlock !\u003d null;\n\n    DatanodeDescriptor dn \u003d storageInfo.getDatanodeDescriptor();\n    BlockUCState ucState \u003d storedBlock.getBlockUCState();\n\n    // Block is on the NN\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"In memory blockUCState \u003d \" + ucState);\n    }\n\n    // Ignore replicas already scheduled to be removed from the DN\n    if (invalidateBlocks.contains(dn, replica)) {\n      return;\n    }\n\n    BlockToMarkCorrupt c \u003d checkReplicaCorrupt(replica, reportedState,\n                                               storedBlock, ucState, dn);\n    if (c !\u003d null) {\n      if (shouldPostponeBlocksFromFuture) {\n        // If the block is an out-of-date generation stamp or state,\n        // but we\u0027re the standby, we shouldn\u0027t treat it as corrupt,\n        // but instead just queue it for later processing.\n        // TODO: Pretty confident this should be s/storedBlock/block below,\n        // since we should be postponing the info of the reported block, not\n        // the stored block. See HDFS-6289 for more context.\n        queueReportedBlock(storageInfo, storedBlock, reportedState,\n            QUEUE_REASON_CORRUPT_STATE);\n      } else {\n        toCorrupt.add(c);\n      }\n    } else if (isBlockUnderConstruction(storedBlock, ucState, reportedState)) {\n      toUC.add(new StatefulBlockInfo(storedBlock, new Block(replica),\n          reportedState));\n    } else if (reportedState \u003d\u003d ReplicaState.FINALIZED \u0026\u0026\n               (storedBlock.findStorageInfo(storageInfo) \u003d\u003d -1 ||\n                corruptReplicas.isReplicaCorrupt(storedBlock, dn))) {\n      // Add replica if appropriate. If the replica was previously corrupt\n      // but now okay, it might need to be updated.\n      toAdd.add(new BlockInfoToAdd(storedBlock, new Block(replica)));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a": {
      "type": "Ymultichange(Yrename,Yparameterchange,Ybodychange,Yparametermetachange)",
      "commitMessage": "HDFS-9260. Improve the performance and GC friendliness of NameNode startup and full block reports (Staffan Friberg via cmccabe)\n",
      "commitDate": "02/02/16 11:23 AM",
      "commitName": "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a",
      "commitAuthor": "Colin Patrick Mccabe",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-9260. Improve the performance and GC friendliness of NameNode startup and full block reports (Staffan Friberg via cmccabe)\n",
          "commitDate": "02/02/16 11:23 AM",
          "commitName": "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "31/01/16 11:54 PM",
          "commitNameOld": "e418bd1fb0568ce7ae22f588fea2dd9c95567383",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 1.48,
          "commitsBetweenForRepo": 16,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,50 @@\n-  private void reportDiff(DatanodeStorageInfo storageInfo, \n-      BlockListAsLongs newReport,\n-      Collection\u003cBlockInfoToAdd\u003e toAdd,     // add to DatanodeDescriptor\n-      Collection\u003cBlockInfo\u003e toRemove,       // remove from DatanodeDescriptor\n-      Collection\u003cBlock\u003e toInvalidate,       // should be removed from DN\n-      Collection\u003cBlockToMarkCorrupt\u003e toCorrupt, // add to corrupt replicas list\n-      Collection\u003cStatefulBlockInfo\u003e toUC) { // add to under-construction list\n+  private void reportDiffSortedInner(\n+      final DatanodeStorageInfo storageInfo,\n+      final BlockReportReplica replica, final ReplicaState reportedState,\n+      final BlockInfo storedBlock,\n+      final Collection\u003cBlockInfoToAdd\u003e toAdd,\n+      final Collection\u003cBlockToMarkCorrupt\u003e toCorrupt,\n+      final Collection\u003cStatefulBlockInfo\u003e toUC) {\n \n-    // place a delimiter in the list which separates blocks \n-    // that have been reported from those that have not\n-    Block delimiterBlock \u003d new Block();\n-    BlockInfo delimiter \u003d new BlockInfoContiguous(delimiterBlock,\n-        (short) 1);\n-    AddBlockResult result \u003d storageInfo.addBlock(delimiter, delimiterBlock);\n-    assert result \u003d\u003d AddBlockResult.ADDED \n-        : \"Delimiting block cannot be present in the node\";\n-    int headIndex \u003d 0; //currently the delimiter is in the head of the list\n-    int curIndex;\n+    assert replica !\u003d null;\n+    assert storedBlock !\u003d null;\n \n-    if (newReport \u003d\u003d null) {\n-      newReport \u003d BlockListAsLongs.EMPTY;\n+    DatanodeDescriptor dn \u003d storageInfo.getDatanodeDescriptor();\n+    BlockUCState ucState \u003d storedBlock.getBlockUCState();\n+\n+    // Block is on the NN\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"In memory blockUCState \u003d \" + ucState);\n     }\n-    // scan the report and process newly reported blocks\n-    for (BlockReportReplica iblk : newReport) {\n-      ReplicaState iState \u003d iblk.getState();\n-      BlockInfo storedBlock \u003d processReportedBlock(storageInfo,\n-          iblk, iState, toAdd, toInvalidate, toCorrupt, toUC);\n \n-      // move block to the head of the list\n-      if (storedBlock !\u003d null \u0026\u0026\n-          (curIndex \u003d storedBlock.findStorageInfo(storageInfo)) \u003e\u003d 0) {\n-        headIndex \u003d storageInfo.moveBlockToHead(storedBlock, curIndex, headIndex);\n+    // Ignore replicas already scheduled to be removed from the DN\n+    if (invalidateBlocks.contains(dn, replica)) {\n+      return;\n+    }\n+\n+    BlockToMarkCorrupt c \u003d checkReplicaCorrupt(replica, reportedState,\n+                                               storedBlock, ucState, dn);\n+    if (c !\u003d null) {\n+      if (shouldPostponeBlocksFromFuture) {\n+        // If the block is an out-of-date generation stamp or state,\n+        // but we\u0027re the standby, we shouldn\u0027t treat it as corrupt,\n+        // but instead just queue it for later processing.\n+        // TODO: Pretty confident this should be s/storedBlock/block below,\n+        // since we should be postponing the info of the reported block, not\n+        // the stored block. See HDFS-6289 for more context.\n+        queueReportedBlock(storageInfo, storedBlock, reportedState,\n+            QUEUE_REASON_CORRUPT_STATE);\n+      } else {\n+        toCorrupt.add(c);\n       }\n+    } else if (isBlockUnderConstruction(storedBlock, ucState, reportedState)) {\n+      toUC.add(new StatefulBlockInfo(storedBlock, new Block(replica),\n+          reportedState));\n+    } else if (reportedState \u003d\u003d ReplicaState.FINALIZED \u0026\u0026\n+               (storedBlock.findStorageInfo(storageInfo) \u003d\u003d -1 ||\n+                corruptReplicas.isReplicaCorrupt(storedBlock, dn))) {\n+      // Add replica if appropriate. If the replica was previously corrupt\n+      // but now okay, it might need to be updated.\n+      toAdd.add(new BlockInfoToAdd(storedBlock, replica));\n     }\n-\n-    // collect blocks that have not been reported\n-    // all of them are next to the delimiter\n-    Iterator\u003cBlockInfo\u003e it \u003d\n-        storageInfo.new BlockIterator(delimiter.getNext(0));\n-    while (it.hasNext()) {\n-      toRemove.add(it.next());\n-    }\n-    storageInfo.removeBlock(delimiter);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void reportDiffSortedInner(\n      final DatanodeStorageInfo storageInfo,\n      final BlockReportReplica replica, final ReplicaState reportedState,\n      final BlockInfo storedBlock,\n      final Collection\u003cBlockInfoToAdd\u003e toAdd,\n      final Collection\u003cBlockToMarkCorrupt\u003e toCorrupt,\n      final Collection\u003cStatefulBlockInfo\u003e toUC) {\n\n    assert replica !\u003d null;\n    assert storedBlock !\u003d null;\n\n    DatanodeDescriptor dn \u003d storageInfo.getDatanodeDescriptor();\n    BlockUCState ucState \u003d storedBlock.getBlockUCState();\n\n    // Block is on the NN\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"In memory blockUCState \u003d \" + ucState);\n    }\n\n    // Ignore replicas already scheduled to be removed from the DN\n    if (invalidateBlocks.contains(dn, replica)) {\n      return;\n    }\n\n    BlockToMarkCorrupt c \u003d checkReplicaCorrupt(replica, reportedState,\n                                               storedBlock, ucState, dn);\n    if (c !\u003d null) {\n      if (shouldPostponeBlocksFromFuture) {\n        // If the block is an out-of-date generation stamp or state,\n        // but we\u0027re the standby, we shouldn\u0027t treat it as corrupt,\n        // but instead just queue it for later processing.\n        // TODO: Pretty confident this should be s/storedBlock/block below,\n        // since we should be postponing the info of the reported block, not\n        // the stored block. See HDFS-6289 for more context.\n        queueReportedBlock(storageInfo, storedBlock, reportedState,\n            QUEUE_REASON_CORRUPT_STATE);\n      } else {\n        toCorrupt.add(c);\n      }\n    } else if (isBlockUnderConstruction(storedBlock, ucState, reportedState)) {\n      toUC.add(new StatefulBlockInfo(storedBlock, new Block(replica),\n          reportedState));\n    } else if (reportedState \u003d\u003d ReplicaState.FINALIZED \u0026\u0026\n               (storedBlock.findStorageInfo(storageInfo) \u003d\u003d -1 ||\n                corruptReplicas.isReplicaCorrupt(storedBlock, dn))) {\n      // Add replica if appropriate. If the replica was previously corrupt\n      // but now okay, it might need to be updated.\n      toAdd.add(new BlockInfoToAdd(storedBlock, replica));\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "reportDiff",
            "newValue": "reportDiffSortedInner"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9260. Improve the performance and GC friendliness of NameNode startup and full block reports (Staffan Friberg via cmccabe)\n",
          "commitDate": "02/02/16 11:23 AM",
          "commitName": "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "31/01/16 11:54 PM",
          "commitNameOld": "e418bd1fb0568ce7ae22f588fea2dd9c95567383",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 1.48,
          "commitsBetweenForRepo": 16,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,50 @@\n-  private void reportDiff(DatanodeStorageInfo storageInfo, \n-      BlockListAsLongs newReport,\n-      Collection\u003cBlockInfoToAdd\u003e toAdd,     // add to DatanodeDescriptor\n-      Collection\u003cBlockInfo\u003e toRemove,       // remove from DatanodeDescriptor\n-      Collection\u003cBlock\u003e toInvalidate,       // should be removed from DN\n-      Collection\u003cBlockToMarkCorrupt\u003e toCorrupt, // add to corrupt replicas list\n-      Collection\u003cStatefulBlockInfo\u003e toUC) { // add to under-construction list\n+  private void reportDiffSortedInner(\n+      final DatanodeStorageInfo storageInfo,\n+      final BlockReportReplica replica, final ReplicaState reportedState,\n+      final BlockInfo storedBlock,\n+      final Collection\u003cBlockInfoToAdd\u003e toAdd,\n+      final Collection\u003cBlockToMarkCorrupt\u003e toCorrupt,\n+      final Collection\u003cStatefulBlockInfo\u003e toUC) {\n \n-    // place a delimiter in the list which separates blocks \n-    // that have been reported from those that have not\n-    Block delimiterBlock \u003d new Block();\n-    BlockInfo delimiter \u003d new BlockInfoContiguous(delimiterBlock,\n-        (short) 1);\n-    AddBlockResult result \u003d storageInfo.addBlock(delimiter, delimiterBlock);\n-    assert result \u003d\u003d AddBlockResult.ADDED \n-        : \"Delimiting block cannot be present in the node\";\n-    int headIndex \u003d 0; //currently the delimiter is in the head of the list\n-    int curIndex;\n+    assert replica !\u003d null;\n+    assert storedBlock !\u003d null;\n \n-    if (newReport \u003d\u003d null) {\n-      newReport \u003d BlockListAsLongs.EMPTY;\n+    DatanodeDescriptor dn \u003d storageInfo.getDatanodeDescriptor();\n+    BlockUCState ucState \u003d storedBlock.getBlockUCState();\n+\n+    // Block is on the NN\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"In memory blockUCState \u003d \" + ucState);\n     }\n-    // scan the report and process newly reported blocks\n-    for (BlockReportReplica iblk : newReport) {\n-      ReplicaState iState \u003d iblk.getState();\n-      BlockInfo storedBlock \u003d processReportedBlock(storageInfo,\n-          iblk, iState, toAdd, toInvalidate, toCorrupt, toUC);\n \n-      // move block to the head of the list\n-      if (storedBlock !\u003d null \u0026\u0026\n-          (curIndex \u003d storedBlock.findStorageInfo(storageInfo)) \u003e\u003d 0) {\n-        headIndex \u003d storageInfo.moveBlockToHead(storedBlock, curIndex, headIndex);\n+    // Ignore replicas already scheduled to be removed from the DN\n+    if (invalidateBlocks.contains(dn, replica)) {\n+      return;\n+    }\n+\n+    BlockToMarkCorrupt c \u003d checkReplicaCorrupt(replica, reportedState,\n+                                               storedBlock, ucState, dn);\n+    if (c !\u003d null) {\n+      if (shouldPostponeBlocksFromFuture) {\n+        // If the block is an out-of-date generation stamp or state,\n+        // but we\u0027re the standby, we shouldn\u0027t treat it as corrupt,\n+        // but instead just queue it for later processing.\n+        // TODO: Pretty confident this should be s/storedBlock/block below,\n+        // since we should be postponing the info of the reported block, not\n+        // the stored block. See HDFS-6289 for more context.\n+        queueReportedBlock(storageInfo, storedBlock, reportedState,\n+            QUEUE_REASON_CORRUPT_STATE);\n+      } else {\n+        toCorrupt.add(c);\n       }\n+    } else if (isBlockUnderConstruction(storedBlock, ucState, reportedState)) {\n+      toUC.add(new StatefulBlockInfo(storedBlock, new Block(replica),\n+          reportedState));\n+    } else if (reportedState \u003d\u003d ReplicaState.FINALIZED \u0026\u0026\n+               (storedBlock.findStorageInfo(storageInfo) \u003d\u003d -1 ||\n+                corruptReplicas.isReplicaCorrupt(storedBlock, dn))) {\n+      // Add replica if appropriate. If the replica was previously corrupt\n+      // but now okay, it might need to be updated.\n+      toAdd.add(new BlockInfoToAdd(storedBlock, replica));\n     }\n-\n-    // collect blocks that have not been reported\n-    // all of them are next to the delimiter\n-    Iterator\u003cBlockInfo\u003e it \u003d\n-        storageInfo.new BlockIterator(delimiter.getNext(0));\n-    while (it.hasNext()) {\n-      toRemove.add(it.next());\n-    }\n-    storageInfo.removeBlock(delimiter);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void reportDiffSortedInner(\n      final DatanodeStorageInfo storageInfo,\n      final BlockReportReplica replica, final ReplicaState reportedState,\n      final BlockInfo storedBlock,\n      final Collection\u003cBlockInfoToAdd\u003e toAdd,\n      final Collection\u003cBlockToMarkCorrupt\u003e toCorrupt,\n      final Collection\u003cStatefulBlockInfo\u003e toUC) {\n\n    assert replica !\u003d null;\n    assert storedBlock !\u003d null;\n\n    DatanodeDescriptor dn \u003d storageInfo.getDatanodeDescriptor();\n    BlockUCState ucState \u003d storedBlock.getBlockUCState();\n\n    // Block is on the NN\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"In memory blockUCState \u003d \" + ucState);\n    }\n\n    // Ignore replicas already scheduled to be removed from the DN\n    if (invalidateBlocks.contains(dn, replica)) {\n      return;\n    }\n\n    BlockToMarkCorrupt c \u003d checkReplicaCorrupt(replica, reportedState,\n                                               storedBlock, ucState, dn);\n    if (c !\u003d null) {\n      if (shouldPostponeBlocksFromFuture) {\n        // If the block is an out-of-date generation stamp or state,\n        // but we\u0027re the standby, we shouldn\u0027t treat it as corrupt,\n        // but instead just queue it for later processing.\n        // TODO: Pretty confident this should be s/storedBlock/block below,\n        // since we should be postponing the info of the reported block, not\n        // the stored block. See HDFS-6289 for more context.\n        queueReportedBlock(storageInfo, storedBlock, reportedState,\n            QUEUE_REASON_CORRUPT_STATE);\n      } else {\n        toCorrupt.add(c);\n      }\n    } else if (isBlockUnderConstruction(storedBlock, ucState, reportedState)) {\n      toUC.add(new StatefulBlockInfo(storedBlock, new Block(replica),\n          reportedState));\n    } else if (reportedState \u003d\u003d ReplicaState.FINALIZED \u0026\u0026\n               (storedBlock.findStorageInfo(storageInfo) \u003d\u003d -1 ||\n                corruptReplicas.isReplicaCorrupt(storedBlock, dn))) {\n      // Add replica if appropriate. If the replica was previously corrupt\n      // but now okay, it might need to be updated.\n      toAdd.add(new BlockInfoToAdd(storedBlock, replica));\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "[storageInfo-DatanodeStorageInfo, newReport-BlockListAsLongs, toAdd-Collection\u003cBlockInfoToAdd\u003e, toRemove-Collection\u003cBlockInfo\u003e, toInvalidate-Collection\u003cBlock\u003e, toCorrupt-Collection\u003cBlockToMarkCorrupt\u003e, toUC-Collection\u003cStatefulBlockInfo\u003e]",
            "newValue": "[storageInfo-DatanodeStorageInfo(modifiers-final), replica-BlockReportReplica(modifiers-final), reportedState-ReplicaState(modifiers-final), storedBlock-BlockInfo(modifiers-final), toAdd-Collection\u003cBlockInfoToAdd\u003e(modifiers-final), toCorrupt-Collection\u003cBlockToMarkCorrupt\u003e(modifiers-final), toUC-Collection\u003cStatefulBlockInfo\u003e(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9260. Improve the performance and GC friendliness of NameNode startup and full block reports (Staffan Friberg via cmccabe)\n",
          "commitDate": "02/02/16 11:23 AM",
          "commitName": "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "31/01/16 11:54 PM",
          "commitNameOld": "e418bd1fb0568ce7ae22f588fea2dd9c95567383",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 1.48,
          "commitsBetweenForRepo": 16,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,50 @@\n-  private void reportDiff(DatanodeStorageInfo storageInfo, \n-      BlockListAsLongs newReport,\n-      Collection\u003cBlockInfoToAdd\u003e toAdd,     // add to DatanodeDescriptor\n-      Collection\u003cBlockInfo\u003e toRemove,       // remove from DatanodeDescriptor\n-      Collection\u003cBlock\u003e toInvalidate,       // should be removed from DN\n-      Collection\u003cBlockToMarkCorrupt\u003e toCorrupt, // add to corrupt replicas list\n-      Collection\u003cStatefulBlockInfo\u003e toUC) { // add to under-construction list\n+  private void reportDiffSortedInner(\n+      final DatanodeStorageInfo storageInfo,\n+      final BlockReportReplica replica, final ReplicaState reportedState,\n+      final BlockInfo storedBlock,\n+      final Collection\u003cBlockInfoToAdd\u003e toAdd,\n+      final Collection\u003cBlockToMarkCorrupt\u003e toCorrupt,\n+      final Collection\u003cStatefulBlockInfo\u003e toUC) {\n \n-    // place a delimiter in the list which separates blocks \n-    // that have been reported from those that have not\n-    Block delimiterBlock \u003d new Block();\n-    BlockInfo delimiter \u003d new BlockInfoContiguous(delimiterBlock,\n-        (short) 1);\n-    AddBlockResult result \u003d storageInfo.addBlock(delimiter, delimiterBlock);\n-    assert result \u003d\u003d AddBlockResult.ADDED \n-        : \"Delimiting block cannot be present in the node\";\n-    int headIndex \u003d 0; //currently the delimiter is in the head of the list\n-    int curIndex;\n+    assert replica !\u003d null;\n+    assert storedBlock !\u003d null;\n \n-    if (newReport \u003d\u003d null) {\n-      newReport \u003d BlockListAsLongs.EMPTY;\n+    DatanodeDescriptor dn \u003d storageInfo.getDatanodeDescriptor();\n+    BlockUCState ucState \u003d storedBlock.getBlockUCState();\n+\n+    // Block is on the NN\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"In memory blockUCState \u003d \" + ucState);\n     }\n-    // scan the report and process newly reported blocks\n-    for (BlockReportReplica iblk : newReport) {\n-      ReplicaState iState \u003d iblk.getState();\n-      BlockInfo storedBlock \u003d processReportedBlock(storageInfo,\n-          iblk, iState, toAdd, toInvalidate, toCorrupt, toUC);\n \n-      // move block to the head of the list\n-      if (storedBlock !\u003d null \u0026\u0026\n-          (curIndex \u003d storedBlock.findStorageInfo(storageInfo)) \u003e\u003d 0) {\n-        headIndex \u003d storageInfo.moveBlockToHead(storedBlock, curIndex, headIndex);\n+    // Ignore replicas already scheduled to be removed from the DN\n+    if (invalidateBlocks.contains(dn, replica)) {\n+      return;\n+    }\n+\n+    BlockToMarkCorrupt c \u003d checkReplicaCorrupt(replica, reportedState,\n+                                               storedBlock, ucState, dn);\n+    if (c !\u003d null) {\n+      if (shouldPostponeBlocksFromFuture) {\n+        // If the block is an out-of-date generation stamp or state,\n+        // but we\u0027re the standby, we shouldn\u0027t treat it as corrupt,\n+        // but instead just queue it for later processing.\n+        // TODO: Pretty confident this should be s/storedBlock/block below,\n+        // since we should be postponing the info of the reported block, not\n+        // the stored block. See HDFS-6289 for more context.\n+        queueReportedBlock(storageInfo, storedBlock, reportedState,\n+            QUEUE_REASON_CORRUPT_STATE);\n+      } else {\n+        toCorrupt.add(c);\n       }\n+    } else if (isBlockUnderConstruction(storedBlock, ucState, reportedState)) {\n+      toUC.add(new StatefulBlockInfo(storedBlock, new Block(replica),\n+          reportedState));\n+    } else if (reportedState \u003d\u003d ReplicaState.FINALIZED \u0026\u0026\n+               (storedBlock.findStorageInfo(storageInfo) \u003d\u003d -1 ||\n+                corruptReplicas.isReplicaCorrupt(storedBlock, dn))) {\n+      // Add replica if appropriate. If the replica was previously corrupt\n+      // but now okay, it might need to be updated.\n+      toAdd.add(new BlockInfoToAdd(storedBlock, replica));\n     }\n-\n-    // collect blocks that have not been reported\n-    // all of them are next to the delimiter\n-    Iterator\u003cBlockInfo\u003e it \u003d\n-        storageInfo.new BlockIterator(delimiter.getNext(0));\n-    while (it.hasNext()) {\n-      toRemove.add(it.next());\n-    }\n-    storageInfo.removeBlock(delimiter);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void reportDiffSortedInner(\n      final DatanodeStorageInfo storageInfo,\n      final BlockReportReplica replica, final ReplicaState reportedState,\n      final BlockInfo storedBlock,\n      final Collection\u003cBlockInfoToAdd\u003e toAdd,\n      final Collection\u003cBlockToMarkCorrupt\u003e toCorrupt,\n      final Collection\u003cStatefulBlockInfo\u003e toUC) {\n\n    assert replica !\u003d null;\n    assert storedBlock !\u003d null;\n\n    DatanodeDescriptor dn \u003d storageInfo.getDatanodeDescriptor();\n    BlockUCState ucState \u003d storedBlock.getBlockUCState();\n\n    // Block is on the NN\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"In memory blockUCState \u003d \" + ucState);\n    }\n\n    // Ignore replicas already scheduled to be removed from the DN\n    if (invalidateBlocks.contains(dn, replica)) {\n      return;\n    }\n\n    BlockToMarkCorrupt c \u003d checkReplicaCorrupt(replica, reportedState,\n                                               storedBlock, ucState, dn);\n    if (c !\u003d null) {\n      if (shouldPostponeBlocksFromFuture) {\n        // If the block is an out-of-date generation stamp or state,\n        // but we\u0027re the standby, we shouldn\u0027t treat it as corrupt,\n        // but instead just queue it for later processing.\n        // TODO: Pretty confident this should be s/storedBlock/block below,\n        // since we should be postponing the info of the reported block, not\n        // the stored block. See HDFS-6289 for more context.\n        queueReportedBlock(storageInfo, storedBlock, reportedState,\n            QUEUE_REASON_CORRUPT_STATE);\n      } else {\n        toCorrupt.add(c);\n      }\n    } else if (isBlockUnderConstruction(storedBlock, ucState, reportedState)) {\n      toUC.add(new StatefulBlockInfo(storedBlock, new Block(replica),\n          reportedState));\n    } else if (reportedState \u003d\u003d ReplicaState.FINALIZED \u0026\u0026\n               (storedBlock.findStorageInfo(storageInfo) \u003d\u003d -1 ||\n                corruptReplicas.isReplicaCorrupt(storedBlock, dn))) {\n      // Add replica if appropriate. If the replica was previously corrupt\n      // but now okay, it might need to be updated.\n      toAdd.add(new BlockInfoToAdd(storedBlock, replica));\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparametermetachange",
          "commitMessage": "HDFS-9260. Improve the performance and GC friendliness of NameNode startup and full block reports (Staffan Friberg via cmccabe)\n",
          "commitDate": "02/02/16 11:23 AM",
          "commitName": "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a",
          "commitAuthor": "Colin Patrick Mccabe",
          "commitDateOld": "31/01/16 11:54 PM",
          "commitNameOld": "e418bd1fb0568ce7ae22f588fea2dd9c95567383",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 1.48,
          "commitsBetweenForRepo": 16,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,50 @@\n-  private void reportDiff(DatanodeStorageInfo storageInfo, \n-      BlockListAsLongs newReport,\n-      Collection\u003cBlockInfoToAdd\u003e toAdd,     // add to DatanodeDescriptor\n-      Collection\u003cBlockInfo\u003e toRemove,       // remove from DatanodeDescriptor\n-      Collection\u003cBlock\u003e toInvalidate,       // should be removed from DN\n-      Collection\u003cBlockToMarkCorrupt\u003e toCorrupt, // add to corrupt replicas list\n-      Collection\u003cStatefulBlockInfo\u003e toUC) { // add to under-construction list\n+  private void reportDiffSortedInner(\n+      final DatanodeStorageInfo storageInfo,\n+      final BlockReportReplica replica, final ReplicaState reportedState,\n+      final BlockInfo storedBlock,\n+      final Collection\u003cBlockInfoToAdd\u003e toAdd,\n+      final Collection\u003cBlockToMarkCorrupt\u003e toCorrupt,\n+      final Collection\u003cStatefulBlockInfo\u003e toUC) {\n \n-    // place a delimiter in the list which separates blocks \n-    // that have been reported from those that have not\n-    Block delimiterBlock \u003d new Block();\n-    BlockInfo delimiter \u003d new BlockInfoContiguous(delimiterBlock,\n-        (short) 1);\n-    AddBlockResult result \u003d storageInfo.addBlock(delimiter, delimiterBlock);\n-    assert result \u003d\u003d AddBlockResult.ADDED \n-        : \"Delimiting block cannot be present in the node\";\n-    int headIndex \u003d 0; //currently the delimiter is in the head of the list\n-    int curIndex;\n+    assert replica !\u003d null;\n+    assert storedBlock !\u003d null;\n \n-    if (newReport \u003d\u003d null) {\n-      newReport \u003d BlockListAsLongs.EMPTY;\n+    DatanodeDescriptor dn \u003d storageInfo.getDatanodeDescriptor();\n+    BlockUCState ucState \u003d storedBlock.getBlockUCState();\n+\n+    // Block is on the NN\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"In memory blockUCState \u003d \" + ucState);\n     }\n-    // scan the report and process newly reported blocks\n-    for (BlockReportReplica iblk : newReport) {\n-      ReplicaState iState \u003d iblk.getState();\n-      BlockInfo storedBlock \u003d processReportedBlock(storageInfo,\n-          iblk, iState, toAdd, toInvalidate, toCorrupt, toUC);\n \n-      // move block to the head of the list\n-      if (storedBlock !\u003d null \u0026\u0026\n-          (curIndex \u003d storedBlock.findStorageInfo(storageInfo)) \u003e\u003d 0) {\n-        headIndex \u003d storageInfo.moveBlockToHead(storedBlock, curIndex, headIndex);\n+    // Ignore replicas already scheduled to be removed from the DN\n+    if (invalidateBlocks.contains(dn, replica)) {\n+      return;\n+    }\n+\n+    BlockToMarkCorrupt c \u003d checkReplicaCorrupt(replica, reportedState,\n+                                               storedBlock, ucState, dn);\n+    if (c !\u003d null) {\n+      if (shouldPostponeBlocksFromFuture) {\n+        // If the block is an out-of-date generation stamp or state,\n+        // but we\u0027re the standby, we shouldn\u0027t treat it as corrupt,\n+        // but instead just queue it for later processing.\n+        // TODO: Pretty confident this should be s/storedBlock/block below,\n+        // since we should be postponing the info of the reported block, not\n+        // the stored block. See HDFS-6289 for more context.\n+        queueReportedBlock(storageInfo, storedBlock, reportedState,\n+            QUEUE_REASON_CORRUPT_STATE);\n+      } else {\n+        toCorrupt.add(c);\n       }\n+    } else if (isBlockUnderConstruction(storedBlock, ucState, reportedState)) {\n+      toUC.add(new StatefulBlockInfo(storedBlock, new Block(replica),\n+          reportedState));\n+    } else if (reportedState \u003d\u003d ReplicaState.FINALIZED \u0026\u0026\n+               (storedBlock.findStorageInfo(storageInfo) \u003d\u003d -1 ||\n+                corruptReplicas.isReplicaCorrupt(storedBlock, dn))) {\n+      // Add replica if appropriate. If the replica was previously corrupt\n+      // but now okay, it might need to be updated.\n+      toAdd.add(new BlockInfoToAdd(storedBlock, replica));\n     }\n-\n-    // collect blocks that have not been reported\n-    // all of them are next to the delimiter\n-    Iterator\u003cBlockInfo\u003e it \u003d\n-        storageInfo.new BlockIterator(delimiter.getNext(0));\n-    while (it.hasNext()) {\n-      toRemove.add(it.next());\n-    }\n-    storageInfo.removeBlock(delimiter);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void reportDiffSortedInner(\n      final DatanodeStorageInfo storageInfo,\n      final BlockReportReplica replica, final ReplicaState reportedState,\n      final BlockInfo storedBlock,\n      final Collection\u003cBlockInfoToAdd\u003e toAdd,\n      final Collection\u003cBlockToMarkCorrupt\u003e toCorrupt,\n      final Collection\u003cStatefulBlockInfo\u003e toUC) {\n\n    assert replica !\u003d null;\n    assert storedBlock !\u003d null;\n\n    DatanodeDescriptor dn \u003d storageInfo.getDatanodeDescriptor();\n    BlockUCState ucState \u003d storedBlock.getBlockUCState();\n\n    // Block is on the NN\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"In memory blockUCState \u003d \" + ucState);\n    }\n\n    // Ignore replicas already scheduled to be removed from the DN\n    if (invalidateBlocks.contains(dn, replica)) {\n      return;\n    }\n\n    BlockToMarkCorrupt c \u003d checkReplicaCorrupt(replica, reportedState,\n                                               storedBlock, ucState, dn);\n    if (c !\u003d null) {\n      if (shouldPostponeBlocksFromFuture) {\n        // If the block is an out-of-date generation stamp or state,\n        // but we\u0027re the standby, we shouldn\u0027t treat it as corrupt,\n        // but instead just queue it for later processing.\n        // TODO: Pretty confident this should be s/storedBlock/block below,\n        // since we should be postponing the info of the reported block, not\n        // the stored block. See HDFS-6289 for more context.\n        queueReportedBlock(storageInfo, storedBlock, reportedState,\n            QUEUE_REASON_CORRUPT_STATE);\n      } else {\n        toCorrupt.add(c);\n      }\n    } else if (isBlockUnderConstruction(storedBlock, ucState, reportedState)) {\n      toUC.add(new StatefulBlockInfo(storedBlock, new Block(replica),\n          reportedState));\n    } else if (reportedState \u003d\u003d ReplicaState.FINALIZED \u0026\u0026\n               (storedBlock.findStorageInfo(storageInfo) \u003d\u003d -1 ||\n                corruptReplicas.isReplicaCorrupt(storedBlock, dn))) {\n      // Add replica if appropriate. If the replica was previously corrupt\n      // but now okay, it might need to be updated.\n      toAdd.add(new BlockInfoToAdd(storedBlock, replica));\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "[storageInfo-DatanodeStorageInfo, newReport-BlockListAsLongs, toAdd-Collection\u003cBlockInfoToAdd\u003e, toRemove-Collection\u003cBlockInfo\u003e, toInvalidate-Collection\u003cBlock\u003e, toCorrupt-Collection\u003cBlockToMarkCorrupt\u003e, toUC-Collection\u003cStatefulBlockInfo\u003e]",
            "newValue": "[storageInfo-DatanodeStorageInfo(modifiers-final), replica-BlockReportReplica(modifiers-final), reportedState-ReplicaState(modifiers-final), storedBlock-BlockInfo(modifiers-final), toAdd-Collection\u003cBlockInfoToAdd\u003e(modifiers-final), toCorrupt-Collection\u003cBlockToMarkCorrupt\u003e(modifiers-final), toUC-Collection\u003cStatefulBlockInfo\u003e(modifiers-final)]"
          }
        }
      ]
    }
  }
}