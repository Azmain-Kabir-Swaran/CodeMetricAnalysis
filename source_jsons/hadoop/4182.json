{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "StripedBlockUtil.java",
  "functionName": "getInternalBlockLength",
  "functionId": "getInternalBlockLength___dataSize-long__cellSize-int__numDataBlocks-int__idxInBlockGroup-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/util/StripedBlockUtil.java",
  "functionStartLine": 210,
  "functionEndLine": 229,
  "numCommitsSeen": 25,
  "timeTaken": 1101,
  "changeHistory": [
    "3c18a53cbd2efabb2ad108d63a0b0b558424115f"
  ],
  "changeHistoryShort": {
    "3c18a53cbd2efabb2ad108d63a0b0b558424115f": "Ymultichange(Yparameterchange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "3c18a53cbd2efabb2ad108d63a0b0b558424115f": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-9719. Refactoring ErasureCodingWorker into smaller reusable constructs. Contributed by Kai Zheng.\n",
      "commitDate": "06/04/16 10:50 PM",
      "commitName": "3c18a53cbd2efabb2ad108d63a0b0b558424115f",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9719. Refactoring ErasureCodingWorker into smaller reusable constructs. Contributed by Kai Zheng.\n",
          "commitDate": "06/04/16 10:50 PM",
          "commitName": "3c18a53cbd2efabb2ad108d63a0b0b558424115f",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "26/03/16 7:58 PM",
          "commitNameOld": "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 11.12,
          "commitsBetweenForRepo": 82,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,20 @@\n   public static long getInternalBlockLength(long dataSize,\n-      int cellSize, int numDataBlocks, int i) {\n+      int cellSize, int numDataBlocks, int idxInBlockGroup) {\n     Preconditions.checkArgument(dataSize \u003e\u003d 0);\n     Preconditions.checkArgument(cellSize \u003e 0);\n     Preconditions.checkArgument(numDataBlocks \u003e 0);\n-    Preconditions.checkArgument(i \u003e\u003d 0);\n+    Preconditions.checkArgument(idxInBlockGroup \u003e\u003d 0);\n     // Size of each stripe (only counting data blocks)\n     final int stripeSize \u003d cellSize * numDataBlocks;\n     // If block group ends at stripe boundary, each internal block has an equal\n     // share of the group\n     final int lastStripeDataLen \u003d (int)(dataSize % stripeSize);\n     if (lastStripeDataLen \u003d\u003d 0) {\n       return dataSize / numDataBlocks;\n     }\n \n     final int numStripes \u003d (int) ((dataSize - 1) / stripeSize + 1);\n     return (numStripes - 1L)*cellSize\n-        + lastCellSize(lastStripeDataLen, cellSize, numDataBlocks, i);\n+        + lastCellSize(lastStripeDataLen, cellSize,\n+        numDataBlocks, idxInBlockGroup);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static long getInternalBlockLength(long dataSize,\n      int cellSize, int numDataBlocks, int idxInBlockGroup) {\n    Preconditions.checkArgument(dataSize \u003e\u003d 0);\n    Preconditions.checkArgument(cellSize \u003e 0);\n    Preconditions.checkArgument(numDataBlocks \u003e 0);\n    Preconditions.checkArgument(idxInBlockGroup \u003e\u003d 0);\n    // Size of each stripe (only counting data blocks)\n    final int stripeSize \u003d cellSize * numDataBlocks;\n    // If block group ends at stripe boundary, each internal block has an equal\n    // share of the group\n    final int lastStripeDataLen \u003d (int)(dataSize % stripeSize);\n    if (lastStripeDataLen \u003d\u003d 0) {\n      return dataSize / numDataBlocks;\n    }\n\n    final int numStripes \u003d (int) ((dataSize - 1) / stripeSize + 1);\n    return (numStripes - 1L)*cellSize\n        + lastCellSize(lastStripeDataLen, cellSize,\n        numDataBlocks, idxInBlockGroup);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/util/StripedBlockUtil.java",
          "extendedDetails": {
            "oldValue": "[dataSize-long, cellSize-int, numDataBlocks-int, i-int]",
            "newValue": "[dataSize-long, cellSize-int, numDataBlocks-int, idxInBlockGroup-int]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9719. Refactoring ErasureCodingWorker into smaller reusable constructs. Contributed by Kai Zheng.\n",
          "commitDate": "06/04/16 10:50 PM",
          "commitName": "3c18a53cbd2efabb2ad108d63a0b0b558424115f",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "26/03/16 7:58 PM",
          "commitNameOld": "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 11.12,
          "commitsBetweenForRepo": 82,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,20 @@\n   public static long getInternalBlockLength(long dataSize,\n-      int cellSize, int numDataBlocks, int i) {\n+      int cellSize, int numDataBlocks, int idxInBlockGroup) {\n     Preconditions.checkArgument(dataSize \u003e\u003d 0);\n     Preconditions.checkArgument(cellSize \u003e 0);\n     Preconditions.checkArgument(numDataBlocks \u003e 0);\n-    Preconditions.checkArgument(i \u003e\u003d 0);\n+    Preconditions.checkArgument(idxInBlockGroup \u003e\u003d 0);\n     // Size of each stripe (only counting data blocks)\n     final int stripeSize \u003d cellSize * numDataBlocks;\n     // If block group ends at stripe boundary, each internal block has an equal\n     // share of the group\n     final int lastStripeDataLen \u003d (int)(dataSize % stripeSize);\n     if (lastStripeDataLen \u003d\u003d 0) {\n       return dataSize / numDataBlocks;\n     }\n \n     final int numStripes \u003d (int) ((dataSize - 1) / stripeSize + 1);\n     return (numStripes - 1L)*cellSize\n-        + lastCellSize(lastStripeDataLen, cellSize, numDataBlocks, i);\n+        + lastCellSize(lastStripeDataLen, cellSize,\n+        numDataBlocks, idxInBlockGroup);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static long getInternalBlockLength(long dataSize,\n      int cellSize, int numDataBlocks, int idxInBlockGroup) {\n    Preconditions.checkArgument(dataSize \u003e\u003d 0);\n    Preconditions.checkArgument(cellSize \u003e 0);\n    Preconditions.checkArgument(numDataBlocks \u003e 0);\n    Preconditions.checkArgument(idxInBlockGroup \u003e\u003d 0);\n    // Size of each stripe (only counting data blocks)\n    final int stripeSize \u003d cellSize * numDataBlocks;\n    // If block group ends at stripe boundary, each internal block has an equal\n    // share of the group\n    final int lastStripeDataLen \u003d (int)(dataSize % stripeSize);\n    if (lastStripeDataLen \u003d\u003d 0) {\n      return dataSize / numDataBlocks;\n    }\n\n    final int numStripes \u003d (int) ((dataSize - 1) / stripeSize + 1);\n    return (numStripes - 1L)*cellSize\n        + lastCellSize(lastStripeDataLen, cellSize,\n        numDataBlocks, idxInBlockGroup);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/util/StripedBlockUtil.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}