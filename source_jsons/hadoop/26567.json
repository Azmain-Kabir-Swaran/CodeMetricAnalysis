{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "TaskAttemptImpl.java",
  "functionName": "createTaskAttemptUnsuccessfulCompletionEvent",
  "functionId": "createTaskAttemptUnsuccessfulCompletionEvent___taskAttempt-TaskAttemptImpl__attemptState-TaskAttemptStateInternal",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
  "functionStartLine": 1686,
  "functionEndLine": 1705,
  "numCommitsSeen": 153,
  "timeTaken": 9076,
  "changeHistory": [
    "092fead5d9875fb3760206bcdd76cdafec5e9481",
    "cb78a65a152a4f576a3255df3676c3b788c84eb5",
    "979fb054f8e7141116718645d19ec7ba00455a63",
    "022f7b4a25c73b8c43985e8d1bac717b96373ac6",
    "264d3b7dd0c81fe02baaa09b6e3aaad5ee6d191a",
    "94bf0dacbaa54ead5af98b6d62ae1713c579a16b",
    "13e4562924a6cb3d16c262e0f595b2ffbf9e0546",
    "a26b1672a85e97bea973cfcc7eab22b4cca01448",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "092fead5d9875fb3760206bcdd76cdafec5e9481": "Ybodychange",
    "cb78a65a152a4f576a3255df3676c3b788c84eb5": "Ybodychange",
    "979fb054f8e7141116718645d19ec7ba00455a63": "Ybodychange",
    "022f7b4a25c73b8c43985e8d1bac717b96373ac6": "Yparameterchange",
    "264d3b7dd0c81fe02baaa09b6e3aaad5ee6d191a": "Ybodychange",
    "94bf0dacbaa54ead5af98b6d62ae1713c579a16b": "Ybodychange",
    "13e4562924a6cb3d16c262e0f595b2ffbf9e0546": "Ybodychange",
    "a26b1672a85e97bea973cfcc7eab22b4cca01448": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "092fead5d9875fb3760206bcdd76cdafec5e9481": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5792. Adopt the id prefix for YARN, MR, and DS entities. Contributed by Varun Saxena.\n",
      "commitDate": "29/08/17 10:59 PM",
      "commitName": "092fead5d9875fb3760206bcdd76cdafec5e9481",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "02/04/17 9:06 PM",
      "commitNameOld": "845529b3ab338e759665a687eb525fb2cccde7bf",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 149.08,
      "commitsBetweenForRepo": 858,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n       createTaskAttemptUnsuccessfulCompletionEvent(TaskAttemptImpl taskAttempt,\n           TaskAttemptStateInternal attemptState) {\n     TaskAttemptUnsuccessfulCompletionEvent tauce \u003d\n         new TaskAttemptUnsuccessfulCompletionEvent(\n             TypeConverter.fromYarn(taskAttempt.attemptId),\n             TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId()\n                 .getTaskType()), attemptState.toString(),\n             taskAttempt.finishTime,\n             taskAttempt.container \u003d\u003d null ? \"UNKNOWN\"\n                 : taskAttempt.container.getNodeId().getHost(),\n             taskAttempt.container \u003d\u003d null ? -1 \n                 : taskAttempt.container.getNodeId().getPort(),    \n             taskAttempt.nodeRackName \u003d\u003d null ? \"UNKNOWN\" \n                 : taskAttempt.nodeRackName,\n             StringUtils.join(\n                 LINE_SEPARATOR, taskAttempt.getDiagnostics()),\n                 taskAttempt.getCounters(), taskAttempt\n-                .getProgressSplitBlock().burst());\n+                .getProgressSplitBlock().burst(), taskAttempt.launchTime);\n     return tauce;\n   }\n\\ No newline at end of file\n",
      "actualSource": "      createTaskAttemptUnsuccessfulCompletionEvent(TaskAttemptImpl taskAttempt,\n          TaskAttemptStateInternal attemptState) {\n    TaskAttemptUnsuccessfulCompletionEvent tauce \u003d\n        new TaskAttemptUnsuccessfulCompletionEvent(\n            TypeConverter.fromYarn(taskAttempt.attemptId),\n            TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId()\n                .getTaskType()), attemptState.toString(),\n            taskAttempt.finishTime,\n            taskAttempt.container \u003d\u003d null ? \"UNKNOWN\"\n                : taskAttempt.container.getNodeId().getHost(),\n            taskAttempt.container \u003d\u003d null ? -1 \n                : taskAttempt.container.getNodeId().getPort(),    \n            taskAttempt.nodeRackName \u003d\u003d null ? \"UNKNOWN\" \n                : taskAttempt.nodeRackName,\n            StringUtils.join(\n                LINE_SEPARATOR, taskAttempt.getDiagnostics()),\n                taskAttempt.getCounters(), taskAttempt\n                .getProgressSplitBlock().burst(), taskAttempt.launchTime);\n    return tauce;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "cb78a65a152a4f576a3255df3676c3b788c84eb5": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5152. Make MR App to simply pass through the container from RM instead of extracting and populating information itself to start any container. Contributed by Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1469544 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/04/13 1:13 PM",
      "commitName": "cb78a65a152a4f576a3255df3676c3b788c84eb5",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "11/04/13 12:28 PM",
      "commitNameOld": "e4c55e17fea55e2fcbef182bb2b0c4b22686f38c",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 7.03,
      "commitsBetweenForRepo": 35,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n       createTaskAttemptUnsuccessfulCompletionEvent(TaskAttemptImpl taskAttempt,\n           TaskAttemptStateInternal attemptState) {\n     TaskAttemptUnsuccessfulCompletionEvent tauce \u003d\n         new TaskAttemptUnsuccessfulCompletionEvent(\n             TypeConverter.fromYarn(taskAttempt.attemptId),\n             TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId()\n                 .getTaskType()), attemptState.toString(),\n             taskAttempt.finishTime,\n-            taskAttempt.containerNodeId \u003d\u003d null ? \"UNKNOWN\"\n-                : taskAttempt.containerNodeId.getHost(),\n-            taskAttempt.containerNodeId \u003d\u003d null ? -1 \n-                : taskAttempt.containerNodeId.getPort(),    \n+            taskAttempt.container \u003d\u003d null ? \"UNKNOWN\"\n+                : taskAttempt.container.getNodeId().getHost(),\n+            taskAttempt.container \u003d\u003d null ? -1 \n+                : taskAttempt.container.getNodeId().getPort(),    \n             taskAttempt.nodeRackName \u003d\u003d null ? \"UNKNOWN\" \n                 : taskAttempt.nodeRackName,\n             StringUtils.join(\n                 LINE_SEPARATOR, taskAttempt.getDiagnostics()),\n                 taskAttempt.getCounters(), taskAttempt\n                 .getProgressSplitBlock().burst());\n     return tauce;\n   }\n\\ No newline at end of file\n",
      "actualSource": "      createTaskAttemptUnsuccessfulCompletionEvent(TaskAttemptImpl taskAttempt,\n          TaskAttemptStateInternal attemptState) {\n    TaskAttemptUnsuccessfulCompletionEvent tauce \u003d\n        new TaskAttemptUnsuccessfulCompletionEvent(\n            TypeConverter.fromYarn(taskAttempt.attemptId),\n            TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId()\n                .getTaskType()), attemptState.toString(),\n            taskAttempt.finishTime,\n            taskAttempt.container \u003d\u003d null ? \"UNKNOWN\"\n                : taskAttempt.container.getNodeId().getHost(),\n            taskAttempt.container \u003d\u003d null ? -1 \n                : taskAttempt.container.getNodeId().getPort(),    \n            taskAttempt.nodeRackName \u003d\u003d null ? \"UNKNOWN\" \n                : taskAttempt.nodeRackName,\n            StringUtils.join(\n                LINE_SEPARATOR, taskAttempt.getDiagnostics()),\n                taskAttempt.getCounters(), taskAttempt\n                .getProgressSplitBlock().burst());\n    return tauce;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "979fb054f8e7141116718645d19ec7ba00455a63": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4693. Historyserver should provide counters for failed tasks. Contributed by Xuan Gong.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1450956 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/02/13 1:03 PM",
      "commitName": "979fb054f8e7141116718645d19ec7ba00455a63",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "21/02/13 3:56 AM",
      "commitNameOld": "0b73dde6ce865ff94b483558ff0701de9932e211",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 6.38,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,20 @@\n       createTaskAttemptUnsuccessfulCompletionEvent(TaskAttemptImpl taskAttempt,\n           TaskAttemptStateInternal attemptState) {\n     TaskAttemptUnsuccessfulCompletionEvent tauce \u003d\n         new TaskAttemptUnsuccessfulCompletionEvent(\n             TypeConverter.fromYarn(taskAttempt.attemptId),\n             TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId()\n                 .getTaskType()), attemptState.toString(),\n             taskAttempt.finishTime,\n             taskAttempt.containerNodeId \u003d\u003d null ? \"UNKNOWN\"\n                 : taskAttempt.containerNodeId.getHost(),\n             taskAttempt.containerNodeId \u003d\u003d null ? -1 \n                 : taskAttempt.containerNodeId.getPort(),    \n             taskAttempt.nodeRackName \u003d\u003d null ? \"UNKNOWN\" \n                 : taskAttempt.nodeRackName,\n             StringUtils.join(\n-                LINE_SEPARATOR, taskAttempt.getDiagnostics()), taskAttempt\n+                LINE_SEPARATOR, taskAttempt.getDiagnostics()),\n+                taskAttempt.getCounters(), taskAttempt\n                 .getProgressSplitBlock().burst());\n     return tauce;\n   }\n\\ No newline at end of file\n",
      "actualSource": "      createTaskAttemptUnsuccessfulCompletionEvent(TaskAttemptImpl taskAttempt,\n          TaskAttemptStateInternal attemptState) {\n    TaskAttemptUnsuccessfulCompletionEvent tauce \u003d\n        new TaskAttemptUnsuccessfulCompletionEvent(\n            TypeConverter.fromYarn(taskAttempt.attemptId),\n            TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId()\n                .getTaskType()), attemptState.toString(),\n            taskAttempt.finishTime,\n            taskAttempt.containerNodeId \u003d\u003d null ? \"UNKNOWN\"\n                : taskAttempt.containerNodeId.getHost(),\n            taskAttempt.containerNodeId \u003d\u003d null ? -1 \n                : taskAttempt.containerNodeId.getPort(),    \n            taskAttempt.nodeRackName \u003d\u003d null ? \"UNKNOWN\" \n                : taskAttempt.nodeRackName,\n            StringUtils.join(\n                LINE_SEPARATOR, taskAttempt.getDiagnostics()),\n                taskAttempt.getCounters(), taskAttempt\n                .getProgressSplitBlock().burst());\n    return tauce;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "022f7b4a25c73b8c43985e8d1bac717b96373ac6": {
      "type": "Yparameterchange",
      "commitMessage": "MAPREDUCE-4596. Split StateMachine state from states seen by MRClientProtocol for Job, Task and TaskAttempt. Contributed by Siddarth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1399976 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/10/12 10:57 PM",
      "commitName": "022f7b4a25c73b8c43985e8d1bac717b96373ac6",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "08/10/12 1:50 PM",
      "commitNameOld": "49b20c2ed1be55c90a057acea71b55a28a3f69fb",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 10.38,
      "commitsBetweenForRepo": 75,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n       createTaskAttemptUnsuccessfulCompletionEvent(TaskAttemptImpl taskAttempt,\n-          TaskAttemptState attemptState) {\n+          TaskAttemptStateInternal attemptState) {\n     TaskAttemptUnsuccessfulCompletionEvent tauce \u003d\n         new TaskAttemptUnsuccessfulCompletionEvent(\n             TypeConverter.fromYarn(taskAttempt.attemptId),\n             TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId()\n                 .getTaskType()), attemptState.toString(),\n             taskAttempt.finishTime,\n             taskAttempt.containerNodeId \u003d\u003d null ? \"UNKNOWN\"\n                 : taskAttempt.containerNodeId.getHost(),\n             taskAttempt.containerNodeId \u003d\u003d null ? -1 \n                 : taskAttempt.containerNodeId.getPort(),    \n             taskAttempt.nodeRackName \u003d\u003d null ? \"UNKNOWN\" \n                 : taskAttempt.nodeRackName,\n             StringUtils.join(\n                 LINE_SEPARATOR, taskAttempt.getDiagnostics()), taskAttempt\n                 .getProgressSplitBlock().burst());\n     return tauce;\n   }\n\\ No newline at end of file\n",
      "actualSource": "      createTaskAttemptUnsuccessfulCompletionEvent(TaskAttemptImpl taskAttempt,\n          TaskAttemptStateInternal attemptState) {\n    TaskAttemptUnsuccessfulCompletionEvent tauce \u003d\n        new TaskAttemptUnsuccessfulCompletionEvent(\n            TypeConverter.fromYarn(taskAttempt.attemptId),\n            TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId()\n                .getTaskType()), attemptState.toString(),\n            taskAttempt.finishTime,\n            taskAttempt.containerNodeId \u003d\u003d null ? \"UNKNOWN\"\n                : taskAttempt.containerNodeId.getHost(),\n            taskAttempt.containerNodeId \u003d\u003d null ? -1 \n                : taskAttempt.containerNodeId.getPort(),    \n            taskAttempt.nodeRackName \u003d\u003d null ? \"UNKNOWN\" \n                : taskAttempt.nodeRackName,\n            StringUtils.join(\n                LINE_SEPARATOR, taskAttempt.getDiagnostics()), taskAttempt\n                .getProgressSplitBlock().burst());\n    return tauce;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {
        "oldValue": "[taskAttempt-TaskAttemptImpl, attemptState-TaskAttemptState]",
        "newValue": "[taskAttempt-TaskAttemptImpl, attemptState-TaskAttemptStateInternal]"
      }
    },
    "264d3b7dd0c81fe02baaa09b6e3aaad5ee6d191a": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3349. Log rack-name in JobHistory for unsuccessful tasks. (Devaraj K and Amar Kamat via amarrk)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1221578 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/12/11 6:58 PM",
      "commitName": "264d3b7dd0c81fe02baaa09b6e3aaad5ee6d191a",
      "commitAuthor": "Amar Kamat",
      "commitDateOld": "30/11/11 12:43 AM",
      "commitNameOld": "94bf0dacbaa54ead5af98b6d62ae1713c579a16b",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 20.76,
      "commitsBetweenForRepo": 135,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,19 @@\n       createTaskAttemptUnsuccessfulCompletionEvent(TaskAttemptImpl taskAttempt,\n           TaskAttemptState attemptState) {\n     TaskAttemptUnsuccessfulCompletionEvent tauce \u003d\n         new TaskAttemptUnsuccessfulCompletionEvent(\n             TypeConverter.fromYarn(taskAttempt.attemptId),\n             TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId()\n                 .getTaskType()), attemptState.toString(),\n             taskAttempt.finishTime,\n             taskAttempt.containerNodeId \u003d\u003d null ? \"UNKNOWN\"\n                 : taskAttempt.containerNodeId.getHost(),\n             taskAttempt.containerNodeId \u003d\u003d null ? -1 \n                 : taskAttempt.containerNodeId.getPort(),    \n+            taskAttempt.nodeRackName \u003d\u003d null ? \"UNKNOWN\" \n+                : taskAttempt.nodeRackName,\n             StringUtils.join(\n                 LINE_SEPARATOR, taskAttempt.getDiagnostics()), taskAttempt\n                 .getProgressSplitBlock().burst());\n     return tauce;\n   }\n\\ No newline at end of file\n",
      "actualSource": "      createTaskAttemptUnsuccessfulCompletionEvent(TaskAttemptImpl taskAttempt,\n          TaskAttemptState attemptState) {\n    TaskAttemptUnsuccessfulCompletionEvent tauce \u003d\n        new TaskAttemptUnsuccessfulCompletionEvent(\n            TypeConverter.fromYarn(taskAttempt.attemptId),\n            TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId()\n                .getTaskType()), attemptState.toString(),\n            taskAttempt.finishTime,\n            taskAttempt.containerNodeId \u003d\u003d null ? \"UNKNOWN\"\n                : taskAttempt.containerNodeId.getHost(),\n            taskAttempt.containerNodeId \u003d\u003d null ? -1 \n                : taskAttempt.containerNodeId.getPort(),    \n            taskAttempt.nodeRackName \u003d\u003d null ? \"UNKNOWN\" \n                : taskAttempt.nodeRackName,\n            StringUtils.join(\n                LINE_SEPARATOR, taskAttempt.getDiagnostics()), taskAttempt\n                .getProgressSplitBlock().burst());\n    return tauce;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "94bf0dacbaa54ead5af98b6d62ae1713c579a16b": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3450. NM port info no longer available in JobHistory. (Siddharth Seth via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1208327 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/11/11 12:43 AM",
      "commitName": "94bf0dacbaa54ead5af98b6d62ae1713c579a16b",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "31/10/11 10:27 AM",
      "commitNameOld": "9db078212f5a37154925cc8872f9adaeca0ed371",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 29.64,
      "commitsBetweenForRepo": 165,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,17 @@\n       createTaskAttemptUnsuccessfulCompletionEvent(TaskAttemptImpl taskAttempt,\n           TaskAttemptState attemptState) {\n     TaskAttemptUnsuccessfulCompletionEvent tauce \u003d\n         new TaskAttemptUnsuccessfulCompletionEvent(\n             TypeConverter.fromYarn(taskAttempt.attemptId),\n             TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId()\n                 .getTaskType()), attemptState.toString(),\n             taskAttempt.finishTime,\n-            taskAttempt.containerMgrAddress \u003d\u003d null ? \"UNKNOWN\"\n-                : taskAttempt.containerMgrAddress, StringUtils.join(\n+            taskAttempt.containerNodeId \u003d\u003d null ? \"UNKNOWN\"\n+                : taskAttempt.containerNodeId.getHost(),\n+            taskAttempt.containerNodeId \u003d\u003d null ? -1 \n+                : taskAttempt.containerNodeId.getPort(),    \n+            StringUtils.join(\n                 LINE_SEPARATOR, taskAttempt.getDiagnostics()), taskAttempt\n                 .getProgressSplitBlock().burst());\n     return tauce;\n   }\n\\ No newline at end of file\n",
      "actualSource": "      createTaskAttemptUnsuccessfulCompletionEvent(TaskAttemptImpl taskAttempt,\n          TaskAttemptState attemptState) {\n    TaskAttemptUnsuccessfulCompletionEvent tauce \u003d\n        new TaskAttemptUnsuccessfulCompletionEvent(\n            TypeConverter.fromYarn(taskAttempt.attemptId),\n            TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId()\n                .getTaskType()), attemptState.toString(),\n            taskAttempt.finishTime,\n            taskAttempt.containerNodeId \u003d\u003d null ? \"UNKNOWN\"\n                : taskAttempt.containerNodeId.getHost(),\n            taskAttempt.containerNodeId \u003d\u003d null ? -1 \n                : taskAttempt.containerNodeId.getPort(),    \n            StringUtils.join(\n                LINE_SEPARATOR, taskAttempt.getDiagnostics()), taskAttempt\n                .getProgressSplitBlock().burst());\n    return tauce;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "13e4562924a6cb3d16c262e0f595b2ffbf9e0546": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3144. Augmented JobHistory with the information needed for serving aggregated logs. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1185976 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/10/11 10:21 PM",
      "commitName": "13e4562924a6cb3d16c262e0f595b2ffbf9e0546",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/10/11 6:22 PM",
      "commitNameOld": "c1d90772b6e38bb4e4be7ed75cb5d34f3048ad7b",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 1.17,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,14 @@\n-  private static TaskAttemptUnsuccessfulCompletionEvent createTaskAttemptUnsuccessfulCompletionEvent(\n-      TaskAttemptImpl taskAttempt, TaskAttemptState attemptState) {\n-    TaskAttemptUnsuccessfulCompletionEvent tauce \u003d new TaskAttemptUnsuccessfulCompletionEvent(\n-        TypeConverter.fromYarn(taskAttempt.attemptId),\n-        TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId().getTaskType()),\n-        attemptState.toString(), taskAttempt.finishTime,\n-        taskAttempt.nodeHostName \u003d\u003d null ? \"UNKNOWN\" : taskAttempt.nodeHostName,\n-        StringUtils.join(LINE_SEPARATOR, taskAttempt.getDiagnostics()),\n-        taskAttempt.getProgressSplitBlock().burst());\n+      createTaskAttemptUnsuccessfulCompletionEvent(TaskAttemptImpl taskAttempt,\n+          TaskAttemptState attemptState) {\n+    TaskAttemptUnsuccessfulCompletionEvent tauce \u003d\n+        new TaskAttemptUnsuccessfulCompletionEvent(\n+            TypeConverter.fromYarn(taskAttempt.attemptId),\n+            TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId()\n+                .getTaskType()), attemptState.toString(),\n+            taskAttempt.finishTime,\n+            taskAttempt.containerMgrAddress \u003d\u003d null ? \"UNKNOWN\"\n+                : taskAttempt.containerMgrAddress, StringUtils.join(\n+                LINE_SEPARATOR, taskAttempt.getDiagnostics()), taskAttempt\n+                .getProgressSplitBlock().burst());\n     return tauce;\n   }\n\\ No newline at end of file\n",
      "actualSource": "      createTaskAttemptUnsuccessfulCompletionEvent(TaskAttemptImpl taskAttempt,\n          TaskAttemptState attemptState) {\n    TaskAttemptUnsuccessfulCompletionEvent tauce \u003d\n        new TaskAttemptUnsuccessfulCompletionEvent(\n            TypeConverter.fromYarn(taskAttempt.attemptId),\n            TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId()\n                .getTaskType()), attemptState.toString(),\n            taskAttempt.finishTime,\n            taskAttempt.containerMgrAddress \u003d\u003d null ? \"UNKNOWN\"\n                : taskAttempt.containerMgrAddress, StringUtils.join(\n                LINE_SEPARATOR, taskAttempt.getDiagnostics()), taskAttempt\n                .getProgressSplitBlock().burst());\n    return tauce;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "a26b1672a85e97bea973cfcc7eab22b4cca01448": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3032. Fixed TaskAttemptImpl so that JobHistory can have error information about failed tasks. Contributed by Devaraj K.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1185247 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/10/11 8:17 AM",
      "commitName": "a26b1672a85e97bea973cfcc7eab22b4cca01448",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "12/10/11 4:12 PM",
      "commitNameOld": "277e520579a3452b95a5ffe2616d4f252d3c53fb",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 4.67,
      "commitsBetweenForRepo": 35,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n   private static TaskAttemptUnsuccessfulCompletionEvent createTaskAttemptUnsuccessfulCompletionEvent(\n       TaskAttemptImpl taskAttempt, TaskAttemptState attemptState) {\n     TaskAttemptUnsuccessfulCompletionEvent tauce \u003d new TaskAttemptUnsuccessfulCompletionEvent(\n         TypeConverter.fromYarn(taskAttempt.attemptId),\n         TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId().getTaskType()),\n         attemptState.toString(), taskAttempt.finishTime,\n         taskAttempt.nodeHostName \u003d\u003d null ? \"UNKNOWN\" : taskAttempt.nodeHostName,\n-        taskAttempt.reportedStatus.diagnosticInfo.toString(),\n+        StringUtils.join(LINE_SEPARATOR, taskAttempt.getDiagnostics()),\n         taskAttempt.getProgressSplitBlock().burst());\n     return tauce;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static TaskAttemptUnsuccessfulCompletionEvent createTaskAttemptUnsuccessfulCompletionEvent(\n      TaskAttemptImpl taskAttempt, TaskAttemptState attemptState) {\n    TaskAttemptUnsuccessfulCompletionEvent tauce \u003d new TaskAttemptUnsuccessfulCompletionEvent(\n        TypeConverter.fromYarn(taskAttempt.attemptId),\n        TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId().getTaskType()),\n        attemptState.toString(), taskAttempt.finishTime,\n        taskAttempt.nodeHostName \u003d\u003d null ? \"UNKNOWN\" : taskAttempt.nodeHostName,\n        StringUtils.join(LINE_SEPARATOR, taskAttempt.getDiagnostics()),\n        taskAttempt.getProgressSplitBlock().burst());\n    return tauce;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private static TaskAttemptUnsuccessfulCompletionEvent createTaskAttemptUnsuccessfulCompletionEvent(\n      TaskAttemptImpl taskAttempt, TaskAttemptState attemptState) {\n    TaskAttemptUnsuccessfulCompletionEvent tauce \u003d new TaskAttemptUnsuccessfulCompletionEvent(\n        TypeConverter.fromYarn(taskAttempt.attemptId),\n        TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId().getTaskType()),\n        attemptState.toString(), taskAttempt.finishTime,\n        taskAttempt.nodeHostName \u003d\u003d null ? \"UNKNOWN\" : taskAttempt.nodeHostName,\n        taskAttempt.reportedStatus.diagnosticInfo.toString(),\n        taskAttempt.getProgressSplitBlock().burst());\n    return tauce;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,11 @@\n+  private static TaskAttemptUnsuccessfulCompletionEvent createTaskAttemptUnsuccessfulCompletionEvent(\n+      TaskAttemptImpl taskAttempt, TaskAttemptState attemptState) {\n+    TaskAttemptUnsuccessfulCompletionEvent tauce \u003d new TaskAttemptUnsuccessfulCompletionEvent(\n+        TypeConverter.fromYarn(taskAttempt.attemptId),\n+        TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId().getTaskType()),\n+        attemptState.toString(), taskAttempt.finishTime,\n+        taskAttempt.nodeHostName \u003d\u003d null ? \"UNKNOWN\" : taskAttempt.nodeHostName,\n+        taskAttempt.reportedStatus.diagnosticInfo.toString(),\n+        taskAttempt.getProgressSplitBlock().burst());\n+    return tauce;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static TaskAttemptUnsuccessfulCompletionEvent createTaskAttemptUnsuccessfulCompletionEvent(\n      TaskAttemptImpl taskAttempt, TaskAttemptState attemptState) {\n    TaskAttemptUnsuccessfulCompletionEvent tauce \u003d new TaskAttemptUnsuccessfulCompletionEvent(\n        TypeConverter.fromYarn(taskAttempt.attemptId),\n        TypeConverter.fromYarn(taskAttempt.attemptId.getTaskId().getTaskType()),\n        attemptState.toString(), taskAttempt.finishTime,\n        taskAttempt.nodeHostName \u003d\u003d null ? \"UNKNOWN\" : taskAttempt.nodeHostName,\n        taskAttempt.reportedStatus.diagnosticInfo.toString(),\n        taskAttempt.getProgressSplitBlock().burst());\n    return tauce;\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java"
    }
  }
}