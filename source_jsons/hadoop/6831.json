{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImageSerialization.java",
  "functionName": "writeErasureCodingPolicy",
  "functionId": "writeErasureCodingPolicy___out-DataOutputStream__ecPolicy-ErasureCodingPolicy",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
  "functionStartLine": 757,
  "functionEndLine": 775,
  "numCommitsSeen": 62,
  "timeTaken": 2043,
  "changeHistory": [
    "08d996d3e9265efad737efad50cbc5b10a0202f8"
  ],
  "changeHistoryShort": {
    "08d996d3e9265efad737efad50cbc5b10a0202f8": "Yintroduced"
  },
  "changeHistoryDetails": {
    "08d996d3e9265efad737efad50cbc5b10a0202f8": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-12395. Support erasure coding policy operations in namenode edit log. Contributed by Sammi Chen\n",
      "commitDate": "14/09/17 6:43 PM",
      "commitName": "08d996d3e9265efad737efad50cbc5b10a0202f8",
      "commitAuthor": "Kai Zheng",
      "diff": "@@ -0,0 +1,19 @@\n+  public static void writeErasureCodingPolicy(DataOutputStream out,\n+      ErasureCodingPolicy ecPolicy) throws IOException {\n+    writeString(ecPolicy.getSchema().getCodecName(), out);\n+    writeInt(ecPolicy.getNumDataUnits(), out);\n+    writeInt(ecPolicy.getNumParityUnits(), out);\n+    writeInt(ecPolicy.getCellSize(), out);\n+\n+    Map\u003cString, String\u003e extraOptions \u003d ecPolicy.getSchema().getExtraOptions();\n+    if (extraOptions \u003d\u003d null || extraOptions.isEmpty()) {\n+      writeInt(0, out);\n+      return;\n+    }\n+\n+    writeInt(extraOptions.size(), out);\n+    for (Map.Entry\u003cString, String\u003e entry : extraOptions.entrySet()) {\n+      writeString(entry.getKey(), out);\n+      writeString(entry.getValue(), out);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static void writeErasureCodingPolicy(DataOutputStream out,\n      ErasureCodingPolicy ecPolicy) throws IOException {\n    writeString(ecPolicy.getSchema().getCodecName(), out);\n    writeInt(ecPolicy.getNumDataUnits(), out);\n    writeInt(ecPolicy.getNumParityUnits(), out);\n    writeInt(ecPolicy.getCellSize(), out);\n\n    Map\u003cString, String\u003e extraOptions \u003d ecPolicy.getSchema().getExtraOptions();\n    if (extraOptions \u003d\u003d null || extraOptions.isEmpty()) {\n      writeInt(0, out);\n      return;\n    }\n\n    writeInt(extraOptions.size(), out);\n    for (Map.Entry\u003cString, String\u003e entry : extraOptions.entrySet()) {\n      writeString(entry.getKey(), out);\n      writeString(entry.getValue(), out);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java"
    }
  }
}