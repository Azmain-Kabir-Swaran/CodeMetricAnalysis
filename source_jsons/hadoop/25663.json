{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JobHistoryEventHandler.java",
  "functionName": "serviceInit",
  "functionId": "serviceInit___conf-Configuration",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
  "functionStartLine": 163,
  "functionEndLine": 322,
  "numCommitsSeen": 88,
  "timeTaken": 11504,
  "changeHistory": [
    "83e60cd2db20f655e272958ef43b1b5a084ef3e3",
    "345e7624d58a058a1bad666bd1e5ce4b346a9056",
    "7dd385098c7a3046e6b049e70669d5b726de79c9",
    "4fa1afdb883dab8786d2fb5c72a195dd2e87d711",
    "0d02ab8729630ad3cfb4300702927333b1d349e3",
    "89e5c44f9e891a3579384c3fa3766937cd4970f1",
    "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5",
    "2ac87df578accb6e612f70ded76271cb5082ee10",
    "c298a9a845f89317eb9efad332e6657c56736a4d",
    "971e91c8c03a23e4613ed3f071b4f982ee5a1b63",
    "6b2f11b54bc679b0715fe66bd129e340e8c61c5c",
    "84bc2fe4021be32e0ff8ba395359337904149034",
    "0928502029ef141759008997335ea2cd836a7154",
    "a83fb61ac07c0468cbc7a38526e92683883dd932",
    "64e4fb983e022d8d3375a3e1b8facbf95f7ba403",
    "74697f231772a556884feaf1c986631d02a9ae4e",
    "fffdf661e30afd10331d2153ff052c141b7ebe4b",
    "fafe8cd28e726566509c679e19d7da622f29f90d",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "83e60cd2db20f655e272958ef43b1b5a084ef3e3": "Ybodychange",
    "345e7624d58a058a1bad666bd1e5ce4b346a9056": "Ybodychange",
    "7dd385098c7a3046e6b049e70669d5b726de79c9": "Ybodychange",
    "4fa1afdb883dab8786d2fb5c72a195dd2e87d711": "Ybodychange",
    "0d02ab8729630ad3cfb4300702927333b1d349e3": "Ybodychange",
    "89e5c44f9e891a3579384c3fa3766937cd4970f1": "Ybodychange",
    "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5": "Ybodychange",
    "2ac87df578accb6e612f70ded76271cb5082ee10": "Ybodychange",
    "c298a9a845f89317eb9efad332e6657c56736a4d": "Ybodychange",
    "971e91c8c03a23e4613ed3f071b4f982ee5a1b63": "Ybodychange",
    "6b2f11b54bc679b0715fe66bd129e340e8c61c5c": "Ybodychange",
    "84bc2fe4021be32e0ff8ba395359337904149034": "Ybodychange",
    "0928502029ef141759008997335ea2cd836a7154": "Ymultichange(Yrename,Ymodifierchange,Yexceptionschange,Ybodychange)",
    "a83fb61ac07c0468cbc7a38526e92683883dd932": "Ybodychange",
    "64e4fb983e022d8d3375a3e1b8facbf95f7ba403": "Ybodychange",
    "74697f231772a556884feaf1c986631d02a9ae4e": "Ybodychange",
    "fffdf661e30afd10331d2153ff052c141b7ebe4b": "Ybodychange",
    "fafe8cd28e726566509c679e19d7da622f29f90d": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "83e60cd2db20f655e272958ef43b1b5a084ef3e3": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-7042. Killed MR job data does not move to mapreduce.jobhistory.done-dir when ATS v2 is enabled. Contributed by Rohith Sharma K S.\n",
      "commitDate": "26/04/18 1:54 PM",
      "commitName": "83e60cd2db20f655e272958ef43b1b5a084ef3e3",
      "commitAuthor": "Sunil G",
      "commitDateOld": "04/04/18 3:08 PM",
      "commitNameOld": "345e7624d58a058a1bad666bd1e5ce4b346a9056",
      "commitAuthorOld": "Vrushali C",
      "daysBetweenCommits": 21.95,
      "commitsBetweenForRepo": 653,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,150 +1,160 @@\n   protected void serviceInit(Configuration conf) throws Exception {\n     String jobId \u003d\n       TypeConverter.fromYarn(context.getApplicationID()).toString();\n     \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n           jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnRuntimeException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, JobHistoryUtils.\n           getConfiguredHistoryIntermediateUserDoneDirPermissions(conf));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n \n     // TODO replace MR specific configurations on timeline service with getting\n     // configuration from RM through registerApplicationMaster() in\n     // ApplicationMasterProtocol with return value for timeline service\n     // configuration status: off, on_with_v1 or on_with_v2.\n     if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n         MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n       LOG.info(\"Emitting job history data to the timeline service is enabled\");\n       if (YarnConfiguration.timelineServiceEnabled(conf)) {\n         boolean timelineServiceV2Enabled \u003d\n             YarnConfiguration.timelineServiceV2Enabled(conf);\n         if(timelineServiceV2Enabled) {\n           timelineV2Client \u003d\n               ((MRAppMaster.RunningAppContext)context).getTimelineV2Client();\n           timelineV2Client.init(conf);\n         } else {\n           timelineClient \u003d\n               ((MRAppMaster.RunningAppContext) context).getTimelineClient();\n           timelineClient.init(conf);\n         }\n+        handleTimelineEvent \u003d true;\n         LOG.info(\"Timeline service is enabled; version: \" +\n             YarnConfiguration.getTimelineServiceVersion(conf));\n       } else {\n         LOG.info(\"Timeline service is not enabled\");\n       }\n     } else {\n       LOG.info(\"Emitting job history data to the timeline server is not \" +\n           \"enabled\");\n     }\n \n     // Flag for setting\n     String jhistFormat \u003d conf.get(JHAdminConfig.MR_HS_JHIST_FORMAT,\n         JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT);\n     if (jhistFormat.equals(\"json\")) {\n       jhistMode \u003d EventWriter.WriteMode.JSON;\n     } else if (jhistFormat.equals(\"binary\")) {\n       jhistMode \u003d EventWriter.WriteMode.BINARY;\n     } else {\n       LOG.warn(\"Unrecognized value \u0027\" + jhistFormat + \"\u0027 for property \" +\n           JHAdminConfig.MR_HS_JHIST_FORMAT + \".  Valid values are \" +\n           \"\u0027json\u0027 or \u0027binary\u0027.  Falling back to default value \u0027\" +\n           JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT + \"\u0027.\");\n     }\n-\n+    // initiate the atsEventDispatcher for timeline event\n+    // if timeline service is enabled.\n+    if (handleTimelineEvent) {\n+      atsEventDispatcher \u003d createDispatcher();\n+      EventHandler\u003cJobHistoryEvent\u003e timelineEventHandler \u003d\n+          new ForwardingEventHandler();\n+      atsEventDispatcher.register(EventType.class, timelineEventHandler);\n+      atsEventDispatcher.setDrainEventsOnStop();\n+      atsEventDispatcher.init(conf);\n+    }\n     super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnRuntimeException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, JobHistoryUtils.\n          getConfiguredHistoryIntermediateUserDoneDirPermissions(conf));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n\n    // TODO replace MR specific configurations on timeline service with getting\n    // configuration from RM through registerApplicationMaster() in\n    // ApplicationMasterProtocol with return value for timeline service\n    // configuration status: off, on_with_v1 or on_with_v2.\n    if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n        MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n      LOG.info(\"Emitting job history data to the timeline service is enabled\");\n      if (YarnConfiguration.timelineServiceEnabled(conf)) {\n        boolean timelineServiceV2Enabled \u003d\n            YarnConfiguration.timelineServiceV2Enabled(conf);\n        if(timelineServiceV2Enabled) {\n          timelineV2Client \u003d\n              ((MRAppMaster.RunningAppContext)context).getTimelineV2Client();\n          timelineV2Client.init(conf);\n        } else {\n          timelineClient \u003d\n              ((MRAppMaster.RunningAppContext) context).getTimelineClient();\n          timelineClient.init(conf);\n        }\n        handleTimelineEvent \u003d true;\n        LOG.info(\"Timeline service is enabled; version: \" +\n            YarnConfiguration.getTimelineServiceVersion(conf));\n      } else {\n        LOG.info(\"Timeline service is not enabled\");\n      }\n    } else {\n      LOG.info(\"Emitting job history data to the timeline server is not \" +\n          \"enabled\");\n    }\n\n    // Flag for setting\n    String jhistFormat \u003d conf.get(JHAdminConfig.MR_HS_JHIST_FORMAT,\n        JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT);\n    if (jhistFormat.equals(\"json\")) {\n      jhistMode \u003d EventWriter.WriteMode.JSON;\n    } else if (jhistFormat.equals(\"binary\")) {\n      jhistMode \u003d EventWriter.WriteMode.BINARY;\n    } else {\n      LOG.warn(\"Unrecognized value \u0027\" + jhistFormat + \"\u0027 for property \" +\n          JHAdminConfig.MR_HS_JHIST_FORMAT + \".  Valid values are \" +\n          \"\u0027json\u0027 or \u0027binary\u0027.  Falling back to default value \u0027\" +\n          JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT + \"\u0027.\");\n    }\n    // initiate the atsEventDispatcher for timeline event\n    // if timeline service is enabled.\n    if (handleTimelineEvent) {\n      atsEventDispatcher \u003d createDispatcher();\n      EventHandler\u003cJobHistoryEvent\u003e timelineEventHandler \u003d\n          new ForwardingEventHandler();\n      atsEventDispatcher.register(EventType.class, timelineEventHandler);\n      atsEventDispatcher.setDrainEventsOnStop();\n      atsEventDispatcher.init(conf);\n    }\n    super.serviceInit(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "345e7624d58a058a1bad666bd1e5ce4b346a9056": {
      "type": "Ybodychange",
      "commitMessage": "YARN-8073 TimelineClientImpl doesn\u0027t honor yarn.timeline-service.versions configuration. Contributed by Rohith Sharma K S\n",
      "commitDate": "04/04/18 3:08 PM",
      "commitName": "345e7624d58a058a1bad666bd1e5ce4b346a9056",
      "commitAuthor": "Vrushali C",
      "commitDateOld": "26/02/18 2:32 PM",
      "commitNameOld": "7dd385098c7a3046e6b049e70669d5b726de79c9",
      "commitAuthorOld": "Billie Rinaldi",
      "daysBetweenCommits": 36.98,
      "commitsBetweenForRepo": 386,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,150 +1,150 @@\n   protected void serviceInit(Configuration conf) throws Exception {\n     String jobId \u003d\n       TypeConverter.fromYarn(context.getApplicationID()).toString();\n     \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n           jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnRuntimeException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, JobHistoryUtils.\n           getConfiguredHistoryIntermediateUserDoneDirPermissions(conf));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n \n     // TODO replace MR specific configurations on timeline service with getting\n     // configuration from RM through registerApplicationMaster() in\n     // ApplicationMasterProtocol with return value for timeline service\n     // configuration status: off, on_with_v1 or on_with_v2.\n     if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n         MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n       LOG.info(\"Emitting job history data to the timeline service is enabled\");\n       if (YarnConfiguration.timelineServiceEnabled(conf)) {\n         boolean timelineServiceV2Enabled \u003d\n-            ((int) YarnConfiguration.getTimelineServiceVersion(conf) \u003d\u003d 2);\n+            YarnConfiguration.timelineServiceV2Enabled(conf);\n         if(timelineServiceV2Enabled) {\n           timelineV2Client \u003d\n               ((MRAppMaster.RunningAppContext)context).getTimelineV2Client();\n           timelineV2Client.init(conf);\n         } else {\n           timelineClient \u003d\n               ((MRAppMaster.RunningAppContext) context).getTimelineClient();\n           timelineClient.init(conf);\n         }\n         LOG.info(\"Timeline service is enabled; version: \" +\n             YarnConfiguration.getTimelineServiceVersion(conf));\n       } else {\n         LOG.info(\"Timeline service is not enabled\");\n       }\n     } else {\n       LOG.info(\"Emitting job history data to the timeline server is not \" +\n           \"enabled\");\n     }\n \n     // Flag for setting\n     String jhistFormat \u003d conf.get(JHAdminConfig.MR_HS_JHIST_FORMAT,\n         JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT);\n     if (jhistFormat.equals(\"json\")) {\n       jhistMode \u003d EventWriter.WriteMode.JSON;\n     } else if (jhistFormat.equals(\"binary\")) {\n       jhistMode \u003d EventWriter.WriteMode.BINARY;\n     } else {\n       LOG.warn(\"Unrecognized value \u0027\" + jhistFormat + \"\u0027 for property \" +\n           JHAdminConfig.MR_HS_JHIST_FORMAT + \".  Valid values are \" +\n           \"\u0027json\u0027 or \u0027binary\u0027.  Falling back to default value \u0027\" +\n           JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT + \"\u0027.\");\n     }\n \n     super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnRuntimeException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, JobHistoryUtils.\n          getConfiguredHistoryIntermediateUserDoneDirPermissions(conf));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n\n    // TODO replace MR specific configurations on timeline service with getting\n    // configuration from RM through registerApplicationMaster() in\n    // ApplicationMasterProtocol with return value for timeline service\n    // configuration status: off, on_with_v1 or on_with_v2.\n    if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n        MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n      LOG.info(\"Emitting job history data to the timeline service is enabled\");\n      if (YarnConfiguration.timelineServiceEnabled(conf)) {\n        boolean timelineServiceV2Enabled \u003d\n            YarnConfiguration.timelineServiceV2Enabled(conf);\n        if(timelineServiceV2Enabled) {\n          timelineV2Client \u003d\n              ((MRAppMaster.RunningAppContext)context).getTimelineV2Client();\n          timelineV2Client.init(conf);\n        } else {\n          timelineClient \u003d\n              ((MRAppMaster.RunningAppContext) context).getTimelineClient();\n          timelineClient.init(conf);\n        }\n        LOG.info(\"Timeline service is enabled; version: \" +\n            YarnConfiguration.getTimelineServiceVersion(conf));\n      } else {\n        LOG.info(\"Timeline service is not enabled\");\n      }\n    } else {\n      LOG.info(\"Emitting job history data to the timeline server is not \" +\n          \"enabled\");\n    }\n\n    // Flag for setting\n    String jhistFormat \u003d conf.get(JHAdminConfig.MR_HS_JHIST_FORMAT,\n        JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT);\n    if (jhistFormat.equals(\"json\")) {\n      jhistMode \u003d EventWriter.WriteMode.JSON;\n    } else if (jhistFormat.equals(\"binary\")) {\n      jhistMode \u003d EventWriter.WriteMode.BINARY;\n    } else {\n      LOG.warn(\"Unrecognized value \u0027\" + jhistFormat + \"\u0027 for property \" +\n          JHAdminConfig.MR_HS_JHIST_FORMAT + \".  Valid values are \" +\n          \"\u0027json\u0027 or \u0027binary\u0027.  Falling back to default value \u0027\" +\n          JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT + \"\u0027.\");\n    }\n\n    super.serviceInit(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "7dd385098c7a3046e6b049e70669d5b726de79c9": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-7010. Make Job History File Permissions configurable. Contributed by Gergely Nov√°k\n",
      "commitDate": "26/02/18 2:32 PM",
      "commitName": "7dd385098c7a3046e6b049e70669d5b726de79c9",
      "commitAuthor": "Billie Rinaldi",
      "commitDateOld": "02/10/17 8:14 PM",
      "commitNameOld": "453d48bdfbb67ed3e66c33c4aef239c3d7bdd3bc",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 146.8,
      "commitsBetweenForRepo": 984,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,150 +1,150 @@\n   protected void serviceInit(Configuration conf) throws Exception {\n     String jobId \u003d\n       TypeConverter.fromYarn(context.getApplicationID()).toString();\n     \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n           jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnRuntimeException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n-      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n-          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n+      mkdir(doneDirFS, doneDirPrefixPath, JobHistoryUtils.\n+          getConfiguredHistoryIntermediateUserDoneDirPermissions(conf));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n \n     // TODO replace MR specific configurations on timeline service with getting\n     // configuration from RM through registerApplicationMaster() in\n     // ApplicationMasterProtocol with return value for timeline service\n     // configuration status: off, on_with_v1 or on_with_v2.\n     if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n         MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n       LOG.info(\"Emitting job history data to the timeline service is enabled\");\n       if (YarnConfiguration.timelineServiceEnabled(conf)) {\n         boolean timelineServiceV2Enabled \u003d\n             ((int) YarnConfiguration.getTimelineServiceVersion(conf) \u003d\u003d 2);\n         if(timelineServiceV2Enabled) {\n           timelineV2Client \u003d\n               ((MRAppMaster.RunningAppContext)context).getTimelineV2Client();\n           timelineV2Client.init(conf);\n         } else {\n           timelineClient \u003d\n               ((MRAppMaster.RunningAppContext) context).getTimelineClient();\n           timelineClient.init(conf);\n         }\n         LOG.info(\"Timeline service is enabled; version: \" +\n             YarnConfiguration.getTimelineServiceVersion(conf));\n       } else {\n         LOG.info(\"Timeline service is not enabled\");\n       }\n     } else {\n       LOG.info(\"Emitting job history data to the timeline server is not \" +\n           \"enabled\");\n     }\n \n     // Flag for setting\n     String jhistFormat \u003d conf.get(JHAdminConfig.MR_HS_JHIST_FORMAT,\n         JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT);\n     if (jhistFormat.equals(\"json\")) {\n       jhistMode \u003d EventWriter.WriteMode.JSON;\n     } else if (jhistFormat.equals(\"binary\")) {\n       jhistMode \u003d EventWriter.WriteMode.BINARY;\n     } else {\n       LOG.warn(\"Unrecognized value \u0027\" + jhistFormat + \"\u0027 for property \" +\n           JHAdminConfig.MR_HS_JHIST_FORMAT + \".  Valid values are \" +\n           \"\u0027json\u0027 or \u0027binary\u0027.  Falling back to default value \u0027\" +\n           JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT + \"\u0027.\");\n     }\n \n     super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnRuntimeException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, JobHistoryUtils.\n          getConfiguredHistoryIntermediateUserDoneDirPermissions(conf));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n\n    // TODO replace MR specific configurations on timeline service with getting\n    // configuration from RM through registerApplicationMaster() in\n    // ApplicationMasterProtocol with return value for timeline service\n    // configuration status: off, on_with_v1 or on_with_v2.\n    if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n        MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n      LOG.info(\"Emitting job history data to the timeline service is enabled\");\n      if (YarnConfiguration.timelineServiceEnabled(conf)) {\n        boolean timelineServiceV2Enabled \u003d\n            ((int) YarnConfiguration.getTimelineServiceVersion(conf) \u003d\u003d 2);\n        if(timelineServiceV2Enabled) {\n          timelineV2Client \u003d\n              ((MRAppMaster.RunningAppContext)context).getTimelineV2Client();\n          timelineV2Client.init(conf);\n        } else {\n          timelineClient \u003d\n              ((MRAppMaster.RunningAppContext) context).getTimelineClient();\n          timelineClient.init(conf);\n        }\n        LOG.info(\"Timeline service is enabled; version: \" +\n            YarnConfiguration.getTimelineServiceVersion(conf));\n      } else {\n        LOG.info(\"Timeline service is not enabled\");\n      }\n    } else {\n      LOG.info(\"Emitting job history data to the timeline server is not \" +\n          \"enabled\");\n    }\n\n    // Flag for setting\n    String jhistFormat \u003d conf.get(JHAdminConfig.MR_HS_JHIST_FORMAT,\n        JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT);\n    if (jhistFormat.equals(\"json\")) {\n      jhistMode \u003d EventWriter.WriteMode.JSON;\n    } else if (jhistFormat.equals(\"binary\")) {\n      jhistMode \u003d EventWriter.WriteMode.BINARY;\n    } else {\n      LOG.warn(\"Unrecognized value \u0027\" + jhistFormat + \"\u0027 for property \" +\n          JHAdminConfig.MR_HS_JHIST_FORMAT + \".  Valid values are \" +\n          \"\u0027json\u0027 or \u0027binary\u0027.  Falling back to default value \u0027\" +\n          JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT + \"\u0027.\");\n    }\n\n    super.serviceInit(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "4fa1afdb883dab8786d2fb5c72a195dd2e87d711": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4675. Reorganize TimelineClient and TimelineClientImpl into separate classes for ATSv1.x and ATSv2. Contributed by Naganarasimha G R.\n",
      "commitDate": "16/02/17 11:41 AM",
      "commitName": "4fa1afdb883dab8786d2fb5c72a195dd2e87d711",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "15/11/16 10:57 AM",
      "commitNameOld": "5af572b6443715b7a741296c1bd520a1840f9a7c",
      "commitAuthorOld": "Mingliang Liu",
      "daysBetweenCommits": 93.03,
      "commitsBetweenForRepo": 475,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,145 +1,150 @@\n   protected void serviceInit(Configuration conf) throws Exception {\n     String jobId \u003d\n       TypeConverter.fromYarn(context.getApplicationID()).toString();\n     \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n           jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnRuntimeException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n \n     // TODO replace MR specific configurations on timeline service with getting\n     // configuration from RM through registerApplicationMaster() in\n     // ApplicationMasterProtocol with return value for timeline service\n     // configuration status: off, on_with_v1 or on_with_v2.\n     if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n         MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n       LOG.info(\"Emitting job history data to the timeline service is enabled\");\n       if (YarnConfiguration.timelineServiceEnabled(conf)) {\n-\n-        timelineClient \u003d\n-            ((MRAppMaster.RunningAppContext)context).getTimelineClient();\n-        timelineClient.init(conf);\n-        timelineServiceV2Enabled \u003d\n-            YarnConfiguration.timelineServiceV2Enabled(conf);\n+        boolean timelineServiceV2Enabled \u003d\n+            ((int) YarnConfiguration.getTimelineServiceVersion(conf) \u003d\u003d 2);\n+        if(timelineServiceV2Enabled) {\n+          timelineV2Client \u003d\n+              ((MRAppMaster.RunningAppContext)context).getTimelineV2Client();\n+          timelineV2Client.init(conf);\n+        } else {\n+          timelineClient \u003d\n+              ((MRAppMaster.RunningAppContext) context).getTimelineClient();\n+          timelineClient.init(conf);\n+        }\n         LOG.info(\"Timeline service is enabled; version: \" +\n             YarnConfiguration.getTimelineServiceVersion(conf));\n       } else {\n         LOG.info(\"Timeline service is not enabled\");\n       }\n     } else {\n       LOG.info(\"Emitting job history data to the timeline server is not \" +\n           \"enabled\");\n     }\n \n     // Flag for setting\n     String jhistFormat \u003d conf.get(JHAdminConfig.MR_HS_JHIST_FORMAT,\n         JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT);\n     if (jhistFormat.equals(\"json\")) {\n       jhistMode \u003d EventWriter.WriteMode.JSON;\n     } else if (jhistFormat.equals(\"binary\")) {\n       jhistMode \u003d EventWriter.WriteMode.BINARY;\n     } else {\n       LOG.warn(\"Unrecognized value \u0027\" + jhistFormat + \"\u0027 for property \" +\n           JHAdminConfig.MR_HS_JHIST_FORMAT + \".  Valid values are \" +\n           \"\u0027json\u0027 or \u0027binary\u0027.  Falling back to default value \u0027\" +\n           JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT + \"\u0027.\");\n     }\n \n     super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnRuntimeException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n\n    // TODO replace MR specific configurations on timeline service with getting\n    // configuration from RM through registerApplicationMaster() in\n    // ApplicationMasterProtocol with return value for timeline service\n    // configuration status: off, on_with_v1 or on_with_v2.\n    if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n        MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n      LOG.info(\"Emitting job history data to the timeline service is enabled\");\n      if (YarnConfiguration.timelineServiceEnabled(conf)) {\n        boolean timelineServiceV2Enabled \u003d\n            ((int) YarnConfiguration.getTimelineServiceVersion(conf) \u003d\u003d 2);\n        if(timelineServiceV2Enabled) {\n          timelineV2Client \u003d\n              ((MRAppMaster.RunningAppContext)context).getTimelineV2Client();\n          timelineV2Client.init(conf);\n        } else {\n          timelineClient \u003d\n              ((MRAppMaster.RunningAppContext) context).getTimelineClient();\n          timelineClient.init(conf);\n        }\n        LOG.info(\"Timeline service is enabled; version: \" +\n            YarnConfiguration.getTimelineServiceVersion(conf));\n      } else {\n        LOG.info(\"Timeline service is not enabled\");\n      }\n    } else {\n      LOG.info(\"Emitting job history data to the timeline server is not \" +\n          \"enabled\");\n    }\n\n    // Flag for setting\n    String jhistFormat \u003d conf.get(JHAdminConfig.MR_HS_JHIST_FORMAT,\n        JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT);\n    if (jhistFormat.equals(\"json\")) {\n      jhistMode \u003d EventWriter.WriteMode.JSON;\n    } else if (jhistFormat.equals(\"binary\")) {\n      jhistMode \u003d EventWriter.WriteMode.BINARY;\n    } else {\n      LOG.warn(\"Unrecognized value \u0027\" + jhistFormat + \"\u0027 for property \" +\n          JHAdminConfig.MR_HS_JHIST_FORMAT + \".  Valid values are \" +\n          \"\u0027json\u0027 or \u0027binary\u0027.  Falling back to default value \u0027\" +\n          JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT + \"\u0027.\");\n    }\n\n    super.serviceInit(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "0d02ab8729630ad3cfb4300702927333b1d349e3": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3367. Replace starting a separate thread for post entity with event loop in TimelineClient (Naganarasimha G R via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "0d02ab8729630ad3cfb4300702927333b1d349e3",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "960af7d4717b8a8949d0b2e43949e7daab45aa88",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,149 +1,145 @@\n   protected void serviceInit(Configuration conf) throws Exception {\n     String jobId \u003d\n       TypeConverter.fromYarn(context.getApplicationID()).toString();\n     \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n           jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnRuntimeException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n \n     // TODO replace MR specific configurations on timeline service with getting \n     // configuration from RM through registerApplicationMaster() in \n     // ApplicationMasterProtocol with return value for timeline service \n     // configuration status: off, on_with_v1 or on_with_v2.\n     if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n         MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n       LOG.info(\"Emitting job history data to the timeline service is enabled\");\n       if (YarnConfiguration.timelineServiceEnabled(conf)) {\n \n         timelineClient \u003d \n             ((MRAppMaster.RunningAppContext)context).getTimelineClient();\n         timelineClient.init(conf);\n         timelineServiceV2Enabled \u003d\n             YarnConfiguration.timelineServiceV2Enabled(conf);\n         LOG.info(\"Timeline service is enabled; version: \" +\n             YarnConfiguration.getTimelineServiceVersion(conf));\n-        if (timelineServiceV2Enabled) {\n-          // initialize the thread pool for v.2 timeline service\n-          threadPool \u003d createThreadPool();\n-        }\n       } else {\n         LOG.info(\"Timeline service is not enabled\");\n       }\n     } else {\n       LOG.info(\"Emitting job history data to the timeline server is not \" +\n           \"enabled\");\n     }\n \n     // Flag for setting\n     String jhistFormat \u003d conf.get(JHAdminConfig.MR_HS_JHIST_FORMAT,\n         JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT);\n     if (jhistFormat.equals(\"json\")) {\n       jhistMode \u003d EventWriter.WriteMode.JSON;\n     } else if (jhistFormat.equals(\"binary\")) {\n       jhistMode \u003d EventWriter.WriteMode.BINARY;\n     } else {\n       LOG.warn(\"Unrecognized value \u0027\" + jhistFormat + \"\u0027 for property \" +\n           JHAdminConfig.MR_HS_JHIST_FORMAT + \".  Valid values are \" +\n           \"\u0027json\u0027 or \u0027binary\u0027.  Falling back to default value \u0027\" +\n           JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT + \"\u0027.\");\n     }\n \n     super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnRuntimeException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n\n    // TODO replace MR specific configurations on timeline service with getting \n    // configuration from RM through registerApplicationMaster() in \n    // ApplicationMasterProtocol with return value for timeline service \n    // configuration status: off, on_with_v1 or on_with_v2.\n    if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n        MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n      LOG.info(\"Emitting job history data to the timeline service is enabled\");\n      if (YarnConfiguration.timelineServiceEnabled(conf)) {\n\n        timelineClient \u003d \n            ((MRAppMaster.RunningAppContext)context).getTimelineClient();\n        timelineClient.init(conf);\n        timelineServiceV2Enabled \u003d\n            YarnConfiguration.timelineServiceV2Enabled(conf);\n        LOG.info(\"Timeline service is enabled; version: \" +\n            YarnConfiguration.getTimelineServiceVersion(conf));\n      } else {\n        LOG.info(\"Timeline service is not enabled\");\n      }\n    } else {\n      LOG.info(\"Emitting job history data to the timeline server is not \" +\n          \"enabled\");\n    }\n\n    // Flag for setting\n    String jhistFormat \u003d conf.get(JHAdminConfig.MR_HS_JHIST_FORMAT,\n        JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT);\n    if (jhistFormat.equals(\"json\")) {\n      jhistMode \u003d EventWriter.WriteMode.JSON;\n    } else if (jhistFormat.equals(\"binary\")) {\n      jhistMode \u003d EventWriter.WriteMode.BINARY;\n    } else {\n      LOG.warn(\"Unrecognized value \u0027\" + jhistFormat + \"\u0027 for property \" +\n          JHAdminConfig.MR_HS_JHIST_FORMAT + \".  Valid values are \" +\n          \"\u0027json\u0027 or \u0027binary\u0027.  Falling back to default value \u0027\" +\n          JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT + \"\u0027.\");\n    }\n\n    super.serviceInit(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "89e5c44f9e891a3579384c3fa3766937cd4970f1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4356. Ensure the timeline service v.2 is disabled cleanly and has no\nimpact when it\u0027s turned off. Contributed by Sangjin Lee.\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "89e5c44f9e891a3579384c3fa3766937cd4970f1",
      "commitAuthor": "Li Lu",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 48,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,145 +1,149 @@\n   protected void serviceInit(Configuration conf) throws Exception {\n     String jobId \u003d\n       TypeConverter.fromYarn(context.getApplicationID()).toString();\n     \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n           jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnRuntimeException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n \n     // TODO replace MR specific configurations on timeline service with getting \n     // configuration from RM through registerApplicationMaster() in \n     // ApplicationMasterProtocol with return value for timeline service \n     // configuration status: off, on_with_v1 or on_with_v2.\n     if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n         MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n-      if (conf.getBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED,\n-            YarnConfiguration.DEFAULT_TIMELINE_SERVICE_ENABLED)) {\n-        \n+      LOG.info(\"Emitting job history data to the timeline service is enabled\");\n+      if (YarnConfiguration.timelineServiceEnabled(conf)) {\n+\n         timelineClient \u003d \n             ((MRAppMaster.RunningAppContext)context).getTimelineClient();\n         timelineClient.init(conf);\n-        newTimelineServiceEnabled \u003d conf.getBoolean(\n-            MRJobConfig.MAPREDUCE_JOB_NEW_TIMELINE_SERVICE_ENABLED,\n-            MRJobConfig.DEFAULT_MAPREDUCE_JOB_NEW_TIMELINE_SERVICE_ENABLED);\n-        LOG.info(\"Timeline service is enabled: \" + (newTimelineServiceEnabled? \"v2\" : \"v1\"));\n-        LOG.info(\"Emitting job history data to the timeline server is enabled\");\n+        timelineServiceV2Enabled \u003d\n+            YarnConfiguration.timelineServiceV2Enabled(conf);\n+        LOG.info(\"Timeline service is enabled; version: \" +\n+            YarnConfiguration.getTimelineServiceVersion(conf));\n+        if (timelineServiceV2Enabled) {\n+          // initialize the thread pool for v.2 timeline service\n+          threadPool \u003d createThreadPool();\n+        }\n       } else {\n         LOG.info(\"Timeline service is not enabled\");\n       }\n     } else {\n-      LOG.info(\"Emitting job history data to the timeline server is not enabled\");\n+      LOG.info(\"Emitting job history data to the timeline server is not \" +\n+          \"enabled\");\n     }\n \n     // Flag for setting\n     String jhistFormat \u003d conf.get(JHAdminConfig.MR_HS_JHIST_FORMAT,\n         JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT);\n     if (jhistFormat.equals(\"json\")) {\n       jhistMode \u003d EventWriter.WriteMode.JSON;\n     } else if (jhistFormat.equals(\"binary\")) {\n       jhistMode \u003d EventWriter.WriteMode.BINARY;\n     } else {\n       LOG.warn(\"Unrecognized value \u0027\" + jhistFormat + \"\u0027 for property \" +\n           JHAdminConfig.MR_HS_JHIST_FORMAT + \".  Valid values are \" +\n           \"\u0027json\u0027 or \u0027binary\u0027.  Falling back to default value \u0027\" +\n           JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT + \"\u0027.\");\n     }\n \n     super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnRuntimeException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n\n    // TODO replace MR specific configurations on timeline service with getting \n    // configuration from RM through registerApplicationMaster() in \n    // ApplicationMasterProtocol with return value for timeline service \n    // configuration status: off, on_with_v1 or on_with_v2.\n    if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n        MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n      LOG.info(\"Emitting job history data to the timeline service is enabled\");\n      if (YarnConfiguration.timelineServiceEnabled(conf)) {\n\n        timelineClient \u003d \n            ((MRAppMaster.RunningAppContext)context).getTimelineClient();\n        timelineClient.init(conf);\n        timelineServiceV2Enabled \u003d\n            YarnConfiguration.timelineServiceV2Enabled(conf);\n        LOG.info(\"Timeline service is enabled; version: \" +\n            YarnConfiguration.getTimelineServiceVersion(conf));\n        if (timelineServiceV2Enabled) {\n          // initialize the thread pool for v.2 timeline service\n          threadPool \u003d createThreadPool();\n        }\n      } else {\n        LOG.info(\"Timeline service is not enabled\");\n      }\n    } else {\n      LOG.info(\"Emitting job history data to the timeline server is not \" +\n          \"enabled\");\n    }\n\n    // Flag for setting\n    String jhistFormat \u003d conf.get(JHAdminConfig.MR_HS_JHIST_FORMAT,\n        JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT);\n    if (jhistFormat.equals(\"json\")) {\n      jhistMode \u003d EventWriter.WriteMode.JSON;\n    } else if (jhistFormat.equals(\"binary\")) {\n      jhistMode \u003d EventWriter.WriteMode.BINARY;\n    } else {\n      LOG.warn(\"Unrecognized value \u0027\" + jhistFormat + \"\u0027 for property \" +\n          JHAdminConfig.MR_HS_JHIST_FORMAT + \".  Valid values are \" +\n          \"\u0027json\u0027 or \u0027binary\u0027.  Falling back to default value \u0027\" +\n          JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT + \"\u0027.\");\n    }\n\n    super.serviceInit(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6327. Made MR AM use timeline service v2 API to write history events and counters. Contributed by Junping Du.\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "29/05/16 8:54 AM",
      "commitNameOld": "42f90ab885d9693fcc1e52f9637f7de4111110ae",
      "commitAuthorOld": "Varun Vasudev",
      "daysBetweenCommits": 41.99,
      "commitsBetweenForRepo": 290,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,136 +1,145 @@\n   protected void serviceInit(Configuration conf) throws Exception {\n     String jobId \u003d\n       TypeConverter.fromYarn(context.getApplicationID()).toString();\n     \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n           jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnRuntimeException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n \n+    // TODO replace MR specific configurations on timeline service with getting \n+    // configuration from RM through registerApplicationMaster() in \n+    // ApplicationMasterProtocol with return value for timeline service \n+    // configuration status: off, on_with_v1 or on_with_v2.\n     if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n         MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n       if (conf.getBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED,\n             YarnConfiguration.DEFAULT_TIMELINE_SERVICE_ENABLED)) {\n-        timelineClient \u003d TimelineClient.createTimelineClient();\n+        \n+        timelineClient \u003d \n+            ((MRAppMaster.RunningAppContext)context).getTimelineClient();\n         timelineClient.init(conf);\n-        LOG.info(\"Timeline service is enabled\");\n+        newTimelineServiceEnabled \u003d conf.getBoolean(\n+            MRJobConfig.MAPREDUCE_JOB_NEW_TIMELINE_SERVICE_ENABLED,\n+            MRJobConfig.DEFAULT_MAPREDUCE_JOB_NEW_TIMELINE_SERVICE_ENABLED);\n+        LOG.info(\"Timeline service is enabled: \" + (newTimelineServiceEnabled? \"v2\" : \"v1\"));\n         LOG.info(\"Emitting job history data to the timeline server is enabled\");\n       } else {\n         LOG.info(\"Timeline service is not enabled\");\n       }\n     } else {\n       LOG.info(\"Emitting job history data to the timeline server is not enabled\");\n     }\n \n     // Flag for setting\n     String jhistFormat \u003d conf.get(JHAdminConfig.MR_HS_JHIST_FORMAT,\n         JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT);\n     if (jhistFormat.equals(\"json\")) {\n       jhistMode \u003d EventWriter.WriteMode.JSON;\n     } else if (jhistFormat.equals(\"binary\")) {\n       jhistMode \u003d EventWriter.WriteMode.BINARY;\n     } else {\n       LOG.warn(\"Unrecognized value \u0027\" + jhistFormat + \"\u0027 for property \" +\n           JHAdminConfig.MR_HS_JHIST_FORMAT + \".  Valid values are \" +\n           \"\u0027json\u0027 or \u0027binary\u0027.  Falling back to default value \u0027\" +\n           JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT + \"\u0027.\");\n     }\n \n     super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnRuntimeException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n\n    // TODO replace MR specific configurations on timeline service with getting \n    // configuration from RM through registerApplicationMaster() in \n    // ApplicationMasterProtocol with return value for timeline service \n    // configuration status: off, on_with_v1 or on_with_v2.\n    if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n        MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n      if (conf.getBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED,\n            YarnConfiguration.DEFAULT_TIMELINE_SERVICE_ENABLED)) {\n        \n        timelineClient \u003d \n            ((MRAppMaster.RunningAppContext)context).getTimelineClient();\n        timelineClient.init(conf);\n        newTimelineServiceEnabled \u003d conf.getBoolean(\n            MRJobConfig.MAPREDUCE_JOB_NEW_TIMELINE_SERVICE_ENABLED,\n            MRJobConfig.DEFAULT_MAPREDUCE_JOB_NEW_TIMELINE_SERVICE_ENABLED);\n        LOG.info(\"Timeline service is enabled: \" + (newTimelineServiceEnabled? \"v2\" : \"v1\"));\n        LOG.info(\"Emitting job history data to the timeline server is enabled\");\n      } else {\n        LOG.info(\"Timeline service is not enabled\");\n      }\n    } else {\n      LOG.info(\"Emitting job history data to the timeline server is not enabled\");\n    }\n\n    // Flag for setting\n    String jhistFormat \u003d conf.get(JHAdminConfig.MR_HS_JHIST_FORMAT,\n        JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT);\n    if (jhistFormat.equals(\"json\")) {\n      jhistMode \u003d EventWriter.WriteMode.JSON;\n    } else if (jhistFormat.equals(\"binary\")) {\n      jhistMode \u003d EventWriter.WriteMode.BINARY;\n    } else {\n      LOG.warn(\"Unrecognized value \u0027\" + jhistFormat + \"\u0027 for property \" +\n          JHAdminConfig.MR_HS_JHIST_FORMAT + \".  Valid values are \" +\n          \"\u0027json\u0027 or \u0027binary\u0027.  Falling back to default value \u0027\" +\n          JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT + \"\u0027.\");\n    }\n\n    super.serviceInit(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "2ac87df578accb6e612f70ded76271cb5082ee10": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6376. Add avro binary support for jhist files. Contributed by Ray Chiang\n",
      "commitDate": "01/07/15 9:00 AM",
      "commitName": "2ac87df578accb6e612f70ded76271cb5082ee10",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "10/06/15 12:10 AM",
      "commitNameOld": "6785661e554114a4613b5fe7dabec9bfa80c41d9",
      "commitAuthorOld": "Devaraj K",
      "daysBetweenCommits": 21.37,
      "commitsBetweenForRepo": 145,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,122 +1,136 @@\n   protected void serviceInit(Configuration conf) throws Exception {\n     String jobId \u003d\n       TypeConverter.fromYarn(context.getApplicationID()).toString();\n     \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n           jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnRuntimeException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n \n     if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n         MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n       if (conf.getBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED,\n             YarnConfiguration.DEFAULT_TIMELINE_SERVICE_ENABLED)) {\n         timelineClient \u003d TimelineClient.createTimelineClient();\n         timelineClient.init(conf);\n         LOG.info(\"Timeline service is enabled\");\n         LOG.info(\"Emitting job history data to the timeline server is enabled\");\n       } else {\n         LOG.info(\"Timeline service is not enabled\");\n       }\n     } else {\n       LOG.info(\"Emitting job history data to the timeline server is not enabled\");\n     }\n \n+    // Flag for setting\n+    String jhistFormat \u003d conf.get(JHAdminConfig.MR_HS_JHIST_FORMAT,\n+        JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT);\n+    if (jhistFormat.equals(\"json\")) {\n+      jhistMode \u003d EventWriter.WriteMode.JSON;\n+    } else if (jhistFormat.equals(\"binary\")) {\n+      jhistMode \u003d EventWriter.WriteMode.BINARY;\n+    } else {\n+      LOG.warn(\"Unrecognized value \u0027\" + jhistFormat + \"\u0027 for property \" +\n+          JHAdminConfig.MR_HS_JHIST_FORMAT + \".  Valid values are \" +\n+          \"\u0027json\u0027 or \u0027binary\u0027.  Falling back to default value \u0027\" +\n+          JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT + \"\u0027.\");\n+    }\n+\n     super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnRuntimeException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n\n    if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n        MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n      if (conf.getBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED,\n            YarnConfiguration.DEFAULT_TIMELINE_SERVICE_ENABLED)) {\n        timelineClient \u003d TimelineClient.createTimelineClient();\n        timelineClient.init(conf);\n        LOG.info(\"Timeline service is enabled\");\n        LOG.info(\"Emitting job history data to the timeline server is enabled\");\n      } else {\n        LOG.info(\"Timeline service is not enabled\");\n      }\n    } else {\n      LOG.info(\"Emitting job history data to the timeline server is not enabled\");\n    }\n\n    // Flag for setting\n    String jhistFormat \u003d conf.get(JHAdminConfig.MR_HS_JHIST_FORMAT,\n        JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT);\n    if (jhistFormat.equals(\"json\")) {\n      jhistMode \u003d EventWriter.WriteMode.JSON;\n    } else if (jhistFormat.equals(\"binary\")) {\n      jhistMode \u003d EventWriter.WriteMode.BINARY;\n    } else {\n      LOG.warn(\"Unrecognized value \u0027\" + jhistFormat + \"\u0027 for property \" +\n          JHAdminConfig.MR_HS_JHIST_FORMAT + \".  Valid values are \" +\n          \"\u0027json\u0027 or \u0027binary\u0027.  Falling back to default value \u0027\" +\n          JHAdminConfig.DEFAULT_MR_HS_JHIST_FORMAT + \"\u0027.\");\n    }\n\n    super.serviceInit(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "c298a9a845f89317eb9efad332e6657c56736a4d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2375. Allow enabling/disabling timeline server per framework. (Mit Desai via jeagles)\n",
      "commitDate": "20/11/14 9:34 PM",
      "commitName": "c298a9a845f89317eb9efad332e6657c56736a4d",
      "commitAuthor": "Jonathan Eagles",
      "commitDateOld": "27/10/14 9:03 PM",
      "commitNameOld": "971e91c8c03a23e4613ed3f071b4f982ee5a1b63",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 24.06,
      "commitsBetweenForRepo": 243,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,116 +1,122 @@\n   protected void serviceInit(Configuration conf) throws Exception {\n     String jobId \u003d\n       TypeConverter.fromYarn(context.getApplicationID()).toString();\n     \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n           jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnRuntimeException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n \n     if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n         MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n-      timelineClient \u003d TimelineClient.createTimelineClient();\n-      timelineClient.init(conf);\n-      LOG.info(\"Emitting job history data to the timeline server is enabled\");\n+      if (conf.getBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED,\n+            YarnConfiguration.DEFAULT_TIMELINE_SERVICE_ENABLED)) {\n+        timelineClient \u003d TimelineClient.createTimelineClient();\n+        timelineClient.init(conf);\n+        LOG.info(\"Timeline service is enabled\");\n+        LOG.info(\"Emitting job history data to the timeline server is enabled\");\n+      } else {\n+        LOG.info(\"Timeline service is not enabled\");\n+      }\n     } else {\n       LOG.info(\"Emitting job history data to the timeline server is not enabled\");\n     }\n \n     super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnRuntimeException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n\n    if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n        MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n      if (conf.getBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED,\n            YarnConfiguration.DEFAULT_TIMELINE_SERVICE_ENABLED)) {\n        timelineClient \u003d TimelineClient.createTimelineClient();\n        timelineClient.init(conf);\n        LOG.info(\"Timeline service is enabled\");\n        LOG.info(\"Emitting job history data to the timeline server is enabled\");\n      } else {\n        LOG.info(\"Timeline service is not enabled\");\n      }\n    } else {\n      LOG.info(\"Emitting job history data to the timeline server is not enabled\");\n    }\n\n    super.serviceInit(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "971e91c8c03a23e4613ed3f071b4f982ee5a1b63": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6018. Added an MR specific config to enable emitting job history data to the timeline server. Contributed by Robert Kanter.\n",
      "commitDate": "27/10/14 9:03 PM",
      "commitName": "971e91c8c03a23e4613ed3f071b4f982ee5a1b63",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "27/10/14 8:35 PM",
      "commitNameOld": "6b2f11b54bc679b0715fe66bd129e340e8c61c5c",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,110 +1,116 @@\n   protected void serviceInit(Configuration conf) throws Exception {\n     String jobId \u003d\n       TypeConverter.fromYarn(context.getApplicationID()).toString();\n     \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n           jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnRuntimeException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n \n-    timelineClient \u003d TimelineClient.createTimelineClient();\n-    timelineClient.init(conf);\n+    if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n+        MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n+      timelineClient \u003d TimelineClient.createTimelineClient();\n+      timelineClient.init(conf);\n+      LOG.info(\"Emitting job history data to the timeline server is enabled\");\n+    } else {\n+      LOG.info(\"Emitting job history data to the timeline server is not enabled\");\n+    }\n \n     super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnRuntimeException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n\n    if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_EMIT_TIMELINE_DATA,\n        MRJobConfig.DEFAULT_MAPREDUCE_JOB_EMIT_TIMELINE_DATA)) {\n      timelineClient \u003d TimelineClient.createTimelineClient();\n      timelineClient.init(conf);\n      LOG.info(\"Emitting job history data to the timeline server is enabled\");\n    } else {\n      LOG.info(\"Emitting job history data to the timeline server is not enabled\");\n    }\n\n    super.serviceInit(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "6b2f11b54bc679b0715fe66bd129e340e8c61c5c": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5933. Enabled MR AM to post history events to the timeline server. Contributed by Robert Kanter.\n",
      "commitDate": "27/10/14 8:35 PM",
      "commitName": "6b2f11b54bc679b0715fe66bd129e340e8c61c5c",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "15/08/14 1:17 PM",
      "commitNameOld": "84bc2fe4021be32e0ff8ba395359337904149034",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 73.3,
      "commitsBetweenForRepo": 704,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,107 +1,110 @@\n   protected void serviceInit(Configuration conf) throws Exception {\n     String jobId \u003d\n       TypeConverter.fromYarn(context.getApplicationID()).toString();\n     \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n           jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnRuntimeException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n-    \n+\n+    timelineClient \u003d TimelineClient.createTimelineClient();\n+    timelineClient.init(conf);\n+\n     super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnRuntimeException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n\n    timelineClient \u003d TimelineClient.createTimelineClient();\n    timelineClient.init(conf);\n\n    super.serviceInit(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "84bc2fe4021be32e0ff8ba395359337904149034": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6032. Made MR jobs write job history files on the default FS when the current context‚Äôs FS is different. Contributed by Benjamin Zhitomirsky.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1618269 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/08/14 1:17 PM",
      "commitName": "84bc2fe4021be32e0ff8ba395359337904149034",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "10/04/14 9:01 PM",
      "commitNameOld": "8d41b363b85105630623b07b909b83775ffda384",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 126.68,
      "commitsBetweenForRepo": 819,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,107 +1,107 @@\n   protected void serviceInit(Configuration conf) throws Exception {\n     String jobId \u003d\n       TypeConverter.fromYarn(context.getApplicationID()).toString();\n     \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n           jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n-          FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n+          FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n-      doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n+      doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnRuntimeException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n-          FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n+          FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n     \n     super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileContext.getFileContext(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnRuntimeException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileContext.getFileContext(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n    \n    super.serviceInit(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "0928502029ef141759008997335ea2cd836a7154": {
      "type": "Ymultichange(Yrename,Ymodifierchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/06/13 8:54 AM",
      "commitName": "0928502029ef141759008997335ea2cd836a7154",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,107 +1,107 @@\n-  public void init(Configuration conf) {\n+  protected void serviceInit(Configuration conf) throws Exception {\n     String jobId \u003d\n       TypeConverter.fromYarn(context.getApplicationID()).toString();\n     \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n           jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnRuntimeException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n     \n-    super.init(conf);\n+    super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnRuntimeException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n    \n    super.serviceInit(conf);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
          "extendedDetails": {
            "oldValue": "init",
            "newValue": "serviceInit"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,107 +1,107 @@\n-  public void init(Configuration conf) {\n+  protected void serviceInit(Configuration conf) throws Exception {\n     String jobId \u003d\n       TypeConverter.fromYarn(context.getApplicationID()).toString();\n     \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n           jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnRuntimeException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n     \n-    super.init(conf);\n+    super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnRuntimeException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n    \n    super.serviceInit(conf);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[protected]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,107 +1,107 @@\n-  public void init(Configuration conf) {\n+  protected void serviceInit(Configuration conf) throws Exception {\n     String jobId \u003d\n       TypeConverter.fromYarn(context.getApplicationID()).toString();\n     \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n           jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnRuntimeException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n     \n-    super.init(conf);\n+    super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnRuntimeException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n    \n    super.serviceInit(conf);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[Exception]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/06/13 8:54 AM",
          "commitName": "0928502029ef141759008997335ea2cd836a7154",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "03/06/13 9:05 PM",
          "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 9.49,
          "commitsBetweenForRepo": 61,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,107 +1,107 @@\n-  public void init(Configuration conf) {\n+  protected void serviceInit(Configuration conf) throws Exception {\n     String jobId \u003d\n       TypeConverter.fromYarn(context.getApplicationID()).toString();\n     \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n           jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnRuntimeException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnRuntimeException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnRuntimeException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n     \n-    super.init(conf);\n+    super.serviceInit(conf);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void serviceInit(Configuration conf) throws Exception {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnRuntimeException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n    \n    super.serviceInit(conf);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
          "extendedDetails": {}
        }
      ]
    },
    "a83fb61ac07c0468cbc7a38526e92683883dd932": {
      "type": "Ybodychange",
      "commitMessage": "YARN-635. Renamed YarnRemoteException to YarnException. Contributed by Siddharth Seth.\nMAPREDUCE-5301. Updated MR code to work with YARN-635 changes of renaming YarnRemoteException to YarnException. Contributed by Siddharth Seth\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1489283 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/06/13 9:05 PM",
      "commitName": "a83fb61ac07c0468cbc7a38526e92683883dd932",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "04/01/13 12:35 PM",
      "commitNameOld": "64e4fb983e022d8d3375a3e1b8facbf95f7ba403",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 150.31,
      "commitsBetweenForRepo": 892,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,107 +1,107 @@\n   public void init(Configuration conf) {\n     String jobId \u003d\n       TypeConverter.fromYarn(context.getApplicationID()).toString();\n     \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n           jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n-      throw new YarnException(e);\n+      throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n-      throw new YarnException(e);\n+      throw new YarnRuntimeException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n-        throw new YarnException(message);\n+        throw new YarnRuntimeException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n-      throw new YarnException(e);\n+      throw new YarnRuntimeException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n-      throw new YarnException(e);\n+      throw new YarnRuntimeException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n     \n     super.init(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void init(Configuration conf) {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnRuntimeException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnRuntimeException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnRuntimeException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n    \n    super.init(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "64e4fb983e022d8d3375a3e1b8facbf95f7ba403": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4819. AM can rerun job after reporting final job status to the client (bobby and Bikas Saha via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1429114 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/01/13 12:35 PM",
      "commitName": "64e4fb983e022d8d3375a3e1b8facbf95f7ba403",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "19/11/12 8:43 AM",
      "commitNameOld": "c271f3cded8636724673882eac3cd2229c157f31",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 46.16,
      "commitsBetweenForRepo": 156,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,104 +1,107 @@\n   public void init(Configuration conf) {\n-\n+    String jobId \u003d\n+      TypeConverter.fromYarn(context.getApplicationID()).toString();\n+    \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n-      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf);\n+      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n+          jobId);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnException(e);\n     }\n \n     // Maximum number of unflushed completion-events that can stay in the queue\n     // before flush kicks in.\n     maxUnflushedCompletionEvents \u003d\n         conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n     // We want to cut down flushes after job completes so as to write quicker,\n     // so we increase maxUnflushedEvents post Job completion by using the\n     // following multiplier.\n     postJobCompletionMultiplier \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n     // Max time until which flush doesn\u0027t take place.\n     flushTimeout \u003d\n         conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n     minQueueSizeForBatchingFlushes \u003d\n         conf.getInt(\n             MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n             MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n     \n     super.init(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void init(Configuration conf) {\n    String jobId \u003d\n      TypeConverter.fromYarn(context.getApplicationID()).toString();\n    \n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf,\n          jobId);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n    \n    super.init(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "74697f231772a556884feaf1c986631d02a9ae4e": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3512. Batching JobHistory flushing to DFS so that we don\u0027t flush for every event slowing down AM. Contributed by Siddarth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1230353 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/01/12 5:42 PM",
      "commitName": "74697f231772a556884feaf1c986631d02a9ae4e",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "09/01/12 1:04 PM",
      "commitNameOld": "e8645636ce1721aa6dc3674fbc553a7bb3522fbe",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 2.19,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,85 +1,104 @@\n   public void init(Configuration conf) {\n \n-    this.conf \u003d conf;\n-\n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with\" +\n                 \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate \" +\n       \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnException(e);\n     }\n \n+    // Maximum number of unflushed completion-events that can stay in the queue\n+    // before flush kicks in.\n+    maxUnflushedCompletionEvents \u003d\n+        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n+            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n+    // We want to cut down flushes after job completes so as to write quicker,\n+    // so we increase maxUnflushedEvents post Job completion by using the\n+    // following multiplier.\n+    postJobCompletionMultiplier \u003d\n+        conf.getInt(\n+            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n+            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n+    // Max time until which flush doesn\u0027t take place.\n+    flushTimeout \u003d\n+        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n+            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n+    minQueueSizeForBatchingFlushes \u003d\n+        conf.getInt(\n+            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n+            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n+    \n     super.init(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void init(Configuration conf) {\n\n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnException(e);\n    }\n\n    // Maximum number of unflushed completion-events that can stay in the queue\n    // before flush kicks in.\n    maxUnflushedCompletionEvents \u003d\n        conf.getInt(MRJobConfig.MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_MAX_UNFLUSHED_COMPLETE_EVENTS);\n    // We want to cut down flushes after job completes so as to write quicker,\n    // so we increase maxUnflushedEvents post Job completion by using the\n    // following multiplier.\n    postJobCompletionMultiplier \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_JOB_COMPLETE_UNFLUSHED_MULTIPLIER);\n    // Max time until which flush doesn\u0027t take place.\n    flushTimeout \u003d\n        conf.getLong(MRJobConfig.MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_COMPLETE_EVENT_FLUSH_TIMEOUT_MS);\n    minQueueSizeForBatchingFlushes \u003d\n        conf.getInt(\n            MRJobConfig.MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD,\n            MRJobConfig.DEFAULT_MR_AM_HISTORY_USE_BATCHED_FLUSH_QUEUE_SIZE_THRESHOLD);\n    \n    super.init(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "fffdf661e30afd10331d2153ff052c141b7ebe4b": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2821. Added missing fields (resourcePerMap \u0026 resourcePerReduce) to JobSummary logs. Contributed by Mahadev Konar.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1188528 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/10/11 11:26 PM",
      "commitName": "fffdf661e30afd10331d2153ff052c141b7ebe4b",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "18/10/11 10:21 PM",
      "commitNameOld": "13e4562924a6cb3d16c262e0f595b2ffbf9e0546",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 6.05,
      "commitsBetweenForRepo": 52,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,85 @@\n   public void init(Configuration conf) {\n \n     this.conf \u003d conf;\n \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n             + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n                 + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n-                + \". Either set to true or pre-create this directory with appropriate permissions\";\n+                + \". Either set to true or pre-create this directory with\" +\n+                \" appropriate permissions\";\n         LOG.error(message);\n         throw new YarnException(message);\n       }\n       }\n     } catch (IOException e) {\n-      LOG.error(\"Failed checking for the existance of history intermediate done directory: [\"\n-          + doneDirPath + \"]\");\n+      LOG.error(\"Failed checking for the existance of history intermediate \" +\n+      \t\t\"done directory: [\" + doneDirPath + \"]\");\n       throw new YarnException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnException(e);\n     }\n \n     super.init(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void init(Configuration conf) {\n\n    this.conf \u003d conf;\n\n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with\" +\n                \" appropriate permissions\";\n        LOG.error(message);\n        throw new YarnException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate \" +\n      \t\t\"done directory: [\" + doneDirPath + \"]\");\n      throw new YarnException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnException(e);\n    }\n\n    super.init(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "fafe8cd28e726566509c679e19d7da622f29f90d": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2864. Normalize configuration variable names for YARN. Contributed by Robert Evans.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1166955 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/09/11 6:44 PM",
      "commitName": "fafe8cd28e726566509c679e19d7da622f29f90d",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 15.06,
      "commitsBetweenForRepo": 86,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,84 @@\n   public void init(Configuration conf) {\n \n     this.conf \u003d conf;\n \n     String stagingDirStr \u003d null;\n     String doneDirStr \u003d null;\n     String userDoneDirStr \u003d null;\n     try {\n       stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf);\n       doneDirStr \u003d\n           JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n       userDoneDirStr \u003d\n           JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n     } catch (IOException e) {\n       LOG.error(\"Failed while getting the configured log directories\", e);\n       throw new YarnException(e);\n     }\n \n     //Check for the existence of the history staging dir. Maybe create it. \n     try {\n       stagingDirPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n       stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n       mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n           JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Failed while checking for/creating  history staging path: [\"\n           + stagingDirPath + \"]\", e);\n       throw new YarnException(e);\n     }\n \n     //Check for the existence of intermediate done dir.\n     Path doneDirPath \u003d null;\n     try {\n       doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n       doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n       // This directory will be in a common location, or this may be a cluster\n       // meant for a single user. Creating based on the conf. Should ideally be\n       // created by the JobHistoryServer or as part of deployment.\n       if (!doneDirFS.exists(doneDirPath)) {\n       if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n         LOG.info(\"Creating intermediate history logDir: [\"\n             + doneDirPath\n             + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n-            + JHConfig.CREATE_HISTORY_INTERMEDIATE_BASE_DIR_KEY);\n+            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n           mkdir(\n               doneDirFS,\n               doneDirPath,\n               new FsPermission(\n             JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                 .toShort()));\n           // TODO Temporary toShort till new FsPermission(FsPermissions)\n           // respects\n         // sticky\n       } else {\n           String message \u003d \"Not creating intermediate history logDir: [\"\n                 + doneDirPath\n                 + \"] based on conf: \"\n-                + JHConfig.CREATE_HISTORY_INTERMEDIATE_BASE_DIR_KEY\n+                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                 + \". Either set to true or pre-create this directory with appropriate permissions\";\n         LOG.error(message);\n         throw new YarnException(message);\n       }\n       }\n     } catch (IOException e) {\n       LOG.error(\"Failed checking for the existance of history intermediate done directory: [\"\n           + doneDirPath + \"]\");\n       throw new YarnException(e);\n     }\n \n     //Check/create user directory under intermediate done dir.\n     try {\n       doneDirPrefixPath \u003d\n           FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n       mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n           JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n     } catch (IOException e) {\n       LOG.error(\"Error creating user intermediate history done directory: [ \"\n           + doneDirPrefixPath + \"]\", e);\n       throw new YarnException(e);\n     }\n \n     super.init(conf);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void init(Configuration conf) {\n\n    this.conf \u003d conf;\n\n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR\n                + \". Either set to true or pre-create this directory with appropriate permissions\";\n        LOG.error(message);\n        throw new YarnException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate done directory: [\"\n          + doneDirPath + \"]\");\n      throw new YarnException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnException(e);\n    }\n\n    super.init(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void init(Configuration conf) {\n\n    this.conf \u003d conf;\n\n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + JHConfig.CREATE_HISTORY_INTERMEDIATE_BASE_DIR_KEY);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + JHConfig.CREATE_HISTORY_INTERMEDIATE_BASE_DIR_KEY\n                + \". Either set to true or pre-create this directory with appropriate permissions\";\n        LOG.error(message);\n        throw new YarnException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate done directory: [\"\n          + doneDirPath + \"]\");\n      throw new YarnException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnException(e);\n    }\n\n    super.init(conf);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,84 @@\n+  public void init(Configuration conf) {\n+\n+    this.conf \u003d conf;\n+\n+    String stagingDirStr \u003d null;\n+    String doneDirStr \u003d null;\n+    String userDoneDirStr \u003d null;\n+    try {\n+      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf);\n+      doneDirStr \u003d\n+          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n+      userDoneDirStr \u003d\n+          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n+    } catch (IOException e) {\n+      LOG.error(\"Failed while getting the configured log directories\", e);\n+      throw new YarnException(e);\n+    }\n+\n+    //Check for the existence of the history staging dir. Maybe create it. \n+    try {\n+      stagingDirPath \u003d\n+          FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n+      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n+      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n+          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n+    } catch (IOException e) {\n+      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n+          + stagingDirPath + \"]\", e);\n+      throw new YarnException(e);\n+    }\n+\n+    //Check for the existence of intermediate done dir.\n+    Path doneDirPath \u003d null;\n+    try {\n+      doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n+      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n+      // This directory will be in a common location, or this may be a cluster\n+      // meant for a single user. Creating based on the conf. Should ideally be\n+      // created by the JobHistoryServer or as part of deployment.\n+      if (!doneDirFS.exists(doneDirPath)) {\n+      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n+        LOG.info(\"Creating intermediate history logDir: [\"\n+            + doneDirPath\n+            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n+            + JHConfig.CREATE_HISTORY_INTERMEDIATE_BASE_DIR_KEY);\n+          mkdir(\n+              doneDirFS,\n+              doneDirPath,\n+              new FsPermission(\n+            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n+                .toShort()));\n+          // TODO Temporary toShort till new FsPermission(FsPermissions)\n+          // respects\n+        // sticky\n+      } else {\n+          String message \u003d \"Not creating intermediate history logDir: [\"\n+                + doneDirPath\n+                + \"] based on conf: \"\n+                + JHConfig.CREATE_HISTORY_INTERMEDIATE_BASE_DIR_KEY\n+                + \". Either set to true or pre-create this directory with appropriate permissions\";\n+        LOG.error(message);\n+        throw new YarnException(message);\n+      }\n+      }\n+    } catch (IOException e) {\n+      LOG.error(\"Failed checking for the existance of history intermediate done directory: [\"\n+          + doneDirPath + \"]\");\n+      throw new YarnException(e);\n+    }\n+\n+    //Check/create user directory under intermediate done dir.\n+    try {\n+      doneDirPrefixPath \u003d\n+          FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n+      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n+          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n+    } catch (IOException e) {\n+      LOG.error(\"Error creating user intermediate history done directory: [ \"\n+          + doneDirPrefixPath + \"]\", e);\n+      throw new YarnException(e);\n+    }\n+\n+    super.init(conf);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void init(Configuration conf) {\n\n    this.conf \u003d conf;\n\n    String stagingDirStr \u003d null;\n    String doneDirStr \u003d null;\n    String userDoneDirStr \u003d null;\n    try {\n      stagingDirStr \u003d JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf);\n      doneDirStr \u003d\n          JobHistoryUtils.getConfiguredHistoryIntermediateDoneDirPrefix(conf);\n      userDoneDirStr \u003d\n          JobHistoryUtils.getHistoryIntermediateDoneDirForUser(conf);\n    } catch (IOException e) {\n      LOG.error(\"Failed while getting the configured log directories\", e);\n      throw new YarnException(e);\n    }\n\n    //Check for the existence of the history staging dir. Maybe create it. \n    try {\n      stagingDirPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(stagingDirStr));\n      stagingDirFS \u003d FileSystem.get(stagingDirPath.toUri(), conf);\n      mkdir(stagingDirFS, stagingDirPath, new FsPermission(\n          JobHistoryUtils.HISTORY_STAGING_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Failed while checking for/creating  history staging path: [\"\n          + stagingDirPath + \"]\", e);\n      throw new YarnException(e);\n    }\n\n    //Check for the existence of intermediate done dir.\n    Path doneDirPath \u003d null;\n    try {\n      doneDirPath \u003d FileSystem.get(conf).makeQualified(new Path(doneDirStr));\n      doneDirFS \u003d FileSystem.get(doneDirPath.toUri(), conf);\n      // This directory will be in a common location, or this may be a cluster\n      // meant for a single user. Creating based on the conf. Should ideally be\n      // created by the JobHistoryServer or as part of deployment.\n      if (!doneDirFS.exists(doneDirPath)) {\n      if (JobHistoryUtils.shouldCreateNonUserDirectory(conf)) {\n        LOG.info(\"Creating intermediate history logDir: [\"\n            + doneDirPath\n            + \"] + based on conf. Should ideally be created by the JobHistoryServer: \"\n            + JHConfig.CREATE_HISTORY_INTERMEDIATE_BASE_DIR_KEY);\n          mkdir(\n              doneDirFS,\n              doneDirPath,\n              new FsPermission(\n            JobHistoryUtils.HISTORY_INTERMEDIATE_DONE_DIR_PERMISSIONS\n                .toShort()));\n          // TODO Temporary toShort till new FsPermission(FsPermissions)\n          // respects\n        // sticky\n      } else {\n          String message \u003d \"Not creating intermediate history logDir: [\"\n                + doneDirPath\n                + \"] based on conf: \"\n                + JHConfig.CREATE_HISTORY_INTERMEDIATE_BASE_DIR_KEY\n                + \". Either set to true or pre-create this directory with appropriate permissions\";\n        LOG.error(message);\n        throw new YarnException(message);\n      }\n      }\n    } catch (IOException e) {\n      LOG.error(\"Failed checking for the existance of history intermediate done directory: [\"\n          + doneDirPath + \"]\");\n      throw new YarnException(e);\n    }\n\n    //Check/create user directory under intermediate done dir.\n    try {\n      doneDirPrefixPath \u003d\n          FileSystem.get(conf).makeQualified(new Path(userDoneDirStr));\n      mkdir(doneDirFS, doneDirPrefixPath, new FsPermission(\n          JobHistoryUtils.HISTORY_INTERMEDIATE_USER_DIR_PERMISSIONS));\n    } catch (IOException e) {\n      LOG.error(\"Error creating user intermediate history done directory: [ \"\n          + doneDirPrefixPath + \"]\", e);\n      throw new YarnException(e);\n    }\n\n    super.init(conf);\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java"
    }
  }
}