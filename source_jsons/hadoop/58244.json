{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ContainerTokenIdentifier.java",
  "functionName": "write",
  "functionId": "write___out-DataOutput",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
  "functionStartLine": 328,
  "functionEndLine": 331,
  "numCommitsSeen": 39,
  "timeTaken": 10345,
  "changeHistory": [
    "2064ca015d1584263aac0cc20c60b925a3aff612",
    "5391919b09ce9549d13c897aa89bb0a0536760fe",
    "c86674a3a4d99aa56bb8ed3f6df51e3fef215eba",
    "f4886111aa573ec928de69e8ca9328d480bf673e",
    "e285b98f0fe8637b574c52498035f7f11fb4e962",
    "b16c5638b5190c56f9d854d873589cb5c11c8b32",
    "453926397182078c65a4428eb5de5a90d6af6448",
    "40062e1aaa09628c6f45d20298fd66d799fd1f3f",
    "ffd2e01604be814fa3db1dded7cd7cff26a79b1e",
    "e1fdf62123625e4ba399af02f8aad500637d29d1",
    "3bfb26ad3b5ac46f992a632541c97ca2bc897638",
    "7f4dc277572df6ba25fa961073b99a5bdb086c00",
    "6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1",
    "f2b91a8367a762091482074505618b570a520b19",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "2064ca015d1584263aac0cc20c60b925a3aff612": "Ybodychange",
    "5391919b09ce9549d13c897aa89bb0a0536760fe": "Ybodychange",
    "c86674a3a4d99aa56bb8ed3f6df51e3fef215eba": "Ybodychange",
    "f4886111aa573ec928de69e8ca9328d480bf673e": "Ybodychange",
    "e285b98f0fe8637b574c52498035f7f11fb4e962": "Ybodychange",
    "b16c5638b5190c56f9d854d873589cb5c11c8b32": "Ybodychange",
    "453926397182078c65a4428eb5de5a90d6af6448": "Ybodychange",
    "40062e1aaa09628c6f45d20298fd66d799fd1f3f": "Ybodychange",
    "ffd2e01604be814fa3db1dded7cd7cff26a79b1e": "Ybodychange",
    "e1fdf62123625e4ba399af02f8aad500637d29d1": "Yfilerename",
    "3bfb26ad3b5ac46f992a632541c97ca2bc897638": "Ybodychange",
    "7f4dc277572df6ba25fa961073b99a5bdb086c00": "Ybodychange",
    "6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1": "Ybodychange",
    "f2b91a8367a762091482074505618b570a520b19": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Ymultichange(Ymovefromfile,Yexceptionschange,Ybodychange,Yparameterchange)",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2064ca015d1584263aac0cc20c60b925a3aff612": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9349.  Changed logging to use slf4j api.\n            Contributed by Prabhu Joseph\n",
      "commitDate": "15/03/19 4:20 PM",
      "commitName": "2064ca015d1584263aac0cc20c60b925a3aff612",
      "commitAuthor": "Eric Yang",
      "commitDateOld": "03/03/19 11:59 PM",
      "commitNameOld": "bd8d299ded742813cabd4b4e7ce1e33e0d1f9509",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 11.64,
      "commitsBetweenForRepo": 118,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,4 @@\n   public void write(DataOutput out) throws IOException {\n-    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n+    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: {}\", this);\n     out.write(proto.toByteArray());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: {}\", this);\n    out.write(proto.toByteArray());\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "5391919b09ce9549d13c897aa89bb0a0536760fe": {
      "type": "Ybodychange",
      "commitMessage": "YARN-668. Changed NMTokenIdentifier/AMRMTokenIdentifier/ContainerTokenIdentifier to use protobuf object as the payload. Contributed by Junping Du.\n",
      "commitDate": "26/09/14 5:48 PM",
      "commitName": "5391919b09ce9549d13c897aa89bb0a0536760fe",
      "commitAuthor": "Jian He",
      "commitDateOld": "24/09/14 5:50 PM",
      "commitNameOld": "c86674a3a4d99aa56bb8ed3f6df51e3fef215eba",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 2.0,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,4 @@\n   public void write(DataOutput out) throws IOException {\n     LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n-    ApplicationAttemptId applicationAttemptId \u003d this.containerId\n-        .getApplicationAttemptId();\n-    ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n-    out.writeLong(applicationId.getClusterTimestamp());\n-    out.writeInt(applicationId.getId());\n-    out.writeInt(applicationAttemptId.getAttemptId());\n-    out.writeLong(this.containerId.getContainerId());\n-    out.writeUTF(this.nmHostAddr);\n-    out.writeUTF(this.appSubmitter);\n-    out.writeInt(this.resource.getMemory());\n-    out.writeInt(this.resource.getVirtualCores());\n-    out.writeLong(this.expiryTimeStamp);\n-    out.writeInt(this.masterKeyId);\n-    out.writeLong(this.rmIdentifier);\n-    out.writeInt(this.priority.getPriority());\n-    out.writeLong(this.creationTime);\n-    if (this.logAggregationContext \u003d\u003d null) {\n-      out.writeInt(-1);\n-    } else {\n-      byte[] logAggregationContext \u003d\n-          ((LogAggregationContextPBImpl) this.logAggregationContext).getProto()\n-            .toByteArray();\n-      out.writeInt(logAggregationContext.length);\n-      out.write(logAggregationContext);\n-    }\n+    out.write(proto.toByteArray());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n    out.write(proto.toByteArray());\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "c86674a3a4d99aa56bb8ed3f6df51e3fef215eba": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2581. Passed LogAggregationContext to NM via ContainerTokenIdentifier. Contributed by Xuan Gong.\n",
      "commitDate": "24/09/14 5:50 PM",
      "commitName": "c86674a3a4d99aa56bb8ed3f6df51e3fef215eba",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "17/09/14 3:13 PM",
      "commitNameOld": "f4886111aa573ec928de69e8ca9328d480bf673e",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 7.11,
      "commitsBetweenForRepo": 81,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,28 @@\n   public void write(DataOutput out) throws IOException {\n     LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n     ApplicationAttemptId applicationAttemptId \u003d this.containerId\n         .getApplicationAttemptId();\n     ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n     out.writeLong(applicationId.getClusterTimestamp());\n     out.writeInt(applicationId.getId());\n     out.writeInt(applicationAttemptId.getAttemptId());\n     out.writeLong(this.containerId.getContainerId());\n     out.writeUTF(this.nmHostAddr);\n     out.writeUTF(this.appSubmitter);\n     out.writeInt(this.resource.getMemory());\n     out.writeInt(this.resource.getVirtualCores());\n     out.writeLong(this.expiryTimeStamp);\n     out.writeInt(this.masterKeyId);\n     out.writeLong(this.rmIdentifier);\n     out.writeInt(this.priority.getPriority());\n     out.writeLong(this.creationTime);\n+    if (this.logAggregationContext \u003d\u003d null) {\n+      out.writeInt(-1);\n+    } else {\n+      byte[] logAggregationContext \u003d\n+          ((LogAggregationContextPBImpl) this.logAggregationContext).getProto()\n+            .toByteArray();\n+      out.writeInt(logAggregationContext.length);\n+      out.write(logAggregationContext);\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n    ApplicationAttemptId applicationAttemptId \u003d this.containerId\n        .getApplicationAttemptId();\n    ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n    out.writeLong(applicationId.getClusterTimestamp());\n    out.writeInt(applicationId.getId());\n    out.writeInt(applicationAttemptId.getAttemptId());\n    out.writeLong(this.containerId.getContainerId());\n    out.writeUTF(this.nmHostAddr);\n    out.writeUTF(this.appSubmitter);\n    out.writeInt(this.resource.getMemory());\n    out.writeInt(this.resource.getVirtualCores());\n    out.writeLong(this.expiryTimeStamp);\n    out.writeInt(this.masterKeyId);\n    out.writeLong(this.rmIdentifier);\n    out.writeInt(this.priority.getPriority());\n    out.writeLong(this.creationTime);\n    if (this.logAggregationContext \u003d\u003d null) {\n      out.writeInt(-1);\n    } else {\n      byte[] logAggregationContext \u003d\n          ((LogAggregationContextPBImpl) this.logAggregationContext).getProto()\n            .toByteArray();\n      out.writeInt(logAggregationContext.length);\n      out.write(logAggregationContext);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "f4886111aa573ec928de69e8ca9328d480bf673e": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2558. Updated ContainerTokenIdentifier#read/write to use ContainerId#getContainerId. Contributed by Tsuyoshi OZAWA.\n",
      "commitDate": "17/09/14 3:13 PM",
      "commitName": "f4886111aa573ec928de69e8ca9328d480bf673e",
      "commitAuthor": "Jian He",
      "commitDateOld": "24/06/14 2:43 PM",
      "commitNameOld": "e285b98f0fe8637b574c52498035f7f11fb4e962",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 85.02,
      "commitsBetweenForRepo": 707,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n   public void write(DataOutput out) throws IOException {\n     LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n     ApplicationAttemptId applicationAttemptId \u003d this.containerId\n         .getApplicationAttemptId();\n     ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n     out.writeLong(applicationId.getClusterTimestamp());\n     out.writeInt(applicationId.getId());\n     out.writeInt(applicationAttemptId.getAttemptId());\n-    out.writeInt(this.containerId.getId());\n+    out.writeLong(this.containerId.getContainerId());\n     out.writeUTF(this.nmHostAddr);\n     out.writeUTF(this.appSubmitter);\n     out.writeInt(this.resource.getMemory());\n     out.writeInt(this.resource.getVirtualCores());\n     out.writeLong(this.expiryTimeStamp);\n     out.writeInt(this.masterKeyId);\n     out.writeLong(this.rmIdentifier);\n     out.writeInt(this.priority.getPriority());\n     out.writeLong(this.creationTime);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n    ApplicationAttemptId applicationAttemptId \u003d this.containerId\n        .getApplicationAttemptId();\n    ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n    out.writeLong(applicationId.getClusterTimestamp());\n    out.writeInt(applicationId.getId());\n    out.writeInt(applicationAttemptId.getAttemptId());\n    out.writeLong(this.containerId.getContainerId());\n    out.writeUTF(this.nmHostAddr);\n    out.writeUTF(this.appSubmitter);\n    out.writeInt(this.resource.getMemory());\n    out.writeInt(this.resource.getVirtualCores());\n    out.writeLong(this.expiryTimeStamp);\n    out.writeInt(this.masterKeyId);\n    out.writeLong(this.rmIdentifier);\n    out.writeInt(this.priority.getPriority());\n    out.writeLong(this.creationTime);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "e285b98f0fe8637b574c52498035f7f11fb4e962": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2152. Added missing information into ContainerTokenIdentifier so that NodeManagers can report the same to RM when RM restarts. Contributed Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1605205 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/06/14 2:43 PM",
      "commitName": "e285b98f0fe8637b574c52498035f7f11fb4e962",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "16/06/13 8:32 PM",
      "commitNameOld": "f5f8f3bca4eeaedeff8181812452ec363c4db744",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 372.76,
      "commitsBetweenForRepo": 2453,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,19 @@\n   public void write(DataOutput out) throws IOException {\n     LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n     ApplicationAttemptId applicationAttemptId \u003d this.containerId\n         .getApplicationAttemptId();\n     ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n     out.writeLong(applicationId.getClusterTimestamp());\n     out.writeInt(applicationId.getId());\n     out.writeInt(applicationAttemptId.getAttemptId());\n     out.writeInt(this.containerId.getId());\n     out.writeUTF(this.nmHostAddr);\n     out.writeUTF(this.appSubmitter);\n     out.writeInt(this.resource.getMemory());\n     out.writeInt(this.resource.getVirtualCores());\n     out.writeLong(this.expiryTimeStamp);\n     out.writeInt(this.masterKeyId);\n     out.writeLong(this.rmIdentifier);\n+    out.writeInt(this.priority.getPriority());\n+    out.writeLong(this.creationTime);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n    ApplicationAttemptId applicationAttemptId \u003d this.containerId\n        .getApplicationAttemptId();\n    ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n    out.writeLong(applicationId.getClusterTimestamp());\n    out.writeInt(applicationId.getId());\n    out.writeInt(applicationAttemptId.getAttemptId());\n    out.writeInt(this.containerId.getId());\n    out.writeUTF(this.nmHostAddr);\n    out.writeUTF(this.appSubmitter);\n    out.writeInt(this.resource.getMemory());\n    out.writeInt(this.resource.getVirtualCores());\n    out.writeLong(this.expiryTimeStamp);\n    out.writeInt(this.masterKeyId);\n    out.writeLong(this.rmIdentifier);\n    out.writeInt(this.priority.getPriority());\n    out.writeLong(this.creationTime);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "b16c5638b5190c56f9d854d873589cb5c11c8b32": {
      "type": "Ybodychange",
      "commitMessage": "YARN-719. Move RMIdentifier from Container to ContainerTokenIdentifier. Contributed by Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1487741 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/05/13 9:59 PM",
      "commitName": "b16c5638b5190c56f9d854d873589cb5c11c8b32",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "08/01/13 9:08 PM",
      "commitNameOld": "453926397182078c65a4428eb5de5a90d6af6448",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 140.99,
      "commitsBetweenForRepo": 816,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,17 @@\n   public void write(DataOutput out) throws IOException {\n     LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n     ApplicationAttemptId applicationAttemptId \u003d this.containerId\n         .getApplicationAttemptId();\n     ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n     out.writeLong(applicationId.getClusterTimestamp());\n     out.writeInt(applicationId.getId());\n     out.writeInt(applicationAttemptId.getAttemptId());\n     out.writeInt(this.containerId.getId());\n     out.writeUTF(this.nmHostAddr);\n     out.writeUTF(this.appSubmitter);\n     out.writeInt(this.resource.getMemory());\n     out.writeInt(this.resource.getVirtualCores());\n     out.writeLong(this.expiryTimeStamp);\n     out.writeInt(this.masterKeyId);\n+    out.writeLong(this.rmIdentifier);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n    ApplicationAttemptId applicationAttemptId \u003d this.containerId\n        .getApplicationAttemptId();\n    ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n    out.writeLong(applicationId.getClusterTimestamp());\n    out.writeInt(applicationId.getId());\n    out.writeInt(applicationAttemptId.getAttemptId());\n    out.writeInt(this.containerId.getId());\n    out.writeUTF(this.nmHostAddr);\n    out.writeUTF(this.appSubmitter);\n    out.writeInt(this.resource.getMemory());\n    out.writeInt(this.resource.getVirtualCores());\n    out.writeLong(this.expiryTimeStamp);\n    out.writeInt(this.masterKeyId);\n    out.writeLong(this.rmIdentifier);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "453926397182078c65a4428eb5de5a90d6af6448": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2. Enhanced CapacityScheduler to account for CPU alongwith memory for multi-dimensional resource scheduling. Contributed by Arun C. Murthy.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1430682 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/01/13 9:08 PM",
      "commitName": "453926397182078c65a4428eb5de5a90d6af6448",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "26/09/12 8:43 PM",
      "commitNameOld": "40062e1aaa09628c6f45d20298fd66d799fd1f3f",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 104.06,
      "commitsBetweenForRepo": 490,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,16 @@\n   public void write(DataOutput out) throws IOException {\n     LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n     ApplicationAttemptId applicationAttemptId \u003d this.containerId\n         .getApplicationAttemptId();\n     ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n     out.writeLong(applicationId.getClusterTimestamp());\n     out.writeInt(applicationId.getId());\n     out.writeInt(applicationAttemptId.getAttemptId());\n     out.writeInt(this.containerId.getId());\n     out.writeUTF(this.nmHostAddr);\n     out.writeUTF(this.appSubmitter);\n     out.writeInt(this.resource.getMemory());\n+    out.writeInt(this.resource.getVirtualCores());\n     out.writeLong(this.expiryTimeStamp);\n     out.writeInt(this.masterKeyId);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n    ApplicationAttemptId applicationAttemptId \u003d this.containerId\n        .getApplicationAttemptId();\n    ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n    out.writeLong(applicationId.getClusterTimestamp());\n    out.writeInt(applicationId.getId());\n    out.writeInt(applicationAttemptId.getAttemptId());\n    out.writeInt(this.containerId.getId());\n    out.writeUTF(this.nmHostAddr);\n    out.writeUTF(this.appSubmitter);\n    out.writeInt(this.resource.getMemory());\n    out.writeInt(this.resource.getVirtualCores());\n    out.writeLong(this.expiryTimeStamp);\n    out.writeInt(this.masterKeyId);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "40062e1aaa09628c6f45d20298fd66d799fd1f3f": {
      "type": "Ybodychange",
      "commitMessage": "Fix NodeManager to verify the application\u0027s user-name.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1390825 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/09/12 8:43 PM",
      "commitName": "40062e1aaa09628c6f45d20298fd66d799fd1f3f",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "24/08/12 7:18 PM",
      "commitNameOld": "ffd2e01604be814fa3db1dded7cd7cff26a79b1e",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 33.06,
      "commitsBetweenForRepo": 173,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,15 @@\n   public void write(DataOutput out) throws IOException {\n     LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n     ApplicationAttemptId applicationAttemptId \u003d this.containerId\n         .getApplicationAttemptId();\n     ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n     out.writeLong(applicationId.getClusterTimestamp());\n     out.writeInt(applicationId.getId());\n     out.writeInt(applicationAttemptId.getAttemptId());\n     out.writeInt(this.containerId.getId());\n     out.writeUTF(this.nmHostAddr);\n+    out.writeUTF(this.appSubmitter);\n     out.writeInt(this.resource.getMemory());\n     out.writeLong(this.expiryTimeStamp);\n     out.writeInt(this.masterKeyId);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n    ApplicationAttemptId applicationAttemptId \u003d this.containerId\n        .getApplicationAttemptId();\n    ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n    out.writeLong(applicationId.getClusterTimestamp());\n    out.writeInt(applicationId.getId());\n    out.writeInt(applicationAttemptId.getAttemptId());\n    out.writeInt(this.containerId.getId());\n    out.writeUTF(this.nmHostAddr);\n    out.writeUTF(this.appSubmitter);\n    out.writeInt(this.resource.getMemory());\n    out.writeLong(this.expiryTimeStamp);\n    out.writeInt(this.masterKeyId);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "ffd2e01604be814fa3db1dded7cd7cff26a79b1e": {
      "type": "Ybodychange",
      "commitMessage": "YARN-39. RM-NM secret-keys should be randomly generated and rolled every so often. (Contributed by Vinod Kumar Vavilapalli and Siddharth Seth)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1377180 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/12 7:18 PM",
      "commitName": "ffd2e01604be814fa3db1dded7cd7cff26a79b1e",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "07/08/12 10:22 PM",
      "commitNameOld": "e1fdf62123625e4ba399af02f8aad500637d29d1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 16.87,
      "commitsBetweenForRepo": 114,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,14 @@\n   public void write(DataOutput out) throws IOException {\n     LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n     ApplicationAttemptId applicationAttemptId \u003d this.containerId\n         .getApplicationAttemptId();\n     ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n     out.writeLong(applicationId.getClusterTimestamp());\n     out.writeInt(applicationId.getId());\n     out.writeInt(applicationAttemptId.getAttemptId());\n     out.writeInt(this.containerId.getId());\n     out.writeUTF(this.nmHostAddr);\n     out.writeInt(this.resource.getMemory());\n     out.writeLong(this.expiryTimeStamp);\n+    out.writeInt(this.masterKeyId);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n    ApplicationAttemptId applicationAttemptId \u003d this.containerId\n        .getApplicationAttemptId();\n    ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n    out.writeLong(applicationId.getClusterTimestamp());\n    out.writeInt(applicationId.getId());\n    out.writeInt(applicationAttemptId.getAttemptId());\n    out.writeInt(this.containerId.getId());\n    out.writeUTF(this.nmHostAddr);\n    out.writeInt(this.resource.getMemory());\n    out.writeLong(this.expiryTimeStamp);\n    out.writeInt(this.masterKeyId);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "e1fdf62123625e4ba399af02f8aad500637d29d1": {
      "type": "Yfilerename",
      "commitMessage": "YARN-1. Promote YARN to be a sub-project of Apache Hadoop.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370666 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/12 10:22 PM",
      "commitName": "e1fdf62123625e4ba399af02f8aad500637d29d1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "07/08/12 7:53 PM",
      "commitNameOld": "34554d1e11ee1d5b564d7d9ed3e6d55931d72749",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n    ApplicationAttemptId applicationAttemptId \u003d this.containerId\n        .getApplicationAttemptId();\n    ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n    out.writeLong(applicationId.getClusterTimestamp());\n    out.writeInt(applicationId.getId());\n    out.writeInt(applicationAttemptId.getAttemptId());\n    out.writeInt(this.containerId.getId());\n    out.writeUTF(this.nmHostAddr);\n    out.writeInt(this.resource.getMemory());\n    out.writeLong(this.expiryTimeStamp);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java"
      }
    },
    "3bfb26ad3b5ac46f992a632541c97ca2bc897638": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3940. ContainerTokens should have an expiry interval. Contributed by Siddharth Seth and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1359910 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/07/12 2:26 PM",
      "commitName": "3bfb26ad3b5ac46f992a632541c97ca2bc897638",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "29/10/11 2:35 AM",
      "commitNameOld": "7f4dc277572df6ba25fa961073b99a5bdb086c00",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 255.49,
      "commitsBetweenForRepo": 1664,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,13 @@\n   public void write(DataOutput out) throws IOException {\n     LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n     ApplicationAttemptId applicationAttemptId \u003d this.containerId\n         .getApplicationAttemptId();\n     ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n     out.writeLong(applicationId.getClusterTimestamp());\n     out.writeInt(applicationId.getId());\n     out.writeInt(applicationAttemptId.getAttemptId());\n     out.writeInt(this.containerId.getId());\n     out.writeUTF(this.nmHostAddr);\n     out.writeInt(this.resource.getMemory());\n+    out.writeLong(this.expiryTimeStamp);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n    ApplicationAttemptId applicationAttemptId \u003d this.containerId\n        .getApplicationAttemptId();\n    ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n    out.writeLong(applicationId.getClusterTimestamp());\n    out.writeInt(applicationId.getId());\n    out.writeInt(applicationAttemptId.getAttemptId());\n    out.writeInt(this.containerId.getId());\n    out.writeUTF(this.nmHostAddr);\n    out.writeInt(this.resource.getMemory());\n    out.writeLong(this.expiryTimeStamp);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "7f4dc277572df6ba25fa961073b99a5bdb086c00": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3256. Added authorization checks for the protocol between NodeManager and ApplicationMaster. Contributed by Vinod K V.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1194850 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/10/11 2:35 AM",
      "commitName": "7f4dc277572df6ba25fa961073b99a5bdb086c00",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "13/10/11 6:24 PM",
      "commitNameOld": "002dd6968b89ded6a77858ccb50c9b2df074c226",
      "commitAuthorOld": "Jitendra Nath Pandey",
      "daysBetweenCommits": 15.34,
      "commitsBetweenForRepo": 154,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   public void write(DataOutput out) throws IOException {\n-    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer\");\n-    ApplicationAttemptId applicationAttemptId \u003d \n-        containerId.getApplicationAttemptId();\n+    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n+    ApplicationAttemptId applicationAttemptId \u003d this.containerId\n+        .getApplicationAttemptId();\n     ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n     out.writeLong(applicationId.getClusterTimestamp());\n     out.writeInt(applicationId.getId());\n     out.writeInt(applicationAttemptId.getAttemptId());\n     out.writeInt(this.containerId.getId());\n-    out.writeUTF(this.nmHostName);\n+    out.writeUTF(this.nmHostAddr);\n     out.writeInt(this.resource.getMemory());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer: \" + this);\n    ApplicationAttemptId applicationAttemptId \u003d this.containerId\n        .getApplicationAttemptId();\n    ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n    out.writeLong(applicationId.getClusterTimestamp());\n    out.writeInt(applicationId.getId());\n    out.writeInt(applicationAttemptId.getAttemptId());\n    out.writeInt(this.containerId.getId());\n    out.writeUTF(this.nmHostAddr);\n    out.writeInt(this.resource.getMemory());\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2896. Simplify all apis to in org.apache.hadoop.yarn.api.records.* to be get/set only. Added javadocs to all public records.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1169980 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/09/11 5:05 PM",
      "commitName": "6165875dc6bf67d72fc3ce1d96dfc80ba312d4a1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 11:35 PM",
      "commitNameOld": "f2b91a8367a762091482074505618b570a520b19",
      "commitAuthorOld": "Sharad Agarwal",
      "daysBetweenCommits": 18.73,
      "commitsBetweenForRepo": 109,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,12 @@\n   public void write(DataOutput out) throws IOException {\n     LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer\");\n-    out.writeInt(this.containerId.getAppId().getId());\n-    out.writeInt(this.containerId.getAppAttemptId().getAttemptId());\n+    ApplicationAttemptId applicationAttemptId \u003d \n+        containerId.getApplicationAttemptId();\n+    ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n+    out.writeLong(applicationId.getClusterTimestamp());\n+    out.writeInt(applicationId.getId());\n+    out.writeInt(applicationAttemptId.getAttemptId());\n     out.writeInt(this.containerId.getId());\n-    // TODO: Cluster time-stamp?\n     out.writeUTF(this.nmHostName);\n-    out.writeInt(this.resource.getMemory()); // TODO: more resources.\n+    out.writeInt(this.resource.getMemory());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer\");\n    ApplicationAttemptId applicationAttemptId \u003d \n        containerId.getApplicationAttemptId();\n    ApplicationId applicationId \u003d applicationAttemptId.getApplicationId();\n    out.writeLong(applicationId.getClusterTimestamp());\n    out.writeInt(applicationId.getId());\n    out.writeInt(applicationAttemptId.getAttemptId());\n    out.writeInt(this.containerId.getId());\n    out.writeUTF(this.nmHostName);\n    out.writeInt(this.resource.getMemory());\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "f2b91a8367a762091482074505618b570a520b19": {
      "type": "Ybodychange",
      "commitMessage": " MAPREDUCE-2807. Fix AM restart and client redirection. Contributed by Sharad Agarwal.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161408 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 11:35 PM",
      "commitName": "f2b91a8367a762091482074505618b570a520b19",
      "commitAuthor": "Sharad Agarwal",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.26,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,9 @@\n   public void write(DataOutput out) throws IOException {\n     LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer\");\n     out.writeInt(this.containerId.getAppId().getId());\n+    out.writeInt(this.containerId.getAppAttemptId().getAttemptId());\n     out.writeInt(this.containerId.getId());\n     // TODO: Cluster time-stamp?\n     out.writeUTF(this.nmHostName);\n     out.writeInt(this.resource.getMemory()); // TODO: more resources.\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer\");\n    out.writeInt(this.containerId.getAppId().getId());\n    out.writeInt(this.containerId.getAppAttemptId().getAttemptId());\n    out.writeInt(this.containerId.getId());\n    // TODO: Cluster time-stamp?\n    out.writeUTF(this.nmHostName);\n    out.writeInt(this.resource.getMemory()); // TODO: more resources.\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer\");\n    out.writeInt(this.containerId.getAppId().getId());\n    out.writeInt(this.containerId.getId());\n    // TODO: Cluster time-stamp?\n    out.writeUTF(this.nmHostName);\n    out.writeInt(this.resource.getMemory()); // TODO: more resources.\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
        "newPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Ymultichange(Ymovefromfile,Yexceptionschange,Ybodychange,Yparameterchange)",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,8 @@\n-    public void write(K key, V value) \n-    throws IOException, InterruptedException {\n-      reporter.progress();\n-      long bytesOutPrev \u003d getOutputBytes(fsStats);\n-      out.write(key, value);\n-      long bytesOutCurr \u003d getOutputBytes(fsStats);\n-      fileOutputByteCounter.increment(bytesOutCurr - bytesOutPrev);\n-      mapOutputRecordCounter.increment(1);\n-    }\n\\ No newline at end of file\n+  public void write(DataOutput out) throws IOException {\n+    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer\");\n+    out.writeInt(this.containerId.getAppId().getId());\n+    out.writeInt(this.containerId.getId());\n+    // TODO: Cluster time-stamp?\n+    out.writeUTF(this.nmHostName);\n+    out.writeInt(this.resource.getMemory()); // TODO: more resources.\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer\");\n    out.writeInt(this.containerId.getAppId().getId());\n    out.writeInt(this.containerId.getId());\n    // TODO: Cluster time-stamp?\n    out.writeUTF(this.nmHostName);\n    out.writeInt(this.resource.getMemory()); // TODO: more resources.\n  }",
          "path": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
          "extendedDetails": {
            "oldPath": "mapreduce/src/java/org/apache/hadoop/mapred/MapTask.java",
            "newPath": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
            "oldMethodName": "write",
            "newMethodName": "write"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,8 @@\n-    public void write(K key, V value) \n-    throws IOException, InterruptedException {\n-      reporter.progress();\n-      long bytesOutPrev \u003d getOutputBytes(fsStats);\n-      out.write(key, value);\n-      long bytesOutCurr \u003d getOutputBytes(fsStats);\n-      fileOutputByteCounter.increment(bytesOutCurr - bytesOutPrev);\n-      mapOutputRecordCounter.increment(1);\n-    }\n\\ No newline at end of file\n+  public void write(DataOutput out) throws IOException {\n+    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer\");\n+    out.writeInt(this.containerId.getAppId().getId());\n+    out.writeInt(this.containerId.getId());\n+    // TODO: Cluster time-stamp?\n+    out.writeUTF(this.nmHostName);\n+    out.writeInt(this.resource.getMemory()); // TODO: more resources.\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer\");\n    out.writeInt(this.containerId.getAppId().getId());\n    out.writeInt(this.containerId.getId());\n    // TODO: Cluster time-stamp?\n    out.writeUTF(this.nmHostName);\n    out.writeInt(this.resource.getMemory()); // TODO: more resources.\n  }",
          "path": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
          "extendedDetails": {
            "oldValue": "[IOException, InterruptedException]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,8 @@\n-    public void write(K key, V value) \n-    throws IOException, InterruptedException {\n-      reporter.progress();\n-      long bytesOutPrev \u003d getOutputBytes(fsStats);\n-      out.write(key, value);\n-      long bytesOutCurr \u003d getOutputBytes(fsStats);\n-      fileOutputByteCounter.increment(bytesOutCurr - bytesOutPrev);\n-      mapOutputRecordCounter.increment(1);\n-    }\n\\ No newline at end of file\n+  public void write(DataOutput out) throws IOException {\n+    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer\");\n+    out.writeInt(this.containerId.getAppId().getId());\n+    out.writeInt(this.containerId.getId());\n+    // TODO: Cluster time-stamp?\n+    out.writeUTF(this.nmHostName);\n+    out.writeInt(this.resource.getMemory()); // TODO: more resources.\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer\");\n    out.writeInt(this.containerId.getAppId().getId());\n    out.writeInt(this.containerId.getId());\n    // TODO: Cluster time-stamp?\n    out.writeUTF(this.nmHostName);\n    out.writeInt(this.resource.getMemory()); // TODO: more resources.\n  }",
          "path": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,8 @@\n-    public void write(K key, V value) \n-    throws IOException, InterruptedException {\n-      reporter.progress();\n-      long bytesOutPrev \u003d getOutputBytes(fsStats);\n-      out.write(key, value);\n-      long bytesOutCurr \u003d getOutputBytes(fsStats);\n-      fileOutputByteCounter.increment(bytesOutCurr - bytesOutPrev);\n-      mapOutputRecordCounter.increment(1);\n-    }\n\\ No newline at end of file\n+  public void write(DataOutput out) throws IOException {\n+    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer\");\n+    out.writeInt(this.containerId.getAppId().getId());\n+    out.writeInt(this.containerId.getId());\n+    // TODO: Cluster time-stamp?\n+    out.writeUTF(this.nmHostName);\n+    out.writeInt(this.resource.getMemory()); // TODO: more resources.\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  public void write(DataOutput out) throws IOException {\n    LOG.debug(\"Writing ContainerTokenIdentifier to RPC layer\");\n    out.writeInt(this.containerId.getAppId().getId());\n    out.writeInt(this.containerId.getId());\n    // TODO: Cluster time-stamp?\n    out.writeUTF(this.nmHostName);\n    out.writeInt(this.resource.getMemory()); // TODO: more resources.\n  }",
          "path": "hadoop-mapreduce/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/security/ContainerTokenIdentifier.java",
          "extendedDetails": {
            "oldValue": "[key-K, value-V]",
            "newValue": "[out-DataOutput]"
          }
        }
      ]
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,4 @@\n+    public void write(K key, V value) throws IOException, InterruptedException {\n+      collector.collect(key, value,\n+                        partitioner.getPartition(key, value, partitions));\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public void write(K key, V value) throws IOException, InterruptedException {\n      collector.collect(key, value,\n                        partitioner.getPartition(key, value, partitions));\n    }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapred/MapTask.java"
    }
  }
}