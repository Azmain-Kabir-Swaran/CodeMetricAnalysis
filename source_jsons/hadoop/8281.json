{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NamenodeWebHdfsMethods.java",
  "functionName": "init",
  "functionId": "init___ugi-UserGroupInformation(modifiers-final)__delegation-DelegationParam(modifiers-final)__username-UserParam(modifiers-final)__doAsUser-DoAsParam(modifiers-final)__path-UriFsPathParam(modifiers-final)__op-HttpOpParam__?__(modifiers-final)__parameters-Param__?,?__(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java",
  "functionStartLine": 152,
  "functionEndLine": 173,
  "numCommitsSeen": 104,
  "timeTaken": 3568,
  "changeHistory": [
    "6e31a090842f8aeedb331b653b075499f8df6c60",
    "85cd06f6636f295ad1f3bf2a90063f4714c9cca7",
    "02d0f0ba549e584f98b4606c7cea325c9c1afb6c",
    "5991ed9cbd18520040159508ef8bd02b7b3bf5e5",
    "09a156fcce2bc1be4081717bf7ef7d290e80d818"
  ],
  "changeHistoryShort": {
    "6e31a090842f8aeedb331b653b075499f8df6c60": "Ymodifierchange",
    "85cd06f6636f295ad1f3bf2a90063f4714c9cca7": "Ybodychange",
    "02d0f0ba549e584f98b4606c7cea325c9c1afb6c": "Ybodychange",
    "5991ed9cbd18520040159508ef8bd02b7b3bf5e5": "Yexceptionschange",
    "09a156fcce2bc1be4081717bf7ef7d290e80d818": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6e31a090842f8aeedb331b653b075499f8df6c60": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-12512. RBF: Add WebHDFS.\n",
      "commitDate": "23/03/18 8:32 AM",
      "commitName": "6e31a090842f8aeedb331b653b075499f8df6c60",
      "commitAuthor": "weiy",
      "commitDateOld": "12/03/18 8:41 PM",
      "commitNameOld": "0355ec20ebeb988679c7192c7024bef7a2a3bced",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 10.49,
      "commitsBetweenForRepo": 212,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n-  private void init(final UserGroupInformation ugi,\n+  protected void init(final UserGroupInformation ugi,\n       final DelegationParam delegation,\n       final UserParam username, final DoAsParam doAsUser,\n       final UriFsPathParam path, final HttpOpParam\u003c?\u003e op,\n       final Param\u003c?, ?\u003e... parameters) {\n     if (useIpcCallq \u003d\u003d null) {\n       Configuration conf \u003d\n           (Configuration)context.getAttribute(JspHelper.CURRENT_CONF);\n       useIpcCallq \u003d conf.getBoolean(\n           DFSConfigKeys.DFS_WEBHDFS_USE_IPC_CALLQ,\n           DFSConfigKeys.DFS_WEBHDFS_USE_IPC_CALLQ_DEFAULT);\n     }\n \n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"HTTP \" + op.getValue().getType() + \": \" + op + \", \" + path\n           + \", ugi\u003d\" + ugi + \", \" + username + \", \" + doAsUser\n           + Param.toSortedString(\", \", parameters));\n     }\n \n     //clear content type\n     response.setContentType(null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void init(final UserGroupInformation ugi,\n      final DelegationParam delegation,\n      final UserParam username, final DoAsParam doAsUser,\n      final UriFsPathParam path, final HttpOpParam\u003c?\u003e op,\n      final Param\u003c?, ?\u003e... parameters) {\n    if (useIpcCallq \u003d\u003d null) {\n      Configuration conf \u003d\n          (Configuration)context.getAttribute(JspHelper.CURRENT_CONF);\n      useIpcCallq \u003d conf.getBoolean(\n          DFSConfigKeys.DFS_WEBHDFS_USE_IPC_CALLQ,\n          DFSConfigKeys.DFS_WEBHDFS_USE_IPC_CALLQ_DEFAULT);\n    }\n\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"HTTP \" + op.getValue().getType() + \": \" + op + \", \" + path\n          + \", ugi\u003d\" + ugi + \", \" + username + \", \" + doAsUser\n          + Param.toSortedString(\", \", parameters));\n    }\n\n    //clear content type\n    response.setContentType(null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java",
      "extendedDetails": {
        "oldValue": "[private]",
        "newValue": "[protected]"
      }
    },
    "85cd06f6636f295ad1f3bf2a90063f4714c9cca7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10789. Route webhdfs through the RPC call queue. Contributed by Daryn Sharp and Rushabh S Shah.\n",
      "commitDate": "12/10/16 1:11 PM",
      "commitName": "85cd06f6636f295ad1f3bf2a90063f4714c9cca7",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "06/09/16 11:02 AM",
      "commitNameOld": "f0d5382ff3e31a47d13e4cb6c3a244cca82b17ce",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 36.09,
      "commitsBetweenForRepo": 241,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,22 @@\n   private void init(final UserGroupInformation ugi,\n       final DelegationParam delegation,\n       final UserParam username, final DoAsParam doAsUser,\n       final UriFsPathParam path, final HttpOpParam\u003c?\u003e op,\n       final Param\u003c?, ?\u003e... parameters) {\n+    if (useIpcCallq \u003d\u003d null) {\n+      Configuration conf \u003d\n+          (Configuration)context.getAttribute(JspHelper.CURRENT_CONF);\n+      useIpcCallq \u003d conf.getBoolean(\n+          DFSConfigKeys.DFS_WEBHDFS_USE_IPC_CALLQ,\n+          DFSConfigKeys.DFS_WEBHDFS_USE_IPC_CALLQ_DEFAULT);\n+    }\n+\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"HTTP \" + op.getValue().getType() + \": \" + op + \", \" + path\n           + \", ugi\u003d\" + ugi + \", \" + username + \", \" + doAsUser\n           + Param.toSortedString(\", \", parameters));\n     }\n \n     //clear content type\n     response.setContentType(null);\n-    \n-    // set the remote address, if coming in via a trust proxy server then\n-    // the address with be that of the proxied client\n-    REMOTE_ADDRESS.set(JspHelper.getRemoteAddr(request));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void init(final UserGroupInformation ugi,\n      final DelegationParam delegation,\n      final UserParam username, final DoAsParam doAsUser,\n      final UriFsPathParam path, final HttpOpParam\u003c?\u003e op,\n      final Param\u003c?, ?\u003e... parameters) {\n    if (useIpcCallq \u003d\u003d null) {\n      Configuration conf \u003d\n          (Configuration)context.getAttribute(JspHelper.CURRENT_CONF);\n      useIpcCallq \u003d conf.getBoolean(\n          DFSConfigKeys.DFS_WEBHDFS_USE_IPC_CALLQ,\n          DFSConfigKeys.DFS_WEBHDFS_USE_IPC_CALLQ_DEFAULT);\n    }\n\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"HTTP \" + op.getValue().getType() + \": \" + op + \", \" + path\n          + \", ugi\u003d\" + ugi + \", \" + username + \", \" + doAsUser\n          + Param.toSortedString(\", \", parameters));\n    }\n\n    //clear content type\n    response.setContentType(null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java",
      "extendedDetails": {}
    },
    "02d0f0ba549e584f98b4606c7cea325c9c1afb6c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6218. Audit log should use true client IP for proxied webhdfs operations. Contributed by Daryn Sharp.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1590640 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/04/14 7:00 AM",
      "commitName": "02d0f0ba549e584f98b4606c7cea325c9c1afb6c",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "19/03/14 10:29 AM",
      "commitNameOld": "7817245d88cb20ece994cc1c5afb3afa0da2661c",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 39.85,
      "commitsBetweenForRepo": 264,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,18 @@\n   private void init(final UserGroupInformation ugi,\n       final DelegationParam delegation,\n       final UserParam username, final DoAsParam doAsUser,\n       final UriFsPathParam path, final HttpOpParam\u003c?\u003e op,\n       final Param\u003c?, ?\u003e... parameters) {\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"HTTP \" + op.getValue().getType() + \": \" + op + \", \" + path\n           + \", ugi\u003d\" + ugi + \", \" + username + \", \" + doAsUser\n           + Param.toSortedString(\", \", parameters));\n     }\n \n     //clear content type\n     response.setContentType(null);\n+    \n+    // set the remote address, if coming in via a trust proxy server then\n+    // the address with be that of the proxied client\n+    REMOTE_ADDRESS.set(JspHelper.getRemoteAddr(request));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void init(final UserGroupInformation ugi,\n      final DelegationParam delegation,\n      final UserParam username, final DoAsParam doAsUser,\n      final UriFsPathParam path, final HttpOpParam\u003c?\u003e op,\n      final Param\u003c?, ?\u003e... parameters) {\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"HTTP \" + op.getValue().getType() + \": \" + op + \", \" + path\n          + \", ugi\u003d\" + ugi + \", \" + username + \", \" + doAsUser\n          + Param.toSortedString(\", \", parameters));\n    }\n\n    //clear content type\n    response.setContentType(null);\n    \n    // set the remote address, if coming in via a trust proxy server then\n    // the address with be that of the proxied client\n    REMOTE_ADDRESS.set(JspHelper.getRemoteAddr(request));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java",
      "extendedDetails": {}
    },
    "5991ed9cbd18520040159508ef8bd02b7b3bf5e5": {
      "type": "Yexceptionschange",
      "commitMessage": "HDFS-3490. DatanodeWebHdfsMethods throws NullPointerException if NamenodeRpcAddressParam is not set. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1348287 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/06/12 5:54 PM",
      "commitName": "5991ed9cbd18520040159508ef8bd02b7b3bf5e5",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "17/04/12 8:25 PM",
      "commitNameOld": "eeec4dc72abf4c540146a81c5419828520b80fa4",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 51.9,
      "commitsBetweenForRepo": 298,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   private void init(final UserGroupInformation ugi,\n       final DelegationParam delegation,\n       final UserParam username, final DoAsParam doAsUser,\n       final UriFsPathParam path, final HttpOpParam\u003c?\u003e op,\n-      final Param\u003c?, ?\u003e... parameters) throws IOException {\n+      final Param\u003c?, ?\u003e... parameters) {\n     if (LOG.isTraceEnabled()) {\n       LOG.trace(\"HTTP \" + op.getValue().getType() + \": \" + op + \", \" + path\n           + \", ugi\u003d\" + ugi + \", \" + username + \", \" + doAsUser\n           + Param.toSortedString(\", \", parameters));\n     }\n \n     //clear content type\n     response.setContentType(null);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void init(final UserGroupInformation ugi,\n      final DelegationParam delegation,\n      final UserParam username, final DoAsParam doAsUser,\n      final UriFsPathParam path, final HttpOpParam\u003c?\u003e op,\n      final Param\u003c?, ?\u003e... parameters) {\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"HTTP \" + op.getValue().getType() + \": \" + op + \", \" + path\n          + \", ugi\u003d\" + ugi + \", \" + username + \", \" + doAsUser\n          + Param.toSortedString(\", \", parameters));\n    }\n\n    //clear content type\n    response.setContentType(null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java",
      "extendedDetails": {
        "oldValue": "[IOException]",
        "newValue": "[]"
      }
    },
    "09a156fcce2bc1be4081717bf7ef7d290e80d818": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2539. Support doAs and GETHOMEDIRECTORY in webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1200731 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/11/11 8:19 PM",
      "commitName": "09a156fcce2bc1be4081717bf7ef7d290e80d818",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,14 @@\n+  private void init(final UserGroupInformation ugi,\n+      final DelegationParam delegation,\n+      final UserParam username, final DoAsParam doAsUser,\n+      final UriFsPathParam path, final HttpOpParam\u003c?\u003e op,\n+      final Param\u003c?, ?\u003e... parameters) throws IOException {\n+    if (LOG.isTraceEnabled()) {\n+      LOG.trace(\"HTTP \" + op.getValue().getType() + \": \" + op + \", \" + path\n+          + \", ugi\u003d\" + ugi + \", \" + username + \", \" + doAsUser\n+          + Param.toSortedString(\", \", parameters));\n+    }\n+\n+    //clear content type\n+    response.setContentType(null);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void init(final UserGroupInformation ugi,\n      final DelegationParam delegation,\n      final UserParam username, final DoAsParam doAsUser,\n      final UriFsPathParam path, final HttpOpParam\u003c?\u003e op,\n      final Param\u003c?, ?\u003e... parameters) throws IOException {\n    if (LOG.isTraceEnabled()) {\n      LOG.trace(\"HTTP \" + op.getValue().getType() + \": \" + op + \", \" + path\n          + \", ugi\u003d\" + ugi + \", \" + username + \", \" + doAsUser\n          + Param.toSortedString(\", \", parameters));\n    }\n\n    //clear content type\n    response.setContentType(null);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.java"
    }
  }
}