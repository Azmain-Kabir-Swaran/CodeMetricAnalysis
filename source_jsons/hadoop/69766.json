{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ReadBufferManager.java",
  "functionName": "queueReadAhead",
  "functionId": "queueReadAhead___stream-AbfsInputStream(modifiers-final)__requestedOffset-long(modifiers-final)__requestedLength-int(modifiers-final)",
  "sourceFilePath": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java",
  "functionStartLine": 98,
  "functionEndLine": 131,
  "numCommitsSeen": 3,
  "timeTaken": 890,
  "changeHistory": [
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be",
    "f044deedbbfee0812316d587139cb828f27172e9"
  ],
  "changeHistoryShort": {
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be": "Ybodychange",
    "f044deedbbfee0812316d587139cb828f27172e9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15446. ABFS: tune imports \u0026 javadocs; stabilise tests.\nContributed by Steve Loughran and Da Zhou.\n",
      "commitDate": "17/09/18 12:54 PM",
      "commitName": "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be",
      "commitAuthor": "Thomas Marquardt",
      "commitDateOld": "17/09/18 12:54 PM",
      "commitNameOld": "f044deedbbfee0812316d587139cb828f27172e9",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n   void queueReadAhead(final AbfsInputStream stream, final long requestedOffset, final int requestedLength) {\n     if (LOGGER.isTraceEnabled()) {\n-      LOGGER.trace(\"Start Queueing readAhead for \" + stream.getPath() + \" offset \" + requestedOffset\n-          + \" length \" + requestedLength);\n+      LOGGER.trace(\"Start Queueing readAhead for {} offset {} length {}\",\n+          stream.getPath(), requestedOffset, requestedLength);\n     }\n     ReadBuffer buffer;\n     synchronized (this) {\n       if (isAlreadyQueued(stream, requestedOffset)) {\n         return; // already queued, do not queue again\n       }\n-      if (freeList.size() \u003d\u003d 0 \u0026\u0026 !tryEvict()) {\n+      if (freeList.isEmpty() \u0026\u0026 !tryEvict()) {\n         return; // no buffers available, cannot queue anything\n       }\n \n       buffer \u003d new ReadBuffer();\n       buffer.setStream(stream);\n       buffer.setOffset(requestedOffset);\n       buffer.setLength(0);\n       buffer.setRequestedLength(requestedLength);\n       buffer.setStatus(ReadBufferStatus.NOT_AVAILABLE);\n       buffer.setLatch(new CountDownLatch(1));\n \n       Integer bufferIndex \u003d freeList.pop();  // will return a value, since we have checked size \u003e 0 already\n \n       buffer.setBuffer(buffers[bufferIndex]);\n       buffer.setBufferindex(bufferIndex);\n       readAheadQueue.add(buffer);\n       notifyAll();\n     }\n     if (LOGGER.isTraceEnabled()) {\n-      LOGGER.trace(\"Done q-ing readAhead for file \" + stream.getPath() + \" offset \" + requestedOffset\n-          + \" buffer idx \" + buffer.getBufferindex());\n+      LOGGER.trace(\"Done q-ing readAhead for file {} offset {} buffer idx {}\",\n+          stream.getPath(), requestedOffset, buffer.getBufferindex());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void queueReadAhead(final AbfsInputStream stream, final long requestedOffset, final int requestedLength) {\n    if (LOGGER.isTraceEnabled()) {\n      LOGGER.trace(\"Start Queueing readAhead for {} offset {} length {}\",\n          stream.getPath(), requestedOffset, requestedLength);\n    }\n    ReadBuffer buffer;\n    synchronized (this) {\n      if (isAlreadyQueued(stream, requestedOffset)) {\n        return; // already queued, do not queue again\n      }\n      if (freeList.isEmpty() \u0026\u0026 !tryEvict()) {\n        return; // no buffers available, cannot queue anything\n      }\n\n      buffer \u003d new ReadBuffer();\n      buffer.setStream(stream);\n      buffer.setOffset(requestedOffset);\n      buffer.setLength(0);\n      buffer.setRequestedLength(requestedLength);\n      buffer.setStatus(ReadBufferStatus.NOT_AVAILABLE);\n      buffer.setLatch(new CountDownLatch(1));\n\n      Integer bufferIndex \u003d freeList.pop();  // will return a value, since we have checked size \u003e 0 already\n\n      buffer.setBuffer(buffers[bufferIndex]);\n      buffer.setBufferindex(bufferIndex);\n      readAheadQueue.add(buffer);\n      notifyAll();\n    }\n    if (LOGGER.isTraceEnabled()) {\n      LOGGER.trace(\"Done q-ing readAhead for file {} offset {} buffer idx {}\",\n          stream.getPath(), requestedOffset, buffer.getBufferindex());\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java",
      "extendedDetails": {}
    },
    "f044deedbbfee0812316d587139cb828f27172e9": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-15407. HADOOP-15540. Support Windows Azure Storage - Blob file system \"ABFS\" in Hadoop: Core Commit.\n\nContributed by Shane Mainali, Thomas Marquardt, Zichen Sun, Georgi Chalakov, Esfandiar Manii, Amit Singh, Dana Kaban, Da Zhou, Junhua Gu, Saher Ahwal, Saurabh Pant, James Baker, Shaoyu Zhang, Lawrence Chen, Kevin Chen and Steve Loughran\n",
      "commitDate": "17/09/18 12:54 PM",
      "commitName": "f044deedbbfee0812316d587139cb828f27172e9",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,34 @@\n+  void queueReadAhead(final AbfsInputStream stream, final long requestedOffset, final int requestedLength) {\n+    if (LOGGER.isTraceEnabled()) {\n+      LOGGER.trace(\"Start Queueing readAhead for \" + stream.getPath() + \" offset \" + requestedOffset\n+          + \" length \" + requestedLength);\n+    }\n+    ReadBuffer buffer;\n+    synchronized (this) {\n+      if (isAlreadyQueued(stream, requestedOffset)) {\n+        return; // already queued, do not queue again\n+      }\n+      if (freeList.size() \u003d\u003d 0 \u0026\u0026 !tryEvict()) {\n+        return; // no buffers available, cannot queue anything\n+      }\n+\n+      buffer \u003d new ReadBuffer();\n+      buffer.setStream(stream);\n+      buffer.setOffset(requestedOffset);\n+      buffer.setLength(0);\n+      buffer.setRequestedLength(requestedLength);\n+      buffer.setStatus(ReadBufferStatus.NOT_AVAILABLE);\n+      buffer.setLatch(new CountDownLatch(1));\n+\n+      Integer bufferIndex \u003d freeList.pop();  // will return a value, since we have checked size \u003e 0 already\n+\n+      buffer.setBuffer(buffers[bufferIndex]);\n+      buffer.setBufferindex(bufferIndex);\n+      readAheadQueue.add(buffer);\n+      notifyAll();\n+    }\n+    if (LOGGER.isTraceEnabled()) {\n+      LOGGER.trace(\"Done q-ing readAhead for file \" + stream.getPath() + \" offset \" + requestedOffset\n+          + \" buffer idx \" + buffer.getBufferindex());\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void queueReadAhead(final AbfsInputStream stream, final long requestedOffset, final int requestedLength) {\n    if (LOGGER.isTraceEnabled()) {\n      LOGGER.trace(\"Start Queueing readAhead for \" + stream.getPath() + \" offset \" + requestedOffset\n          + \" length \" + requestedLength);\n    }\n    ReadBuffer buffer;\n    synchronized (this) {\n      if (isAlreadyQueued(stream, requestedOffset)) {\n        return; // already queued, do not queue again\n      }\n      if (freeList.size() \u003d\u003d 0 \u0026\u0026 !tryEvict()) {\n        return; // no buffers available, cannot queue anything\n      }\n\n      buffer \u003d new ReadBuffer();\n      buffer.setStream(stream);\n      buffer.setOffset(requestedOffset);\n      buffer.setLength(0);\n      buffer.setRequestedLength(requestedLength);\n      buffer.setStatus(ReadBufferStatus.NOT_AVAILABLE);\n      buffer.setLatch(new CountDownLatch(1));\n\n      Integer bufferIndex \u003d freeList.pop();  // will return a value, since we have checked size \u003e 0 already\n\n      buffer.setBuffer(buffers[bufferIndex]);\n      buffer.setBufferindex(bufferIndex);\n      readAheadQueue.add(buffer);\n      notifyAll();\n    }\n    if (LOGGER.isTraceEnabled()) {\n      LOGGER.trace(\"Done q-ing readAhead for file \" + stream.getPath() + \" offset \" + requestedOffset\n          + \" buffer idx \" + buffer.getBufferindex());\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java"
    }
  }
}