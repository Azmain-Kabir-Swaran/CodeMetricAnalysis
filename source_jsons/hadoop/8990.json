{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSNamesystem.java",
  "functionName": "getStorageDirs",
  "functionId": "getStorageDirs___conf-Configuration__propertyName-String",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
  "functionStartLine": 1596,
  "functionEndLine": 1625,
  "numCommitsSeen": 899,
  "timeTaken": 50346,
  "changeHistory": [
    "969e84decbc976bd98f1050aead695d15a024ab6",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "5d5b1c6c10c66c6a17b483a3e1a98d59d3d0bdee",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "969e84decbc976bd98f1050aead695d15a024ab6": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "5d5b1c6c10c66c6a17b483a3e1a98d59d3d0bdee": "Ymodifierchange",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "969e84decbc976bd98f1050aead695d15a024ab6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4342. Directories configured in dfs.namenode.edits.dir.required but not in dfs.namenode.edits.dir are silently ignored.  Contributed by Arpit Agarwal\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1445006 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/02/13 4:50 PM",
      "commitName": "969e84decbc976bd98f1050aead695d15a024ab6",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "06/02/13 11:52 AM",
      "commitNameOld": "4525c4a25ba90163c9543116e2bd54239e0dd097",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 5.21,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,30 @@\n   private static Collection\u003cURI\u003e getStorageDirs(Configuration conf,\n                                                 String propertyName) {\n     Collection\u003cString\u003e dirNames \u003d conf.getTrimmedStringCollection(propertyName);\n     StartupOption startOpt \u003d NameNode.getStartupOption(conf);\n     if(startOpt \u003d\u003d StartupOption.IMPORT) {\n       // In case of IMPORT this will get rid of default directories \n       // but will retain directories specified in hdfs-site.xml\n       // When importing image from a checkpoint, the name-node can\n       // start with empty set of storage directories.\n       Configuration cE \u003d new HdfsConfiguration(false);\n       cE.addResource(\"core-default.xml\");\n       cE.addResource(\"core-site.xml\");\n       cE.addResource(\"hdfs-default.xml\");\n       Collection\u003cString\u003e dirNames2 \u003d cE.getTrimmedStringCollection(propertyName);\n       dirNames.removeAll(dirNames2);\n       if(dirNames.isEmpty())\n         LOG.warn(\"!!! WARNING !!!\" +\n           \"\\n\\tThe NameNode currently runs without persistent storage.\" +\n           \"\\n\\tAny changes to the file system meta-data may be lost.\" +\n           \"\\n\\tRecommended actions:\" +\n           \"\\n\\t\\t- shutdown and restart NameNode with configured \\\"\" \n           + propertyName + \"\\\" in hdfs-site.xml;\" +\n           \"\\n\\t\\t- use Backup Node as a persistent and up-to-date storage \" +\n           \"of the file system meta-data.\");\n     } else if (dirNames.isEmpty()) {\n-      dirNames \u003d Collections.singletonList(\"file:///tmp/hadoop/dfs/name\");\n+      dirNames \u003d Collections.singletonList(\n+          DFSConfigKeys.DFS_NAMENODE_EDITS_DIR_DEFAULT);\n     }\n     return Util.stringCollectionAsURIs(dirNames);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static Collection\u003cURI\u003e getStorageDirs(Configuration conf,\n                                                String propertyName) {\n    Collection\u003cString\u003e dirNames \u003d conf.getTrimmedStringCollection(propertyName);\n    StartupOption startOpt \u003d NameNode.getStartupOption(conf);\n    if(startOpt \u003d\u003d StartupOption.IMPORT) {\n      // In case of IMPORT this will get rid of default directories \n      // but will retain directories specified in hdfs-site.xml\n      // When importing image from a checkpoint, the name-node can\n      // start with empty set of storage directories.\n      Configuration cE \u003d new HdfsConfiguration(false);\n      cE.addResource(\"core-default.xml\");\n      cE.addResource(\"core-site.xml\");\n      cE.addResource(\"hdfs-default.xml\");\n      Collection\u003cString\u003e dirNames2 \u003d cE.getTrimmedStringCollection(propertyName);\n      dirNames.removeAll(dirNames2);\n      if(dirNames.isEmpty())\n        LOG.warn(\"!!! WARNING !!!\" +\n          \"\\n\\tThe NameNode currently runs without persistent storage.\" +\n          \"\\n\\tAny changes to the file system meta-data may be lost.\" +\n          \"\\n\\tRecommended actions:\" +\n          \"\\n\\t\\t- shutdown and restart NameNode with configured \\\"\" \n          + propertyName + \"\\\" in hdfs-site.xml;\" +\n          \"\\n\\t\\t- use Backup Node as a persistent and up-to-date storage \" +\n          \"of the file system meta-data.\");\n    } else if (dirNames.isEmpty()) {\n      dirNames \u003d Collections.singletonList(\n          DFSConfigKeys.DFS_NAMENODE_EDITS_DIR_DEFAULT);\n    }\n    return Util.stringCollectionAsURIs(dirNames);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private static Collection\u003cURI\u003e getStorageDirs(Configuration conf,\n                                                String propertyName) {\n    Collection\u003cString\u003e dirNames \u003d conf.getTrimmedStringCollection(propertyName);\n    StartupOption startOpt \u003d NameNode.getStartupOption(conf);\n    if(startOpt \u003d\u003d StartupOption.IMPORT) {\n      // In case of IMPORT this will get rid of default directories \n      // but will retain directories specified in hdfs-site.xml\n      // When importing image from a checkpoint, the name-node can\n      // start with empty set of storage directories.\n      Configuration cE \u003d new HdfsConfiguration(false);\n      cE.addResource(\"core-default.xml\");\n      cE.addResource(\"core-site.xml\");\n      cE.addResource(\"hdfs-default.xml\");\n      Collection\u003cString\u003e dirNames2 \u003d cE.getTrimmedStringCollection(propertyName);\n      dirNames.removeAll(dirNames2);\n      if(dirNames.isEmpty())\n        LOG.warn(\"!!! WARNING !!!\" +\n          \"\\n\\tThe NameNode currently runs without persistent storage.\" +\n          \"\\n\\tAny changes to the file system meta-data may be lost.\" +\n          \"\\n\\tRecommended actions:\" +\n          \"\\n\\t\\t- shutdown and restart NameNode with configured \\\"\" \n          + propertyName + \"\\\" in hdfs-site.xml;\" +\n          \"\\n\\t\\t- use Backup Node as a persistent and up-to-date storage \" +\n          \"of the file system meta-data.\");\n    } else if (dirNames.isEmpty()) {\n      dirNames \u003d Collections.singletonList(\"file:///tmp/hadoop/dfs/name\");\n    }\n    return Util.stringCollectionAsURIs(dirNames);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private static Collection\u003cURI\u003e getStorageDirs(Configuration conf,\n                                                String propertyName) {\n    Collection\u003cString\u003e dirNames \u003d conf.getTrimmedStringCollection(propertyName);\n    StartupOption startOpt \u003d NameNode.getStartupOption(conf);\n    if(startOpt \u003d\u003d StartupOption.IMPORT) {\n      // In case of IMPORT this will get rid of default directories \n      // but will retain directories specified in hdfs-site.xml\n      // When importing image from a checkpoint, the name-node can\n      // start with empty set of storage directories.\n      Configuration cE \u003d new HdfsConfiguration(false);\n      cE.addResource(\"core-default.xml\");\n      cE.addResource(\"core-site.xml\");\n      cE.addResource(\"hdfs-default.xml\");\n      Collection\u003cString\u003e dirNames2 \u003d cE.getTrimmedStringCollection(propertyName);\n      dirNames.removeAll(dirNames2);\n      if(dirNames.isEmpty())\n        LOG.warn(\"!!! WARNING !!!\" +\n          \"\\n\\tThe NameNode currently runs without persistent storage.\" +\n          \"\\n\\tAny changes to the file system meta-data may be lost.\" +\n          \"\\n\\tRecommended actions:\" +\n          \"\\n\\t\\t- shutdown and restart NameNode with configured \\\"\" \n          + propertyName + \"\\\" in hdfs-site.xml;\" +\n          \"\\n\\t\\t- use Backup Node as a persistent and up-to-date storage \" +\n          \"of the file system meta-data.\");\n    } else if (dirNames.isEmpty()) {\n      dirNames \u003d Collections.singletonList(\"file:///tmp/hadoop/dfs/name\");\n    }\n    return Util.stringCollectionAsURIs(dirNames);\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
      }
    },
    "5d5b1c6c10c66c6a17b483a3e1a98d59d3d0bdee": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-2239. Reduce access levels of the fields and methods in FSNamesystem.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1155998 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/08/11 6:50 PM",
      "commitName": "5d5b1c6c10c66c6a17b483a3e1a98d59d3d0bdee",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "08/08/11 3:06 AM",
      "commitNameOld": "371f4a59059322000a40eb4bdf5386b96b626ece",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 1.66,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,29 +1,29 @@\n-  public static Collection\u003cURI\u003e getStorageDirs(Configuration conf,\n+  private static Collection\u003cURI\u003e getStorageDirs(Configuration conf,\n                                                 String propertyName) {\n     Collection\u003cString\u003e dirNames \u003d conf.getTrimmedStringCollection(propertyName);\n     StartupOption startOpt \u003d NameNode.getStartupOption(conf);\n     if(startOpt \u003d\u003d StartupOption.IMPORT) {\n       // In case of IMPORT this will get rid of default directories \n       // but will retain directories specified in hdfs-site.xml\n       // When importing image from a checkpoint, the name-node can\n       // start with empty set of storage directories.\n       Configuration cE \u003d new HdfsConfiguration(false);\n       cE.addResource(\"core-default.xml\");\n       cE.addResource(\"core-site.xml\");\n       cE.addResource(\"hdfs-default.xml\");\n       Collection\u003cString\u003e dirNames2 \u003d cE.getTrimmedStringCollection(propertyName);\n       dirNames.removeAll(dirNames2);\n       if(dirNames.isEmpty())\n         LOG.warn(\"!!! WARNING !!!\" +\n           \"\\n\\tThe NameNode currently runs without persistent storage.\" +\n           \"\\n\\tAny changes to the file system meta-data may be lost.\" +\n           \"\\n\\tRecommended actions:\" +\n           \"\\n\\t\\t- shutdown and restart NameNode with configured \\\"\" \n           + propertyName + \"\\\" in hdfs-site.xml;\" +\n           \"\\n\\t\\t- use Backup Node as a persistent and up-to-date storage \" +\n           \"of the file system meta-data.\");\n     } else if (dirNames.isEmpty()) {\n       dirNames \u003d Collections.singletonList(\"file:///tmp/hadoop/dfs/name\");\n     }\n     return Util.stringCollectionAsURIs(dirNames);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static Collection\u003cURI\u003e getStorageDirs(Configuration conf,\n                                                String propertyName) {\n    Collection\u003cString\u003e dirNames \u003d conf.getTrimmedStringCollection(propertyName);\n    StartupOption startOpt \u003d NameNode.getStartupOption(conf);\n    if(startOpt \u003d\u003d StartupOption.IMPORT) {\n      // In case of IMPORT this will get rid of default directories \n      // but will retain directories specified in hdfs-site.xml\n      // When importing image from a checkpoint, the name-node can\n      // start with empty set of storage directories.\n      Configuration cE \u003d new HdfsConfiguration(false);\n      cE.addResource(\"core-default.xml\");\n      cE.addResource(\"core-site.xml\");\n      cE.addResource(\"hdfs-default.xml\");\n      Collection\u003cString\u003e dirNames2 \u003d cE.getTrimmedStringCollection(propertyName);\n      dirNames.removeAll(dirNames2);\n      if(dirNames.isEmpty())\n        LOG.warn(\"!!! WARNING !!!\" +\n          \"\\n\\tThe NameNode currently runs without persistent storage.\" +\n          \"\\n\\tAny changes to the file system meta-data may be lost.\" +\n          \"\\n\\tRecommended actions:\" +\n          \"\\n\\t\\t- shutdown and restart NameNode with configured \\\"\" \n          + propertyName + \"\\\" in hdfs-site.xml;\" +\n          \"\\n\\t\\t- use Backup Node as a persistent and up-to-date storage \" +\n          \"of the file system meta-data.\");\n    } else if (dirNames.isEmpty()) {\n      dirNames \u003d Collections.singletonList(\"file:///tmp/hadoop/dfs/name\");\n    }\n    return Util.stringCollectionAsURIs(dirNames);\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {
        "oldValue": "[public, static]",
        "newValue": "[private, static]"
      }
    },
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/11 9:28 AM",
      "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "26/07/11 10:59 PM",
      "commitNameOld": "0b12cc822ddd57e6ecf4f7047f6614419c34580b",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 2.44,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,29 @@\n   public static Collection\u003cURI\u003e getStorageDirs(Configuration conf,\n                                                 String propertyName) {\n     Collection\u003cString\u003e dirNames \u003d conf.getTrimmedStringCollection(propertyName);\n     StartupOption startOpt \u003d NameNode.getStartupOption(conf);\n     if(startOpt \u003d\u003d StartupOption.IMPORT) {\n       // In case of IMPORT this will get rid of default directories \n       // but will retain directories specified in hdfs-site.xml\n       // When importing image from a checkpoint, the name-node can\n       // start with empty set of storage directories.\n       Configuration cE \u003d new HdfsConfiguration(false);\n       cE.addResource(\"core-default.xml\");\n       cE.addResource(\"core-site.xml\");\n       cE.addResource(\"hdfs-default.xml\");\n       Collection\u003cString\u003e dirNames2 \u003d cE.getTrimmedStringCollection(propertyName);\n       dirNames.removeAll(dirNames2);\n       if(dirNames.isEmpty())\n         LOG.warn(\"!!! WARNING !!!\" +\n           \"\\n\\tThe NameNode currently runs without persistent storage.\" +\n           \"\\n\\tAny changes to the file system meta-data may be lost.\" +\n           \"\\n\\tRecommended actions:\" +\n           \"\\n\\t\\t- shutdown and restart NameNode with configured \\\"\" \n           + propertyName + \"\\\" in hdfs-site.xml;\" +\n           \"\\n\\t\\t- use Backup Node as a persistent and up-to-date storage \" +\n           \"of the file system meta-data.\");\n-    } else if (dirNames.isEmpty())\n-      dirNames.add(\"file:///tmp/hadoop/dfs/name\");\n+    } else if (dirNames.isEmpty()) {\n+      dirNames \u003d Collections.singletonList(\"file:///tmp/hadoop/dfs/name\");\n+    }\n     return Util.stringCollectionAsURIs(dirNames);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static Collection\u003cURI\u003e getStorageDirs(Configuration conf,\n                                                String propertyName) {\n    Collection\u003cString\u003e dirNames \u003d conf.getTrimmedStringCollection(propertyName);\n    StartupOption startOpt \u003d NameNode.getStartupOption(conf);\n    if(startOpt \u003d\u003d StartupOption.IMPORT) {\n      // In case of IMPORT this will get rid of default directories \n      // but will retain directories specified in hdfs-site.xml\n      // When importing image from a checkpoint, the name-node can\n      // start with empty set of storage directories.\n      Configuration cE \u003d new HdfsConfiguration(false);\n      cE.addResource(\"core-default.xml\");\n      cE.addResource(\"core-site.xml\");\n      cE.addResource(\"hdfs-default.xml\");\n      Collection\u003cString\u003e dirNames2 \u003d cE.getTrimmedStringCollection(propertyName);\n      dirNames.removeAll(dirNames2);\n      if(dirNames.isEmpty())\n        LOG.warn(\"!!! WARNING !!!\" +\n          \"\\n\\tThe NameNode currently runs without persistent storage.\" +\n          \"\\n\\tAny changes to the file system meta-data may be lost.\" +\n          \"\\n\\tRecommended actions:\" +\n          \"\\n\\t\\t- shutdown and restart NameNode with configured \\\"\" \n          + propertyName + \"\\\" in hdfs-site.xml;\" +\n          \"\\n\\t\\t- use Backup Node as a persistent and up-to-date storage \" +\n          \"of the file system meta-data.\");\n    } else if (dirNames.isEmpty()) {\n      dirNames \u003d Collections.singletonList(\"file:///tmp/hadoop/dfs/name\");\n    }\n    return Util.stringCollectionAsURIs(dirNames);\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,28 @@\n+  public static Collection\u003cURI\u003e getStorageDirs(Configuration conf,\n+                                                String propertyName) {\n+    Collection\u003cString\u003e dirNames \u003d conf.getTrimmedStringCollection(propertyName);\n+    StartupOption startOpt \u003d NameNode.getStartupOption(conf);\n+    if(startOpt \u003d\u003d StartupOption.IMPORT) {\n+      // In case of IMPORT this will get rid of default directories \n+      // but will retain directories specified in hdfs-site.xml\n+      // When importing image from a checkpoint, the name-node can\n+      // start with empty set of storage directories.\n+      Configuration cE \u003d new HdfsConfiguration(false);\n+      cE.addResource(\"core-default.xml\");\n+      cE.addResource(\"core-site.xml\");\n+      cE.addResource(\"hdfs-default.xml\");\n+      Collection\u003cString\u003e dirNames2 \u003d cE.getTrimmedStringCollection(propertyName);\n+      dirNames.removeAll(dirNames2);\n+      if(dirNames.isEmpty())\n+        LOG.warn(\"!!! WARNING !!!\" +\n+          \"\\n\\tThe NameNode currently runs without persistent storage.\" +\n+          \"\\n\\tAny changes to the file system meta-data may be lost.\" +\n+          \"\\n\\tRecommended actions:\" +\n+          \"\\n\\t\\t- shutdown and restart NameNode with configured \\\"\" \n+          + propertyName + \"\\\" in hdfs-site.xml;\" +\n+          \"\\n\\t\\t- use Backup Node as a persistent and up-to-date storage \" +\n+          \"of the file system meta-data.\");\n+    } else if (dirNames.isEmpty())\n+      dirNames.add(\"file:///tmp/hadoop/dfs/name\");\n+    return Util.stringCollectionAsURIs(dirNames);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static Collection\u003cURI\u003e getStorageDirs(Configuration conf,\n                                                String propertyName) {\n    Collection\u003cString\u003e dirNames \u003d conf.getTrimmedStringCollection(propertyName);\n    StartupOption startOpt \u003d NameNode.getStartupOption(conf);\n    if(startOpt \u003d\u003d StartupOption.IMPORT) {\n      // In case of IMPORT this will get rid of default directories \n      // but will retain directories specified in hdfs-site.xml\n      // When importing image from a checkpoint, the name-node can\n      // start with empty set of storage directories.\n      Configuration cE \u003d new HdfsConfiguration(false);\n      cE.addResource(\"core-default.xml\");\n      cE.addResource(\"core-site.xml\");\n      cE.addResource(\"hdfs-default.xml\");\n      Collection\u003cString\u003e dirNames2 \u003d cE.getTrimmedStringCollection(propertyName);\n      dirNames.removeAll(dirNames2);\n      if(dirNames.isEmpty())\n        LOG.warn(\"!!! WARNING !!!\" +\n          \"\\n\\tThe NameNode currently runs without persistent storage.\" +\n          \"\\n\\tAny changes to the file system meta-data may be lost.\" +\n          \"\\n\\tRecommended actions:\" +\n          \"\\n\\t\\t- shutdown and restart NameNode with configured \\\"\" \n          + propertyName + \"\\\" in hdfs-site.xml;\" +\n          \"\\n\\t\\t- use Backup Node as a persistent and up-to-date storage \" +\n          \"of the file system meta-data.\");\n    } else if (dirNames.isEmpty())\n      dirNames.add(\"file:///tmp/hadoop/dfs/name\");\n    return Util.stringCollectionAsURIs(dirNames);\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}