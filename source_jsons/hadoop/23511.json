{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HistoryFileManager.java",
  "functionName": "addDirectoryToJobListCache",
  "functionId": "addDirectoryToJobListCache___path-Path",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
  "functionStartLine": 851,
  "functionEndLine": 872,
  "numCommitsSeen": 57,
  "timeTaken": 8076,
  "changeHistory": [
    "5ffb54694b52657f3b7de4560474ab740734e1b2",
    "7d04a96027ad75877b41b7cd8f67455dd13159d7",
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
    "be32d25c546a7d4f98604e142940c483213b485b",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "5ffb54694b52657f3b7de4560474ab740734e1b2": "Ybodychange",
    "7d04a96027ad75877b41b7cd8f67455dd13159d7": "Ybodychange",
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f": "Ymultichange(Ymovefromfile,Ybodychange)",
    "be32d25c546a7d4f98604e142940c483213b485b": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "5ffb54694b52657f3b7de4560474ab740734e1b2": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6684. High contention on scanning of user directory under immediate_done in Job History Server. Contributed by Haibo Chen\n",
      "commitDate": "10/05/16 9:03 AM",
      "commitName": "5ffb54694b52657f3b7de4560474ab740734e1b2",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "20/04/16 7:02 PM",
      "commitNameOld": "1e48eefe5800975ea0c4295c9911ae3f572ed37d",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 19.58,
      "commitsBetweenForRepo": 113,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   private void addDirectoryToJobListCache(Path path) throws IOException {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"Adding \" + path + \" to job list cache.\");\n     }\n     List\u003cFileStatus\u003e historyFileList \u003d scanDirectoryForHistoryFiles(path,\n         doneDirFc);\n     for (FileStatus fs : historyFileList) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Adding in history for \" + fs.getPath());\n       }\n       JobIndexInfo jobIndexInfo \u003d FileNameIndexUtils.getIndexInfo(fs.getPath()\n           .getName());\n       String confFileName \u003d JobHistoryUtils\n           .getIntermediateConfFileName(jobIndexInfo.getJobId());\n       String summaryFileName \u003d JobHistoryUtils\n           .getIntermediateSummaryFileName(jobIndexInfo.getJobId());\n-      HistoryFileInfo fileInfo \u003d new HistoryFileInfo(fs.getPath(), new Path(fs\n+      HistoryFileInfo fileInfo \u003d createHistoryFileInfo(fs.getPath(), new Path(fs\n           .getPath().getParent(), confFileName), new Path(fs.getPath()\n           .getParent(), summaryFileName), jobIndexInfo, true);\n       jobListCache.addIfAbsent(fileInfo);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addDirectoryToJobListCache(Path path) throws IOException {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Adding \" + path + \" to job list cache.\");\n    }\n    List\u003cFileStatus\u003e historyFileList \u003d scanDirectoryForHistoryFiles(path,\n        doneDirFc);\n    for (FileStatus fs : historyFileList) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Adding in history for \" + fs.getPath());\n      }\n      JobIndexInfo jobIndexInfo \u003d FileNameIndexUtils.getIndexInfo(fs.getPath()\n          .getName());\n      String confFileName \u003d JobHistoryUtils\n          .getIntermediateConfFileName(jobIndexInfo.getJobId());\n      String summaryFileName \u003d JobHistoryUtils\n          .getIntermediateSummaryFileName(jobIndexInfo.getJobId());\n      HistoryFileInfo fileInfo \u003d createHistoryFileInfo(fs.getPath(), new Path(fs\n          .getPath().getParent(), confFileName), new Path(fs.getPath()\n          .getParent(), summaryFileName), jobIndexInfo, true);\n      jobListCache.addIfAbsent(fileInfo);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
      "extendedDetails": {}
    },
    "7d04a96027ad75877b41b7cd8f67455dd13159d7": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3972. Fix locking and exception issues in JobHistory server. (Contributed by Robert Joseph Evans)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1327354 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/04/12 6:59 PM",
      "commitName": "7d04a96027ad75877b41b7cd8f67455dd13159d7",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "10/04/12 11:11 AM",
      "commitNameOld": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
      "commitAuthorOld": "Thomas Graves",
      "daysBetweenCommits": 7.32,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   private void addDirectoryToJobListCache(Path path) throws IOException {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"Adding \" + path + \" to job list cache.\");\n     }\n     List\u003cFileStatus\u003e historyFileList \u003d scanDirectoryForHistoryFiles(path,\n         doneDirFc);\n     for (FileStatus fs : historyFileList) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Adding in history for \" + fs.getPath());\n       }\n       JobIndexInfo jobIndexInfo \u003d FileNameIndexUtils.getIndexInfo(fs.getPath()\n           .getName());\n       String confFileName \u003d JobHistoryUtils\n           .getIntermediateConfFileName(jobIndexInfo.getJobId());\n       String summaryFileName \u003d JobHistoryUtils\n           .getIntermediateSummaryFileName(jobIndexInfo.getJobId());\n-      MetaInfo metaInfo \u003d new MetaInfo(fs.getPath(), new Path(fs.getPath()\n-          .getParent(), confFileName), new Path(fs.getPath().getParent(),\n-          summaryFileName), jobIndexInfo);\n-      addToJobListCache(metaInfo);\n+      HistoryFileInfo fileInfo \u003d new HistoryFileInfo(fs.getPath(), new Path(fs\n+          .getPath().getParent(), confFileName), new Path(fs.getPath()\n+          .getParent(), summaryFileName), jobIndexInfo, true);\n+      jobListCache.addIfAbsent(fileInfo);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addDirectoryToJobListCache(Path path) throws IOException {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Adding \" + path + \" to job list cache.\");\n    }\n    List\u003cFileStatus\u003e historyFileList \u003d scanDirectoryForHistoryFiles(path,\n        doneDirFc);\n    for (FileStatus fs : historyFileList) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Adding in history for \" + fs.getPath());\n      }\n      JobIndexInfo jobIndexInfo \u003d FileNameIndexUtils.getIndexInfo(fs.getPath()\n          .getName());\n      String confFileName \u003d JobHistoryUtils\n          .getIntermediateConfFileName(jobIndexInfo.getJobId());\n      String summaryFileName \u003d JobHistoryUtils\n          .getIntermediateSummaryFileName(jobIndexInfo.getJobId());\n      HistoryFileInfo fileInfo \u003d new HistoryFileInfo(fs.getPath(), new Path(fs\n          .getPath().getParent(), confFileName), new Path(fs.getPath()\n          .getParent(), summaryFileName), jobIndexInfo, true);\n      jobListCache.addIfAbsent(fileInfo);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
      "extendedDetails": {}
    },
    "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311896 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/04/12 11:11 AM",
      "commitName": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
      "commitAuthor": "Thomas Graves",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311896 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/04/12 11:11 AM",
          "commitName": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
          "commitAuthor": "Thomas Graves",
          "commitDateOld": "10/04/12 9:13 AM",
          "commitNameOld": "000859a534f4cc6a57524a676805d8af6ad199de",
          "commitAuthorOld": "Robert Joseph Evans",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,22 @@\n   private void addDirectoryToJobListCache(Path path) throws IOException {\n-    if(LOG.isDebugEnabled()) {\n-      LOG.debug(\"Adding \"+path+\" to job list cache.\");\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Adding \" + path + \" to job list cache.\");\n     }\n     List\u003cFileStatus\u003e historyFileList \u003d scanDirectoryForHistoryFiles(path,\n         doneDirFc);\n     for (FileStatus fs : historyFileList) {\n-      if(LOG.isDebugEnabled()) {\n-        LOG.debug(\"Adding in history for \"+fs.getPath());\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Adding in history for \" + fs.getPath());\n       }\n       JobIndexInfo jobIndexInfo \u003d FileNameIndexUtils.getIndexInfo(fs.getPath()\n           .getName());\n       String confFileName \u003d JobHistoryUtils\n           .getIntermediateConfFileName(jobIndexInfo.getJobId());\n       String summaryFileName \u003d JobHistoryUtils\n           .getIntermediateSummaryFileName(jobIndexInfo.getJobId());\n       MetaInfo metaInfo \u003d new MetaInfo(fs.getPath(), new Path(fs.getPath()\n           .getParent(), confFileName), new Path(fs.getPath().getParent(),\n           summaryFileName), jobIndexInfo);\n-      addToJobListCache(jobIndexInfo.getJobId(), metaInfo);\n+      addToJobListCache(metaInfo);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void addDirectoryToJobListCache(Path path) throws IOException {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Adding \" + path + \" to job list cache.\");\n    }\n    List\u003cFileStatus\u003e historyFileList \u003d scanDirectoryForHistoryFiles(path,\n        doneDirFc);\n    for (FileStatus fs : historyFileList) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Adding in history for \" + fs.getPath());\n      }\n      JobIndexInfo jobIndexInfo \u003d FileNameIndexUtils.getIndexInfo(fs.getPath()\n          .getName());\n      String confFileName \u003d JobHistoryUtils\n          .getIntermediateConfFileName(jobIndexInfo.getJobId());\n      String summaryFileName \u003d JobHistoryUtils\n          .getIntermediateSummaryFileName(jobIndexInfo.getJobId());\n      MetaInfo metaInfo \u003d new MetaInfo(fs.getPath(), new Path(fs.getPath()\n          .getParent(), confFileName), new Path(fs.getPath().getParent(),\n          summaryFileName), jobIndexInfo);\n      addToJobListCache(metaInfo);\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
          "extendedDetails": {
            "oldPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
            "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
            "oldMethodName": "addDirectoryToJobListCache",
            "newMethodName": "addDirectoryToJobListCache"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-4059. The history server should have a separate pluggable storage/query interface. (Robert Evans via tgraves).\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311896 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/04/12 11:11 AM",
          "commitName": "cbb5f6109097a77f18f5fb0ba62ac132b8fa980f",
          "commitAuthor": "Thomas Graves",
          "commitDateOld": "10/04/12 9:13 AM",
          "commitNameOld": "000859a534f4cc6a57524a676805d8af6ad199de",
          "commitAuthorOld": "Robert Joseph Evans",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,22 @@\n   private void addDirectoryToJobListCache(Path path) throws IOException {\n-    if(LOG.isDebugEnabled()) {\n-      LOG.debug(\"Adding \"+path+\" to job list cache.\");\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Adding \" + path + \" to job list cache.\");\n     }\n     List\u003cFileStatus\u003e historyFileList \u003d scanDirectoryForHistoryFiles(path,\n         doneDirFc);\n     for (FileStatus fs : historyFileList) {\n-      if(LOG.isDebugEnabled()) {\n-        LOG.debug(\"Adding in history for \"+fs.getPath());\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Adding in history for \" + fs.getPath());\n       }\n       JobIndexInfo jobIndexInfo \u003d FileNameIndexUtils.getIndexInfo(fs.getPath()\n           .getName());\n       String confFileName \u003d JobHistoryUtils\n           .getIntermediateConfFileName(jobIndexInfo.getJobId());\n       String summaryFileName \u003d JobHistoryUtils\n           .getIntermediateSummaryFileName(jobIndexInfo.getJobId());\n       MetaInfo metaInfo \u003d new MetaInfo(fs.getPath(), new Path(fs.getPath()\n           .getParent(), confFileName), new Path(fs.getPath().getParent(),\n           summaryFileName), jobIndexInfo);\n-      addToJobListCache(jobIndexInfo.getJobId(), metaInfo);\n+      addToJobListCache(metaInfo);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void addDirectoryToJobListCache(Path path) throws IOException {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Adding \" + path + \" to job list cache.\");\n    }\n    List\u003cFileStatus\u003e historyFileList \u003d scanDirectoryForHistoryFiles(path,\n        doneDirFc);\n    for (FileStatus fs : historyFileList) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Adding in history for \" + fs.getPath());\n      }\n      JobIndexInfo jobIndexInfo \u003d FileNameIndexUtils.getIndexInfo(fs.getPath()\n          .getName());\n      String confFileName \u003d JobHistoryUtils\n          .getIntermediateConfFileName(jobIndexInfo.getJobId());\n      String summaryFileName \u003d JobHistoryUtils\n          .getIntermediateSummaryFileName(jobIndexInfo.getJobId());\n      MetaInfo metaInfo \u003d new MetaInfo(fs.getPath(), new Path(fs.getPath()\n          .getParent(), confFileName), new Path(fs.getPath().getParent(),\n          summaryFileName), jobIndexInfo);\n      addToJobListCache(metaInfo);\n    }\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/HistoryFileManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "be32d25c546a7d4f98604e142940c483213b485b": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2675. Reformat JobHistory Server main page to be more useful. Contributed by Robert Joseph Evans.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1169763 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/09/11 7:24 AM",
      "commitName": "be32d25c546a7d4f98604e142940c483213b485b",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "08/09/11 6:44 PM",
      "commitNameOld": "fafe8cd28e726566509c679e19d7da622f29f90d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 3.53,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,22 @@\n   private void addDirectoryToJobListCache(Path path) throws IOException {\n+    if(LOG.isDebugEnabled()) {\n+      LOG.debug(\"Adding \"+path+\" to job list cache.\");\n+    }\n     List\u003cFileStatus\u003e historyFileList \u003d scanDirectoryForHistoryFiles(path,\n         doneDirFc);\n     for (FileStatus fs : historyFileList) {\n+      if(LOG.isDebugEnabled()) {\n+        LOG.debug(\"Adding in history for \"+fs.getPath());\n+      }\n       JobIndexInfo jobIndexInfo \u003d FileNameIndexUtils.getIndexInfo(fs.getPath()\n           .getName());\n       String confFileName \u003d JobHistoryUtils\n           .getIntermediateConfFileName(jobIndexInfo.getJobId());\n       String summaryFileName \u003d JobHistoryUtils\n           .getIntermediateSummaryFileName(jobIndexInfo.getJobId());\n       MetaInfo metaInfo \u003d new MetaInfo(fs.getPath(), new Path(fs.getPath()\n           .getParent(), confFileName), new Path(fs.getPath().getParent(),\n           summaryFileName), jobIndexInfo);\n       addToJobListCache(jobIndexInfo.getJobId(), metaInfo);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void addDirectoryToJobListCache(Path path) throws IOException {\n    if(LOG.isDebugEnabled()) {\n      LOG.debug(\"Adding \"+path+\" to job list cache.\");\n    }\n    List\u003cFileStatus\u003e historyFileList \u003d scanDirectoryForHistoryFiles(path,\n        doneDirFc);\n    for (FileStatus fs : historyFileList) {\n      if(LOG.isDebugEnabled()) {\n        LOG.debug(\"Adding in history for \"+fs.getPath());\n      }\n      JobIndexInfo jobIndexInfo \u003d FileNameIndexUtils.getIndexInfo(fs.getPath()\n          .getName());\n      String confFileName \u003d JobHistoryUtils\n          .getIntermediateConfFileName(jobIndexInfo.getJobId());\n      String summaryFileName \u003d JobHistoryUtils\n          .getIntermediateSummaryFileName(jobIndexInfo.getJobId());\n      MetaInfo metaInfo \u003d new MetaInfo(fs.getPath(), new Path(fs.getPath()\n          .getParent(), confFileName), new Path(fs.getPath().getParent(),\n          summaryFileName), jobIndexInfo);\n      addToJobListCache(jobIndexInfo.getJobId(), metaInfo);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void addDirectoryToJobListCache(Path path) throws IOException {\n    List\u003cFileStatus\u003e historyFileList \u003d scanDirectoryForHistoryFiles(path,\n        doneDirFc);\n    for (FileStatus fs : historyFileList) {\n      JobIndexInfo jobIndexInfo \u003d FileNameIndexUtils.getIndexInfo(fs.getPath()\n          .getName());\n      String confFileName \u003d JobHistoryUtils\n          .getIntermediateConfFileName(jobIndexInfo.getJobId());\n      String summaryFileName \u003d JobHistoryUtils\n          .getIntermediateSummaryFileName(jobIndexInfo.getJobId());\n      MetaInfo metaInfo \u003d new MetaInfo(fs.getPath(), new Path(fs.getPath()\n          .getParent(), confFileName), new Path(fs.getPath().getParent(),\n          summaryFileName), jobIndexInfo);\n      addToJobListCache(jobIndexInfo.getJobId(), metaInfo);\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,16 @@\n+  private void addDirectoryToJobListCache(Path path) throws IOException {\n+    List\u003cFileStatus\u003e historyFileList \u003d scanDirectoryForHistoryFiles(path,\n+        doneDirFc);\n+    for (FileStatus fs : historyFileList) {\n+      JobIndexInfo jobIndexInfo \u003d FileNameIndexUtils.getIndexInfo(fs.getPath()\n+          .getName());\n+      String confFileName \u003d JobHistoryUtils\n+          .getIntermediateConfFileName(jobIndexInfo.getJobId());\n+      String summaryFileName \u003d JobHistoryUtils\n+          .getIntermediateSummaryFileName(jobIndexInfo.getJobId());\n+      MetaInfo metaInfo \u003d new MetaInfo(fs.getPath(), new Path(fs.getPath()\n+          .getParent(), confFileName), new Path(fs.getPath().getParent(),\n+          summaryFileName), jobIndexInfo);\n+      addToJobListCache(jobIndexInfo.getJobId(), metaInfo);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void addDirectoryToJobListCache(Path path) throws IOException {\n    List\u003cFileStatus\u003e historyFileList \u003d scanDirectoryForHistoryFiles(path,\n        doneDirFc);\n    for (FileStatus fs : historyFileList) {\n      JobIndexInfo jobIndexInfo \u003d FileNameIndexUtils.getIndexInfo(fs.getPath()\n          .getName());\n      String confFileName \u003d JobHistoryUtils\n          .getIntermediateConfFileName(jobIndexInfo.getJobId());\n      String summaryFileName \u003d JobHistoryUtils\n          .getIntermediateSummaryFileName(jobIndexInfo.getJobId());\n      MetaInfo metaInfo \u003d new MetaInfo(fs.getPath(), new Path(fs.getPath()\n          .getParent(), confFileName), new Path(fs.getPath().getParent(),\n          summaryFileName), jobIndexInfo);\n      addToJobListCache(jobIndexInfo.getJobId(), metaInfo);\n    }\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistory.java"
    }
  }
}