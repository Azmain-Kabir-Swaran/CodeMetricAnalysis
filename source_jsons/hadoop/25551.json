{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "TaskAttemptListenerImpl.java",
  "functionName": "statusUpdate",
  "functionId": "statusUpdate___taskAttemptID-TaskAttemptID__taskStatus-TaskStatus",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java",
  "functionStartLine": 376,
  "functionEndLine": 479,
  "numCommitsSeen": 39,
  "timeTaken": 9210,
  "changeHistory": [
    "11d17417ceba0f1a2944e0c8b4286515c4883889",
    "82f029f7b50679ea477a3a898e4ee400fa394adf",
    "6eef3d7f1a1e5e3f27fb3bf7596663640d786181",
    "21d36273551fa45c4130e5523b6724358cf34b1e",
    "cd67d5abcd9ac99f882de52d4db9d4a30845cdcf",
    "0fd646b967443f44c237c95f93e03cb0a6a57f8d",
    "47cca0cb6d1f4e5979d11d9a624b005e6e666f2f",
    "905b17876c44634545a68300ff2f2d73fb86d3b7",
    "bb74427da27ab90ade868c4fd89ed8ac3310aea2",
    "e8645636ce1721aa6dc3674fbc553a7bb3522fbe",
    "a26b1672a85e97bea973cfcc7eab22b4cca01448",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "11d17417ceba0f1a2944e0c8b4286515c4883889": "Ybodychange",
    "82f029f7b50679ea477a3a898e4ee400fa394adf": "Ybodychange",
    "6eef3d7f1a1e5e3f27fb3bf7596663640d786181": "Ybodychange",
    "21d36273551fa45c4130e5523b6724358cf34b1e": "Ybodychange",
    "cd67d5abcd9ac99f882de52d4db9d4a30845cdcf": "Ybodychange",
    "0fd646b967443f44c237c95f93e03cb0a6a57f8d": "Ybodychange",
    "47cca0cb6d1f4e5979d11d9a624b005e6e666f2f": "Ymultichange(Yreturntypechange,Ybodychange)",
    "905b17876c44634545a68300ff2f2d73fb86d3b7": "Ybodychange",
    "bb74427da27ab90ade868c4fd89ed8ac3310aea2": "Ybodychange",
    "e8645636ce1721aa6dc3674fbc553a7bb3522fbe": "Ybodychange",
    "a26b1672a85e97bea973cfcc7eab22b4cca01448": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "11d17417ceba0f1a2944e0c8b4286515c4883889": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-7272. TaskAttemptListenerImpl excessive log messages. Contributed by Ahmed Hussein (ahussein)\n",
      "commitDate": "13/04/20 11:20 AM",
      "commitName": "11d17417ceba0f1a2944e0c8b4286515c4883889",
      "commitAuthor": "Eric E Payne",
      "commitDateOld": "16/02/18 6:15 AM",
      "commitNameOld": "82f029f7b50679ea477a3a898e4ee400fa394adf",
      "commitAuthorOld": "Eric Payne",
      "daysBetweenCommits": 787.17,
      "commitsBetweenForRepo": 5871,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,102 +1,104 @@\n   public AMFeedback statusUpdate(TaskAttemptID taskAttemptID,\n       TaskStatus taskStatus) throws IOException, InterruptedException {\n \n     org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n         TypeConverter.toYarn(taskAttemptID);\n \n     AMFeedback feedback \u003d new AMFeedback();\n     feedback.setTaskFound(true);\n \n     AtomicReference\u003cTaskAttemptStatus\u003e lastStatusRef \u003d\n         attemptIdToStatus.get(yarnAttemptID);\n     if (lastStatusRef \u003d\u003d null) {\n       // The task is not known, but it could be in the process of tearing\n       // down gracefully or receiving a thread dump signal. Tolerate unknown\n       // tasks as long as they have unregistered recently.\n       if (!taskHeartbeatHandler.hasRecentlyUnregistered(yarnAttemptID)) {\n         LOG.error(\"Status update was called with illegal TaskAttemptId: \"\n             + yarnAttemptID);\n         feedback.setTaskFound(false);\n       }\n       return feedback;\n     }\n \n     // Propagating preemption to the task if TASK_PREEMPTION is enabled\n     if (getConfig().getBoolean(MRJobConfig.TASK_PREEMPTION, false)\n         \u0026\u0026 preemptionPolicy.isPreempted(yarnAttemptID)) {\n       feedback.setPreemption(true);\n       LOG.info(\"Setting preemption bit for task: \"+ yarnAttemptID\n           + \" of type \" + yarnAttemptID.getTaskId().getTaskType());\n     }\n \n     if (taskStatus \u003d\u003d null) {\n       //We are using statusUpdate only as a simple ping\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Ping from \" + taskAttemptID.toString());\n       }\n       return feedback;\n     }\n \n     // if we are here there is an actual status update to be processed\n \n     taskHeartbeatHandler.progressing(yarnAttemptID);\n     TaskAttemptStatus taskAttemptStatus \u003d\n         new TaskAttemptStatus();\n     taskAttemptStatus.id \u003d yarnAttemptID;\n     // Task sends the updated progress to the TT.\n     taskAttemptStatus.progress \u003d taskStatus.getProgress();\n-    LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n-        + taskStatus.getProgress());\n+    // log the new progress\n+    taskAttemptLogProgressStamps.computeIfAbsent(taskAttemptID,\n+        k -\u003e new TaskProgressLogPair(taskAttemptID))\n+        .update(taskStatus.getProgress());\n     // Task sends the updated state-string to the TT.\n     taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n     // Task sends the updated phase to the TT.\n     taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n     // Counters are updated by the task. Convert counters into new format as\n     // that is the primary storage format inside the AM to avoid multiple\n     // conversions and unnecessary heap usage.\n     taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n       taskStatus.getCounters());\n \n     // Map Finish time set by the task (map only)\n     if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n       taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n     }\n \n     // Shuffle Finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n       taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n     }\n \n     // Sort finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n       taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n     }\n \n     // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n     //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n     \n     //set the fetch failures\n     if (taskStatus.getFetchFailedMaps() !\u003d null \n         \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n       taskAttemptStatus.fetchFailedMaps \u003d \n         new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n       for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n         taskAttemptStatus.fetchFailedMaps.add(\n             TypeConverter.toYarn(failedMapId));\n       }\n     }\n \n  // Task sends the information about the nextRecordRange to the TT\n     \n //    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n //    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n //    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n //    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n //    // This was used by TT to do counter updates only once every minute. So this\n //    // isn\u0027t ever changed by the Task itself.\n //    taskStatus.getIncludeCounters();\n \n     coalesceStatusUpdate(yarnAttemptID, taskAttemptStatus, lastStatusRef);\n \n     return feedback;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AMFeedback statusUpdate(TaskAttemptID taskAttemptID,\n      TaskStatus taskStatus) throws IOException, InterruptedException {\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n        TypeConverter.toYarn(taskAttemptID);\n\n    AMFeedback feedback \u003d new AMFeedback();\n    feedback.setTaskFound(true);\n\n    AtomicReference\u003cTaskAttemptStatus\u003e lastStatusRef \u003d\n        attemptIdToStatus.get(yarnAttemptID);\n    if (lastStatusRef \u003d\u003d null) {\n      // The task is not known, but it could be in the process of tearing\n      // down gracefully or receiving a thread dump signal. Tolerate unknown\n      // tasks as long as they have unregistered recently.\n      if (!taskHeartbeatHandler.hasRecentlyUnregistered(yarnAttemptID)) {\n        LOG.error(\"Status update was called with illegal TaskAttemptId: \"\n            + yarnAttemptID);\n        feedback.setTaskFound(false);\n      }\n      return feedback;\n    }\n\n    // Propagating preemption to the task if TASK_PREEMPTION is enabled\n    if (getConfig().getBoolean(MRJobConfig.TASK_PREEMPTION, false)\n        \u0026\u0026 preemptionPolicy.isPreempted(yarnAttemptID)) {\n      feedback.setPreemption(true);\n      LOG.info(\"Setting preemption bit for task: \"+ yarnAttemptID\n          + \" of type \" + yarnAttemptID.getTaskId().getTaskType());\n    }\n\n    if (taskStatus \u003d\u003d null) {\n      //We are using statusUpdate only as a simple ping\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Ping from \" + taskAttemptID.toString());\n      }\n      return feedback;\n    }\n\n    // if we are here there is an actual status update to be processed\n\n    taskHeartbeatHandler.progressing(yarnAttemptID);\n    TaskAttemptStatus taskAttemptStatus \u003d\n        new TaskAttemptStatus();\n    taskAttemptStatus.id \u003d yarnAttemptID;\n    // Task sends the updated progress to the TT.\n    taskAttemptStatus.progress \u003d taskStatus.getProgress();\n    // log the new progress\n    taskAttemptLogProgressStamps.computeIfAbsent(taskAttemptID,\n        k -\u003e new TaskProgressLogPair(taskAttemptID))\n        .update(taskStatus.getProgress());\n    // Task sends the updated state-string to the TT.\n    taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n    // Task sends the updated phase to the TT.\n    taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n    // Counters are updated by the task. Convert counters into new format as\n    // that is the primary storage format inside the AM to avoid multiple\n    // conversions and unnecessary heap usage.\n    taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n      taskStatus.getCounters());\n\n    // Map Finish time set by the task (map only)\n    if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n      taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n    }\n\n    // Shuffle Finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n      taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n    }\n\n    // Sort finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n      taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n    }\n\n    // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n    //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n    \n    //set the fetch failures\n    if (taskStatus.getFetchFailedMaps() !\u003d null \n        \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n      taskAttemptStatus.fetchFailedMaps \u003d \n        new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n      for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n        taskAttemptStatus.fetchFailedMaps.add(\n            TypeConverter.toYarn(failedMapId));\n      }\n    }\n\n // Task sends the information about the nextRecordRange to the TT\n    \n//    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n//    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n//    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n//    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n//    // This was used by TT to do counter updates only once every minute. So this\n//    // isn\u0027t ever changed by the Task itself.\n//    taskStatus.getIncludeCounters();\n\n    coalesceStatusUpdate(yarnAttemptID, taskAttemptStatus, lastStatusRef);\n\n    return feedback;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java",
      "extendedDetails": {}
    },
    "82f029f7b50679ea477a3a898e4ee400fa394adf": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-7053: Timed out tasks can fail to produce thread dump. Contributed by Jason Lowe.\n",
      "commitDate": "16/02/18 6:15 AM",
      "commitName": "82f029f7b50679ea477a3a898e4ee400fa394adf",
      "commitAuthor": "Eric Payne",
      "commitDateOld": "26/01/18 1:31 PM",
      "commitNameOld": "6eef3d7f1a1e5e3f27fb3bf7596663640d786181",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 20.7,
      "commitsBetweenForRepo": 139,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,97 +1,102 @@\n   public AMFeedback statusUpdate(TaskAttemptID taskAttemptID,\n       TaskStatus taskStatus) throws IOException, InterruptedException {\n \n     org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n         TypeConverter.toYarn(taskAttemptID);\n \n     AMFeedback feedback \u003d new AMFeedback();\n+    feedback.setTaskFound(true);\n+\n     AtomicReference\u003cTaskAttemptStatus\u003e lastStatusRef \u003d\n         attemptIdToStatus.get(yarnAttemptID);\n     if (lastStatusRef \u003d\u003d null) {\n-      LOG.error(\"Status update was called with illegal TaskAttemptId: \"\n-          + yarnAttemptID);\n-      feedback.setTaskFound(false);\n+      // The task is not known, but it could be in the process of tearing\n+      // down gracefully or receiving a thread dump signal. Tolerate unknown\n+      // tasks as long as they have unregistered recently.\n+      if (!taskHeartbeatHandler.hasRecentlyUnregistered(yarnAttemptID)) {\n+        LOG.error(\"Status update was called with illegal TaskAttemptId: \"\n+            + yarnAttemptID);\n+        feedback.setTaskFound(false);\n+      }\n       return feedback;\n     }\n \n-    feedback.setTaskFound(true);\n-\n     // Propagating preemption to the task if TASK_PREEMPTION is enabled\n     if (getConfig().getBoolean(MRJobConfig.TASK_PREEMPTION, false)\n         \u0026\u0026 preemptionPolicy.isPreempted(yarnAttemptID)) {\n       feedback.setPreemption(true);\n       LOG.info(\"Setting preemption bit for task: \"+ yarnAttemptID\n           + \" of type \" + yarnAttemptID.getTaskId().getTaskType());\n     }\n \n     if (taskStatus \u003d\u003d null) {\n       //We are using statusUpdate only as a simple ping\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Ping from \" + taskAttemptID.toString());\n       }\n       return feedback;\n     }\n \n     // if we are here there is an actual status update to be processed\n \n     taskHeartbeatHandler.progressing(yarnAttemptID);\n     TaskAttemptStatus taskAttemptStatus \u003d\n         new TaskAttemptStatus();\n     taskAttemptStatus.id \u003d yarnAttemptID;\n     // Task sends the updated progress to the TT.\n     taskAttemptStatus.progress \u003d taskStatus.getProgress();\n     LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n         + taskStatus.getProgress());\n     // Task sends the updated state-string to the TT.\n     taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n     // Task sends the updated phase to the TT.\n     taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n     // Counters are updated by the task. Convert counters into new format as\n     // that is the primary storage format inside the AM to avoid multiple\n     // conversions and unnecessary heap usage.\n     taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n       taskStatus.getCounters());\n \n     // Map Finish time set by the task (map only)\n     if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n       taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n     }\n \n     // Shuffle Finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n       taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n     }\n \n     // Sort finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n       taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n     }\n \n     // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n     //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n     \n     //set the fetch failures\n     if (taskStatus.getFetchFailedMaps() !\u003d null \n         \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n       taskAttemptStatus.fetchFailedMaps \u003d \n         new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n       for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n         taskAttemptStatus.fetchFailedMaps.add(\n             TypeConverter.toYarn(failedMapId));\n       }\n     }\n \n  // Task sends the information about the nextRecordRange to the TT\n     \n //    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n //    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n //    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n //    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n //    // This was used by TT to do counter updates only once every minute. So this\n //    // isn\u0027t ever changed by the Task itself.\n //    taskStatus.getIncludeCounters();\n \n     coalesceStatusUpdate(yarnAttemptID, taskAttemptStatus, lastStatusRef);\n \n     return feedback;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AMFeedback statusUpdate(TaskAttemptID taskAttemptID,\n      TaskStatus taskStatus) throws IOException, InterruptedException {\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n        TypeConverter.toYarn(taskAttemptID);\n\n    AMFeedback feedback \u003d new AMFeedback();\n    feedback.setTaskFound(true);\n\n    AtomicReference\u003cTaskAttemptStatus\u003e lastStatusRef \u003d\n        attemptIdToStatus.get(yarnAttemptID);\n    if (lastStatusRef \u003d\u003d null) {\n      // The task is not known, but it could be in the process of tearing\n      // down gracefully or receiving a thread dump signal. Tolerate unknown\n      // tasks as long as they have unregistered recently.\n      if (!taskHeartbeatHandler.hasRecentlyUnregistered(yarnAttemptID)) {\n        LOG.error(\"Status update was called with illegal TaskAttemptId: \"\n            + yarnAttemptID);\n        feedback.setTaskFound(false);\n      }\n      return feedback;\n    }\n\n    // Propagating preemption to the task if TASK_PREEMPTION is enabled\n    if (getConfig().getBoolean(MRJobConfig.TASK_PREEMPTION, false)\n        \u0026\u0026 preemptionPolicy.isPreempted(yarnAttemptID)) {\n      feedback.setPreemption(true);\n      LOG.info(\"Setting preemption bit for task: \"+ yarnAttemptID\n          + \" of type \" + yarnAttemptID.getTaskId().getTaskType());\n    }\n\n    if (taskStatus \u003d\u003d null) {\n      //We are using statusUpdate only as a simple ping\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Ping from \" + taskAttemptID.toString());\n      }\n      return feedback;\n    }\n\n    // if we are here there is an actual status update to be processed\n\n    taskHeartbeatHandler.progressing(yarnAttemptID);\n    TaskAttemptStatus taskAttemptStatus \u003d\n        new TaskAttemptStatus();\n    taskAttemptStatus.id \u003d yarnAttemptID;\n    // Task sends the updated progress to the TT.\n    taskAttemptStatus.progress \u003d taskStatus.getProgress();\n    LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n        + taskStatus.getProgress());\n    // Task sends the updated state-string to the TT.\n    taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n    // Task sends the updated phase to the TT.\n    taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n    // Counters are updated by the task. Convert counters into new format as\n    // that is the primary storage format inside the AM to avoid multiple\n    // conversions and unnecessary heap usage.\n    taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n      taskStatus.getCounters());\n\n    // Map Finish time set by the task (map only)\n    if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n      taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n    }\n\n    // Shuffle Finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n      taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n    }\n\n    // Sort finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n      taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n    }\n\n    // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n    //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n    \n    //set the fetch failures\n    if (taskStatus.getFetchFailedMaps() !\u003d null \n        \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n      taskAttemptStatus.fetchFailedMaps \u003d \n        new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n      for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n        taskAttemptStatus.fetchFailedMaps.add(\n            TypeConverter.toYarn(failedMapId));\n      }\n    }\n\n // Task sends the information about the nextRecordRange to the TT\n    \n//    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n//    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n//    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n//    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n//    // This was used by TT to do counter updates only once every minute. So this\n//    // isn\u0027t ever changed by the Task itself.\n//    taskStatus.getIncludeCounters();\n\n    coalesceStatusUpdate(yarnAttemptID, taskAttemptStatus, lastStatusRef);\n\n    return feedback;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java",
      "extendedDetails": {}
    },
    "6eef3d7f1a1e5e3f27fb3bf7596663640d786181": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-7020. Task timeout in uber mode can crash AM. Contributed by Peter Bacsko\n",
      "commitDate": "26/01/18 1:31 PM",
      "commitName": "6eef3d7f1a1e5e3f27fb3bf7596663640d786181",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "26/01/18 12:36 PM",
      "commitNameOld": "a37e7f0ad8b68c7ed16c242bedf62f4cde48d6fd",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,95 +1,97 @@\n   public AMFeedback statusUpdate(TaskAttemptID taskAttemptID,\n       TaskStatus taskStatus) throws IOException, InterruptedException {\n \n     org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n         TypeConverter.toYarn(taskAttemptID);\n \n+    AMFeedback feedback \u003d new AMFeedback();\n     AtomicReference\u003cTaskAttemptStatus\u003e lastStatusRef \u003d\n         attemptIdToStatus.get(yarnAttemptID);\n     if (lastStatusRef \u003d\u003d null) {\n-      throw new IllegalStateException(\"Status update was called\"\n-          + \" with illegal TaskAttemptId: \" + yarnAttemptID);\n+      LOG.error(\"Status update was called with illegal TaskAttemptId: \"\n+          + yarnAttemptID);\n+      feedback.setTaskFound(false);\n+      return feedback;\n     }\n \n-    AMFeedback feedback \u003d new AMFeedback();\n     feedback.setTaskFound(true);\n \n     // Propagating preemption to the task if TASK_PREEMPTION is enabled\n     if (getConfig().getBoolean(MRJobConfig.TASK_PREEMPTION, false)\n         \u0026\u0026 preemptionPolicy.isPreempted(yarnAttemptID)) {\n       feedback.setPreemption(true);\n       LOG.info(\"Setting preemption bit for task: \"+ yarnAttemptID\n           + \" of type \" + yarnAttemptID.getTaskId().getTaskType());\n     }\n \n     if (taskStatus \u003d\u003d null) {\n       //We are using statusUpdate only as a simple ping\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Ping from \" + taskAttemptID.toString());\n       }\n       return feedback;\n     }\n \n     // if we are here there is an actual status update to be processed\n \n     taskHeartbeatHandler.progressing(yarnAttemptID);\n     TaskAttemptStatus taskAttemptStatus \u003d\n         new TaskAttemptStatus();\n     taskAttemptStatus.id \u003d yarnAttemptID;\n     // Task sends the updated progress to the TT.\n     taskAttemptStatus.progress \u003d taskStatus.getProgress();\n     LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n         + taskStatus.getProgress());\n     // Task sends the updated state-string to the TT.\n     taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n     // Task sends the updated phase to the TT.\n     taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n     // Counters are updated by the task. Convert counters into new format as\n     // that is the primary storage format inside the AM to avoid multiple\n     // conversions and unnecessary heap usage.\n     taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n       taskStatus.getCounters());\n \n     // Map Finish time set by the task (map only)\n     if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n       taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n     }\n \n     // Shuffle Finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n       taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n     }\n \n     // Sort finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n       taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n     }\n \n     // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n     //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n     \n     //set the fetch failures\n     if (taskStatus.getFetchFailedMaps() !\u003d null \n         \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n       taskAttemptStatus.fetchFailedMaps \u003d \n         new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n       for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n         taskAttemptStatus.fetchFailedMaps.add(\n             TypeConverter.toYarn(failedMapId));\n       }\n     }\n \n  // Task sends the information about the nextRecordRange to the TT\n     \n //    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n //    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n //    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n //    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n //    // This was used by TT to do counter updates only once every minute. So this\n //    // isn\u0027t ever changed by the Task itself.\n //    taskStatus.getIncludeCounters();\n \n     coalesceStatusUpdate(yarnAttemptID, taskAttemptStatus, lastStatusRef);\n \n     return feedback;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AMFeedback statusUpdate(TaskAttemptID taskAttemptID,\n      TaskStatus taskStatus) throws IOException, InterruptedException {\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n        TypeConverter.toYarn(taskAttemptID);\n\n    AMFeedback feedback \u003d new AMFeedback();\n    AtomicReference\u003cTaskAttemptStatus\u003e lastStatusRef \u003d\n        attemptIdToStatus.get(yarnAttemptID);\n    if (lastStatusRef \u003d\u003d null) {\n      LOG.error(\"Status update was called with illegal TaskAttemptId: \"\n          + yarnAttemptID);\n      feedback.setTaskFound(false);\n      return feedback;\n    }\n\n    feedback.setTaskFound(true);\n\n    // Propagating preemption to the task if TASK_PREEMPTION is enabled\n    if (getConfig().getBoolean(MRJobConfig.TASK_PREEMPTION, false)\n        \u0026\u0026 preemptionPolicy.isPreempted(yarnAttemptID)) {\n      feedback.setPreemption(true);\n      LOG.info(\"Setting preemption bit for task: \"+ yarnAttemptID\n          + \" of type \" + yarnAttemptID.getTaskId().getTaskType());\n    }\n\n    if (taskStatus \u003d\u003d null) {\n      //We are using statusUpdate only as a simple ping\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Ping from \" + taskAttemptID.toString());\n      }\n      return feedback;\n    }\n\n    // if we are here there is an actual status update to be processed\n\n    taskHeartbeatHandler.progressing(yarnAttemptID);\n    TaskAttemptStatus taskAttemptStatus \u003d\n        new TaskAttemptStatus();\n    taskAttemptStatus.id \u003d yarnAttemptID;\n    // Task sends the updated progress to the TT.\n    taskAttemptStatus.progress \u003d taskStatus.getProgress();\n    LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n        + taskStatus.getProgress());\n    // Task sends the updated state-string to the TT.\n    taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n    // Task sends the updated phase to the TT.\n    taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n    // Counters are updated by the task. Convert counters into new format as\n    // that is the primary storage format inside the AM to avoid multiple\n    // conversions and unnecessary heap usage.\n    taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n      taskStatus.getCounters());\n\n    // Map Finish time set by the task (map only)\n    if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n      taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n    }\n\n    // Shuffle Finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n      taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n    }\n\n    // Sort finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n      taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n    }\n\n    // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n    //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n    \n    //set the fetch failures\n    if (taskStatus.getFetchFailedMaps() !\u003d null \n        \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n      taskAttemptStatus.fetchFailedMaps \u003d \n        new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n      for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n        taskAttemptStatus.fetchFailedMaps.add(\n            TypeConverter.toYarn(failedMapId));\n      }\n    }\n\n // Task sends the information about the nextRecordRange to the TT\n    \n//    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n//    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n//    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n//    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n//    // This was used by TT to do counter updates only once every minute. So this\n//    // isn\u0027t ever changed by the Task itself.\n//    taskStatus.getIncludeCounters();\n\n    coalesceStatusUpdate(yarnAttemptID, taskAttemptStatus, lastStatusRef);\n\n    return feedback;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java",
      "extendedDetails": {}
    },
    "21d36273551fa45c4130e5523b6724358cf34b1e": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5124. AM lacks flow control for task events. Contributed by Peter Bacsko\n",
      "commitDate": "01/12/17 12:04 PM",
      "commitName": "21d36273551fa45c4130e5523b6724358cf34b1e",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "02/10/17 8:14 PM",
      "commitNameOld": "453d48bdfbb67ed3e66c33c4aef239c3d7bdd3bc",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 59.7,
      "commitsBetweenForRepo": 476,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,89 +1,95 @@\n   public AMFeedback statusUpdate(TaskAttemptID taskAttemptID,\n       TaskStatus taskStatus) throws IOException, InterruptedException {\n \n     org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n         TypeConverter.toYarn(taskAttemptID);\n \n+    AtomicReference\u003cTaskAttemptStatus\u003e lastStatusRef \u003d\n+        attemptIdToStatus.get(yarnAttemptID);\n+    if (lastStatusRef \u003d\u003d null) {\n+      throw new IllegalStateException(\"Status update was called\"\n+          + \" with illegal TaskAttemptId: \" + yarnAttemptID);\n+    }\n+\n     AMFeedback feedback \u003d new AMFeedback();\n     feedback.setTaskFound(true);\n \n     // Propagating preemption to the task if TASK_PREEMPTION is enabled\n     if (getConfig().getBoolean(MRJobConfig.TASK_PREEMPTION, false)\n         \u0026\u0026 preemptionPolicy.isPreempted(yarnAttemptID)) {\n       feedback.setPreemption(true);\n       LOG.info(\"Setting preemption bit for task: \"+ yarnAttemptID\n           + \" of type \" + yarnAttemptID.getTaskId().getTaskType());\n     }\n \n     if (taskStatus \u003d\u003d null) {\n       //We are using statusUpdate only as a simple ping\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Ping from \" + taskAttemptID.toString());\n       }\n       return feedback;\n     }\n \n     // if we are here there is an actual status update to be processed\n \n     taskHeartbeatHandler.progressing(yarnAttemptID);\n     TaskAttemptStatus taskAttemptStatus \u003d\n         new TaskAttemptStatus();\n     taskAttemptStatus.id \u003d yarnAttemptID;\n     // Task sends the updated progress to the TT.\n     taskAttemptStatus.progress \u003d taskStatus.getProgress();\n     LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n         + taskStatus.getProgress());\n     // Task sends the updated state-string to the TT.\n     taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n     // Task sends the updated phase to the TT.\n     taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n     // Counters are updated by the task. Convert counters into new format as\n     // that is the primary storage format inside the AM to avoid multiple\n     // conversions and unnecessary heap usage.\n     taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n       taskStatus.getCounters());\n \n     // Map Finish time set by the task (map only)\n     if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n       taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n     }\n \n     // Shuffle Finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n       taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n     }\n \n     // Sort finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n       taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n     }\n \n     // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n     //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n     \n     //set the fetch failures\n     if (taskStatus.getFetchFailedMaps() !\u003d null \n         \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n       taskAttemptStatus.fetchFailedMaps \u003d \n         new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n       for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n         taskAttemptStatus.fetchFailedMaps.add(\n             TypeConverter.toYarn(failedMapId));\n       }\n     }\n \n  // Task sends the information about the nextRecordRange to the TT\n     \n //    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n //    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n //    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n //    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n //    // This was used by TT to do counter updates only once every minute. So this\n //    // isn\u0027t ever changed by the Task itself.\n //    taskStatus.getIncludeCounters();\n \n-    context.getEventHandler().handle(\n-        new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n-            taskAttemptStatus));\n+    coalesceStatusUpdate(yarnAttemptID, taskAttemptStatus, lastStatusRef);\n+\n     return feedback;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AMFeedback statusUpdate(TaskAttemptID taskAttemptID,\n      TaskStatus taskStatus) throws IOException, InterruptedException {\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n        TypeConverter.toYarn(taskAttemptID);\n\n    AtomicReference\u003cTaskAttemptStatus\u003e lastStatusRef \u003d\n        attemptIdToStatus.get(yarnAttemptID);\n    if (lastStatusRef \u003d\u003d null) {\n      throw new IllegalStateException(\"Status update was called\"\n          + \" with illegal TaskAttemptId: \" + yarnAttemptID);\n    }\n\n    AMFeedback feedback \u003d new AMFeedback();\n    feedback.setTaskFound(true);\n\n    // Propagating preemption to the task if TASK_PREEMPTION is enabled\n    if (getConfig().getBoolean(MRJobConfig.TASK_PREEMPTION, false)\n        \u0026\u0026 preemptionPolicy.isPreempted(yarnAttemptID)) {\n      feedback.setPreemption(true);\n      LOG.info(\"Setting preemption bit for task: \"+ yarnAttemptID\n          + \" of type \" + yarnAttemptID.getTaskId().getTaskType());\n    }\n\n    if (taskStatus \u003d\u003d null) {\n      //We are using statusUpdate only as a simple ping\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Ping from \" + taskAttemptID.toString());\n      }\n      return feedback;\n    }\n\n    // if we are here there is an actual status update to be processed\n\n    taskHeartbeatHandler.progressing(yarnAttemptID);\n    TaskAttemptStatus taskAttemptStatus \u003d\n        new TaskAttemptStatus();\n    taskAttemptStatus.id \u003d yarnAttemptID;\n    // Task sends the updated progress to the TT.\n    taskAttemptStatus.progress \u003d taskStatus.getProgress();\n    LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n        + taskStatus.getProgress());\n    // Task sends the updated state-string to the TT.\n    taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n    // Task sends the updated phase to the TT.\n    taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n    // Counters are updated by the task. Convert counters into new format as\n    // that is the primary storage format inside the AM to avoid multiple\n    // conversions and unnecessary heap usage.\n    taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n      taskStatus.getCounters());\n\n    // Map Finish time set by the task (map only)\n    if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n      taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n    }\n\n    // Shuffle Finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n      taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n    }\n\n    // Sort finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n      taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n    }\n\n    // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n    //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n    \n    //set the fetch failures\n    if (taskStatus.getFetchFailedMaps() !\u003d null \n        \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n      taskAttemptStatus.fetchFailedMaps \u003d \n        new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n      for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n        taskAttemptStatus.fetchFailedMaps.add(\n            TypeConverter.toYarn(failedMapId));\n      }\n    }\n\n // Task sends the information about the nextRecordRange to the TT\n    \n//    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n//    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n//    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n//    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n//    // This was used by TT to do counter updates only once every minute. So this\n//    // isn\u0027t ever changed by the Task itself.\n//    taskStatus.getIncludeCounters();\n\n    coalesceStatusUpdate(yarnAttemptID, taskAttemptStatus, lastStatusRef);\n\n    return feedback;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java",
      "extendedDetails": {}
    },
    "cd67d5abcd9ac99f882de52d4db9d4a30845cdcf": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5766. Moved ping messages from TaskAttempts to be at DEBUG level inside the ApplicationMaster log. Contributed by Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1572380 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/02/14 5:29 PM",
      "commitName": "cd67d5abcd9ac99f882de52d4db9d4a30845cdcf",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/01/14 1:38 PM",
      "commitNameOld": "0fd646b967443f44c237c95f93e03cb0a6a57f8d",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 40.16,
      "commitsBetweenForRepo": 310,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,88 +1,89 @@\n   public AMFeedback statusUpdate(TaskAttemptID taskAttemptID,\n       TaskStatus taskStatus) throws IOException, InterruptedException {\n \n     org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n         TypeConverter.toYarn(taskAttemptID);\n \n     AMFeedback feedback \u003d new AMFeedback();\n     feedback.setTaskFound(true);\n \n     // Propagating preemption to the task if TASK_PREEMPTION is enabled\n     if (getConfig().getBoolean(MRJobConfig.TASK_PREEMPTION, false)\n         \u0026\u0026 preemptionPolicy.isPreempted(yarnAttemptID)) {\n       feedback.setPreemption(true);\n       LOG.info(\"Setting preemption bit for task: \"+ yarnAttemptID\n           + \" of type \" + yarnAttemptID.getTaskId().getTaskType());\n     }\n \n     if (taskStatus \u003d\u003d null) {\n       //We are using statusUpdate only as a simple ping\n-      LOG.info(\"Ping from \" + taskAttemptID.toString());\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Ping from \" + taskAttemptID.toString());\n+      }\n       return feedback;\n     }\n \n     // if we are here there is an actual status update to be processed\n-    LOG.info(\"Status update from \" + taskAttemptID.toString());\n \n     taskHeartbeatHandler.progressing(yarnAttemptID);\n     TaskAttemptStatus taskAttemptStatus \u003d\n         new TaskAttemptStatus();\n     taskAttemptStatus.id \u003d yarnAttemptID;\n     // Task sends the updated progress to the TT.\n     taskAttemptStatus.progress \u003d taskStatus.getProgress();\n     LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n         + taskStatus.getProgress());\n     // Task sends the updated state-string to the TT.\n     taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n     // Task sends the updated phase to the TT.\n     taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n     // Counters are updated by the task. Convert counters into new format as\n     // that is the primary storage format inside the AM to avoid multiple\n     // conversions and unnecessary heap usage.\n     taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n       taskStatus.getCounters());\n \n     // Map Finish time set by the task (map only)\n     if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n       taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n     }\n \n     // Shuffle Finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n       taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n     }\n \n     // Sort finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n       taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n     }\n \n     // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n     //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n     \n     //set the fetch failures\n     if (taskStatus.getFetchFailedMaps() !\u003d null \n         \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n       taskAttemptStatus.fetchFailedMaps \u003d \n         new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n       for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n         taskAttemptStatus.fetchFailedMaps.add(\n             TypeConverter.toYarn(failedMapId));\n       }\n     }\n \n  // Task sends the information about the nextRecordRange to the TT\n     \n //    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n //    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n //    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n //    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n //    // This was used by TT to do counter updates only once every minute. So this\n //    // isn\u0027t ever changed by the Task itself.\n //    taskStatus.getIncludeCounters();\n \n     context.getEventHandler().handle(\n         new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n             taskAttemptStatus));\n     return feedback;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AMFeedback statusUpdate(TaskAttemptID taskAttemptID,\n      TaskStatus taskStatus) throws IOException, InterruptedException {\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n        TypeConverter.toYarn(taskAttemptID);\n\n    AMFeedback feedback \u003d new AMFeedback();\n    feedback.setTaskFound(true);\n\n    // Propagating preemption to the task if TASK_PREEMPTION is enabled\n    if (getConfig().getBoolean(MRJobConfig.TASK_PREEMPTION, false)\n        \u0026\u0026 preemptionPolicy.isPreempted(yarnAttemptID)) {\n      feedback.setPreemption(true);\n      LOG.info(\"Setting preemption bit for task: \"+ yarnAttemptID\n          + \" of type \" + yarnAttemptID.getTaskId().getTaskType());\n    }\n\n    if (taskStatus \u003d\u003d null) {\n      //We are using statusUpdate only as a simple ping\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Ping from \" + taskAttemptID.toString());\n      }\n      return feedback;\n    }\n\n    // if we are here there is an actual status update to be processed\n\n    taskHeartbeatHandler.progressing(yarnAttemptID);\n    TaskAttemptStatus taskAttemptStatus \u003d\n        new TaskAttemptStatus();\n    taskAttemptStatus.id \u003d yarnAttemptID;\n    // Task sends the updated progress to the TT.\n    taskAttemptStatus.progress \u003d taskStatus.getProgress();\n    LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n        + taskStatus.getProgress());\n    // Task sends the updated state-string to the TT.\n    taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n    // Task sends the updated phase to the TT.\n    taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n    // Counters are updated by the task. Convert counters into new format as\n    // that is the primary storage format inside the AM to avoid multiple\n    // conversions and unnecessary heap usage.\n    taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n      taskStatus.getCounters());\n\n    // Map Finish time set by the task (map only)\n    if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n      taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n    }\n\n    // Shuffle Finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n      taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n    }\n\n    // Sort finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n      taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n    }\n\n    // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n    //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n    \n    //set the fetch failures\n    if (taskStatus.getFetchFailedMaps() !\u003d null \n        \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n      taskAttemptStatus.fetchFailedMaps \u003d \n        new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n      for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n        taskAttemptStatus.fetchFailedMaps.add(\n            TypeConverter.toYarn(failedMapId));\n      }\n    }\n\n // Task sends the information about the nextRecordRange to the TT\n    \n//    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n//    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n//    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n//    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n//    // This was used by TT to do counter updates only once every minute. So this\n//    // isn\u0027t ever changed by the Task itself.\n//    taskStatus.getIncludeCounters();\n\n    context.getEventHandler().handle(\n        new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n            taskAttemptStatus));\n    return feedback;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java",
      "extendedDetails": {}
    },
    "0fd646b967443f44c237c95f93e03cb0a6a57f8d": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5717. Task pings are interpreted as task progress. Contributed by Jason Lowe\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1559256 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/01/14 1:38 PM",
      "commitName": "0fd646b967443f44c237c95f93e03cb0a6a57f8d",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "28/12/13 1:58 PM",
      "commitNameOld": "47cca0cb6d1f4e5979d11d9a624b005e6e666f2f",
      "commitAuthorOld": "Christopher Douglas",
      "daysBetweenCommits": 19.99,
      "commitsBetweenForRepo": 98,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,89 +1,88 @@\n   public AMFeedback statusUpdate(TaskAttemptID taskAttemptID,\n       TaskStatus taskStatus) throws IOException, InterruptedException {\n \n     org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n         TypeConverter.toYarn(taskAttemptID);\n \n     AMFeedback feedback \u003d new AMFeedback();\n     feedback.setTaskFound(true);\n \n     // Propagating preemption to the task if TASK_PREEMPTION is enabled\n     if (getConfig().getBoolean(MRJobConfig.TASK_PREEMPTION, false)\n         \u0026\u0026 preemptionPolicy.isPreempted(yarnAttemptID)) {\n       feedback.setPreemption(true);\n       LOG.info(\"Setting preemption bit for task: \"+ yarnAttemptID\n           + \" of type \" + yarnAttemptID.getTaskId().getTaskType());\n     }\n \n     if (taskStatus \u003d\u003d null) {\n       //We are using statusUpdate only as a simple ping\n       LOG.info(\"Ping from \" + taskAttemptID.toString());\n-      taskHeartbeatHandler.progressing(yarnAttemptID);\n       return feedback;\n     }\n \n     // if we are here there is an actual status update to be processed\n     LOG.info(\"Status update from \" + taskAttemptID.toString());\n \n     taskHeartbeatHandler.progressing(yarnAttemptID);\n     TaskAttemptStatus taskAttemptStatus \u003d\n         new TaskAttemptStatus();\n     taskAttemptStatus.id \u003d yarnAttemptID;\n     // Task sends the updated progress to the TT.\n     taskAttemptStatus.progress \u003d taskStatus.getProgress();\n     LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n         + taskStatus.getProgress());\n     // Task sends the updated state-string to the TT.\n     taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n     // Task sends the updated phase to the TT.\n     taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n     // Counters are updated by the task. Convert counters into new format as\n     // that is the primary storage format inside the AM to avoid multiple\n     // conversions and unnecessary heap usage.\n     taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n       taskStatus.getCounters());\n \n     // Map Finish time set by the task (map only)\n     if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n       taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n     }\n \n     // Shuffle Finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n       taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n     }\n \n     // Sort finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n       taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n     }\n \n     // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n     //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n     \n     //set the fetch failures\n     if (taskStatus.getFetchFailedMaps() !\u003d null \n         \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n       taskAttemptStatus.fetchFailedMaps \u003d \n         new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n       for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n         taskAttemptStatus.fetchFailedMaps.add(\n             TypeConverter.toYarn(failedMapId));\n       }\n     }\n \n  // Task sends the information about the nextRecordRange to the TT\n     \n //    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n //    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n //    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n //    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n //    // This was used by TT to do counter updates only once every minute. So this\n //    // isn\u0027t ever changed by the Task itself.\n //    taskStatus.getIncludeCounters();\n \n     context.getEventHandler().handle(\n         new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n             taskAttemptStatus));\n     return feedback;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public AMFeedback statusUpdate(TaskAttemptID taskAttemptID,\n      TaskStatus taskStatus) throws IOException, InterruptedException {\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n        TypeConverter.toYarn(taskAttemptID);\n\n    AMFeedback feedback \u003d new AMFeedback();\n    feedback.setTaskFound(true);\n\n    // Propagating preemption to the task if TASK_PREEMPTION is enabled\n    if (getConfig().getBoolean(MRJobConfig.TASK_PREEMPTION, false)\n        \u0026\u0026 preemptionPolicy.isPreempted(yarnAttemptID)) {\n      feedback.setPreemption(true);\n      LOG.info(\"Setting preemption bit for task: \"+ yarnAttemptID\n          + \" of type \" + yarnAttemptID.getTaskId().getTaskType());\n    }\n\n    if (taskStatus \u003d\u003d null) {\n      //We are using statusUpdate only as a simple ping\n      LOG.info(\"Ping from \" + taskAttemptID.toString());\n      return feedback;\n    }\n\n    // if we are here there is an actual status update to be processed\n    LOG.info(\"Status update from \" + taskAttemptID.toString());\n\n    taskHeartbeatHandler.progressing(yarnAttemptID);\n    TaskAttemptStatus taskAttemptStatus \u003d\n        new TaskAttemptStatus();\n    taskAttemptStatus.id \u003d yarnAttemptID;\n    // Task sends the updated progress to the TT.\n    taskAttemptStatus.progress \u003d taskStatus.getProgress();\n    LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n        + taskStatus.getProgress());\n    // Task sends the updated state-string to the TT.\n    taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n    // Task sends the updated phase to the TT.\n    taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n    // Counters are updated by the task. Convert counters into new format as\n    // that is the primary storage format inside the AM to avoid multiple\n    // conversions and unnecessary heap usage.\n    taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n      taskStatus.getCounters());\n\n    // Map Finish time set by the task (map only)\n    if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n      taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n    }\n\n    // Shuffle Finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n      taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n    }\n\n    // Sort finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n      taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n    }\n\n    // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n    //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n    \n    //set the fetch failures\n    if (taskStatus.getFetchFailedMaps() !\u003d null \n        \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n      taskAttemptStatus.fetchFailedMaps \u003d \n        new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n      for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n        taskAttemptStatus.fetchFailedMaps.add(\n            TypeConverter.toYarn(failedMapId));\n      }\n    }\n\n // Task sends the information about the nextRecordRange to the TT\n    \n//    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n//    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n//    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n//    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n//    // This was used by TT to do counter updates only once every minute. So this\n//    // isn\u0027t ever changed by the Task itself.\n//    taskStatus.getIncludeCounters();\n\n    context.getEventHandler().handle(\n        new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n            taskAttemptStatus));\n    return feedback;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java",
      "extendedDetails": {}
    },
    "47cca0cb6d1f4e5979d11d9a624b005e6e666f2f": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "MAPREDUCE-5196. Add bookkeeping for managing checkpoints of task state.\nContributed by Carlo Curino\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1553939 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/12/13 1:58 PM",
      "commitName": "47cca0cb6d1f4e5979d11d9a624b005e6e666f2f",
      "commitAuthor": "Christopher Douglas",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "MAPREDUCE-5196. Add bookkeeping for managing checkpoints of task state.\nContributed by Carlo Curino\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1553939 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "28/12/13 1:58 PM",
          "commitName": "47cca0cb6d1f4e5979d11d9a624b005e6e666f2f",
          "commitAuthor": "Christopher Douglas",
          "commitDateOld": "17/12/13 2:54 PM",
          "commitNameOld": "9ca394d54dd24e67867c845a58150f6b51761512",
          "commitAuthorOld": "Christopher Douglas",
          "daysBetweenCommits": 10.96,
          "commitsBetweenForRepo": 37,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,67 +1,89 @@\n-  public boolean statusUpdate(TaskAttemptID taskAttemptID,\n+  public AMFeedback statusUpdate(TaskAttemptID taskAttemptID,\n       TaskStatus taskStatus) throws IOException, InterruptedException {\n-    LOG.info(\"Status update from \" + taskAttemptID.toString());\n+\n     org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n         TypeConverter.toYarn(taskAttemptID);\n+\n+    AMFeedback feedback \u003d new AMFeedback();\n+    feedback.setTaskFound(true);\n+\n+    // Propagating preemption to the task if TASK_PREEMPTION is enabled\n+    if (getConfig().getBoolean(MRJobConfig.TASK_PREEMPTION, false)\n+        \u0026\u0026 preemptionPolicy.isPreempted(yarnAttemptID)) {\n+      feedback.setPreemption(true);\n+      LOG.info(\"Setting preemption bit for task: \"+ yarnAttemptID\n+          + \" of type \" + yarnAttemptID.getTaskId().getTaskType());\n+    }\n+\n+    if (taskStatus \u003d\u003d null) {\n+      //We are using statusUpdate only as a simple ping\n+      LOG.info(\"Ping from \" + taskAttemptID.toString());\n+      taskHeartbeatHandler.progressing(yarnAttemptID);\n+      return feedback;\n+    }\n+\n+    // if we are here there is an actual status update to be processed\n+    LOG.info(\"Status update from \" + taskAttemptID.toString());\n+\n     taskHeartbeatHandler.progressing(yarnAttemptID);\n     TaskAttemptStatus taskAttemptStatus \u003d\n         new TaskAttemptStatus();\n     taskAttemptStatus.id \u003d yarnAttemptID;\n     // Task sends the updated progress to the TT.\n     taskAttemptStatus.progress \u003d taskStatus.getProgress();\n     LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n         + taskStatus.getProgress());\n     // Task sends the updated state-string to the TT.\n     taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n     // Task sends the updated phase to the TT.\n     taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n     // Counters are updated by the task. Convert counters into new format as\n     // that is the primary storage format inside the AM to avoid multiple\n     // conversions and unnecessary heap usage.\n     taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n       taskStatus.getCounters());\n \n     // Map Finish time set by the task (map only)\n     if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n       taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n     }\n \n     // Shuffle Finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n       taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n     }\n \n     // Sort finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n       taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n     }\n \n     // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n     //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n     \n     //set the fetch failures\n     if (taskStatus.getFetchFailedMaps() !\u003d null \n         \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n       taskAttemptStatus.fetchFailedMaps \u003d \n         new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n       for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n         taskAttemptStatus.fetchFailedMaps.add(\n             TypeConverter.toYarn(failedMapId));\n       }\n     }\n \n  // Task sends the information about the nextRecordRange to the TT\n     \n //    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n //    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n //    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n //    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n //    // This was used by TT to do counter updates only once every minute. So this\n //    // isn\u0027t ever changed by the Task itself.\n //    taskStatus.getIncludeCounters();\n \n     context.getEventHandler().handle(\n         new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n             taskAttemptStatus));\n-    return true;\n+    return feedback;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public AMFeedback statusUpdate(TaskAttemptID taskAttemptID,\n      TaskStatus taskStatus) throws IOException, InterruptedException {\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n        TypeConverter.toYarn(taskAttemptID);\n\n    AMFeedback feedback \u003d new AMFeedback();\n    feedback.setTaskFound(true);\n\n    // Propagating preemption to the task if TASK_PREEMPTION is enabled\n    if (getConfig().getBoolean(MRJobConfig.TASK_PREEMPTION, false)\n        \u0026\u0026 preemptionPolicy.isPreempted(yarnAttemptID)) {\n      feedback.setPreemption(true);\n      LOG.info(\"Setting preemption bit for task: \"+ yarnAttemptID\n          + \" of type \" + yarnAttemptID.getTaskId().getTaskType());\n    }\n\n    if (taskStatus \u003d\u003d null) {\n      //We are using statusUpdate only as a simple ping\n      LOG.info(\"Ping from \" + taskAttemptID.toString());\n      taskHeartbeatHandler.progressing(yarnAttemptID);\n      return feedback;\n    }\n\n    // if we are here there is an actual status update to be processed\n    LOG.info(\"Status update from \" + taskAttemptID.toString());\n\n    taskHeartbeatHandler.progressing(yarnAttemptID);\n    TaskAttemptStatus taskAttemptStatus \u003d\n        new TaskAttemptStatus();\n    taskAttemptStatus.id \u003d yarnAttemptID;\n    // Task sends the updated progress to the TT.\n    taskAttemptStatus.progress \u003d taskStatus.getProgress();\n    LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n        + taskStatus.getProgress());\n    // Task sends the updated state-string to the TT.\n    taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n    // Task sends the updated phase to the TT.\n    taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n    // Counters are updated by the task. Convert counters into new format as\n    // that is the primary storage format inside the AM to avoid multiple\n    // conversions and unnecessary heap usage.\n    taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n      taskStatus.getCounters());\n\n    // Map Finish time set by the task (map only)\n    if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n      taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n    }\n\n    // Shuffle Finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n      taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n    }\n\n    // Sort finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n      taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n    }\n\n    // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n    //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n    \n    //set the fetch failures\n    if (taskStatus.getFetchFailedMaps() !\u003d null \n        \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n      taskAttemptStatus.fetchFailedMaps \u003d \n        new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n      for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n        taskAttemptStatus.fetchFailedMaps.add(\n            TypeConverter.toYarn(failedMapId));\n      }\n    }\n\n // Task sends the information about the nextRecordRange to the TT\n    \n//    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n//    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n//    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n//    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n//    // This was used by TT to do counter updates only once every minute. So this\n//    // isn\u0027t ever changed by the Task itself.\n//    taskStatus.getIncludeCounters();\n\n    context.getEventHandler().handle(\n        new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n            taskAttemptStatus));\n    return feedback;\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java",
          "extendedDetails": {
            "oldValue": "boolean",
            "newValue": "AMFeedback"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-5196. Add bookkeeping for managing checkpoints of task state.\nContributed by Carlo Curino\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1553939 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "28/12/13 1:58 PM",
          "commitName": "47cca0cb6d1f4e5979d11d9a624b005e6e666f2f",
          "commitAuthor": "Christopher Douglas",
          "commitDateOld": "17/12/13 2:54 PM",
          "commitNameOld": "9ca394d54dd24e67867c845a58150f6b51761512",
          "commitAuthorOld": "Christopher Douglas",
          "daysBetweenCommits": 10.96,
          "commitsBetweenForRepo": 37,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,67 +1,89 @@\n-  public boolean statusUpdate(TaskAttemptID taskAttemptID,\n+  public AMFeedback statusUpdate(TaskAttemptID taskAttemptID,\n       TaskStatus taskStatus) throws IOException, InterruptedException {\n-    LOG.info(\"Status update from \" + taskAttemptID.toString());\n+\n     org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n         TypeConverter.toYarn(taskAttemptID);\n+\n+    AMFeedback feedback \u003d new AMFeedback();\n+    feedback.setTaskFound(true);\n+\n+    // Propagating preemption to the task if TASK_PREEMPTION is enabled\n+    if (getConfig().getBoolean(MRJobConfig.TASK_PREEMPTION, false)\n+        \u0026\u0026 preemptionPolicy.isPreempted(yarnAttemptID)) {\n+      feedback.setPreemption(true);\n+      LOG.info(\"Setting preemption bit for task: \"+ yarnAttemptID\n+          + \" of type \" + yarnAttemptID.getTaskId().getTaskType());\n+    }\n+\n+    if (taskStatus \u003d\u003d null) {\n+      //We are using statusUpdate only as a simple ping\n+      LOG.info(\"Ping from \" + taskAttemptID.toString());\n+      taskHeartbeatHandler.progressing(yarnAttemptID);\n+      return feedback;\n+    }\n+\n+    // if we are here there is an actual status update to be processed\n+    LOG.info(\"Status update from \" + taskAttemptID.toString());\n+\n     taskHeartbeatHandler.progressing(yarnAttemptID);\n     TaskAttemptStatus taskAttemptStatus \u003d\n         new TaskAttemptStatus();\n     taskAttemptStatus.id \u003d yarnAttemptID;\n     // Task sends the updated progress to the TT.\n     taskAttemptStatus.progress \u003d taskStatus.getProgress();\n     LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n         + taskStatus.getProgress());\n     // Task sends the updated state-string to the TT.\n     taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n     // Task sends the updated phase to the TT.\n     taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n     // Counters are updated by the task. Convert counters into new format as\n     // that is the primary storage format inside the AM to avoid multiple\n     // conversions and unnecessary heap usage.\n     taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n       taskStatus.getCounters());\n \n     // Map Finish time set by the task (map only)\n     if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n       taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n     }\n \n     // Shuffle Finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n       taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n     }\n \n     // Sort finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n       taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n     }\n \n     // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n     //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n     \n     //set the fetch failures\n     if (taskStatus.getFetchFailedMaps() !\u003d null \n         \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n       taskAttemptStatus.fetchFailedMaps \u003d \n         new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n       for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n         taskAttemptStatus.fetchFailedMaps.add(\n             TypeConverter.toYarn(failedMapId));\n       }\n     }\n \n  // Task sends the information about the nextRecordRange to the TT\n     \n //    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n //    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n //    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n //    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n //    // This was used by TT to do counter updates only once every minute. So this\n //    // isn\u0027t ever changed by the Task itself.\n //    taskStatus.getIncludeCounters();\n \n     context.getEventHandler().handle(\n         new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n             taskAttemptStatus));\n-    return true;\n+    return feedback;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public AMFeedback statusUpdate(TaskAttemptID taskAttemptID,\n      TaskStatus taskStatus) throws IOException, InterruptedException {\n\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n        TypeConverter.toYarn(taskAttemptID);\n\n    AMFeedback feedback \u003d new AMFeedback();\n    feedback.setTaskFound(true);\n\n    // Propagating preemption to the task if TASK_PREEMPTION is enabled\n    if (getConfig().getBoolean(MRJobConfig.TASK_PREEMPTION, false)\n        \u0026\u0026 preemptionPolicy.isPreempted(yarnAttemptID)) {\n      feedback.setPreemption(true);\n      LOG.info(\"Setting preemption bit for task: \"+ yarnAttemptID\n          + \" of type \" + yarnAttemptID.getTaskId().getTaskType());\n    }\n\n    if (taskStatus \u003d\u003d null) {\n      //We are using statusUpdate only as a simple ping\n      LOG.info(\"Ping from \" + taskAttemptID.toString());\n      taskHeartbeatHandler.progressing(yarnAttemptID);\n      return feedback;\n    }\n\n    // if we are here there is an actual status update to be processed\n    LOG.info(\"Status update from \" + taskAttemptID.toString());\n\n    taskHeartbeatHandler.progressing(yarnAttemptID);\n    TaskAttemptStatus taskAttemptStatus \u003d\n        new TaskAttemptStatus();\n    taskAttemptStatus.id \u003d yarnAttemptID;\n    // Task sends the updated progress to the TT.\n    taskAttemptStatus.progress \u003d taskStatus.getProgress();\n    LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n        + taskStatus.getProgress());\n    // Task sends the updated state-string to the TT.\n    taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n    // Task sends the updated phase to the TT.\n    taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n    // Counters are updated by the task. Convert counters into new format as\n    // that is the primary storage format inside the AM to avoid multiple\n    // conversions and unnecessary heap usage.\n    taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n      taskStatus.getCounters());\n\n    // Map Finish time set by the task (map only)\n    if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n      taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n    }\n\n    // Shuffle Finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n      taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n    }\n\n    // Sort finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n      taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n    }\n\n    // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n    //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n    \n    //set the fetch failures\n    if (taskStatus.getFetchFailedMaps() !\u003d null \n        \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n      taskAttemptStatus.fetchFailedMaps \u003d \n        new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n      for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n        taskAttemptStatus.fetchFailedMaps.add(\n            TypeConverter.toYarn(failedMapId));\n      }\n    }\n\n // Task sends the information about the nextRecordRange to the TT\n    \n//    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n//    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n//    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n//    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n//    // This was used by TT to do counter updates only once every minute. So this\n//    // isn\u0027t ever changed by the Task itself.\n//    taskStatus.getIncludeCounters();\n\n    context.getEventHandler().handle(\n        new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n            taskAttemptStatus));\n    return feedback;\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java",
          "extendedDetails": {}
        }
      ]
    },
    "905b17876c44634545a68300ff2f2d73fb86d3b7": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4723. Fix warnings found by findbugs 2. Contributed by Sandy Ryza\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1409601 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/11/12 4:16 PM",
      "commitName": "905b17876c44634545a68300ff2f2d73fb86d3b7",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "31/10/12 7:57 AM",
      "commitNameOld": "aac5c149c7ca500b8eb810b7d4b561ff1e38ea02",
      "commitAuthorOld": "Thomas Graves",
      "daysBetweenCommits": 14.39,
      "commitsBetweenForRepo": 88,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,67 @@\n   public boolean statusUpdate(TaskAttemptID taskAttemptID,\n       TaskStatus taskStatus) throws IOException, InterruptedException {\n     LOG.info(\"Status update from \" + taskAttemptID.toString());\n     org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n         TypeConverter.toYarn(taskAttemptID);\n     taskHeartbeatHandler.progressing(yarnAttemptID);\n     TaskAttemptStatus taskAttemptStatus \u003d\n         new TaskAttemptStatus();\n     taskAttemptStatus.id \u003d yarnAttemptID;\n     // Task sends the updated progress to the TT.\n     taskAttemptStatus.progress \u003d taskStatus.getProgress();\n     LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n         + taskStatus.getProgress());\n     // Task sends the updated state-string to the TT.\n     taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n-    // Set the output-size when map-task finishes. Set by the task itself.\n-    taskAttemptStatus.outputSize \u003d taskStatus.getOutputSize();\n     // Task sends the updated phase to the TT.\n     taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n     // Counters are updated by the task. Convert counters into new format as\n     // that is the primary storage format inside the AM to avoid multiple\n     // conversions and unnecessary heap usage.\n     taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n       taskStatus.getCounters());\n \n     // Map Finish time set by the task (map only)\n     if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n       taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n     }\n \n     // Shuffle Finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n       taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n     }\n \n     // Sort finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n       taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n     }\n \n     // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n     //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n     \n     //set the fetch failures\n     if (taskStatus.getFetchFailedMaps() !\u003d null \n         \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n       taskAttemptStatus.fetchFailedMaps \u003d \n         new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n       for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n         taskAttemptStatus.fetchFailedMaps.add(\n             TypeConverter.toYarn(failedMapId));\n       }\n     }\n \n  // Task sends the information about the nextRecordRange to the TT\n     \n //    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n //    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n //    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n //    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n //    // This was used by TT to do counter updates only once every minute. So this\n //    // isn\u0027t ever changed by the Task itself.\n //    taskStatus.getIncludeCounters();\n \n     context.getEventHandler().handle(\n         new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n             taskAttemptStatus));\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean statusUpdate(TaskAttemptID taskAttemptID,\n      TaskStatus taskStatus) throws IOException, InterruptedException {\n    LOG.info(\"Status update from \" + taskAttemptID.toString());\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n        TypeConverter.toYarn(taskAttemptID);\n    taskHeartbeatHandler.progressing(yarnAttemptID);\n    TaskAttemptStatus taskAttemptStatus \u003d\n        new TaskAttemptStatus();\n    taskAttemptStatus.id \u003d yarnAttemptID;\n    // Task sends the updated progress to the TT.\n    taskAttemptStatus.progress \u003d taskStatus.getProgress();\n    LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n        + taskStatus.getProgress());\n    // Task sends the updated state-string to the TT.\n    taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n    // Task sends the updated phase to the TT.\n    taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n    // Counters are updated by the task. Convert counters into new format as\n    // that is the primary storage format inside the AM to avoid multiple\n    // conversions and unnecessary heap usage.\n    taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n      taskStatus.getCounters());\n\n    // Map Finish time set by the task (map only)\n    if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n      taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n    }\n\n    // Shuffle Finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n      taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n    }\n\n    // Sort finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n      taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n    }\n\n    // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n    //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n    \n    //set the fetch failures\n    if (taskStatus.getFetchFailedMaps() !\u003d null \n        \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n      taskAttemptStatus.fetchFailedMaps \u003d \n        new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n      for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n        taskAttemptStatus.fetchFailedMaps.add(\n            TypeConverter.toYarn(failedMapId));\n      }\n    }\n\n // Task sends the information about the nextRecordRange to the TT\n    \n//    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n//    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n//    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n//    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n//    // This was used by TT to do counter updates only once every minute. So this\n//    // isn\u0027t ever changed by the Task itself.\n//    taskStatus.getIncludeCounters();\n\n    context.getEventHandler().handle(\n        new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n            taskAttemptStatus));\n    return true;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java",
      "extendedDetails": {}
    },
    "bb74427da27ab90ade868c4fd89ed8ac3310aea2": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4089. Hung Tasks never time out. (Robert Evans via tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308531 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/04/12 1:20 PM",
      "commitName": "bb74427da27ab90ade868c4fd89ed8ac3310aea2",
      "commitAuthor": "Thomas Graves",
      "commitDateOld": "13/01/12 1:31 PM",
      "commitNameOld": "0c278b0f636a01c81aba9e46fe7658fcdfb0f33c",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 79.95,
      "commitsBetweenForRepo": 599,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,69 @@\n   public boolean statusUpdate(TaskAttemptID taskAttemptID,\n       TaskStatus taskStatus) throws IOException, InterruptedException {\n     LOG.info(\"Status update from \" + taskAttemptID.toString());\n     org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n         TypeConverter.toYarn(taskAttemptID);\n-    taskHeartbeatHandler.receivedPing(yarnAttemptID);\n+    taskHeartbeatHandler.progressing(yarnAttemptID);\n     TaskAttemptStatus taskAttemptStatus \u003d\n         new TaskAttemptStatus();\n     taskAttemptStatus.id \u003d yarnAttemptID;\n     // Task sends the updated progress to the TT.\n     taskAttemptStatus.progress \u003d taskStatus.getProgress();\n     LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n         + taskStatus.getProgress());\n     // Task sends the updated state-string to the TT.\n     taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n     // Set the output-size when map-task finishes. Set by the task itself.\n     taskAttemptStatus.outputSize \u003d taskStatus.getOutputSize();\n     // Task sends the updated phase to the TT.\n     taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n     // Counters are updated by the task. Convert counters into new format as\n     // that is the primary storage format inside the AM to avoid multiple\n     // conversions and unnecessary heap usage.\n     taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n       taskStatus.getCounters());\n \n     // Map Finish time set by the task (map only)\n     if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n       taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n     }\n \n     // Shuffle Finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n       taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n     }\n \n     // Sort finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n       taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n     }\n \n     // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n     //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n     \n     //set the fetch failures\n     if (taskStatus.getFetchFailedMaps() !\u003d null \n         \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n       taskAttemptStatus.fetchFailedMaps \u003d \n         new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n       for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n         taskAttemptStatus.fetchFailedMaps.add(\n             TypeConverter.toYarn(failedMapId));\n       }\n     }\n \n  // Task sends the information about the nextRecordRange to the TT\n     \n //    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n //    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n //    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n //    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n //    // This was used by TT to do counter updates only once every minute. So this\n //    // isn\u0027t ever changed by the Task itself.\n //    taskStatus.getIncludeCounters();\n \n     context.getEventHandler().handle(\n         new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n             taskAttemptStatus));\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean statusUpdate(TaskAttemptID taskAttemptID,\n      TaskStatus taskStatus) throws IOException, InterruptedException {\n    LOG.info(\"Status update from \" + taskAttemptID.toString());\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n        TypeConverter.toYarn(taskAttemptID);\n    taskHeartbeatHandler.progressing(yarnAttemptID);\n    TaskAttemptStatus taskAttemptStatus \u003d\n        new TaskAttemptStatus();\n    taskAttemptStatus.id \u003d yarnAttemptID;\n    // Task sends the updated progress to the TT.\n    taskAttemptStatus.progress \u003d taskStatus.getProgress();\n    LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n        + taskStatus.getProgress());\n    // Task sends the updated state-string to the TT.\n    taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n    // Set the output-size when map-task finishes. Set by the task itself.\n    taskAttemptStatus.outputSize \u003d taskStatus.getOutputSize();\n    // Task sends the updated phase to the TT.\n    taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n    // Counters are updated by the task. Convert counters into new format as\n    // that is the primary storage format inside the AM to avoid multiple\n    // conversions and unnecessary heap usage.\n    taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n      taskStatus.getCounters());\n\n    // Map Finish time set by the task (map only)\n    if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n      taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n    }\n\n    // Shuffle Finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n      taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n    }\n\n    // Sort finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n      taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n    }\n\n    // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n    //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n    \n    //set the fetch failures\n    if (taskStatus.getFetchFailedMaps() !\u003d null \n        \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n      taskAttemptStatus.fetchFailedMaps \u003d \n        new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n      for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n        taskAttemptStatus.fetchFailedMaps.add(\n            TypeConverter.toYarn(failedMapId));\n      }\n    }\n\n // Task sends the information about the nextRecordRange to the TT\n    \n//    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n//    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n//    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n//    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n//    // This was used by TT to do counter updates only once every minute. So this\n//    // isn\u0027t ever changed by the Task itself.\n//    taskStatus.getIncludeCounters();\n\n    context.getEventHandler().handle(\n        new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n            taskAttemptStatus));\n    return true;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java",
      "extendedDetails": {}
    },
    "e8645636ce1721aa6dc3674fbc553a7bb3522fbe": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3511. Removed a multitude of cloned/duplicate counters in the AM thereby reducing the AM heap size and preventing full GCs. (vinodkv)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1229347 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/12 1:04 PM",
      "commitName": "e8645636ce1721aa6dc3674fbc553a7bb3522fbe",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "04/01/12 9:19 PM",
      "commitNameOld": "03d46dc571bc5b0f1b3c0cb5daa52e7ee324dd54",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 4.66,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,69 @@\n   public boolean statusUpdate(TaskAttemptID taskAttemptID,\n       TaskStatus taskStatus) throws IOException, InterruptedException {\n     LOG.info(\"Status update from \" + taskAttemptID.toString());\n     org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n         TypeConverter.toYarn(taskAttemptID);\n     taskHeartbeatHandler.receivedPing(yarnAttemptID);\n     TaskAttemptStatus taskAttemptStatus \u003d\n         new TaskAttemptStatus();\n     taskAttemptStatus.id \u003d yarnAttemptID;\n     // Task sends the updated progress to the TT.\n     taskAttemptStatus.progress \u003d taskStatus.getProgress();\n     LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n         + taskStatus.getProgress());\n     // Task sends the updated state-string to the TT.\n     taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n     // Set the output-size when map-task finishes. Set by the task itself.\n     taskAttemptStatus.outputSize \u003d taskStatus.getOutputSize();\n     // Task sends the updated phase to the TT.\n     taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n-    // Counters are updated by the task.\n-    taskAttemptStatus.counters \u003d\n-        TypeConverter.toYarn(taskStatus.getCounters());\n+    // Counters are updated by the task. Convert counters into new format as\n+    // that is the primary storage format inside the AM to avoid multiple\n+    // conversions and unnecessary heap usage.\n+    taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n+      taskStatus.getCounters());\n \n     // Map Finish time set by the task (map only)\n     if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n       taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n     }\n \n     // Shuffle Finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n       taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n     }\n \n     // Sort finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n       taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n     }\n \n     // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n     //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n     \n     //set the fetch failures\n     if (taskStatus.getFetchFailedMaps() !\u003d null \n         \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n       taskAttemptStatus.fetchFailedMaps \u003d \n         new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n       for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n         taskAttemptStatus.fetchFailedMaps.add(\n             TypeConverter.toYarn(failedMapId));\n       }\n     }\n \n  // Task sends the information about the nextRecordRange to the TT\n     \n //    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n //    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n //    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n //    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n //    // This was used by TT to do counter updates only once every minute. So this\n //    // isn\u0027t ever changed by the Task itself.\n //    taskStatus.getIncludeCounters();\n \n     context.getEventHandler().handle(\n         new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n             taskAttemptStatus));\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean statusUpdate(TaskAttemptID taskAttemptID,\n      TaskStatus taskStatus) throws IOException, InterruptedException {\n    LOG.info(\"Status update from \" + taskAttemptID.toString());\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n        TypeConverter.toYarn(taskAttemptID);\n    taskHeartbeatHandler.receivedPing(yarnAttemptID);\n    TaskAttemptStatus taskAttemptStatus \u003d\n        new TaskAttemptStatus();\n    taskAttemptStatus.id \u003d yarnAttemptID;\n    // Task sends the updated progress to the TT.\n    taskAttemptStatus.progress \u003d taskStatus.getProgress();\n    LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n        + taskStatus.getProgress());\n    // Task sends the updated state-string to the TT.\n    taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n    // Set the output-size when map-task finishes. Set by the task itself.\n    taskAttemptStatus.outputSize \u003d taskStatus.getOutputSize();\n    // Task sends the updated phase to the TT.\n    taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n    // Counters are updated by the task. Convert counters into new format as\n    // that is the primary storage format inside the AM to avoid multiple\n    // conversions and unnecessary heap usage.\n    taskAttemptStatus.counters \u003d new org.apache.hadoop.mapreduce.Counters(\n      taskStatus.getCounters());\n\n    // Map Finish time set by the task (map only)\n    if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n      taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n    }\n\n    // Shuffle Finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n      taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n    }\n\n    // Sort finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n      taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n    }\n\n    // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n    //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n    \n    //set the fetch failures\n    if (taskStatus.getFetchFailedMaps() !\u003d null \n        \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n      taskAttemptStatus.fetchFailedMaps \u003d \n        new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n      for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n        taskAttemptStatus.fetchFailedMaps.add(\n            TypeConverter.toYarn(failedMapId));\n      }\n    }\n\n // Task sends the information about the nextRecordRange to the TT\n    \n//    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n//    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n//    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n//    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n//    // This was used by TT to do counter updates only once every minute. So this\n//    // isn\u0027t ever changed by the Task itself.\n//    taskStatus.getIncludeCounters();\n\n    context.getEventHandler().handle(\n        new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n            taskAttemptStatus));\n    return true;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java",
      "extendedDetails": {}
    },
    "a26b1672a85e97bea973cfcc7eab22b4cca01448": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3032. Fixed TaskAttemptImpl so that JobHistory can have error information about failed tasks. Contributed by Devaraj K.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1185247 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/10/11 8:17 AM",
      "commitName": "a26b1672a85e97bea973cfcc7eab22b4cca01448",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "08/09/11 6:44 PM",
      "commitNameOld": "fafe8cd28e726566509c679e19d7da622f29f90d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 38.56,
      "commitsBetweenForRepo": 276,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,67 @@\n   public boolean statusUpdate(TaskAttemptID taskAttemptID,\n       TaskStatus taskStatus) throws IOException, InterruptedException {\n     LOG.info(\"Status update from \" + taskAttemptID.toString());\n     org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n         TypeConverter.toYarn(taskAttemptID);\n     taskHeartbeatHandler.receivedPing(yarnAttemptID);\n     TaskAttemptStatus taskAttemptStatus \u003d\n         new TaskAttemptStatus();\n     taskAttemptStatus.id \u003d yarnAttemptID;\n     // Task sends the updated progress to the TT.\n     taskAttemptStatus.progress \u003d taskStatus.getProgress();\n     LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n         + taskStatus.getProgress());\n-    // Task sends the diagnostic information to the TT\n-    taskAttemptStatus.diagnosticInfo \u003d taskStatus.getDiagnosticInfo();\n     // Task sends the updated state-string to the TT.\n     taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n     // Set the output-size when map-task finishes. Set by the task itself.\n     taskAttemptStatus.outputSize \u003d taskStatus.getOutputSize();\n     // Task sends the updated phase to the TT.\n     taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n     // Counters are updated by the task.\n     taskAttemptStatus.counters \u003d\n         TypeConverter.toYarn(taskStatus.getCounters());\n \n     // Map Finish time set by the task (map only)\n     if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n       taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n     }\n \n     // Shuffle Finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n       taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n     }\n \n     // Sort finish time set by the task (reduce only).\n     if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n       taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n     }\n \n     // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n     //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n     \n     //set the fetch failures\n     if (taskStatus.getFetchFailedMaps() !\u003d null \n         \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n       taskAttemptStatus.fetchFailedMaps \u003d \n         new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n       for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n         taskAttemptStatus.fetchFailedMaps.add(\n             TypeConverter.toYarn(failedMapId));\n       }\n     }\n \n  // Task sends the information about the nextRecordRange to the TT\n     \n //    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n //    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n //    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n //    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n //    // This was used by TT to do counter updates only once every minute. So this\n //    // isn\u0027t ever changed by the Task itself.\n //    taskStatus.getIncludeCounters();\n \n     context.getEventHandler().handle(\n         new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n             taskAttemptStatus));\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean statusUpdate(TaskAttemptID taskAttemptID,\n      TaskStatus taskStatus) throws IOException, InterruptedException {\n    LOG.info(\"Status update from \" + taskAttemptID.toString());\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n        TypeConverter.toYarn(taskAttemptID);\n    taskHeartbeatHandler.receivedPing(yarnAttemptID);\n    TaskAttemptStatus taskAttemptStatus \u003d\n        new TaskAttemptStatus();\n    taskAttemptStatus.id \u003d yarnAttemptID;\n    // Task sends the updated progress to the TT.\n    taskAttemptStatus.progress \u003d taskStatus.getProgress();\n    LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n        + taskStatus.getProgress());\n    // Task sends the updated state-string to the TT.\n    taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n    // Set the output-size when map-task finishes. Set by the task itself.\n    taskAttemptStatus.outputSize \u003d taskStatus.getOutputSize();\n    // Task sends the updated phase to the TT.\n    taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n    // Counters are updated by the task.\n    taskAttemptStatus.counters \u003d\n        TypeConverter.toYarn(taskStatus.getCounters());\n\n    // Map Finish time set by the task (map only)\n    if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n      taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n    }\n\n    // Shuffle Finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n      taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n    }\n\n    // Sort finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n      taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n    }\n\n    // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n    //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n    \n    //set the fetch failures\n    if (taskStatus.getFetchFailedMaps() !\u003d null \n        \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n      taskAttemptStatus.fetchFailedMaps \u003d \n        new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n      for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n        taskAttemptStatus.fetchFailedMaps.add(\n            TypeConverter.toYarn(failedMapId));\n      }\n    }\n\n // Task sends the information about the nextRecordRange to the TT\n    \n//    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n//    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n//    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n//    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n//    // This was used by TT to do counter updates only once every minute. So this\n//    // isn\u0027t ever changed by the Task itself.\n//    taskStatus.getIncludeCounters();\n\n    context.getEventHandler().handle(\n        new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n            taskAttemptStatus));\n    return true;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public boolean statusUpdate(TaskAttemptID taskAttemptID,\n      TaskStatus taskStatus) throws IOException, InterruptedException {\n    LOG.info(\"Status update from \" + taskAttemptID.toString());\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n        TypeConverter.toYarn(taskAttemptID);\n    taskHeartbeatHandler.receivedPing(yarnAttemptID);\n    TaskAttemptStatus taskAttemptStatus \u003d\n        new TaskAttemptStatus();\n    taskAttemptStatus.id \u003d yarnAttemptID;\n    // Task sends the updated progress to the TT.\n    taskAttemptStatus.progress \u003d taskStatus.getProgress();\n    LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n        + taskStatus.getProgress());\n    // Task sends the diagnostic information to the TT\n    taskAttemptStatus.diagnosticInfo \u003d taskStatus.getDiagnosticInfo();\n    // Task sends the updated state-string to the TT.\n    taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n    // Set the output-size when map-task finishes. Set by the task itself.\n    taskAttemptStatus.outputSize \u003d taskStatus.getOutputSize();\n    // Task sends the updated phase to the TT.\n    taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n    // Counters are updated by the task.\n    taskAttemptStatus.counters \u003d\n        TypeConverter.toYarn(taskStatus.getCounters());\n\n    // Map Finish time set by the task (map only)\n    if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n      taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n    }\n\n    // Shuffle Finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n      taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n    }\n\n    // Sort finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n      taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n    }\n\n    // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n    //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n    \n    //set the fetch failures\n    if (taskStatus.getFetchFailedMaps() !\u003d null \n        \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n      taskAttemptStatus.fetchFailedMaps \u003d \n        new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n      for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n        taskAttemptStatus.fetchFailedMaps.add(\n            TypeConverter.toYarn(failedMapId));\n      }\n    }\n\n // Task sends the information about the nextRecordRange to the TT\n    \n//    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n//    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n//    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n//    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n//    // This was used by TT to do counter updates only once every minute. So this\n//    // isn\u0027t ever changed by the Task itself.\n//    taskStatus.getIncludeCounters();\n\n    context.getEventHandler().handle(\n        new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n            taskAttemptStatus));\n    return true;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,69 @@\n+  public boolean statusUpdate(TaskAttemptID taskAttemptID,\n+      TaskStatus taskStatus) throws IOException, InterruptedException {\n+    LOG.info(\"Status update from \" + taskAttemptID.toString());\n+    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n+        TypeConverter.toYarn(taskAttemptID);\n+    taskHeartbeatHandler.receivedPing(yarnAttemptID);\n+    TaskAttemptStatus taskAttemptStatus \u003d\n+        new TaskAttemptStatus();\n+    taskAttemptStatus.id \u003d yarnAttemptID;\n+    // Task sends the updated progress to the TT.\n+    taskAttemptStatus.progress \u003d taskStatus.getProgress();\n+    LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n+        + taskStatus.getProgress());\n+    // Task sends the diagnostic information to the TT\n+    taskAttemptStatus.diagnosticInfo \u003d taskStatus.getDiagnosticInfo();\n+    // Task sends the updated state-string to the TT.\n+    taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n+    // Set the output-size when map-task finishes. Set by the task itself.\n+    taskAttemptStatus.outputSize \u003d taskStatus.getOutputSize();\n+    // Task sends the updated phase to the TT.\n+    taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n+    // Counters are updated by the task.\n+    taskAttemptStatus.counters \u003d\n+        TypeConverter.toYarn(taskStatus.getCounters());\n+\n+    // Map Finish time set by the task (map only)\n+    if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n+      taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n+    }\n+\n+    // Shuffle Finish time set by the task (reduce only).\n+    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n+      taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n+    }\n+\n+    // Sort finish time set by the task (reduce only).\n+    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n+      taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n+    }\n+\n+    // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n+    //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n+    \n+    //set the fetch failures\n+    if (taskStatus.getFetchFailedMaps() !\u003d null \n+        \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n+      taskAttemptStatus.fetchFailedMaps \u003d \n+        new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n+      for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n+        taskAttemptStatus.fetchFailedMaps.add(\n+            TypeConverter.toYarn(failedMapId));\n+      }\n+    }\n+\n+ // Task sends the information about the nextRecordRange to the TT\n+    \n+//    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n+//    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n+//    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n+//    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n+//    // This was used by TT to do counter updates only once every minute. So this\n+//    // isn\u0027t ever changed by the Task itself.\n+//    taskStatus.getIncludeCounters();\n+\n+    context.getEventHandler().handle(\n+        new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n+            taskAttemptStatus));\n+    return true;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean statusUpdate(TaskAttemptID taskAttemptID,\n      TaskStatus taskStatus) throws IOException, InterruptedException {\n    LOG.info(\"Status update from \" + taskAttemptID.toString());\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId yarnAttemptID \u003d\n        TypeConverter.toYarn(taskAttemptID);\n    taskHeartbeatHandler.receivedPing(yarnAttemptID);\n    TaskAttemptStatus taskAttemptStatus \u003d\n        new TaskAttemptStatus();\n    taskAttemptStatus.id \u003d yarnAttemptID;\n    // Task sends the updated progress to the TT.\n    taskAttemptStatus.progress \u003d taskStatus.getProgress();\n    LOG.info(\"Progress of TaskAttempt \" + taskAttemptID + \" is : \"\n        + taskStatus.getProgress());\n    // Task sends the diagnostic information to the TT\n    taskAttemptStatus.diagnosticInfo \u003d taskStatus.getDiagnosticInfo();\n    // Task sends the updated state-string to the TT.\n    taskAttemptStatus.stateString \u003d taskStatus.getStateString();\n    // Set the output-size when map-task finishes. Set by the task itself.\n    taskAttemptStatus.outputSize \u003d taskStatus.getOutputSize();\n    // Task sends the updated phase to the TT.\n    taskAttemptStatus.phase \u003d TypeConverter.toYarn(taskStatus.getPhase());\n    // Counters are updated by the task.\n    taskAttemptStatus.counters \u003d\n        TypeConverter.toYarn(taskStatus.getCounters());\n\n    // Map Finish time set by the task (map only)\n    if (taskStatus.getIsMap() \u0026\u0026 taskStatus.getMapFinishTime() !\u003d 0) {\n      taskAttemptStatus.mapFinishTime \u003d taskStatus.getMapFinishTime();\n    }\n\n    // Shuffle Finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getShuffleFinishTime() !\u003d 0) {\n      taskAttemptStatus.shuffleFinishTime \u003d taskStatus.getShuffleFinishTime();\n    }\n\n    // Sort finish time set by the task (reduce only).\n    if (!taskStatus.getIsMap() \u0026\u0026 taskStatus.getSortFinishTime() !\u003d 0) {\n      taskAttemptStatus.sortFinishTime \u003d taskStatus.getSortFinishTime();\n    }\n\n    // Not Setting the task state. Used by speculation - will be set in TaskAttemptImpl\n    //taskAttemptStatus.taskState \u003d  TypeConverter.toYarn(taskStatus.getRunState());\n    \n    //set the fetch failures\n    if (taskStatus.getFetchFailedMaps() !\u003d null \n        \u0026\u0026 taskStatus.getFetchFailedMaps().size() \u003e 0) {\n      taskAttemptStatus.fetchFailedMaps \u003d \n        new ArrayList\u003corg.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId\u003e();\n      for (TaskAttemptID failedMapId : taskStatus.getFetchFailedMaps()) {\n        taskAttemptStatus.fetchFailedMaps.add(\n            TypeConverter.toYarn(failedMapId));\n      }\n    }\n\n // Task sends the information about the nextRecordRange to the TT\n    \n//    TODO: The following are not needed here, but needed to be set somewhere inside AppMaster.\n//    taskStatus.getRunState(); // Set by the TT/JT. Transform into a state TODO\n//    taskStatus.getStartTime(); // Used to be set by the TaskTracker. This should be set by getTask().\n//    taskStatus.getFinishTime(); // Used to be set by TT/JT. Should be set when task finishes\n//    // This was used by TT to do counter updates only once every minute. So this\n//    // isn\u0027t ever changed by the Task itself.\n//    taskStatus.getIncludeCounters();\n\n    context.getEventHandler().handle(\n        new TaskAttemptStatusUpdateEvent(taskAttemptStatus.id,\n            taskAttemptStatus));\n    return true;\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java"
    }
  }
}