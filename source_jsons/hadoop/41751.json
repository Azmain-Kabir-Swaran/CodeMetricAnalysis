{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AbstractYarnScheduler.java",
  "functionName": "nodeUpdate",
  "functionId": "nodeUpdate___nm-RMNode",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/AbstractYarnScheduler.java",
  "functionStartLine": 1167,
  "functionEndLine": 1216,
  "numCommitsSeen": 115,
  "timeTaken": 5617,
  "changeHistory": [
    "cfec455c452d85229ef2f9d83e6f7fc827946b59",
    "2064ca015d1584263aac0cc20c60b925a3aff612",
    "0cd145a44390bc1a01113dce4be4e629637c3e8a",
    "e9c72d04beddfe0252d2e81123a9fe66bdf04078",
    "f69a107aeccc68ca1085a7be8093d36b2f45eaa1",
    "ab1faa4ba80702fb04e28ffb23a4b3bb6e64ee16",
    "e0f2379312c48e26b0cb2c1e1e803ef71d1839cf",
    "352cbaa7a54a94bad2bed131d6a250c5b21a7701",
    "754cb4e30fac1c5fe8d44626968c0ddbfe459335"
  ],
  "changeHistoryShort": {
    "cfec455c452d85229ef2f9d83e6f7fc827946b59": "Ybodychange",
    "2064ca015d1584263aac0cc20c60b925a3aff612": "Ybodychange",
    "0cd145a44390bc1a01113dce4be4e629637c3e8a": "Ybodychange",
    "e9c72d04beddfe0252d2e81123a9fe66bdf04078": "Ybodychange",
    "f69a107aeccc68ca1085a7be8093d36b2f45eaa1": "Ymodifierchange",
    "ab1faa4ba80702fb04e28ffb23a4b3bb6e64ee16": "Ymodifierchange",
    "e0f2379312c48e26b0cb2c1e1e803ef71d1839cf": "Ymodifierchange",
    "352cbaa7a54a94bad2bed131d6a250c5b21a7701": "Ybodychange",
    "754cb4e30fac1c5fe8d44626968c0ddbfe459335": "Yintroduced"
  },
  "changeHistoryDetails": {
    "cfec455c452d85229ef2f9d83e6f7fc827946b59": {
      "type": "Ybodychange",
      "commitMessage": "YARN-999. In case of long running tasks, reduce node resource should balloon out resource quickly by calling preemption API and suspending running task. Contributed by Inigo Goiri.\n",
      "commitDate": "09/04/19 10:59 AM",
      "commitName": "cfec455c452d85229ef2f9d83e6f7fc827946b59",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "01/04/19 8:05 PM",
      "commitNameOld": "2f752830ba74c90ccce818d687572db9afded25b",
      "commitAuthorOld": "Yufei Gu",
      "daysBetweenCommits": 7.62,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,50 @@\n   protected void nodeUpdate(RMNode nm) {\n     LOG.debug(\"nodeUpdate: {} cluster capacity: {}\",\n         nm, getClusterResource());\n \n     // Process new container information\n     // NOTICE: it is possible to not find the NodeID as a node can be\n     // decommissioned at the same time. Skip updates if node is null.\n     SchedulerNode schedulerNode \u003d getNode(nm.getNodeID());\n     List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm,\n         schedulerNode);\n \n     // Notify Scheduler Node updated.\n     if (schedulerNode !\u003d null) {\n       schedulerNode.notifyNodeUpdate();\n     }\n \n     // Process completed containers\n     Resource releasedResources \u003d Resource.newInstance(0, 0);\n     int releasedContainers \u003d updateCompletedContainers(completedContainers,\n         releasedResources, nm.getNodeID(), schedulerNode);\n \n     // If the node is decommissioning, send an update to have the total\n     // resource equal to the used resource, so no available resource to\n     // schedule.\n     if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING \u0026\u0026 schedulerNode !\u003d null) {\n       this.rmContext\n           .getDispatcher()\n           .getEventHandler()\n           .handle(\n               new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                   .newInstance(schedulerNode.getAllocatedResource(), 0)));\n     }\n \n     updateSchedulerHealthInformation(releasedResources, releasedContainers);\n     if (schedulerNode !\u003d null) {\n       updateNodeResourceUtilization(nm, schedulerNode);\n     }\n \n+    if (schedulerNode !\u003d null) {\n+      signalContainersIfOvercommitted(schedulerNode, true);\n+    }\n+\n     // Now node data structures are up-to-date and ready for scheduling.\n     if(LOG.isDebugEnabled()) {\n       LOG.debug(\n           \"Node being looked for scheduling \" + nm + \" availableResource: \" +\n               (schedulerNode \u003d\u003d null ? \"unknown (decommissioned)\" :\n                   schedulerNode.getUnallocatedResource()));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void nodeUpdate(RMNode nm) {\n    LOG.debug(\"nodeUpdate: {} cluster capacity: {}\",\n        nm, getClusterResource());\n\n    // Process new container information\n    // NOTICE: it is possible to not find the NodeID as a node can be\n    // decommissioned at the same time. Skip updates if node is null.\n    SchedulerNode schedulerNode \u003d getNode(nm.getNodeID());\n    List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm,\n        schedulerNode);\n\n    // Notify Scheduler Node updated.\n    if (schedulerNode !\u003d null) {\n      schedulerNode.notifyNodeUpdate();\n    }\n\n    // Process completed containers\n    Resource releasedResources \u003d Resource.newInstance(0, 0);\n    int releasedContainers \u003d updateCompletedContainers(completedContainers,\n        releasedResources, nm.getNodeID(), schedulerNode);\n\n    // If the node is decommissioning, send an update to have the total\n    // resource equal to the used resource, so no available resource to\n    // schedule.\n    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING \u0026\u0026 schedulerNode !\u003d null) {\n      this.rmContext\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                  .newInstance(schedulerNode.getAllocatedResource(), 0)));\n    }\n\n    updateSchedulerHealthInformation(releasedResources, releasedContainers);\n    if (schedulerNode !\u003d null) {\n      updateNodeResourceUtilization(nm, schedulerNode);\n    }\n\n    if (schedulerNode !\u003d null) {\n      signalContainersIfOvercommitted(schedulerNode, true);\n    }\n\n    // Now node data structures are up-to-date and ready for scheduling.\n    if(LOG.isDebugEnabled()) {\n      LOG.debug(\n          \"Node being looked for scheduling \" + nm + \" availableResource: \" +\n              (schedulerNode \u003d\u003d null ? \"unknown (decommissioned)\" :\n                  schedulerNode.getUnallocatedResource()));\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/AbstractYarnScheduler.java",
      "extendedDetails": {}
    },
    "2064ca015d1584263aac0cc20c60b925a3aff612": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9349.  Changed logging to use slf4j api.\n            Contributed by Prabhu Joseph\n",
      "commitDate": "15/03/19 4:20 PM",
      "commitName": "2064ca015d1584263aac0cc20c60b925a3aff612",
      "commitAuthor": "Eric Yang",
      "commitDateOld": "07/03/19 1:47 PM",
      "commitNameOld": "39b4a37e02e929a698fcf9e32f1f71bb6b977635",
      "commitAuthorOld": "Eric Yang",
      "daysBetweenCommits": 8.06,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,46 @@\n   protected void nodeUpdate(RMNode nm) {\n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"nodeUpdate: \" + nm +\n-          \" cluster capacity: \" + getClusterResource());\n-    }\n+    LOG.debug(\"nodeUpdate: {} cluster capacity: {}\",\n+        nm, getClusterResource());\n \n     // Process new container information\n     // NOTICE: it is possible to not find the NodeID as a node can be\n     // decommissioned at the same time. Skip updates if node is null.\n     SchedulerNode schedulerNode \u003d getNode(nm.getNodeID());\n     List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm,\n         schedulerNode);\n \n     // Notify Scheduler Node updated.\n     if (schedulerNode !\u003d null) {\n       schedulerNode.notifyNodeUpdate();\n     }\n \n     // Process completed containers\n     Resource releasedResources \u003d Resource.newInstance(0, 0);\n     int releasedContainers \u003d updateCompletedContainers(completedContainers,\n         releasedResources, nm.getNodeID(), schedulerNode);\n \n     // If the node is decommissioning, send an update to have the total\n     // resource equal to the used resource, so no available resource to\n     // schedule.\n     if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING \u0026\u0026 schedulerNode !\u003d null) {\n       this.rmContext\n           .getDispatcher()\n           .getEventHandler()\n           .handle(\n               new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                   .newInstance(schedulerNode.getAllocatedResource(), 0)));\n     }\n \n     updateSchedulerHealthInformation(releasedResources, releasedContainers);\n     if (schedulerNode !\u003d null) {\n       updateNodeResourceUtilization(nm, schedulerNode);\n     }\n \n     // Now node data structures are up-to-date and ready for scheduling.\n     if(LOG.isDebugEnabled()) {\n       LOG.debug(\n           \"Node being looked for scheduling \" + nm + \" availableResource: \" +\n               (schedulerNode \u003d\u003d null ? \"unknown (decommissioned)\" :\n                   schedulerNode.getUnallocatedResource()));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void nodeUpdate(RMNode nm) {\n    LOG.debug(\"nodeUpdate: {} cluster capacity: {}\",\n        nm, getClusterResource());\n\n    // Process new container information\n    // NOTICE: it is possible to not find the NodeID as a node can be\n    // decommissioned at the same time. Skip updates if node is null.\n    SchedulerNode schedulerNode \u003d getNode(nm.getNodeID());\n    List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm,\n        schedulerNode);\n\n    // Notify Scheduler Node updated.\n    if (schedulerNode !\u003d null) {\n      schedulerNode.notifyNodeUpdate();\n    }\n\n    // Process completed containers\n    Resource releasedResources \u003d Resource.newInstance(0, 0);\n    int releasedContainers \u003d updateCompletedContainers(completedContainers,\n        releasedResources, nm.getNodeID(), schedulerNode);\n\n    // If the node is decommissioning, send an update to have the total\n    // resource equal to the used resource, so no available resource to\n    // schedule.\n    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING \u0026\u0026 schedulerNode !\u003d null) {\n      this.rmContext\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                  .newInstance(schedulerNode.getAllocatedResource(), 0)));\n    }\n\n    updateSchedulerHealthInformation(releasedResources, releasedContainers);\n    if (schedulerNode !\u003d null) {\n      updateNodeResourceUtilization(nm, schedulerNode);\n    }\n\n    // Now node data structures are up-to-date and ready for scheduling.\n    if(LOG.isDebugEnabled()) {\n      LOG.debug(\n          \"Node being looked for scheduling \" + nm + \" availableResource: \" +\n              (schedulerNode \u003d\u003d null ? \"unknown (decommissioned)\" :\n                  schedulerNode.getUnallocatedResource()));\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/AbstractYarnScheduler.java",
      "extendedDetails": {}
    },
    "0cd145a44390bc1a01113dce4be4e629637c3e8a": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4677. RMNodeResourceUpdateEvent update from scheduler can lead to race condition (wilfreds and gphillips via rkanter)\n",
      "commitDate": "04/06/18 3:32 PM",
      "commitName": "0cd145a44390bc1a01113dce4be4e629637c3e8a",
      "commitAuthor": "Robert Kanter",
      "commitDateOld": "25/05/18 9:53 PM",
      "commitNameOld": "f24c842d52e166e8566337ef93c96438f1c870d8",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 9.74,
      "commitsBetweenForRepo": 74,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,48 @@\n   protected void nodeUpdate(RMNode nm) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm +\n           \" cluster capacity: \" + getClusterResource());\n     }\n \n     // Process new container information\n+    // NOTICE: it is possible to not find the NodeID as a node can be\n+    // decommissioned at the same time. Skip updates if node is null.\n     SchedulerNode schedulerNode \u003d getNode(nm.getNodeID());\n     List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm,\n         schedulerNode);\n \n     // Notify Scheduler Node updated.\n-    schedulerNode.notifyNodeUpdate();\n+    if (schedulerNode !\u003d null) {\n+      schedulerNode.notifyNodeUpdate();\n+    }\n \n     // Process completed containers\n     Resource releasedResources \u003d Resource.newInstance(0, 0);\n     int releasedContainers \u003d updateCompletedContainers(completedContainers,\n         releasedResources, nm.getNodeID(), schedulerNode);\n \n     // If the node is decommissioning, send an update to have the total\n     // resource equal to the used resource, so no available resource to\n     // schedule.\n-    // TODO YARN-5128: Fix possible race-condition when request comes in before\n-    // update is propagated\n-    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n+    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING \u0026\u0026 schedulerNode !\u003d null) {\n       this.rmContext\n           .getDispatcher()\n           .getEventHandler()\n           .handle(\n               new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                   .newInstance(schedulerNode.getAllocatedResource(), 0)));\n     }\n \n     updateSchedulerHealthInformation(releasedResources, releasedContainers);\n-    updateNodeResourceUtilization(nm, schedulerNode);\n+    if (schedulerNode !\u003d null) {\n+      updateNodeResourceUtilization(nm, schedulerNode);\n+    }\n \n     // Now node data structures are up-to-date and ready for scheduling.\n     if(LOG.isDebugEnabled()) {\n       LOG.debug(\n-          \"Node being looked for scheduling \" + nm + \" availableResource: \"\n-              + schedulerNode.getUnallocatedResource());\n+          \"Node being looked for scheduling \" + nm + \" availableResource: \" +\n+              (schedulerNode \u003d\u003d null ? \"unknown (decommissioned)\" :\n+                  schedulerNode.getUnallocatedResource()));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm +\n          \" cluster capacity: \" + getClusterResource());\n    }\n\n    // Process new container information\n    // NOTICE: it is possible to not find the NodeID as a node can be\n    // decommissioned at the same time. Skip updates if node is null.\n    SchedulerNode schedulerNode \u003d getNode(nm.getNodeID());\n    List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm,\n        schedulerNode);\n\n    // Notify Scheduler Node updated.\n    if (schedulerNode !\u003d null) {\n      schedulerNode.notifyNodeUpdate();\n    }\n\n    // Process completed containers\n    Resource releasedResources \u003d Resource.newInstance(0, 0);\n    int releasedContainers \u003d updateCompletedContainers(completedContainers,\n        releasedResources, nm.getNodeID(), schedulerNode);\n\n    // If the node is decommissioning, send an update to have the total\n    // resource equal to the used resource, so no available resource to\n    // schedule.\n    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING \u0026\u0026 schedulerNode !\u003d null) {\n      this.rmContext\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                  .newInstance(schedulerNode.getAllocatedResource(), 0)));\n    }\n\n    updateSchedulerHealthInformation(releasedResources, releasedContainers);\n    if (schedulerNode !\u003d null) {\n      updateNodeResourceUtilization(nm, schedulerNode);\n    }\n\n    // Now node data structures are up-to-date and ready for scheduling.\n    if(LOG.isDebugEnabled()) {\n      LOG.debug(\n          \"Node being looked for scheduling \" + nm + \" availableResource: \" +\n              (schedulerNode \u003d\u003d null ? \"unknown (decommissioned)\" :\n                  schedulerNode.getUnallocatedResource()));\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/AbstractYarnScheduler.java",
      "extendedDetails": {}
    },
    "e9c72d04beddfe0252d2e81123a9fe66bdf04078": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7790. Improve Capacity Scheduler Async Scheduling to better handle node failures. Contributed by Wangda Tan.\n",
      "commitDate": "29/01/18 7:14 AM",
      "commitName": "e9c72d04beddfe0252d2e81123a9fe66bdf04078",
      "commitAuthor": "Sunil G",
      "commitDateOld": "09/01/18 4:59 PM",
      "commitNameOld": "55066cc53dc22b68f9ca55a0029741d6c846be0a",
      "commitAuthorOld": "Miklos Szegedi",
      "daysBetweenCommits": 19.59,
      "commitsBetweenForRepo": 102,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,43 @@\n   protected void nodeUpdate(RMNode nm) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm +\n           \" cluster capacity: \" + getClusterResource());\n     }\n \n     // Process new container information\n-    List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm);\n+    SchedulerNode schedulerNode \u003d getNode(nm.getNodeID());\n+    List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm,\n+        schedulerNode);\n+\n+    // Notify Scheduler Node updated.\n+    schedulerNode.notifyNodeUpdate();\n \n     // Process completed containers\n     Resource releasedResources \u003d Resource.newInstance(0, 0);\n     int releasedContainers \u003d updateCompletedContainers(completedContainers,\n-        releasedResources, nm.getNodeID());\n+        releasedResources, nm.getNodeID(), schedulerNode);\n \n     // If the node is decommissioning, send an update to have the total\n     // resource equal to the used resource, so no available resource to\n     // schedule.\n     // TODO YARN-5128: Fix possible race-condition when request comes in before\n     // update is propagated\n     if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n       this.rmContext\n           .getDispatcher()\n           .getEventHandler()\n           .handle(\n               new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n-                  .newInstance(getSchedulerNode(nm.getNodeID())\n-                      .getAllocatedResource(), 0)));\n+                  .newInstance(schedulerNode.getAllocatedResource(), 0)));\n     }\n \n     updateSchedulerHealthInformation(releasedResources, releasedContainers);\n-    updateNodeResourceUtilization(nm);\n+    updateNodeResourceUtilization(nm, schedulerNode);\n \n     // Now node data structures are up-to-date and ready for scheduling.\n     if(LOG.isDebugEnabled()) {\n-      SchedulerNode node \u003d getNode(nm.getNodeID());\n-      LOG.debug(\"Node being looked for scheduling \" + nm +\n-          \" availableResource: \" + node.getUnallocatedResource());\n+      LOG.debug(\n+          \"Node being looked for scheduling \" + nm + \" availableResource: \"\n+              + schedulerNode.getUnallocatedResource());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm +\n          \" cluster capacity: \" + getClusterResource());\n    }\n\n    // Process new container information\n    SchedulerNode schedulerNode \u003d getNode(nm.getNodeID());\n    List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm,\n        schedulerNode);\n\n    // Notify Scheduler Node updated.\n    schedulerNode.notifyNodeUpdate();\n\n    // Process completed containers\n    Resource releasedResources \u003d Resource.newInstance(0, 0);\n    int releasedContainers \u003d updateCompletedContainers(completedContainers,\n        releasedResources, nm.getNodeID(), schedulerNode);\n\n    // If the node is decommissioning, send an update to have the total\n    // resource equal to the used resource, so no available resource to\n    // schedule.\n    // TODO YARN-5128: Fix possible race-condition when request comes in before\n    // update is propagated\n    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n      this.rmContext\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                  .newInstance(schedulerNode.getAllocatedResource(), 0)));\n    }\n\n    updateSchedulerHealthInformation(releasedResources, releasedContainers);\n    updateNodeResourceUtilization(nm, schedulerNode);\n\n    // Now node data structures are up-to-date and ready for scheduling.\n    if(LOG.isDebugEnabled()) {\n      LOG.debug(\n          \"Node being looked for scheduling \" + nm + \" availableResource: \"\n              + schedulerNode.getUnallocatedResource());\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/AbstractYarnScheduler.java",
      "extendedDetails": {}
    },
    "f69a107aeccc68ca1085a7be8093d36b2f45eaa1": {
      "type": "Ymodifierchange",
      "commitMessage": "YARN-6025. Fix synchronization issues of AbstractYarnScheduler#nodeUpdate and its implementations. (Naganarasimha G R via wangda)\n\n(cherry picked from commit e0f2379312c48e26b0cb2c1e1e803ef71d1839cf)\n",
      "commitDate": "03/01/17 2:53 PM",
      "commitName": "f69a107aeccc68ca1085a7be8093d36b2f45eaa1",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "03/01/17 2:53 PM",
      "commitNameOld": "ab1faa4ba80702fb04e28ffb23a4b3bb6e64ee16",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,39 @@\n-  protected synchronized void nodeUpdate(RMNode nm) {\n+  protected void nodeUpdate(RMNode nm) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm +\n           \" cluster capacity: \" + getClusterResource());\n     }\n \n     // Process new container information\n     List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm);\n \n     // Process completed containers\n     Resource releasedResources \u003d Resource.newInstance(0, 0);\n     int releasedContainers \u003d updateCompletedContainers(completedContainers,\n         releasedResources, nm.getNodeID());\n \n     // If the node is decommissioning, send an update to have the total\n     // resource equal to the used resource, so no available resource to\n     // schedule.\n     // TODO YARN-5128: Fix possible race-condition when request comes in before\n     // update is propagated\n     if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n       this.rmContext\n           .getDispatcher()\n           .getEventHandler()\n           .handle(\n               new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                   .newInstance(getSchedulerNode(nm.getNodeID())\n                       .getAllocatedResource(), 0)));\n     }\n \n     updateSchedulerHealthInformation(releasedResources, releasedContainers);\n     updateNodeResourceUtilization(nm);\n \n     // Now node data structures are up-to-date and ready for scheduling.\n     if(LOG.isDebugEnabled()) {\n       SchedulerNode node \u003d getNode(nm.getNodeID());\n       LOG.debug(\"Node being looked for scheduling \" + nm +\n           \" availableResource: \" + node.getUnallocatedResource());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm +\n          \" cluster capacity: \" + getClusterResource());\n    }\n\n    // Process new container information\n    List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm);\n\n    // Process completed containers\n    Resource releasedResources \u003d Resource.newInstance(0, 0);\n    int releasedContainers \u003d updateCompletedContainers(completedContainers,\n        releasedResources, nm.getNodeID());\n\n    // If the node is decommissioning, send an update to have the total\n    // resource equal to the used resource, so no available resource to\n    // schedule.\n    // TODO YARN-5128: Fix possible race-condition when request comes in before\n    // update is propagated\n    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n      this.rmContext\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                  .newInstance(getSchedulerNode(nm.getNodeID())\n                      .getAllocatedResource(), 0)));\n    }\n\n    updateSchedulerHealthInformation(releasedResources, releasedContainers);\n    updateNodeResourceUtilization(nm);\n\n    // Now node data structures are up-to-date and ready for scheduling.\n    if(LOG.isDebugEnabled()) {\n      SchedulerNode node \u003d getNode(nm.getNodeID());\n      LOG.debug(\"Node being looked for scheduling \" + nm +\n          \" availableResource: \" + node.getUnallocatedResource());\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/AbstractYarnScheduler.java",
      "extendedDetails": {
        "oldValue": "[protected, synchronized]",
        "newValue": "[protected]"
      }
    },
    "ab1faa4ba80702fb04e28ffb23a4b3bb6e64ee16": {
      "type": "Ymodifierchange",
      "commitMessage": "Revert \"Fix synchronization issues of AbstractYarnScheduler#nodeUpdate and its implementations. (Naganarasimha G R via wangda)\" to add correct JIRA number\n\nThis reverts commit e0f2379312c48e26b0cb2c1e1e803ef71d1839cf.\n",
      "commitDate": "03/01/17 2:53 PM",
      "commitName": "ab1faa4ba80702fb04e28ffb23a4b3bb6e64ee16",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "03/01/17 2:46 PM",
      "commitNameOld": "e0f2379312c48e26b0cb2c1e1e803ef71d1839cf",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,39 @@\n-  protected void nodeUpdate(RMNode nm) {\n+  protected synchronized void nodeUpdate(RMNode nm) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm +\n           \" cluster capacity: \" + getClusterResource());\n     }\n \n     // Process new container information\n     List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm);\n \n     // Process completed containers\n     Resource releasedResources \u003d Resource.newInstance(0, 0);\n     int releasedContainers \u003d updateCompletedContainers(completedContainers,\n         releasedResources, nm.getNodeID());\n \n     // If the node is decommissioning, send an update to have the total\n     // resource equal to the used resource, so no available resource to\n     // schedule.\n     // TODO YARN-5128: Fix possible race-condition when request comes in before\n     // update is propagated\n     if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n       this.rmContext\n           .getDispatcher()\n           .getEventHandler()\n           .handle(\n               new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                   .newInstance(getSchedulerNode(nm.getNodeID())\n                       .getAllocatedResource(), 0)));\n     }\n \n     updateSchedulerHealthInformation(releasedResources, releasedContainers);\n     updateNodeResourceUtilization(nm);\n \n     // Now node data structures are up-to-date and ready for scheduling.\n     if(LOG.isDebugEnabled()) {\n       SchedulerNode node \u003d getNode(nm.getNodeID());\n       LOG.debug(\"Node being looked for scheduling \" + nm +\n           \" availableResource: \" + node.getUnallocatedResource());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm +\n          \" cluster capacity: \" + getClusterResource());\n    }\n\n    // Process new container information\n    List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm);\n\n    // Process completed containers\n    Resource releasedResources \u003d Resource.newInstance(0, 0);\n    int releasedContainers \u003d updateCompletedContainers(completedContainers,\n        releasedResources, nm.getNodeID());\n\n    // If the node is decommissioning, send an update to have the total\n    // resource equal to the used resource, so no available resource to\n    // schedule.\n    // TODO YARN-5128: Fix possible race-condition when request comes in before\n    // update is propagated\n    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n      this.rmContext\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                  .newInstance(getSchedulerNode(nm.getNodeID())\n                      .getAllocatedResource(), 0)));\n    }\n\n    updateSchedulerHealthInformation(releasedResources, releasedContainers);\n    updateNodeResourceUtilization(nm);\n\n    // Now node data structures are up-to-date and ready for scheduling.\n    if(LOG.isDebugEnabled()) {\n      SchedulerNode node \u003d getNode(nm.getNodeID());\n      LOG.debug(\"Node being looked for scheduling \" + nm +\n          \" availableResource: \" + node.getUnallocatedResource());\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/AbstractYarnScheduler.java",
      "extendedDetails": {
        "oldValue": "[protected]",
        "newValue": "[protected, synchronized]"
      }
    },
    "e0f2379312c48e26b0cb2c1e1e803ef71d1839cf": {
      "type": "Ymodifierchange",
      "commitMessage": "Fix synchronization issues of AbstractYarnScheduler#nodeUpdate and its implementations. (Naganarasimha G R via wangda)\n",
      "commitDate": "03/01/17 2:46 PM",
      "commitName": "e0f2379312c48e26b0cb2c1e1e803ef71d1839cf",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "06/12/16 9:09 PM",
      "commitNameOld": "563480dccd0136d82730f4228f1df44449ed5822",
      "commitAuthorOld": "Rohith Sharma K S",
      "daysBetweenCommits": 27.73,
      "commitsBetweenForRepo": 119,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,39 @@\n-  protected synchronized void nodeUpdate(RMNode nm) {\n+  protected void nodeUpdate(RMNode nm) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm +\n           \" cluster capacity: \" + getClusterResource());\n     }\n \n     // Process new container information\n     List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm);\n \n     // Process completed containers\n     Resource releasedResources \u003d Resource.newInstance(0, 0);\n     int releasedContainers \u003d updateCompletedContainers(completedContainers,\n         releasedResources, nm.getNodeID());\n \n     // If the node is decommissioning, send an update to have the total\n     // resource equal to the used resource, so no available resource to\n     // schedule.\n     // TODO YARN-5128: Fix possible race-condition when request comes in before\n     // update is propagated\n     if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n       this.rmContext\n           .getDispatcher()\n           .getEventHandler()\n           .handle(\n               new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                   .newInstance(getSchedulerNode(nm.getNodeID())\n                       .getAllocatedResource(), 0)));\n     }\n \n     updateSchedulerHealthInformation(releasedResources, releasedContainers);\n     updateNodeResourceUtilization(nm);\n \n     // Now node data structures are up-to-date and ready for scheduling.\n     if(LOG.isDebugEnabled()) {\n       SchedulerNode node \u003d getNode(nm.getNodeID());\n       LOG.debug(\"Node being looked for scheduling \" + nm +\n           \" availableResource: \" + node.getUnallocatedResource());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm +\n          \" cluster capacity: \" + getClusterResource());\n    }\n\n    // Process new container information\n    List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm);\n\n    // Process completed containers\n    Resource releasedResources \u003d Resource.newInstance(0, 0);\n    int releasedContainers \u003d updateCompletedContainers(completedContainers,\n        releasedResources, nm.getNodeID());\n\n    // If the node is decommissioning, send an update to have the total\n    // resource equal to the used resource, so no available resource to\n    // schedule.\n    // TODO YARN-5128: Fix possible race-condition when request comes in before\n    // update is propagated\n    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n      this.rmContext\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                  .newInstance(getSchedulerNode(nm.getNodeID())\n                      .getAllocatedResource(), 0)));\n    }\n\n    updateSchedulerHealthInformation(releasedResources, releasedContainers);\n    updateNodeResourceUtilization(nm);\n\n    // Now node data structures are up-to-date and ready for scheduling.\n    if(LOG.isDebugEnabled()) {\n      SchedulerNode node \u003d getNode(nm.getNodeID());\n      LOG.debug(\"Node being looked for scheduling \" + nm +\n          \" availableResource: \" + node.getUnallocatedResource());\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/AbstractYarnScheduler.java",
      "extendedDetails": {
        "oldValue": "[protected, synchronized]",
        "newValue": "[protected]"
      }
    },
    "352cbaa7a54a94bad2bed131d6a250c5b21a7701": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4862. Handle duplicate completed containers in RMNodeImpl. Contributed by Rohith Sharma K S\n",
      "commitDate": "03/11/16 6:54 AM",
      "commitName": "352cbaa7a54a94bad2bed131d6a250c5b21a7701",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "20/10/16 9:17 PM",
      "commitNameOld": "754cb4e30fac1c5fe8d44626968c0ddbfe459335",
      "commitAuthorOld": "Karthik Kambatla",
      "daysBetweenCommits": 13.4,
      "commitsBetweenForRepo": 141,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,39 @@\n   protected synchronized void nodeUpdate(RMNode nm) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm +\n           \" cluster capacity: \" + getClusterResource());\n     }\n \n     // Process new container information\n     List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm);\n \n     // Process completed containers\n     Resource releasedResources \u003d Resource.newInstance(0, 0);\n     int releasedContainers \u003d updateCompletedContainers(completedContainers,\n-        releasedResources);\n+        releasedResources, nm.getNodeID());\n \n     // If the node is decommissioning, send an update to have the total\n     // resource equal to the used resource, so no available resource to\n     // schedule.\n     // TODO YARN-5128: Fix possible race-condition when request comes in before\n     // update is propagated\n     if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n       this.rmContext\n           .getDispatcher()\n           .getEventHandler()\n           .handle(\n               new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                   .newInstance(getSchedulerNode(nm.getNodeID())\n                       .getAllocatedResource(), 0)));\n     }\n \n     updateSchedulerHealthInformation(releasedResources, releasedContainers);\n     updateNodeResourceUtilization(nm);\n \n     // Now node data structures are up-to-date and ready for scheduling.\n     if(LOG.isDebugEnabled()) {\n       SchedulerNode node \u003d getNode(nm.getNodeID());\n       LOG.debug(\"Node being looked for scheduling \" + nm +\n           \" availableResource: \" + node.getUnallocatedResource());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm +\n          \" cluster capacity: \" + getClusterResource());\n    }\n\n    // Process new container information\n    List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm);\n\n    // Process completed containers\n    Resource releasedResources \u003d Resource.newInstance(0, 0);\n    int releasedContainers \u003d updateCompletedContainers(completedContainers,\n        releasedResources, nm.getNodeID());\n\n    // If the node is decommissioning, send an update to have the total\n    // resource equal to the used resource, so no available resource to\n    // schedule.\n    // TODO YARN-5128: Fix possible race-condition when request comes in before\n    // update is propagated\n    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n      this.rmContext\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                  .newInstance(getSchedulerNode(nm.getNodeID())\n                      .getAllocatedResource(), 0)));\n    }\n\n    updateSchedulerHealthInformation(releasedResources, releasedContainers);\n    updateNodeResourceUtilization(nm);\n\n    // Now node data structures are up-to-date and ready for scheduling.\n    if(LOG.isDebugEnabled()) {\n      SchedulerNode node \u003d getNode(nm.getNodeID());\n      LOG.debug(\"Node being looked for scheduling \" + nm +\n          \" availableResource: \" + node.getUnallocatedResource());\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/AbstractYarnScheduler.java",
      "extendedDetails": {}
    },
    "754cb4e30fac1c5fe8d44626968c0ddbfe459335": {
      "type": "Yintroduced",
      "commitMessage": "YARN-5047. Refactor nodeUpdate across schedulers. (Ray Chiang via kasha)\n",
      "commitDate": "20/10/16 9:17 PM",
      "commitName": "754cb4e30fac1c5fe8d44626968c0ddbfe459335",
      "commitAuthor": "Karthik Kambatla",
      "diff": "@@ -0,0 +1,39 @@\n+  protected synchronized void nodeUpdate(RMNode nm) {\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"nodeUpdate: \" + nm +\n+          \" cluster capacity: \" + getClusterResource());\n+    }\n+\n+    // Process new container information\n+    List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm);\n+\n+    // Process completed containers\n+    Resource releasedResources \u003d Resource.newInstance(0, 0);\n+    int releasedContainers \u003d updateCompletedContainers(completedContainers,\n+        releasedResources);\n+\n+    // If the node is decommissioning, send an update to have the total\n+    // resource equal to the used resource, so no available resource to\n+    // schedule.\n+    // TODO YARN-5128: Fix possible race-condition when request comes in before\n+    // update is propagated\n+    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n+      this.rmContext\n+          .getDispatcher()\n+          .getEventHandler()\n+          .handle(\n+              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n+                  .newInstance(getSchedulerNode(nm.getNodeID())\n+                      .getAllocatedResource(), 0)));\n+    }\n+\n+    updateSchedulerHealthInformation(releasedResources, releasedContainers);\n+    updateNodeResourceUtilization(nm);\n+\n+    // Now node data structures are up-to-date and ready for scheduling.\n+    if(LOG.isDebugEnabled()) {\n+      SchedulerNode node \u003d getNode(nm.getNodeID());\n+      LOG.debug(\"Node being looked for scheduling \" + nm +\n+          \" availableResource: \" + node.getUnallocatedResource());\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm +\n          \" cluster capacity: \" + getClusterResource());\n    }\n\n    // Process new container information\n    List\u003cContainerStatus\u003e completedContainers \u003d updateNewContainerInfo(nm);\n\n    // Process completed containers\n    Resource releasedResources \u003d Resource.newInstance(0, 0);\n    int releasedContainers \u003d updateCompletedContainers(completedContainers,\n        releasedResources);\n\n    // If the node is decommissioning, send an update to have the total\n    // resource equal to the used resource, so no available resource to\n    // schedule.\n    // TODO YARN-5128: Fix possible race-condition when request comes in before\n    // update is propagated\n    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n      this.rmContext\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                  .newInstance(getSchedulerNode(nm.getNodeID())\n                      .getAllocatedResource(), 0)));\n    }\n\n    updateSchedulerHealthInformation(releasedResources, releasedContainers);\n    updateNodeResourceUtilization(nm);\n\n    // Now node data structures are up-to-date and ready for scheduling.\n    if(LOG.isDebugEnabled()) {\n      SchedulerNode node \u003d getNode(nm.getNodeID());\n      LOG.debug(\"Node being looked for scheduling \" + nm +\n          \" availableResource: \" + node.getUnallocatedResource());\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/AbstractYarnScheduler.java"
    }
  }
}