{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataXceiver.java",
  "functionName": "writeBlock",
  "functionId": "writeBlock___block-ExtendedBlock(modifiers-final)__storageType-StorageType(modifiers-final)__blockToken-Token__BlockTokenIdentifier__(modifiers-final)__clientname-String(modifiers-final)__targets-DatanodeInfo[](modifiers-final)__targetStorageTypes-StorageType[](modifiers-final)__srcDataNode-DatanodeInfo(modifiers-final)__stage-BlockConstructionStage(modifiers-final)__pipelineSize-int(modifiers-final)__minBytesRcvd-long(modifiers-final)__maxBytesRcvd-long(modifiers-final)__latestGenerationStamp-long(modifiers-final)__requestedChecksum-DataChecksum__cachingStrategy-CachingStrategy__allowLazyPersist-boolean__pinning-boolean(modifiers-final)__targetPinnings-boolean[](modifiers-final)__storageId-String(modifiers-final)__targetStorageIds-String[](modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
  "functionStartLine": 667,
  "functionEndLine": 956,
  "numCommitsSeen": 423,
  "timeTaken": 21046,
  "changeHistory": [
    "f580a87079bb47bf92d254677745d067b6bc8fde",
    "626fec652b9f3dae10c9af78fd220b1240f19fc7",
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
    "7774759830f32ef97ac9f157dbb210264b7d042a",
    "2c367b464c86a7d67a2b8dd82ae804d169957573",
    "a3954ccab148bddc290cb96528e63ff19799bcc9",
    "2f73396b5901fd5fe29f6cd76fc1b3134b854b37",
    "e4a25456202feeee9880d822a8e6f9c19cbcf24a",
    "f2ac132d6a21c215093b7f87acf2843ac8123716",
    "aede8c10ecad4f2a8802a834e4bd0b8286cebade",
    "d1d4e16690cc85f7f22fbead9cf596260819b561",
    "38c4c14472996562eb3d610649246770c2888c6b",
    "49949a4bb03aa81cbb9115e91ab1c61cc6dc8a62",
    "dfd807afab0fae3839c9cc5d552aa0304444f956",
    "7b5cf5352efedc7d7ebdbb6b58f1b9a688812e75",
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
    "3aac4758b007a56e3d66998d457b2156effca528",
    "88d8736ddeff10a03acaa99a9a0ee99dcfabe590",
    "4da8490b512a33a255ed27309860859388d7c168",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
    "36e4cd3be6f7fec8db82d3d1bcb258af470ece2e",
    "02e7dec79d2d4f2b801435343219d8fb53ec931f",
    "085b1e293ff53f7a86aa21406cfd4bfa0f3bf33b",
    "2d4f3e567e4bb8068c028de12df118a4f3fa6343",
    "86cad007d7d6366b293bb9a073814889081c8662",
    "a317bd7b02c37bd57743bfad59593ec12f53f4ed",
    "c2354a7f81ff5a48a5b65d25e1036d3e0ba86420",
    "6824abc19e12ed142d9f32b8706ef73d97edd1cc",
    "2fb04d2a30919bde350f566a39faa7085f1a1d7b",
    "195961a7c1da86421761162836766b1de07930fd",
    "6554994fab2d8a2a139fb71ed54be144f4057e08",
    "471b1368e2a81b4d9850f0f4d98d31df1451354c",
    "25b0e8471ed744578b2d8e3f0debe5477b268e54",
    "3b54223c0f32d42a84436c670d80b791a8e9696d",
    "1fbb04e367d7c330e6052207f9f11911f4f5f368",
    "97acde2d33967f7f870f7dfe96c6b558e6fe324b",
    "01f37e42f050207b7659bf74e2484cf8bdae2d89",
    "c1314eb2a382bd9ce045a2fcc4a9e5c1fc368a24",
    "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7",
    "3cd17b614e9436d06cd9b4ccc5f9cf59fbe1cf21",
    "837e17b2eac1471d93e2eff395272063b265fee7",
    "239b2742d0e80d13c970fd062af4930e672fe903",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
    "f98d8eb291be364102b5c3011ce72e8f43eab389",
    "9b4a7900c7dfc0590316eedaa97144f938885651",
    "7aa2889f822a970b8b1edb8bc58aab67412877ae",
    "be7dd8333a7e56e732171db0781786987de03195",
    "905a127850d5e0cba85c2e075f989fa0f5cf129a",
    "1c940637b14eee777a65d153d0d712a1aea3866c",
    "c46876982ed90d0819a94b518f6135b82334d10d",
    "8ae98a9d1ca4725e28783370517cb3a3ecda7324",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "ef223e8e8e1e18733fc18cd84e34dd0bb0f9a710",
    "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f",
    "2f48fae72aa52e6ec42264cad24fab36b6a426c2",
    "3f190b3e1acc5ea9e9a03e85a4df0e3f0ab73b9f",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "f580a87079bb47bf92d254677745d067b6bc8fde": "Ybodychange",
    "626fec652b9f3dae10c9af78fd220b1240f19fc7": "Ybodychange",
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": "Ybodychange",
    "7774759830f32ef97ac9f157dbb210264b7d042a": "Ybodychange",
    "2c367b464c86a7d67a2b8dd82ae804d169957573": "Ybodychange",
    "a3954ccab148bddc290cb96528e63ff19799bcc9": "Ymultichange(Yparameterchange,Ybodychange)",
    "2f73396b5901fd5fe29f6cd76fc1b3134b854b37": "Ybodychange",
    "e4a25456202feeee9880d822a8e6f9c19cbcf24a": "Ybodychange",
    "f2ac132d6a21c215093b7f87acf2843ac8123716": "Ybodychange",
    "aede8c10ecad4f2a8802a834e4bd0b8286cebade": "Ybodychange",
    "d1d4e16690cc85f7f22fbead9cf596260819b561": "Ybodychange",
    "38c4c14472996562eb3d610649246770c2888c6b": "Ybodychange",
    "49949a4bb03aa81cbb9115e91ab1c61cc6dc8a62": "Ybodychange",
    "dfd807afab0fae3839c9cc5d552aa0304444f956": "Ybodychange",
    "7b5cf5352efedc7d7ebdbb6b58f1b9a688812e75": "Ybodychange",
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": "Ybodychange",
    "3aac4758b007a56e3d66998d457b2156effca528": "Ybodychange",
    "88d8736ddeff10a03acaa99a9a0ee99dcfabe590": "Ymultichange(Ybodychange,Yparametermetachange)",
    "4da8490b512a33a255ed27309860859388d7c168": "Ybodychange",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": "Ybodychange",
    "36e4cd3be6f7fec8db82d3d1bcb258af470ece2e": "Ybodychange",
    "02e7dec79d2d4f2b801435343219d8fb53ec931f": "Ybodychange",
    "085b1e293ff53f7a86aa21406cfd4bfa0f3bf33b": "Ymultichange(Yparameterchange,Ybodychange)",
    "2d4f3e567e4bb8068c028de12df118a4f3fa6343": "Ybodychange",
    "86cad007d7d6366b293bb9a073814889081c8662": "Ybodychange",
    "a317bd7b02c37bd57743bfad59593ec12f53f4ed": "Ybodychange",
    "c2354a7f81ff5a48a5b65d25e1036d3e0ba86420": "Ymultichange(Yparameterchange,Ybodychange)",
    "6824abc19e12ed142d9f32b8706ef73d97edd1cc": "Ybodychange",
    "2fb04d2a30919bde350f566a39faa7085f1a1d7b": "Ybodychange",
    "195961a7c1da86421761162836766b1de07930fd": "Ybodychange",
    "6554994fab2d8a2a139fb71ed54be144f4057e08": "Ybodychange",
    "471b1368e2a81b4d9850f0f4d98d31df1451354c": "Ybodychange",
    "25b0e8471ed744578b2d8e3f0debe5477b268e54": "Ymultichange(Yparameterchange,Ybodychange)",
    "3b54223c0f32d42a84436c670d80b791a8e9696d": "Ybodychange",
    "1fbb04e367d7c330e6052207f9f11911f4f5f368": "Ybodychange",
    "97acde2d33967f7f870f7dfe96c6b558e6fe324b": "Ybodychange",
    "01f37e42f050207b7659bf74e2484cf8bdae2d89": "Ybodychange",
    "c1314eb2a382bd9ce045a2fcc4a9e5c1fc368a24": "Ymultichange(Yparameterchange,Ybodychange)",
    "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7": "Ybodychange",
    "3cd17b614e9436d06cd9b4ccc5f9cf59fbe1cf21": "Ybodychange",
    "837e17b2eac1471d93e2eff395272063b265fee7": "Ybodychange",
    "239b2742d0e80d13c970fd062af4930e672fe903": "Ybodychange",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": "Ybodychange",
    "f98d8eb291be364102b5c3011ce72e8f43eab389": "Ybodychange",
    "9b4a7900c7dfc0590316eedaa97144f938885651": "Ybodychange",
    "7aa2889f822a970b8b1edb8bc58aab67412877ae": "Ybodychange",
    "be7dd8333a7e56e732171db0781786987de03195": "Ybodychange",
    "905a127850d5e0cba85c2e075f989fa0f5cf129a": "Ybodychange",
    "1c940637b14eee777a65d153d0d712a1aea3866c": "Ymultichange(Yparameterchange,Ybodychange)",
    "c46876982ed90d0819a94b518f6135b82334d10d": "Ybodychange",
    "8ae98a9d1ca4725e28783370517cb3a3ecda7324": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "ef223e8e8e1e18733fc18cd84e34dd0bb0f9a710": "Ybodychange",
    "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f": "Ybodychange",
    "2f48fae72aa52e6ec42264cad24fab36b6a426c2": "Ymultichange(Yrename,Yparameterchange,Ymodifierchange,Ybodychange)",
    "3f190b3e1acc5ea9e9a03e85a4df0e3f0ab73b9f": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f580a87079bb47bf92d254677745d067b6bc8fde": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14795. Add Throttler for writing block. Contributed by Lisheng Sun.\n",
      "commitDate": "17/09/19 2:55 PM",
      "commitName": "f580a87079bb47bf92d254677745d067b6bc8fde",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "02/09/19 9:47 AM",
      "commitNameOld": "915cbc91c0a12cc7b4d3ef4ea951941defbbcb33",
      "commitAuthorOld": "Stephen O\u0027Donnell",
      "daysBetweenCommits": 15.21,
      "commitsBetweenForRepo": 108,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,290 +1,290 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings,\n       final String storageId,\n       final String[] targetStorageIds) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d getBufferedOutputStream();\n \n     int nst \u003d targetStorageTypes.length;\n     StorageType[] storageTypes \u003d new StorageType[nst + 1];\n     storageTypes[0] \u003d storageType;\n     if (targetStorageTypes.length \u003e 0) {\n       System.arraycopy(targetStorageTypes, 0, storageTypes, 1, nst);\n     }\n \n     // To support older clients, we don\u0027t pass in empty storageIds\n     final int nsi \u003d targetStorageIds.length;\n     final String[] storageIds;\n     if (nsi \u003e 0) {\n       storageIds \u003d new String[nsi + 1];\n       storageIds[0] \u003d storageId;\n       if (targetStorageTypes.length \u003e 0) {\n         System.arraycopy(targetStorageIds, 0, storageIds, 1, nsi);\n       }\n     } else {\n       storageIds \u003d new String[0];\n     }\n     checkAccess(replyOut, isClient, block, blockToken, Op.WRITE_BLOCK,\n         BlockTokenIdentifier.AccessMode.WRITE,\n         storageTypes, storageIds);\n \n     // check single target for transfer-RBW/Finalized\n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d{}, clientname\u003d{}\\n  \" +\n               \"block  \u003d{}, newGs\u003d{}, bytesRcvd\u003d[{}, {}]\\n  \" +\n               \"targets\u003d{}; pipelineSize\u003d{}, srcDataNode\u003d{}, pinning\u003d{}\",\n           stage, clientname, block, latestGenerationStamp, minBytesRcvd,\n           maxBytesRcvd, Arrays.asList(targets), pipelineSize, srcDataNode,\n           pinning);\n       LOG.debug(\"isDatanode\u003d{}, isClient\u003d{}, isTransfer\u003d{}\",\n           isDatanode, isClient, isTransfer);\n       LOG.debug(\"writeBlock receive buf size {} tcp no delay {}\",\n           peer.getReceiveBufferSize(), peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving {} src: {} dest: {}\",\n         block, remoteAddress, localAddress);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     final boolean isOnTransientStorage;\n     try {\n       final Replica replica;\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning, storageId));\n         replica \u003d blockReceiver.getReplica();\n       } else {\n         replica \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n       storageUuid \u003d replica.getStorageUuid();\n       isOnTransientStorage \u003d replica.isOnTransientStorage();\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         LOG.debug(\"Connecting to datanode {}\", mirrorNode);\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n \n           DataNodeFaultInjector.get().failMirrorConnection();\n \n           int timeoutValue \u003d dnConf.socketTimeout +\n               (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout +\n               (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setKeepAlive(true);\n           if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n             mirrorSock.setSendBufferSize(\n                 dnConf.getTransferSocketSendBufferSize());\n           }\n \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           SecretKey secretKey \u003d null;\n           if (dnConf.overwriteDownstreamDerivedQOP) {\n             String bpid \u003d block.getBlockPoolId();\n             BlockKey blockKey \u003d datanode.blockPoolTokenSecretManager\n                 .get(bpid).getCurrentKey();\n             secretKey \u003d blockKey.getKey();\n           }\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(\n               mirrorSock, unbufMirrorOut, unbufMirrorIn, keyFactory,\n               blockToken, targets[0], secretKey);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           String targetStorageId \u003d null;\n           if (targetStorageIds.length \u003e 0) {\n             // Older clients may not have provided any targetStorageIds\n             targetStorageId \u003d targetStorageIds[0];\n           }\n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                 blockToken, clientname, targets, targetStorageTypes,\n                 srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                 latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, targetPinnings[0], targetPinnings,\n                 targetStorageId, targetStorageIds);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                 blockToken, clientname, targets, targetStorageTypes,\n                 srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                 latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, false, targetPinnings,\n                 targetStorageId, targetStorageIds);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (mirrorInStatus !\u003d SUCCESS) {\n               LOG.debug(\"Datanode {} got response for connect\" +\n                   \"ack  from downstream datanode with firstbadlink as {}\",\n                   targets.length, firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(\"{}:Exception transfering block {} to mirror {}\",\n                 datanode, block, mirrorNode, e);\n             throw e;\n           } else {\n             LOG.info(\"{}:Exception transfering {} to mirror {}- continuing \" +\n                 \"without the mirror\", datanode, block, mirrorNode, e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (mirrorInStatus !\u003d SUCCESS) {\n           LOG.debug(\"Datanode {} forwarding connect ack to upstream \" +\n               \"firstbadlink is {}\", targets.length, firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n-        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n-            mirrorAddr, null, targets, false);\n+        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut, mirrorAddr,\n+            dataXceiverServer.getWriteThrottler(), targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           LOG.trace(\"TRANSFER: send close-ack\");\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n         LOG.info(\"Received {} src: {} dest: {} of size {}\",\n             block, remoteAddress, localAddress, block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock {} received exception {}\",\n           block, ioe.toString());\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       setCurrentBlockReceiver(null);\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings,\n      final String storageId,\n      final String[] targetStorageIds) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n\n    int nst \u003d targetStorageTypes.length;\n    StorageType[] storageTypes \u003d new StorageType[nst + 1];\n    storageTypes[0] \u003d storageType;\n    if (targetStorageTypes.length \u003e 0) {\n      System.arraycopy(targetStorageTypes, 0, storageTypes, 1, nst);\n    }\n\n    // To support older clients, we don\u0027t pass in empty storageIds\n    final int nsi \u003d targetStorageIds.length;\n    final String[] storageIds;\n    if (nsi \u003e 0) {\n      storageIds \u003d new String[nsi + 1];\n      storageIds[0] \u003d storageId;\n      if (targetStorageTypes.length \u003e 0) {\n        System.arraycopy(targetStorageIds, 0, storageIds, 1, nsi);\n      }\n    } else {\n      storageIds \u003d new String[0];\n    }\n    checkAccess(replyOut, isClient, block, blockToken, Op.WRITE_BLOCK,\n        BlockTokenIdentifier.AccessMode.WRITE,\n        storageTypes, storageIds);\n\n    // check single target for transfer-RBW/Finalized\n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d{}, clientname\u003d{}\\n  \" +\n              \"block  \u003d{}, newGs\u003d{}, bytesRcvd\u003d[{}, {}]\\n  \" +\n              \"targets\u003d{}; pipelineSize\u003d{}, srcDataNode\u003d{}, pinning\u003d{}\",\n          stage, clientname, block, latestGenerationStamp, minBytesRcvd,\n          maxBytesRcvd, Arrays.asList(targets), pipelineSize, srcDataNode,\n          pinning);\n      LOG.debug(\"isDatanode\u003d{}, isClient\u003d{}, isTransfer\u003d{}\",\n          isDatanode, isClient, isTransfer);\n      LOG.debug(\"writeBlock receive buf size {} tcp no delay {}\",\n          peer.getReceiveBufferSize(), peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving {} src: {} dest: {}\",\n        block, remoteAddress, localAddress);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    final boolean isOnTransientStorage;\n    try {\n      final Replica replica;\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning, storageId));\n        replica \u003d blockReceiver.getReplica();\n      } else {\n        replica \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n      storageUuid \u003d replica.getStorageUuid();\n      isOnTransientStorage \u003d replica.isOnTransientStorage();\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        LOG.debug(\"Connecting to datanode {}\", mirrorNode);\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n\n          DataNodeFaultInjector.get().failMirrorConnection();\n\n          int timeoutValue \u003d dnConf.socketTimeout +\n              (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout +\n              (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setKeepAlive(true);\n          if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n            mirrorSock.setSendBufferSize(\n                dnConf.getTransferSocketSendBufferSize());\n          }\n\n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          SecretKey secretKey \u003d null;\n          if (dnConf.overwriteDownstreamDerivedQOP) {\n            String bpid \u003d block.getBlockPoolId();\n            BlockKey blockKey \u003d datanode.blockPoolTokenSecretManager\n                .get(bpid).getCurrentKey();\n            secretKey \u003d blockKey.getKey();\n          }\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(\n              mirrorSock, unbufMirrorOut, unbufMirrorIn, keyFactory,\n              blockToken, targets[0], secretKey);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          String targetStorageId \u003d null;\n          if (targetStorageIds.length \u003e 0) {\n            // Older clients may not have provided any targetStorageIds\n            targetStorageId \u003d targetStorageIds[0];\n          }\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                blockToken, clientname, targets, targetStorageTypes,\n                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings,\n                targetStorageId, targetStorageIds);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                blockToken, clientname, targets, targetStorageTypes,\n                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings,\n                targetStorageId, targetStorageIds);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (mirrorInStatus !\u003d SUCCESS) {\n              LOG.debug(\"Datanode {} got response for connect\" +\n                  \"ack  from downstream datanode with firstbadlink as {}\",\n                  targets.length, firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(\"{}:Exception transfering block {} to mirror {}\",\n                datanode, block, mirrorNode, e);\n            throw e;\n          } else {\n            LOG.info(\"{}:Exception transfering {} to mirror {}- continuing \" +\n                \"without the mirror\", datanode, block, mirrorNode, e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (mirrorInStatus !\u003d SUCCESS) {\n          LOG.debug(\"Datanode {} forwarding connect ack to upstream \" +\n              \"firstbadlink is {}\", targets.length, firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut, mirrorAddr,\n            dataXceiverServer.getWriteThrottler(), targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          LOG.trace(\"TRANSFER: send close-ack\");\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n        LOG.info(\"Received {} src: {} dest: {} of size {}\",\n            block, remoteAddress, localAddress, block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock {} received exception {}\",\n          block, ioe.toString());\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      setCurrentBlockReceiver(null);\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "626fec652b9f3dae10c9af78fd220b1240f19fc7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13699. Add DFSClient sending handshake token to DataNode, and allow DataNode overwrite downstream QOP. Contributed by Chen Liang.\n",
      "commitDate": "12/04/19 5:37 PM",
      "commitName": "626fec652b9f3dae10c9af78fd220b1240f19fc7",
      "commitAuthor": "Chen Liang",
      "commitDateOld": "05/02/19 3:14 PM",
      "commitNameOld": "49ddd8a6ed5b40d12defb0771b4c8b53d4ffde3f",
      "commitAuthorOld": "Kitti Nanasi",
      "daysBetweenCommits": 66.06,
      "commitsBetweenForRepo": 543,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,282 +1,290 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings,\n       final String storageId,\n       final String[] targetStorageIds) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d getBufferedOutputStream();\n \n     int nst \u003d targetStorageTypes.length;\n     StorageType[] storageTypes \u003d new StorageType[nst + 1];\n     storageTypes[0] \u003d storageType;\n     if (targetStorageTypes.length \u003e 0) {\n       System.arraycopy(targetStorageTypes, 0, storageTypes, 1, nst);\n     }\n \n     // To support older clients, we don\u0027t pass in empty storageIds\n     final int nsi \u003d targetStorageIds.length;\n     final String[] storageIds;\n     if (nsi \u003e 0) {\n       storageIds \u003d new String[nsi + 1];\n       storageIds[0] \u003d storageId;\n       if (targetStorageTypes.length \u003e 0) {\n         System.arraycopy(targetStorageIds, 0, storageIds, 1, nsi);\n       }\n     } else {\n       storageIds \u003d new String[0];\n     }\n     checkAccess(replyOut, isClient, block, blockToken, Op.WRITE_BLOCK,\n         BlockTokenIdentifier.AccessMode.WRITE,\n         storageTypes, storageIds);\n \n     // check single target for transfer-RBW/Finalized\n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d{}, clientname\u003d{}\\n  \" +\n               \"block  \u003d{}, newGs\u003d{}, bytesRcvd\u003d[{}, {}]\\n  \" +\n               \"targets\u003d{}; pipelineSize\u003d{}, srcDataNode\u003d{}, pinning\u003d{}\",\n           stage, clientname, block, latestGenerationStamp, minBytesRcvd,\n           maxBytesRcvd, Arrays.asList(targets), pipelineSize, srcDataNode,\n           pinning);\n       LOG.debug(\"isDatanode\u003d{}, isClient\u003d{}, isTransfer\u003d{}\",\n           isDatanode, isClient, isTransfer);\n       LOG.debug(\"writeBlock receive buf size {} tcp no delay {}\",\n           peer.getReceiveBufferSize(), peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving {} src: {} dest: {}\",\n         block, remoteAddress, localAddress);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     final boolean isOnTransientStorage;\n     try {\n       final Replica replica;\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning, storageId));\n         replica \u003d blockReceiver.getReplica();\n       } else {\n         replica \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n       storageUuid \u003d replica.getStorageUuid();\n       isOnTransientStorage \u003d replica.isOnTransientStorage();\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         LOG.debug(\"Connecting to datanode {}\", mirrorNode);\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n \n           DataNodeFaultInjector.get().failMirrorConnection();\n \n           int timeoutValue \u003d dnConf.socketTimeout +\n               (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout +\n               (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setKeepAlive(true);\n           if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n             mirrorSock.setSendBufferSize(\n                 dnConf.getTransferSocketSendBufferSize());\n           }\n \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n-          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n-            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n+          SecretKey secretKey \u003d null;\n+          if (dnConf.overwriteDownstreamDerivedQOP) {\n+            String bpid \u003d block.getBlockPoolId();\n+            BlockKey blockKey \u003d datanode.blockPoolTokenSecretManager\n+                .get(bpid).getCurrentKey();\n+            secretKey \u003d blockKey.getKey();\n+          }\n+          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(\n+              mirrorSock, unbufMirrorOut, unbufMirrorIn, keyFactory,\n+              blockToken, targets[0], secretKey);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           String targetStorageId \u003d null;\n           if (targetStorageIds.length \u003e 0) {\n             // Older clients may not have provided any targetStorageIds\n             targetStorageId \u003d targetStorageIds[0];\n           }\n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                 blockToken, clientname, targets, targetStorageTypes,\n                 srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                 latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, targetPinnings[0], targetPinnings,\n                 targetStorageId, targetStorageIds);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                 blockToken, clientname, targets, targetStorageTypes,\n                 srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                 latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, false, targetPinnings,\n                 targetStorageId, targetStorageIds);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (mirrorInStatus !\u003d SUCCESS) {\n               LOG.debug(\"Datanode {} got response for connect\" +\n                   \"ack  from downstream datanode with firstbadlink as {}\",\n                   targets.length, firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(\"{}:Exception transfering block {} to mirror {}\",\n                 datanode, block, mirrorNode, e);\n             throw e;\n           } else {\n             LOG.info(\"{}:Exception transfering {} to mirror {}- continuing \" +\n                 \"without the mirror\", datanode, block, mirrorNode, e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (mirrorInStatus !\u003d SUCCESS) {\n           LOG.debug(\"Datanode {} forwarding connect ack to upstream \" +\n               \"firstbadlink is {}\", targets.length, firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           LOG.trace(\"TRANSFER: send close-ack\");\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n         LOG.info(\"Received {} src: {} dest: {} of size {}\",\n             block, remoteAddress, localAddress, block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock {} received exception {}\",\n           block, ioe.toString());\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       setCurrentBlockReceiver(null);\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings,\n      final String storageId,\n      final String[] targetStorageIds) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n\n    int nst \u003d targetStorageTypes.length;\n    StorageType[] storageTypes \u003d new StorageType[nst + 1];\n    storageTypes[0] \u003d storageType;\n    if (targetStorageTypes.length \u003e 0) {\n      System.arraycopy(targetStorageTypes, 0, storageTypes, 1, nst);\n    }\n\n    // To support older clients, we don\u0027t pass in empty storageIds\n    final int nsi \u003d targetStorageIds.length;\n    final String[] storageIds;\n    if (nsi \u003e 0) {\n      storageIds \u003d new String[nsi + 1];\n      storageIds[0] \u003d storageId;\n      if (targetStorageTypes.length \u003e 0) {\n        System.arraycopy(targetStorageIds, 0, storageIds, 1, nsi);\n      }\n    } else {\n      storageIds \u003d new String[0];\n    }\n    checkAccess(replyOut, isClient, block, blockToken, Op.WRITE_BLOCK,\n        BlockTokenIdentifier.AccessMode.WRITE,\n        storageTypes, storageIds);\n\n    // check single target for transfer-RBW/Finalized\n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d{}, clientname\u003d{}\\n  \" +\n              \"block  \u003d{}, newGs\u003d{}, bytesRcvd\u003d[{}, {}]\\n  \" +\n              \"targets\u003d{}; pipelineSize\u003d{}, srcDataNode\u003d{}, pinning\u003d{}\",\n          stage, clientname, block, latestGenerationStamp, minBytesRcvd,\n          maxBytesRcvd, Arrays.asList(targets), pipelineSize, srcDataNode,\n          pinning);\n      LOG.debug(\"isDatanode\u003d{}, isClient\u003d{}, isTransfer\u003d{}\",\n          isDatanode, isClient, isTransfer);\n      LOG.debug(\"writeBlock receive buf size {} tcp no delay {}\",\n          peer.getReceiveBufferSize(), peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving {} src: {} dest: {}\",\n        block, remoteAddress, localAddress);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    final boolean isOnTransientStorage;\n    try {\n      final Replica replica;\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning, storageId));\n        replica \u003d blockReceiver.getReplica();\n      } else {\n        replica \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n      storageUuid \u003d replica.getStorageUuid();\n      isOnTransientStorage \u003d replica.isOnTransientStorage();\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        LOG.debug(\"Connecting to datanode {}\", mirrorNode);\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n\n          DataNodeFaultInjector.get().failMirrorConnection();\n\n          int timeoutValue \u003d dnConf.socketTimeout +\n              (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout +\n              (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setKeepAlive(true);\n          if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n            mirrorSock.setSendBufferSize(\n                dnConf.getTransferSocketSendBufferSize());\n          }\n\n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          SecretKey secretKey \u003d null;\n          if (dnConf.overwriteDownstreamDerivedQOP) {\n            String bpid \u003d block.getBlockPoolId();\n            BlockKey blockKey \u003d datanode.blockPoolTokenSecretManager\n                .get(bpid).getCurrentKey();\n            secretKey \u003d blockKey.getKey();\n          }\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(\n              mirrorSock, unbufMirrorOut, unbufMirrorIn, keyFactory,\n              blockToken, targets[0], secretKey);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          String targetStorageId \u003d null;\n          if (targetStorageIds.length \u003e 0) {\n            // Older clients may not have provided any targetStorageIds\n            targetStorageId \u003d targetStorageIds[0];\n          }\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                blockToken, clientname, targets, targetStorageTypes,\n                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings,\n                targetStorageId, targetStorageIds);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                blockToken, clientname, targets, targetStorageTypes,\n                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings,\n                targetStorageId, targetStorageIds);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (mirrorInStatus !\u003d SUCCESS) {\n              LOG.debug(\"Datanode {} got response for connect\" +\n                  \"ack  from downstream datanode with firstbadlink as {}\",\n                  targets.length, firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(\"{}:Exception transfering block {} to mirror {}\",\n                datanode, block, mirrorNode, e);\n            throw e;\n          } else {\n            LOG.info(\"{}:Exception transfering {} to mirror {}- continuing \" +\n                \"without the mirror\", datanode, block, mirrorNode, e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (mirrorInStatus !\u003d SUCCESS) {\n          LOG.debug(\"Datanode {} forwarding connect ack to upstream \" +\n              \"firstbadlink is {}\", targets.length, firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          LOG.trace(\"TRANSFER: send close-ack\");\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n        LOG.info(\"Received {} src: {} dest: {} of size {}\",\n            block, remoteAddress, localAddress, block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock {} received exception {}\",\n          block, ioe.toString());\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      setCurrentBlockReceiver(null);\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10571. Use Log.*(Object, Throwable) overload to log exceptions.\nContributed by Andras Bokor.\n",
      "commitDate": "14/02/18 8:20 AM",
      "commitName": "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "01/11/17 1:41 AM",
      "commitNameOld": "56b88b06705441f6f171eec7fb2fa77946ca204b",
      "commitAuthorOld": "Weiwei Yang",
      "daysBetweenCommits": 105.32,
      "commitsBetweenForRepo": 696,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,289 +1,282 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings,\n       final String storageId,\n       final String[] targetStorageIds) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d getBufferedOutputStream();\n \n     int nst \u003d targetStorageTypes.length;\n     StorageType[] storageTypes \u003d new StorageType[nst + 1];\n     storageTypes[0] \u003d storageType;\n     if (targetStorageTypes.length \u003e 0) {\n       System.arraycopy(targetStorageTypes, 0, storageTypes, 1, nst);\n     }\n \n     // To support older clients, we don\u0027t pass in empty storageIds\n     final int nsi \u003d targetStorageIds.length;\n     final String[] storageIds;\n     if (nsi \u003e 0) {\n       storageIds \u003d new String[nsi + 1];\n       storageIds[0] \u003d storageId;\n       if (targetStorageTypes.length \u003e 0) {\n         System.arraycopy(targetStorageIds, 0, storageIds, 1, nsi);\n       }\n     } else {\n       storageIds \u003d new String[0];\n     }\n     checkAccess(replyOut, isClient, block, blockToken, Op.WRITE_BLOCK,\n         BlockTokenIdentifier.AccessMode.WRITE,\n         storageTypes, storageIds);\n \n     // check single target for transfer-RBW/Finalized\n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n-    \n+\n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n-      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n-      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n-          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n-          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n-          + \", pinning\u003d\" + pinning);\n-      LOG.debug(\"isDatanode\u003d\" + isDatanode\n-          + \", isClient\u003d\" + isClient\n-          + \", isTransfer\u003d\" + isTransfer);\n-      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n-                \" tcp no delay \" + peer.getTcpNoDelay());\n+      LOG.debug(\"opWriteBlock: stage\u003d{}, clientname\u003d{}\\n  \" +\n+              \"block  \u003d{}, newGs\u003d{}, bytesRcvd\u003d[{}, {}]\\n  \" +\n+              \"targets\u003d{}; pipelineSize\u003d{}, srcDataNode\u003d{}, pinning\u003d{}\",\n+          stage, clientname, block, latestGenerationStamp, minBytesRcvd,\n+          maxBytesRcvd, Arrays.asList(targets), pipelineSize, srcDataNode,\n+          pinning);\n+      LOG.debug(\"isDatanode\u003d{}, isClient\u003d{}, isTransfer\u003d{}\",\n+          isDatanode, isClient, isTransfer);\n+      LOG.debug(\"writeBlock receive buf size {} tcp no delay {}\",\n+          peer.getReceiveBufferSize(), peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n-    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n-        + localAddress);\n+    LOG.info(\"Receiving {} src: {} dest: {}\",\n+        block, remoteAddress, localAddress);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     final boolean isOnTransientStorage;\n     try {\n       final Replica replica;\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning, storageId));\n         replica \u003d blockReceiver.getReplica();\n       } else {\n         replica \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n       storageUuid \u003d replica.getStorageUuid();\n       isOnTransientStorage \u003d replica.isOnTransientStorage();\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n-        }\n+        LOG.debug(\"Connecting to datanode {}\", mirrorNode);\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n \n           DataNodeFaultInjector.get().failMirrorConnection();\n \n           int timeoutValue \u003d dnConf.socketTimeout +\n               (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout +\n               (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setKeepAlive(true);\n           if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n             mirrorSock.setSendBufferSize(\n                 dnConf.getTransferSocketSendBufferSize());\n           }\n \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           String targetStorageId \u003d null;\n           if (targetStorageIds.length \u003e 0) {\n             // Older clients may not have provided any targetStorageIds\n             targetStorageId \u003d targetStorageIds[0];\n           }\n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                 blockToken, clientname, targets, targetStorageTypes,\n                 srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                 latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, targetPinnings[0], targetPinnings,\n                 targetStorageId, targetStorageIds);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                 blockToken, clientname, targets, targetStorageTypes,\n                 srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                 latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, false, targetPinnings,\n                 targetStorageId, targetStorageIds);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n-            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n-              LOG.debug(\"Datanode \" + targets.length +\n-                       \" got response for connect ack \" +\n-                       \" from downstream datanode with firstbadlink as \" +\n-                       firstBadLink);\n+            if (mirrorInStatus !\u003d SUCCESS) {\n+              LOG.debug(\"Datanode {} got response for connect\" +\n+                  \"ack  from downstream datanode with firstbadlink as {}\",\n+                  targets.length, firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n-            LOG.error(datanode + \":Exception transfering block \" +\n-                      block + \" to mirror \" + mirrorNode + \": \" + e);\n+            LOG.error(\"{}:Exception transfering block {} to mirror {}\",\n+                datanode, block, mirrorNode, e);\n             throw e;\n           } else {\n-            LOG.info(datanode + \":Exception transfering \" +\n-                     block + \" to mirror \" + mirrorNode +\n-                     \"- continuing without the mirror\", e);\n+            LOG.info(\"{}:Exception transfering {} to mirror {}- continuing \" +\n+                \"without the mirror\", datanode, block, mirrorNode, e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n-        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n-          LOG.debug(\"Datanode \" + targets.length +\n-                   \" forwarding connect ack to upstream firstbadlink is \" +\n-                   firstBadLink);\n+        if (mirrorInStatus !\u003d SUCCESS) {\n+          LOG.debug(\"Datanode {} forwarding connect ack to upstream \" +\n+              \"firstbadlink is {}\", targets.length, firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n-          if (LOG.isTraceEnabled()) {\n-            LOG.trace(\"TRANSFER: send close-ack\");\n-          }\n+          LOG.trace(\"TRANSFER: send close-ack\");\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n-        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n-            + localAddress + \" of size \" + block.getNumBytes());\n+        LOG.info(\"Received {} src: {} dest: {} of size {}\",\n+            block, remoteAddress, localAddress, block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n-      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n+      LOG.info(\"opWriteBlock {} received exception {}\",\n+          block, ioe.toString());\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       setCurrentBlockReceiver(null);\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings,\n      final String storageId,\n      final String[] targetStorageIds) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n\n    int nst \u003d targetStorageTypes.length;\n    StorageType[] storageTypes \u003d new StorageType[nst + 1];\n    storageTypes[0] \u003d storageType;\n    if (targetStorageTypes.length \u003e 0) {\n      System.arraycopy(targetStorageTypes, 0, storageTypes, 1, nst);\n    }\n\n    // To support older clients, we don\u0027t pass in empty storageIds\n    final int nsi \u003d targetStorageIds.length;\n    final String[] storageIds;\n    if (nsi \u003e 0) {\n      storageIds \u003d new String[nsi + 1];\n      storageIds[0] \u003d storageId;\n      if (targetStorageTypes.length \u003e 0) {\n        System.arraycopy(targetStorageIds, 0, storageIds, 1, nsi);\n      }\n    } else {\n      storageIds \u003d new String[0];\n    }\n    checkAccess(replyOut, isClient, block, blockToken, Op.WRITE_BLOCK,\n        BlockTokenIdentifier.AccessMode.WRITE,\n        storageTypes, storageIds);\n\n    // check single target for transfer-RBW/Finalized\n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d{}, clientname\u003d{}\\n  \" +\n              \"block  \u003d{}, newGs\u003d{}, bytesRcvd\u003d[{}, {}]\\n  \" +\n              \"targets\u003d{}; pipelineSize\u003d{}, srcDataNode\u003d{}, pinning\u003d{}\",\n          stage, clientname, block, latestGenerationStamp, minBytesRcvd,\n          maxBytesRcvd, Arrays.asList(targets), pipelineSize, srcDataNode,\n          pinning);\n      LOG.debug(\"isDatanode\u003d{}, isClient\u003d{}, isTransfer\u003d{}\",\n          isDatanode, isClient, isTransfer);\n      LOG.debug(\"writeBlock receive buf size {} tcp no delay {}\",\n          peer.getReceiveBufferSize(), peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving {} src: {} dest: {}\",\n        block, remoteAddress, localAddress);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    final boolean isOnTransientStorage;\n    try {\n      final Replica replica;\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning, storageId));\n        replica \u003d blockReceiver.getReplica();\n      } else {\n        replica \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n      storageUuid \u003d replica.getStorageUuid();\n      isOnTransientStorage \u003d replica.isOnTransientStorage();\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        LOG.debug(\"Connecting to datanode {}\", mirrorNode);\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n\n          DataNodeFaultInjector.get().failMirrorConnection();\n\n          int timeoutValue \u003d dnConf.socketTimeout +\n              (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout +\n              (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setKeepAlive(true);\n          if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n            mirrorSock.setSendBufferSize(\n                dnConf.getTransferSocketSendBufferSize());\n          }\n\n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          String targetStorageId \u003d null;\n          if (targetStorageIds.length \u003e 0) {\n            // Older clients may not have provided any targetStorageIds\n            targetStorageId \u003d targetStorageIds[0];\n          }\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                blockToken, clientname, targets, targetStorageTypes,\n                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings,\n                targetStorageId, targetStorageIds);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                blockToken, clientname, targets, targetStorageTypes,\n                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings,\n                targetStorageId, targetStorageIds);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (mirrorInStatus !\u003d SUCCESS) {\n              LOG.debug(\"Datanode {} got response for connect\" +\n                  \"ack  from downstream datanode with firstbadlink as {}\",\n                  targets.length, firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(\"{}:Exception transfering block {} to mirror {}\",\n                datanode, block, mirrorNode, e);\n            throw e;\n          } else {\n            LOG.info(\"{}:Exception transfering {} to mirror {}- continuing \" +\n                \"without the mirror\", datanode, block, mirrorNode, e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (mirrorInStatus !\u003d SUCCESS) {\n          LOG.debug(\"Datanode {} forwarding connect ack to upstream \" +\n              \"firstbadlink is {}\", targets.length, firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          LOG.trace(\"TRANSFER: send close-ack\");\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n        LOG.info(\"Received {} src: {} dest: {} of size {}\",\n            block, remoteAddress, localAddress, block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock {} received exception {}\",\n          block, ioe.toString());\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      setCurrentBlockReceiver(null);\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "7774759830f32ef97ac9f157dbb210264b7d042a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12151. Hadoop 2 clients cannot writeBlock to Hadoop 3 DataNodes.\n",
      "commitDate": "01/08/17 1:34 PM",
      "commitName": "7774759830f32ef97ac9f157dbb210264b7d042a",
      "commitAuthor": "Sean Mackrory",
      "commitDateOld": "26/06/17 11:20 AM",
      "commitNameOld": "2c367b464c86a7d67a2b8dd82ae804d169957573",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 36.09,
      "commitsBetweenForRepo": 180,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,284 +1,289 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings,\n       final String storageId,\n       final String[] targetStorageIds) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d getBufferedOutputStream();\n \n     int nst \u003d targetStorageTypes.length;\n     StorageType[] storageTypes \u003d new StorageType[nst + 1];\n     storageTypes[0] \u003d storageType;\n     if (targetStorageTypes.length \u003e 0) {\n       System.arraycopy(targetStorageTypes, 0, storageTypes, 1, nst);\n     }\n \n     // To support older clients, we don\u0027t pass in empty storageIds\n     final int nsi \u003d targetStorageIds.length;\n     final String[] storageIds;\n     if (nsi \u003e 0) {\n       storageIds \u003d new String[nsi + 1];\n       storageIds[0] \u003d storageId;\n       if (targetStorageTypes.length \u003e 0) {\n         System.arraycopy(targetStorageIds, 0, storageIds, 1, nsi);\n       }\n     } else {\n       storageIds \u003d new String[0];\n     }\n     checkAccess(replyOut, isClient, block, blockToken, Op.WRITE_BLOCK,\n         BlockTokenIdentifier.AccessMode.WRITE,\n         storageTypes, storageIds);\n \n     // check single target for transfer-RBW/Finalized\n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     final boolean isOnTransientStorage;\n     try {\n       final Replica replica;\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning, storageId));\n         replica \u003d blockReceiver.getReplica();\n       } else {\n         replica \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n       storageUuid \u003d replica.getStorageUuid();\n       isOnTransientStorage \u003d replica.isOnTransientStorage();\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n \n           DataNodeFaultInjector.get().failMirrorConnection();\n \n           int timeoutValue \u003d dnConf.socketTimeout +\n               (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout +\n               (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setKeepAlive(true);\n           if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n             mirrorSock.setSendBufferSize(\n                 dnConf.getTransferSocketSendBufferSize());\n           }\n \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n+          String targetStorageId \u003d null;\n+          if (targetStorageIds.length \u003e 0) {\n+            // Older clients may not have provided any targetStorageIds\n+            targetStorageId \u003d targetStorageIds[0];\n+          }\n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                 blockToken, clientname, targets, targetStorageTypes,\n                 srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                 latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, targetPinnings[0], targetPinnings,\n-                targetStorageIds[0], targetStorageIds);\n+                targetStorageId, targetStorageIds);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                 blockToken, clientname, targets, targetStorageTypes,\n                 srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                 latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, false, targetPinnings,\n-                targetStorageIds[0], targetStorageIds);\n+                targetStorageId, targetStorageIds);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.debug(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.debug(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       setCurrentBlockReceiver(null);\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings,\n      final String storageId,\n      final String[] targetStorageIds) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n\n    int nst \u003d targetStorageTypes.length;\n    StorageType[] storageTypes \u003d new StorageType[nst + 1];\n    storageTypes[0] \u003d storageType;\n    if (targetStorageTypes.length \u003e 0) {\n      System.arraycopy(targetStorageTypes, 0, storageTypes, 1, nst);\n    }\n\n    // To support older clients, we don\u0027t pass in empty storageIds\n    final int nsi \u003d targetStorageIds.length;\n    final String[] storageIds;\n    if (nsi \u003e 0) {\n      storageIds \u003d new String[nsi + 1];\n      storageIds[0] \u003d storageId;\n      if (targetStorageTypes.length \u003e 0) {\n        System.arraycopy(targetStorageIds, 0, storageIds, 1, nsi);\n      }\n    } else {\n      storageIds \u003d new String[0];\n    }\n    checkAccess(replyOut, isClient, block, blockToken, Op.WRITE_BLOCK,\n        BlockTokenIdentifier.AccessMode.WRITE,\n        storageTypes, storageIds);\n\n    // check single target for transfer-RBW/Finalized\n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    final boolean isOnTransientStorage;\n    try {\n      final Replica replica;\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning, storageId));\n        replica \u003d blockReceiver.getReplica();\n      } else {\n        replica \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n      storageUuid \u003d replica.getStorageUuid();\n      isOnTransientStorage \u003d replica.isOnTransientStorage();\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n\n          DataNodeFaultInjector.get().failMirrorConnection();\n\n          int timeoutValue \u003d dnConf.socketTimeout +\n              (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout +\n              (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setKeepAlive(true);\n          if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n            mirrorSock.setSendBufferSize(\n                dnConf.getTransferSocketSendBufferSize());\n          }\n\n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          String targetStorageId \u003d null;\n          if (targetStorageIds.length \u003e 0) {\n            // Older clients may not have provided any targetStorageIds\n            targetStorageId \u003d targetStorageIds[0];\n          }\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                blockToken, clientname, targets, targetStorageTypes,\n                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings,\n                targetStorageId, targetStorageIds);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                blockToken, clientname, targets, targetStorageTypes,\n                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings,\n                targetStorageId, targetStorageIds);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.debug(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.debug(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      setCurrentBlockReceiver(null);\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "2c367b464c86a7d67a2b8dd82ae804d169957573": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11956. Do not require a storage ID or target storage IDs when writing a block. Contributed by Ewan Higgs.\n",
      "commitDate": "26/06/17 11:20 AM",
      "commitName": "2c367b464c86a7d67a2b8dd82ae804d169957573",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "05/05/17 12:01 PM",
      "commitNameOld": "a3954ccab148bddc290cb96528e63ff19799bcc9",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 51.97,
      "commitsBetweenForRepo": 250,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,277 +1,284 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings,\n       final String storageId,\n       final String[] targetStorageIds) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d getBufferedOutputStream();\n \n     int nst \u003d targetStorageTypes.length;\n     StorageType[] storageTypes \u003d new StorageType[nst + 1];\n     storageTypes[0] \u003d storageType;\n     if (targetStorageTypes.length \u003e 0) {\n       System.arraycopy(targetStorageTypes, 0, storageTypes, 1, nst);\n     }\n-    int nsi \u003d targetStorageIds.length;\n-    String[] storageIds \u003d new String[nsi + 1];\n-    storageIds[0] \u003d storageId;\n-    if (targetStorageTypes.length \u003e 0) {\n-      System.arraycopy(targetStorageIds, 0, storageIds, 1, nsi);\n+\n+    // To support older clients, we don\u0027t pass in empty storageIds\n+    final int nsi \u003d targetStorageIds.length;\n+    final String[] storageIds;\n+    if (nsi \u003e 0) {\n+      storageIds \u003d new String[nsi + 1];\n+      storageIds[0] \u003d storageId;\n+      if (targetStorageTypes.length \u003e 0) {\n+        System.arraycopy(targetStorageIds, 0, storageIds, 1, nsi);\n+      }\n+    } else {\n+      storageIds \u003d new String[0];\n     }\n     checkAccess(replyOut, isClient, block, blockToken, Op.WRITE_BLOCK,\n         BlockTokenIdentifier.AccessMode.WRITE,\n         storageTypes, storageIds);\n \n     // check single target for transfer-RBW/Finalized\n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     final boolean isOnTransientStorage;\n     try {\n       final Replica replica;\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning, storageId));\n         replica \u003d blockReceiver.getReplica();\n       } else {\n         replica \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n       storageUuid \u003d replica.getStorageUuid();\n       isOnTransientStorage \u003d replica.isOnTransientStorage();\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n \n           DataNodeFaultInjector.get().failMirrorConnection();\n \n           int timeoutValue \u003d dnConf.socketTimeout +\n               (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout +\n               (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setKeepAlive(true);\n           if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n             mirrorSock.setSendBufferSize(\n                 dnConf.getTransferSocketSendBufferSize());\n           }\n \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                 blockToken, clientname, targets, targetStorageTypes,\n                 srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                 latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, targetPinnings[0], targetPinnings,\n                 targetStorageIds[0], targetStorageIds);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                 blockToken, clientname, targets, targetStorageTypes,\n                 srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                 latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, false, targetPinnings,\n                 targetStorageIds[0], targetStorageIds);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.debug(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.debug(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       setCurrentBlockReceiver(null);\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings,\n      final String storageId,\n      final String[] targetStorageIds) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n\n    int nst \u003d targetStorageTypes.length;\n    StorageType[] storageTypes \u003d new StorageType[nst + 1];\n    storageTypes[0] \u003d storageType;\n    if (targetStorageTypes.length \u003e 0) {\n      System.arraycopy(targetStorageTypes, 0, storageTypes, 1, nst);\n    }\n\n    // To support older clients, we don\u0027t pass in empty storageIds\n    final int nsi \u003d targetStorageIds.length;\n    final String[] storageIds;\n    if (nsi \u003e 0) {\n      storageIds \u003d new String[nsi + 1];\n      storageIds[0] \u003d storageId;\n      if (targetStorageTypes.length \u003e 0) {\n        System.arraycopy(targetStorageIds, 0, storageIds, 1, nsi);\n      }\n    } else {\n      storageIds \u003d new String[0];\n    }\n    checkAccess(replyOut, isClient, block, blockToken, Op.WRITE_BLOCK,\n        BlockTokenIdentifier.AccessMode.WRITE,\n        storageTypes, storageIds);\n\n    // check single target for transfer-RBW/Finalized\n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    final boolean isOnTransientStorage;\n    try {\n      final Replica replica;\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning, storageId));\n        replica \u003d blockReceiver.getReplica();\n      } else {\n        replica \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n      storageUuid \u003d replica.getStorageUuid();\n      isOnTransientStorage \u003d replica.isOnTransientStorage();\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n\n          DataNodeFaultInjector.get().failMirrorConnection();\n\n          int timeoutValue \u003d dnConf.socketTimeout +\n              (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout +\n              (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setKeepAlive(true);\n          if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n            mirrorSock.setSendBufferSize(\n                dnConf.getTransferSocketSendBufferSize());\n          }\n\n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                blockToken, clientname, targets, targetStorageTypes,\n                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings,\n                targetStorageIds[0], targetStorageIds);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                blockToken, clientname, targets, targetStorageTypes,\n                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings,\n                targetStorageIds[0], targetStorageIds);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.debug(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.debug(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      setCurrentBlockReceiver(null);\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "a3954ccab148bddc290cb96528e63ff19799bcc9": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-9807. Add an optional StorageID to writes. Contributed by Ewan Higgs\n",
      "commitDate": "05/05/17 12:01 PM",
      "commitName": "a3954ccab148bddc290cb96528e63ff19799bcc9",
      "commitAuthor": "Chris Douglas",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9807. Add an optional StorageID to writes. Contributed by Ewan Higgs\n",
          "commitDate": "05/05/17 12:01 PM",
          "commitName": "a3954ccab148bddc290cb96528e63ff19799bcc9",
          "commitAuthor": "Chris Douglas",
          "commitDateOld": "25/04/17 11:57 PM",
          "commitNameOld": "2f73396b5901fd5fe29f6cd76fc1b3134b854b37",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 9.5,
          "commitsBetweenForRepo": 64,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,266 +1,277 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n-      final StorageType[] targetStorageTypes, \n+      final StorageType[] targetStorageTypes,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n-      final boolean[] targetPinnings) throws IOException {\n+      final boolean[] targetPinnings,\n+      final String storageId,\n+      final String[] targetStorageIds) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d getBufferedOutputStream();\n \n     int nst \u003d targetStorageTypes.length;\n     StorageType[] storageTypes \u003d new StorageType[nst + 1];\n     storageTypes[0] \u003d storageType;\n     if (targetStorageTypes.length \u003e 0) {\n       System.arraycopy(targetStorageTypes, 0, storageTypes, 1, nst);\n     }\n+    int nsi \u003d targetStorageIds.length;\n+    String[] storageIds \u003d new String[nsi + 1];\n+    storageIds[0] \u003d storageId;\n+    if (targetStorageTypes.length \u003e 0) {\n+      System.arraycopy(targetStorageIds, 0, storageIds, 1, nsi);\n+    }\n     checkAccess(replyOut, isClient, block, blockToken, Op.WRITE_BLOCK,\n-        BlockTokenIdentifier.AccessMode.WRITE, storageTypes);\n+        BlockTokenIdentifier.AccessMode.WRITE,\n+        storageTypes, storageIds);\n \n     // check single target for transfer-RBW/Finalized\n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     final boolean isOnTransientStorage;\n     try {\n       final Replica replica;\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n-            cachingStrategy, allowLazyPersist, pinning));\n+            cachingStrategy, allowLazyPersist, pinning, storageId));\n         replica \u003d blockReceiver.getReplica();\n       } else {\n         replica \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n       storageUuid \u003d replica.getStorageUuid();\n       isOnTransientStorage \u003d replica.isOnTransientStorage();\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n \n           DataNodeFaultInjector.get().failMirrorConnection();\n \n           int timeoutValue \u003d dnConf.socketTimeout +\n               (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout +\n               (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setKeepAlive(true);\n           if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n             mirrorSock.setSendBufferSize(\n                 dnConf.getTransferSocketSendBufferSize());\n           }\n \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n-              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n-              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n-              latestGenerationStamp, requestedChecksum, cachingStrategy,\n-                allowLazyPersist, targetPinnings[0], targetPinnings);\n+                blockToken, clientname, targets, targetStorageTypes,\n+                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n+                latestGenerationStamp, requestedChecksum, cachingStrategy,\n+                allowLazyPersist, targetPinnings[0], targetPinnings,\n+                targetStorageIds[0], targetStorageIds);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n-              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n-              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n-              latestGenerationStamp, requestedChecksum, cachingStrategy,\n-                allowLazyPersist, false, targetPinnings);\n+                blockToken, clientname, targets, targetStorageTypes,\n+                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n+                latestGenerationStamp, requestedChecksum, cachingStrategy,\n+                allowLazyPersist, false, targetPinnings,\n+                targetStorageIds[0], targetStorageIds);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.debug(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.debug(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       setCurrentBlockReceiver(null);\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings,\n      final String storageId,\n      final String[] targetStorageIds) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n\n    int nst \u003d targetStorageTypes.length;\n    StorageType[] storageTypes \u003d new StorageType[nst + 1];\n    storageTypes[0] \u003d storageType;\n    if (targetStorageTypes.length \u003e 0) {\n      System.arraycopy(targetStorageTypes, 0, storageTypes, 1, nst);\n    }\n    int nsi \u003d targetStorageIds.length;\n    String[] storageIds \u003d new String[nsi + 1];\n    storageIds[0] \u003d storageId;\n    if (targetStorageTypes.length \u003e 0) {\n      System.arraycopy(targetStorageIds, 0, storageIds, 1, nsi);\n    }\n    checkAccess(replyOut, isClient, block, blockToken, Op.WRITE_BLOCK,\n        BlockTokenIdentifier.AccessMode.WRITE,\n        storageTypes, storageIds);\n\n    // check single target for transfer-RBW/Finalized\n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    final boolean isOnTransientStorage;\n    try {\n      final Replica replica;\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning, storageId));\n        replica \u003d blockReceiver.getReplica();\n      } else {\n        replica \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n      storageUuid \u003d replica.getStorageUuid();\n      isOnTransientStorage \u003d replica.isOnTransientStorage();\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n\n          DataNodeFaultInjector.get().failMirrorConnection();\n\n          int timeoutValue \u003d dnConf.socketTimeout +\n              (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout +\n              (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setKeepAlive(true);\n          if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n            mirrorSock.setSendBufferSize(\n                dnConf.getTransferSocketSendBufferSize());\n          }\n\n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                blockToken, clientname, targets, targetStorageTypes,\n                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings,\n                targetStorageIds[0], targetStorageIds);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                blockToken, clientname, targets, targetStorageTypes,\n                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings,\n                targetStorageIds[0], targetStorageIds);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.debug(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.debug(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      setCurrentBlockReceiver(null);\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {
            "oldValue": "[block-ExtendedBlock(modifiers-final), storageType-StorageType(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientname-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), targetStorageTypes-StorageType[](modifiers-final), srcDataNode-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final), requestedChecksum-DataChecksum, cachingStrategy-CachingStrategy, allowLazyPersist-boolean, pinning-boolean(modifiers-final), targetPinnings-boolean[](modifiers-final)]",
            "newValue": "[block-ExtendedBlock(modifiers-final), storageType-StorageType(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientname-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), targetStorageTypes-StorageType[](modifiers-final), srcDataNode-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final), requestedChecksum-DataChecksum, cachingStrategy-CachingStrategy, allowLazyPersist-boolean, pinning-boolean(modifiers-final), targetPinnings-boolean[](modifiers-final), storageId-String(modifiers-final), targetStorageIds-String[](modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9807. Add an optional StorageID to writes. Contributed by Ewan Higgs\n",
          "commitDate": "05/05/17 12:01 PM",
          "commitName": "a3954ccab148bddc290cb96528e63ff19799bcc9",
          "commitAuthor": "Chris Douglas",
          "commitDateOld": "25/04/17 11:57 PM",
          "commitNameOld": "2f73396b5901fd5fe29f6cd76fc1b3134b854b37",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 9.5,
          "commitsBetweenForRepo": 64,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,266 +1,277 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n-      final StorageType[] targetStorageTypes, \n+      final StorageType[] targetStorageTypes,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n-      final boolean[] targetPinnings) throws IOException {\n+      final boolean[] targetPinnings,\n+      final String storageId,\n+      final String[] targetStorageIds) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d getBufferedOutputStream();\n \n     int nst \u003d targetStorageTypes.length;\n     StorageType[] storageTypes \u003d new StorageType[nst + 1];\n     storageTypes[0] \u003d storageType;\n     if (targetStorageTypes.length \u003e 0) {\n       System.arraycopy(targetStorageTypes, 0, storageTypes, 1, nst);\n     }\n+    int nsi \u003d targetStorageIds.length;\n+    String[] storageIds \u003d new String[nsi + 1];\n+    storageIds[0] \u003d storageId;\n+    if (targetStorageTypes.length \u003e 0) {\n+      System.arraycopy(targetStorageIds, 0, storageIds, 1, nsi);\n+    }\n     checkAccess(replyOut, isClient, block, blockToken, Op.WRITE_BLOCK,\n-        BlockTokenIdentifier.AccessMode.WRITE, storageTypes);\n+        BlockTokenIdentifier.AccessMode.WRITE,\n+        storageTypes, storageIds);\n \n     // check single target for transfer-RBW/Finalized\n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     final boolean isOnTransientStorage;\n     try {\n       final Replica replica;\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n-            cachingStrategy, allowLazyPersist, pinning));\n+            cachingStrategy, allowLazyPersist, pinning, storageId));\n         replica \u003d blockReceiver.getReplica();\n       } else {\n         replica \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n       storageUuid \u003d replica.getStorageUuid();\n       isOnTransientStorage \u003d replica.isOnTransientStorage();\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n \n           DataNodeFaultInjector.get().failMirrorConnection();\n \n           int timeoutValue \u003d dnConf.socketTimeout +\n               (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout +\n               (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setKeepAlive(true);\n           if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n             mirrorSock.setSendBufferSize(\n                 dnConf.getTransferSocketSendBufferSize());\n           }\n \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n-              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n-              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n-              latestGenerationStamp, requestedChecksum, cachingStrategy,\n-                allowLazyPersist, targetPinnings[0], targetPinnings);\n+                blockToken, clientname, targets, targetStorageTypes,\n+                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n+                latestGenerationStamp, requestedChecksum, cachingStrategy,\n+                allowLazyPersist, targetPinnings[0], targetPinnings,\n+                targetStorageIds[0], targetStorageIds);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n-              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n-              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n-              latestGenerationStamp, requestedChecksum, cachingStrategy,\n-                allowLazyPersist, false, targetPinnings);\n+                blockToken, clientname, targets, targetStorageTypes,\n+                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n+                latestGenerationStamp, requestedChecksum, cachingStrategy,\n+                allowLazyPersist, false, targetPinnings,\n+                targetStorageIds[0], targetStorageIds);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.debug(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.debug(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       setCurrentBlockReceiver(null);\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings,\n      final String storageId,\n      final String[] targetStorageIds) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n\n    int nst \u003d targetStorageTypes.length;\n    StorageType[] storageTypes \u003d new StorageType[nst + 1];\n    storageTypes[0] \u003d storageType;\n    if (targetStorageTypes.length \u003e 0) {\n      System.arraycopy(targetStorageTypes, 0, storageTypes, 1, nst);\n    }\n    int nsi \u003d targetStorageIds.length;\n    String[] storageIds \u003d new String[nsi + 1];\n    storageIds[0] \u003d storageId;\n    if (targetStorageTypes.length \u003e 0) {\n      System.arraycopy(targetStorageIds, 0, storageIds, 1, nsi);\n    }\n    checkAccess(replyOut, isClient, block, blockToken, Op.WRITE_BLOCK,\n        BlockTokenIdentifier.AccessMode.WRITE,\n        storageTypes, storageIds);\n\n    // check single target for transfer-RBW/Finalized\n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    final boolean isOnTransientStorage;\n    try {\n      final Replica replica;\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning, storageId));\n        replica \u003d blockReceiver.getReplica();\n      } else {\n        replica \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n      storageUuid \u003d replica.getStorageUuid();\n      isOnTransientStorage \u003d replica.isOnTransientStorage();\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n\n          DataNodeFaultInjector.get().failMirrorConnection();\n\n          int timeoutValue \u003d dnConf.socketTimeout +\n              (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout +\n              (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setKeepAlive(true);\n          if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n            mirrorSock.setSendBufferSize(\n                dnConf.getTransferSocketSendBufferSize());\n          }\n\n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                blockToken, clientname, targets, targetStorageTypes,\n                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings,\n                targetStorageIds[0], targetStorageIds);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n                blockToken, clientname, targets, targetStorageTypes,\n                srcDataNode, stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n                latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings,\n                targetStorageIds[0], targetStorageIds);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.debug(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.debug(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      setCurrentBlockReceiver(null);\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {}
        }
      ]
    },
    "2f73396b5901fd5fe29f6cd76fc1b3134b854b37": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6708. StorageType should be encoded in the block token. Contributed by Ewan Higgs\n",
      "commitDate": "25/04/17 11:57 PM",
      "commitName": "2f73396b5901fd5fe29f6cd76fc1b3134b854b37",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "12/04/17 11:40 AM",
      "commitNameOld": "abce61335678da753cd0f7965a236370274abee8",
      "commitAuthorOld": "Anu Engineer",
      "daysBetweenCommits": 13.51,
      "commitsBetweenForRepo": 57,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,258 +1,266 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d getBufferedOutputStream();\n-    checkAccess(replyOut, isClient, block, blockToken,\n-        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n-    // check single target for transfer-RBW/Finalized \n+\n+    int nst \u003d targetStorageTypes.length;\n+    StorageType[] storageTypes \u003d new StorageType[nst + 1];\n+    storageTypes[0] \u003d storageType;\n+    if (targetStorageTypes.length \u003e 0) {\n+      System.arraycopy(targetStorageTypes, 0, storageTypes, 1, nst);\n+    }\n+    checkAccess(replyOut, isClient, block, blockToken, Op.WRITE_BLOCK,\n+        BlockTokenIdentifier.AccessMode.WRITE, storageTypes);\n+\n+    // check single target for transfer-RBW/Finalized\n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     final boolean isOnTransientStorage;\n     try {\n       final Replica replica;\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning));\n         replica \u003d blockReceiver.getReplica();\n       } else {\n         replica \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n       storageUuid \u003d replica.getStorageUuid();\n       isOnTransientStorage \u003d replica.isOnTransientStorage();\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n \n           DataNodeFaultInjector.get().failMirrorConnection();\n \n           int timeoutValue \u003d dnConf.socketTimeout +\n               (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout +\n               (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setKeepAlive(true);\n           if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n             mirrorSock.setSendBufferSize(\n                 dnConf.getTransferSocketSendBufferSize());\n           }\n \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, targetPinnings[0], targetPinnings);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, false, targetPinnings);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.debug(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.debug(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       setCurrentBlockReceiver(null);\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n\n    int nst \u003d targetStorageTypes.length;\n    StorageType[] storageTypes \u003d new StorageType[nst + 1];\n    storageTypes[0] \u003d storageType;\n    if (targetStorageTypes.length \u003e 0) {\n      System.arraycopy(targetStorageTypes, 0, storageTypes, 1, nst);\n    }\n    checkAccess(replyOut, isClient, block, blockToken, Op.WRITE_BLOCK,\n        BlockTokenIdentifier.AccessMode.WRITE, storageTypes);\n\n    // check single target for transfer-RBW/Finalized\n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    final boolean isOnTransientStorage;\n    try {\n      final Replica replica;\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning));\n        replica \u003d blockReceiver.getReplica();\n      } else {\n        replica \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n      storageUuid \u003d replica.getStorageUuid();\n      isOnTransientStorage \u003d replica.isOnTransientStorage();\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n\n          DataNodeFaultInjector.get().failMirrorConnection();\n\n          int timeoutValue \u003d dnConf.socketTimeout +\n              (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout +\n              (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setKeepAlive(true);\n          if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n            mirrorSock.setSendBufferSize(\n                dnConf.getTransferSocketSendBufferSize());\n          }\n\n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.debug(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.debug(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      setCurrentBlockReceiver(null);\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "e4a25456202feeee9880d822a8e6f9c19cbcf24a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9805. Add server-side configuration for enabling TCP_NODELAY for DataTransferProtocol and default it to true (Gary Helmling via cmccabe)\n",
      "commitDate": "29/06/16 12:41 PM",
      "commitName": "e4a25456202feeee9880d822a8e6f9c19cbcf24a",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "24/06/16 2:39 AM",
      "commitNameOld": "e6cb07520f935efde3e881de8f84ee7f6e0a746f",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 5.42,
      "commitsBetweenForRepo": 28,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,257 +1,258 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d getBufferedOutputStream();\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     final boolean isOnTransientStorage;\n     try {\n       final Replica replica;\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning));\n         replica \u003d blockReceiver.getReplica();\n       } else {\n         replica \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n       storageUuid \u003d replica.getStorageUuid();\n       isOnTransientStorage \u003d replica.isOnTransientStorage();\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n \n           DataNodeFaultInjector.get().failMirrorConnection();\n \n           int timeoutValue \u003d dnConf.socketTimeout +\n               (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout +\n               (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n+          mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setKeepAlive(true);\n           if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n             mirrorSock.setSendBufferSize(\n                 dnConf.getTransferSocketSendBufferSize());\n           }\n \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, targetPinnings[0], targetPinnings);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, false, targetPinnings);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.debug(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.debug(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       setCurrentBlockReceiver(null);\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    final boolean isOnTransientStorage;\n    try {\n      final Replica replica;\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning));\n        replica \u003d blockReceiver.getReplica();\n      } else {\n        replica \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n      storageUuid \u003d replica.getStorageUuid();\n      isOnTransientStorage \u003d replica.isOnTransientStorage();\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n\n          DataNodeFaultInjector.get().failMirrorConnection();\n\n          int timeoutValue \u003d dnConf.socketTimeout +\n              (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout +\n              (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setTcpNoDelay(dnConf.getDataTransferServerTcpNoDelay());\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setKeepAlive(true);\n          if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n            mirrorSock.setSendBufferSize(\n                dnConf.getTransferSocketSendBufferSize());\n          }\n\n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.debug(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.debug(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      setCurrentBlockReceiver(null);\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "f2ac132d6a21c215093b7f87acf2843ac8123716": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9530. ReservedSpace is not cleared for abandoned Blocks (Contributed by Brahma Reddy Battula)\n",
      "commitDate": "21/06/16 3:12 AM",
      "commitName": "f2ac132d6a21c215093b7f87acf2843ac8123716",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "06/04/16 1:20 PM",
      "commitNameOld": "aede8c10ecad4f2a8802a834e4bd0b8286cebade",
      "commitAuthorOld": "Eric Payne",
      "daysBetweenCommits": 75.58,
      "commitsBetweenForRepo": 485,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,254 +1,257 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d getBufferedOutputStream();\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     final boolean isOnTransientStorage;\n     try {\n       final Replica replica;\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning));\n         replica \u003d blockReceiver.getReplica();\n       } else {\n         replica \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n       storageUuid \u003d replica.getStorageUuid();\n       isOnTransientStorage \u003d replica.isOnTransientStorage();\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n+\n+          DataNodeFaultInjector.get().failMirrorConnection();\n+\n           int timeoutValue \u003d dnConf.socketTimeout +\n               (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout +\n               (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setKeepAlive(true);\n           if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n             mirrorSock.setSendBufferSize(\n                 dnConf.getTransferSocketSendBufferSize());\n           }\n \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, targetPinnings[0], targetPinnings);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, false, targetPinnings);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.debug(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.debug(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       setCurrentBlockReceiver(null);\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    final boolean isOnTransientStorage;\n    try {\n      final Replica replica;\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning));\n        replica \u003d blockReceiver.getReplica();\n      } else {\n        replica \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n      storageUuid \u003d replica.getStorageUuid();\n      isOnTransientStorage \u003d replica.isOnTransientStorage();\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n\n          DataNodeFaultInjector.get().failMirrorConnection();\n\n          int timeoutValue \u003d dnConf.socketTimeout +\n              (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout +\n              (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setKeepAlive(true);\n          if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n            mirrorSock.setSendBufferSize(\n                dnConf.getTransferSocketSendBufferSize());\n          }\n\n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.debug(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.debug(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      setCurrentBlockReceiver(null);\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "aede8c10ecad4f2a8802a834e4bd0b8286cebade": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9945. Datanode command for evicting writers. Contributed by Kihwal Lee\n",
      "commitDate": "06/04/16 1:20 PM",
      "commitName": "aede8c10ecad4f2a8802a834e4bd0b8286cebade",
      "commitAuthor": "Eric Payne",
      "commitDateOld": "26/03/16 7:58 PM",
      "commitNameOld": "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 10.72,
      "commitsBetweenForRepo": 76,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,254 +1,254 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d getBufferedOutputStream();\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     final boolean isOnTransientStorage;\n     try {\n       final Replica replica;\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n-        blockReceiver \u003d getBlockReceiver(block, storageType, in,\n+        setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n-            cachingStrategy, allowLazyPersist, pinning);\n+            cachingStrategy, allowLazyPersist, pinning));\n         replica \u003d blockReceiver.getReplica();\n       } else {\n         replica \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n       storageUuid \u003d replica.getStorageUuid();\n       isOnTransientStorage \u003d replica.isOnTransientStorage();\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout +\n               (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout +\n               (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setKeepAlive(true);\n           if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n             mirrorSock.setSendBufferSize(\n                 dnConf.getTransferSocketSendBufferSize());\n           }\n \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, targetPinnings[0], targetPinnings);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, false, targetPinnings);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.debug(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.debug(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n-      blockReceiver \u003d null;\n+      setCurrentBlockReceiver(null);\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    final boolean isOnTransientStorage;\n    try {\n      final Replica replica;\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        setCurrentBlockReceiver(getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning));\n        replica \u003d blockReceiver.getReplica();\n      } else {\n        replica \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n      storageUuid \u003d replica.getStorageUuid();\n      isOnTransientStorage \u003d replica.isOnTransientStorage();\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout +\n              (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout +\n              (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setKeepAlive(true);\n          if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n            mirrorSock.setSendBufferSize(\n                dnConf.getTransferSocketSendBufferSize());\n          }\n\n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.debug(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.debug(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      setCurrentBlockReceiver(null);\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "d1d4e16690cc85f7f22fbead9cf596260819b561": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9710. DN can be configured to send block receipt IBRs in batches.\n",
      "commitDate": "26/02/16 3:32 PM",
      "commitName": "d1d4e16690cc85f7f22fbead9cf596260819b561",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "07/02/16 8:50 PM",
      "commitNameOld": "aea31eee78a287f251447686ba3f5bbcfe9c60a3",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 18.78,
      "commitsBetweenForRepo": 140,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,251 +1,254 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d getBufferedOutputStream();\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n+    final boolean isOnTransientStorage;\n     try {\n+      final Replica replica;\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning);\n-\n-        storageUuid \u003d blockReceiver.getStorageUuid();\n+        replica \u003d blockReceiver.getReplica();\n       } else {\n-        storageUuid \u003d datanode.data.recoverClose(\n+        replica \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n+      storageUuid \u003d replica.getStorageUuid();\n+      isOnTransientStorage \u003d replica.isOnTransientStorage();\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout +\n               (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout +\n               (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setKeepAlive(true);\n           if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n             mirrorSock.setSendBufferSize(\n                 dnConf.getTransferSocketSendBufferSize());\n           }\n \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, targetPinnings[0], targetPinnings);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, false, targetPinnings);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.debug(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.debug(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n-        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n+        datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    final boolean isOnTransientStorage;\n    try {\n      final Replica replica;\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning);\n        replica \u003d blockReceiver.getReplica();\n      } else {\n        replica \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n      storageUuid \u003d replica.getStorageUuid();\n      isOnTransientStorage \u003d replica.isOnTransientStorage();\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout +\n              (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout +\n              (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setKeepAlive(true);\n          if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n            mirrorSock.setSendBufferSize(\n                dnConf.getTransferSocketSendBufferSize());\n          }\n\n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.debug(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.debug(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, null, storageUuid, isOnTransientStorage);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "38c4c14472996562eb3d610649246770c2888c6b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9574. Reduce client failures during datanode restart. Contributed by Kihwal Lee.\n",
      "commitDate": "08/01/16 9:13 AM",
      "commitName": "38c4c14472996562eb3d610649246770c2888c6b",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "04/01/16 2:32 PM",
      "commitNameOld": "778146eaae5b1e17928a1f26fb1e46536a6ee510",
      "commitAuthorOld": "Uma Mahesh",
      "daysBetweenCommits": 3.78,
      "commitsBetweenForRepo": 30,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,252 +1,251 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n+    // reply to upstream datanode or client \n+    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n+    checkAccess(replyOut, isClient, block, blockToken,\n+        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n-    // reply to upstream datanode or client \n-    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n-    checkAccess(replyOut, isClient, block, blockToken,\n-        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n-\n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning);\n \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout +\n               (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout +\n               (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setKeepAlive(true);\n           if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n             mirrorSock.setSendBufferSize(\n                 dnConf.getTransferSocketSendBufferSize());\n           }\n \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, targetPinnings[0], targetPinnings);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, false, targetPinnings);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.debug(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.debug(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning);\n\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout +\n              (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout +\n              (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setKeepAlive(true);\n          if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n            mirrorSock.setSendBufferSize(\n                dnConf.getTransferSocketSendBufferSize());\n          }\n\n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.debug(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.debug(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "49949a4bb03aa81cbb9115e91ab1c61cc6dc8a62": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8894. Set SO_KEEPALIVE on DN server sockets. Contributed by Kanaka Kumar Avvaru.\n",
      "commitDate": "15/12/15 2:38 PM",
      "commitName": "49949a4bb03aa81cbb9115e91ab1c61cc6dc8a62",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "22/11/15 3:54 PM",
      "commitNameOld": "176ff5ce90f2cbcd8342016d0f5570337d2ff79f",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 22.95,
      "commitsBetweenForRepo": 158,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,251 +1,252 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d getBufferedOutputStream();\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning);\n \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout +\n               (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout +\n               (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n+          mirrorSock.setKeepAlive(true);\n           if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n             mirrorSock.setSendBufferSize(\n                 dnConf.getTransferSocketSendBufferSize());\n           }\n \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, targetPinnings[0], targetPinnings);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, false, targetPinnings);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.debug(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.debug(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning);\n\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout +\n              (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout +\n              (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setKeepAlive(true);\n          if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n            mirrorSock.setSendBufferSize(\n                dnConf.getTransferSocketSendBufferSize());\n          }\n\n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.debug(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.debug(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "dfd807afab0fae3839c9cc5d552aa0304444f956": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12428. Fix inconsistency between log-level guards and statements. Contributed by Jagadesh Kiran N and Jackie Chang.\n",
      "commitDate": "21/09/15 8:54 PM",
      "commitName": "dfd807afab0fae3839c9cc5d552aa0304444f956",
      "commitAuthor": "Tsuyoshi Ozawa",
      "commitDateOld": "14/09/15 4:02 PM",
      "commitNameOld": "7b5cf5352efedc7d7ebdbb6b58f1b9a688812e75",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 7.2,
      "commitsBetweenForRepo": 52,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,251 +1,251 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d getBufferedOutputStream();\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning);\n \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout +\n               (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout +\n               (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n             mirrorSock.setSendBufferSize(\n                 dnConf.getTransferSocketSendBufferSize());\n           }\n \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, targetPinnings[0], targetPinnings);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, false, targetPinnings);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n-              LOG.info(\"Datanode \" + targets.length +\n+              LOG.debug(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n-          LOG.info(\"Datanode \" + targets.length +\n+          LOG.debug(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning);\n\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout +\n              (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout +\n              (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n            mirrorSock.setSendBufferSize(\n                dnConf.getTransferSocketSendBufferSize());\n          }\n\n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.debug(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.debug(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "7b5cf5352efedc7d7ebdbb6b58f1b9a688812e75": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8829. Make SO_RCVBUF and SO_SNDBUF size configurable for DataTransferProtocol sockets and allow configuring auto-tuning (He Tianyi via Colin P. McCabe)\n\nChange-Id: I77dc71aaf9e14ef743f2a2cbebeec04a4f628c78\n",
      "commitDate": "14/09/15 4:02 PM",
      "commitName": "7b5cf5352efedc7d7ebdbb6b58f1b9a688812e75",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "27/08/15 9:02 AM",
      "commitNameOld": "7e971b7315fa2942b4db7ba11ed513766957b777",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 18.29,
      "commitsBetweenForRepo": 106,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,248 +1,251 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d getBufferedOutputStream();\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning);\n \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout +\n               (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout +\n               (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n-          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n-          \n+          if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n+            mirrorSock.setSendBufferSize(\n+                dnConf.getTransferSocketSendBufferSize());\n+          }\n+\n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, targetPinnings[0], targetPinnings);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, false, targetPinnings);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning);\n\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout +\n              (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout +\n              (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          if (dnConf.getTransferSocketSendBufferSize() \u003e 0) {\n            mirrorSock.setSendBufferSize(\n                dnConf.getTransferSocketSendBufferSize());\n          }\n\n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8934. Move ShortCircuitShm to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "22/08/15 1:31 PM",
      "commitName": "490bb5ebd6c6d6f9c08fcad167f976687fc3aa42",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "19/08/15 11:28 AM",
      "commitNameOld": "3aac4758b007a56e3d66998d457b2156effca528",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 3.09,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,248 +1,248 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d getBufferedOutputStream();\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning);\n \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, targetPinnings[0], targetPinnings);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, false, targetPinnings);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n-              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n+              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning);\n\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelperClient.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "3aac4758b007a56e3d66998d457b2156effca528": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8803. Move DfsClientConf to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "19/08/15 11:28 AM",
      "commitName": "3aac4758b007a56e3d66998d457b2156effca528",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "30/07/15 1:16 PM",
      "commitNameOld": "88d8736ddeff10a03acaa99a9a0ee99dcfabe590",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 19.92,
      "commitsBetweenForRepo": 99,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,248 +1,248 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n         (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d getBufferedOutputStream();\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning);\n \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n-              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n+              + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n-                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n+                      (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, targetPinnings[0], targetPinnings);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n                 allowLazyPersist, false, targetPinnings);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.getMetrics().addWriteBlockOp(elapsed());\n     datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning);\n\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "88d8736ddeff10a03acaa99a9a0ee99dcfabe590": {
      "type": "Ymultichange(Ybodychange,Yparametermetachange)",
      "commitMessage": "HDFS-7192. DN should ignore lazyPersist hint if the writer is not local. (Contributed by Arpit Agarwal)\n",
      "commitDate": "30/07/15 1:16 PM",
      "commitName": "88d8736ddeff10a03acaa99a9a0ee99dcfabe590",
      "commitAuthor": "Arpit Agarwal",
      "subchanges": [
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7192. DN should ignore lazyPersist hint if the writer is not local. (Contributed by Arpit Agarwal)\n",
          "commitDate": "30/07/15 1:16 PM",
          "commitName": "88d8736ddeff10a03acaa99a9a0ee99dcfabe590",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "05/05/15 3:41 PM",
          "commitNameOld": "4da8490b512a33a255ed27309860859388d7c168",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 85.9,
          "commitsBetweenForRepo": 672,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,250 +1,248 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n-      final boolean allowLazyPersist,\n+      boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n+    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n+        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n-    final DataOutputStream replyOut \u003d new DataOutputStream(\n-        new BufferedOutputStream(\n-            getOutputStream(),\n-            smallBufferSize));\n+    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n-        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n+        blockReceiver \u003d getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning);\n \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n-          // Do not propagate allowLazyPersist to downstream DataNodes.\n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n-              false, targetPinnings[0], targetPinnings);\n+                allowLazyPersist, targetPinnings[0], targetPinnings);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n-              false, false, targetPinnings);\n+                allowLazyPersist, false, targetPinnings);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n-    datanode.metrics.addWriteBlockOp(elapsed());\n-    datanode.metrics.incrWritesFromClient(peer.isLocal(), size);\n+    datanode.getMetrics().addWriteBlockOp(elapsed());\n+    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning);\n\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparametermetachange",
          "commitMessage": "HDFS-7192. DN should ignore lazyPersist hint if the writer is not local. (Contributed by Arpit Agarwal)\n",
          "commitDate": "30/07/15 1:16 PM",
          "commitName": "88d8736ddeff10a03acaa99a9a0ee99dcfabe590",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "05/05/15 3:41 PM",
          "commitNameOld": "4da8490b512a33a255ed27309860859388d7c168",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 85.9,
          "commitsBetweenForRepo": 672,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,250 +1,248 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n-      final boolean allowLazyPersist,\n+      boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n+    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n+        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n     long size \u003d 0;\n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n-    final DataOutputStream replyOut \u003d new DataOutputStream(\n-        new BufferedOutputStream(\n-            getOutputStream(),\n-            smallBufferSize));\n+    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n-        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n+        blockReceiver \u003d getBlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning);\n \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n-          // Do not propagate allowLazyPersist to downstream DataNodes.\n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n-              false, targetPinnings[0], targetPinnings);\n+                allowLazyPersist, targetPinnings[0], targetPinnings);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n-              false, false, targetPinnings);\n+                allowLazyPersist, false, targetPinnings);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n-    datanode.metrics.addWriteBlockOp(elapsed());\n-    datanode.metrics.incrWritesFromClient(peer.isLocal(), size);\n+    datanode.getMetrics().addWriteBlockOp(elapsed());\n+    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    allowLazyPersist \u003d allowLazyPersist \u0026\u0026\n        (dnConf.getAllowNonLocalLazyPersist() || peer.isLocal());\n    long size \u003d 0;\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d getBufferedOutputStream();\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d getBlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning);\n\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n                allowLazyPersist, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.getMetrics().addWriteBlockOp(elapsed());\n    datanode.getMetrics().incrWritesFromClient(peer.isLocal(), size);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {
            "oldValue": "[block-ExtendedBlock(modifiers-final), storageType-StorageType(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientname-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), targetStorageTypes-StorageType[](modifiers-final), srcDataNode-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final), requestedChecksum-DataChecksum, cachingStrategy-CachingStrategy, allowLazyPersist-boolean(modifiers-final), pinning-boolean(modifiers-final), targetPinnings-boolean[](modifiers-final)]",
            "newValue": "[block-ExtendedBlock(modifiers-final), storageType-StorageType(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientname-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), targetStorageTypes-StorageType[](modifiers-final), srcDataNode-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final), requestedChecksum-DataChecksum, cachingStrategy-CachingStrategy, allowLazyPersist-boolean, pinning-boolean(modifiers-final), targetPinnings-boolean[](modifiers-final)]"
          }
        }
      ]
    },
    "4da8490b512a33a255ed27309860859388d7c168": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8314. Move HdfsServerConstants#IO_FILE_BUFFER_SIZE and SMALL_BUFFER_SIZE to the users. Contributed by Li Lu.\n",
      "commitDate": "05/05/15 3:41 PM",
      "commitName": "4da8490b512a33a255ed27309860859388d7c168",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "02/05/15 10:03 AM",
      "commitNameOld": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 3.23,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,250 +1,250 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       final boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     long size \u003d 0;\n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n-            HdfsServerConstants.SMALL_BUFFER_SIZE));\n+            smallBufferSize));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning);\n \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n-              HdfsServerConstants.SMALL_BUFFER_SIZE));\n+              smallBufferSize));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           // Do not propagate allowLazyPersist to downstream DataNodes.\n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n               false, targetPinnings[0], targetPinnings);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n               false, false, targetPinnings);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      final boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    long size \u003d 0;\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            smallBufferSize));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning);\n\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              smallBufferSize));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          // Do not propagate allowLazyPersist to downstream DataNodes.\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n              false, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n              false, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8249. Separate HdfsConstants into the client and the server side class. Contributed by Haohui Mai.\n",
      "commitDate": "02/05/15 10:03 AM",
      "commitName": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "23/04/15 7:00 PM",
      "commitNameOld": "a0e0a63209b5eb17dca5cc503be36aa52defeabd",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 8.63,
      "commitsBetweenForRepo": 77,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,250 +1,250 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       final boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     long size \u003d 0;\n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n-            HdfsConstants.SMALL_BUFFER_SIZE));\n+            HdfsServerConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning);\n \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n-              HdfsConstants.SMALL_BUFFER_SIZE));\n+              HdfsServerConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           // Do not propagate allowLazyPersist to downstream DataNodes.\n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n               false, targetPinnings[0], targetPinnings);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n               false, false, targetPinnings);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      final boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    long size \u003d 0;\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsServerConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning);\n\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsServerConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          // Do not propagate allowLazyPersist to downstream DataNodes.\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n              false, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n              false, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "36e4cd3be6f7fec8db82d3d1bcb258af470ece2e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8103. Move BlockTokenSecretManager.AccessMode into BlockTokenIdentifier. Contributed by Haohui Mai.\n",
      "commitDate": "10/04/15 4:36 PM",
      "commitName": "36e4cd3be6f7fec8db82d3d1bcb258af470ece2e",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "20/03/15 12:02 PM",
      "commitNameOld": "75ead273bea8a7dad61c4f99c3a16cab2697c498",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 21.19,
      "commitsBetweenForRepo": 196,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,250 +1,250 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       final boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n     long size \u003d 0;\n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n-        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n+        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning);\n \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           // Do not propagate allowLazyPersist to downstream DataNodes.\n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n               false, targetPinnings[0], targetPinnings);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n               false, false, targetPinnings);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       if(isClient) {\n         size \u003d block.getNumBytes();\n       }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      final boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    long size \u003d 0;\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenIdentifier.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning);\n\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          // Do not propagate allowLazyPersist to downstream DataNodes.\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n              false, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n              false, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "02e7dec79d2d4f2b801435343219d8fb53ec931f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7773. Additional metrics in HDFS to be accessed via jmx. Contributed by Anu Engineer.\n",
      "commitDate": "20/02/15 12:37 PM",
      "commitName": "02e7dec79d2d4f2b801435343219d8fb53ec931f",
      "commitAuthor": "cnauroth",
      "commitDateOld": "11/02/15 3:12 PM",
      "commitNameOld": "085b1e293ff53f7a86aa21406cfd4bfa0f3bf33b",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 8.89,
      "commitsBetweenForRepo": 106,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,248 +1,250 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       final boolean allowLazyPersist,\n       final boolean pinning,\n       final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n-\n+    long size \u003d 0;\n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n     \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist, pinning);\n \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           // Do not propagate allowLazyPersist to downstream DataNodes.\n           if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n               false, targetPinnings[0], targetPinnings);\n           } else {\n             new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy,\n               false, false, targetPinnings);\n           }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n-      \n+      if(isClient) {\n+        size \u003d block.getNumBytes();\n+      }\n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n-    datanode.metrics.incrWritesFromClient(peer.isLocal());\n+    datanode.metrics.incrWritesFromClient(peer.isLocal(), size);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      final boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n    long size \u003d 0;\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning);\n\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          // Do not propagate allowLazyPersist to downstream DataNodes.\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n              false, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n              false, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      if(isClient) {\n        size \u003d block.getNumBytes();\n      }\n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal(), size);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "085b1e293ff53f7a86aa21406cfd4bfa0f3bf33b": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6133. Add a feature for replica pinning so that a pinned replica will not be moved by Balancer/Mover.  Contributed by zhaoyunjiong\n",
      "commitDate": "11/02/15 3:12 PM",
      "commitName": "085b1e293ff53f7a86aa21406cfd4bfa0f3bf33b",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6133. Add a feature for replica pinning so that a pinned replica will not be moved by Balancer/Mover.  Contributed by zhaoyunjiong\n",
          "commitDate": "11/02/15 3:12 PM",
          "commitName": "085b1e293ff53f7a86aa21406cfd4bfa0f3bf33b",
          "commitAuthor": "Tsz-Wo Nicholas Sze",
          "commitDateOld": "18/12/14 3:03 PM",
          "commitNameOld": "5df7ecb33ab24de903f0fd98e2a055164874def5",
          "commitAuthorOld": "cnauroth",
          "daysBetweenCommits": 55.01,
          "commitsBetweenForRepo": 369,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,237 +1,248 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n-      final boolean allowLazyPersist) throws IOException {\n+      final boolean allowLazyPersist,\n+      final boolean pinning,\n+      final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n-\n+    \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n-          );\n+          + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n-            cachingStrategy, allowLazyPersist);\n+            cachingStrategy, allowLazyPersist, pinning);\n \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           // Do not propagate allowLazyPersist to downstream DataNodes.\n-          new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n+          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n+            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n-              latestGenerationStamp, requestedChecksum, cachingStrategy, false);\n+              latestGenerationStamp, requestedChecksum, cachingStrategy,\n+              false, targetPinnings[0], targetPinnings);\n+          } else {\n+            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n+              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n+              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n+              latestGenerationStamp, requestedChecksum, cachingStrategy,\n+              false, false, targetPinnings);\n+          }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      final boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning);\n\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          // Do not propagate allowLazyPersist to downstream DataNodes.\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n              false, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n              false, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {
            "oldValue": "[block-ExtendedBlock(modifiers-final), storageType-StorageType(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientname-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), targetStorageTypes-StorageType[](modifiers-final), srcDataNode-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final), requestedChecksum-DataChecksum, cachingStrategy-CachingStrategy, allowLazyPersist-boolean(modifiers-final)]",
            "newValue": "[block-ExtendedBlock(modifiers-final), storageType-StorageType(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientname-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), targetStorageTypes-StorageType[](modifiers-final), srcDataNode-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final), requestedChecksum-DataChecksum, cachingStrategy-CachingStrategy, allowLazyPersist-boolean(modifiers-final), pinning-boolean(modifiers-final), targetPinnings-boolean[](modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6133. Add a feature for replica pinning so that a pinned replica will not be moved by Balancer/Mover.  Contributed by zhaoyunjiong\n",
          "commitDate": "11/02/15 3:12 PM",
          "commitName": "085b1e293ff53f7a86aa21406cfd4bfa0f3bf33b",
          "commitAuthor": "Tsz-Wo Nicholas Sze",
          "commitDateOld": "18/12/14 3:03 PM",
          "commitNameOld": "5df7ecb33ab24de903f0fd98e2a055164874def5",
          "commitAuthorOld": "cnauroth",
          "daysBetweenCommits": 55.01,
          "commitsBetweenForRepo": 369,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,237 +1,248 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n-      final boolean allowLazyPersist) throws IOException {\n+      final boolean allowLazyPersist,\n+      final boolean pinning,\n+      final boolean[] targetPinnings) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n-\n+    \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n-          );\n+          + \", pinning\u003d\" + pinning);\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n-            cachingStrategy, allowLazyPersist);\n+            cachingStrategy, allowLazyPersist, pinning);\n \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           // Do not propagate allowLazyPersist to downstream DataNodes.\n-          new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n+          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n+            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n-              latestGenerationStamp, requestedChecksum, cachingStrategy, false);\n+              latestGenerationStamp, requestedChecksum, cachingStrategy,\n+              false, targetPinnings[0], targetPinnings);\n+          } else {\n+            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n+              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n+              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n+              latestGenerationStamp, requestedChecksum, cachingStrategy,\n+              false, false, targetPinnings);\n+          }\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n             incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      final boolean allowLazyPersist,\n      final boolean pinning,\n      final boolean[] targetPinnings) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          + \", pinning\u003d\" + pinning);\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist, pinning);\n\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          // Do not propagate allowLazyPersist to downstream DataNodes.\n          if (targetPinnings !\u003d null \u0026\u0026 targetPinnings.length \u003e 0) {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n              false, targetPinnings[0], targetPinnings);\n          } else {\n            new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy,\n              false, false, targetPinnings);\n          }\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {}
        }
      ]
    },
    "2d4f3e567e4bb8068c028de12df118a4f3fa6343": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7331. Add Datanode network counts to datanode jmx page. Contributed by Charles Lamb.\n",
      "commitDate": "21/11/14 4:36 PM",
      "commitName": "2d4f3e567e4bb8068c028de12df118a4f3fa6343",
      "commitAuthor": "Aaron T. Myers",
      "commitDateOld": "08/11/14 10:24 PM",
      "commitNameOld": "9ba8d8c7eb65eeb6fe673f04e493d9eedd95a822",
      "commitAuthorOld": "cnauroth",
      "daysBetweenCommits": 12.76,
      "commitsBetweenForRepo": 104,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,237 +1,237 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       final boolean allowLazyPersist) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist);\n \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           // Do not propagate allowLazyPersist to downstream DataNodes.\n           new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy, false);\n \n           mirrorOut.flush();\n \n           DataNodeFaultInjector.get().writeBlockAfterFlush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n-            datanode.metrics.incrDatanodeNetworkErrors();\n+            incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n-      datanode.metrics.incrDatanodeNetworkErrors();\n+      incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      final boolean allowLazyPersist) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist);\n\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          // Do not propagate allowLazyPersist to downstream DataNodes.\n          new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy, false);\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "86cad007d7d6366b293bb9a073814889081c8662": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7222. Expose DataNode network errors as a metric. (Charles Lamb via wang)\n",
      "commitDate": "23/10/14 12:53 PM",
      "commitName": "86cad007d7d6366b293bb9a073814889081c8662",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "27/08/14 9:47 PM",
      "commitNameOld": "a317bd7b02c37bd57743bfad59593ec12f53f4ed",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 56.63,
      "commitsBetweenForRepo": 574,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,233 +1,237 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       final boolean allowLazyPersist) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy, allowLazyPersist);\n \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           // Do not propagate allowLazyPersist to downstream DataNodes.\n           new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy, false);\n \n           mirrorOut.flush();\n \n+          DataNodeFaultInjector.get().writeBlockAfterFlush();\n+\n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n+            datanode.metrics.incrDatanodeNetworkErrors();\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n+      datanode.metrics.incrDatanodeNetworkErrors();\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      final boolean allowLazyPersist) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist);\n\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          // Do not propagate allowLazyPersist to downstream DataNodes.\n          new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy, false);\n\n          mirrorOut.flush();\n\n          DataNodeFaultInjector.get().writeBlockAfterFlush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n            datanode.metrics.incrDatanodeNetworkErrors();\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      datanode.metrics.incrDatanodeNetworkErrors();\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "a317bd7b02c37bd57743bfad59593ec12f53f4ed": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6925. DataNode should attempt to place replicas on transient storage first if lazyPersist flag is received. (Arpit Agarwal)\n",
      "commitDate": "27/08/14 9:47 PM",
      "commitName": "a317bd7b02c37bd57743bfad59593ec12f53f4ed",
      "commitAuthor": "arp",
      "commitDateOld": "27/08/14 9:47 PM",
      "commitNameOld": "c2354a7f81ff5a48a5b65d25e1036d3e0ba86420",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,233 +1,233 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy,\n       final boolean allowLazyPersist) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n-            cachingStrategy);\n-        \n+            cachingStrategy, allowLazyPersist);\n+\n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           // Do not propagate allowLazyPersist to downstream DataNodes.\n           new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy, false);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      final boolean allowLazyPersist) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy, allowLazyPersist);\n\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          // Do not propagate allowLazyPersist to downstream DataNodes.\n          new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy, false);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "c2354a7f81ff5a48a5b65d25e1036d3e0ba86420": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6923. Propagate LazyPersist flag to DNs via DataTransferProtocol. (Arpit Agarwal)\n",
      "commitDate": "27/08/14 9:47 PM",
      "commitName": "c2354a7f81ff5a48a5b65d25e1036d3e0ba86420",
      "commitAuthor": "arp",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6923. Propagate LazyPersist flag to DNs via DataTransferProtocol. (Arpit Agarwal)\n",
          "commitDate": "27/08/14 9:47 PM",
          "commitName": "c2354a7f81ff5a48a5b65d25e1036d3e0ba86420",
          "commitAuthor": "arp",
          "commitDateOld": "20/08/14 6:13 PM",
          "commitNameOld": "6824abc19e12ed142d9f32b8706ef73d97edd1cc",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 7.15,
          "commitsBetweenForRepo": 41,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,231 +1,233 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n-      CachingStrategy cachingStrategy) throws IOException {\n+      CachingStrategy cachingStrategy,\n+      final boolean allowLazyPersist) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy);\n         \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n+          // Do not propagate allowLazyPersist to downstream DataNodes.\n           new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n-              latestGenerationStamp, requestedChecksum, cachingStrategy);\n+              latestGenerationStamp, requestedChecksum, cachingStrategy, false);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      final boolean allowLazyPersist) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy);\n        \n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          // Do not propagate allowLazyPersist to downstream DataNodes.\n          new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy, false);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {
            "oldValue": "[block-ExtendedBlock(modifiers-final), storageType-StorageType(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientname-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), targetStorageTypes-StorageType[](modifiers-final), srcDataNode-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final), requestedChecksum-DataChecksum, cachingStrategy-CachingStrategy]",
            "newValue": "[block-ExtendedBlock(modifiers-final), storageType-StorageType(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientname-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), targetStorageTypes-StorageType[](modifiers-final), srcDataNode-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final), requestedChecksum-DataChecksum, cachingStrategy-CachingStrategy, allowLazyPersist-boolean(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6923. Propagate LazyPersist flag to DNs via DataTransferProtocol. (Arpit Agarwal)\n",
          "commitDate": "27/08/14 9:47 PM",
          "commitName": "c2354a7f81ff5a48a5b65d25e1036d3e0ba86420",
          "commitAuthor": "arp",
          "commitDateOld": "20/08/14 6:13 PM",
          "commitNameOld": "6824abc19e12ed142d9f32b8706ef73d97edd1cc",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 7.15,
          "commitsBetweenForRepo": 41,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,231 +1,233 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n-      CachingStrategy cachingStrategy) throws IOException {\n+      CachingStrategy cachingStrategy,\n+      final boolean allowLazyPersist) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     if (block.getNumBytes() \u003d\u003d 0) {\n       block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy);\n         \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n+          // Do not propagate allowLazyPersist to downstream DataNodes.\n           new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n-              latestGenerationStamp, requestedChecksum, cachingStrategy);\n+              latestGenerationStamp, requestedChecksum, cachingStrategy, false);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy,\n      final boolean allowLazyPersist) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy);\n        \n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          // Do not propagate allowLazyPersist to downstream DataNodes.\n          new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy, false);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {}
        }
      ]
    },
    "6824abc19e12ed142d9f32b8706ef73d97edd1cc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6758. Block writer should pass the expected block size to DataXceiverServer (Arpit Agarwal)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1619275 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/08/14 6:13 PM",
      "commitName": "6824abc19e12ed142d9f32b8706ef73d97edd1cc",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "18/08/14 2:23 PM",
      "commitNameOld": "2fb04d2a30919bde350f566a39faa7085f1a1d7b",
      "commitAuthorOld": "Brandon Li",
      "daysBetweenCommits": 2.16,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,229 +1,231 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n-    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n+    if (block.getNumBytes() \u003d\u003d 0) {\n+      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n+    }\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy);\n         \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n       blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    if (block.getNumBytes() \u003d\u003d 0) {\n      block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    }\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy);\n        \n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "2fb04d2a30919bde350f566a39faa7085f1a1d7b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6569. OOB message can\u0027t be sent to the client when DataNode shuts down for upgrade. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1618742 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/14 2:23 PM",
      "commitName": "2fb04d2a30919bde350f566a39faa7085f1a1d7b",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "13/08/14 11:43 AM",
      "commitNameOld": "195961a7c1da86421761162836766b1de07930fd",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 5.11,
      "commitsBetweenForRepo": 56,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,229 +1,229 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n-    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy);\n         \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n+      blockReceiver \u003d null;\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy);\n        \n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n      blockReceiver \u003d null;\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "195961a7c1da86421761162836766b1de07930fd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6247. Avoid timeouts for replaceBlock() call by sending intermediate responses to Balancer (vinayakumarb)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1617799 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/08/14 11:43 AM",
      "commitName": "195961a7c1da86421761162836766b1de07930fd",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "13/08/14 11:36 AM",
      "commitNameOld": "6554994fab2d8a2a139fb71ed54be144f4057e08",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,229 +1,229 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy);\n         \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n-            mirrorAddr, null, targets);\n+            mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy);\n        \n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "6554994fab2d8a2a139fb71ed54be144f4057e08": {
      "type": "Ybodychange",
      "commitMessage": "Reverted\nMerged revision(s) 1617784 from hadoop/common/trunk:\nHDFS-6847. Avoid timeouts for replaceBlock() call by sending intermediate responses to Balancer (Contributed by Vinayakumar B.)\n........\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1617794 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/08/14 11:36 AM",
      "commitName": "6554994fab2d8a2a139fb71ed54be144f4057e08",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "13/08/14 11:06 AM",
      "commitNameOld": "471b1368e2a81b4d9850f0f4d98d31df1451354c",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,229 +1,229 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy);\n         \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n-            mirrorAddr, null, targets, false);\n+            mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy);\n        \n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "471b1368e2a81b4d9850f0f4d98d31df1451354c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6847. Avoid timeouts for replaceBlock() call by sending intermediate responses to Balancer (Contributed by Vinayakumar B.)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1617784 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/08/14 11:06 AM",
      "commitName": "471b1368e2a81b4d9850f0f4d98d31df1451354c",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "22/07/14 12:41 AM",
      "commitNameOld": "25b0e8471ed744578b2d8e3f0debe5477b268e54",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 22.43,
      "commitsBetweenForRepo": 167,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,229 +1,229 @@\n   public void writeBlock(final ExtendedBlock block,\n       final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy);\n         \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n               blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n               stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n               latestGenerationStamp, requestedChecksum, cachingStrategy);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n-            mirrorAddr, null, targets);\n+            mirrorAddr, null, targets, false);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy);\n        \n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets, false);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "25b0e8471ed744578b2d8e3f0debe5477b268e54": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6702. Change DFSClient to pass the StorageType from the namenode to datanodes and change datanode to write block replicas using the specified storage type.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1612493 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/07/14 12:41 AM",
      "commitName": "25b0e8471ed744578b2d8e3f0debe5477b268e54",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6702. Change DFSClient to pass the StorageType from the namenode to datanodes and change datanode to write block replicas using the specified storage type.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1612493 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/07/14 12:41 AM",
          "commitName": "25b0e8471ed744578b2d8e3f0debe5477b268e54",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "14/07/14 11:10 AM",
          "commitNameOld": "3b54223c0f32d42a84436c670d80b791a8e9696d",
          "commitAuthorOld": "Chris Nauroth",
          "daysBetweenCommits": 7.56,
          "commitsBetweenForRepo": 68,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,226 +1,229 @@\n   public void writeBlock(final ExtendedBlock block,\n+      final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n+      final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n-        blockReceiver \u003d new BlockReceiver(block, in, \n+        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy);\n+        \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n-          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n-              clientname, targets, srcDataNode, stage, pipelineSize,\n-              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum,\n-              cachingStrategy);\n+          new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n+              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n+              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n+              latestGenerationStamp, requestedChecksum, cachingStrategy);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy);\n        \n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {
            "oldValue": "[block-ExtendedBlock(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientname-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), srcDataNode-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final), requestedChecksum-DataChecksum, cachingStrategy-CachingStrategy]",
            "newValue": "[block-ExtendedBlock(modifiers-final), storageType-StorageType(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientname-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), targetStorageTypes-StorageType[](modifiers-final), srcDataNode-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final), requestedChecksum-DataChecksum, cachingStrategy-CachingStrategy]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6702. Change DFSClient to pass the StorageType from the namenode to datanodes and change datanode to write block replicas using the specified storage type.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1612493 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/07/14 12:41 AM",
          "commitName": "25b0e8471ed744578b2d8e3f0debe5477b268e54",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "14/07/14 11:10 AM",
          "commitNameOld": "3b54223c0f32d42a84436c670d80b791a8e9696d",
          "commitAuthorOld": "Chris Nauroth",
          "daysBetweenCommits": 7.56,
          "commitsBetweenForRepo": 68,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,226 +1,229 @@\n   public void writeBlock(final ExtendedBlock block,\n+      final StorageType storageType, \n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n+      final StorageType[] targetStorageTypes, \n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n-        blockReceiver \u003d new BlockReceiver(block, in, \n+        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy);\n+        \n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           DataEncryptionKeyFactory keyFactory \u003d\n             datanode.getDataEncryptionKeyFactoryForBlock(block);\n           IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n             unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n           unbufMirrorOut \u003d saslStreams.out;\n           unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n-          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n-              clientname, targets, srcDataNode, stage, pipelineSize,\n-              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum,\n-              cachingStrategy);\n+          new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n+              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n+              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n+              latestGenerationStamp, requestedChecksum, cachingStrategy);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final StorageType storageType, \n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final StorageType[] targetStorageTypes, \n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, storageType, in,\n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy);\n        \n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[0],\n              blockToken, clientname, targets, targetStorageTypes, srcDataNode,\n              stage, pipelineSize, minBytesRcvd, maxBytesRcvd,\n              latestGenerationStamp, requestedChecksum, cachingStrategy);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {}
        }
      ]
    },
    "3b54223c0f32d42a84436c670d80b791a8e9696d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2856. Fix block protocol so that Datanodes don\u0027t require root or jsvc. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1610474 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/07/14 11:10 AM",
      "commitName": "3b54223c0f32d42a84436c670d80b791a8e9696d",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "22/05/14 11:17 AM",
      "commitNameOld": "3671a5e16fbddbe5a0516289ce98e1305e02291c",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 53.0,
      "commitsBetweenForRepo": 313,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,231 +1,226 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy);\n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n-          if (dnConf.encryptDataTransfer \u0026\u0026\n-              !dnConf.trustedChannelResolver.isTrusted(mirrorSock.getInetAddress())) {\n-            IOStreamPair encryptedStreams \u003d\n-                DataTransferEncryptor.getEncryptedStreams(\n-                    unbufMirrorOut, unbufMirrorIn,\n-                    datanode.blockPoolTokenSecretManager\n-                        .generateDataEncryptionKey(block.getBlockPoolId()));\n-            \n-            unbufMirrorOut \u003d encryptedStreams.out;\n-            unbufMirrorIn \u003d encryptedStreams.in;\n-          }\n+          DataEncryptionKeyFactory keyFactory \u003d\n+            datanode.getDataEncryptionKeyFactoryForBlock(block);\n+          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n+            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n+          unbufMirrorOut \u003d saslStreams.out;\n+          unbufMirrorIn \u003d saslStreams.in;\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum,\n               cachingStrategy);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy);\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          DataEncryptionKeyFactory keyFactory \u003d\n            datanode.getDataEncryptionKeyFactoryForBlock(block);\n          IOStreamPair saslStreams \u003d datanode.saslClient.socketSend(mirrorSock,\n            unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[0]);\n          unbufMirrorOut \u003d saslStreams.out;\n          unbufMirrorIn \u003d saslStreams.in;\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum,\n              cachingStrategy);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "1fbb04e367d7c330e6052207f9f11911f4f5f368": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5910. Enhance DataTransferProtocol to allow per-connection choice of encryption/plain-text. (Contributed by Benoy Antony)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1581688 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/03/14 9:11 PM",
      "commitName": "1fbb04e367d7c330e6052207f9f11911f4f5f368",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "19/03/14 2:04 PM",
      "commitNameOld": "cfb468332e482a51f0a8aea61da4fe5245419a89",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 6.3,
      "commitsBetweenForRepo": 55,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,230 +1,231 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy);\n         storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n         storageUuid \u003d datanode.data.recoverClose(\n             block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n-          if (dnConf.encryptDataTransfer) {\n+          if (dnConf.encryptDataTransfer \u0026\u0026\n+              !dnConf.trustedChannelResolver.isTrusted(mirrorSock.getInetAddress())) {\n             IOStreamPair encryptedStreams \u003d\n                 DataTransferEncryptor.getEncryptedStreams(\n                     unbufMirrorOut, unbufMirrorIn,\n                     datanode.blockPoolTokenSecretManager\n                         .generateDataEncryptionKey(block.getBlockPoolId()));\n             \n             unbufMirrorOut \u003d encryptedStreams.out;\n             unbufMirrorIn \u003d encryptedStreams.in;\n           }\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum,\n               cachingStrategy);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy);\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          if (dnConf.encryptDataTransfer \u0026\u0026\n              !dnConf.trustedChannelResolver.isTrusted(mirrorSock.getInetAddress())) {\n            IOStreamPair encryptedStreams \u003d\n                DataTransferEncryptor.getEncryptedStreams(\n                    unbufMirrorOut, unbufMirrorIn,\n                    datanode.blockPoolTokenSecretManager\n                        .generateDataEncryptionKey(block.getBlockPoolId()));\n            \n            unbufMirrorOut \u003d encryptedStreams.out;\n            unbufMirrorIn \u003d encryptedStreams.in;\n          }\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum,\n              cachingStrategy);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "97acde2d33967f7f870f7dfe96c6b558e6fe324b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5542. Fix TODO and clean up the code in HDFS-2832. (Contributed by szetszwo)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1544664 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/11/13 12:07 PM",
      "commitName": "97acde2d33967f7f870f7dfe96c6b558e6fe324b",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "10/11/13 12:59 PM",
      "commitNameOld": "907fb15ee8c150e5ecc0560b7374441c57a84122",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 11.96,
      "commitsBetweenForRepo": 102,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,231 +1,230 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n-    Replica replica;\n+    final String storageUuid;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy);\n-        replica \u003d blockReceiver.getReplicaInfo();\n+        storageUuid \u003d blockReceiver.getStorageUuid();\n       } else {\n-        replica \u003d\n-            datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n+        storageUuid \u003d datanode.data.recoverClose(\n+            block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           if (dnConf.encryptDataTransfer) {\n             IOStreamPair encryptedStreams \u003d\n                 DataTransferEncryptor.getEncryptedStreams(\n                     unbufMirrorOut, unbufMirrorIn,\n                     datanode.blockPoolTokenSecretManager\n                         .generateDataEncryptionKey(block.getBlockPoolId()));\n             \n             unbufMirrorOut \u003d encryptedStreams.out;\n             unbufMirrorIn \u003d encryptedStreams.in;\n           }\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum,\n               cachingStrategy);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n-        datanode.closeBlock(\n-            block, DataNode.EMPTY_DEL_HINT, replica.getStorageUuid());\n+        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    final String storageUuid;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy);\n        storageUuid \u003d blockReceiver.getStorageUuid();\n      } else {\n        storageUuid \u003d datanode.data.recoverClose(\n            block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          if (dnConf.encryptDataTransfer) {\n            IOStreamPair encryptedStreams \u003d\n                DataTransferEncryptor.getEncryptedStreams(\n                    unbufMirrorOut, unbufMirrorIn,\n                    datanode.blockPoolTokenSecretManager\n                        .generateDataEncryptionKey(block.getBlockPoolId()));\n            \n            unbufMirrorOut \u003d encryptedStreams.out;\n            unbufMirrorIn \u003d encryptedStreams.in;\n          }\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum,\n              cachingStrategy);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "01f37e42f050207b7659bf74e2484cf8bdae2d89": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5390. Send one incremental block report per storage directory.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1534891 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/10/13 6:28 PM",
      "commitName": "01f37e42f050207b7659bf74e2484cf8bdae2d89",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "22/09/13 11:03 AM",
      "commitNameOld": "4551da302d94cffea0313eac79479ab6f9b7cb34",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 30.31,
      "commitsBetweenForRepo": 225,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,227 +1,231 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum,\n       CachingStrategy cachingStrategy) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n+    Replica replica;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum,\n             cachingStrategy);\n+        replica \u003d blockReceiver.getReplicaInfo();\n       } else {\n-        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n+        replica \u003d\n+            datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           if (dnConf.encryptDataTransfer) {\n             IOStreamPair encryptedStreams \u003d\n                 DataTransferEncryptor.getEncryptedStreams(\n                     unbufMirrorOut, unbufMirrorIn,\n                     datanode.blockPoolTokenSecretManager\n                         .generateDataEncryptionKey(block.getBlockPoolId()));\n             \n             unbufMirrorOut \u003d encryptedStreams.out;\n             unbufMirrorIn \u003d encryptedStreams.in;\n           }\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum,\n               cachingStrategy);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n-        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n+        datanode.closeBlock(\n+            block, DataNode.EMPTY_DEL_HINT, replica.getStorageUuid());\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    Replica replica;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy);\n        replica \u003d blockReceiver.getReplicaInfo();\n      } else {\n        replica \u003d\n            datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          if (dnConf.encryptDataTransfer) {\n            IOStreamPair encryptedStreams \u003d\n                DataTransferEncryptor.getEncryptedStreams(\n                    unbufMirrorOut, unbufMirrorIn,\n                    datanode.blockPoolTokenSecretManager\n                        .generateDataEncryptionKey(block.getBlockPoolId()));\n            \n            unbufMirrorOut \u003d encryptedStreams.out;\n            unbufMirrorIn \u003d encryptedStreams.in;\n          }\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum,\n              cachingStrategy);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(\n            block, DataNode.EMPTY_DEL_HINT, replica.getStorageUuid());\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "c1314eb2a382bd9ce045a2fcc4a9e5c1fc368a24": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-4817.  Make HDFS advisory caching configurable on a per-file basis.  (Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1505753 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/07/13 11:15 AM",
      "commitName": "c1314eb2a382bd9ce045a2fcc4a9e5c1fc368a24",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4817.  Make HDFS advisory caching configurable on a per-file basis.  (Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1505753 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/07/13 11:15 AM",
          "commitName": "c1314eb2a382bd9ce045a2fcc4a9e5c1fc368a24",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "09/05/13 5:03 PM",
          "commitNameOld": "a18fd620d070cf8e84aaf80d93807ac9ee207a0f",
          "commitAuthorOld": "Aaron Myers",
          "daysBetweenCommits": 73.76,
          "commitsBetweenForRepo": 437,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,224 +1,227 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n-      DataChecksum requestedChecksum) throws IOException {\n+      DataChecksum requestedChecksum,\n+      CachingStrategy cachingStrategy) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n-            clientname, srcDataNode, datanode, requestedChecksum);\n+            clientname, srcDataNode, datanode, requestedChecksum,\n+            cachingStrategy);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           if (dnConf.encryptDataTransfer) {\n             IOStreamPair encryptedStreams \u003d\n                 DataTransferEncryptor.getEncryptedStreams(\n                     unbufMirrorOut, unbufMirrorIn,\n                     datanode.blockPoolTokenSecretManager\n                         .generateDataEncryptionKey(block.getBlockPoolId()));\n             \n             unbufMirrorOut \u003d encryptedStreams.out;\n             unbufMirrorIn \u003d encryptedStreams.in;\n           }\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n-              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n+              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum,\n+              cachingStrategy);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          if (dnConf.encryptDataTransfer) {\n            IOStreamPair encryptedStreams \u003d\n                DataTransferEncryptor.getEncryptedStreams(\n                    unbufMirrorOut, unbufMirrorIn,\n                    datanode.blockPoolTokenSecretManager\n                        .generateDataEncryptionKey(block.getBlockPoolId()));\n            \n            unbufMirrorOut \u003d encryptedStreams.out;\n            unbufMirrorIn \u003d encryptedStreams.in;\n          }\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum,\n              cachingStrategy);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {
            "oldValue": "[block-ExtendedBlock(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientname-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), srcDataNode-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final), requestedChecksum-DataChecksum]",
            "newValue": "[block-ExtendedBlock(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientname-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), srcDataNode-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final), requestedChecksum-DataChecksum, cachingStrategy-CachingStrategy]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4817.  Make HDFS advisory caching configurable on a per-file basis.  (Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1505753 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/07/13 11:15 AM",
          "commitName": "c1314eb2a382bd9ce045a2fcc4a9e5c1fc368a24",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "09/05/13 5:03 PM",
          "commitNameOld": "a18fd620d070cf8e84aaf80d93807ac9ee207a0f",
          "commitAuthorOld": "Aaron Myers",
          "daysBetweenCommits": 73.76,
          "commitsBetweenForRepo": 437,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,224 +1,227 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n-      DataChecksum requestedChecksum) throws IOException {\n+      DataChecksum requestedChecksum,\n+      CachingStrategy cachingStrategy) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                 \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             peer.getRemoteAddressString(),\n             peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n-            clientname, srcDataNode, datanode, requestedChecksum);\n+            clientname, srcDataNode, datanode, requestedChecksum,\n+            cachingStrategy);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           if (dnConf.encryptDataTransfer) {\n             IOStreamPair encryptedStreams \u003d\n                 DataTransferEncryptor.getEncryptedStreams(\n                     unbufMirrorOut, unbufMirrorIn,\n                     datanode.blockPoolTokenSecretManager\n                         .generateDataEncryptionKey(block.getBlockPoolId()));\n             \n             unbufMirrorOut \u003d encryptedStreams.out;\n             unbufMirrorIn \u003d encryptedStreams.in;\n           }\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n-              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n+              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum,\n+              cachingStrategy);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum,\n      CachingStrategy cachingStrategy) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum,\n            cachingStrategy);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          if (dnConf.encryptDataTransfer) {\n            IOStreamPair encryptedStreams \u003d\n                DataTransferEncryptor.getEncryptedStreams(\n                    unbufMirrorOut, unbufMirrorIn,\n                    datanode.blockPoolTokenSecretManager\n                        .generateDataEncryptionKey(block.getBlockPoolId()));\n            \n            unbufMirrorOut \u003d encryptedStreams.out;\n            unbufMirrorIn \u003d encryptedStreams.in;\n          }\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum,\n              cachingStrategy);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {}
        }
      ]
    },
    "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4353. Encapsulate connections to peers in Peer and PeerServer classes. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1431097 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/13 1:34 PM",
      "commitName": "c9db06f2e4d1c1f71f021d5070323f9fc194cdd7",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "08/01/13 6:39 PM",
      "commitNameOld": "837e17b2eac1471d93e2eff395272063b265fee7",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.79,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,224 +1,224 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n-      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n-                \" tcp no delay \" + s.getTcpNoDelay());\n+      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n+                \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n-            s.getRemoteSocketAddress().toString(),\n-            s.getLocalSocketAddress().toString(),\n+            peer.getRemoteAddressString(),\n+            peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           if (dnConf.encryptDataTransfer) {\n             IOStreamPair encryptedStreams \u003d\n                 DataTransferEncryptor.getEncryptedStreams(\n                     unbufMirrorOut, unbufMirrorIn,\n                     datanode.blockPoolTokenSecretManager\n                         .generateDataEncryptionKey(block.getBlockPoolId()));\n             \n             unbufMirrorOut \u003d encryptedStreams.out;\n             unbufMirrorIn \u003d encryptedStreams.in;\n           }\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n-    datanode.metrics.incrWritesFromClient(isLocal);\n+    datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          if (dnConf.encryptDataTransfer) {\n            IOStreamPair encryptedStreams \u003d\n                DataTransferEncryptor.getEncryptedStreams(\n                    unbufMirrorOut, unbufMirrorIn,\n                    datanode.blockPoolTokenSecretManager\n                        .generateDataEncryptionKey(block.getBlockPoolId()));\n            \n            unbufMirrorOut \u003d encryptedStreams.out;\n            unbufMirrorIn \u003d encryptedStreams.in;\n          }\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "3cd17b614e9436d06cd9b4ccc5f9cf59fbe1cf21": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4363. Combine PBHelper and HdfsProtoUtil and remove redundant methods. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1431088 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/13 1:20 PM",
      "commitName": "3cd17b614e9436d06cd9b4ccc5f9cf59fbe1cf21",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "08/01/13 6:39 PM",
      "commitNameOld": "837e17b2eac1471d93e2eff395272063b265fee7",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.78,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,224 +1,224 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           if (dnConf.encryptDataTransfer) {\n             IOStreamPair encryptedStreams \u003d\n                 DataTransferEncryptor.getEncryptedStreams(\n                     unbufMirrorOut, unbufMirrorIn,\n                     datanode.blockPoolTokenSecretManager\n                         .generateDataEncryptionKey(block.getBlockPoolId()));\n             \n             unbufMirrorOut \u003d encryptedStreams.out;\n             unbufMirrorIn \u003d encryptedStreams.in;\n           }\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n-              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n+              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          if (dnConf.encryptDataTransfer) {\n            IOStreamPair encryptedStreams \u003d\n                DataTransferEncryptor.getEncryptedStreams(\n                    unbufMirrorOut, unbufMirrorIn,\n                    datanode.blockPoolTokenSecretManager\n                        .generateDataEncryptionKey(block.getBlockPoolId()));\n            \n            unbufMirrorOut \u003d encryptedStreams.out;\n            unbufMirrorIn \u003d encryptedStreams.in;\n          }\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "837e17b2eac1471d93e2eff395272063b265fee7": {
      "type": "Ybodychange",
      "commitMessage": "svn merge -c -1430507 . for reverting HDFS-4353. Encapsulate connections to peers in Peer and PeerServer classes\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1430662 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/01/13 6:39 PM",
      "commitName": "837e17b2eac1471d93e2eff395272063b265fee7",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "08/01/13 12:44 PM",
      "commitNameOld": "239b2742d0e80d13c970fd062af4930e672fe903",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.25,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,224 +1,224 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n-      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n-                \" tcp no delay \" + peer.getTcpNoDelay());\n+      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n+                \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n-            peer.getRemoteAddressString(),\n-            peer.getLocalAddressString(),\n+            s.getRemoteSocketAddress().toString(),\n+            s.getLocalSocketAddress().toString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           if (dnConf.encryptDataTransfer) {\n             IOStreamPair encryptedStreams \u003d\n                 DataTransferEncryptor.getEncryptedStreams(\n                     unbufMirrorOut, unbufMirrorIn,\n                     datanode.blockPoolTokenSecretManager\n                         .generateDataEncryptionKey(block.getBlockPoolId()));\n             \n             unbufMirrorOut \u003d encryptedStreams.out;\n             unbufMirrorIn \u003d encryptedStreams.in;\n           }\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n-    datanode.metrics.incrWritesFromClient(peer.isLocal());\n+    datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          if (dnConf.encryptDataTransfer) {\n            IOStreamPair encryptedStreams \u003d\n                DataTransferEncryptor.getEncryptedStreams(\n                    unbufMirrorOut, unbufMirrorIn,\n                    datanode.blockPoolTokenSecretManager\n                        .generateDataEncryptionKey(block.getBlockPoolId()));\n            \n            unbufMirrorOut \u003d encryptedStreams.out;\n            unbufMirrorIn \u003d encryptedStreams.in;\n          }\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "239b2742d0e80d13c970fd062af4930e672fe903": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4353. Encapsulate connections to peers in Peer and PeerServer classes. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1430507 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/01/13 12:44 PM",
      "commitName": "239b2742d0e80d13c970fd062af4930e672fe903",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "28/10/12 4:10 PM",
      "commitNameOld": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 71.9,
      "commitsBetweenForRepo": 300,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,224 +1,224 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n-      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n-                \" tcp no delay \" + s.getTcpNoDelay());\n+      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n+                \" tcp no delay \" + peer.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n         + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n-            s.getRemoteSocketAddress().toString(),\n-            s.getLocalSocketAddress().toString(),\n+            peer.getRemoteAddressString(),\n+            peer.getLocalAddressString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           if (dnConf.encryptDataTransfer) {\n             IOStreamPair encryptedStreams \u003d\n                 DataTransferEncryptor.getEncryptedStreams(\n                     unbufMirrorOut, unbufMirrorIn,\n                     datanode.blockPoolTokenSecretManager\n                         .generateDataEncryptionKey(block.getBlockPoolId()));\n             \n             unbufMirrorOut \u003d encryptedStreams.out;\n             unbufMirrorIn \u003d encryptedStreams.in;\n           }\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n             + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n-    datanode.metrics.incrWritesFromClient(isLocal);\n+    datanode.metrics.incrWritesFromClient(peer.isLocal());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + peer.getReceiveBufferSize() +\n                \" tcp no delay \" + peer.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            peer.getRemoteAddressString(),\n            peer.getLocalAddressString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          if (dnConf.encryptDataTransfer) {\n            IOStreamPair encryptedStreams \u003d\n                DataTransferEncryptor.getEncryptedStreams(\n                    unbufMirrorOut, unbufMirrorIn,\n                    datanode.blockPoolTokenSecretManager\n                        .generateDataEncryptionKey(block.getBlockPoolId()));\n            \n            unbufMirrorOut \u003d encryptedStreams.out;\n            unbufMirrorIn \u003d encryptedStreams.in;\n          }\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(peer.isLocal());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4122. Cleanup HDFS logs and reduce the size of logged messages. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1403120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/10/12 4:10 PM",
      "commitName": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "24/08/12 7:15 AM",
      "commitNameOld": "c46de830da98959f40dd41c95bdebecdfb9ea730",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 65.37,
      "commitsBetweenForRepo": 392,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,227 +1,224 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n-    LOG.info(\"Receiving block \" + block + \n-             \" src: \" + remoteAddress +\n-             \" dest: \" + localAddress);\n+    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n+        + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Connecting to datanode \" + mirrorNode);\n         }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           if (dnConf.encryptDataTransfer) {\n             IOStreamPair encryptedStreams \u003d\n                 DataTransferEncryptor.getEncryptedStreams(\n                     unbufMirrorOut, unbufMirrorIn,\n                     datanode.blockPoolTokenSecretManager\n                         .generateDataEncryptionKey(block.getBlockPoolId()));\n             \n             unbufMirrorOut \u003d encryptedStreams.out;\n             unbufMirrorIn \u003d encryptedStreams.in;\n           }\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n                // NB: Unconditionally using the xfer addr w/o hostname\n               .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n-            LOG.info(datanode + \":Exception transfering block \" +\n+            LOG.info(datanode + \":Exception transfering \" +\n                      block + \" to mirror \" + mirrorNode +\n-                     \". continuing without the mirror.\", e);\n+                     \"- continuing without the mirror\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n-        LOG.info(\"Received block \" + block + \n-                 \" src: \" + remoteAddress +\n-                 \" dest: \" + localAddress +\n-                 \" of size \" + block.getNumBytes());\n+        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n+            + localAddress + \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving \" + block + \" src: \" + remoteAddress + \" dest: \"\n        + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          if (dnConf.encryptDataTransfer) {\n            IOStreamPair encryptedStreams \u003d\n                DataTransferEncryptor.getEncryptedStreams(\n                    unbufMirrorOut, unbufMirrorIn,\n                    datanode.blockPoolTokenSecretManager\n                        .generateDataEncryptionKey(block.getBlockPoolId()));\n            \n            unbufMirrorOut \u003d encryptedStreams.out;\n            unbufMirrorIn \u003d encryptedStreams.in;\n          }\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \"- continuing without the mirror\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received \" + block + \" src: \" + remoteAddress + \" dest: \"\n            + localAddress + \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "f98d8eb291be364102b5c3011ce72e8f43eab389": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3150. Add option for clients to contact DNs via hostname. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1373094 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/08/12 1:59 PM",
      "commitName": "f98d8eb291be364102b5c3011ce72e8f43eab389",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "07/08/12 9:40 AM",
      "commitNameOld": "9b4a7900c7dfc0590316eedaa97144f938885651",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 7.18,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,223 +1,227 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving block \" + block + \n              \" src: \" + remoteAddress +\n              \" dest: \" + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n-        mirrorNode \u003d targets[0].getXferAddr();\n+        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n+        }\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           \n           OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n               writeTimeout);\n           InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n           if (dnConf.encryptDataTransfer) {\n             IOStreamPair encryptedStreams \u003d\n                 DataTransferEncryptor.getEncryptedStreams(\n                     unbufMirrorOut, unbufMirrorIn,\n                     datanode.blockPoolTokenSecretManager\n                         .generateDataEncryptionKey(block.getBlockPoolId()));\n             \n             unbufMirrorOut \u003d encryptedStreams.out;\n             unbufMirrorIn \u003d encryptedStreams.in;\n           }\n           mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n               HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n-              .setFirstBadLink(mirrorNode)\n+               // NB: Unconditionally using the xfer addr w/o hostname\n+              .setFirstBadLink(targets[0].getXferAddr())\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \". continuing without the mirror.\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received block \" + block + \n                  \" src: \" + remoteAddress +\n                  \" dest: \" + localAddress +\n                  \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr(connectToDnViaHostname);\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to datanode \" + mirrorNode);\n        }\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          if (dnConf.encryptDataTransfer) {\n            IOStreamPair encryptedStreams \u003d\n                DataTransferEncryptor.getEncryptedStreams(\n                    unbufMirrorOut, unbufMirrorIn,\n                    datanode.blockPoolTokenSecretManager\n                        .generateDataEncryptionKey(block.getBlockPoolId()));\n            \n            unbufMirrorOut \u003d encryptedStreams.out;\n            unbufMirrorIn \u003d encryptedStreams.in;\n          }\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n               // NB: Unconditionally using the xfer addr w/o hostname\n              .setFirstBadLink(targets[0].getXferAddr())\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "9b4a7900c7dfc0590316eedaa97144f938885651": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3637. Add support for encrypting the DataTransferProtocol. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370354 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/12 9:40 AM",
      "commitName": "9b4a7900c7dfc0590316eedaa97144f938885651",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "15/07/12 7:58 PM",
      "commitNameOld": "0e8e499ff482c165d21c8e4f5ff9c33f306ca0d9",
      "commitAuthorOld": "Harsh J",
      "daysBetweenCommits": 22.57,
      "commitsBetweenForRepo": 106,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,211 +1,223 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum) throws IOException {\n     previousOpClientName \u003d clientname;\n     updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving block \" + block + \n              \" src: \" + remoteAddress +\n              \" dest: \" + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n-            NetUtils.getOutputStream(s, dnConf.socketWriteTimeout),\n+            getOutputStream(),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr();\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n-          mirrorOut \u003d new DataOutputStream(\n-             new BufferedOutputStream(\n-                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n-                         HdfsConstants.SMALL_BUFFER_SIZE));\n-          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n+          \n+          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n+              writeTimeout);\n+          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n+          if (dnConf.encryptDataTransfer) {\n+            IOStreamPair encryptedStreams \u003d\n+                DataTransferEncryptor.getEncryptedStreams(\n+                    unbufMirrorOut, unbufMirrorIn,\n+                    datanode.blockPoolTokenSecretManager\n+                        .generateDataEncryptionKey(block.getBlockPoolId()));\n+            \n+            unbufMirrorOut \u003d encryptedStreams.out;\n+            unbufMirrorIn \u003d encryptedStreams.in;\n+          }\n+          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n+              HdfsConstants.SMALL_BUFFER_SIZE));\n+          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n               .setFirstBadLink(mirrorNode)\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \". continuing without the mirror.\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received block \" + block + \n                  \" src: \" + remoteAddress +\n                  \" dest: \" + localAddress +\n                  \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            getOutputStream(),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          \n          OutputStream unbufMirrorOut \u003d NetUtils.getOutputStream(mirrorSock,\n              writeTimeout);\n          InputStream unbufMirrorIn \u003d NetUtils.getInputStream(mirrorSock);\n          if (dnConf.encryptDataTransfer) {\n            IOStreamPair encryptedStreams \u003d\n                DataTransferEncryptor.getEncryptedStreams(\n                    unbufMirrorOut, unbufMirrorIn,\n                    datanode.blockPoolTokenSecretManager\n                        .generateDataEncryptionKey(block.getBlockPoolId()));\n            \n            unbufMirrorOut \u003d encryptedStreams.out;\n            unbufMirrorIn \u003d encryptedStreams.in;\n          }\n          mirrorOut \u003d new DataOutputStream(new BufferedOutputStream(unbufMirrorOut,\n              HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(unbufMirrorIn);\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "7aa2889f822a970b8b1edb8bc58aab67412877ae": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3375. Put client name in DataXceiver thread name for readBlock and keepalive. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1335270 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/05/12 2:34 PM",
      "commitName": "7aa2889f822a970b8b1edb8bc58aab67412877ae",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "04/05/12 11:50 AM",
      "commitNameOld": "a701c792f880c43ba807f00a92a99dadf89eab0c",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 3.11,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,210 +1,211 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum) throws IOException {\n-    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n+    previousOpClientName \u003d clientname;\n+    updateCurrentThreadName(\"Receiving block \" + block);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving block \" + block + \n              \" src: \" + remoteAddress +\n              \" dest: \" + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             NetUtils.getOutputStream(s, dnConf.socketWriteTimeout),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getXferAddr();\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           mirrorOut \u003d new DataOutputStream(\n              new BufferedOutputStream(\n                          NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                          HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n               .setFirstBadLink(mirrorNode)\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \". continuing without the mirror.\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received block \" + block + \n                  \" src: \" + remoteAddress +\n                  \" dest: \" + localAddress +\n                  \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum) throws IOException {\n    previousOpClientName \u003d clientname;\n    updateCurrentThreadName(\"Receiving block \" + block);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            NetUtils.getOutputStream(s, dnConf.socketWriteTimeout),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          mirrorOut \u003d new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "be7dd8333a7e56e732171db0781786987de03195": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3144. Refactor DatanodeID#getName by use. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308205 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/04/12 3:12 PM",
      "commitName": "be7dd8333a7e56e732171db0781786987de03195",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "31/03/12 8:41 PM",
      "commitNameOld": "0663dbaac0a19719ddf9cd4290ba893bfca69da2",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.77,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,210 +1,210 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum) throws IOException {\n     updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving block \" + block + \n              \" src: \" + remoteAddress +\n              \" dest: \" + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             NetUtils.getOutputStream(s, dnConf.socketWriteTimeout),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n-        mirrorNode \u003d targets[0].getName();\n+        mirrorNode \u003d targets[0].getXferAddr();\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           mirrorOut \u003d new DataOutputStream(\n              new BufferedOutputStream(\n                          NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                          HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n               .setFirstBadLink(mirrorNode)\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \". continuing without the mirror.\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received block \" + block + \n                  \" src: \" + remoteAddress +\n                  \" dest: \" + localAddress +\n                  \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum) throws IOException {\n    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            NetUtils.getOutputStream(s, dnConf.socketWriteTimeout),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getXferAddr();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          mirrorOut \u003d new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "905a127850d5e0cba85c2e075f989fa0f5cf129a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2562. Refactor DN configuration variables out of DataNode class. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1203543 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/11/11 1:04 AM",
      "commitName": "905a127850d5e0cba85c2e075f989fa0f5cf129a",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "31/10/11 10:17 PM",
      "commitNameOld": "1c940637b14eee777a65d153d0d712a1aea3866c",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 17.16,
      "commitsBetweenForRepo": 77,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,210 +1,210 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp,\n       DataChecksum requestedChecksum) throws IOException {\n     updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving block \" + block + \n              \" src: \" + remoteAddress +\n              \" dest: \" + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n-            NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n+            NetUtils.getOutputStream(s, dnConf.socketWriteTimeout),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode, requestedChecksum);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getName();\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n-          int timeoutValue \u003d datanode.socketTimeout\n+          int timeoutValue \u003d dnConf.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n-          int writeTimeout \u003d datanode.socketWriteTimeout + \n+          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           mirrorOut \u003d new DataOutputStream(\n              new BufferedOutputStream(\n                          NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                          HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n \n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n               .setFirstBadLink(mirrorNode)\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \". continuing without the mirror.\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received block \" + block + \n                  \" src: \" + remoteAddress +\n                  \" dest: \" + localAddress +\n                  \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum) throws IOException {\n    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            NetUtils.getOutputStream(s, dnConf.socketWriteTimeout),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getName();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d dnConf.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d dnConf.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          mirrorOut \u003d new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "1c940637b14eee777a65d153d0d712a1aea3866c": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-2521. Remove custom checksum headers from data transfer protocol. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195829 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/10/11 10:17 PM",
      "commitName": "1c940637b14eee777a65d153d0d712a1aea3866c",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2521. Remove custom checksum headers from data transfer protocol. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195829 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "31/10/11 10:17 PM",
          "commitName": "1c940637b14eee777a65d153d0d712a1aea3866c",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "31/10/11 2:53 PM",
          "commitNameOld": "c46876982ed90d0819a94b518f6135b82334d10d",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.31,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,212 +1,210 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n-      final long latestGenerationStamp) throws IOException {\n+      final long latestGenerationStamp,\n+      DataChecksum requestedChecksum) throws IOException {\n     updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving block \" + block + \n              \" src: \" + remoteAddress +\n              \" dest: \" + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n-            clientname, srcDataNode, datanode);\n+            clientname, srcDataNode, datanode, requestedChecksum);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getName();\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d datanode.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d datanode.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           mirrorOut \u003d new DataOutputStream(\n              new BufferedOutputStream(\n                          NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                          HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n-              minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n+              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n \n-          if (blockReceiver !\u003d null) { // send checksum header\n-            blockReceiver.writeChecksumHeader(mirrorOut);\n-          }\n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n               .setFirstBadLink(mirrorNode)\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \". continuing without the mirror.\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received block \" + block + \n                  \" src: \" + remoteAddress +\n                  \" dest: \" + localAddress +\n                  \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum) throws IOException {\n    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getName();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d datanode.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d datanode.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          mirrorOut \u003d new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {
            "oldValue": "[block-ExtendedBlock(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientname-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), srcDataNode-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final)]",
            "newValue": "[block-ExtendedBlock(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientname-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), srcDataNode-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final), requestedChecksum-DataChecksum]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2521. Remove custom checksum headers from data transfer protocol. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195829 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "31/10/11 10:17 PM",
          "commitName": "1c940637b14eee777a65d153d0d712a1aea3866c",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "31/10/11 2:53 PM",
          "commitNameOld": "c46876982ed90d0819a94b518f6135b82334d10d",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.31,
          "commitsBetweenForRepo": 13,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,212 +1,210 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n-      final long latestGenerationStamp) throws IOException {\n+      final long latestGenerationStamp,\n+      DataChecksum requestedChecksum) throws IOException {\n     updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving block \" + block + \n              \" src: \" + remoteAddress +\n              \" dest: \" + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n-            clientname, srcDataNode, datanode);\n+            clientname, srcDataNode, datanode, requestedChecksum);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getName();\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d datanode.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d datanode.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           mirrorOut \u003d new DataOutputStream(\n              new BufferedOutputStream(\n                          NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                          HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n-              minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n+              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n \n-          if (blockReceiver !\u003d null) { // send checksum header\n-            blockReceiver.writeChecksumHeader(mirrorOut);\n-          }\n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n               .setFirstBadLink(mirrorNode)\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \". continuing without the mirror.\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received block \" + block + \n                  \" src: \" + remoteAddress +\n                  \" dest: \" + localAddress +\n                  \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp,\n      DataChecksum requestedChecksum) throws IOException {\n    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode, requestedChecksum);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getName();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d datanode.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d datanode.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          mirrorOut \u003d new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp, requestedChecksum);\n\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {}
        }
      ]
    },
    "c46876982ed90d0819a94b518f6135b82334d10d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2512. Add textual error message to data transfer protocol responses. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1195693 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/10/11 2:53 PM",
      "commitName": "c46876982ed90d0819a94b518f6135b82334d10d",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "23/10/11 1:17 PM",
      "commitNameOld": "6e0991704ffda5cf4cff758f0e7086523fa7bcb4",
      "commitAuthorOld": "Konstantin Shvachko",
      "daysBetweenCommits": 8.07,
      "commitsBetweenForRepo": 100,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,212 +1,212 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp) throws IOException {\n     updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving block \" + block + \n              \" src: \" + remoteAddress +\n              \" dest: \" + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n             HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getName();\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d datanode.socketTimeout\n               + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d datanode.socketWriteTimeout + \n                       (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           mirrorOut \u003d new DataOutputStream(\n              new BufferedOutputStream(\n                          NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                          HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n \n           if (blockReceiver !\u003d null) { // send checksum header\n             blockReceiver.writeChecksumHeader(mirrorOut);\n           }\n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n               .setFirstBadLink(mirrorNode)\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \". continuing without the mirror.\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n-          writeResponse(SUCCESS, replyOut);\n+          writeResponse(SUCCESS, null, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received block \" + block + \n                  \" src: \" + remoteAddress +\n                  \" dest: \" + localAddress +\n                  \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp) throws IOException {\n    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getName();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d datanode.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d datanode.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          mirrorOut \u003d new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n\n          if (blockReceiver !\u003d null) { // send checksum header\n            blockReceiver.writeChecksumHeader(mirrorOut);\n          }\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, null, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "8ae98a9d1ca4725e28783370517cb3a3ecda7324": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1620. Rename HdfsConstants -\u003e HdfsServerConstants, FSConstants -\u003e HdfsConstants. (Harsh J Chouraria via atm)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1165096 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/09/11 12:30 PM",
      "commitName": "8ae98a9d1ca4725e28783370517cb3a3ecda7324",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 10.8,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,212 +1,212 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp) throws IOException {\n     updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving block \" + block + \n              \" src: \" + remoteAddress +\n              \" dest: \" + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n-            FSConstants.SMALL_BUFFER_SIZE));\n+            HdfsConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getName();\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d datanode.socketTimeout\n-              + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n+              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d datanode.socketWriteTimeout + \n-                      (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n+                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n-          mirrorSock.setSendBufferSize(FSConstants.DEFAULT_DATA_SOCKET_SIZE);\n+          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n           mirrorOut \u003d new DataOutputStream(\n              new BufferedOutputStream(\n                          NetUtils.getOutputStream(mirrorSock, writeTimeout),\n-                         FSConstants.SMALL_BUFFER_SIZE));\n+                         HdfsConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n \n           if (blockReceiver !\u003d null) { // send checksum header\n             blockReceiver.writeChecksumHeader(mirrorOut);\n           }\n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n               .setFirstBadLink(mirrorNode)\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \". continuing without the mirror.\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received block \" + block + \n                  \" src: \" + remoteAddress +\n                  \" dest: \" + localAddress +\n                  \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp) throws IOException {\n    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n            HdfsConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getName();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d datanode.socketTimeout\n              + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d datanode.socketWriteTimeout + \n                      (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);\n          mirrorOut \u003d new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         HdfsConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n\n          if (blockReceiver !\u003d null) { // send checksum header\n            blockReceiver.writeChecksumHeader(mirrorOut);\n          }\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp) throws IOException {\n    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n            FSConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getName();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d datanode.socketTimeout\n              + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d datanode.socketWriteTimeout + \n                      (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(FSConstants.DEFAULT_DATA_SOCKET_SIZE);\n          mirrorOut \u003d new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         FSConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n\n          if (blockReceiver !\u003d null) { // send checksum header\n            blockReceiver.writeChecksumHeader(mirrorOut);\n          }\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp) throws IOException {\n    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n            FSConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getName();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d datanode.socketTimeout\n              + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d datanode.socketWriteTimeout + \n                      (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(FSConstants.DEFAULT_DATA_SOCKET_SIZE);\n          mirrorOut \u003d new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         FSConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n\n          if (blockReceiver !\u003d null) { // send checksum header\n            blockReceiver.writeChecksumHeader(mirrorOut);\n          }\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java"
      }
    },
    "ef223e8e8e1e18733fc18cd84e34dd0bb0f9a710": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2241. Remove implementing FSConstants interface to just get the constants from the interface. Contributed by Suresh Srinivas.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1156420 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/08/11 5:46 PM",
      "commitName": "ef223e8e8e1e18733fc18cd84e34dd0bb0f9a710",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "12/07/11 6:11 PM",
      "commitNameOld": "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f",
      "commitAuthorOld": "Jitendra Nath Pandey",
      "daysBetweenCommits": 28.98,
      "commitsBetweenForRepo": 108,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,212 +1,212 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp) throws IOException {\n     updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving block \" + block + \n              \" src: \" + remoteAddress +\n              \" dest: \" + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n-            SMALL_BUFFER_SIZE));\n+            FSConstants.SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getName();\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d datanode.socketTimeout\n               + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d datanode.socketWriteTimeout + \n                       (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n-          mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);\n+          mirrorSock.setSendBufferSize(FSConstants.DEFAULT_DATA_SOCKET_SIZE);\n           mirrorOut \u003d new DataOutputStream(\n              new BufferedOutputStream(\n                          NetUtils.getOutputStream(mirrorSock, writeTimeout),\n-                         SMALL_BUFFER_SIZE));\n+                         FSConstants.SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n \n           if (blockReceiver !\u003d null) { // send checksum header\n             blockReceiver.writeChecksumHeader(mirrorOut);\n           }\n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n               .setFirstBadLink(mirrorNode)\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \". continuing without the mirror.\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received block \" + block + \n                  \" src: \" + remoteAddress +\n                  \" dest: \" + localAddress +\n                  \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp) throws IOException {\n    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n            FSConstants.SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getName();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d datanode.socketTimeout\n              + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d datanode.socketWriteTimeout + \n                      (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(FSConstants.DEFAULT_DATA_SOCKET_SIZE);\n          mirrorOut \u003d new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         FSConstants.SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n\n          if (blockReceiver !\u003d null) { // send checksum header\n            blockReceiver.writeChecksumHeader(mirrorOut);\n          }\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1977. Stop using StringUtils.stringifyException(). Contributed by Bharath Mundlapudi.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1145834 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/07/11 6:11 PM",
      "commitName": "2c5dd549e31aa5d3377ff2619ede8e92b8dc5d0f",
      "commitAuthor": "Jitendra Nath Pandey",
      "commitDateOld": "30/06/11 1:56 PM",
      "commitNameOld": "3af51887b40df8de7482040cf8a90600a2c4305f",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 12.18,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,213 +1,212 @@\n   public void writeBlock(final ExtendedBlock block,\n       final Token\u003cBlockTokenIdentifier\u003e blockToken,\n       final String clientname,\n       final DatanodeInfo[] targets,\n       final DatanodeInfo srcDataNode,\n       final BlockConstructionStage stage,\n       final int pipelineSize,\n       final long minBytesRcvd,\n       final long maxBytesRcvd,\n       final long latestGenerationStamp) throws IOException {\n     updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving block \" + block + \n              \" src: \" + remoteAddress +\n              \" dest: \" + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n             SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n             stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode);\n       } else {\n         datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getName();\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d datanode.socketTimeout\n               + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d datanode.socketWriteTimeout + \n                       (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);\n           mirrorOut \u003d new DataOutputStream(\n              new BufferedOutputStream(\n                          NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                          SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n \n           new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n               clientname, targets, srcDataNode, stage, pipelineSize,\n               minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n \n           if (blockReceiver !\u003d null) { // send checksum header\n             blockReceiver.writeChecksumHeader(mirrorOut);\n           }\n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n               .setFirstBadLink(mirrorNode)\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode +\n-                     \". continuing without the mirror.\\n\" +\n-                     StringUtils.stringifyException(e));\n+                     \". continuing without the mirror.\", e);\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received block \" + block + \n                  \" src: \" + remoteAddress +\n                  \" dest: \" + localAddress +\n                  \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp) throws IOException {\n    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n            SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getName();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d datanode.socketTimeout\n              + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d datanode.socketWriteTimeout + \n                      (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);\n          mirrorOut \u003d new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n\n          if (blockReceiver !\u003d null) { // send checksum header\n            blockReceiver.writeChecksumHeader(mirrorOut);\n          }\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\", e);\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "2f48fae72aa52e6ec42264cad24fab36b6a426c2": {
      "type": "Ymultichange(Yrename,Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-2087. Declare methods in DataTransferProtocol interface, and change Sender and Receiver to implement the interface.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1139124 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/06/11 4:57 PM",
      "commitName": "2f48fae72aa52e6ec42264cad24fab36b6a426c2",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-2087. Declare methods in DataTransferProtocol interface, and change Sender and Receiver to implement the interface.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1139124 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/06/11 4:57 PM",
          "commitName": "2f48fae72aa52e6ec42264cad24fab36b6a426c2",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/06/11 10:12 AM",
          "commitNameOld": "3f190b3e1acc5ea9e9a03e85a4df0e3f0ab73b9f",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 2.28,
          "commitsBetweenForRepo": 7,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,209 +1,213 @@\n-  protected void opWriteBlock(final DataInputStream in, final ExtendedBlock block, \n-      final int pipelineSize, final BlockConstructionStage stage,\n-      final long newGs, final long minBytesRcvd, final long maxBytesRcvd,\n-      final String clientname, final DatanodeInfo srcDataNode,\n-      final DatanodeInfo[] targets, final Token\u003cBlockTokenIdentifier\u003e blockToken\n-      ) throws IOException {\n+  public void writeBlock(final ExtendedBlock block,\n+      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n+      final String clientname,\n+      final DatanodeInfo[] targets,\n+      final DatanodeInfo srcDataNode,\n+      final BlockConstructionStage stage,\n+      final int pipelineSize,\n+      final long minBytesRcvd,\n+      final long maxBytesRcvd,\n+      final long latestGenerationStamp) throws IOException {\n     updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n-      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + newGs\n+      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving block \" + block + \n              \" src: \" + remoteAddress +\n              \" dest: \" + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n             SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n-            stage, newGs, minBytesRcvd, maxBytesRcvd,\n+            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode);\n       } else {\n-        datanode.data.recoverClose(block, newGs, minBytesRcvd);\n+        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getName();\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d datanode.socketTimeout\n               + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d datanode.socketWriteTimeout + \n                       (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);\n           mirrorOut \u003d new DataOutputStream(\n              new BufferedOutputStream(\n                          NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                          SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n \n-          Sender.opWriteBlock(mirrorOut, originalBlock,\n-              pipelineSize, stage, newGs, minBytesRcvd, maxBytesRcvd, clientname,\n-              srcDataNode, targets, blockToken);\n+          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n+              clientname, targets, srcDataNode, stage, pipelineSize,\n+              minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n \n           if (blockReceiver !\u003d null) { // send checksum header\n             blockReceiver.writeChecksumHeader(mirrorOut);\n           }\n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n               .setFirstBadLink(mirrorNode)\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \". continuing without the mirror.\\n\" +\n                      StringUtils.stringifyException(e));\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n-        block.setGenerationStamp(newGs);\n+        block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received block \" + block + \n                  \" src: \" + remoteAddress +\n                  \" dest: \" + localAddress +\n                  \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp) throws IOException {\n    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n            SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getName();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d datanode.socketTimeout\n              + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d datanode.socketWriteTimeout + \n                      (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);\n          mirrorOut \u003d new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n\n          if (blockReceiver !\u003d null) { // send checksum header\n            blockReceiver.writeChecksumHeader(mirrorOut);\n          }\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\\n\" +\n                     StringUtils.stringifyException(e));\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {
            "oldValue": "opWriteBlock",
            "newValue": "writeBlock"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2087. Declare methods in DataTransferProtocol interface, and change Sender and Receiver to implement the interface.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1139124 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/06/11 4:57 PM",
          "commitName": "2f48fae72aa52e6ec42264cad24fab36b6a426c2",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/06/11 10:12 AM",
          "commitNameOld": "3f190b3e1acc5ea9e9a03e85a4df0e3f0ab73b9f",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 2.28,
          "commitsBetweenForRepo": 7,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,209 +1,213 @@\n-  protected void opWriteBlock(final DataInputStream in, final ExtendedBlock block, \n-      final int pipelineSize, final BlockConstructionStage stage,\n-      final long newGs, final long minBytesRcvd, final long maxBytesRcvd,\n-      final String clientname, final DatanodeInfo srcDataNode,\n-      final DatanodeInfo[] targets, final Token\u003cBlockTokenIdentifier\u003e blockToken\n-      ) throws IOException {\n+  public void writeBlock(final ExtendedBlock block,\n+      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n+      final String clientname,\n+      final DatanodeInfo[] targets,\n+      final DatanodeInfo srcDataNode,\n+      final BlockConstructionStage stage,\n+      final int pipelineSize,\n+      final long minBytesRcvd,\n+      final long maxBytesRcvd,\n+      final long latestGenerationStamp) throws IOException {\n     updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n-      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + newGs\n+      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving block \" + block + \n              \" src: \" + remoteAddress +\n              \" dest: \" + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n             SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n-            stage, newGs, minBytesRcvd, maxBytesRcvd,\n+            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode);\n       } else {\n-        datanode.data.recoverClose(block, newGs, minBytesRcvd);\n+        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getName();\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d datanode.socketTimeout\n               + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d datanode.socketWriteTimeout + \n                       (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);\n           mirrorOut \u003d new DataOutputStream(\n              new BufferedOutputStream(\n                          NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                          SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n \n-          Sender.opWriteBlock(mirrorOut, originalBlock,\n-              pipelineSize, stage, newGs, minBytesRcvd, maxBytesRcvd, clientname,\n-              srcDataNode, targets, blockToken);\n+          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n+              clientname, targets, srcDataNode, stage, pipelineSize,\n+              minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n \n           if (blockReceiver !\u003d null) { // send checksum header\n             blockReceiver.writeChecksumHeader(mirrorOut);\n           }\n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n               .setFirstBadLink(mirrorNode)\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \". continuing without the mirror.\\n\" +\n                      StringUtils.stringifyException(e));\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n-        block.setGenerationStamp(newGs);\n+        block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received block \" + block + \n                  \" src: \" + remoteAddress +\n                  \" dest: \" + localAddress +\n                  \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp) throws IOException {\n    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n            SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getName();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d datanode.socketTimeout\n              + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d datanode.socketWriteTimeout + \n                      (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);\n          mirrorOut \u003d new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n\n          if (blockReceiver !\u003d null) { // send checksum header\n            blockReceiver.writeChecksumHeader(mirrorOut);\n          }\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\\n\" +\n                     StringUtils.stringifyException(e));\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {
            "oldValue": "[in-DataInputStream(modifiers-final), block-ExtendedBlock(modifiers-final), pipelineSize-int(modifiers-final), stage-BlockConstructionStage(modifiers-final), newGs-long(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), clientname-String(modifiers-final), srcDataNode-DatanodeInfo(modifiers-final), targets-DatanodeInfo[](modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final)]",
            "newValue": "[block-ExtendedBlock(modifiers-final), blockToken-Token\u003cBlockTokenIdentifier\u003e(modifiers-final), clientname-String(modifiers-final), targets-DatanodeInfo[](modifiers-final), srcDataNode-DatanodeInfo(modifiers-final), stage-BlockConstructionStage(modifiers-final), pipelineSize-int(modifiers-final), minBytesRcvd-long(modifiers-final), maxBytesRcvd-long(modifiers-final), latestGenerationStamp-long(modifiers-final)]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-2087. Declare methods in DataTransferProtocol interface, and change Sender and Receiver to implement the interface.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1139124 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/06/11 4:57 PM",
          "commitName": "2f48fae72aa52e6ec42264cad24fab36b6a426c2",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/06/11 10:12 AM",
          "commitNameOld": "3f190b3e1acc5ea9e9a03e85a4df0e3f0ab73b9f",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 2.28,
          "commitsBetweenForRepo": 7,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,209 +1,213 @@\n-  protected void opWriteBlock(final DataInputStream in, final ExtendedBlock block, \n-      final int pipelineSize, final BlockConstructionStage stage,\n-      final long newGs, final long minBytesRcvd, final long maxBytesRcvd,\n-      final String clientname, final DatanodeInfo srcDataNode,\n-      final DatanodeInfo[] targets, final Token\u003cBlockTokenIdentifier\u003e blockToken\n-      ) throws IOException {\n+  public void writeBlock(final ExtendedBlock block,\n+      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n+      final String clientname,\n+      final DatanodeInfo[] targets,\n+      final DatanodeInfo srcDataNode,\n+      final BlockConstructionStage stage,\n+      final int pipelineSize,\n+      final long minBytesRcvd,\n+      final long maxBytesRcvd,\n+      final long latestGenerationStamp) throws IOException {\n     updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n-      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + newGs\n+      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving block \" + block + \n              \" src: \" + remoteAddress +\n              \" dest: \" + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n             SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n-            stage, newGs, minBytesRcvd, maxBytesRcvd,\n+            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode);\n       } else {\n-        datanode.data.recoverClose(block, newGs, minBytesRcvd);\n+        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getName();\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d datanode.socketTimeout\n               + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d datanode.socketWriteTimeout + \n                       (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);\n           mirrorOut \u003d new DataOutputStream(\n              new BufferedOutputStream(\n                          NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                          SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n \n-          Sender.opWriteBlock(mirrorOut, originalBlock,\n-              pipelineSize, stage, newGs, minBytesRcvd, maxBytesRcvd, clientname,\n-              srcDataNode, targets, blockToken);\n+          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n+              clientname, targets, srcDataNode, stage, pipelineSize,\n+              minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n \n           if (blockReceiver !\u003d null) { // send checksum header\n             blockReceiver.writeChecksumHeader(mirrorOut);\n           }\n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n               .setFirstBadLink(mirrorNode)\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \". continuing without the mirror.\\n\" +\n                      StringUtils.stringifyException(e));\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n-        block.setGenerationStamp(newGs);\n+        block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received block \" + block + \n                  \" src: \" + remoteAddress +\n                  \" dest: \" + localAddress +\n                  \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp) throws IOException {\n    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n            SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getName();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d datanode.socketTimeout\n              + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d datanode.socketWriteTimeout + \n                      (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);\n          mirrorOut \u003d new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n\n          if (blockReceiver !\u003d null) { // send checksum header\n            blockReceiver.writeChecksumHeader(mirrorOut);\n          }\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\\n\" +\n                     StringUtils.stringifyException(e));\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {
            "oldValue": "[protected]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2087. Declare methods in DataTransferProtocol interface, and change Sender and Receiver to implement the interface.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1139124 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/06/11 4:57 PM",
          "commitName": "2f48fae72aa52e6ec42264cad24fab36b6a426c2",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/06/11 10:12 AM",
          "commitNameOld": "3f190b3e1acc5ea9e9a03e85a4df0e3f0ab73b9f",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 2.28,
          "commitsBetweenForRepo": 7,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,209 +1,213 @@\n-  protected void opWriteBlock(final DataInputStream in, final ExtendedBlock block, \n-      final int pipelineSize, final BlockConstructionStage stage,\n-      final long newGs, final long minBytesRcvd, final long maxBytesRcvd,\n-      final String clientname, final DatanodeInfo srcDataNode,\n-      final DatanodeInfo[] targets, final Token\u003cBlockTokenIdentifier\u003e blockToken\n-      ) throws IOException {\n+  public void writeBlock(final ExtendedBlock block,\n+      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n+      final String clientname,\n+      final DatanodeInfo[] targets,\n+      final DatanodeInfo srcDataNode,\n+      final BlockConstructionStage stage,\n+      final int pipelineSize,\n+      final long minBytesRcvd,\n+      final long maxBytesRcvd,\n+      final long latestGenerationStamp) throws IOException {\n     updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n-      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + newGs\n+      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving block \" + block + \n              \" src: \" + remoteAddress +\n              \" dest: \" + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n             SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n-            stage, newGs, minBytesRcvd, maxBytesRcvd,\n+            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode);\n       } else {\n-        datanode.data.recoverClose(block, newGs, minBytesRcvd);\n+        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getName();\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d datanode.socketTimeout\n               + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d datanode.socketWriteTimeout + \n                       (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);\n           mirrorOut \u003d new DataOutputStream(\n              new BufferedOutputStream(\n                          NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                          SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n \n-          Sender.opWriteBlock(mirrorOut, originalBlock,\n-              pipelineSize, stage, newGs, minBytesRcvd, maxBytesRcvd, clientname,\n-              srcDataNode, targets, blockToken);\n+          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n+              clientname, targets, srcDataNode, stage, pipelineSize,\n+              minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n \n           if (blockReceiver !\u003d null) { // send checksum header\n             blockReceiver.writeChecksumHeader(mirrorOut);\n           }\n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n               .setFirstBadLink(mirrorNode)\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n             LOG.error(datanode + \":Exception transfering block \" +\n                       block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \". continuing without the mirror.\\n\" +\n                      StringUtils.stringifyException(e));\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n-        block.setGenerationStamp(newGs);\n+        block.setGenerationStamp(latestGenerationStamp);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received block \" + block + \n                  \" src: \" + remoteAddress +\n                  \" dest: \" + localAddress +\n                  \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n       LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void writeBlock(final ExtendedBlock block,\n      final Token\u003cBlockTokenIdentifier\u003e blockToken,\n      final String clientname,\n      final DatanodeInfo[] targets,\n      final DatanodeInfo srcDataNode,\n      final BlockConstructionStage stage,\n      final int pipelineSize,\n      final long minBytesRcvd,\n      final long maxBytesRcvd,\n      final long latestGenerationStamp) throws IOException {\n    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + latestGenerationStamp\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n            SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode);\n      } else {\n        datanode.data.recoverClose(block, latestGenerationStamp, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getName();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d datanode.socketTimeout\n              + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d datanode.socketWriteTimeout + \n                      (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);\n          mirrorOut \u003d new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n\n          new Sender(mirrorOut).writeBlock(originalBlock, blockToken,\n              clientname, targets, srcDataNode, stage, pipelineSize,\n              minBytesRcvd, maxBytesRcvd, latestGenerationStamp);\n\n          if (blockReceiver !\u003d null) { // send checksum header\n            blockReceiver.writeChecksumHeader(mirrorOut);\n          }\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\\n\" +\n                     StringUtils.stringifyException(e));\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(latestGenerationStamp);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
          "extendedDetails": {}
        }
      ]
    },
    "3f190b3e1acc5ea9e9a03e85a4df0e3f0ab73b9f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1568. Improve the log messages in DataXceiver.  Contributed by Joey Echeverria\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1138098 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/06/11 10:12 AM",
      "commitName": "3f190b3e1acc5ea9e9a03e85a4df0e3f0ab73b9f",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "15/06/11 2:36 PM",
      "commitNameOld": "6a3963cc8b4cdadf6dc8d2a9ca4f3af4da50a1d2",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 5.82,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,207 +1,209 @@\n   protected void opWriteBlock(final DataInputStream in, final ExtendedBlock block, \n       final int pipelineSize, final BlockConstructionStage stage,\n       final long newGs, final long minBytesRcvd, final long maxBytesRcvd,\n       final String clientname, final DatanodeInfo srcDataNode,\n       final DatanodeInfo[] targets, final Token\u003cBlockTokenIdentifier\u003e blockToken\n       ) throws IOException {\n     updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n     final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n     final boolean isClient \u003d !isDatanode;\n     final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n         || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n \n     // check single target for transfer-RBW/Finalized \n     if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n       throw new IOException(stage + \" does not support multiple targets \"\n           + Arrays.asList(targets));\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n       \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + newGs\n       \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n           + \"\\n  targets\u003d\" + Arrays.asList(targets)\n           + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n           );\n       LOG.debug(\"isDatanode\u003d\" + isDatanode\n           + \", isClient\u003d\" + isClient\n           + \", isTransfer\u003d\" + isTransfer);\n       LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                 \" tcp no delay \" + s.getTcpNoDelay());\n     }\n \n     // We later mutate block\u0027s generation stamp and length, but we need to\n     // forward the original version of the block to downstream mirrors, so\n     // make a copy here.\n     final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n     block.setNumBytes(dataXceiverServer.estimateBlockSize);\n     LOG.info(\"Receiving block \" + block + \n              \" src: \" + remoteAddress +\n              \" dest: \" + localAddress);\n \n     // reply to upstream datanode or client \n     final DataOutputStream replyOut \u003d new DataOutputStream(\n         new BufferedOutputStream(\n             NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n             SMALL_BUFFER_SIZE));\n     checkAccess(replyOut, isClient, block, blockToken,\n         Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n \n     DataOutputStream mirrorOut \u003d null;  // stream to next target\n     DataInputStream mirrorIn \u003d null;    // reply from next target\n     Socket mirrorSock \u003d null;           // socket to next target\n     BlockReceiver blockReceiver \u003d null; // responsible for data handling\n     String mirrorNode \u003d null;           // the name:port of next target\n     String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n     Status mirrorInStatus \u003d SUCCESS;\n     try {\n       if (isDatanode || \n           stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         // open a block receiver\n         blockReceiver \u003d new BlockReceiver(block, in, \n             s.getRemoteSocketAddress().toString(),\n             s.getLocalSocketAddress().toString(),\n             stage, newGs, minBytesRcvd, maxBytesRcvd,\n             clientname, srcDataNode, datanode);\n       } else {\n         datanode.data.recoverClose(block, newGs, minBytesRcvd);\n       }\n \n       //\n       // Connect to downstream machine, if appropriate\n       //\n       if (targets.length \u003e 0) {\n         InetSocketAddress mirrorTarget \u003d null;\n         // Connect to backup machine\n         mirrorNode \u003d targets[0].getName();\n         mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n         mirrorSock \u003d datanode.newSocket();\n         try {\n           int timeoutValue \u003d datanode.socketTimeout\n               + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n           int writeTimeout \u003d datanode.socketWriteTimeout + \n                       (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n           NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n           mirrorSock.setSoTimeout(timeoutValue);\n           mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);\n           mirrorOut \u003d new DataOutputStream(\n              new BufferedOutputStream(\n                          NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                          SMALL_BUFFER_SIZE));\n           mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n \n           Sender.opWriteBlock(mirrorOut, originalBlock,\n               pipelineSize, stage, newGs, minBytesRcvd, maxBytesRcvd, clientname,\n               srcDataNode, targets, blockToken);\n \n           if (blockReceiver !\u003d null) { // send checksum header\n             blockReceiver.writeChecksumHeader(mirrorOut);\n           }\n           mirrorOut.flush();\n \n           // read connect ack (only for clients, not for replication req)\n           if (isClient) {\n             BlockOpResponseProto connectAck \u003d\n               BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n             mirrorInStatus \u003d connectAck.getStatus();\n             firstBadLink \u003d connectAck.getFirstBadLink();\n             if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n               LOG.info(\"Datanode \" + targets.length +\n                        \" got response for connect ack \" +\n                        \" from downstream datanode with firstbadlink as \" +\n                        firstBadLink);\n             }\n           }\n \n         } catch (IOException e) {\n           if (isClient) {\n             BlockOpResponseProto.newBuilder()\n               .setStatus(ERROR)\n               .setFirstBadLink(mirrorNode)\n               .build()\n               .writeDelimitedTo(replyOut);\n             replyOut.flush();\n           }\n           IOUtils.closeStream(mirrorOut);\n           mirrorOut \u003d null;\n           IOUtils.closeStream(mirrorIn);\n           mirrorIn \u003d null;\n           IOUtils.closeSocket(mirrorSock);\n           mirrorSock \u003d null;\n           if (isClient) {\n+            LOG.error(datanode + \":Exception transfering block \" +\n+                      block + \" to mirror \" + mirrorNode + \": \" + e);\n             throw e;\n           } else {\n             LOG.info(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode +\n                      \". continuing without the mirror.\\n\" +\n                      StringUtils.stringifyException(e));\n           }\n         }\n       }\n \n       // send connect-ack to source for clients and not transfer-RBW/Finalized\n       if (isClient \u0026\u0026 !isTransfer) {\n         if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n           LOG.info(\"Datanode \" + targets.length +\n                    \" forwarding connect ack to upstream firstbadlink is \" +\n                    firstBadLink);\n         }\n         BlockOpResponseProto.newBuilder()\n           .setStatus(mirrorInStatus)\n           .setFirstBadLink(firstBadLink)\n           .build()\n           .writeDelimitedTo(replyOut);\n         replyOut.flush();\n       }\n \n       // receive the block and mirror to the next target\n       if (blockReceiver !\u003d null) {\n         String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n         blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n             mirrorAddr, null, targets);\n \n         // send close-ack for transfer-RBW/Finalized \n         if (isTransfer) {\n           if (LOG.isTraceEnabled()) {\n             LOG.trace(\"TRANSFER: send close-ack\");\n           }\n           writeResponse(SUCCESS, replyOut);\n         }\n       }\n \n       // update its generation stamp\n       if (isClient \u0026\u0026 \n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         block.setGenerationStamp(newGs);\n         block.setNumBytes(minBytesRcvd);\n       }\n       \n       // if this write is for a replication request or recovering\n       // a failed close for client, then confirm block. For other client-writes,\n       // the block is finalized in the PacketResponder.\n       if (isDatanode ||\n           stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n         datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n         LOG.info(\"Received block \" + block + \n                  \" src: \" + remoteAddress +\n                  \" dest: \" + localAddress +\n                  \" of size \" + block.getNumBytes());\n       }\n \n       \n     } catch (IOException ioe) {\n-      LOG.info(\"writeBlock \" + block + \" received exception \" + ioe);\n+      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n       throw ioe;\n     } finally {\n       // close all opened streams\n       IOUtils.closeStream(mirrorOut);\n       IOUtils.closeStream(mirrorIn);\n       IOUtils.closeStream(replyOut);\n       IOUtils.closeSocket(mirrorSock);\n       IOUtils.closeStream(blockReceiver);\n     }\n \n     //update metrics\n     datanode.metrics.addWriteBlockOp(elapsed());\n     datanode.metrics.incrWritesFromClient(isLocal);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void opWriteBlock(final DataInputStream in, final ExtendedBlock block, \n      final int pipelineSize, final BlockConstructionStage stage,\n      final long newGs, final long minBytesRcvd, final long maxBytesRcvd,\n      final String clientname, final DatanodeInfo srcDataNode,\n      final DatanodeInfo[] targets, final Token\u003cBlockTokenIdentifier\u003e blockToken\n      ) throws IOException {\n    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + newGs\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n            SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, newGs, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode);\n      } else {\n        datanode.data.recoverClose(block, newGs, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getName();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d datanode.socketTimeout\n              + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d datanode.socketWriteTimeout + \n                      (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);\n          mirrorOut \u003d new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n\n          Sender.opWriteBlock(mirrorOut, originalBlock,\n              pipelineSize, stage, newGs, minBytesRcvd, maxBytesRcvd, clientname,\n              srcDataNode, targets, blockToken);\n\n          if (blockReceiver !\u003d null) { // send checksum header\n            blockReceiver.writeChecksumHeader(mirrorOut);\n          }\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            LOG.error(datanode + \":Exception transfering block \" +\n                      block + \" to mirror \" + mirrorNode + \": \" + e);\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\\n\" +\n                     StringUtils.stringifyException(e));\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(newGs);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"opWriteBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,207 @@\n+  protected void opWriteBlock(final DataInputStream in, final ExtendedBlock block, \n+      final int pipelineSize, final BlockConstructionStage stage,\n+      final long newGs, final long minBytesRcvd, final long maxBytesRcvd,\n+      final String clientname, final DatanodeInfo srcDataNode,\n+      final DatanodeInfo[] targets, final Token\u003cBlockTokenIdentifier\u003e blockToken\n+      ) throws IOException {\n+    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n+    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n+    final boolean isClient \u003d !isDatanode;\n+    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n+        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n+\n+    // check single target for transfer-RBW/Finalized \n+    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n+      throw new IOException(stage + \" does not support multiple targets \"\n+          + Arrays.asList(targets));\n+    }\n+\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n+      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + newGs\n+      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n+          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n+          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n+          );\n+      LOG.debug(\"isDatanode\u003d\" + isDatanode\n+          + \", isClient\u003d\" + isClient\n+          + \", isTransfer\u003d\" + isTransfer);\n+      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n+                \" tcp no delay \" + s.getTcpNoDelay());\n+    }\n+\n+    // We later mutate block\u0027s generation stamp and length, but we need to\n+    // forward the original version of the block to downstream mirrors, so\n+    // make a copy here.\n+    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n+    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n+    LOG.info(\"Receiving block \" + block + \n+             \" src: \" + remoteAddress +\n+             \" dest: \" + localAddress);\n+\n+    // reply to upstream datanode or client \n+    final DataOutputStream replyOut \u003d new DataOutputStream(\n+        new BufferedOutputStream(\n+            NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n+            SMALL_BUFFER_SIZE));\n+    checkAccess(replyOut, isClient, block, blockToken,\n+        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n+\n+    DataOutputStream mirrorOut \u003d null;  // stream to next target\n+    DataInputStream mirrorIn \u003d null;    // reply from next target\n+    Socket mirrorSock \u003d null;           // socket to next target\n+    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n+    String mirrorNode \u003d null;           // the name:port of next target\n+    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n+    Status mirrorInStatus \u003d SUCCESS;\n+    try {\n+      if (isDatanode || \n+          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n+        // open a block receiver\n+        blockReceiver \u003d new BlockReceiver(block, in, \n+            s.getRemoteSocketAddress().toString(),\n+            s.getLocalSocketAddress().toString(),\n+            stage, newGs, minBytesRcvd, maxBytesRcvd,\n+            clientname, srcDataNode, datanode);\n+      } else {\n+        datanode.data.recoverClose(block, newGs, minBytesRcvd);\n+      }\n+\n+      //\n+      // Connect to downstream machine, if appropriate\n+      //\n+      if (targets.length \u003e 0) {\n+        InetSocketAddress mirrorTarget \u003d null;\n+        // Connect to backup machine\n+        mirrorNode \u003d targets[0].getName();\n+        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n+        mirrorSock \u003d datanode.newSocket();\n+        try {\n+          int timeoutValue \u003d datanode.socketTimeout\n+              + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n+          int writeTimeout \u003d datanode.socketWriteTimeout + \n+                      (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n+          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n+          mirrorSock.setSoTimeout(timeoutValue);\n+          mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);\n+          mirrorOut \u003d new DataOutputStream(\n+             new BufferedOutputStream(\n+                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n+                         SMALL_BUFFER_SIZE));\n+          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n+\n+          Sender.opWriteBlock(mirrorOut, originalBlock,\n+              pipelineSize, stage, newGs, minBytesRcvd, maxBytesRcvd, clientname,\n+              srcDataNode, targets, blockToken);\n+\n+          if (blockReceiver !\u003d null) { // send checksum header\n+            blockReceiver.writeChecksumHeader(mirrorOut);\n+          }\n+          mirrorOut.flush();\n+\n+          // read connect ack (only for clients, not for replication req)\n+          if (isClient) {\n+            BlockOpResponseProto connectAck \u003d\n+              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n+            mirrorInStatus \u003d connectAck.getStatus();\n+            firstBadLink \u003d connectAck.getFirstBadLink();\n+            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n+              LOG.info(\"Datanode \" + targets.length +\n+                       \" got response for connect ack \" +\n+                       \" from downstream datanode with firstbadlink as \" +\n+                       firstBadLink);\n+            }\n+          }\n+\n+        } catch (IOException e) {\n+          if (isClient) {\n+            BlockOpResponseProto.newBuilder()\n+              .setStatus(ERROR)\n+              .setFirstBadLink(mirrorNode)\n+              .build()\n+              .writeDelimitedTo(replyOut);\n+            replyOut.flush();\n+          }\n+          IOUtils.closeStream(mirrorOut);\n+          mirrorOut \u003d null;\n+          IOUtils.closeStream(mirrorIn);\n+          mirrorIn \u003d null;\n+          IOUtils.closeSocket(mirrorSock);\n+          mirrorSock \u003d null;\n+          if (isClient) {\n+            throw e;\n+          } else {\n+            LOG.info(datanode + \":Exception transfering block \" +\n+                     block + \" to mirror \" + mirrorNode +\n+                     \". continuing without the mirror.\\n\" +\n+                     StringUtils.stringifyException(e));\n+          }\n+        }\n+      }\n+\n+      // send connect-ack to source for clients and not transfer-RBW/Finalized\n+      if (isClient \u0026\u0026 !isTransfer) {\n+        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n+          LOG.info(\"Datanode \" + targets.length +\n+                   \" forwarding connect ack to upstream firstbadlink is \" +\n+                   firstBadLink);\n+        }\n+        BlockOpResponseProto.newBuilder()\n+          .setStatus(mirrorInStatus)\n+          .setFirstBadLink(firstBadLink)\n+          .build()\n+          .writeDelimitedTo(replyOut);\n+        replyOut.flush();\n+      }\n+\n+      // receive the block and mirror to the next target\n+      if (blockReceiver !\u003d null) {\n+        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n+        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n+            mirrorAddr, null, targets);\n+\n+        // send close-ack for transfer-RBW/Finalized \n+        if (isTransfer) {\n+          if (LOG.isTraceEnabled()) {\n+            LOG.trace(\"TRANSFER: send close-ack\");\n+          }\n+          writeResponse(SUCCESS, replyOut);\n+        }\n+      }\n+\n+      // update its generation stamp\n+      if (isClient \u0026\u0026 \n+          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n+        block.setGenerationStamp(newGs);\n+        block.setNumBytes(minBytesRcvd);\n+      }\n+      \n+      // if this write is for a replication request or recovering\n+      // a failed close for client, then confirm block. For other client-writes,\n+      // the block is finalized in the PacketResponder.\n+      if (isDatanode ||\n+          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n+        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n+        LOG.info(\"Received block \" + block + \n+                 \" src: \" + remoteAddress +\n+                 \" dest: \" + localAddress +\n+                 \" of size \" + block.getNumBytes());\n+      }\n+\n+      \n+    } catch (IOException ioe) {\n+      LOG.info(\"writeBlock \" + block + \" received exception \" + ioe);\n+      throw ioe;\n+    } finally {\n+      // close all opened streams\n+      IOUtils.closeStream(mirrorOut);\n+      IOUtils.closeStream(mirrorIn);\n+      IOUtils.closeStream(replyOut);\n+      IOUtils.closeSocket(mirrorSock);\n+      IOUtils.closeStream(blockReceiver);\n+    }\n+\n+    //update metrics\n+    datanode.metrics.addWriteBlockOp(elapsed());\n+    datanode.metrics.incrWritesFromClient(isLocal);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected void opWriteBlock(final DataInputStream in, final ExtendedBlock block, \n      final int pipelineSize, final BlockConstructionStage stage,\n      final long newGs, final long minBytesRcvd, final long maxBytesRcvd,\n      final String clientname, final DatanodeInfo srcDataNode,\n      final DatanodeInfo[] targets, final Token\u003cBlockTokenIdentifier\u003e blockToken\n      ) throws IOException {\n    updateCurrentThreadName(\"Receiving block \" + block + \" client\u003d\" + clientname);\n    final boolean isDatanode \u003d clientname.length() \u003d\u003d 0;\n    final boolean isClient \u003d !isDatanode;\n    final boolean isTransfer \u003d stage \u003d\u003d BlockConstructionStage.TRANSFER_RBW\n        || stage \u003d\u003d BlockConstructionStage.TRANSFER_FINALIZED;\n\n    // check single target for transfer-RBW/Finalized \n    if (isTransfer \u0026\u0026 targets.length \u003e 0) {\n      throw new IOException(stage + \" does not support multiple targets \"\n          + Arrays.asList(targets));\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"opWriteBlock: stage\u003d\" + stage + \", clientname\u003d\" + clientname \n      \t\t+ \"\\n  block  \u003d\" + block + \", newGs\u003d\" + newGs\n      \t\t+ \", bytesRcvd\u003d[\" + minBytesRcvd + \", \" + maxBytesRcvd + \"]\"\n          + \"\\n  targets\u003d\" + Arrays.asList(targets)\n          + \"; pipelineSize\u003d\" + pipelineSize + \", srcDataNode\u003d\" + srcDataNode\n          );\n      LOG.debug(\"isDatanode\u003d\" + isDatanode\n          + \", isClient\u003d\" + isClient\n          + \", isTransfer\u003d\" + isTransfer);\n      LOG.debug(\"writeBlock receive buf size \" + s.getReceiveBufferSize() +\n                \" tcp no delay \" + s.getTcpNoDelay());\n    }\n\n    // We later mutate block\u0027s generation stamp and length, but we need to\n    // forward the original version of the block to downstream mirrors, so\n    // make a copy here.\n    final ExtendedBlock originalBlock \u003d new ExtendedBlock(block);\n    block.setNumBytes(dataXceiverServer.estimateBlockSize);\n    LOG.info(\"Receiving block \" + block + \n             \" src: \" + remoteAddress +\n             \" dest: \" + localAddress);\n\n    // reply to upstream datanode or client \n    final DataOutputStream replyOut \u003d new DataOutputStream(\n        new BufferedOutputStream(\n            NetUtils.getOutputStream(s, datanode.socketWriteTimeout),\n            SMALL_BUFFER_SIZE));\n    checkAccess(replyOut, isClient, block, blockToken,\n        Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);\n\n    DataOutputStream mirrorOut \u003d null;  // stream to next target\n    DataInputStream mirrorIn \u003d null;    // reply from next target\n    Socket mirrorSock \u003d null;           // socket to next target\n    BlockReceiver blockReceiver \u003d null; // responsible for data handling\n    String mirrorNode \u003d null;           // the name:port of next target\n    String firstBadLink \u003d \"\";           // first datanode that failed in connection setup\n    Status mirrorInStatus \u003d SUCCESS;\n    try {\n      if (isDatanode || \n          stage !\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        // open a block receiver\n        blockReceiver \u003d new BlockReceiver(block, in, \n            s.getRemoteSocketAddress().toString(),\n            s.getLocalSocketAddress().toString(),\n            stage, newGs, minBytesRcvd, maxBytesRcvd,\n            clientname, srcDataNode, datanode);\n      } else {\n        datanode.data.recoverClose(block, newGs, minBytesRcvd);\n      }\n\n      //\n      // Connect to downstream machine, if appropriate\n      //\n      if (targets.length \u003e 0) {\n        InetSocketAddress mirrorTarget \u003d null;\n        // Connect to backup machine\n        mirrorNode \u003d targets[0].getName();\n        mirrorTarget \u003d NetUtils.createSocketAddr(mirrorNode);\n        mirrorSock \u003d datanode.newSocket();\n        try {\n          int timeoutValue \u003d datanode.socketTimeout\n              + (HdfsConstants.READ_TIMEOUT_EXTENSION * targets.length);\n          int writeTimeout \u003d datanode.socketWriteTimeout + \n                      (HdfsConstants.WRITE_TIMEOUT_EXTENSION * targets.length);\n          NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);\n          mirrorSock.setSoTimeout(timeoutValue);\n          mirrorSock.setSendBufferSize(DEFAULT_DATA_SOCKET_SIZE);\n          mirrorOut \u003d new DataOutputStream(\n             new BufferedOutputStream(\n                         NetUtils.getOutputStream(mirrorSock, writeTimeout),\n                         SMALL_BUFFER_SIZE));\n          mirrorIn \u003d new DataInputStream(NetUtils.getInputStream(mirrorSock));\n\n          Sender.opWriteBlock(mirrorOut, originalBlock,\n              pipelineSize, stage, newGs, minBytesRcvd, maxBytesRcvd, clientname,\n              srcDataNode, targets, blockToken);\n\n          if (blockReceiver !\u003d null) { // send checksum header\n            blockReceiver.writeChecksumHeader(mirrorOut);\n          }\n          mirrorOut.flush();\n\n          // read connect ack (only for clients, not for replication req)\n          if (isClient) {\n            BlockOpResponseProto connectAck \u003d\n              BlockOpResponseProto.parseFrom(HdfsProtoUtil.vintPrefixed(mirrorIn));\n            mirrorInStatus \u003d connectAck.getStatus();\n            firstBadLink \u003d connectAck.getFirstBadLink();\n            if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n              LOG.info(\"Datanode \" + targets.length +\n                       \" got response for connect ack \" +\n                       \" from downstream datanode with firstbadlink as \" +\n                       firstBadLink);\n            }\n          }\n\n        } catch (IOException e) {\n          if (isClient) {\n            BlockOpResponseProto.newBuilder()\n              .setStatus(ERROR)\n              .setFirstBadLink(mirrorNode)\n              .build()\n              .writeDelimitedTo(replyOut);\n            replyOut.flush();\n          }\n          IOUtils.closeStream(mirrorOut);\n          mirrorOut \u003d null;\n          IOUtils.closeStream(mirrorIn);\n          mirrorIn \u003d null;\n          IOUtils.closeSocket(mirrorSock);\n          mirrorSock \u003d null;\n          if (isClient) {\n            throw e;\n          } else {\n            LOG.info(datanode + \":Exception transfering block \" +\n                     block + \" to mirror \" + mirrorNode +\n                     \". continuing without the mirror.\\n\" +\n                     StringUtils.stringifyException(e));\n          }\n        }\n      }\n\n      // send connect-ack to source for clients and not transfer-RBW/Finalized\n      if (isClient \u0026\u0026 !isTransfer) {\n        if (LOG.isDebugEnabled() || mirrorInStatus !\u003d SUCCESS) {\n          LOG.info(\"Datanode \" + targets.length +\n                   \" forwarding connect ack to upstream firstbadlink is \" +\n                   firstBadLink);\n        }\n        BlockOpResponseProto.newBuilder()\n          .setStatus(mirrorInStatus)\n          .setFirstBadLink(firstBadLink)\n          .build()\n          .writeDelimitedTo(replyOut);\n        replyOut.flush();\n      }\n\n      // receive the block and mirror to the next target\n      if (blockReceiver !\u003d null) {\n        String mirrorAddr \u003d (mirrorSock \u003d\u003d null) ? null : mirrorNode;\n        blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,\n            mirrorAddr, null, targets);\n\n        // send close-ack for transfer-RBW/Finalized \n        if (isTransfer) {\n          if (LOG.isTraceEnabled()) {\n            LOG.trace(\"TRANSFER: send close-ack\");\n          }\n          writeResponse(SUCCESS, replyOut);\n        }\n      }\n\n      // update its generation stamp\n      if (isClient \u0026\u0026 \n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        block.setGenerationStamp(newGs);\n        block.setNumBytes(minBytesRcvd);\n      }\n      \n      // if this write is for a replication request or recovering\n      // a failed close for client, then confirm block. For other client-writes,\n      // the block is finalized in the PacketResponder.\n      if (isDatanode ||\n          stage \u003d\u003d BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) {\n        datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT);\n        LOG.info(\"Received block \" + block + \n                 \" src: \" + remoteAddress +\n                 \" dest: \" + localAddress +\n                 \" of size \" + block.getNumBytes());\n      }\n\n      \n    } catch (IOException ioe) {\n      LOG.info(\"writeBlock \" + block + \" received exception \" + ioe);\n      throw ioe;\n    } finally {\n      // close all opened streams\n      IOUtils.closeStream(mirrorOut);\n      IOUtils.closeStream(mirrorIn);\n      IOUtils.closeStream(replyOut);\n      IOUtils.closeSocket(mirrorSock);\n      IOUtils.closeStream(blockReceiver);\n    }\n\n    //update metrics\n    datanode.metrics.addWriteBlockOp(elapsed());\n    datanode.metrics.incrWritesFromClient(isLocal);\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java"
    }
  }
}