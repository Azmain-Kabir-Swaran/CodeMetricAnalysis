{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BackupNode.java",
  "functionName": "stop",
  "functionId": "stop",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java",
  "functionStartLine": 183,
  "functionEndLine": 185,
  "numCommitsSeen": 57,
  "timeTaken": 5292,
  "changeHistory": [
    "e449de0526ce0aa58bdd0f513b0e2a744a4bbda1",
    "c69dfdd5e14af490790dff8227b11962ec816577",
    "fa6033a029aeb04ebb0b6221bdc9e6e06c1bf0ba",
    "371f4228e86f5ebffb3d8647fb30b8bdc2b777c4",
    "0920056f0467bcf055628bc23d91c602aac7da49",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "e449de0526ce0aa58bdd0f513b0e2a744a4bbda1": "Ybodychange",
    "c69dfdd5e14af490790dff8227b11962ec816577": "Ybodychange",
    "fa6033a029aeb04ebb0b6221bdc9e6e06c1bf0ba": "Ybodychange",
    "371f4228e86f5ebffb3d8647fb30b8bdc2b777c4": "Ybodychange",
    "0920056f0467bcf055628bc23d91c602aac7da49": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "e449de0526ce0aa58bdd0f513b0e2a744a4bbda1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3126. Journal stream from Namenode to BackupNode needs to have timeout. Contributed by Hari Mankude.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308636 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/04/12 5:55 PM",
      "commitName": "e449de0526ce0aa58bdd0f513b0e2a744a4bbda1",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "29/02/12 3:47 PM",
      "commitNameOld": "1ba357553aafe30ecf33b9c7863c44c0b8021e78",
      "commitAuthorOld": "",
      "daysBetweenCommits": 33.05,
      "commitsBetweenForRepo": 207,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,3 @@\n   public void stop() {\n-    if(checkpointManager !\u003d null) {\n-      // Prevent from starting a new checkpoint.\n-      // Checkpoints that has already been started may proceed until \n-      // the error reporting to the name-node is complete.\n-      // Checkpoint manager should not be interrupted yet because it will\n-      // close storage file channels and the checkpoint may fail with \n-      // ClosedByInterruptException.\n-      checkpointManager.shouldRun \u003d false;\n-    }\n-    if(namenode !\u003d null \u0026\u0026 getRegistration() !\u003d null) {\n-      // Exclude this node from the list of backup streams on the name-node\n-      try {\n-        namenode.errorReport(getRegistration(), NamenodeProtocol.FATAL,\n-            \"Shutting down.\");\n-      } catch(IOException e) {\n-        LOG.error(\"Failed to report to name-node.\", e);\n-      }\n-    }\n-    // Stop the RPC client\n-    if (namenode !\u003d null) {\n-      RPC.stopProxy(namenode);\n-    }\n-    namenode \u003d null;\n-    // Stop the checkpoint manager\n-    if(checkpointManager !\u003d null) {\n-      checkpointManager.interrupt();\n-      checkpointManager \u003d null;\n-    }\n-\n-    // Abort current log segment - otherwise the NN shutdown code\n-    // will close it gracefully, which is incorrect.\n-    getFSImage().getEditLog().abortCurrentLogSegment();\n-\n-    // Stop name-node threads\n-    super.stop();\n+    stop(true);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void stop() {\n    stop(true);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java",
      "extendedDetails": {}
    },
    "c69dfdd5e14af490790dff8227b11962ec816577": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2958. Sweep for remaining proxy construction which doesn\u0027t go through failover path.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1294811 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/02/12 12:09 PM",
      "commitName": "c69dfdd5e14af490790dff8227b11962ec816577",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "25/02/12 8:57 PM",
      "commitNameOld": "ae9014ef6a6a135c1244e2bc5c09b29fd11da370",
      "commitAuthorOld": "",
      "daysBetweenCommits": 2.63,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,37 @@\n   public void stop() {\n     if(checkpointManager !\u003d null) {\n       // Prevent from starting a new checkpoint.\n       // Checkpoints that has already been started may proceed until \n       // the error reporting to the name-node is complete.\n       // Checkpoint manager should not be interrupted yet because it will\n       // close storage file channels and the checkpoint may fail with \n       // ClosedByInterruptException.\n       checkpointManager.shouldRun \u003d false;\n     }\n     if(namenode !\u003d null \u0026\u0026 getRegistration() !\u003d null) {\n       // Exclude this node from the list of backup streams on the name-node\n       try {\n         namenode.errorReport(getRegistration(), NamenodeProtocol.FATAL,\n             \"Shutting down.\");\n       } catch(IOException e) {\n         LOG.error(\"Failed to report to name-node.\", e);\n       }\n     }\n     // Stop the RPC client\n     if (namenode !\u003d null) {\n-      IOUtils.cleanup(LOG, namenode);\n+      RPC.stopProxy(namenode);\n     }\n     namenode \u003d null;\n     // Stop the checkpoint manager\n     if(checkpointManager !\u003d null) {\n       checkpointManager.interrupt();\n       checkpointManager \u003d null;\n     }\n \n     // Abort current log segment - otherwise the NN shutdown code\n     // will close it gracefully, which is incorrect.\n     getFSImage().getEditLog().abortCurrentLogSegment();\n \n     // Stop name-node threads\n     super.stop();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void stop() {\n    if(checkpointManager !\u003d null) {\n      // Prevent from starting a new checkpoint.\n      // Checkpoints that has already been started may proceed until \n      // the error reporting to the name-node is complete.\n      // Checkpoint manager should not be interrupted yet because it will\n      // close storage file channels and the checkpoint may fail with \n      // ClosedByInterruptException.\n      checkpointManager.shouldRun \u003d false;\n    }\n    if(namenode !\u003d null \u0026\u0026 getRegistration() !\u003d null) {\n      // Exclude this node from the list of backup streams on the name-node\n      try {\n        namenode.errorReport(getRegistration(), NamenodeProtocol.FATAL,\n            \"Shutting down.\");\n      } catch(IOException e) {\n        LOG.error(\"Failed to report to name-node.\", e);\n      }\n    }\n    // Stop the RPC client\n    if (namenode !\u003d null) {\n      RPC.stopProxy(namenode);\n    }\n    namenode \u003d null;\n    // Stop the checkpoint manager\n    if(checkpointManager !\u003d null) {\n      checkpointManager.interrupt();\n      checkpointManager \u003d null;\n    }\n\n    // Abort current log segment - otherwise the NN shutdown code\n    // will close it gracefully, which is incorrect.\n    getFSImage().getEditLog().abortCurrentLogSegment();\n\n    // Stop name-node threads\n    super.stop();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java",
      "extendedDetails": {}
    },
    "fa6033a029aeb04ebb0b6221bdc9e6e06c1bf0ba": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2768. BackupNode stop can not close proxy connections because it is not a proxy instance. Contributed by Uma Maheswara Rao G.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1233584 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/01/12 1:41 PM",
      "commitName": "fa6033a029aeb04ebb0b6221bdc9e6e06c1bf0ba",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "10/01/12 6:54 PM",
      "commitNameOld": "8faf7e8fb6e4024b03ce5f938daba626f2f5357c",
      "commitAuthorOld": "Jitendra Nath Pandey",
      "daysBetweenCommits": 8.78,
      "commitsBetweenForRepo": 34,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,32 @@\n   public void stop() {\n     if(checkpointManager !\u003d null) {\n       // Prevent from starting a new checkpoint.\n       // Checkpoints that has already been started may proceed until \n       // the error reporting to the name-node is complete.\n       // Checkpoint manager should not be interrupted yet because it will\n       // close storage file channels and the checkpoint may fail with \n       // ClosedByInterruptException.\n       checkpointManager.shouldRun \u003d false;\n     }\n     if(namenode !\u003d null \u0026\u0026 getRegistration() !\u003d null) {\n       // Exclude this node from the list of backup streams on the name-node\n       try {\n         namenode.errorReport(getRegistration(), NamenodeProtocol.FATAL,\n             \"Shutting down.\");\n       } catch(IOException e) {\n         LOG.error(\"Failed to report to name-node.\", e);\n       }\n     }\n     // Stop the RPC client\n     if (namenode !\u003d null) {\n-      RPC.stopProxy(namenode);\n+      IOUtils.cleanup(LOG, namenode);\n     }\n     namenode \u003d null;\n     // Stop the checkpoint manager\n     if(checkpointManager !\u003d null) {\n       checkpointManager.interrupt();\n       checkpointManager \u003d null;\n     }\n     // Stop name-node threads\n     super.stop();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void stop() {\n    if(checkpointManager !\u003d null) {\n      // Prevent from starting a new checkpoint.\n      // Checkpoints that has already been started may proceed until \n      // the error reporting to the name-node is complete.\n      // Checkpoint manager should not be interrupted yet because it will\n      // close storage file channels and the checkpoint may fail with \n      // ClosedByInterruptException.\n      checkpointManager.shouldRun \u003d false;\n    }\n    if(namenode !\u003d null \u0026\u0026 getRegistration() !\u003d null) {\n      // Exclude this node from the list of backup streams on the name-node\n      try {\n        namenode.errorReport(getRegistration(), NamenodeProtocol.FATAL,\n            \"Shutting down.\");\n      } catch(IOException e) {\n        LOG.error(\"Failed to report to name-node.\", e);\n      }\n    }\n    // Stop the RPC client\n    if (namenode !\u003d null) {\n      IOUtils.cleanup(LOG, namenode);\n    }\n    namenode \u003d null;\n    // Stop the checkpoint manager\n    if(checkpointManager !\u003d null) {\n      checkpointManager.interrupt();\n      checkpointManager \u003d null;\n    }\n    // Stop name-node threads\n    super.stop();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java",
      "extendedDetails": {}
    },
    "371f4228e86f5ebffb3d8647fb30b8bdc2b777c4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2684. Fix up some failing unit tests on HA branch. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1215241 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/12/11 10:36 AM",
      "commitName": "371f4228e86f5ebffb3d8647fb30b8bdc2b777c4",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "14/12/11 12:56 AM",
      "commitNameOld": "7e8accd68ebfe67455e1b8d223691a6c0242c18b",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 2.4,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,37 @@\n   public void stop() {\n     if(checkpointManager !\u003d null) {\n       // Prevent from starting a new checkpoint.\n       // Checkpoints that has already been started may proceed until \n       // the error reporting to the name-node is complete.\n       // Checkpoint manager should not be interrupted yet because it will\n       // close storage file channels and the checkpoint may fail with \n       // ClosedByInterruptException.\n       checkpointManager.shouldRun \u003d false;\n     }\n     if(namenode !\u003d null \u0026\u0026 getRegistration() !\u003d null) {\n       // Exclude this node from the list of backup streams on the name-node\n       try {\n         namenode.errorReport(getRegistration(), NamenodeProtocol.FATAL,\n             \"Shutting down.\");\n       } catch(IOException e) {\n         LOG.error(\"Failed to report to name-node.\", e);\n       }\n     }\n     // Stop the RPC client\n     if (namenode !\u003d null) {\n       RPC.stopProxy(namenode);\n     }\n     namenode \u003d null;\n     // Stop the checkpoint manager\n     if(checkpointManager !\u003d null) {\n       checkpointManager.interrupt();\n       checkpointManager \u003d null;\n     }\n+\n+    // Abort current log segment - otherwise the NN shutdown code\n+    // will close it gracefully, which is incorrect.\n+    getFSImage().getEditLog().abortCurrentLogSegment();\n+\n     // Stop name-node threads\n     super.stop();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void stop() {\n    if(checkpointManager !\u003d null) {\n      // Prevent from starting a new checkpoint.\n      // Checkpoints that has already been started may proceed until \n      // the error reporting to the name-node is complete.\n      // Checkpoint manager should not be interrupted yet because it will\n      // close storage file channels and the checkpoint may fail with \n      // ClosedByInterruptException.\n      checkpointManager.shouldRun \u003d false;\n    }\n    if(namenode !\u003d null \u0026\u0026 getRegistration() !\u003d null) {\n      // Exclude this node from the list of backup streams on the name-node\n      try {\n        namenode.errorReport(getRegistration(), NamenodeProtocol.FATAL,\n            \"Shutting down.\");\n      } catch(IOException e) {\n        LOG.error(\"Failed to report to name-node.\", e);\n      }\n    }\n    // Stop the RPC client\n    if (namenode !\u003d null) {\n      RPC.stopProxy(namenode);\n    }\n    namenode \u003d null;\n    // Stop the checkpoint manager\n    if(checkpointManager !\u003d null) {\n      checkpointManager.interrupt();\n      checkpointManager \u003d null;\n    }\n\n    // Abort current log segment - otherwise the NN shutdown code\n    // will close it gracefully, which is incorrect.\n    getFSImage().getEditLog().abortCurrentLogSegment();\n\n    // Stop name-node threads\n    super.stop();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java",
      "extendedDetails": {}
    },
    "0920056f0467bcf055628bc23d91c602aac7da49": {
      "type": "Ybodychange",
      "commitMessage": "\tHDFS-2481 Unknown protocol: org.apache.hadoop.hdfs.protocol.ClientProtocol (sanjay)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1188300 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/10/11 12:08 PM",
      "commitName": "0920056f0467bcf055628bc23d91c602aac7da49",
      "commitAuthor": "Sanjay Radia",
      "commitDateOld": "20/10/11 9:31 AM",
      "commitNameOld": "520d2502c52ec60f8ba66d6bd8b7c812e2941bba",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 4.11,
      "commitsBetweenForRepo": 24,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,32 @@\n   public void stop() {\n     if(checkpointManager !\u003d null) {\n       // Prevent from starting a new checkpoint.\n       // Checkpoints that has already been started may proceed until \n       // the error reporting to the name-node is complete.\n       // Checkpoint manager should not be interrupted yet because it will\n       // close storage file channels and the checkpoint may fail with \n       // ClosedByInterruptException.\n       checkpointManager.shouldRun \u003d false;\n     }\n     if(namenode !\u003d null \u0026\u0026 getRegistration() !\u003d null) {\n       // Exclude this node from the list of backup streams on the name-node\n       try {\n         namenode.errorReport(getRegistration(), NamenodeProtocol.FATAL,\n             \"Shutting down.\");\n       } catch(IOException e) {\n         LOG.error(\"Failed to report to name-node.\", e);\n       }\n     }\n     // Stop the RPC client\n-    RPC.stopProxy(namenode);\n+    if (namenode !\u003d null) {\n+      RPC.stopProxy(namenode);\n+    }\n     namenode \u003d null;\n     // Stop the checkpoint manager\n     if(checkpointManager !\u003d null) {\n       checkpointManager.interrupt();\n       checkpointManager \u003d null;\n     }\n     // Stop name-node threads\n     super.stop();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void stop() {\n    if(checkpointManager !\u003d null) {\n      // Prevent from starting a new checkpoint.\n      // Checkpoints that has already been started may proceed until \n      // the error reporting to the name-node is complete.\n      // Checkpoint manager should not be interrupted yet because it will\n      // close storage file channels and the checkpoint may fail with \n      // ClosedByInterruptException.\n      checkpointManager.shouldRun \u003d false;\n    }\n    if(namenode !\u003d null \u0026\u0026 getRegistration() !\u003d null) {\n      // Exclude this node from the list of backup streams on the name-node\n      try {\n        namenode.errorReport(getRegistration(), NamenodeProtocol.FATAL,\n            \"Shutting down.\");\n      } catch(IOException e) {\n        LOG.error(\"Failed to report to name-node.\", e);\n      }\n    }\n    // Stop the RPC client\n    if (namenode !\u003d null) {\n      RPC.stopProxy(namenode);\n    }\n    namenode \u003d null;\n    // Stop the checkpoint manager\n    if(checkpointManager !\u003d null) {\n      checkpointManager.interrupt();\n      checkpointManager \u003d null;\n    }\n    // Stop name-node threads\n    super.stop();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void stop() {\n    if(checkpointManager !\u003d null) {\n      // Prevent from starting a new checkpoint.\n      // Checkpoints that has already been started may proceed until \n      // the error reporting to the name-node is complete.\n      // Checkpoint manager should not be interrupted yet because it will\n      // close storage file channels and the checkpoint may fail with \n      // ClosedByInterruptException.\n      checkpointManager.shouldRun \u003d false;\n    }\n    if(namenode !\u003d null \u0026\u0026 getRegistration() !\u003d null) {\n      // Exclude this node from the list of backup streams on the name-node\n      try {\n        namenode.errorReport(getRegistration(), NamenodeProtocol.FATAL,\n            \"Shutting down.\");\n      } catch(IOException e) {\n        LOG.error(\"Failed to report to name-node.\", e);\n      }\n    }\n    // Stop the RPC client\n    RPC.stopProxy(namenode);\n    namenode \u003d null;\n    // Stop the checkpoint manager\n    if(checkpointManager !\u003d null) {\n      checkpointManager.interrupt();\n      checkpointManager \u003d null;\n    }\n    // Stop name-node threads\n    super.stop();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void stop() {\n    if(checkpointManager !\u003d null) {\n      // Prevent from starting a new checkpoint.\n      // Checkpoints that has already been started may proceed until \n      // the error reporting to the name-node is complete.\n      // Checkpoint manager should not be interrupted yet because it will\n      // close storage file channels and the checkpoint may fail with \n      // ClosedByInterruptException.\n      checkpointManager.shouldRun \u003d false;\n    }\n    if(namenode !\u003d null \u0026\u0026 getRegistration() !\u003d null) {\n      // Exclude this node from the list of backup streams on the name-node\n      try {\n        namenode.errorReport(getRegistration(), NamenodeProtocol.FATAL,\n            \"Shutting down.\");\n      } catch(IOException e) {\n        LOG.error(\"Failed to report to name-node.\", e);\n      }\n    }\n    // Stop the RPC client\n    RPC.stopProxy(namenode);\n    namenode \u003d null;\n    // Stop the checkpoint manager\n    if(checkpointManager !\u003d null) {\n      checkpointManager.interrupt();\n      checkpointManager \u003d null;\n    }\n    // Stop name-node threads\n    super.stop();\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,30 @@\n+  public void stop() {\n+    if(checkpointManager !\u003d null) {\n+      // Prevent from starting a new checkpoint.\n+      // Checkpoints that has already been started may proceed until \n+      // the error reporting to the name-node is complete.\n+      // Checkpoint manager should not be interrupted yet because it will\n+      // close storage file channels and the checkpoint may fail with \n+      // ClosedByInterruptException.\n+      checkpointManager.shouldRun \u003d false;\n+    }\n+    if(namenode !\u003d null \u0026\u0026 getRegistration() !\u003d null) {\n+      // Exclude this node from the list of backup streams on the name-node\n+      try {\n+        namenode.errorReport(getRegistration(), NamenodeProtocol.FATAL,\n+            \"Shutting down.\");\n+      } catch(IOException e) {\n+        LOG.error(\"Failed to report to name-node.\", e);\n+      }\n+    }\n+    // Stop the RPC client\n+    RPC.stopProxy(namenode);\n+    namenode \u003d null;\n+    // Stop the checkpoint manager\n+    if(checkpointManager !\u003d null) {\n+      checkpointManager.interrupt();\n+      checkpointManager \u003d null;\n+    }\n+    // Stop name-node threads\n+    super.stop();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void stop() {\n    if(checkpointManager !\u003d null) {\n      // Prevent from starting a new checkpoint.\n      // Checkpoints that has already been started may proceed until \n      // the error reporting to the name-node is complete.\n      // Checkpoint manager should not be interrupted yet because it will\n      // close storage file channels and the checkpoint may fail with \n      // ClosedByInterruptException.\n      checkpointManager.shouldRun \u003d false;\n    }\n    if(namenode !\u003d null \u0026\u0026 getRegistration() !\u003d null) {\n      // Exclude this node from the list of backup streams on the name-node\n      try {\n        namenode.errorReport(getRegistration(), NamenodeProtocol.FATAL,\n            \"Shutting down.\");\n      } catch(IOException e) {\n        LOG.error(\"Failed to report to name-node.\", e);\n      }\n    }\n    // Stop the RPC client\n    RPC.stopProxy(namenode);\n    namenode \u003d null;\n    // Stop the checkpoint manager\n    if(checkpointManager !\u003d null) {\n      checkpointManager.interrupt();\n      checkpointManager \u003d null;\n    }\n    // Stop name-node threads\n    super.stop();\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/BackupNode.java"
    }
  }
}