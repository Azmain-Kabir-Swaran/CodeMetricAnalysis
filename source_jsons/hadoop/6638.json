{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSEditLogOp.java",
  "functionName": "readFields",
  "functionId": "readFields___in-DataInputStream__logVersion-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
  "functionStartLine": 4076,
  "functionEndLine": 4079,
  "numCommitsSeen": 109,
  "timeTaken": 8644,
  "changeHistory": [
    "37207b75d4b83f7c032dc446d5c7e578f5b7e93a",
    "4f9bbaa301194e3d20972a10f51638c7f4d121f0",
    "09b8ce5b442489739694a2ebac4e342f6d2e2ac0",
    "4563ba08e75ecf09afe0d803b731fdde0657101b",
    "c3b56ed1c869ff225e549a1a3abc032209103195",
    "69e5f90e9febf37d2cdd69c485729c448ac3cabc",
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2",
    "ecffab63af630dac6e51fd2ccf225bf40d31b157",
    "40f8b7dcfb72727558ebed99f68f6fec368546e5",
    "4cccdc2a96b90c9e46e801b12b03788c1b16ecb7",
    "e75424544ff60d38575cde580fdae1a17f7a7289",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
    "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "37207b75d4b83f7c032dc446d5c7e578f5b7e93a": "Ybodychange",
    "4f9bbaa301194e3d20972a10f51638c7f4d121f0": "Ybodychange",
    "09b8ce5b442489739694a2ebac4e342f6d2e2ac0": "Ybodychange",
    "4563ba08e75ecf09afe0d803b731fdde0657101b": "Ybodychange",
    "c3b56ed1c869ff225e549a1a3abc032209103195": "Ybodychange",
    "69e5f90e9febf37d2cdd69c485729c448ac3cabc": "Ybodychange",
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2": "Ybodychange",
    "ecffab63af630dac6e51fd2ccf225bf40d31b157": "Ybodychange",
    "40f8b7dcfb72727558ebed99f68f6fec368546e5": "Ybodychange",
    "4cccdc2a96b90c9e46e801b12b03788c1b16ecb7": "Ybodychange",
    "e75424544ff60d38575cde580fdae1a17f7a7289": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": "Ybodychange",
    "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea": "Ymultichange(Ymodifierchange,Ybodychange)",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "37207b75d4b83f7c032dc446d5c7e578f5b7e93a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6835. Archival Storage: Add a new API to set storage policy. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-6584@1617568 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/08/14 12:32 PM",
      "commitName": "37207b75d4b83f7c032dc446d5c7e578f5b7e93a",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "23/07/14 12:05 PM",
      "commitNameOld": "5343b43fd989ec596afed807ddce29ad96c23e2d",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 20.02,
      "commitsBetweenForRepo": 135,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,5 @@\n-    void readFields(DataInputStream in, int logVersion) throws IOException {\n-      time \u003d in.readLong();\n+    void readFields(DataInputStream in, int logVersion)\n+        throws IOException {\n+      this.path \u003d FSImageSerialization.readString(in);\n+      this.policyId \u003d in.readByte();\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void readFields(DataInputStream in, int logVersion)\n        throws IOException {\n      this.path \u003d FSImageSerialization.readString(in);\n      this.policyId \u003d in.readByte();\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "4f9bbaa301194e3d20972a10f51638c7f4d121f0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5889. When starting rolling upgrade, create a fs image for rollback so that the standby namenode can create checkpoints during upgrade.  Contributed by szetszwo \u0026 jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1567861 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/02/14 12:04 AM",
      "commitName": "4f9bbaa301194e3d20972a10f51638c7f4d121f0",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "30/01/14 7:21 PM",
      "commitNameOld": "00067895a01c66d53715b50bbcb3605efd6425f2",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 13.2,
      "commitsBetweenForRepo": 60,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,3 @@\n     void readFields(DataInputStream in, int logVersion) throws IOException {\n-      startTime \u003d in.readLong();\n+      time \u003d in.readLong();\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void readFields(DataInputStream in, int logVersion) throws IOException {\n      time \u003d in.readLong();\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "09b8ce5b442489739694a2ebac4e342f6d2e2ac0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5786. Support QUERY and FINALIZE actions of rolling upgrade.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1559304 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/01/14 6:07 PM",
      "commitName": "09b8ce5b442489739694a2ebac4e342f6d2e2ac0",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "09/01/14 10:06 PM",
      "commitNameOld": "4563ba08e75ecf09afe0d803b731fdde0657101b",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 7.83,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,2 +1,3 @@\n     void readFields(DataInputStream in, int logVersion) throws IOException {\n+      startTime \u003d in.readLong();\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void readFields(DataInputStream in, int logVersion) throws IOException {\n      startTime \u003d in.readLong();\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "4563ba08e75ecf09afe0d803b731fdde0657101b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5645. Support upgrade marker in editlog streams.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1557038 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/14 10:06 PM",
      "commitName": "4563ba08e75ecf09afe0d803b731fdde0657101b",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "17/12/13 6:46 PM",
      "commitNameOld": "504bd0bca3ebed1941bbf5407fac0636447e745b",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 23.14,
      "commitsBetweenForRepo": 80,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,2 @@\n     void readFields(DataInputStream in, int logVersion) throws IOException {\n-      poolName \u003d FSImageSerialization.readString(in);\n-      readRpcIds(in, logVersion);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void readFields(DataInputStream in, int logVersion) throws IOException {\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "c3b56ed1c869ff225e549a1a3abc032209103195": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5619. NameNode: record ACL modifications to edit log. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4685@1553224 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/12/13 2:12 PM",
      "commitName": "c3b56ed1c869ff225e549a1a3abc032209103195",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "17/12/13 6:46 PM",
      "commitNameOld": "504bd0bca3ebed1941bbf5407fac0636447e745b",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 5.81,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,5 @@\n     void readFields(DataInputStream in, int logVersion) throws IOException {\n-      poolName \u003d FSImageSerialization.readString(in);\n-      readRpcIds(in, logVersion);\n+      AclEditLogProto p \u003d AclEditLogProto.parseDelimitedFrom((DataInputStream)in);\n+      src \u003d p.getSrc();\n+      aclEntries \u003d PBHelper.convertAclEntry(p.getEntriesList());\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void readFields(DataInputStream in, int logVersion) throws IOException {\n      AclEditLogProto p \u003d AclEditLogProto.parseDelimitedFrom((DataInputStream)in);\n      src \u003d p.getSrc();\n      aclEntries \u003d PBHelper.convertAclEntry(p.getEntriesList());\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "69e5f90e9febf37d2cdd69c485729c448ac3cabc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5385. Caching RPCs are AtMostOnce, but do not persist client ID and call ID to edit log.  (Chris Nauroth via Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1534345 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/10/13 12:42 PM",
      "commitName": "69e5f90e9febf37d2cdd69c485729c448ac3cabc",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "14/10/13 3:56 PM",
      "commitNameOld": "efe545b0c219eeba61ac5259aee4d518beb74316",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 6.87,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,4 @@\n     void readFields(DataInputStream in, int logVersion) throws IOException {\n       poolName \u003d FSImageSerialization.readString(in);\n+      readRpcIds(in, logVersion);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void readFields(DataInputStream in, int logVersion) throws IOException {\n      poolName \u003d FSImageSerialization.readString(in);\n      readRpcIds(in, logVersion);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5119. Persist CacheManager state in the edit log. (Contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1529238 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/10/13 10:46 AM",
      "commitName": "af1ac9a5e8d8d97a855940d853dd59ab4666f6e2",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "30/07/13 12:51 AM",
      "commitNameOld": "8c7a7e619699386f9e6991842558d78aa0c8053d",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 66.41,
      "commitsBetweenForRepo": 271,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,3 @@\n     void readFields(DataInputStream in, int logVersion) throws IOException {\n-      snapshotRoot \u003d FSImageSerialization.readString(in);\n+      poolName \u003d FSImageSerialization.readString(in);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void readFields(DataInputStream in, int logVersion) throws IOException {\n      poolName \u003d FSImageSerialization.readString(in);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "ecffab63af630dac6e51fd2ccf225bf40d31b157": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4086. Add editlog opcodes to allow and disallow snapshots on a directory. Contributed by Brandon Li.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1400298 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/10/12 2:15 PM",
      "commitName": "ecffab63af630dac6e51fd2ccf225bf40d31b157",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "19/10/12 2:04 PM",
      "commitNameOld": "40f8b7dcfb72727558ebed99f68f6fec368546e5",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,3 @@\n     void readFields(DataInputStream in, int logVersion) throws IOException {\n-      snapshotName \u003d FSImageSerialization.readString(in);\n       snapshotRoot \u003d FSImageSerialization.readString(in);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void readFields(DataInputStream in, int logVersion) throws IOException {\n      snapshotRoot \u003d FSImageSerialization.readString(in);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "40f8b7dcfb72727558ebed99f68f6fec368546e5": {
      "type": "Ybodychange",
      "commitMessage": "Reverting the change r1400285 since it included unrelated changes\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1400290 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/10/12 2:04 PM",
      "commitName": "40f8b7dcfb72727558ebed99f68f6fec368546e5",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "19/10/12 2:01 PM",
      "commitNameOld": "4cccdc2a96b90c9e46e801b12b03788c1b16ecb7",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,3 +1,4 @@\n     void readFields(DataInputStream in, int logVersion) throws IOException {\n+      snapshotName \u003d FSImageSerialization.readString(in);\n       snapshotRoot \u003d FSImageSerialization.readString(in);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void readFields(DataInputStream in, int logVersion) throws IOException {\n      snapshotName \u003d FSImageSerialization.readString(in);\n      snapshotRoot \u003d FSImageSerialization.readString(in);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "4cccdc2a96b90c9e46e801b12b03788c1b16ecb7": {
      "type": "Ybodychange",
      "commitMessage": "Moving HDFS-2802 related changes to a separate CHANGES.txt\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1400285 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/10/12 2:01 PM",
      "commitName": "4cccdc2a96b90c9e46e801b12b03788c1b16ecb7",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "19/10/12 12:38 PM",
      "commitNameOld": "e75424544ff60d38575cde580fdae1a17f7a7289",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 0.06,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,3 @@\n     void readFields(DataInputStream in, int logVersion) throws IOException {\n-      snapshotName \u003d FSImageSerialization.readString(in);\n       snapshotRoot \u003d FSImageSerialization.readString(in);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void readFields(DataInputStream in, int logVersion) throws IOException {\n      snapshotRoot \u003d FSImageSerialization.readString(in);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "e75424544ff60d38575cde580fdae1a17f7a7289": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4082. Add editlog opcodes for snapshot create and delete operations.  Contributed by suresh\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1400247 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/10/12 12:38 PM",
      "commitName": "e75424544ff60d38575cde580fdae1a17f7a7289",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "24/08/12 6:03 PM",
      "commitNameOld": "deead78e35b0cb81af875b5a8032cbd06c9a2dae",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 55.77,
      "commitsBetweenForRepo": 332,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,4 @@\n-    void readFields(DataInputStream in, int logVersion)\n-        throws IOException {\n-      // nothing to read\n+    void readFields(DataInputStream in, int logVersion) throws IOException {\n+      snapshotName \u003d FSImageSerialization.readString(in);\n+      snapshotRoot \u003d FSImageSerialization.readString(in);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void readFields(DataInputStream in, int logVersion) throws IOException {\n      snapshotName \u003d FSImageSerialization.readString(in);\n      snapshotRoot \u003d FSImageSerialization.readString(in);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    void readFields(DataInputStream in, int logVersion)\n        throws IOException {\n      // nothing to read\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    void readFields(DataInputStream in, int logVersion)\n        throws IOException {\n      // nothing to read\n    }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java"
      }
    },
    "28e6a4e44a3e920dcaf858f9a74a6358226b3a63": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1073. Redesign the NameNode\u0027s storage layout for image checkpoints and edit logs to introduce transaction IDs and be more robust. Contributed by Todd Lipcon and Ivan Kelly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1152295 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/07/11 9:28 AM",
      "commitName": "28e6a4e44a3e920dcaf858f9a74a6358226b3a63",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "27/07/11 10:46 PM",
      "commitNameOld": "44320eed1732ea59bd9ec83009eb10e0e6f13023",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 1.45,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,4 @@\n     void readFields(DataInputStream in, int logVersion)\n         throws IOException {\n-      this.checkpointTime \u003d readLong(in);\n+      // nothing to read\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void readFields(DataInputStream in, int logVersion)\n        throws IOException {\n      // nothing to read\n    }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
      "extendedDetails": {}
    },
    "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-2149. Move EditLogOp serialization formats into FsEditLogOp implementations. Contributed by Ivan Kelly.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1151238 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/07/11 1:46 PM",
      "commitName": "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-2149. Move EditLogOp serialization formats into FsEditLogOp implementations. Contributed by Ivan Kelly.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1151238 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "26/07/11 1:46 PM",
          "commitName": "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "28/06/11 6:31 PM",
          "commitNameOld": "09b6f98de431628c80bc8a6faf0070eeaf72ff2a",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 27.8,
          "commitsBetweenForRepo": 92,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,4 @@\n-    public void readFields(DataInputStream in, int logVersion)\n+    void readFields(DataInputStream in, int logVersion)\n         throws IOException {\n-      this.key \u003d new DelegationKey();\n-      this.key.readFields(in);\n+      this.checkpointTime \u003d readLong(in);\n     }\n\\ No newline at end of file\n",
          "actualSource": "    void readFields(DataInputStream in, int logVersion)\n        throws IOException {\n      this.checkpointTime \u003d readLong(in);\n    }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2149. Move EditLogOp serialization formats into FsEditLogOp implementations. Contributed by Ivan Kelly.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1151238 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "26/07/11 1:46 PM",
          "commitName": "438c32aaf9fb0c63f55044cf5ef1b2e0adcf7fea",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "28/06/11 6:31 PM",
          "commitNameOld": "09b6f98de431628c80bc8a6faf0070eeaf72ff2a",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 27.8,
          "commitsBetweenForRepo": 92,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,4 @@\n-    public void readFields(DataInputStream in, int logVersion)\n+    void readFields(DataInputStream in, int logVersion)\n         throws IOException {\n-      this.key \u003d new DelegationKey();\n-      this.key.readFields(in);\n+      this.checkpointTime \u003d readLong(in);\n     }\n\\ No newline at end of file\n",
          "actualSource": "    void readFields(DataInputStream in, int logVersion)\n        throws IOException {\n      this.checkpointTime \u003d readLong(in);\n    }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java",
          "extendedDetails": {}
        }
      ]
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,5 @@\n+    public void readFields(DataInputStream in, int logVersion)\n+        throws IOException {\n+      this.key \u003d new DelegationKey();\n+      this.key.readFields(in);\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public void readFields(DataInputStream in, int logVersion)\n        throws IOException {\n      this.key \u003d new DelegationKey();\n      this.key.readFields(in);\n    }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java"
    }
  }
}