{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Receiver.java",
  "functionName": "processOp",
  "functionId": "processOp___op-Op",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java",
  "functionStartLine": 101,
  "functionEndLine": 136,
  "numCommitsSeen": 34,
  "timeTaken": 6047,
  "changeHistory": [
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
    "a337ceb74e984991dbf976236d2e785cf5921b16",
    "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f",
    "9a4030e0e84a688c12daa21fe9a165808c3eca70",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "2f48fae72aa52e6ec42264cad24fab36b6a426c2",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720": "Ybodychange",
    "a337ceb74e984991dbf976236d2e785cf5921b16": "Ybodychange",
    "e5ff0ea7ba087984262f1f27200ae5bb40d9b838": "Ybodychange",
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f": "Ybodychange",
    "9a4030e0e84a688c12daa21fe9a165808c3eca70": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "2f48fae72aa52e6ec42264cad24fab36b6a426c2": "Ymultichange(Yparameterchange,Ybodychange)",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\n",
      "commitDate": "26/03/16 7:58 PM",
      "commitName": "3a4ff7776e8fab6cc87932b9aa8fb48f7b69c720",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "26/03/16 9:20 AM",
      "commitNameOld": "a337ceb74e984991dbf976236d2e785cf5921b16",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 0.44,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,36 @@\n   protected final void processOp(Op op) throws IOException {\n     switch(op) {\n     case READ_BLOCK:\n       opReadBlock();\n       break;\n     case WRITE_BLOCK:\n       opWriteBlock(in);\n       break;\n     case REPLACE_BLOCK:\n       opReplaceBlock(in);\n       break;\n     case COPY_BLOCK:\n       opCopyBlock(in);\n       break;\n     case BLOCK_CHECKSUM:\n       opBlockChecksum(in);\n       break;\n+    case BLOCK_GROUP_CHECKSUM:\n+      opStripedBlockChecksum(in);\n+      break;\n     case TRANSFER_BLOCK:\n       opTransferBlock(in);\n       break;\n     case REQUEST_SHORT_CIRCUIT_FDS:\n       opRequestShortCircuitFds(in);\n       break;\n     case RELEASE_SHORT_CIRCUIT_FDS:\n       opReleaseShortCircuitFds(in);\n       break;\n     case REQUEST_SHORT_CIRCUIT_SHM:\n       opRequestShortCircuitShm(in);\n       break;\n     default:\n       throw new IOException(\"Unknown op \" + op + \" in data stream\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected final void processOp(Op op) throws IOException {\n    switch(op) {\n    case READ_BLOCK:\n      opReadBlock();\n      break;\n    case WRITE_BLOCK:\n      opWriteBlock(in);\n      break;\n    case REPLACE_BLOCK:\n      opReplaceBlock(in);\n      break;\n    case COPY_BLOCK:\n      opCopyBlock(in);\n      break;\n    case BLOCK_CHECKSUM:\n      opBlockChecksum(in);\n      break;\n    case BLOCK_GROUP_CHECKSUM:\n      opStripedBlockChecksum(in);\n      break;\n    case TRANSFER_BLOCK:\n      opTransferBlock(in);\n      break;\n    case REQUEST_SHORT_CIRCUIT_FDS:\n      opRequestShortCircuitFds(in);\n      break;\n    case RELEASE_SHORT_CIRCUIT_FDS:\n      opReleaseShortCircuitFds(in);\n      break;\n    case REQUEST_SHORT_CIRCUIT_SHM:\n      opRequestShortCircuitShm(in);\n      break;\n    default:\n      throw new IOException(\"Unknown op \" + op + \" in data stream\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java",
      "extendedDetails": {}
    },
    "a337ceb74e984991dbf976236d2e785cf5921b16": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\"\n\nThis reverts commit e5ff0ea7ba087984262f1f27200ae5bb40d9b838.\n",
      "commitDate": "26/03/16 9:20 AM",
      "commitName": "a337ceb74e984991dbf976236d2e785cf5921b16",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "26/03/16 12:52 AM",
      "commitNameOld": "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.35,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,33 @@\n   protected final void processOp(Op op) throws IOException {\n     switch(op) {\n     case READ_BLOCK:\n       opReadBlock();\n       break;\n     case WRITE_BLOCK:\n       opWriteBlock(in);\n       break;\n     case REPLACE_BLOCK:\n       opReplaceBlock(in);\n       break;\n     case COPY_BLOCK:\n       opCopyBlock(in);\n       break;\n     case BLOCK_CHECKSUM:\n       opBlockChecksum(in);\n       break;\n-    case BLOCK_GROUP_CHECKSUM:\n-      opStripedBlockChecksum(in);\n-      break;\n     case TRANSFER_BLOCK:\n       opTransferBlock(in);\n       break;\n     case REQUEST_SHORT_CIRCUIT_FDS:\n       opRequestShortCircuitFds(in);\n       break;\n     case RELEASE_SHORT_CIRCUIT_FDS:\n       opReleaseShortCircuitFds(in);\n       break;\n     case REQUEST_SHORT_CIRCUIT_SHM:\n       opRequestShortCircuitShm(in);\n       break;\n     default:\n       throw new IOException(\"Unknown op \" + op + \" in data stream\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected final void processOp(Op op) throws IOException {\n    switch(op) {\n    case READ_BLOCK:\n      opReadBlock();\n      break;\n    case WRITE_BLOCK:\n      opWriteBlock(in);\n      break;\n    case REPLACE_BLOCK:\n      opReplaceBlock(in);\n      break;\n    case COPY_BLOCK:\n      opCopyBlock(in);\n      break;\n    case BLOCK_CHECKSUM:\n      opBlockChecksum(in);\n      break;\n    case TRANSFER_BLOCK:\n      opTransferBlock(in);\n      break;\n    case REQUEST_SHORT_CIRCUIT_FDS:\n      opRequestShortCircuitFds(in);\n      break;\n    case RELEASE_SHORT_CIRCUIT_FDS:\n      opReleaseShortCircuitFds(in);\n      break;\n    case REQUEST_SHORT_CIRCUIT_SHM:\n      opRequestShortCircuitShm(in);\n      break;\n    default:\n      throw new IOException(\"Unknown op \" + op + \" in data stream\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java",
      "extendedDetails": {}
    },
    "e5ff0ea7ba087984262f1f27200ae5bb40d9b838": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9694. Make existing DFSClient#getFileChecksum() work for striped blocks. Contributed by Kai Zheng\n",
      "commitDate": "26/03/16 12:52 AM",
      "commitName": "e5ff0ea7ba087984262f1f27200ae5bb40d9b838",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "28/09/15 7:42 AM",
      "commitNameOld": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 179.72,
      "commitsBetweenForRepo": 1204,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,36 @@\n   protected final void processOp(Op op) throws IOException {\n     switch(op) {\n     case READ_BLOCK:\n       opReadBlock();\n       break;\n     case WRITE_BLOCK:\n       opWriteBlock(in);\n       break;\n     case REPLACE_BLOCK:\n       opReplaceBlock(in);\n       break;\n     case COPY_BLOCK:\n       opCopyBlock(in);\n       break;\n     case BLOCK_CHECKSUM:\n       opBlockChecksum(in);\n       break;\n+    case BLOCK_GROUP_CHECKSUM:\n+      opStripedBlockChecksum(in);\n+      break;\n     case TRANSFER_BLOCK:\n       opTransferBlock(in);\n       break;\n     case REQUEST_SHORT_CIRCUIT_FDS:\n       opRequestShortCircuitFds(in);\n       break;\n     case RELEASE_SHORT_CIRCUIT_FDS:\n       opReleaseShortCircuitFds(in);\n       break;\n     case REQUEST_SHORT_CIRCUIT_SHM:\n       opRequestShortCircuitShm(in);\n       break;\n     default:\n       throw new IOException(\"Unknown op \" + op + \" in data stream\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected final void processOp(Op op) throws IOException {\n    switch(op) {\n    case READ_BLOCK:\n      opReadBlock();\n      break;\n    case WRITE_BLOCK:\n      opWriteBlock(in);\n      break;\n    case REPLACE_BLOCK:\n      opReplaceBlock(in);\n      break;\n    case COPY_BLOCK:\n      opCopyBlock(in);\n      break;\n    case BLOCK_CHECKSUM:\n      opBlockChecksum(in);\n      break;\n    case BLOCK_GROUP_CHECKSUM:\n      opStripedBlockChecksum(in);\n      break;\n    case TRANSFER_BLOCK:\n      opTransferBlock(in);\n      break;\n    case REQUEST_SHORT_CIRCUIT_FDS:\n      opRequestShortCircuitFds(in);\n      break;\n    case RELEASE_SHORT_CIRCUIT_FDS:\n      opReleaseShortCircuitFds(in);\n      break;\n    case REQUEST_SHORT_CIRCUIT_SHM:\n      opRequestShortCircuitShm(in);\n      break;\n    default:\n      throw new IOException(\"Unknown op \" + op + \" in data stream\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java",
      "extendedDetails": {}
    },
    "dd049a2f6097da189ccce2f5890a2b9bc77fa73f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5950. The DFSClient and DataNode should use shared memory segments to communicate short-circuit information (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1573433 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/03/14 7:58 PM",
      "commitName": "dd049a2f6097da189ccce2f5890a2b9bc77fa73f",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "22/07/13 11:15 AM",
      "commitNameOld": "c1314eb2a382bd9ce045a2fcc4a9e5c1fc368a24",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 223.41,
      "commitsBetweenForRepo": 1453,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,33 @@\n   protected final void processOp(Op op) throws IOException {\n     switch(op) {\n     case READ_BLOCK:\n       opReadBlock();\n       break;\n     case WRITE_BLOCK:\n       opWriteBlock(in);\n       break;\n     case REPLACE_BLOCK:\n       opReplaceBlock(in);\n       break;\n     case COPY_BLOCK:\n       opCopyBlock(in);\n       break;\n     case BLOCK_CHECKSUM:\n       opBlockChecksum(in);\n       break;\n     case TRANSFER_BLOCK:\n       opTransferBlock(in);\n       break;\n     case REQUEST_SHORT_CIRCUIT_FDS:\n       opRequestShortCircuitFds(in);\n       break;\n+    case RELEASE_SHORT_CIRCUIT_FDS:\n+      opReleaseShortCircuitFds(in);\n+      break;\n+    case REQUEST_SHORT_CIRCUIT_SHM:\n+      opRequestShortCircuitShm(in);\n+      break;\n     default:\n       throw new IOException(\"Unknown op \" + op + \" in data stream\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected final void processOp(Op op) throws IOException {\n    switch(op) {\n    case READ_BLOCK:\n      opReadBlock();\n      break;\n    case WRITE_BLOCK:\n      opWriteBlock(in);\n      break;\n    case REPLACE_BLOCK:\n      opReplaceBlock(in);\n      break;\n    case COPY_BLOCK:\n      opCopyBlock(in);\n      break;\n    case BLOCK_CHECKSUM:\n      opBlockChecksum(in);\n      break;\n    case TRANSFER_BLOCK:\n      opTransferBlock(in);\n      break;\n    case REQUEST_SHORT_CIRCUIT_FDS:\n      opRequestShortCircuitFds(in);\n      break;\n    case RELEASE_SHORT_CIRCUIT_FDS:\n      opReleaseShortCircuitFds(in);\n      break;\n    case REQUEST_SHORT_CIRCUIT_SHM:\n      opRequestShortCircuitShm(in);\n      break;\n    default:\n      throw new IOException(\"Unknown op \" + op + \" in data stream\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java",
      "extendedDetails": {}
    },
    "9a4030e0e84a688c12daa21fe9a165808c3eca70": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4356. BlockReaderLocal should use passed file descriptors rather than paths. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-347@1432335 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/01/13 3:52 PM",
      "commitName": "9a4030e0e84a688c12daa21fe9a165808c3eca70",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "07/08/12 9:40 AM",
      "commitNameOld": "9b4a7900c7dfc0590316eedaa97144f938885651",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 157.3,
      "commitsBetweenForRepo": 828,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,27 @@\n   protected final void processOp(Op op) throws IOException {\n     switch(op) {\n     case READ_BLOCK:\n       opReadBlock();\n       break;\n     case WRITE_BLOCK:\n       opWriteBlock(in);\n       break;\n     case REPLACE_BLOCK:\n       opReplaceBlock(in);\n       break;\n     case COPY_BLOCK:\n       opCopyBlock(in);\n       break;\n     case BLOCK_CHECKSUM:\n       opBlockChecksum(in);\n       break;\n     case TRANSFER_BLOCK:\n       opTransferBlock(in);\n       break;\n+    case REQUEST_SHORT_CIRCUIT_FDS:\n+      opRequestShortCircuitFds(in);\n+      break;\n     default:\n       throw new IOException(\"Unknown op \" + op + \" in data stream\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected final void processOp(Op op) throws IOException {\n    switch(op) {\n    case READ_BLOCK:\n      opReadBlock();\n      break;\n    case WRITE_BLOCK:\n      opWriteBlock(in);\n      break;\n    case REPLACE_BLOCK:\n      opReplaceBlock(in);\n      break;\n    case COPY_BLOCK:\n      opCopyBlock(in);\n      break;\n    case BLOCK_CHECKSUM:\n      opBlockChecksum(in);\n      break;\n    case TRANSFER_BLOCK:\n      opTransferBlock(in);\n      break;\n    case REQUEST_SHORT_CIRCUIT_FDS:\n      opRequestShortCircuitFds(in);\n      break;\n    default:\n      throw new IOException(\"Unknown op \" + op + \" in data stream\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected final void processOp(Op op) throws IOException {\n    switch(op) {\n    case READ_BLOCK:\n      opReadBlock();\n      break;\n    case WRITE_BLOCK:\n      opWriteBlock(in);\n      break;\n    case REPLACE_BLOCK:\n      opReplaceBlock(in);\n      break;\n    case COPY_BLOCK:\n      opCopyBlock(in);\n      break;\n    case BLOCK_CHECKSUM:\n      opBlockChecksum(in);\n      break;\n    case TRANSFER_BLOCK:\n      opTransferBlock(in);\n      break;\n    default:\n      throw new IOException(\"Unknown op \" + op + \" in data stream\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected final void processOp(Op op) throws IOException {\n    switch(op) {\n    case READ_BLOCK:\n      opReadBlock();\n      break;\n    case WRITE_BLOCK:\n      opWriteBlock(in);\n      break;\n    case REPLACE_BLOCK:\n      opReplaceBlock(in);\n      break;\n    case COPY_BLOCK:\n      opCopyBlock(in);\n      break;\n    case BLOCK_CHECKSUM:\n      opBlockChecksum(in);\n      break;\n    case TRANSFER_BLOCK:\n      opTransferBlock(in);\n      break;\n    default:\n      throw new IOException(\"Unknown op \" + op + \" in data stream\");\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java"
      }
    },
    "2f48fae72aa52e6ec42264cad24fab36b6a426c2": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-2087. Declare methods in DataTransferProtocol interface, and change Sender and Receiver to implement the interface.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1139124 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/06/11 4:57 PM",
      "commitName": "2f48fae72aa52e6ec42264cad24fab36b6a426c2",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2087. Declare methods in DataTransferProtocol interface, and change Sender and Receiver to implement the interface.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1139124 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/06/11 4:57 PM",
          "commitName": "2f48fae72aa52e6ec42264cad24fab36b6a426c2",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "12/06/11 3:00 PM",
          "commitNameOld": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 11.08,
          "commitsBetweenForRepo": 38,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,24 @@\n-  protected final void processOp(Op op, DataInputStream in\n-      ) throws IOException {\n+  protected final void processOp(Op op) throws IOException {\n     switch(op) {\n     case READ_BLOCK:\n-      opReadBlock(in);\n+      opReadBlock();\n       break;\n     case WRITE_BLOCK:\n       opWriteBlock(in);\n       break;\n     case REPLACE_BLOCK:\n       opReplaceBlock(in);\n       break;\n     case COPY_BLOCK:\n       opCopyBlock(in);\n       break;\n     case BLOCK_CHECKSUM:\n       opBlockChecksum(in);\n       break;\n     case TRANSFER_BLOCK:\n       opTransferBlock(in);\n       break;\n     default:\n       throw new IOException(\"Unknown op \" + op + \" in data stream\");\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected final void processOp(Op op) throws IOException {\n    switch(op) {\n    case READ_BLOCK:\n      opReadBlock();\n      break;\n    case WRITE_BLOCK:\n      opWriteBlock(in);\n      break;\n    case REPLACE_BLOCK:\n      opReplaceBlock(in);\n      break;\n    case COPY_BLOCK:\n      opCopyBlock(in);\n      break;\n    case BLOCK_CHECKSUM:\n      opBlockChecksum(in);\n      break;\n    case TRANSFER_BLOCK:\n      opTransferBlock(in);\n      break;\n    default:\n      throw new IOException(\"Unknown op \" + op + \" in data stream\");\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java",
          "extendedDetails": {
            "oldValue": "[op-Op, in-DataInputStream]",
            "newValue": "[op-Op]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2087. Declare methods in DataTransferProtocol interface, and change Sender and Receiver to implement the interface.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1139124 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/06/11 4:57 PM",
          "commitName": "2f48fae72aa52e6ec42264cad24fab36b6a426c2",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "12/06/11 3:00 PM",
          "commitNameOld": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 11.08,
          "commitsBetweenForRepo": 38,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,25 +1,24 @@\n-  protected final void processOp(Op op, DataInputStream in\n-      ) throws IOException {\n+  protected final void processOp(Op op) throws IOException {\n     switch(op) {\n     case READ_BLOCK:\n-      opReadBlock(in);\n+      opReadBlock();\n       break;\n     case WRITE_BLOCK:\n       opWriteBlock(in);\n       break;\n     case REPLACE_BLOCK:\n       opReplaceBlock(in);\n       break;\n     case COPY_BLOCK:\n       opCopyBlock(in);\n       break;\n     case BLOCK_CHECKSUM:\n       opBlockChecksum(in);\n       break;\n     case TRANSFER_BLOCK:\n       opTransferBlock(in);\n       break;\n     default:\n       throw new IOException(\"Unknown op \" + op + \" in data stream\");\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected final void processOp(Op op) throws IOException {\n    switch(op) {\n    case READ_BLOCK:\n      opReadBlock();\n      break;\n    case WRITE_BLOCK:\n      opWriteBlock(in);\n      break;\n    case REPLACE_BLOCK:\n      opReplaceBlock(in);\n      break;\n    case COPY_BLOCK:\n      opCopyBlock(in);\n      break;\n    case BLOCK_CHECKSUM:\n      opBlockChecksum(in);\n      break;\n    case TRANSFER_BLOCK:\n      opTransferBlock(in);\n      break;\n    default:\n      throw new IOException(\"Unknown op \" + op + \" in data stream\");\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java",
          "extendedDetails": {}
        }
      ]
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,25 @@\n+  protected final void processOp(Op op, DataInputStream in\n+      ) throws IOException {\n+    switch(op) {\n+    case READ_BLOCK:\n+      opReadBlock(in);\n+      break;\n+    case WRITE_BLOCK:\n+      opWriteBlock(in);\n+      break;\n+    case REPLACE_BLOCK:\n+      opReplaceBlock(in);\n+      break;\n+    case COPY_BLOCK:\n+      opCopyBlock(in);\n+      break;\n+    case BLOCK_CHECKSUM:\n+      opBlockChecksum(in);\n+      break;\n+    case TRANSFER_BLOCK:\n+      opTransferBlock(in);\n+      break;\n+    default:\n+      throw new IOException(\"Unknown op \" + op + \" in data stream\");\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected final void processOp(Op op, DataInputStream in\n      ) throws IOException {\n    switch(op) {\n    case READ_BLOCK:\n      opReadBlock(in);\n      break;\n    case WRITE_BLOCK:\n      opWriteBlock(in);\n      break;\n    case REPLACE_BLOCK:\n      opReplaceBlock(in);\n      break;\n    case COPY_BLOCK:\n      opCopyBlock(in);\n      break;\n    case BLOCK_CHECKSUM:\n      opBlockChecksum(in);\n      break;\n    case TRANSFER_BLOCK:\n      opTransferBlock(in);\n      break;\n    default:\n      throw new IOException(\"Unknown op \" + op + \" in data stream\");\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/protocol/datatransfer/Receiver.java"
    }
  }
}