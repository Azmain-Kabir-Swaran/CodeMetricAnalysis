{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSAdmin.java",
  "functionName": "saveNamespace",
  "functionId": "saveNamespace___argv-String[]",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
  "functionStartLine": 806,
  "functionEndLine": 866,
  "numCommitsSeen": 179,
  "timeTaken": 8722,
  "changeHistory": [
    "01bd6ab18fa48f4c7cac1497905b52e547962599",
    "d37dc5d1b8e022a7085118a2e7066623483c293f",
    "b9936689c9ea37bf0050e7970643bcddfc9cfdbe",
    "6f8003dc7bc9e8be7b0512c514d370c303faf003",
    "5e21e4ca377f68e030f8f3436cd93fd7a74dc5e0",
    "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "01bd6ab18fa48f4c7cac1497905b52e547962599": "Ybodychange",
    "d37dc5d1b8e022a7085118a2e7066623483c293f": "Ybodychange",
    "b9936689c9ea37bf0050e7970643bcddfc9cfdbe": "Ybodychange",
    "6f8003dc7bc9e8be7b0512c514d370c303faf003": "Ybodychange",
    "5e21e4ca377f68e030f8f3436cd93fd7a74dc5e0": "Ymultichange(Yparameterchange,Ybodychange)",
    "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "01bd6ab18fa48f4c7cac1497905b52e547962599": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12935. Get ambiguous result for DFSAdmin command in HA mode when only one namenode is up. Contributed by Jianfei Jiang.\n",
      "commitDate": "07/02/18 9:40 AM",
      "commitName": "01bd6ab18fa48f4c7cac1497905b52e547962599",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "05/01/18 10:31 PM",
      "commitNameOld": "bf5c94899537011465350d5d999fad9ffaeb605d",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 32.46,
      "commitsBetweenForRepo": 204,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,51 +1,61 @@\n   public int saveNamespace(String[] argv) throws IOException {\n     final DistributedFileSystem dfs \u003d getDFS();\n     final Configuration dfsConf \u003d dfs.getConf();\n \n     long timeWindow \u003d 0;\n     long txGap \u003d 0;\n     if (argv.length \u003e 1 \u0026\u0026 \"-beforeShutdown\".equals(argv[1])) {\n       final long checkpointPeriod \u003d dfsConf.getTimeDuration(\n           DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n           DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT,\n           TimeUnit.SECONDS);\n       final long checkpointTxnCount \u003d dfsConf.getLong(\n           DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n           DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n       final int toleratePeriodNum \u003d dfsConf.getInt(\n           DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_KEY,\n           DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_DEFAULT);\n       timeWindow \u003d checkpointPeriod * toleratePeriodNum;\n       txGap \u003d checkpointTxnCount * toleratePeriodNum;\n       System.out.println(\"Do checkpoint if necessary before stopping \" +\n           \"namenode. The time window is \" + timeWindow + \" seconds, and the \" +\n           \"transaction gap is \" + txGap);\n     }\n \n     URI dfsUri \u003d dfs.getUri();\n     boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(dfsConf, dfsUri);\n     if (isHaEnabled) {\n       String nsId \u003d dfsUri.getHost();\n       List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n           HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n           nsId, ClientProtocol.class);\n+      List\u003cIOException\u003e exceptions \u003d new ArrayList\u003c\u003e();\n       for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n-        boolean saved \u003d proxy.getProxy().saveNamespace(timeWindow, txGap);\n-        if (saved) {\n-          System.out.println(\"Save namespace successful for \" +\n+        try{\n+          boolean saved \u003d proxy.getProxy().saveNamespace(timeWindow, txGap);\n+          if (saved) {\n+            System.out.println(\"Save namespace successful for \" +\n+                proxy.getAddress());\n+          } else {\n+            System.out.println(\"No extra checkpoint has been made for \"\n+                + proxy.getAddress());\n+          }\n+        }catch (IOException ioe){\n+          System.out.println(\"Save namespace failed for \" +\n               proxy.getAddress());\n-        } else {\n-          System.out.println(\"No extra checkpoint has been made for \"\n-              + proxy.getAddress());\n+          exceptions.add(ioe);\n         }\n       }\n+      if(!exceptions.isEmpty()){\n+        throw MultipleIOException.createIOException(exceptions);\n+      }\n     } else {\n       boolean saved \u003d dfs.saveNamespace(timeWindow, txGap);\n       if (saved) {\n         System.out.println(\"Save namespace successful\");\n       } else {\n         System.out.println(\"No extra checkpoint has been made\");\n       }\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int saveNamespace(String[] argv) throws IOException {\n    final DistributedFileSystem dfs \u003d getDFS();\n    final Configuration dfsConf \u003d dfs.getConf();\n\n    long timeWindow \u003d 0;\n    long txGap \u003d 0;\n    if (argv.length \u003e 1 \u0026\u0026 \"-beforeShutdown\".equals(argv[1])) {\n      final long checkpointPeriod \u003d dfsConf.getTimeDuration(\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT,\n          TimeUnit.SECONDS);\n      final long checkpointTxnCount \u003d dfsConf.getLong(\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n      final int toleratePeriodNum \u003d dfsConf.getInt(\n          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_KEY,\n          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_DEFAULT);\n      timeWindow \u003d checkpointPeriod * toleratePeriodNum;\n      txGap \u003d checkpointTxnCount * toleratePeriodNum;\n      System.out.println(\"Do checkpoint if necessary before stopping \" +\n          \"namenode. The time window is \" + timeWindow + \" seconds, and the \" +\n          \"transaction gap is \" + txGap);\n    }\n\n    URI dfsUri \u003d dfs.getUri();\n    boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(dfsConf, dfsUri);\n    if (isHaEnabled) {\n      String nsId \u003d dfsUri.getHost();\n      List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n          HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n          nsId, ClientProtocol.class);\n      List\u003cIOException\u003e exceptions \u003d new ArrayList\u003c\u003e();\n      for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n        try{\n          boolean saved \u003d proxy.getProxy().saveNamespace(timeWindow, txGap);\n          if (saved) {\n            System.out.println(\"Save namespace successful for \" +\n                proxy.getAddress());\n          } else {\n            System.out.println(\"No extra checkpoint has been made for \"\n                + proxy.getAddress());\n          }\n        }catch (IOException ioe){\n          System.out.println(\"Save namespace failed for \" +\n              proxy.getAddress());\n          exceptions.add(ioe);\n        }\n      }\n      if(!exceptions.isEmpty()){\n        throw MultipleIOException.createIOException(exceptions);\n      }\n    } else {\n      boolean saved \u003d dfs.saveNamespace(timeWindow, txGap);\n      if (saved) {\n        System.out.println(\"Save namespace successful\");\n      } else {\n        System.out.println(\"No extra checkpoint has been made\");\n      }\n    }\n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {}
    },
    "d37dc5d1b8e022a7085118a2e7066623483c293f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9847. HDFS configuration should accept time units. Contributed by Yiqun Lin\n",
      "commitDate": "06/09/16 10:38 AM",
      "commitName": "d37dc5d1b8e022a7085118a2e7066623483c293f",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "28/07/16 12:58 AM",
      "commitNameOld": "414fbfab41470923eb82a21628709e51fd3a3f6e",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 40.4,
      "commitsBetweenForRepo": 266,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,51 @@\n   public int saveNamespace(String[] argv) throws IOException {\n     final DistributedFileSystem dfs \u003d getDFS();\n     final Configuration dfsConf \u003d dfs.getConf();\n \n     long timeWindow \u003d 0;\n     long txGap \u003d 0;\n     if (argv.length \u003e 1 \u0026\u0026 \"-beforeShutdown\".equals(argv[1])) {\n-      final long checkpointPeriod \u003d dfsConf.getLong(\n+      final long checkpointPeriod \u003d dfsConf.getTimeDuration(\n           DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n-          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n+          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT,\n+          TimeUnit.SECONDS);\n       final long checkpointTxnCount \u003d dfsConf.getLong(\n           DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n           DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n       final int toleratePeriodNum \u003d dfsConf.getInt(\n           DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_KEY,\n           DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_DEFAULT);\n       timeWindow \u003d checkpointPeriod * toleratePeriodNum;\n       txGap \u003d checkpointTxnCount * toleratePeriodNum;\n       System.out.println(\"Do checkpoint if necessary before stopping \" +\n           \"namenode. The time window is \" + timeWindow + \" seconds, and the \" +\n           \"transaction gap is \" + txGap);\n     }\n \n     URI dfsUri \u003d dfs.getUri();\n     boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(dfsConf, dfsUri);\n     if (isHaEnabled) {\n       String nsId \u003d dfsUri.getHost();\n       List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n           HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n           nsId, ClientProtocol.class);\n       for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n         boolean saved \u003d proxy.getProxy().saveNamespace(timeWindow, txGap);\n         if (saved) {\n           System.out.println(\"Save namespace successful for \" +\n               proxy.getAddress());\n         } else {\n           System.out.println(\"No extra checkpoint has been made for \"\n               + proxy.getAddress());\n         }\n       }\n     } else {\n       boolean saved \u003d dfs.saveNamespace(timeWindow, txGap);\n       if (saved) {\n         System.out.println(\"Save namespace successful\");\n       } else {\n         System.out.println(\"No extra checkpoint has been made\");\n       }\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int saveNamespace(String[] argv) throws IOException {\n    final DistributedFileSystem dfs \u003d getDFS();\n    final Configuration dfsConf \u003d dfs.getConf();\n\n    long timeWindow \u003d 0;\n    long txGap \u003d 0;\n    if (argv.length \u003e 1 \u0026\u0026 \"-beforeShutdown\".equals(argv[1])) {\n      final long checkpointPeriod \u003d dfsConf.getTimeDuration(\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT,\n          TimeUnit.SECONDS);\n      final long checkpointTxnCount \u003d dfsConf.getLong(\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n      final int toleratePeriodNum \u003d dfsConf.getInt(\n          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_KEY,\n          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_DEFAULT);\n      timeWindow \u003d checkpointPeriod * toleratePeriodNum;\n      txGap \u003d checkpointTxnCount * toleratePeriodNum;\n      System.out.println(\"Do checkpoint if necessary before stopping \" +\n          \"namenode. The time window is \" + timeWindow + \" seconds, and the \" +\n          \"transaction gap is \" + txGap);\n    }\n\n    URI dfsUri \u003d dfs.getUri();\n    boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(dfsConf, dfsUri);\n    if (isHaEnabled) {\n      String nsId \u003d dfsUri.getHost();\n      List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n          HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n          nsId, ClientProtocol.class);\n      for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n        boolean saved \u003d proxy.getProxy().saveNamespace(timeWindow, txGap);\n        if (saved) {\n          System.out.println(\"Save namespace successful for \" +\n              proxy.getAddress());\n        } else {\n          System.out.println(\"No extra checkpoint has been made for \"\n              + proxy.getAddress());\n        }\n      }\n    } else {\n      boolean saved \u003d dfs.saveNamespace(timeWindow, txGap);\n      if (saved) {\n        System.out.println(\"Save namespace successful\");\n      } else {\n        System.out.println(\"No extra checkpoint has been made\");\n      }\n    }\n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {}
    },
    "b9936689c9ea37bf0050e7970643bcddfc9cfdbe": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9615. Fix variable name typo in DFSConfigKeys. (Contributed by Ray Chiang)\n",
      "commitDate": "06/01/16 9:40 AM",
      "commitName": "b9936689c9ea37bf0050e7970643bcddfc9cfdbe",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "23/10/15 6:07 PM",
      "commitNameOld": "86c92227fc56b6e06d879d250728e8dc8cbe98fe",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 74.69,
      "commitsBetweenForRepo": 466,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,50 @@\n   public int saveNamespace(String[] argv) throws IOException {\n     final DistributedFileSystem dfs \u003d getDFS();\n     final Configuration dfsConf \u003d dfs.getConf();\n \n     long timeWindow \u003d 0;\n     long txGap \u003d 0;\n     if (argv.length \u003e 1 \u0026\u0026 \"-beforeShutdown\".equals(argv[1])) {\n       final long checkpointPeriod \u003d dfsConf.getLong(\n           DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n           DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n       final long checkpointTxnCount \u003d dfsConf.getLong(\n           DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n           DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n       final int toleratePeriodNum \u003d dfsConf.getInt(\n           DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_KEY,\n-          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDONW_DEFAULT);\n+          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_DEFAULT);\n       timeWindow \u003d checkpointPeriod * toleratePeriodNum;\n       txGap \u003d checkpointTxnCount * toleratePeriodNum;\n       System.out.println(\"Do checkpoint if necessary before stopping \" +\n           \"namenode. The time window is \" + timeWindow + \" seconds, and the \" +\n           \"transaction gap is \" + txGap);\n     }\n \n     URI dfsUri \u003d dfs.getUri();\n     boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(dfsConf, dfsUri);\n     if (isHaEnabled) {\n       String nsId \u003d dfsUri.getHost();\n       List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n           HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n           nsId, ClientProtocol.class);\n       for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n         boolean saved \u003d proxy.getProxy().saveNamespace(timeWindow, txGap);\n         if (saved) {\n           System.out.println(\"Save namespace successful for \" +\n               proxy.getAddress());\n         } else {\n           System.out.println(\"No extra checkpoint has been made for \"\n               + proxy.getAddress());\n         }\n       }\n     } else {\n       boolean saved \u003d dfs.saveNamespace(timeWindow, txGap);\n       if (saved) {\n         System.out.println(\"Save namespace successful\");\n       } else {\n         System.out.println(\"No extra checkpoint has been made\");\n       }\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int saveNamespace(String[] argv) throws IOException {\n    final DistributedFileSystem dfs \u003d getDFS();\n    final Configuration dfsConf \u003d dfs.getConf();\n\n    long timeWindow \u003d 0;\n    long txGap \u003d 0;\n    if (argv.length \u003e 1 \u0026\u0026 \"-beforeShutdown\".equals(argv[1])) {\n      final long checkpointPeriod \u003d dfsConf.getLong(\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n      final long checkpointTxnCount \u003d dfsConf.getLong(\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n      final int toleratePeriodNum \u003d dfsConf.getInt(\n          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_KEY,\n          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_DEFAULT);\n      timeWindow \u003d checkpointPeriod * toleratePeriodNum;\n      txGap \u003d checkpointTxnCount * toleratePeriodNum;\n      System.out.println(\"Do checkpoint if necessary before stopping \" +\n          \"namenode. The time window is \" + timeWindow + \" seconds, and the \" +\n          \"transaction gap is \" + txGap);\n    }\n\n    URI dfsUri \u003d dfs.getUri();\n    boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(dfsConf, dfsUri);\n    if (isHaEnabled) {\n      String nsId \u003d dfsUri.getHost();\n      List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n          HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n          nsId, ClientProtocol.class);\n      for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n        boolean saved \u003d proxy.getProxy().saveNamespace(timeWindow, txGap);\n        if (saved) {\n          System.out.println(\"Save namespace successful for \" +\n              proxy.getAddress());\n        } else {\n          System.out.println(\"No extra checkpoint has been made for \"\n              + proxy.getAddress());\n        }\n      }\n    } else {\n      boolean saved \u003d dfs.saveNamespace(timeWindow, txGap);\n      if (saved) {\n        System.out.println(\"Save namespace successful\");\n      } else {\n        System.out.println(\"No extra checkpoint has been made\");\n      }\n    }\n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {}
    },
    "6f8003dc7bc9e8be7b0512c514d370c303faf003": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8185. Separate client related routines in HAUtil into a new class. Contributed by Haohui Mai.\n",
      "commitDate": "21/04/15 9:59 PM",
      "commitName": "6f8003dc7bc9e8be7b0512c514d370c303faf003",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "25/03/15 10:38 AM",
      "commitNameOld": "5e21e4ca377f68e030f8f3436cd93fd7a74dc5e0",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 27.47,
      "commitsBetweenForRepo": 221,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,50 @@\n   public int saveNamespace(String[] argv) throws IOException {\n     final DistributedFileSystem dfs \u003d getDFS();\n     final Configuration dfsConf \u003d dfs.getConf();\n \n     long timeWindow \u003d 0;\n     long txGap \u003d 0;\n     if (argv.length \u003e 1 \u0026\u0026 \"-beforeShutdown\".equals(argv[1])) {\n       final long checkpointPeriod \u003d dfsConf.getLong(\n           DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n           DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n       final long checkpointTxnCount \u003d dfsConf.getLong(\n           DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n           DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n       final int toleratePeriodNum \u003d dfsConf.getInt(\n           DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_KEY,\n           DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDONW_DEFAULT);\n       timeWindow \u003d checkpointPeriod * toleratePeriodNum;\n       txGap \u003d checkpointTxnCount * toleratePeriodNum;\n       System.out.println(\"Do checkpoint if necessary before stopping \" +\n           \"namenode. The time window is \" + timeWindow + \" seconds, and the \" +\n           \"transaction gap is \" + txGap);\n     }\n \n     URI dfsUri \u003d dfs.getUri();\n-    boolean isHaEnabled \u003d HAUtil.isLogicalUri(dfsConf, dfsUri);\n+    boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(dfsConf, dfsUri);\n     if (isHaEnabled) {\n       String nsId \u003d dfsUri.getHost();\n       List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n           HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n           nsId, ClientProtocol.class);\n       for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n         boolean saved \u003d proxy.getProxy().saveNamespace(timeWindow, txGap);\n         if (saved) {\n           System.out.println(\"Save namespace successful for \" +\n               proxy.getAddress());\n         } else {\n           System.out.println(\"No extra checkpoint has been made for \"\n               + proxy.getAddress());\n         }\n       }\n     } else {\n       boolean saved \u003d dfs.saveNamespace(timeWindow, txGap);\n       if (saved) {\n         System.out.println(\"Save namespace successful\");\n       } else {\n         System.out.println(\"No extra checkpoint has been made\");\n       }\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int saveNamespace(String[] argv) throws IOException {\n    final DistributedFileSystem dfs \u003d getDFS();\n    final Configuration dfsConf \u003d dfs.getConf();\n\n    long timeWindow \u003d 0;\n    long txGap \u003d 0;\n    if (argv.length \u003e 1 \u0026\u0026 \"-beforeShutdown\".equals(argv[1])) {\n      final long checkpointPeriod \u003d dfsConf.getLong(\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n      final long checkpointTxnCount \u003d dfsConf.getLong(\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n      final int toleratePeriodNum \u003d dfsConf.getInt(\n          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_KEY,\n          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDONW_DEFAULT);\n      timeWindow \u003d checkpointPeriod * toleratePeriodNum;\n      txGap \u003d checkpointTxnCount * toleratePeriodNum;\n      System.out.println(\"Do checkpoint if necessary before stopping \" +\n          \"namenode. The time window is \" + timeWindow + \" seconds, and the \" +\n          \"transaction gap is \" + txGap);\n    }\n\n    URI dfsUri \u003d dfs.getUri();\n    boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(dfsConf, dfsUri);\n    if (isHaEnabled) {\n      String nsId \u003d dfsUri.getHost();\n      List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n          HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n          nsId, ClientProtocol.class);\n      for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n        boolean saved \u003d proxy.getProxy().saveNamespace(timeWindow, txGap);\n        if (saved) {\n          System.out.println(\"Save namespace successful for \" +\n              proxy.getAddress());\n        } else {\n          System.out.println(\"No extra checkpoint has been made for \"\n              + proxy.getAddress());\n        }\n      }\n    } else {\n      boolean saved \u003d dfs.saveNamespace(timeWindow, txGap);\n      if (saved) {\n        System.out.println(\"Save namespace successful\");\n      } else {\n        System.out.println(\"No extra checkpoint has been made\");\n      }\n    }\n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {}
    },
    "5e21e4ca377f68e030f8f3436cd93fd7a74dc5e0": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6353. Check and make checkpoint before stopping the NameNode. Contributed by Jing Zhao.\n",
      "commitDate": "25/03/15 10:38 AM",
      "commitName": "5e21e4ca377f68e030f8f3436cd93fd7a74dc5e0",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6353. Check and make checkpoint before stopping the NameNode. Contributed by Jing Zhao.\n",
          "commitDate": "25/03/15 10:38 AM",
          "commitName": "5e21e4ca377f68e030f8f3436cd93fd7a74dc5e0",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "04/03/15 1:08 AM",
          "commitNameOld": "3560180b6e9926aa3ee1357da59b28a4b4689a0d",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 21.35,
          "commitsBetweenForRepo": 195,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,50 @@\n-  public int saveNamespace() throws IOException {\n-    int exitCode \u003d -1;\n+  public int saveNamespace(String[] argv) throws IOException {\n+    final DistributedFileSystem dfs \u003d getDFS();\n+    final Configuration dfsConf \u003d dfs.getConf();\n \n-    DistributedFileSystem dfs \u003d getDFS();\n-    Configuration dfsConf \u003d dfs.getConf();\n+    long timeWindow \u003d 0;\n+    long txGap \u003d 0;\n+    if (argv.length \u003e 1 \u0026\u0026 \"-beforeShutdown\".equals(argv[1])) {\n+      final long checkpointPeriod \u003d dfsConf.getLong(\n+          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n+          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n+      final long checkpointTxnCount \u003d dfsConf.getLong(\n+          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n+          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n+      final int toleratePeriodNum \u003d dfsConf.getInt(\n+          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_KEY,\n+          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDONW_DEFAULT);\n+      timeWindow \u003d checkpointPeriod * toleratePeriodNum;\n+      txGap \u003d checkpointTxnCount * toleratePeriodNum;\n+      System.out.println(\"Do checkpoint if necessary before stopping \" +\n+          \"namenode. The time window is \" + timeWindow + \" seconds, and the \" +\n+          \"transaction gap is \" + txGap);\n+    }\n+\n     URI dfsUri \u003d dfs.getUri();\n     boolean isHaEnabled \u003d HAUtil.isLogicalUri(dfsConf, dfsUri);\n-\n     if (isHaEnabled) {\n       String nsId \u003d dfsUri.getHost();\n       List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n           HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n           nsId, ClientProtocol.class);\n       for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n-        proxy.getProxy().saveNamespace();\n-        System.out.println(\"Save namespace successful for \" +\n-            proxy.getAddress());\n+        boolean saved \u003d proxy.getProxy().saveNamespace(timeWindow, txGap);\n+        if (saved) {\n+          System.out.println(\"Save namespace successful for \" +\n+              proxy.getAddress());\n+        } else {\n+          System.out.println(\"No extra checkpoint has been made for \"\n+              + proxy.getAddress());\n+        }\n       }\n     } else {\n-      dfs.saveNamespace();\n-      System.out.println(\"Save namespace successful\");\n+      boolean saved \u003d dfs.saveNamespace(timeWindow, txGap);\n+      if (saved) {\n+        System.out.println(\"Save namespace successful\");\n+      } else {\n+        System.out.println(\"No extra checkpoint has been made\");\n+      }\n     }\n-    exitCode \u003d 0;\n-   \n-    return exitCode;\n+    return 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public int saveNamespace(String[] argv) throws IOException {\n    final DistributedFileSystem dfs \u003d getDFS();\n    final Configuration dfsConf \u003d dfs.getConf();\n\n    long timeWindow \u003d 0;\n    long txGap \u003d 0;\n    if (argv.length \u003e 1 \u0026\u0026 \"-beforeShutdown\".equals(argv[1])) {\n      final long checkpointPeriod \u003d dfsConf.getLong(\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n      final long checkpointTxnCount \u003d dfsConf.getLong(\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n      final int toleratePeriodNum \u003d dfsConf.getInt(\n          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_KEY,\n          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDONW_DEFAULT);\n      timeWindow \u003d checkpointPeriod * toleratePeriodNum;\n      txGap \u003d checkpointTxnCount * toleratePeriodNum;\n      System.out.println(\"Do checkpoint if necessary before stopping \" +\n          \"namenode. The time window is \" + timeWindow + \" seconds, and the \" +\n          \"transaction gap is \" + txGap);\n    }\n\n    URI dfsUri \u003d dfs.getUri();\n    boolean isHaEnabled \u003d HAUtil.isLogicalUri(dfsConf, dfsUri);\n    if (isHaEnabled) {\n      String nsId \u003d dfsUri.getHost();\n      List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n          HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n          nsId, ClientProtocol.class);\n      for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n        boolean saved \u003d proxy.getProxy().saveNamespace(timeWindow, txGap);\n        if (saved) {\n          System.out.println(\"Save namespace successful for \" +\n              proxy.getAddress());\n        } else {\n          System.out.println(\"No extra checkpoint has been made for \"\n              + proxy.getAddress());\n        }\n      }\n    } else {\n      boolean saved \u003d dfs.saveNamespace(timeWindow, txGap);\n      if (saved) {\n        System.out.println(\"Save namespace successful\");\n      } else {\n        System.out.println(\"No extra checkpoint has been made\");\n      }\n    }\n    return 0;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[argv-String[]]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6353. Check and make checkpoint before stopping the NameNode. Contributed by Jing Zhao.\n",
          "commitDate": "25/03/15 10:38 AM",
          "commitName": "5e21e4ca377f68e030f8f3436cd93fd7a74dc5e0",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "04/03/15 1:08 AM",
          "commitNameOld": "3560180b6e9926aa3ee1357da59b28a4b4689a0d",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 21.35,
          "commitsBetweenForRepo": 195,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,50 @@\n-  public int saveNamespace() throws IOException {\n-    int exitCode \u003d -1;\n+  public int saveNamespace(String[] argv) throws IOException {\n+    final DistributedFileSystem dfs \u003d getDFS();\n+    final Configuration dfsConf \u003d dfs.getConf();\n \n-    DistributedFileSystem dfs \u003d getDFS();\n-    Configuration dfsConf \u003d dfs.getConf();\n+    long timeWindow \u003d 0;\n+    long txGap \u003d 0;\n+    if (argv.length \u003e 1 \u0026\u0026 \"-beforeShutdown\".equals(argv[1])) {\n+      final long checkpointPeriod \u003d dfsConf.getLong(\n+          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n+          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n+      final long checkpointTxnCount \u003d dfsConf.getLong(\n+          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n+          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n+      final int toleratePeriodNum \u003d dfsConf.getInt(\n+          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_KEY,\n+          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDONW_DEFAULT);\n+      timeWindow \u003d checkpointPeriod * toleratePeriodNum;\n+      txGap \u003d checkpointTxnCount * toleratePeriodNum;\n+      System.out.println(\"Do checkpoint if necessary before stopping \" +\n+          \"namenode. The time window is \" + timeWindow + \" seconds, and the \" +\n+          \"transaction gap is \" + txGap);\n+    }\n+\n     URI dfsUri \u003d dfs.getUri();\n     boolean isHaEnabled \u003d HAUtil.isLogicalUri(dfsConf, dfsUri);\n-\n     if (isHaEnabled) {\n       String nsId \u003d dfsUri.getHost();\n       List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n           HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n           nsId, ClientProtocol.class);\n       for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n-        proxy.getProxy().saveNamespace();\n-        System.out.println(\"Save namespace successful for \" +\n-            proxy.getAddress());\n+        boolean saved \u003d proxy.getProxy().saveNamespace(timeWindow, txGap);\n+        if (saved) {\n+          System.out.println(\"Save namespace successful for \" +\n+              proxy.getAddress());\n+        } else {\n+          System.out.println(\"No extra checkpoint has been made for \"\n+              + proxy.getAddress());\n+        }\n       }\n     } else {\n-      dfs.saveNamespace();\n-      System.out.println(\"Save namespace successful\");\n+      boolean saved \u003d dfs.saveNamespace(timeWindow, txGap);\n+      if (saved) {\n+        System.out.println(\"Save namespace successful\");\n+      } else {\n+        System.out.println(\"No extra checkpoint has been made\");\n+      }\n     }\n-    exitCode \u003d 0;\n-   \n-    return exitCode;\n+    return 0;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public int saveNamespace(String[] argv) throws IOException {\n    final DistributedFileSystem dfs \u003d getDFS();\n    final Configuration dfsConf \u003d dfs.getConf();\n\n    long timeWindow \u003d 0;\n    long txGap \u003d 0;\n    if (argv.length \u003e 1 \u0026\u0026 \"-beforeShutdown\".equals(argv[1])) {\n      final long checkpointPeriod \u003d dfsConf.getLong(\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_KEY,\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_PERIOD_DEFAULT);\n      final long checkpointTxnCount \u003d dfsConf.getLong(\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_KEY,\n          DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_TXNS_DEFAULT);\n      final int toleratePeriodNum \u003d dfsConf.getInt(\n          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDOWN_KEY,\n          DFSConfigKeys.DFS_NAMENODE_MISSING_CHECKPOINT_PERIODS_BEFORE_SHUTDONW_DEFAULT);\n      timeWindow \u003d checkpointPeriod * toleratePeriodNum;\n      txGap \u003d checkpointTxnCount * toleratePeriodNum;\n      System.out.println(\"Do checkpoint if necessary before stopping \" +\n          \"namenode. The time window is \" + timeWindow + \" seconds, and the \" +\n          \"transaction gap is \" + txGap);\n    }\n\n    URI dfsUri \u003d dfs.getUri();\n    boolean isHaEnabled \u003d HAUtil.isLogicalUri(dfsConf, dfsUri);\n    if (isHaEnabled) {\n      String nsId \u003d dfsUri.getHost();\n      List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n          HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n          nsId, ClientProtocol.class);\n      for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n        boolean saved \u003d proxy.getProxy().saveNamespace(timeWindow, txGap);\n        if (saved) {\n          System.out.println(\"Save namespace successful for \" +\n              proxy.getAddress());\n        } else {\n          System.out.println(\"No extra checkpoint has been made for \"\n              + proxy.getAddress());\n        }\n      }\n    } else {\n      boolean saved \u003d dfs.saveNamespace(timeWindow, txGap);\n      if (saved) {\n        System.out.println(\"Save namespace successful\");\n      } else {\n        System.out.println(\"No extra checkpoint has been made\");\n      }\n    }\n    return 0;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
          "extendedDetails": {}
        }
      ]
    },
    "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6507. Improve DFSAdmin to support HA cluster better. (Contributd by Zesheng Wu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1604692 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/06/14 10:16 PM",
      "commitName": "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "11/06/14 6:27 PM",
      "commitNameOld": "34e9173c00f7e1ae55dec365850849c793cde8e3",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 11.16,
      "commitsBetweenForRepo": 76,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,26 @@\n   public int saveNamespace() throws IOException {\n     int exitCode \u003d -1;\n \n     DistributedFileSystem dfs \u003d getDFS();\n-    dfs.saveNamespace();\n+    Configuration dfsConf \u003d dfs.getConf();\n+    URI dfsUri \u003d dfs.getUri();\n+    boolean isHaEnabled \u003d HAUtil.isLogicalUri(dfsConf, dfsUri);\n+\n+    if (isHaEnabled) {\n+      String nsId \u003d dfsUri.getHost();\n+      List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n+          HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n+          nsId, ClientProtocol.class);\n+      for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n+        proxy.getProxy().saveNamespace();\n+        System.out.println(\"Save namespace successful for \" +\n+            proxy.getAddress());\n+      }\n+    } else {\n+      dfs.saveNamespace();\n+      System.out.println(\"Save namespace successful\");\n+    }\n     exitCode \u003d 0;\n    \n     return exitCode;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int saveNamespace() throws IOException {\n    int exitCode \u003d -1;\n\n    DistributedFileSystem dfs \u003d getDFS();\n    Configuration dfsConf \u003d dfs.getConf();\n    URI dfsUri \u003d dfs.getUri();\n    boolean isHaEnabled \u003d HAUtil.isLogicalUri(dfsConf, dfsUri);\n\n    if (isHaEnabled) {\n      String nsId \u003d dfsUri.getHost();\n      List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n          HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n          nsId, ClientProtocol.class);\n      for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n        proxy.getProxy().saveNamespace();\n        System.out.println(\"Save namespace successful for \" +\n            proxy.getAddress());\n      }\n    } else {\n      dfs.saveNamespace();\n      System.out.println(\"Save namespace successful\");\n    }\n    exitCode \u003d 0;\n   \n    return exitCode;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int saveNamespace() throws IOException {\n    int exitCode \u003d -1;\n\n    DistributedFileSystem dfs \u003d getDFS();\n    dfs.saveNamespace();\n    exitCode \u003d 0;\n   \n    return exitCode;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int saveNamespace() throws IOException {\n    int exitCode \u003d -1;\n\n    DistributedFileSystem dfs \u003d getDFS();\n    dfs.saveNamespace();\n    exitCode \u003d 0;\n   \n    return exitCode;\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,9 @@\n+  public int saveNamespace() throws IOException {\n+    int exitCode \u003d -1;\n+\n+    DistributedFileSystem dfs \u003d getDFS();\n+    dfs.saveNamespace();\n+    exitCode \u003d 0;\n+   \n+    return exitCode;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public int saveNamespace() throws IOException {\n    int exitCode \u003d -1;\n\n    DistributedFileSystem dfs \u003d getDFS();\n    dfs.saveNamespace();\n    exitCode \u003d 0;\n   \n    return exitCode;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java"
    }
  }
}