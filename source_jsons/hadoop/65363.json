{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3AMultipartUploader.java",
  "functionName": "parsePartHandlePayload",
  "functionId": "parsePartHandlePayload___data-byte[]",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AMultipartUploader.java",
  "functionStartLine": 198,
  "functionEndLine": 214,
  "numCommitsSeen": 5,
  "timeTaken": 1306,
  "changeHistory": [
    "c1d24f848345f6d34a2ac2d570d49e9787a0df6a",
    "2ec97abb2e93c1a8127e7a146c08e26454b583fa"
  ],
  "changeHistoryShort": {
    "c1d24f848345f6d34a2ac2d570d49e9787a0df6a": "Ybodychange",
    "2ec97abb2e93c1a8127e7a146c08e26454b583fa": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c1d24f848345f6d34a2ac2d570d49e9787a0df6a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13713. Add specification of Multipart Upload API to FS specification, with contract tests.\n\nContributed by Ewan Higgs and Steve Loughran.\n",
      "commitDate": "29/11/18 7:12 AM",
      "commitName": "c1d24f848345f6d34a2ac2d570d49e9787a0df6a",
      "commitAuthor": "Ewan Higgs",
      "commitDateOld": "24/09/18 8:49 AM",
      "commitNameOld": "d060cbea48ffc75da0f4fa98c3ea5203d6db1360",
      "commitAuthorOld": "Sunil G",
      "daysBetweenCommits": 65.97,
      "commitsBetweenForRepo": 566,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   static Pair\u003cLong, String\u003e parsePartHandlePayload(byte[] data)\n       throws IOException {\n \n     try(DataInputStream input \u003d\n             new DataInputStream(new ByteArrayInputStream(data))) {\n       final String header \u003d input.readUTF();\n       if (!HEADER.equals(header)) {\n         throw new IOException(\"Wrong header string: \\\"\" + header + \"\\\"\");\n       }\n       final long len \u003d input.readLong();\n       final String etag \u003d input.readUTF();\n-      if (len \u003c\u003d 0) {\n+      if (len \u003c 0) {\n         throw new IOException(\"Negative length\");\n       }\n       return Pair.of(len, etag);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static Pair\u003cLong, String\u003e parsePartHandlePayload(byte[] data)\n      throws IOException {\n\n    try(DataInputStream input \u003d\n            new DataInputStream(new ByteArrayInputStream(data))) {\n      final String header \u003d input.readUTF();\n      if (!HEADER.equals(header)) {\n        throw new IOException(\"Wrong header string: \\\"\" + header + \"\\\"\");\n      }\n      final long len \u003d input.readLong();\n      final String etag \u003d input.readUTF();\n      if (len \u003c 0) {\n        throw new IOException(\"Negative length\");\n      }\n      return Pair.of(len, etag);\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AMultipartUploader.java",
      "extendedDetails": {}
    },
    "2ec97abb2e93c1a8127e7a146c08e26454b583fa": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-15576. S3A Multipart Uploader to work with S3Guard and encryption Originally contributed by Ewan Higgs with refinements by Steve Loughran.\n",
      "commitDate": "08/08/18 4:50 AM",
      "commitName": "2ec97abb2e93c1a8127e7a146c08e26454b583fa",
      "commitAuthor": "Ewan Higgs",
      "diff": "@@ -0,0 +1,17 @@\n+  static Pair\u003cLong, String\u003e parsePartHandlePayload(byte[] data)\n+      throws IOException {\n+\n+    try(DataInputStream input \u003d\n+            new DataInputStream(new ByteArrayInputStream(data))) {\n+      final String header \u003d input.readUTF();\n+      if (!HEADER.equals(header)) {\n+        throw new IOException(\"Wrong header string: \\\"\" + header + \"\\\"\");\n+      }\n+      final long len \u003d input.readLong();\n+      final String etag \u003d input.readUTF();\n+      if (len \u003c\u003d 0) {\n+        throw new IOException(\"Negative length\");\n+      }\n+      return Pair.of(len, etag);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static Pair\u003cLong, String\u003e parsePartHandlePayload(byte[] data)\n      throws IOException {\n\n    try(DataInputStream input \u003d\n            new DataInputStream(new ByteArrayInputStream(data))) {\n      final String header \u003d input.readUTF();\n      if (!HEADER.equals(header)) {\n        throw new IOException(\"Wrong header string: \\\"\" + header + \"\\\"\");\n      }\n      final long len \u003d input.readLong();\n      final String etag \u003d input.readUTF();\n      if (len \u003c\u003d 0) {\n        throw new IOException(\"Negative length\");\n      }\n      return Pair.of(len, etag);\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AMultipartUploader.java"
    }
  }
}