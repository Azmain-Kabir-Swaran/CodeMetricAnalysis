{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RouterCacheAdmin.java",
  "functionName": "modifyCacheDirective",
  "functionId": "modifyCacheDirective___directive-CacheDirectiveInfo__flags-EnumSet__CacheFlag__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterCacheAdmin.java",
  "functionStartLine": 73,
  "functionEndLine": 91,
  "numCommitsSeen": 1,
  "timeTaken": 732,
  "changeHistory": [
    "9b197c289384d2cd3879f9a464b35ae80aecdf39"
  ],
  "changeHistoryShort": {
    "9b197c289384d2cd3879f9a464b35ae80aecdf39": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9b197c289384d2cd3879f9a464b35ae80aecdf39": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13909. RBF: Add Cache pools and directives related ClientProtocol APIs. Contributed by Ayush Saxena.\n",
      "commitDate": "24/06/19 9:33 AM",
      "commitName": "9b197c289384d2cd3879f9a464b35ae80aecdf39",
      "commitAuthor": "Ayush Saxena",
      "diff": "@@ -0,0 +1,19 @@\n+  public void modifyCacheDirective(CacheDirectiveInfo directive,\n+      EnumSet\u003cCacheFlag\u003e flags) throws IOException {\n+    rpcServer.checkOperation(NameNode.OperationCategory.WRITE, true);\n+    Path p \u003d directive.getPath();\n+    if (p !\u003d null) {\n+      final List\u003cRemoteLocation\u003e locations \u003d rpcServer\n+          .getLocationsForPath(directive.getPath().toString(), true, false);\n+      RemoteMethod method \u003d new RemoteMethod(\"modifyCacheDirective\",\n+          new Class\u003c?\u003e[] {CacheDirectiveInfo.class, EnumSet.class},\n+          new RemoteParam(getRemoteMap(directive, locations)), flags);\n+      rpcClient.invokeConcurrent(locations, method);\n+      return;\n+    }\n+    RemoteMethod method \u003d new RemoteMethod(\"modifyCacheDirective\",\n+        new Class\u003c?\u003e[] {CacheDirectiveInfo.class, EnumSet.class}, directive,\n+        flags);\n+    Set\u003cFederationNamespaceInfo\u003e nss \u003d namenodeResolver.getNamespaces();\n+    rpcClient.invokeConcurrent(nss, method, false, false);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void modifyCacheDirective(CacheDirectiveInfo directive,\n      EnumSet\u003cCacheFlag\u003e flags) throws IOException {\n    rpcServer.checkOperation(NameNode.OperationCategory.WRITE, true);\n    Path p \u003d directive.getPath();\n    if (p !\u003d null) {\n      final List\u003cRemoteLocation\u003e locations \u003d rpcServer\n          .getLocationsForPath(directive.getPath().toString(), true, false);\n      RemoteMethod method \u003d new RemoteMethod(\"modifyCacheDirective\",\n          new Class\u003c?\u003e[] {CacheDirectiveInfo.class, EnumSet.class},\n          new RemoteParam(getRemoteMap(directive, locations)), flags);\n      rpcClient.invokeConcurrent(locations, method);\n      return;\n    }\n    RemoteMethod method \u003d new RemoteMethod(\"modifyCacheDirective\",\n        new Class\u003c?\u003e[] {CacheDirectiveInfo.class, EnumSet.class}, directive,\n        flags);\n    Set\u003cFederationNamespaceInfo\u003e nss \u003d namenodeResolver.getNamespaces();\n    rpcClient.invokeConcurrent(nss, method, false, false);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterCacheAdmin.java"
    }
  }
}