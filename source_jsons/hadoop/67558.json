{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JobMetaData.java",
  "functionName": "createSkyline",
  "functionId": "createSkyline",
  "sourceFilePath": "hadoop-tools/hadoop-resourceestimator/src/main/java/org/apache/hadoop/resourceestimator/translator/api/JobMetaData.java",
  "functionStartLine": 135,
  "functionEndLine": 162,
  "numCommitsSeen": 1,
  "timeTaken": 355,
  "changeHistory": [
    "625039ef20e6011ab360131d70582a6e4bf2ec1d"
  ],
  "changeHistoryShort": {
    "625039ef20e6011ab360131d70582a6e4bf2ec1d": "Yintroduced"
  },
  "changeHistoryDetails": {
    "625039ef20e6011ab360131d70582a6e4bf2ec1d": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-14840. Tool to estimate resource requirements of an application pipeline based on prior executions. (Rui Li via Subru).\n",
      "commitDate": "25/10/17 3:51 PM",
      "commitName": "625039ef20e6011ab360131d70582a6e4bf2ec1d",
      "commitAuthor": "Subru Krishnan",
      "diff": "@@ -0,0 +1,28 @@\n+  public final void createSkyline() {\n+    final long jobSubmissionTime \u003d resourceSkyline.getJobSubmissionTime();\n+    Resource containerSpec \u003d resourceSkyline.getContainerSpec();\n+    final TreeMap\u003cLong, Resource\u003e resourceOverTime \u003d new TreeMap\u003c\u003e();\n+    final RLESparseResourceAllocation skylineList \u003d\n+        new RLESparseResourceAllocation(resourceOverTime,\n+            new DefaultResourceCalculator());\n+    resourceSkyline.setSkylineList(skylineList);\n+    if (containerSpec \u003d\u003d null) {\n+      // if RmParser fails to extract container resource spec from logs, we will\n+      // statically set\n+      // it to be \u003c1core, 1GB\u003e\n+      containerSpec \u003d Resource.newInstance(1024, 1);\n+    }\n+    resourceSkyline.setContainerSpec(containerSpec);\n+    for (final Map.Entry\u003cString, Long\u003e entry : rawStart.entrySet()) {\n+      final long timeStart \u003d entry.getValue();\n+      final Long timeEnd \u003d rawEnd.get(entry.getKey());\n+      if (timeEnd \u003d\u003d null) {\n+        LOGGER.warn(\"container release time not found for {}.\", entry.getKey());\n+      } else {\n+        final ReservationInterval riAdd \u003d\n+            new ReservationInterval((timeStart - jobSubmissionTime) / 1000,\n+                (timeEnd - jobSubmissionTime) / 1000);\n+        resourceSkyline.getSkylineList().addInterval(riAdd, containerSpec);\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public final void createSkyline() {\n    final long jobSubmissionTime \u003d resourceSkyline.getJobSubmissionTime();\n    Resource containerSpec \u003d resourceSkyline.getContainerSpec();\n    final TreeMap\u003cLong, Resource\u003e resourceOverTime \u003d new TreeMap\u003c\u003e();\n    final RLESparseResourceAllocation skylineList \u003d\n        new RLESparseResourceAllocation(resourceOverTime,\n            new DefaultResourceCalculator());\n    resourceSkyline.setSkylineList(skylineList);\n    if (containerSpec \u003d\u003d null) {\n      // if RmParser fails to extract container resource spec from logs, we will\n      // statically set\n      // it to be \u003c1core, 1GB\u003e\n      containerSpec \u003d Resource.newInstance(1024, 1);\n    }\n    resourceSkyline.setContainerSpec(containerSpec);\n    for (final Map.Entry\u003cString, Long\u003e entry : rawStart.entrySet()) {\n      final long timeStart \u003d entry.getValue();\n      final Long timeEnd \u003d rawEnd.get(entry.getKey());\n      if (timeEnd \u003d\u003d null) {\n        LOGGER.warn(\"container release time not found for {}.\", entry.getKey());\n      } else {\n        final ReservationInterval riAdd \u003d\n            new ReservationInterval((timeStart - jobSubmissionTime) / 1000,\n                (timeEnd - jobSubmissionTime) / 1000);\n        resourceSkyline.getSkylineList().addInterval(riAdd, containerSpec);\n      }\n    }\n  }",
      "path": "hadoop-tools/hadoop-resourceestimator/src/main/java/org/apache/hadoop/resourceestimator/translator/api/JobMetaData.java"
    }
  }
}