{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeDescriptor.java",
  "functionName": "hasStaleStorages",
  "functionId": "hasStaleStorages",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
  "functionStartLine": 323,
  "functionEndLine": 338,
  "numCommitsSeen": 118,
  "timeTaken": 2615,
  "changeHistory": [
    "d65df0f27395792c6e25f5e03b6ba1765e2ba925",
    "5beeb3016954a3ee0c1fb10a2083ffd540cd2c14"
  ],
  "changeHistoryShort": {
    "d65df0f27395792c6e25f5e03b6ba1765e2ba925": "Ybodychange",
    "5beeb3016954a3ee0c1fb10a2083ffd540cd2c14": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d65df0f27395792c6e25f5e03b6ba1765e2ba925": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11190. [READ] Namenode support for data stored in external stores.\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "d65df0f27395792c6e25f5e03b6ba1765e2ba925",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "17/08/17 3:26 PM",
      "commitNameOld": "b29894889742dda654cd88a7ce72a4e51fccb328",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 120.14,
      "commitsBetweenForRepo": 995,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,16 @@\n   boolean hasStaleStorages() {\n     synchronized (storageMap) {\n       for (DatanodeStorageInfo storage : storageMap.values()) {\n+        if (StorageType.PROVIDED.equals(storage.getStorageType())) {\n+          // to verify provided storage participated in this hb, requires\n+          // check to pass DNDesc.\n+          // e.g., storageInfo.verifyBlockReportId(this, curBlockReportId)\n+          continue;\n+        }\n         if (storage.areBlockContentsStale()) {\n           return true;\n         }\n       }\n       return false;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean hasStaleStorages() {\n    synchronized (storageMap) {\n      for (DatanodeStorageInfo storage : storageMap.values()) {\n        if (StorageType.PROVIDED.equals(storage.getStorageType())) {\n          // to verify provided storage participated in this hb, requires\n          // check to pass DNDesc.\n          // e.g., storageInfo.verifyBlockReportId(this, curBlockReportId)\n          continue;\n        }\n        if (storage.areBlockContentsStale()) {\n          return true;\n        }\n      }\n      return false;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "5beeb3016954a3ee0c1fb10a2083ffd540cd2c14": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5153. Datanode should send block reports for each storage in a separate message. (Arpit Agarwal)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1563254 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/01/14 1:00 PM",
      "commitName": "5beeb3016954a3ee0c1fb10a2083ffd540cd2c14",
      "commitAuthor": "Arpit Agarwal",
      "diff": "@@ -0,0 +1,10 @@\n+  boolean hasStaleStorages() {\n+    synchronized (storageMap) {\n+      for (DatanodeStorageInfo storage : storageMap.values()) {\n+        if (storage.areBlockContentsStale()) {\n+          return true;\n+        }\n+      }\n+      return false;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  boolean hasStaleStorages() {\n    synchronized (storageMap) {\n      for (DatanodeStorageInfo storage : storageMap.values()) {\n        if (storage.areBlockContentsStale()) {\n          return true;\n        }\n      }\n      return false;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java"
    }
  }
}