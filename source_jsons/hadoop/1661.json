{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataTransferSaslUtil.java",
  "functionName": "readSaslMessage",
  "functionId": "readSaslMessage___in-InputStream",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/DataTransferSaslUtil.java",
  "functionStartLine": 214,
  "functionEndLine": 224,
  "numCommitsSeen": 17,
  "timeTaken": 3069,
  "changeHistory": [
    "ed78b14ebc9a21bb57ccd088e8b49bfa457a396f",
    "3b54223c0f32d42a84436c670d80b791a8e9696d",
    "9b4a7900c7dfc0590316eedaa97144f938885651"
  ],
  "changeHistoryShort": {
    "ed78b14ebc9a21bb57ccd088e8b49bfa457a396f": "Yfilerename",
    "3b54223c0f32d42a84436c670d80b791a8e9696d": "Ymultichange(Ymovefromfile,Ymodifierchange,Yparameterchange)",
    "9b4a7900c7dfc0590316eedaa97144f938885651": "Yintroduced"
  },
  "changeHistoryDetails": {
    "ed78b14ebc9a21bb57ccd088e8b49bfa457a396f": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-9002. Move o.a.h.hdfs.net/*Peer classes to hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "03/09/15 3:32 PM",
      "commitName": "ed78b14ebc9a21bb57ccd088e8b49bfa457a396f",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "03/09/15 1:26 PM",
      "commitNameOld": "c2d2c1802a11e3e11a953b23b0eccbf4d107de59",
      "commitAuthorOld": "Jakob Homan",
      "daysBetweenCommits": 0.09,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public static byte[] readSaslMessage(InputStream in) throws IOException {\n    DataTransferEncryptorMessageProto proto \u003d\n        DataTransferEncryptorMessageProto.parseFrom(vintPrefixed(in));\n    if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR_UNKNOWN_KEY) {\n      throw new InvalidEncryptionKeyException(proto.getMessage());\n    } else if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR) {\n      throw new IOException(proto.getMessage());\n    } else {\n      return proto.getPayload().toByteArray();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/DataTransferSaslUtil.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/DataTransferSaslUtil.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/DataTransferSaslUtil.java"
      }
    },
    "3b54223c0f32d42a84436c670d80b791a8e9696d": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Yparameterchange)",
      "commitMessage": "HDFS-2856. Fix block protocol so that Datanodes don\u0027t require root or jsvc. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1610474 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/07/14 11:10 AM",
      "commitName": "3b54223c0f32d42a84436c670d80b791a8e9696d",
      "commitAuthor": "Chris Nauroth",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-2856. Fix block protocol so that Datanodes don\u0027t require root or jsvc. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1610474 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/07/14 11:10 AM",
          "commitName": "3b54223c0f32d42a84436c670d80b791a8e9696d",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "14/07/14 10:51 AM",
          "commitNameOld": "425616861bd7e801fdcf0a113606ad81015b1861",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,11 @@\n-  private static byte[] readSaslMessage(DataInputStream in) throws IOException {\n+  public static byte[] readSaslMessage(InputStream in) throws IOException {\n     DataTransferEncryptorMessageProto proto \u003d\n         DataTransferEncryptorMessageProto.parseFrom(vintPrefixed(in));\n     if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR_UNKNOWN_KEY) {\n       throw new InvalidEncryptionKeyException(proto.getMessage());\n     } else if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR) {\n       throw new IOException(proto.getMessage());\n     } else {\n       return proto.getPayload().toByteArray();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static byte[] readSaslMessage(InputStream in) throws IOException {\n    DataTransferEncryptorMessageProto proto \u003d\n        DataTransferEncryptorMessageProto.parseFrom(vintPrefixed(in));\n    if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR_UNKNOWN_KEY) {\n      throw new InvalidEncryptionKeyException(proto.getMessage());\n    } else if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR) {\n      throw new IOException(proto.getMessage());\n    } else {\n      return proto.getPayload().toByteArray();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/DataTransferSaslUtil.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferEncryptor.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/DataTransferSaslUtil.java",
            "oldMethodName": "readSaslMessage",
            "newMethodName": "readSaslMessage"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-2856. Fix block protocol so that Datanodes don\u0027t require root or jsvc. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1610474 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/07/14 11:10 AM",
          "commitName": "3b54223c0f32d42a84436c670d80b791a8e9696d",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "14/07/14 10:51 AM",
          "commitNameOld": "425616861bd7e801fdcf0a113606ad81015b1861",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,11 @@\n-  private static byte[] readSaslMessage(DataInputStream in) throws IOException {\n+  public static byte[] readSaslMessage(InputStream in) throws IOException {\n     DataTransferEncryptorMessageProto proto \u003d\n         DataTransferEncryptorMessageProto.parseFrom(vintPrefixed(in));\n     if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR_UNKNOWN_KEY) {\n       throw new InvalidEncryptionKeyException(proto.getMessage());\n     } else if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR) {\n       throw new IOException(proto.getMessage());\n     } else {\n       return proto.getPayload().toByteArray();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static byte[] readSaslMessage(InputStream in) throws IOException {\n    DataTransferEncryptorMessageProto proto \u003d\n        DataTransferEncryptorMessageProto.parseFrom(vintPrefixed(in));\n    if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR_UNKNOWN_KEY) {\n      throw new InvalidEncryptionKeyException(proto.getMessage());\n    } else if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR) {\n      throw new IOException(proto.getMessage());\n    } else {\n      return proto.getPayload().toByteArray();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/DataTransferSaslUtil.java",
          "extendedDetails": {
            "oldValue": "[private, static]",
            "newValue": "[public, static]"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-2856. Fix block protocol so that Datanodes don\u0027t require root or jsvc. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1610474 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/07/14 11:10 AM",
          "commitName": "3b54223c0f32d42a84436c670d80b791a8e9696d",
          "commitAuthor": "Chris Nauroth",
          "commitDateOld": "14/07/14 10:51 AM",
          "commitNameOld": "425616861bd7e801fdcf0a113606ad81015b1861",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,11 @@\n-  private static byte[] readSaslMessage(DataInputStream in) throws IOException {\n+  public static byte[] readSaslMessage(InputStream in) throws IOException {\n     DataTransferEncryptorMessageProto proto \u003d\n         DataTransferEncryptorMessageProto.parseFrom(vintPrefixed(in));\n     if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR_UNKNOWN_KEY) {\n       throw new InvalidEncryptionKeyException(proto.getMessage());\n     } else if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR) {\n       throw new IOException(proto.getMessage());\n     } else {\n       return proto.getPayload().toByteArray();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static byte[] readSaslMessage(InputStream in) throws IOException {\n    DataTransferEncryptorMessageProto proto \u003d\n        DataTransferEncryptorMessageProto.parseFrom(vintPrefixed(in));\n    if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR_UNKNOWN_KEY) {\n      throw new InvalidEncryptionKeyException(proto.getMessage());\n    } else if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR) {\n      throw new IOException(proto.getMessage());\n    } else {\n      return proto.getPayload().toByteArray();\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/DataTransferSaslUtil.java",
          "extendedDetails": {
            "oldValue": "[in-DataInputStream]",
            "newValue": "[in-InputStream]"
          }
        }
      ]
    },
    "9b4a7900c7dfc0590316eedaa97144f938885651": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3637. Add support for encrypting the DataTransferProtocol. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370354 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/12 9:40 AM",
      "commitName": "9b4a7900c7dfc0590316eedaa97144f938885651",
      "commitAuthor": "Aaron Myers",
      "diff": "@@ -0,0 +1,11 @@\n+  private static byte[] readSaslMessage(DataInputStream in) throws IOException {\n+    DataTransferEncryptorMessageProto proto \u003d\n+        DataTransferEncryptorMessageProto.parseFrom(vintPrefixed(in));\n+    if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR_UNKNOWN_KEY) {\n+      throw new InvalidEncryptionKeyException(proto.getMessage());\n+    } else if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR) {\n+      throw new IOException(proto.getMessage());\n+    } else {\n+      return proto.getPayload().toByteArray();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static byte[] readSaslMessage(DataInputStream in) throws IOException {\n    DataTransferEncryptorMessageProto proto \u003d\n        DataTransferEncryptorMessageProto.parseFrom(vintPrefixed(in));\n    if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR_UNKNOWN_KEY) {\n      throw new InvalidEncryptionKeyException(proto.getMessage());\n    } else if (proto.getStatus() \u003d\u003d DataTransferEncryptorStatus.ERROR) {\n      throw new IOException(proto.getMessage());\n    } else {\n      return proto.getPayload().toByteArray();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocol/datatransfer/DataTransferEncryptor.java"
    }
  }
}