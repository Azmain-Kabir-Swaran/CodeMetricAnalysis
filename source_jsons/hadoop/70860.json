{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AzureFileSystemThreadPoolExecutor.java",
  "functionName": "executeParallel",
  "functionId": "executeParallel___contents-FileMetadata[]__threadOperation-AzureFileSystemThreadTask",
  "sourceFilePath": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureFileSystemThreadPoolExecutor.java",
  "functionStartLine": 126,
  "functionEndLine": 238,
  "numCommitsSeen": 1,
  "timeTaken": 706,
  "changeHistory": [
    "2ed58c40e5dcbf5c5303c00e85096085b1055f85"
  ],
  "changeHistoryShort": {
    "2ed58c40e5dcbf5c5303c00e85096085b1055f85": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2ed58c40e5dcbf5c5303c00e85096085b1055f85": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13403. AzureNativeFileSystem rename/delete performance improvements. Contributed by Subramanyam Pattipaka.\n",
      "commitDate": "08/08/16 12:28 PM",
      "commitName": "2ed58c40e5dcbf5c5303c00e85096085b1055f85",
      "commitAuthor": "Chris Nauroth",
      "diff": "@@ -0,0 +1,113 @@\n+  boolean executeParallel(FileMetadata[] contents, AzureFileSystemThreadTask threadOperation) throws IOException {\n+\n+    boolean operationStatus \u003d false;\n+    boolean threadsEnabled \u003d false;\n+    int threadCount \u003d this.threadCount;\n+    ThreadPoolExecutor ioThreadPool \u003d null;\n+\n+    // Start time for file operation\n+    long start \u003d Time.monotonicNow();\n+\n+    // If number of files  are less then reduce threads to file count.\n+    threadCount \u003d Math.min(contents.length, threadCount);\n+\n+    if (threadCount \u003e 1) {\n+      try {\n+        ioThreadPool \u003d getThreadPool(threadCount);\n+        threadsEnabled \u003d true;\n+      } catch(Exception e) {\n+        // The possibility of this scenario is very remote. Added this code as safety net.\n+        LOG.warn(\"Failed to create thread pool with threads {} for operation {} on blob {}.\"\n+            + \" Use config {} to set less number of threads. Setting config value to \u003c\u003d 1 will disable threads.\",\n+            threadCount, operation, key, config);\n+      }\n+    } else {\n+      LOG.warn(\"Disabling threads for {} operation as thread count {} is \u003c\u003d 1\", operation, threadCount);\n+    }\n+\n+    if (threadsEnabled) {\n+      LOG.debug(\"Using thread pool for {} operation with threads {}\", operation, threadCount);\n+      boolean started \u003d false;\n+      AzureFileSystemThreadRunnable runnable \u003d new AzureFileSystemThreadRunnable(contents, threadOperation, operation);\n+\n+      // Don\u0027t start any new requests if there is an exception from any one thread.\n+      for (int i \u003d 0; i \u003c threadCount \u0026\u0026 runnable.lastException \u003d\u003d null \u0026\u0026 runnable.operationStatus; i++)\n+      {\n+        try {\n+          ioThreadPool.execute(runnable);\n+          started \u003d true;\n+        } catch (RejectedExecutionException ex) {\n+          // If threads can\u0027t be scheduled then report error and move ahead with next thread.\n+          // Don\u0027t fail operation due to this issue.\n+          LOG.error(\"Rejected execution of thread for {} operation on blob {}.\"\n+              + \" Continuing with existing threads. Use config {} to set less number of threads\"\n+              + \" to avoid this error\", operation, key, config);\n+        }\n+      }\n+\n+      // Stop accepting any new execute requests.\n+      ioThreadPool.shutdown();\n+\n+      try {\n+        // Wait for threads to terminate. Keep time out as large value\n+        ioThreadPool.awaitTermination(Long.MAX_VALUE, TimeUnit.DAYS);\n+      } catch(InterruptedException intrEx) {\n+        // If current thread got interrupted then shutdown all threads now.\n+        ioThreadPool.shutdownNow();\n+\n+        // Restore the interrupted status\n+        Thread.currentThread().interrupt();\n+        LOG.error(\"Threads got interrupted {} blob operation for {} \"\n+            , operation, key);\n+      }\n+\n+      int threadsNotUsed \u003d threadCount - runnable.threadsUsed.get();\n+      if (threadsNotUsed \u003e 0) {\n+        LOG.warn(\"{} threads not used for {} operation on blob {}\", threadsNotUsed, operation, key);\n+      }\n+\n+      if (!started) {\n+        // No threads started. Fall back to serial mode.\n+        threadsEnabled \u003d false;\n+        LOG.info(\"Not able to schedule threads to {} blob {}. Fall back to {} blob serially.\"\n+            , operation, key, operation);\n+      } else {\n+        IOException lastException \u003d runnable.lastException;\n+\n+        // There are no exceptions from threads and no operation failures. Consider this scenario\n+        // as failure only if file operations are not done on all files.\n+        if (lastException \u003d\u003d null \u0026\u0026 runnable.operationStatus \u0026\u0026 runnable.filesProcessed.get() \u003c contents.length) {\n+          LOG.error(\"{} failed as operation on subfolders and files failed.\", operation);\n+          lastException \u003d new IOException(operation + \" failed as operation on subfolders and files failed.\");\n+        }\n+\n+        if (lastException !\u003d null) {\n+          // Threads started and executed. One or more threads seems to have hit exception.\n+          // Raise the same exception.\n+          throw lastException;\n+        }\n+\n+        operationStatus \u003d runnable.operationStatus;\n+      }\n+    }\n+\n+    if (!threadsEnabled) {\n+      // No threads. Serialize the operation. Clear any last exceptions.\n+      LOG.debug(\"Serializing the {} operation\", operation);\n+      for (int i \u003d 0; i \u003c contents.length; i++) {\n+        if (!threadOperation.execute(contents[i])) {\n+          LOG.warn(\"Failed to {} file {}\", operation, contents[i]);\n+          return false;\n+        }\n+      }\n+\n+      // Operation is success\n+      operationStatus \u003d true;\n+    }\n+\n+    // Find the duration of time taken for file operation\n+    long end \u003d Time.monotonicNow();\n+    LOG.info(\"Time taken for {} operation is: {} ms with threads: {}\", operation, (end - start), threadCount);\n+\n+    return operationStatus;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  boolean executeParallel(FileMetadata[] contents, AzureFileSystemThreadTask threadOperation) throws IOException {\n\n    boolean operationStatus \u003d false;\n    boolean threadsEnabled \u003d false;\n    int threadCount \u003d this.threadCount;\n    ThreadPoolExecutor ioThreadPool \u003d null;\n\n    // Start time for file operation\n    long start \u003d Time.monotonicNow();\n\n    // If number of files  are less then reduce threads to file count.\n    threadCount \u003d Math.min(contents.length, threadCount);\n\n    if (threadCount \u003e 1) {\n      try {\n        ioThreadPool \u003d getThreadPool(threadCount);\n        threadsEnabled \u003d true;\n      } catch(Exception e) {\n        // The possibility of this scenario is very remote. Added this code as safety net.\n        LOG.warn(\"Failed to create thread pool with threads {} for operation {} on blob {}.\"\n            + \" Use config {} to set less number of threads. Setting config value to \u003c\u003d 1 will disable threads.\",\n            threadCount, operation, key, config);\n      }\n    } else {\n      LOG.warn(\"Disabling threads for {} operation as thread count {} is \u003c\u003d 1\", operation, threadCount);\n    }\n\n    if (threadsEnabled) {\n      LOG.debug(\"Using thread pool for {} operation with threads {}\", operation, threadCount);\n      boolean started \u003d false;\n      AzureFileSystemThreadRunnable runnable \u003d new AzureFileSystemThreadRunnable(contents, threadOperation, operation);\n\n      // Don\u0027t start any new requests if there is an exception from any one thread.\n      for (int i \u003d 0; i \u003c threadCount \u0026\u0026 runnable.lastException \u003d\u003d null \u0026\u0026 runnable.operationStatus; i++)\n      {\n        try {\n          ioThreadPool.execute(runnable);\n          started \u003d true;\n        } catch (RejectedExecutionException ex) {\n          // If threads can\u0027t be scheduled then report error and move ahead with next thread.\n          // Don\u0027t fail operation due to this issue.\n          LOG.error(\"Rejected execution of thread for {} operation on blob {}.\"\n              + \" Continuing with existing threads. Use config {} to set less number of threads\"\n              + \" to avoid this error\", operation, key, config);\n        }\n      }\n\n      // Stop accepting any new execute requests.\n      ioThreadPool.shutdown();\n\n      try {\n        // Wait for threads to terminate. Keep time out as large value\n        ioThreadPool.awaitTermination(Long.MAX_VALUE, TimeUnit.DAYS);\n      } catch(InterruptedException intrEx) {\n        // If current thread got interrupted then shutdown all threads now.\n        ioThreadPool.shutdownNow();\n\n        // Restore the interrupted status\n        Thread.currentThread().interrupt();\n        LOG.error(\"Threads got interrupted {} blob operation for {} \"\n            , operation, key);\n      }\n\n      int threadsNotUsed \u003d threadCount - runnable.threadsUsed.get();\n      if (threadsNotUsed \u003e 0) {\n        LOG.warn(\"{} threads not used for {} operation on blob {}\", threadsNotUsed, operation, key);\n      }\n\n      if (!started) {\n        // No threads started. Fall back to serial mode.\n        threadsEnabled \u003d false;\n        LOG.info(\"Not able to schedule threads to {} blob {}. Fall back to {} blob serially.\"\n            , operation, key, operation);\n      } else {\n        IOException lastException \u003d runnable.lastException;\n\n        // There are no exceptions from threads and no operation failures. Consider this scenario\n        // as failure only if file operations are not done on all files.\n        if (lastException \u003d\u003d null \u0026\u0026 runnable.operationStatus \u0026\u0026 runnable.filesProcessed.get() \u003c contents.length) {\n          LOG.error(\"{} failed as operation on subfolders and files failed.\", operation);\n          lastException \u003d new IOException(operation + \" failed as operation on subfolders and files failed.\");\n        }\n\n        if (lastException !\u003d null) {\n          // Threads started and executed. One or more threads seems to have hit exception.\n          // Raise the same exception.\n          throw lastException;\n        }\n\n        operationStatus \u003d runnable.operationStatus;\n      }\n    }\n\n    if (!threadsEnabled) {\n      // No threads. Serialize the operation. Clear any last exceptions.\n      LOG.debug(\"Serializing the {} operation\", operation);\n      for (int i \u003d 0; i \u003c contents.length; i++) {\n        if (!threadOperation.execute(contents[i])) {\n          LOG.warn(\"Failed to {} file {}\", operation, contents[i]);\n          return false;\n        }\n      }\n\n      // Operation is success\n      operationStatus \u003d true;\n    }\n\n    // Find the duration of time taken for file operation\n    long end \u003d Time.monotonicNow();\n    LOG.info(\"Time taken for {} operation is: {} ms with threads: {}\", operation, (end - start), threadCount);\n\n    return operationStatus;\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureFileSystemThreadPoolExecutor.java"
    }
  }
}