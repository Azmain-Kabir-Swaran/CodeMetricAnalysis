{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeDescriptor.java",
  "functionName": "updateHeartbeatState",
  "functionId": "updateHeartbeatState___reports-StorageReport[]__cacheCapacity-long__cacheUsed-long__xceiverCount-int__volFailures-int__volumeFailureSummary-VolumeFailureSummary",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
  "functionStartLine": 389,
  "functionEndLine": 397,
  "numCommitsSeen": 167,
  "timeTaken": 5449,
  "changeHistory": [
    "f3f5e7ad005a88afad6fa09602073eaa450e21ed",
    "c4a85c694fae3f814ab4e7f3c172da1df0e0e353",
    "5f23abfa30ea29a5474513c463b4d462c0e824ee",
    "2e7b7e2cda67eba4c03e0a2c7892d868d235b0cf",
    "2ffd84273ac490724fe7e7825664bb6d09ef0e99",
    "1feb9569f366a29ecb43592d71ee21023162c18f",
    "75ead273bea8a7dad61c4f99c3a16cab2697c498",
    "9729b244de50322c2cc889c97c2ffb2b4675cf77",
    "ef3c3a832c2f0c1e5ccdda2ff8ef84902912955f",
    "41980c56d3c01d7a0ddc7deea2d89b7f28026722"
  ],
  "changeHistoryShort": {
    "f3f5e7ad005a88afad6fa09602073eaa450e21ed": "Ymodifierchange",
    "c4a85c694fae3f814ab4e7f3c172da1df0e0e353": "Ybodychange",
    "5f23abfa30ea29a5474513c463b4d462c0e824ee": "Ybodychange",
    "2e7b7e2cda67eba4c03e0a2c7892d868d235b0cf": "Ybodychange",
    "2ffd84273ac490724fe7e7825664bb6d09ef0e99": "Ybodychange",
    "1feb9569f366a29ecb43592d71ee21023162c18f": "Ybodychange",
    "75ead273bea8a7dad61c4f99c3a16cab2697c498": "Ybodychange",
    "9729b244de50322c2cc889c97c2ffb2b4675cf77": "Ymultichange(Yparameterchange,Ybodychange)",
    "ef3c3a832c2f0c1e5ccdda2ff8ef84902912955f": "Ybodychange",
    "41980c56d3c01d7a0ddc7deea2d89b7f28026722": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f3f5e7ad005a88afad6fa09602073eaa450e21ed": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-14042. Fix NPE when PROVIDED storage is missing. Contributed by Virajith Jalaparti.\n",
      "commitDate": "05/11/18 11:02 AM",
      "commitName": "f3f5e7ad005a88afad6fa09602073eaa450e21ed",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "3ac07b720b7839a7fe6c83f4ccfe319b6a892501",
      "commitAuthorOld": "Uma Maheswara Rao Gangumalla",
      "daysBetweenCommits": 85.37,
      "commitsBetweenForRepo": 763,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,9 @@\n-  public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n+  void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n       long cacheUsed, int xceiverCount, int volFailures,\n       VolumeFailureSummary volumeFailureSummary) {\n     updateStorageStats(reports, cacheCapacity, cacheUsed, xceiverCount,\n         volFailures, volumeFailureSummary);\n     setLastUpdate(Time.now());\n     setLastUpdateMonotonic(Time.monotonicNow());\n     rollBlocksScheduled(getLastUpdateMonotonic());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n      long cacheUsed, int xceiverCount, int volFailures,\n      VolumeFailureSummary volumeFailureSummary) {\n    updateStorageStats(reports, cacheCapacity, cacheUsed, xceiverCount,\n        volFailures, volumeFailureSummary);\n    setLastUpdate(Time.now());\n    setLastUpdateMonotonic(Time.monotonicNow());\n    rollBlocksScheduled(getLastUpdateMonotonic());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {
        "oldValue": "[public]",
        "newValue": "[]"
      }
    },
    "c4a85c694fae3f814ab4e7f3c172da1df0e0e353": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11896. Non-dfsUsed will be doubled on dead node re-registration. Contributed by Brahma Reddy Battula.",
      "commitDate": "27/07/17 12:02 PM",
      "commitName": "c4a85c694fae3f814ab4e7f3c172da1df0e0e353",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "26/06/17 10:54 AM",
      "commitNameOld": "06c8ca3bb330c1763d31ed37309e7552dcd3e7aa",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 31.05,
      "commitsBetweenForRepo": 148,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,89 +1,9 @@\n   public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n       long cacheUsed, int xceiverCount, int volFailures,\n       VolumeFailureSummary volumeFailureSummary) {\n-    long totalCapacity \u003d 0;\n-    long totalRemaining \u003d 0;\n-    long totalBlockPoolUsed \u003d 0;\n-    long totalDfsUsed \u003d 0;\n-    long totalNonDfsUsed \u003d 0;\n-    Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n-\n-    // Decide if we should check for any missing StorageReport and mark it as\n-    // failed. There are different scenarios.\n-    // 1. When DN is running, a storage failed. Given the current DN\n-    //    implementation doesn\u0027t add recovered storage back to its storage list\n-    //    until DN restart, we can assume volFailures won\u0027t decrease\n-    //    during the current DN registration session.\n-    //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n-    //    state change. No need to check for failed storage. This is an\n-    //    optimization.  Recent versions of the DataNode report a\n-    //    VolumeFailureSummary containing the date/time of the last volume\n-    //    failure.  If that\u0027s available, then we check that instead for greater\n-    //    accuracy.\n-    // 2. After DN restarts, volFailures might not increase and it is possible\n-    //    we still have new failed storage. For example, admins reduce\n-    //    available storages in configuration. Another corner case\n-    //    is the failed volumes might change after restart; a) there\n-    //    is one good storage A, one restored good storage B, so there is\n-    //    one element in storageReports and that is A. b) A failed. c) Before\n-    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n-    //    restarts, storageReports has one element which is B.\n-    final boolean checkFailedStorages;\n-    if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n-      checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n-          this.volumeFailureSummary.getLastVolumeFailureDate();\n-    } else {\n-      checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n-          !heartbeatedSinceRegistration;\n-    }\n-\n-    if (checkFailedStorages) {\n-      if (this.volumeFailures !\u003d volFailures) {\n-        LOG.info(\"Number of failed storages changes from {} to {}\",\n-            this.volumeFailures, volFailures);\n-      }\n-      synchronized (storageMap) {\n-        failedStorageInfos \u003d\n-            new HashSet\u003c\u003e(storageMap.values());\n-      }\n-    }\n-\n-    setCacheCapacity(cacheCapacity);\n-    setCacheUsed(cacheUsed);\n-    setXceiverCount(xceiverCount);\n+    updateStorageStats(reports, cacheCapacity, cacheUsed, xceiverCount,\n+        volFailures, volumeFailureSummary);\n     setLastUpdate(Time.now());\n     setLastUpdateMonotonic(Time.monotonicNow());\n-    this.volumeFailures \u003d volFailures;\n-    this.volumeFailureSummary \u003d volumeFailureSummary;\n-    for (StorageReport report : reports) {\n-      DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n-      if (checkFailedStorages) {\n-        failedStorageInfos.remove(storage);\n-      }\n-\n-      storage.receivedHeartbeat(report);\n-      totalCapacity +\u003d report.getCapacity();\n-      totalRemaining +\u003d report.getRemaining();\n-      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n-      totalDfsUsed +\u003d report.getDfsUsed();\n-      totalNonDfsUsed +\u003d report.getNonDfsUsed();\n-    }\n     rollBlocksScheduled(getLastUpdateMonotonic());\n-\n-    // Update total metrics for the node.\n-    setCapacity(totalCapacity);\n-    setRemaining(totalRemaining);\n-    setBlockPoolUsed(totalBlockPoolUsed);\n-    setDfsUsed(totalDfsUsed);\n-    setNonDfsUsed(totalNonDfsUsed);\n-    if (checkFailedStorages) {\n-      updateFailedStorage(failedStorageInfos);\n-    }\n-    long storageMapSize;\n-    synchronized (storageMap) {\n-      storageMapSize \u003d storageMap.size();\n-    }\n-    if (storageMapSize !\u003d reports.length) {\n-      pruneStorageMap(reports);\n-    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n      long cacheUsed, int xceiverCount, int volFailures,\n      VolumeFailureSummary volumeFailureSummary) {\n    updateStorageStats(reports, cacheCapacity, cacheUsed, xceiverCount,\n        volFailures, volumeFailureSummary);\n    setLastUpdate(Time.now());\n    setLastUpdateMonotonic(Time.monotonicNow());\n    rollBlocksScheduled(getLastUpdateMonotonic());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "5f23abfa30ea29a5474513c463b4d462c0e824ee": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9038. DFS reserved space is erroneously counted towards non-DFS used. (Brahma Reddy Battula)\n",
      "commitDate": "06/09/16 1:37 PM",
      "commitName": "5f23abfa30ea29a5474513c463b4d462c0e824ee",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "01/08/16 10:34 PM",
      "commitNameOld": "c4463f2ef20d2cb634a1249246f83c451975f3dc",
      "commitAuthorOld": "Konstantin V Shvachko",
      "daysBetweenCommits": 35.63,
      "commitsBetweenForRepo": 246,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,89 @@\n   public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n       long cacheUsed, int xceiverCount, int volFailures,\n       VolumeFailureSummary volumeFailureSummary) {\n     long totalCapacity \u003d 0;\n     long totalRemaining \u003d 0;\n     long totalBlockPoolUsed \u003d 0;\n     long totalDfsUsed \u003d 0;\n+    long totalNonDfsUsed \u003d 0;\n     Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n \n     // Decide if we should check for any missing StorageReport and mark it as\n     // failed. There are different scenarios.\n     // 1. When DN is running, a storage failed. Given the current DN\n     //    implementation doesn\u0027t add recovered storage back to its storage list\n     //    until DN restart, we can assume volFailures won\u0027t decrease\n     //    during the current DN registration session.\n     //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n     //    state change. No need to check for failed storage. This is an\n     //    optimization.  Recent versions of the DataNode report a\n     //    VolumeFailureSummary containing the date/time of the last volume\n     //    failure.  If that\u0027s available, then we check that instead for greater\n     //    accuracy.\n     // 2. After DN restarts, volFailures might not increase and it is possible\n     //    we still have new failed storage. For example, admins reduce\n     //    available storages in configuration. Another corner case\n     //    is the failed volumes might change after restart; a) there\n     //    is one good storage A, one restored good storage B, so there is\n     //    one element in storageReports and that is A. b) A failed. c) Before\n     //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n     //    restarts, storageReports has one element which is B.\n     final boolean checkFailedStorages;\n     if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n       checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n           this.volumeFailureSummary.getLastVolumeFailureDate();\n     } else {\n       checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n           !heartbeatedSinceRegistration;\n     }\n \n     if (checkFailedStorages) {\n       if (this.volumeFailures !\u003d volFailures) {\n         LOG.info(\"Number of failed storages changes from {} to {}\",\n             this.volumeFailures, volFailures);\n       }\n       synchronized (storageMap) {\n         failedStorageInfos \u003d\n             new HashSet\u003c\u003e(storageMap.values());\n       }\n     }\n \n     setCacheCapacity(cacheCapacity);\n     setCacheUsed(cacheUsed);\n     setXceiverCount(xceiverCount);\n     setLastUpdate(Time.now());\n     setLastUpdateMonotonic(Time.monotonicNow());\n     this.volumeFailures \u003d volFailures;\n     this.volumeFailureSummary \u003d volumeFailureSummary;\n     for (StorageReport report : reports) {\n       DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n       if (checkFailedStorages) {\n         failedStorageInfos.remove(storage);\n       }\n \n       storage.receivedHeartbeat(report);\n       totalCapacity +\u003d report.getCapacity();\n       totalRemaining +\u003d report.getRemaining();\n       totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n       totalDfsUsed +\u003d report.getDfsUsed();\n+      totalNonDfsUsed +\u003d report.getNonDfsUsed();\n     }\n     rollBlocksScheduled(getLastUpdateMonotonic());\n \n     // Update total metrics for the node.\n     setCapacity(totalCapacity);\n     setRemaining(totalRemaining);\n     setBlockPoolUsed(totalBlockPoolUsed);\n     setDfsUsed(totalDfsUsed);\n+    setNonDfsUsed(totalNonDfsUsed);\n     if (checkFailedStorages) {\n       updateFailedStorage(failedStorageInfos);\n     }\n     long storageMapSize;\n     synchronized (storageMap) {\n       storageMapSize \u003d storageMap.size();\n     }\n     if (storageMapSize !\u003d reports.length) {\n       pruneStorageMap(reports);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n      long cacheUsed, int xceiverCount, int volFailures,\n      VolumeFailureSummary volumeFailureSummary) {\n    long totalCapacity \u003d 0;\n    long totalRemaining \u003d 0;\n    long totalBlockPoolUsed \u003d 0;\n    long totalDfsUsed \u003d 0;\n    long totalNonDfsUsed \u003d 0;\n    Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n\n    // Decide if we should check for any missing StorageReport and mark it as\n    // failed. There are different scenarios.\n    // 1. When DN is running, a storage failed. Given the current DN\n    //    implementation doesn\u0027t add recovered storage back to its storage list\n    //    until DN restart, we can assume volFailures won\u0027t decrease\n    //    during the current DN registration session.\n    //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n    //    state change. No need to check for failed storage. This is an\n    //    optimization.  Recent versions of the DataNode report a\n    //    VolumeFailureSummary containing the date/time of the last volume\n    //    failure.  If that\u0027s available, then we check that instead for greater\n    //    accuracy.\n    // 2. After DN restarts, volFailures might not increase and it is possible\n    //    we still have new failed storage. For example, admins reduce\n    //    available storages in configuration. Another corner case\n    //    is the failed volumes might change after restart; a) there\n    //    is one good storage A, one restored good storage B, so there is\n    //    one element in storageReports and that is A. b) A failed. c) Before\n    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n    //    restarts, storageReports has one element which is B.\n    final boolean checkFailedStorages;\n    if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n      checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n          this.volumeFailureSummary.getLastVolumeFailureDate();\n    } else {\n      checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n          !heartbeatedSinceRegistration;\n    }\n\n    if (checkFailedStorages) {\n      if (this.volumeFailures !\u003d volFailures) {\n        LOG.info(\"Number of failed storages changes from {} to {}\",\n            this.volumeFailures, volFailures);\n      }\n      synchronized (storageMap) {\n        failedStorageInfos \u003d\n            new HashSet\u003c\u003e(storageMap.values());\n      }\n    }\n\n    setCacheCapacity(cacheCapacity);\n    setCacheUsed(cacheUsed);\n    setXceiverCount(xceiverCount);\n    setLastUpdate(Time.now());\n    setLastUpdateMonotonic(Time.monotonicNow());\n    this.volumeFailures \u003d volFailures;\n    this.volumeFailureSummary \u003d volumeFailureSummary;\n    for (StorageReport report : reports) {\n      DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n      if (checkFailedStorages) {\n        failedStorageInfos.remove(storage);\n      }\n\n      storage.receivedHeartbeat(report);\n      totalCapacity +\u003d report.getCapacity();\n      totalRemaining +\u003d report.getRemaining();\n      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n      totalDfsUsed +\u003d report.getDfsUsed();\n      totalNonDfsUsed +\u003d report.getNonDfsUsed();\n    }\n    rollBlocksScheduled(getLastUpdateMonotonic());\n\n    // Update total metrics for the node.\n    setCapacity(totalCapacity);\n    setRemaining(totalRemaining);\n    setBlockPoolUsed(totalBlockPoolUsed);\n    setDfsUsed(totalDfsUsed);\n    setNonDfsUsed(totalNonDfsUsed);\n    if (checkFailedStorages) {\n      updateFailedStorage(failedStorageInfos);\n    }\n    long storageMapSize;\n    synchronized (storageMap) {\n      storageMapSize \u003d storageMap.size();\n    }\n    if (storageMapSize !\u003d reports.length) {\n      pruneStorageMap(reports);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "2e7b7e2cda67eba4c03e0a2c7892d868d235b0cf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8713. Convert DatanodeDescriptor to use SLF4J logging.\n",
      "commitDate": "17/08/15 10:17 AM",
      "commitName": "2e7b7e2cda67eba4c03e0a2c7892d868d235b0cf",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "06/08/15 10:21 AM",
      "commitNameOld": "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 11.0,
      "commitsBetweenForRepo": 44,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,86 @@\n   public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n       long cacheUsed, int xceiverCount, int volFailures,\n       VolumeFailureSummary volumeFailureSummary) {\n     long totalCapacity \u003d 0;\n     long totalRemaining \u003d 0;\n     long totalBlockPoolUsed \u003d 0;\n     long totalDfsUsed \u003d 0;\n     Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n \n     // Decide if we should check for any missing StorageReport and mark it as\n     // failed. There are different scenarios.\n     // 1. When DN is running, a storage failed. Given the current DN\n     //    implementation doesn\u0027t add recovered storage back to its storage list\n     //    until DN restart, we can assume volFailures won\u0027t decrease\n     //    during the current DN registration session.\n     //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n     //    state change. No need to check for failed storage. This is an\n     //    optimization.  Recent versions of the DataNode report a\n     //    VolumeFailureSummary containing the date/time of the last volume\n     //    failure.  If that\u0027s available, then we check that instead for greater\n     //    accuracy.\n     // 2. After DN restarts, volFailures might not increase and it is possible\n     //    we still have new failed storage. For example, admins reduce\n     //    available storages in configuration. Another corner case\n     //    is the failed volumes might change after restart; a) there\n     //    is one good storage A, one restored good storage B, so there is\n     //    one element in storageReports and that is A. b) A failed. c) Before\n     //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n     //    restarts, storageReports has one element which is B.\n     final boolean checkFailedStorages;\n     if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n       checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n           this.volumeFailureSummary.getLastVolumeFailureDate();\n     } else {\n       checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n           !heartbeatedSinceRegistration;\n     }\n \n     if (checkFailedStorages) {\n-      LOG.info(\"Number of failed storage changes from \"\n-          + this.volumeFailures + \" to \" + volFailures);\n+      if (this.volumeFailures !\u003d volFailures) {\n+        LOG.info(\"Number of failed storages changes from {} to {}\",\n+            this.volumeFailures, volFailures);\n+      }\n       synchronized (storageMap) {\n         failedStorageInfos \u003d\n             new HashSet\u003c\u003e(storageMap.values());\n       }\n     }\n \n     setCacheCapacity(cacheCapacity);\n     setCacheUsed(cacheUsed);\n     setXceiverCount(xceiverCount);\n     setLastUpdate(Time.now());\n     setLastUpdateMonotonic(Time.monotonicNow());\n     this.volumeFailures \u003d volFailures;\n     this.volumeFailureSummary \u003d volumeFailureSummary;\n     for (StorageReport report : reports) {\n       DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n       if (checkFailedStorages) {\n         failedStorageInfos.remove(storage);\n       }\n \n       storage.receivedHeartbeat(report);\n       totalCapacity +\u003d report.getCapacity();\n       totalRemaining +\u003d report.getRemaining();\n       totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n       totalDfsUsed +\u003d report.getDfsUsed();\n     }\n     rollBlocksScheduled(getLastUpdateMonotonic());\n \n     // Update total metrics for the node.\n     setCapacity(totalCapacity);\n     setRemaining(totalRemaining);\n     setBlockPoolUsed(totalBlockPoolUsed);\n     setDfsUsed(totalDfsUsed);\n     if (checkFailedStorages) {\n       updateFailedStorage(failedStorageInfos);\n     }\n     long storageMapSize;\n     synchronized (storageMap) {\n       storageMapSize \u003d storageMap.size();\n     }\n     if (storageMapSize !\u003d reports.length) {\n       pruneStorageMap(reports);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n      long cacheUsed, int xceiverCount, int volFailures,\n      VolumeFailureSummary volumeFailureSummary) {\n    long totalCapacity \u003d 0;\n    long totalRemaining \u003d 0;\n    long totalBlockPoolUsed \u003d 0;\n    long totalDfsUsed \u003d 0;\n    Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n\n    // Decide if we should check for any missing StorageReport and mark it as\n    // failed. There are different scenarios.\n    // 1. When DN is running, a storage failed. Given the current DN\n    //    implementation doesn\u0027t add recovered storage back to its storage list\n    //    until DN restart, we can assume volFailures won\u0027t decrease\n    //    during the current DN registration session.\n    //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n    //    state change. No need to check for failed storage. This is an\n    //    optimization.  Recent versions of the DataNode report a\n    //    VolumeFailureSummary containing the date/time of the last volume\n    //    failure.  If that\u0027s available, then we check that instead for greater\n    //    accuracy.\n    // 2. After DN restarts, volFailures might not increase and it is possible\n    //    we still have new failed storage. For example, admins reduce\n    //    available storages in configuration. Another corner case\n    //    is the failed volumes might change after restart; a) there\n    //    is one good storage A, one restored good storage B, so there is\n    //    one element in storageReports and that is A. b) A failed. c) Before\n    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n    //    restarts, storageReports has one element which is B.\n    final boolean checkFailedStorages;\n    if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n      checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n          this.volumeFailureSummary.getLastVolumeFailureDate();\n    } else {\n      checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n          !heartbeatedSinceRegistration;\n    }\n\n    if (checkFailedStorages) {\n      if (this.volumeFailures !\u003d volFailures) {\n        LOG.info(\"Number of failed storages changes from {} to {}\",\n            this.volumeFailures, volFailures);\n      }\n      synchronized (storageMap) {\n        failedStorageInfos \u003d\n            new HashSet\u003c\u003e(storageMap.values());\n      }\n    }\n\n    setCacheCapacity(cacheCapacity);\n    setCacheUsed(cacheUsed);\n    setXceiverCount(xceiverCount);\n    setLastUpdate(Time.now());\n    setLastUpdateMonotonic(Time.monotonicNow());\n    this.volumeFailures \u003d volFailures;\n    this.volumeFailureSummary \u003d volumeFailureSummary;\n    for (StorageReport report : reports) {\n      DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n      if (checkFailedStorages) {\n        failedStorageInfos.remove(storage);\n      }\n\n      storage.receivedHeartbeat(report);\n      totalCapacity +\u003d report.getCapacity();\n      totalRemaining +\u003d report.getRemaining();\n      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n      totalDfsUsed +\u003d report.getDfsUsed();\n    }\n    rollBlocksScheduled(getLastUpdateMonotonic());\n\n    // Update total metrics for the node.\n    setCapacity(totalCapacity);\n    setRemaining(totalRemaining);\n    setBlockPoolUsed(totalBlockPoolUsed);\n    setDfsUsed(totalDfsUsed);\n    if (checkFailedStorages) {\n      updateFailedStorage(failedStorageInfos);\n    }\n    long storageMapSize;\n    synchronized (storageMap) {\n      storageMapSize \u003d storageMap.size();\n    }\n    if (storageMapSize !\u003d reports.length) {\n      pruneStorageMap(reports);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "2ffd84273ac490724fe7e7825664bb6d09ef0e99": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8653. Code cleanup for DatanodeManager, DatanodeDescriptor and DatanodeStorageInfo. Contributed by Zhe Zhang.\n",
      "commitDate": "29/06/15 12:12 PM",
      "commitName": "2ffd84273ac490724fe7e7825664bb6d09ef0e99",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "12/06/15 11:38 AM",
      "commitNameOld": "c17439c2ddd921b63b1635e6f1cba634b8da8557",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 17.02,
      "commitsBetweenForRepo": 104,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,84 @@\n   public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n       long cacheUsed, int xceiverCount, int volFailures,\n       VolumeFailureSummary volumeFailureSummary) {\n     long totalCapacity \u003d 0;\n     long totalRemaining \u003d 0;\n     long totalBlockPoolUsed \u003d 0;\n     long totalDfsUsed \u003d 0;\n     Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n \n     // Decide if we should check for any missing StorageReport and mark it as\n     // failed. There are different scenarios.\n     // 1. When DN is running, a storage failed. Given the current DN\n     //    implementation doesn\u0027t add recovered storage back to its storage list\n     //    until DN restart, we can assume volFailures won\u0027t decrease\n     //    during the current DN registration session.\n     //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n     //    state change. No need to check for failed storage. This is an\n     //    optimization.  Recent versions of the DataNode report a\n     //    VolumeFailureSummary containing the date/time of the last volume\n     //    failure.  If that\u0027s available, then we check that instead for greater\n     //    accuracy.\n     // 2. After DN restarts, volFailures might not increase and it is possible\n     //    we still have new failed storage. For example, admins reduce\n     //    available storages in configuration. Another corner case\n     //    is the failed volumes might change after restart; a) there\n     //    is one good storage A, one restored good storage B, so there is\n     //    one element in storageReports and that is A. b) A failed. c) Before\n     //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n     //    restarts, storageReports has one element which is B.\n     final boolean checkFailedStorages;\n     if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n       checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n           this.volumeFailureSummary.getLastVolumeFailureDate();\n     } else {\n       checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n           !heartbeatedSinceRegistration;\n     }\n \n     if (checkFailedStorages) {\n       LOG.info(\"Number of failed storage changes from \"\n           + this.volumeFailures + \" to \" + volFailures);\n       synchronized (storageMap) {\n         failedStorageInfos \u003d\n-            new HashSet\u003cDatanodeStorageInfo\u003e(storageMap.values());\n+            new HashSet\u003c\u003e(storageMap.values());\n       }\n     }\n \n     setCacheCapacity(cacheCapacity);\n     setCacheUsed(cacheUsed);\n     setXceiverCount(xceiverCount);\n     setLastUpdate(Time.now());\n     setLastUpdateMonotonic(Time.monotonicNow());\n     this.volumeFailures \u003d volFailures;\n     this.volumeFailureSummary \u003d volumeFailureSummary;\n     for (StorageReport report : reports) {\n       DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n       if (checkFailedStorages) {\n         failedStorageInfos.remove(storage);\n       }\n \n       storage.receivedHeartbeat(report);\n       totalCapacity +\u003d report.getCapacity();\n       totalRemaining +\u003d report.getRemaining();\n       totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n       totalDfsUsed +\u003d report.getDfsUsed();\n     }\n     rollBlocksScheduled(getLastUpdateMonotonic());\n \n     // Update total metrics for the node.\n     setCapacity(totalCapacity);\n     setRemaining(totalRemaining);\n     setBlockPoolUsed(totalBlockPoolUsed);\n     setDfsUsed(totalDfsUsed);\n     if (checkFailedStorages) {\n       updateFailedStorage(failedStorageInfos);\n     }\n     long storageMapSize;\n     synchronized (storageMap) {\n       storageMapSize \u003d storageMap.size();\n     }\n     if (storageMapSize !\u003d reports.length) {\n       pruneStorageMap(reports);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n      long cacheUsed, int xceiverCount, int volFailures,\n      VolumeFailureSummary volumeFailureSummary) {\n    long totalCapacity \u003d 0;\n    long totalRemaining \u003d 0;\n    long totalBlockPoolUsed \u003d 0;\n    long totalDfsUsed \u003d 0;\n    Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n\n    // Decide if we should check for any missing StorageReport and mark it as\n    // failed. There are different scenarios.\n    // 1. When DN is running, a storage failed. Given the current DN\n    //    implementation doesn\u0027t add recovered storage back to its storage list\n    //    until DN restart, we can assume volFailures won\u0027t decrease\n    //    during the current DN registration session.\n    //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n    //    state change. No need to check for failed storage. This is an\n    //    optimization.  Recent versions of the DataNode report a\n    //    VolumeFailureSummary containing the date/time of the last volume\n    //    failure.  If that\u0027s available, then we check that instead for greater\n    //    accuracy.\n    // 2. After DN restarts, volFailures might not increase and it is possible\n    //    we still have new failed storage. For example, admins reduce\n    //    available storages in configuration. Another corner case\n    //    is the failed volumes might change after restart; a) there\n    //    is one good storage A, one restored good storage B, so there is\n    //    one element in storageReports and that is A. b) A failed. c) Before\n    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n    //    restarts, storageReports has one element which is B.\n    final boolean checkFailedStorages;\n    if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n      checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n          this.volumeFailureSummary.getLastVolumeFailureDate();\n    } else {\n      checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n          !heartbeatedSinceRegistration;\n    }\n\n    if (checkFailedStorages) {\n      LOG.info(\"Number of failed storage changes from \"\n          + this.volumeFailures + \" to \" + volFailures);\n      synchronized (storageMap) {\n        failedStorageInfos \u003d\n            new HashSet\u003c\u003e(storageMap.values());\n      }\n    }\n\n    setCacheCapacity(cacheCapacity);\n    setCacheUsed(cacheUsed);\n    setXceiverCount(xceiverCount);\n    setLastUpdate(Time.now());\n    setLastUpdateMonotonic(Time.monotonicNow());\n    this.volumeFailures \u003d volFailures;\n    this.volumeFailureSummary \u003d volumeFailureSummary;\n    for (StorageReport report : reports) {\n      DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n      if (checkFailedStorages) {\n        failedStorageInfos.remove(storage);\n      }\n\n      storage.receivedHeartbeat(report);\n      totalCapacity +\u003d report.getCapacity();\n      totalRemaining +\u003d report.getRemaining();\n      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n      totalDfsUsed +\u003d report.getDfsUsed();\n    }\n    rollBlocksScheduled(getLastUpdateMonotonic());\n\n    // Update total metrics for the node.\n    setCapacity(totalCapacity);\n    setRemaining(totalRemaining);\n    setBlockPoolUsed(totalBlockPoolUsed);\n    setDfsUsed(totalDfsUsed);\n    if (checkFailedStorages) {\n      updateFailedStorage(failedStorageInfos);\n    }\n    long storageMapSize;\n    synchronized (storageMap) {\n      storageMapSize \u003d storageMap.size();\n    }\n    if (storageMapSize !\u003d reports.length) {\n      pruneStorageMap(reports);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "1feb9569f366a29ecb43592d71ee21023162c18f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7261. storageMap is accessed without synchronization in DatanodeDescriptor#updateHeartbeatState() (Brahma Reddy Battula via Colin P. McCabe)\n",
      "commitDate": "30/03/15 10:46 AM",
      "commitName": "1feb9569f366a29ecb43592d71ee21023162c18f",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "23/03/15 10:00 PM",
      "commitNameOld": "50ee8f4e67a66aa77c5359182f61f3e951844db6",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 6.53,
      "commitsBetweenForRepo": 56,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,79 +1,84 @@\n   public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n       long cacheUsed, int xceiverCount, int volFailures,\n       VolumeFailureSummary volumeFailureSummary) {\n     long totalCapacity \u003d 0;\n     long totalRemaining \u003d 0;\n     long totalBlockPoolUsed \u003d 0;\n     long totalDfsUsed \u003d 0;\n     Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n \n     // Decide if we should check for any missing StorageReport and mark it as\n     // failed. There are different scenarios.\n     // 1. When DN is running, a storage failed. Given the current DN\n     //    implementation doesn\u0027t add recovered storage back to its storage list\n     //    until DN restart, we can assume volFailures won\u0027t decrease\n     //    during the current DN registration session.\n     //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n     //    state change. No need to check for failed storage. This is an\n     //    optimization.  Recent versions of the DataNode report a\n     //    VolumeFailureSummary containing the date/time of the last volume\n     //    failure.  If that\u0027s available, then we check that instead for greater\n     //    accuracy.\n     // 2. After DN restarts, volFailures might not increase and it is possible\n     //    we still have new failed storage. For example, admins reduce\n     //    available storages in configuration. Another corner case\n     //    is the failed volumes might change after restart; a) there\n     //    is one good storage A, one restored good storage B, so there is\n     //    one element in storageReports and that is A. b) A failed. c) Before\n     //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n     //    restarts, storageReports has one element which is B.\n     final boolean checkFailedStorages;\n     if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n       checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n           this.volumeFailureSummary.getLastVolumeFailureDate();\n     } else {\n       checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n           !heartbeatedSinceRegistration;\n     }\n \n     if (checkFailedStorages) {\n       LOG.info(\"Number of failed storage changes from \"\n           + this.volumeFailures + \" to \" + volFailures);\n-      failedStorageInfos \u003d new HashSet\u003cDatanodeStorageInfo\u003e(\n-          storageMap.values());\n+      synchronized (storageMap) {\n+        failedStorageInfos \u003d\n+            new HashSet\u003cDatanodeStorageInfo\u003e(storageMap.values());\n+      }\n     }\n \n     setCacheCapacity(cacheCapacity);\n     setCacheUsed(cacheUsed);\n     setXceiverCount(xceiverCount);\n     setLastUpdate(Time.now());\n     setLastUpdateMonotonic(Time.monotonicNow());\n     this.volumeFailures \u003d volFailures;\n     this.volumeFailureSummary \u003d volumeFailureSummary;\n     for (StorageReport report : reports) {\n       DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n       if (checkFailedStorages) {\n         failedStorageInfos.remove(storage);\n       }\n \n       storage.receivedHeartbeat(report);\n       totalCapacity +\u003d report.getCapacity();\n       totalRemaining +\u003d report.getRemaining();\n       totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n       totalDfsUsed +\u003d report.getDfsUsed();\n     }\n     rollBlocksScheduled(getLastUpdateMonotonic());\n \n     // Update total metrics for the node.\n     setCapacity(totalCapacity);\n     setRemaining(totalRemaining);\n     setBlockPoolUsed(totalBlockPoolUsed);\n     setDfsUsed(totalDfsUsed);\n     if (checkFailedStorages) {\n       updateFailedStorage(failedStorageInfos);\n     }\n-\n-    if (storageMap.size() !\u003d reports.length) {\n+    long storageMapSize;\n+    synchronized (storageMap) {\n+      storageMapSize \u003d storageMap.size();\n+    }\n+    if (storageMapSize !\u003d reports.length) {\n       pruneStorageMap(reports);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n      long cacheUsed, int xceiverCount, int volFailures,\n      VolumeFailureSummary volumeFailureSummary) {\n    long totalCapacity \u003d 0;\n    long totalRemaining \u003d 0;\n    long totalBlockPoolUsed \u003d 0;\n    long totalDfsUsed \u003d 0;\n    Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n\n    // Decide if we should check for any missing StorageReport and mark it as\n    // failed. There are different scenarios.\n    // 1. When DN is running, a storage failed. Given the current DN\n    //    implementation doesn\u0027t add recovered storage back to its storage list\n    //    until DN restart, we can assume volFailures won\u0027t decrease\n    //    during the current DN registration session.\n    //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n    //    state change. No need to check for failed storage. This is an\n    //    optimization.  Recent versions of the DataNode report a\n    //    VolumeFailureSummary containing the date/time of the last volume\n    //    failure.  If that\u0027s available, then we check that instead for greater\n    //    accuracy.\n    // 2. After DN restarts, volFailures might not increase and it is possible\n    //    we still have new failed storage. For example, admins reduce\n    //    available storages in configuration. Another corner case\n    //    is the failed volumes might change after restart; a) there\n    //    is one good storage A, one restored good storage B, so there is\n    //    one element in storageReports and that is A. b) A failed. c) Before\n    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n    //    restarts, storageReports has one element which is B.\n    final boolean checkFailedStorages;\n    if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n      checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n          this.volumeFailureSummary.getLastVolumeFailureDate();\n    } else {\n      checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n          !heartbeatedSinceRegistration;\n    }\n\n    if (checkFailedStorages) {\n      LOG.info(\"Number of failed storage changes from \"\n          + this.volumeFailures + \" to \" + volFailures);\n      synchronized (storageMap) {\n        failedStorageInfos \u003d\n            new HashSet\u003cDatanodeStorageInfo\u003e(storageMap.values());\n      }\n    }\n\n    setCacheCapacity(cacheCapacity);\n    setCacheUsed(cacheUsed);\n    setXceiverCount(xceiverCount);\n    setLastUpdate(Time.now());\n    setLastUpdateMonotonic(Time.monotonicNow());\n    this.volumeFailures \u003d volFailures;\n    this.volumeFailureSummary \u003d volumeFailureSummary;\n    for (StorageReport report : reports) {\n      DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n      if (checkFailedStorages) {\n        failedStorageInfos.remove(storage);\n      }\n\n      storage.receivedHeartbeat(report);\n      totalCapacity +\u003d report.getCapacity();\n      totalRemaining +\u003d report.getRemaining();\n      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n      totalDfsUsed +\u003d report.getDfsUsed();\n    }\n    rollBlocksScheduled(getLastUpdateMonotonic());\n\n    // Update total metrics for the node.\n    setCapacity(totalCapacity);\n    setRemaining(totalRemaining);\n    setBlockPoolUsed(totalBlockPoolUsed);\n    setDfsUsed(totalDfsUsed);\n    if (checkFailedStorages) {\n      updateFailedStorage(failedStorageInfos);\n    }\n    long storageMapSize;\n    synchronized (storageMap) {\n      storageMapSize \u003d storageMap.size();\n    }\n    if (storageMapSize !\u003d reports.length) {\n      pruneStorageMap(reports);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "75ead273bea8a7dad61c4f99c3a16cab2697c498": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6841. Use Time.monotonicNow() wherever applicable instead of Time.now(). Contributed by Vinayakumar B\n",
      "commitDate": "20/03/15 12:02 PM",
      "commitName": "75ead273bea8a7dad61c4f99c3a16cab2697c498",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "21/02/15 3:38 PM",
      "commitNameOld": "8b465b4b8caed31ca9daeaae108f9a868a30a455",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 26.81,
      "commitsBetweenForRepo": 229,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,78 +1,79 @@\n   public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n       long cacheUsed, int xceiverCount, int volFailures,\n       VolumeFailureSummary volumeFailureSummary) {\n     long totalCapacity \u003d 0;\n     long totalRemaining \u003d 0;\n     long totalBlockPoolUsed \u003d 0;\n     long totalDfsUsed \u003d 0;\n     Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n \n     // Decide if we should check for any missing StorageReport and mark it as\n     // failed. There are different scenarios.\n     // 1. When DN is running, a storage failed. Given the current DN\n     //    implementation doesn\u0027t add recovered storage back to its storage list\n     //    until DN restart, we can assume volFailures won\u0027t decrease\n     //    during the current DN registration session.\n     //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n     //    state change. No need to check for failed storage. This is an\n     //    optimization.  Recent versions of the DataNode report a\n     //    VolumeFailureSummary containing the date/time of the last volume\n     //    failure.  If that\u0027s available, then we check that instead for greater\n     //    accuracy.\n     // 2. After DN restarts, volFailures might not increase and it is possible\n     //    we still have new failed storage. For example, admins reduce\n     //    available storages in configuration. Another corner case\n     //    is the failed volumes might change after restart; a) there\n     //    is one good storage A, one restored good storage B, so there is\n     //    one element in storageReports and that is A. b) A failed. c) Before\n     //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n     //    restarts, storageReports has one element which is B.\n     final boolean checkFailedStorages;\n     if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n       checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n           this.volumeFailureSummary.getLastVolumeFailureDate();\n     } else {\n       checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n           !heartbeatedSinceRegistration;\n     }\n \n     if (checkFailedStorages) {\n       LOG.info(\"Number of failed storage changes from \"\n           + this.volumeFailures + \" to \" + volFailures);\n       failedStorageInfos \u003d new HashSet\u003cDatanodeStorageInfo\u003e(\n           storageMap.values());\n     }\n \n     setCacheCapacity(cacheCapacity);\n     setCacheUsed(cacheUsed);\n     setXceiverCount(xceiverCount);\n-    setLastUpdate(Time.now());    \n+    setLastUpdate(Time.now());\n+    setLastUpdateMonotonic(Time.monotonicNow());\n     this.volumeFailures \u003d volFailures;\n     this.volumeFailureSummary \u003d volumeFailureSummary;\n     for (StorageReport report : reports) {\n       DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n       if (checkFailedStorages) {\n         failedStorageInfos.remove(storage);\n       }\n \n       storage.receivedHeartbeat(report);\n       totalCapacity +\u003d report.getCapacity();\n       totalRemaining +\u003d report.getRemaining();\n       totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n       totalDfsUsed +\u003d report.getDfsUsed();\n     }\n-    rollBlocksScheduled(getLastUpdate());\n+    rollBlocksScheduled(getLastUpdateMonotonic());\n \n     // Update total metrics for the node.\n     setCapacity(totalCapacity);\n     setRemaining(totalRemaining);\n     setBlockPoolUsed(totalBlockPoolUsed);\n     setDfsUsed(totalDfsUsed);\n     if (checkFailedStorages) {\n       updateFailedStorage(failedStorageInfos);\n     }\n \n     if (storageMap.size() !\u003d reports.length) {\n       pruneStorageMap(reports);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n      long cacheUsed, int xceiverCount, int volFailures,\n      VolumeFailureSummary volumeFailureSummary) {\n    long totalCapacity \u003d 0;\n    long totalRemaining \u003d 0;\n    long totalBlockPoolUsed \u003d 0;\n    long totalDfsUsed \u003d 0;\n    Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n\n    // Decide if we should check for any missing StorageReport and mark it as\n    // failed. There are different scenarios.\n    // 1. When DN is running, a storage failed. Given the current DN\n    //    implementation doesn\u0027t add recovered storage back to its storage list\n    //    until DN restart, we can assume volFailures won\u0027t decrease\n    //    during the current DN registration session.\n    //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n    //    state change. No need to check for failed storage. This is an\n    //    optimization.  Recent versions of the DataNode report a\n    //    VolumeFailureSummary containing the date/time of the last volume\n    //    failure.  If that\u0027s available, then we check that instead for greater\n    //    accuracy.\n    // 2. After DN restarts, volFailures might not increase and it is possible\n    //    we still have new failed storage. For example, admins reduce\n    //    available storages in configuration. Another corner case\n    //    is the failed volumes might change after restart; a) there\n    //    is one good storage A, one restored good storage B, so there is\n    //    one element in storageReports and that is A. b) A failed. c) Before\n    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n    //    restarts, storageReports has one element which is B.\n    final boolean checkFailedStorages;\n    if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n      checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n          this.volumeFailureSummary.getLastVolumeFailureDate();\n    } else {\n      checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n          !heartbeatedSinceRegistration;\n    }\n\n    if (checkFailedStorages) {\n      LOG.info(\"Number of failed storage changes from \"\n          + this.volumeFailures + \" to \" + volFailures);\n      failedStorageInfos \u003d new HashSet\u003cDatanodeStorageInfo\u003e(\n          storageMap.values());\n    }\n\n    setCacheCapacity(cacheCapacity);\n    setCacheUsed(cacheUsed);\n    setXceiverCount(xceiverCount);\n    setLastUpdate(Time.now());\n    setLastUpdateMonotonic(Time.monotonicNow());\n    this.volumeFailures \u003d volFailures;\n    this.volumeFailureSummary \u003d volumeFailureSummary;\n    for (StorageReport report : reports) {\n      DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n      if (checkFailedStorages) {\n        failedStorageInfos.remove(storage);\n      }\n\n      storage.receivedHeartbeat(report);\n      totalCapacity +\u003d report.getCapacity();\n      totalRemaining +\u003d report.getRemaining();\n      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n      totalDfsUsed +\u003d report.getDfsUsed();\n    }\n    rollBlocksScheduled(getLastUpdateMonotonic());\n\n    // Update total metrics for the node.\n    setCapacity(totalCapacity);\n    setRemaining(totalRemaining);\n    setBlockPoolUsed(totalBlockPoolUsed);\n    setDfsUsed(totalDfsUsed);\n    if (checkFailedStorages) {\n      updateFailedStorage(failedStorageInfos);\n    }\n\n    if (storageMap.size() !\u003d reports.length) {\n      pruneStorageMap(reports);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "9729b244de50322c2cc889c97c2ffb2b4675cf77": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7604. Track and display failed DataNode storage locations in NameNode. Contributed by Chris Nauroth.\n",
      "commitDate": "16/02/15 2:43 PM",
      "commitName": "9729b244de50322c2cc889c97c2ffb2b4675cf77",
      "commitAuthor": "cnauroth",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7604. Track and display failed DataNode storage locations in NameNode. Contributed by Chris Nauroth.\n",
          "commitDate": "16/02/15 2:43 PM",
          "commitName": "9729b244de50322c2cc889c97c2ffb2b4675cf77",
          "commitAuthor": "cnauroth",
          "commitDateOld": "08/02/15 11:51 AM",
          "commitNameOld": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 8.12,
          "commitsBetweenForRepo": 110,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,67 +1,78 @@\n   public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n-      long cacheUsed, int xceiverCount, int volFailures) {\n+      long cacheUsed, int xceiverCount, int volFailures,\n+      VolumeFailureSummary volumeFailureSummary) {\n     long totalCapacity \u003d 0;\n     long totalRemaining \u003d 0;\n     long totalBlockPoolUsed \u003d 0;\n     long totalDfsUsed \u003d 0;\n     Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n \n     // Decide if we should check for any missing StorageReport and mark it as\n     // failed. There are different scenarios.\n     // 1. When DN is running, a storage failed. Given the current DN\n     //    implementation doesn\u0027t add recovered storage back to its storage list\n     //    until DN restart, we can assume volFailures won\u0027t decrease\n     //    during the current DN registration session.\n     //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n     //    state change. No need to check for failed storage. This is an\n-    //    optimization.\n+    //    optimization.  Recent versions of the DataNode report a\n+    //    VolumeFailureSummary containing the date/time of the last volume\n+    //    failure.  If that\u0027s available, then we check that instead for greater\n+    //    accuracy.\n     // 2. After DN restarts, volFailures might not increase and it is possible\n     //    we still have new failed storage. For example, admins reduce\n     //    available storages in configuration. Another corner case\n     //    is the failed volumes might change after restart; a) there\n     //    is one good storage A, one restored good storage B, so there is\n     //    one element in storageReports and that is A. b) A failed. c) Before\n     //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n     //    restarts, storageReports has one element which is B.\n-    boolean checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n-        !heartbeatedSinceRegistration;\n+    final boolean checkFailedStorages;\n+    if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n+      checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n+          this.volumeFailureSummary.getLastVolumeFailureDate();\n+    } else {\n+      checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n+          !heartbeatedSinceRegistration;\n+    }\n \n     if (checkFailedStorages) {\n       LOG.info(\"Number of failed storage changes from \"\n           + this.volumeFailures + \" to \" + volFailures);\n       failedStorageInfos \u003d new HashSet\u003cDatanodeStorageInfo\u003e(\n           storageMap.values());\n     }\n \n     setCacheCapacity(cacheCapacity);\n     setCacheUsed(cacheUsed);\n     setXceiverCount(xceiverCount);\n     setLastUpdate(Time.now());    \n     this.volumeFailures \u003d volFailures;\n+    this.volumeFailureSummary \u003d volumeFailureSummary;\n     for (StorageReport report : reports) {\n       DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n       if (checkFailedStorages) {\n         failedStorageInfos.remove(storage);\n       }\n \n       storage.receivedHeartbeat(report);\n       totalCapacity +\u003d report.getCapacity();\n       totalRemaining +\u003d report.getRemaining();\n       totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n       totalDfsUsed +\u003d report.getDfsUsed();\n     }\n     rollBlocksScheduled(getLastUpdate());\n \n     // Update total metrics for the node.\n     setCapacity(totalCapacity);\n     setRemaining(totalRemaining);\n     setBlockPoolUsed(totalBlockPoolUsed);\n     setDfsUsed(totalDfsUsed);\n     if (checkFailedStorages) {\n       updateFailedStorage(failedStorageInfos);\n     }\n \n     if (storageMap.size() !\u003d reports.length) {\n       pruneStorageMap(reports);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n      long cacheUsed, int xceiverCount, int volFailures,\n      VolumeFailureSummary volumeFailureSummary) {\n    long totalCapacity \u003d 0;\n    long totalRemaining \u003d 0;\n    long totalBlockPoolUsed \u003d 0;\n    long totalDfsUsed \u003d 0;\n    Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n\n    // Decide if we should check for any missing StorageReport and mark it as\n    // failed. There are different scenarios.\n    // 1. When DN is running, a storage failed. Given the current DN\n    //    implementation doesn\u0027t add recovered storage back to its storage list\n    //    until DN restart, we can assume volFailures won\u0027t decrease\n    //    during the current DN registration session.\n    //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n    //    state change. No need to check for failed storage. This is an\n    //    optimization.  Recent versions of the DataNode report a\n    //    VolumeFailureSummary containing the date/time of the last volume\n    //    failure.  If that\u0027s available, then we check that instead for greater\n    //    accuracy.\n    // 2. After DN restarts, volFailures might not increase and it is possible\n    //    we still have new failed storage. For example, admins reduce\n    //    available storages in configuration. Another corner case\n    //    is the failed volumes might change after restart; a) there\n    //    is one good storage A, one restored good storage B, so there is\n    //    one element in storageReports and that is A. b) A failed. c) Before\n    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n    //    restarts, storageReports has one element which is B.\n    final boolean checkFailedStorages;\n    if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n      checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n          this.volumeFailureSummary.getLastVolumeFailureDate();\n    } else {\n      checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n          !heartbeatedSinceRegistration;\n    }\n\n    if (checkFailedStorages) {\n      LOG.info(\"Number of failed storage changes from \"\n          + this.volumeFailures + \" to \" + volFailures);\n      failedStorageInfos \u003d new HashSet\u003cDatanodeStorageInfo\u003e(\n          storageMap.values());\n    }\n\n    setCacheCapacity(cacheCapacity);\n    setCacheUsed(cacheUsed);\n    setXceiverCount(xceiverCount);\n    setLastUpdate(Time.now());    \n    this.volumeFailures \u003d volFailures;\n    this.volumeFailureSummary \u003d volumeFailureSummary;\n    for (StorageReport report : reports) {\n      DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n      if (checkFailedStorages) {\n        failedStorageInfos.remove(storage);\n      }\n\n      storage.receivedHeartbeat(report);\n      totalCapacity +\u003d report.getCapacity();\n      totalRemaining +\u003d report.getRemaining();\n      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n      totalDfsUsed +\u003d report.getDfsUsed();\n    }\n    rollBlocksScheduled(getLastUpdate());\n\n    // Update total metrics for the node.\n    setCapacity(totalCapacity);\n    setRemaining(totalRemaining);\n    setBlockPoolUsed(totalBlockPoolUsed);\n    setDfsUsed(totalDfsUsed);\n    if (checkFailedStorages) {\n      updateFailedStorage(failedStorageInfos);\n    }\n\n    if (storageMap.size() !\u003d reports.length) {\n      pruneStorageMap(reports);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
          "extendedDetails": {
            "oldValue": "[reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xceiverCount-int, volFailures-int]",
            "newValue": "[reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xceiverCount-int, volFailures-int, volumeFailureSummary-VolumeFailureSummary]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7604. Track and display failed DataNode storage locations in NameNode. Contributed by Chris Nauroth.\n",
          "commitDate": "16/02/15 2:43 PM",
          "commitName": "9729b244de50322c2cc889c97c2ffb2b4675cf77",
          "commitAuthor": "cnauroth",
          "commitDateOld": "08/02/15 11:51 AM",
          "commitNameOld": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 8.12,
          "commitsBetweenForRepo": 110,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,67 +1,78 @@\n   public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n-      long cacheUsed, int xceiverCount, int volFailures) {\n+      long cacheUsed, int xceiverCount, int volFailures,\n+      VolumeFailureSummary volumeFailureSummary) {\n     long totalCapacity \u003d 0;\n     long totalRemaining \u003d 0;\n     long totalBlockPoolUsed \u003d 0;\n     long totalDfsUsed \u003d 0;\n     Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n \n     // Decide if we should check for any missing StorageReport and mark it as\n     // failed. There are different scenarios.\n     // 1. When DN is running, a storage failed. Given the current DN\n     //    implementation doesn\u0027t add recovered storage back to its storage list\n     //    until DN restart, we can assume volFailures won\u0027t decrease\n     //    during the current DN registration session.\n     //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n     //    state change. No need to check for failed storage. This is an\n-    //    optimization.\n+    //    optimization.  Recent versions of the DataNode report a\n+    //    VolumeFailureSummary containing the date/time of the last volume\n+    //    failure.  If that\u0027s available, then we check that instead for greater\n+    //    accuracy.\n     // 2. After DN restarts, volFailures might not increase and it is possible\n     //    we still have new failed storage. For example, admins reduce\n     //    available storages in configuration. Another corner case\n     //    is the failed volumes might change after restart; a) there\n     //    is one good storage A, one restored good storage B, so there is\n     //    one element in storageReports and that is A. b) A failed. c) Before\n     //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n     //    restarts, storageReports has one element which is B.\n-    boolean checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n-        !heartbeatedSinceRegistration;\n+    final boolean checkFailedStorages;\n+    if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n+      checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n+          this.volumeFailureSummary.getLastVolumeFailureDate();\n+    } else {\n+      checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n+          !heartbeatedSinceRegistration;\n+    }\n \n     if (checkFailedStorages) {\n       LOG.info(\"Number of failed storage changes from \"\n           + this.volumeFailures + \" to \" + volFailures);\n       failedStorageInfos \u003d new HashSet\u003cDatanodeStorageInfo\u003e(\n           storageMap.values());\n     }\n \n     setCacheCapacity(cacheCapacity);\n     setCacheUsed(cacheUsed);\n     setXceiverCount(xceiverCount);\n     setLastUpdate(Time.now());    \n     this.volumeFailures \u003d volFailures;\n+    this.volumeFailureSummary \u003d volumeFailureSummary;\n     for (StorageReport report : reports) {\n       DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n       if (checkFailedStorages) {\n         failedStorageInfos.remove(storage);\n       }\n \n       storage.receivedHeartbeat(report);\n       totalCapacity +\u003d report.getCapacity();\n       totalRemaining +\u003d report.getRemaining();\n       totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n       totalDfsUsed +\u003d report.getDfsUsed();\n     }\n     rollBlocksScheduled(getLastUpdate());\n \n     // Update total metrics for the node.\n     setCapacity(totalCapacity);\n     setRemaining(totalRemaining);\n     setBlockPoolUsed(totalBlockPoolUsed);\n     setDfsUsed(totalDfsUsed);\n     if (checkFailedStorages) {\n       updateFailedStorage(failedStorageInfos);\n     }\n \n     if (storageMap.size() !\u003d reports.length) {\n       pruneStorageMap(reports);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n      long cacheUsed, int xceiverCount, int volFailures,\n      VolumeFailureSummary volumeFailureSummary) {\n    long totalCapacity \u003d 0;\n    long totalRemaining \u003d 0;\n    long totalBlockPoolUsed \u003d 0;\n    long totalDfsUsed \u003d 0;\n    Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n\n    // Decide if we should check for any missing StorageReport and mark it as\n    // failed. There are different scenarios.\n    // 1. When DN is running, a storage failed. Given the current DN\n    //    implementation doesn\u0027t add recovered storage back to its storage list\n    //    until DN restart, we can assume volFailures won\u0027t decrease\n    //    during the current DN registration session.\n    //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n    //    state change. No need to check for failed storage. This is an\n    //    optimization.  Recent versions of the DataNode report a\n    //    VolumeFailureSummary containing the date/time of the last volume\n    //    failure.  If that\u0027s available, then we check that instead for greater\n    //    accuracy.\n    // 2. After DN restarts, volFailures might not increase and it is possible\n    //    we still have new failed storage. For example, admins reduce\n    //    available storages in configuration. Another corner case\n    //    is the failed volumes might change after restart; a) there\n    //    is one good storage A, one restored good storage B, so there is\n    //    one element in storageReports and that is A. b) A failed. c) Before\n    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n    //    restarts, storageReports has one element which is B.\n    final boolean checkFailedStorages;\n    if (volumeFailureSummary !\u003d null \u0026\u0026 this.volumeFailureSummary !\u003d null) {\n      checkFailedStorages \u003d volumeFailureSummary.getLastVolumeFailureDate() \u003e\n          this.volumeFailureSummary.getLastVolumeFailureDate();\n    } else {\n      checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n          !heartbeatedSinceRegistration;\n    }\n\n    if (checkFailedStorages) {\n      LOG.info(\"Number of failed storage changes from \"\n          + this.volumeFailures + \" to \" + volFailures);\n      failedStorageInfos \u003d new HashSet\u003cDatanodeStorageInfo\u003e(\n          storageMap.values());\n    }\n\n    setCacheCapacity(cacheCapacity);\n    setCacheUsed(cacheUsed);\n    setXceiverCount(xceiverCount);\n    setLastUpdate(Time.now());    \n    this.volumeFailures \u003d volFailures;\n    this.volumeFailureSummary \u003d volumeFailureSummary;\n    for (StorageReport report : reports) {\n      DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n      if (checkFailedStorages) {\n        failedStorageInfos.remove(storage);\n      }\n\n      storage.receivedHeartbeat(report);\n      totalCapacity +\u003d report.getCapacity();\n      totalRemaining +\u003d report.getRemaining();\n      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n      totalDfsUsed +\u003d report.getDfsUsed();\n    }\n    rollBlocksScheduled(getLastUpdate());\n\n    // Update total metrics for the node.\n    setCapacity(totalCapacity);\n    setRemaining(totalRemaining);\n    setBlockPoolUsed(totalBlockPoolUsed);\n    setDfsUsed(totalDfsUsed);\n    if (checkFailedStorages) {\n      updateFailedStorage(failedStorageInfos);\n    }\n\n    if (storageMap.size() !\u003d reports.length) {\n      pruneStorageMap(reports);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
          "extendedDetails": {}
        }
      ]
    },
    "ef3c3a832c2f0c1e5ccdda2ff8ef84902912955f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7596. NameNode should prune dead storages from storageMap. Contributed by Arpit Agarwal.\n",
      "commitDate": "10/01/15 9:18 AM",
      "commitName": "ef3c3a832c2f0c1e5ccdda2ff8ef84902912955f",
      "commitAuthor": "cnauroth",
      "commitDateOld": "15/10/14 8:44 PM",
      "commitNameOld": "41980c56d3c01d7a0ddc7deea2d89b7f28026722",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 86.57,
      "commitsBetweenForRepo": 625,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,63 +1,67 @@\n   public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n       long cacheUsed, int xceiverCount, int volFailures) {\n     long totalCapacity \u003d 0;\n     long totalRemaining \u003d 0;\n     long totalBlockPoolUsed \u003d 0;\n     long totalDfsUsed \u003d 0;\n     Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n \n     // Decide if we should check for any missing StorageReport and mark it as\n     // failed. There are different scenarios.\n     // 1. When DN is running, a storage failed. Given the current DN\n     //    implementation doesn\u0027t add recovered storage back to its storage list\n     //    until DN restart, we can assume volFailures won\u0027t decrease\n     //    during the current DN registration session.\n     //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n     //    state change. No need to check for failed storage. This is an\n     //    optimization.\n     // 2. After DN restarts, volFailures might not increase and it is possible\n     //    we still have new failed storage. For example, admins reduce\n     //    available storages in configuration. Another corner case\n     //    is the failed volumes might change after restart; a) there\n     //    is one good storage A, one restored good storage B, so there is\n     //    one element in storageReports and that is A. b) A failed. c) Before\n     //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n     //    restarts, storageReports has one element which is B.\n     boolean checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n         !heartbeatedSinceRegistration;\n \n     if (checkFailedStorages) {\n       LOG.info(\"Number of failed storage changes from \"\n           + this.volumeFailures + \" to \" + volFailures);\n       failedStorageInfos \u003d new HashSet\u003cDatanodeStorageInfo\u003e(\n           storageMap.values());\n     }\n \n     setCacheCapacity(cacheCapacity);\n     setCacheUsed(cacheUsed);\n     setXceiverCount(xceiverCount);\n     setLastUpdate(Time.now());    \n     this.volumeFailures \u003d volFailures;\n     for (StorageReport report : reports) {\n       DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n       if (checkFailedStorages) {\n         failedStorageInfos.remove(storage);\n       }\n \n       storage.receivedHeartbeat(report);\n       totalCapacity +\u003d report.getCapacity();\n       totalRemaining +\u003d report.getRemaining();\n       totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n       totalDfsUsed +\u003d report.getDfsUsed();\n     }\n     rollBlocksScheduled(getLastUpdate());\n \n     // Update total metrics for the node.\n     setCapacity(totalCapacity);\n     setRemaining(totalRemaining);\n     setBlockPoolUsed(totalBlockPoolUsed);\n     setDfsUsed(totalDfsUsed);\n     if (checkFailedStorages) {\n       updateFailedStorage(failedStorageInfos);\n     }\n+\n+    if (storageMap.size() !\u003d reports.length) {\n+      pruneStorageMap(reports);\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n      long cacheUsed, int xceiverCount, int volFailures) {\n    long totalCapacity \u003d 0;\n    long totalRemaining \u003d 0;\n    long totalBlockPoolUsed \u003d 0;\n    long totalDfsUsed \u003d 0;\n    Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n\n    // Decide if we should check for any missing StorageReport and mark it as\n    // failed. There are different scenarios.\n    // 1. When DN is running, a storage failed. Given the current DN\n    //    implementation doesn\u0027t add recovered storage back to its storage list\n    //    until DN restart, we can assume volFailures won\u0027t decrease\n    //    during the current DN registration session.\n    //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n    //    state change. No need to check for failed storage. This is an\n    //    optimization.\n    // 2. After DN restarts, volFailures might not increase and it is possible\n    //    we still have new failed storage. For example, admins reduce\n    //    available storages in configuration. Another corner case\n    //    is the failed volumes might change after restart; a) there\n    //    is one good storage A, one restored good storage B, so there is\n    //    one element in storageReports and that is A. b) A failed. c) Before\n    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n    //    restarts, storageReports has one element which is B.\n    boolean checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n        !heartbeatedSinceRegistration;\n\n    if (checkFailedStorages) {\n      LOG.info(\"Number of failed storage changes from \"\n          + this.volumeFailures + \" to \" + volFailures);\n      failedStorageInfos \u003d new HashSet\u003cDatanodeStorageInfo\u003e(\n          storageMap.values());\n    }\n\n    setCacheCapacity(cacheCapacity);\n    setCacheUsed(cacheUsed);\n    setXceiverCount(xceiverCount);\n    setLastUpdate(Time.now());    \n    this.volumeFailures \u003d volFailures;\n    for (StorageReport report : reports) {\n      DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n      if (checkFailedStorages) {\n        failedStorageInfos.remove(storage);\n      }\n\n      storage.receivedHeartbeat(report);\n      totalCapacity +\u003d report.getCapacity();\n      totalRemaining +\u003d report.getRemaining();\n      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n      totalDfsUsed +\u003d report.getDfsUsed();\n    }\n    rollBlocksScheduled(getLastUpdate());\n\n    // Update total metrics for the node.\n    setCapacity(totalCapacity);\n    setRemaining(totalRemaining);\n    setBlockPoolUsed(totalBlockPoolUsed);\n    setDfsUsed(totalDfsUsed);\n    if (checkFailedStorages) {\n      updateFailedStorage(failedStorageInfos);\n    }\n\n    if (storageMap.size() !\u003d reports.length) {\n      pruneStorageMap(reports);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "41980c56d3c01d7a0ddc7deea2d89b7f28026722": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7208. NN doesn\u0027t schedule replication when a DN storage fails.  Contributed by Ming Ma\n",
      "commitDate": "15/10/14 8:44 PM",
      "commitName": "41980c56d3c01d7a0ddc7deea2d89b7f28026722",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "diff": "@@ -0,0 +1,63 @@\n+  public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n+      long cacheUsed, int xceiverCount, int volFailures) {\n+    long totalCapacity \u003d 0;\n+    long totalRemaining \u003d 0;\n+    long totalBlockPoolUsed \u003d 0;\n+    long totalDfsUsed \u003d 0;\n+    Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n+\n+    // Decide if we should check for any missing StorageReport and mark it as\n+    // failed. There are different scenarios.\n+    // 1. When DN is running, a storage failed. Given the current DN\n+    //    implementation doesn\u0027t add recovered storage back to its storage list\n+    //    until DN restart, we can assume volFailures won\u0027t decrease\n+    //    during the current DN registration session.\n+    //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n+    //    state change. No need to check for failed storage. This is an\n+    //    optimization.\n+    // 2. After DN restarts, volFailures might not increase and it is possible\n+    //    we still have new failed storage. For example, admins reduce\n+    //    available storages in configuration. Another corner case\n+    //    is the failed volumes might change after restart; a) there\n+    //    is one good storage A, one restored good storage B, so there is\n+    //    one element in storageReports and that is A. b) A failed. c) Before\n+    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n+    //    restarts, storageReports has one element which is B.\n+    boolean checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n+        !heartbeatedSinceRegistration;\n+\n+    if (checkFailedStorages) {\n+      LOG.info(\"Number of failed storage changes from \"\n+          + this.volumeFailures + \" to \" + volFailures);\n+      failedStorageInfos \u003d new HashSet\u003cDatanodeStorageInfo\u003e(\n+          storageMap.values());\n+    }\n+\n+    setCacheCapacity(cacheCapacity);\n+    setCacheUsed(cacheUsed);\n+    setXceiverCount(xceiverCount);\n+    setLastUpdate(Time.now());    \n+    this.volumeFailures \u003d volFailures;\n+    for (StorageReport report : reports) {\n+      DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n+      if (checkFailedStorages) {\n+        failedStorageInfos.remove(storage);\n+      }\n+\n+      storage.receivedHeartbeat(report);\n+      totalCapacity +\u003d report.getCapacity();\n+      totalRemaining +\u003d report.getRemaining();\n+      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n+      totalDfsUsed +\u003d report.getDfsUsed();\n+    }\n+    rollBlocksScheduled(getLastUpdate());\n+\n+    // Update total metrics for the node.\n+    setCapacity(totalCapacity);\n+    setRemaining(totalRemaining);\n+    setBlockPoolUsed(totalBlockPoolUsed);\n+    setDfsUsed(totalDfsUsed);\n+    if (checkFailedStorages) {\n+      updateFailedStorage(failedStorageInfos);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void updateHeartbeatState(StorageReport[] reports, long cacheCapacity,\n      long cacheUsed, int xceiverCount, int volFailures) {\n    long totalCapacity \u003d 0;\n    long totalRemaining \u003d 0;\n    long totalBlockPoolUsed \u003d 0;\n    long totalDfsUsed \u003d 0;\n    Set\u003cDatanodeStorageInfo\u003e failedStorageInfos \u003d null;\n\n    // Decide if we should check for any missing StorageReport and mark it as\n    // failed. There are different scenarios.\n    // 1. When DN is running, a storage failed. Given the current DN\n    //    implementation doesn\u0027t add recovered storage back to its storage list\n    //    until DN restart, we can assume volFailures won\u0027t decrease\n    //    during the current DN registration session.\n    //    When volumeFailures \u003d\u003d this.volumeFailures, it implies there is no\n    //    state change. No need to check for failed storage. This is an\n    //    optimization.\n    // 2. After DN restarts, volFailures might not increase and it is possible\n    //    we still have new failed storage. For example, admins reduce\n    //    available storages in configuration. Another corner case\n    //    is the failed volumes might change after restart; a) there\n    //    is one good storage A, one restored good storage B, so there is\n    //    one element in storageReports and that is A. b) A failed. c) Before\n    //    DN sends HB to NN to indicate A has failed, DN restarts. d) After DN\n    //    restarts, storageReports has one element which is B.\n    boolean checkFailedStorages \u003d (volFailures \u003e this.volumeFailures) ||\n        !heartbeatedSinceRegistration;\n\n    if (checkFailedStorages) {\n      LOG.info(\"Number of failed storage changes from \"\n          + this.volumeFailures + \" to \" + volFailures);\n      failedStorageInfos \u003d new HashSet\u003cDatanodeStorageInfo\u003e(\n          storageMap.values());\n    }\n\n    setCacheCapacity(cacheCapacity);\n    setCacheUsed(cacheUsed);\n    setXceiverCount(xceiverCount);\n    setLastUpdate(Time.now());    \n    this.volumeFailures \u003d volFailures;\n    for (StorageReport report : reports) {\n      DatanodeStorageInfo storage \u003d updateStorage(report.getStorage());\n      if (checkFailedStorages) {\n        failedStorageInfos.remove(storage);\n      }\n\n      storage.receivedHeartbeat(report);\n      totalCapacity +\u003d report.getCapacity();\n      totalRemaining +\u003d report.getRemaining();\n      totalBlockPoolUsed +\u003d report.getBlockPoolUsed();\n      totalDfsUsed +\u003d report.getDfsUsed();\n    }\n    rollBlocksScheduled(getLastUpdate());\n\n    // Update total metrics for the node.\n    setCapacity(totalCapacity);\n    setRemaining(totalRemaining);\n    setBlockPoolUsed(totalBlockPoolUsed);\n    setDfsUsed(totalDfsUsed);\n    if (checkFailedStorages) {\n      updateFailedStorage(failedStorageInfos);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java"
    }
  }
}