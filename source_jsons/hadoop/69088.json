{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "StressJobFactory.java",
  "functionName": "checkLoadAndGetSlotsToBackfill",
  "functionId": "checkLoadAndGetSlotsToBackfill",
  "sourceFilePath": "hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java",
  "functionStartLine": 303,
  "functionEndLine": 475,
  "numCommitsSeen": 10,
  "timeTaken": 4850,
  "changeHistory": [
    "dcf84707ab50662add112bd6b01c0bfd63374853",
    "8a2073cc61699f5692fcf638f4bae4d1c544870a",
    "5652e71992ad1590bf3ae3a79f1127b59ead3a61",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "dcf84707ab50662add112bd6b01c0bfd63374853": "Yfilerename",
    "8a2073cc61699f5692fcf638f4bae4d1c544870a": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
    "5652e71992ad1590bf3ae3a79f1127b59ead3a61": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "dcf84707ab50662add112bd6b01c0bfd63374853": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-3543. Mavenize Gridmix. (tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1339629 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/05/12 8:06 AM",
      "commitName": "dcf84707ab50662add112bd6b01c0bfd63374853",
      "commitAuthor": "Thomas Graves",
      "commitDateOld": "17/05/12 7:20 AM",
      "commitNameOld": "e1f09365ca0bee093f849fcf2e546dd6e2c0a965",
      "commitAuthorOld": "Harsh J",
      "daysBetweenCommits": 0.03,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected void checkLoadAndGetSlotsToBackfill() \n  throws IOException, InterruptedException {\n    if (loadStatus.getJobLoad() \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" [JobLoad] Overloaded is \"\n                  + Boolean.TRUE.toString() + \" NumJobsBackfill is \"\n                  + loadStatus.getJobLoad());\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    int mapCapacity \u003d loadStatus.getMapCapacity();\n    int reduceCapacity \u003d loadStatus.getReduceCapacity();\n    \n    // return if the cluster status is not set\n    if (mapCapacity \u003c 0 || reduceCapacity \u003c 0) {\n      // note that, by default, the overload status is true\n      // missing cluster status will result into blocking of job submission\n      return;\n    }\n    \n    // Determine the max permissible map \u0026 reduce task load\n    int maxMapLoad \u003d (int) (overloadMapTaskMapSlotRatio * mapCapacity);\n    int maxReduceLoad \u003d \n      (int) (overloadReduceTaskReduceSlotRatio * reduceCapacity);\n    \n    // compute the total number of map \u0026 reduce tasks submitted\n    int totalMapTasks \u003d ClusterStats.getSubmittedMapTasks();\n    int totalReduceTasks \u003d ClusterStats.getSubmittedReduceTasks();\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Total submitted map tasks: \" + totalMapTasks);\n      LOG.debug(\"Total submitted reduce tasks: \" + totalReduceTasks);\n      LOG.debug(\"Max map load: \" + maxMapLoad);\n      LOG.debug(\"Max reduce load: \" + maxReduceLoad);\n    }\n    \n    // generate a pessimistic bound on the max running+pending map tasks\n    // this check is to avoid the heavy-duty actual map load calculation\n    int mapSlotsBackFill \u003d (int) (maxMapLoad - totalMapTasks);\n    \n    // generate a pessimistic bound on the max running+pending reduce tasks\n    // this check is to avoid the heavy-duty actual reduce load calculation\n    int reduceSlotsBackFill \u003d (int) (maxReduceLoad - totalReduceTasks);\n    \n    // maintain a list of seen job ids\n    Set\u003cJobID\u003e seenJobIDs \u003d new HashSet\u003cJobID\u003e();\n    \n    // check if the total number of submitted map/reduce tasks exceeds the \n    // permissible limit\n    if (totalMapTasks \u003e maxMapLoad || totalReduceTasks \u003e maxReduceLoad) {\n      // if yes, calculate the real load\n      float incompleteMapTasks \u003d 0; // include pending \u0026 running map tasks.\n      float incompleteReduceTasks \u003d 0; // include pending \u0026 running reduce tasks\n      \n      for (JobStats job : ClusterStats.getRunningJobStats()) {\n        JobID id \u003d job.getJob().getJobID();\n        seenJobIDs.add(id);\n        \n        // Note that this is a hack! Ideally, ClusterStats.getRunningJobStats()\n        // should be smart enough to take care of completed jobs.\n        if (blacklistedJobs.contains(id)) {\n          LOG.warn(\"Ignoring blacklisted job: \" + id);\n          continue;\n        }\n        \n        int noOfMaps \u003d job.getNoOfMaps();\n        int noOfReduces \u003d job.getNoOfReds();\n        \n        // consider polling for jobs where maps\u003e0 and reds\u003e0\n        // TODO: What about setup/cleanup tasks for cases where m\u003d0 and r\u003d0\n        //       What otherwise?\n        if (noOfMaps \u003e 0 || noOfReduces \u003e 0) {\n          // get the job\u0027s status\n          JobStatus status \u003d job.getJobStatus();\n          \n          // blacklist completed jobs and continue\n          if (status !\u003d null \u0026\u0026 status.isJobComplete()) {\n            LOG.warn(\"Blacklisting completed job: \" + id);\n            blacklistedJobs.add(id);\n            continue;\n          }\n          \n          // get the map and reduce tasks\u0027 progress\n          float mapProgress \u003d 0f;\n          float reduceProgress \u003d 0f;\n          \n          // check if the status is missing (this can happen for unpolled jobs)\n          if (status !\u003d null) {\n            mapProgress \u003d status.getMapProgress();\n            reduceProgress \u003d status.getReduceProgress();\n          }\n          \n          incompleteMapTasks +\u003d \n            calcEffectiveIncompleteMapTasks(mapCapacity, noOfMaps, mapProgress);\n\n          // bail out early\n          int currentMapSlotsBackFill \u003d (int) (maxMapLoad - incompleteMapTasks);\n          if (currentMapSlotsBackFill \u003c\u003d 0) {\n            // reset the reduce task load since we are bailing out\n            incompleteReduceTasks \u003d totalReduceTasks;\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Terminating overload check due to high map load.\");\n            }\n            break;\n          }\n\n          // compute the real reduce load\n          if (noOfReduces \u003e 0) {\n            incompleteReduceTasks +\u003d \n              calcEffectiveIncompleteReduceTasks(reduceCapacity, noOfReduces, \n                  reduceProgress);\n          }\n\n          // bail out early\n          int currentReduceSlotsBackFill \u003d \n            (int) (maxReduceLoad - incompleteReduceTasks);\n          if (currentReduceSlotsBackFill \u003c\u003d 0) {\n            // reset the map task load since we are bailing out\n            incompleteMapTasks \u003d totalMapTasks;\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Terminating overload check due to high reduce load.\");\n            }\n            break;\n          }\n        } else {\n          LOG.warn(\"Blacklisting empty job: \" + id);\n          blacklistedJobs.add(id);\n        }\n      }\n\n      // calculate the real map load on the cluster\n      mapSlotsBackFill \u003d (int) (maxMapLoad - incompleteMapTasks);\n      \n      // calculate the real reduce load on the cluster\n      reduceSlotsBackFill \u003d (int)(maxReduceLoad - incompleteReduceTasks);\n      \n      // clean up the backlisted set to keep the memory footprint minimal\n      // retain only the jobs that are seen in this cycle\n      blacklistedJobs.retainAll(seenJobIDs);\n      if (LOG.isDebugEnabled() \u0026\u0026 blacklistedJobs.size() \u003e 0) {\n        LOG.debug(\"Blacklisted jobs count: \" + blacklistedJobs.size());\n      }\n    }\n    \n    // update\n    loadStatus.updateMapLoad(mapSlotsBackFill); \n    loadStatus.updateReduceLoad(reduceSlotsBackFill);\n    \n    if (loadStatus.getMapLoad() \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" [MAP-LOAD] Overloaded is \"\n                  + Boolean.TRUE.toString() + \" MapSlotsBackfill is \"\n                  + loadStatus.getMapLoad());\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n    \n    if (loadStatus.getReduceLoad() \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" [REDUCE-LOAD] Overloaded is \"\n                  + Boolean.TRUE.toString() + \" ReduceSlotsBackfill is \"\n                  + loadStatus.getReduceLoad());\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(System.currentTimeMillis() + \" [OVERALL] Overloaded is \"\n                + Boolean.FALSE.toString() + \"Current load Status is \" \n                + loadStatus);\n    }\n  }",
      "path": "hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java",
        "newPath": "hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java"
      }
    },
    "8a2073cc61699f5692fcf638f4bae4d1c544870a": {
      "type": "Ymultichange(Yparameterchange,Ymodifierchange,Ybodychange)",
      "commitMessage": "MAPREDUCE-3787. [Gridmix] Optimize job monitoring and STRESS mode for faster job submission. (amarrk)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1292736 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/02/12 2:41 AM",
      "commitName": "8a2073cc61699f5692fcf638f4bae4d1c544870a",
      "commitAuthor": "Amar Kamat",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-3787. [Gridmix] Optimize job monitoring and STRESS mode for faster job submission. (amarrk)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1292736 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/02/12 2:41 AM",
          "commitName": "8a2073cc61699f5692fcf638f4bae4d1c544870a",
          "commitAuthor": "Amar Kamat",
          "commitDateOld": "29/01/12 10:20 PM",
          "commitNameOld": "5652e71992ad1590bf3ae3a79f1127b59ead3a61",
          "commitAuthorOld": "Amar Kamat",
          "daysBetweenCommits": 24.18,
          "commitsBetweenForRepo": 173,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,77 +1,173 @@\n-  private void checkLoadAndGetSlotsToBackfill(\n-    ClusterStats stats, ClusterStatus clusterStatus) throws IOException, InterruptedException {\n-    \n-    // update the max cluster capacity incase its updated\n-    int mapCapacity \u003d clusterStatus.getMaxMapTasks();\n-    loadStatus.updateMapCapacity(mapCapacity);\n-    \n-    int reduceCapacity \u003d clusterStatus.getMaxReduceTasks();\n-    \n-    loadStatus.updateReduceCapacity(reduceCapacity);\n-    \n-    int numTrackers \u003d clusterStatus.getTaskTrackers();\n-    \n-    int jobLoad \u003d \n-      (int) (maxJobTrackerRatio * numTrackers) - stats.getNumRunningJob();\n-    loadStatus.updateJobLoad(jobLoad);\n+  protected void checkLoadAndGetSlotsToBackfill() \n+  throws IOException, InterruptedException {\n     if (loadStatus.getJobLoad() \u003c\u003d 0) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(System.currentTimeMillis() + \" [JobLoad] Overloaded is \"\n                   + Boolean.TRUE.toString() + \" NumJobsBackfill is \"\n                   + loadStatus.getJobLoad());\n       }\n       return; // stop calculation because we know it is overloaded.\n     }\n \n-    float incompleteMapTasks \u003d 0; // include pending \u0026 running map tasks.\n-    for (JobStats job : ClusterStats.getRunningJobStats()) {\n-      float mapProgress \u003d job.getJob().mapProgress();\n-      int noOfMaps \u003d job.getNoOfMaps();\n-      incompleteMapTasks +\u003d \n-        calcEffectiveIncompleteMapTasks(mapCapacity, noOfMaps, mapProgress);\n+    int mapCapacity \u003d loadStatus.getMapCapacity();\n+    int reduceCapacity \u003d loadStatus.getReduceCapacity();\n+    \n+    // return if the cluster status is not set\n+    if (mapCapacity \u003c 0 || reduceCapacity \u003c 0) {\n+      // note that, by default, the overload status is true\n+      // missing cluster status will result into blocking of job submission\n+      return;\n     }\n     \n-    int mapSlotsBackFill \u003d \n-      (int) ((overloadMapTaskMapSlotRatio * mapCapacity) - incompleteMapTasks);\n-    loadStatus.updateMapLoad(mapSlotsBackFill);\n+    // Determine the max permissible map \u0026 reduce task load\n+    int maxMapLoad \u003d (int) (overloadMapTaskMapSlotRatio * mapCapacity);\n+    int maxReduceLoad \u003d \n+      (int) (overloadReduceTaskReduceSlotRatio * reduceCapacity);\n+    \n+    // compute the total number of map \u0026 reduce tasks submitted\n+    int totalMapTasks \u003d ClusterStats.getSubmittedMapTasks();\n+    int totalReduceTasks \u003d ClusterStats.getSubmittedReduceTasks();\n+    \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Total submitted map tasks: \" + totalMapTasks);\n+      LOG.debug(\"Total submitted reduce tasks: \" + totalReduceTasks);\n+      LOG.debug(\"Max map load: \" + maxMapLoad);\n+      LOG.debug(\"Max reduce load: \" + maxReduceLoad);\n+    }\n+    \n+    // generate a pessimistic bound on the max running+pending map tasks\n+    // this check is to avoid the heavy-duty actual map load calculation\n+    int mapSlotsBackFill \u003d (int) (maxMapLoad - totalMapTasks);\n+    \n+    // generate a pessimistic bound on the max running+pending reduce tasks\n+    // this check is to avoid the heavy-duty actual reduce load calculation\n+    int reduceSlotsBackFill \u003d (int) (maxReduceLoad - totalReduceTasks);\n+    \n+    // maintain a list of seen job ids\n+    Set\u003cJobID\u003e seenJobIDs \u003d new HashSet\u003cJobID\u003e();\n+    \n+    // check if the total number of submitted map/reduce tasks exceeds the \n+    // permissible limit\n+    if (totalMapTasks \u003e maxMapLoad || totalReduceTasks \u003e maxReduceLoad) {\n+      // if yes, calculate the real load\n+      float incompleteMapTasks \u003d 0; // include pending \u0026 running map tasks.\n+      float incompleteReduceTasks \u003d 0; // include pending \u0026 running reduce tasks\n+      \n+      for (JobStats job : ClusterStats.getRunningJobStats()) {\n+        JobID id \u003d job.getJob().getJobID();\n+        seenJobIDs.add(id);\n+        \n+        // Note that this is a hack! Ideally, ClusterStats.getRunningJobStats()\n+        // should be smart enough to take care of completed jobs.\n+        if (blacklistedJobs.contains(id)) {\n+          LOG.warn(\"Ignoring blacklisted job: \" + id);\n+          continue;\n+        }\n+        \n+        int noOfMaps \u003d job.getNoOfMaps();\n+        int noOfReduces \u003d job.getNoOfReds();\n+        \n+        // consider polling for jobs where maps\u003e0 and reds\u003e0\n+        // TODO: What about setup/cleanup tasks for cases where m\u003d0 and r\u003d0\n+        //       What otherwise?\n+        if (noOfMaps \u003e 0 || noOfReduces \u003e 0) {\n+          // get the job\u0027s status\n+          JobStatus status \u003d job.getJobStatus();\n+          \n+          // blacklist completed jobs and continue\n+          if (status !\u003d null \u0026\u0026 status.isJobComplete()) {\n+            LOG.warn(\"Blacklisting completed job: \" + id);\n+            blacklistedJobs.add(id);\n+            continue;\n+          }\n+          \n+          // get the map and reduce tasks\u0027 progress\n+          float mapProgress \u003d 0f;\n+          float reduceProgress \u003d 0f;\n+          \n+          // check if the status is missing (this can happen for unpolled jobs)\n+          if (status !\u003d null) {\n+            mapProgress \u003d status.getMapProgress();\n+            reduceProgress \u003d status.getReduceProgress();\n+          }\n+          \n+          incompleteMapTasks +\u003d \n+            calcEffectiveIncompleteMapTasks(mapCapacity, noOfMaps, mapProgress);\n+\n+          // bail out early\n+          int currentMapSlotsBackFill \u003d (int) (maxMapLoad - incompleteMapTasks);\n+          if (currentMapSlotsBackFill \u003c\u003d 0) {\n+            // reset the reduce task load since we are bailing out\n+            incompleteReduceTasks \u003d totalReduceTasks;\n+            if (LOG.isDebugEnabled()) {\n+              LOG.debug(\"Terminating overload check due to high map load.\");\n+            }\n+            break;\n+          }\n+\n+          // compute the real reduce load\n+          if (noOfReduces \u003e 0) {\n+            incompleteReduceTasks +\u003d \n+              calcEffectiveIncompleteReduceTasks(reduceCapacity, noOfReduces, \n+                  reduceProgress);\n+          }\n+\n+          // bail out early\n+          int currentReduceSlotsBackFill \u003d \n+            (int) (maxReduceLoad - incompleteReduceTasks);\n+          if (currentReduceSlotsBackFill \u003c\u003d 0) {\n+            // reset the map task load since we are bailing out\n+            incompleteMapTasks \u003d totalMapTasks;\n+            if (LOG.isDebugEnabled()) {\n+              LOG.debug(\"Terminating overload check due to high reduce load.\");\n+            }\n+            break;\n+          }\n+        } else {\n+          LOG.warn(\"Blacklisting empty job: \" + id);\n+          blacklistedJobs.add(id);\n+        }\n+      }\n+\n+      // calculate the real map load on the cluster\n+      mapSlotsBackFill \u003d (int) (maxMapLoad - incompleteMapTasks);\n+      \n+      // calculate the real reduce load on the cluster\n+      reduceSlotsBackFill \u003d (int)(maxReduceLoad - incompleteReduceTasks);\n+      \n+      // clean up the backlisted set to keep the memory footprint minimal\n+      // retain only the jobs that are seen in this cycle\n+      blacklistedJobs.retainAll(seenJobIDs);\n+      if (LOG.isDebugEnabled() \u0026\u0026 blacklistedJobs.size() \u003e 0) {\n+        LOG.debug(\"Blacklisted jobs count: \" + blacklistedJobs.size());\n+      }\n+    }\n+    \n+    // update\n+    loadStatus.updateMapLoad(mapSlotsBackFill); \n+    loadStatus.updateReduceLoad(reduceSlotsBackFill);\n     \n     if (loadStatus.getMapLoad() \u003c\u003d 0) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(System.currentTimeMillis() + \" [MAP-LOAD] Overloaded is \"\n                   + Boolean.TRUE.toString() + \" MapSlotsBackfill is \"\n                   + loadStatus.getMapLoad());\n       }\n       return; // stop calculation because we know it is overloaded.\n     }\n-\n-    float incompleteReduceTasks \u003d 0; // include pending \u0026 running reduce tasks.\n-    for (JobStats job : ClusterStats.getRunningJobStats()) {\n-      // Cached the num-reds value in JobStats\n-      int noOfReduces \u003d job.getNoOfReds();\n-      if (noOfReduces \u003e 0) {\n-        float reduceProgress \u003d job.getJob().reduceProgress();\n-        incompleteReduceTasks +\u003d \n-          calcEffectiveIncompleteReduceTasks(reduceCapacity, noOfReduces, \n-                                             reduceProgress);\n-      }\n-    }\n     \n-    int reduceSlotsBackFill \u003d \n-      (int)((overloadReduceTaskReduceSlotRatio * reduceCapacity) \n-             - incompleteReduceTasks);\n-    loadStatus.updateReduceLoad(reduceSlotsBackFill);\n     if (loadStatus.getReduceLoad() \u003c\u003d 0) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(System.currentTimeMillis() + \" [REDUCE-LOAD] Overloaded is \"\n                   + Boolean.TRUE.toString() + \" ReduceSlotsBackfill is \"\n                   + loadStatus.getReduceLoad());\n       }\n       return; // stop calculation because we know it is overloaded.\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(System.currentTimeMillis() + \" [OVERALL] Overloaded is \"\n                 + Boolean.FALSE.toString() + \"Current load Status is \" \n                 + loadStatus);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void checkLoadAndGetSlotsToBackfill() \n  throws IOException, InterruptedException {\n    if (loadStatus.getJobLoad() \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" [JobLoad] Overloaded is \"\n                  + Boolean.TRUE.toString() + \" NumJobsBackfill is \"\n                  + loadStatus.getJobLoad());\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    int mapCapacity \u003d loadStatus.getMapCapacity();\n    int reduceCapacity \u003d loadStatus.getReduceCapacity();\n    \n    // return if the cluster status is not set\n    if (mapCapacity \u003c 0 || reduceCapacity \u003c 0) {\n      // note that, by default, the overload status is true\n      // missing cluster status will result into blocking of job submission\n      return;\n    }\n    \n    // Determine the max permissible map \u0026 reduce task load\n    int maxMapLoad \u003d (int) (overloadMapTaskMapSlotRatio * mapCapacity);\n    int maxReduceLoad \u003d \n      (int) (overloadReduceTaskReduceSlotRatio * reduceCapacity);\n    \n    // compute the total number of map \u0026 reduce tasks submitted\n    int totalMapTasks \u003d ClusterStats.getSubmittedMapTasks();\n    int totalReduceTasks \u003d ClusterStats.getSubmittedReduceTasks();\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Total submitted map tasks: \" + totalMapTasks);\n      LOG.debug(\"Total submitted reduce tasks: \" + totalReduceTasks);\n      LOG.debug(\"Max map load: \" + maxMapLoad);\n      LOG.debug(\"Max reduce load: \" + maxReduceLoad);\n    }\n    \n    // generate a pessimistic bound on the max running+pending map tasks\n    // this check is to avoid the heavy-duty actual map load calculation\n    int mapSlotsBackFill \u003d (int) (maxMapLoad - totalMapTasks);\n    \n    // generate a pessimistic bound on the max running+pending reduce tasks\n    // this check is to avoid the heavy-duty actual reduce load calculation\n    int reduceSlotsBackFill \u003d (int) (maxReduceLoad - totalReduceTasks);\n    \n    // maintain a list of seen job ids\n    Set\u003cJobID\u003e seenJobIDs \u003d new HashSet\u003cJobID\u003e();\n    \n    // check if the total number of submitted map/reduce tasks exceeds the \n    // permissible limit\n    if (totalMapTasks \u003e maxMapLoad || totalReduceTasks \u003e maxReduceLoad) {\n      // if yes, calculate the real load\n      float incompleteMapTasks \u003d 0; // include pending \u0026 running map tasks.\n      float incompleteReduceTasks \u003d 0; // include pending \u0026 running reduce tasks\n      \n      for (JobStats job : ClusterStats.getRunningJobStats()) {\n        JobID id \u003d job.getJob().getJobID();\n        seenJobIDs.add(id);\n        \n        // Note that this is a hack! Ideally, ClusterStats.getRunningJobStats()\n        // should be smart enough to take care of completed jobs.\n        if (blacklistedJobs.contains(id)) {\n          LOG.warn(\"Ignoring blacklisted job: \" + id);\n          continue;\n        }\n        \n        int noOfMaps \u003d job.getNoOfMaps();\n        int noOfReduces \u003d job.getNoOfReds();\n        \n        // consider polling for jobs where maps\u003e0 and reds\u003e0\n        // TODO: What about setup/cleanup tasks for cases where m\u003d0 and r\u003d0\n        //       What otherwise?\n        if (noOfMaps \u003e 0 || noOfReduces \u003e 0) {\n          // get the job\u0027s status\n          JobStatus status \u003d job.getJobStatus();\n          \n          // blacklist completed jobs and continue\n          if (status !\u003d null \u0026\u0026 status.isJobComplete()) {\n            LOG.warn(\"Blacklisting completed job: \" + id);\n            blacklistedJobs.add(id);\n            continue;\n          }\n          \n          // get the map and reduce tasks\u0027 progress\n          float mapProgress \u003d 0f;\n          float reduceProgress \u003d 0f;\n          \n          // check if the status is missing (this can happen for unpolled jobs)\n          if (status !\u003d null) {\n            mapProgress \u003d status.getMapProgress();\n            reduceProgress \u003d status.getReduceProgress();\n          }\n          \n          incompleteMapTasks +\u003d \n            calcEffectiveIncompleteMapTasks(mapCapacity, noOfMaps, mapProgress);\n\n          // bail out early\n          int currentMapSlotsBackFill \u003d (int) (maxMapLoad - incompleteMapTasks);\n          if (currentMapSlotsBackFill \u003c\u003d 0) {\n            // reset the reduce task load since we are bailing out\n            incompleteReduceTasks \u003d totalReduceTasks;\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Terminating overload check due to high map load.\");\n            }\n            break;\n          }\n\n          // compute the real reduce load\n          if (noOfReduces \u003e 0) {\n            incompleteReduceTasks +\u003d \n              calcEffectiveIncompleteReduceTasks(reduceCapacity, noOfReduces, \n                  reduceProgress);\n          }\n\n          // bail out early\n          int currentReduceSlotsBackFill \u003d \n            (int) (maxReduceLoad - incompleteReduceTasks);\n          if (currentReduceSlotsBackFill \u003c\u003d 0) {\n            // reset the map task load since we are bailing out\n            incompleteMapTasks \u003d totalMapTasks;\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Terminating overload check due to high reduce load.\");\n            }\n            break;\n          }\n        } else {\n          LOG.warn(\"Blacklisting empty job: \" + id);\n          blacklistedJobs.add(id);\n        }\n      }\n\n      // calculate the real map load on the cluster\n      mapSlotsBackFill \u003d (int) (maxMapLoad - incompleteMapTasks);\n      \n      // calculate the real reduce load on the cluster\n      reduceSlotsBackFill \u003d (int)(maxReduceLoad - incompleteReduceTasks);\n      \n      // clean up the backlisted set to keep the memory footprint minimal\n      // retain only the jobs that are seen in this cycle\n      blacklistedJobs.retainAll(seenJobIDs);\n      if (LOG.isDebugEnabled() \u0026\u0026 blacklistedJobs.size() \u003e 0) {\n        LOG.debug(\"Blacklisted jobs count: \" + blacklistedJobs.size());\n      }\n    }\n    \n    // update\n    loadStatus.updateMapLoad(mapSlotsBackFill); \n    loadStatus.updateReduceLoad(reduceSlotsBackFill);\n    \n    if (loadStatus.getMapLoad() \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" [MAP-LOAD] Overloaded is \"\n                  + Boolean.TRUE.toString() + \" MapSlotsBackfill is \"\n                  + loadStatus.getMapLoad());\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n    \n    if (loadStatus.getReduceLoad() \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" [REDUCE-LOAD] Overloaded is \"\n                  + Boolean.TRUE.toString() + \" ReduceSlotsBackfill is \"\n                  + loadStatus.getReduceLoad());\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(System.currentTimeMillis() + \" [OVERALL] Overloaded is \"\n                + Boolean.FALSE.toString() + \"Current load Status is \" \n                + loadStatus);\n    }\n  }",
          "path": "hadoop-mapreduce-project/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java",
          "extendedDetails": {
            "oldValue": "[stats-ClusterStats, clusterStatus-ClusterStatus]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "MAPREDUCE-3787. [Gridmix] Optimize job monitoring and STRESS mode for faster job submission. (amarrk)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1292736 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/02/12 2:41 AM",
          "commitName": "8a2073cc61699f5692fcf638f4bae4d1c544870a",
          "commitAuthor": "Amar Kamat",
          "commitDateOld": "29/01/12 10:20 PM",
          "commitNameOld": "5652e71992ad1590bf3ae3a79f1127b59ead3a61",
          "commitAuthorOld": "Amar Kamat",
          "daysBetweenCommits": 24.18,
          "commitsBetweenForRepo": 173,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,77 +1,173 @@\n-  private void checkLoadAndGetSlotsToBackfill(\n-    ClusterStats stats, ClusterStatus clusterStatus) throws IOException, InterruptedException {\n-    \n-    // update the max cluster capacity incase its updated\n-    int mapCapacity \u003d clusterStatus.getMaxMapTasks();\n-    loadStatus.updateMapCapacity(mapCapacity);\n-    \n-    int reduceCapacity \u003d clusterStatus.getMaxReduceTasks();\n-    \n-    loadStatus.updateReduceCapacity(reduceCapacity);\n-    \n-    int numTrackers \u003d clusterStatus.getTaskTrackers();\n-    \n-    int jobLoad \u003d \n-      (int) (maxJobTrackerRatio * numTrackers) - stats.getNumRunningJob();\n-    loadStatus.updateJobLoad(jobLoad);\n+  protected void checkLoadAndGetSlotsToBackfill() \n+  throws IOException, InterruptedException {\n     if (loadStatus.getJobLoad() \u003c\u003d 0) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(System.currentTimeMillis() + \" [JobLoad] Overloaded is \"\n                   + Boolean.TRUE.toString() + \" NumJobsBackfill is \"\n                   + loadStatus.getJobLoad());\n       }\n       return; // stop calculation because we know it is overloaded.\n     }\n \n-    float incompleteMapTasks \u003d 0; // include pending \u0026 running map tasks.\n-    for (JobStats job : ClusterStats.getRunningJobStats()) {\n-      float mapProgress \u003d job.getJob().mapProgress();\n-      int noOfMaps \u003d job.getNoOfMaps();\n-      incompleteMapTasks +\u003d \n-        calcEffectiveIncompleteMapTasks(mapCapacity, noOfMaps, mapProgress);\n+    int mapCapacity \u003d loadStatus.getMapCapacity();\n+    int reduceCapacity \u003d loadStatus.getReduceCapacity();\n+    \n+    // return if the cluster status is not set\n+    if (mapCapacity \u003c 0 || reduceCapacity \u003c 0) {\n+      // note that, by default, the overload status is true\n+      // missing cluster status will result into blocking of job submission\n+      return;\n     }\n     \n-    int mapSlotsBackFill \u003d \n-      (int) ((overloadMapTaskMapSlotRatio * mapCapacity) - incompleteMapTasks);\n-    loadStatus.updateMapLoad(mapSlotsBackFill);\n+    // Determine the max permissible map \u0026 reduce task load\n+    int maxMapLoad \u003d (int) (overloadMapTaskMapSlotRatio * mapCapacity);\n+    int maxReduceLoad \u003d \n+      (int) (overloadReduceTaskReduceSlotRatio * reduceCapacity);\n+    \n+    // compute the total number of map \u0026 reduce tasks submitted\n+    int totalMapTasks \u003d ClusterStats.getSubmittedMapTasks();\n+    int totalReduceTasks \u003d ClusterStats.getSubmittedReduceTasks();\n+    \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Total submitted map tasks: \" + totalMapTasks);\n+      LOG.debug(\"Total submitted reduce tasks: \" + totalReduceTasks);\n+      LOG.debug(\"Max map load: \" + maxMapLoad);\n+      LOG.debug(\"Max reduce load: \" + maxReduceLoad);\n+    }\n+    \n+    // generate a pessimistic bound on the max running+pending map tasks\n+    // this check is to avoid the heavy-duty actual map load calculation\n+    int mapSlotsBackFill \u003d (int) (maxMapLoad - totalMapTasks);\n+    \n+    // generate a pessimistic bound on the max running+pending reduce tasks\n+    // this check is to avoid the heavy-duty actual reduce load calculation\n+    int reduceSlotsBackFill \u003d (int) (maxReduceLoad - totalReduceTasks);\n+    \n+    // maintain a list of seen job ids\n+    Set\u003cJobID\u003e seenJobIDs \u003d new HashSet\u003cJobID\u003e();\n+    \n+    // check if the total number of submitted map/reduce tasks exceeds the \n+    // permissible limit\n+    if (totalMapTasks \u003e maxMapLoad || totalReduceTasks \u003e maxReduceLoad) {\n+      // if yes, calculate the real load\n+      float incompleteMapTasks \u003d 0; // include pending \u0026 running map tasks.\n+      float incompleteReduceTasks \u003d 0; // include pending \u0026 running reduce tasks\n+      \n+      for (JobStats job : ClusterStats.getRunningJobStats()) {\n+        JobID id \u003d job.getJob().getJobID();\n+        seenJobIDs.add(id);\n+        \n+        // Note that this is a hack! Ideally, ClusterStats.getRunningJobStats()\n+        // should be smart enough to take care of completed jobs.\n+        if (blacklistedJobs.contains(id)) {\n+          LOG.warn(\"Ignoring blacklisted job: \" + id);\n+          continue;\n+        }\n+        \n+        int noOfMaps \u003d job.getNoOfMaps();\n+        int noOfReduces \u003d job.getNoOfReds();\n+        \n+        // consider polling for jobs where maps\u003e0 and reds\u003e0\n+        // TODO: What about setup/cleanup tasks for cases where m\u003d0 and r\u003d0\n+        //       What otherwise?\n+        if (noOfMaps \u003e 0 || noOfReduces \u003e 0) {\n+          // get the job\u0027s status\n+          JobStatus status \u003d job.getJobStatus();\n+          \n+          // blacklist completed jobs and continue\n+          if (status !\u003d null \u0026\u0026 status.isJobComplete()) {\n+            LOG.warn(\"Blacklisting completed job: \" + id);\n+            blacklistedJobs.add(id);\n+            continue;\n+          }\n+          \n+          // get the map and reduce tasks\u0027 progress\n+          float mapProgress \u003d 0f;\n+          float reduceProgress \u003d 0f;\n+          \n+          // check if the status is missing (this can happen for unpolled jobs)\n+          if (status !\u003d null) {\n+            mapProgress \u003d status.getMapProgress();\n+            reduceProgress \u003d status.getReduceProgress();\n+          }\n+          \n+          incompleteMapTasks +\u003d \n+            calcEffectiveIncompleteMapTasks(mapCapacity, noOfMaps, mapProgress);\n+\n+          // bail out early\n+          int currentMapSlotsBackFill \u003d (int) (maxMapLoad - incompleteMapTasks);\n+          if (currentMapSlotsBackFill \u003c\u003d 0) {\n+            // reset the reduce task load since we are bailing out\n+            incompleteReduceTasks \u003d totalReduceTasks;\n+            if (LOG.isDebugEnabled()) {\n+              LOG.debug(\"Terminating overload check due to high map load.\");\n+            }\n+            break;\n+          }\n+\n+          // compute the real reduce load\n+          if (noOfReduces \u003e 0) {\n+            incompleteReduceTasks +\u003d \n+              calcEffectiveIncompleteReduceTasks(reduceCapacity, noOfReduces, \n+                  reduceProgress);\n+          }\n+\n+          // bail out early\n+          int currentReduceSlotsBackFill \u003d \n+            (int) (maxReduceLoad - incompleteReduceTasks);\n+          if (currentReduceSlotsBackFill \u003c\u003d 0) {\n+            // reset the map task load since we are bailing out\n+            incompleteMapTasks \u003d totalMapTasks;\n+            if (LOG.isDebugEnabled()) {\n+              LOG.debug(\"Terminating overload check due to high reduce load.\");\n+            }\n+            break;\n+          }\n+        } else {\n+          LOG.warn(\"Blacklisting empty job: \" + id);\n+          blacklistedJobs.add(id);\n+        }\n+      }\n+\n+      // calculate the real map load on the cluster\n+      mapSlotsBackFill \u003d (int) (maxMapLoad - incompleteMapTasks);\n+      \n+      // calculate the real reduce load on the cluster\n+      reduceSlotsBackFill \u003d (int)(maxReduceLoad - incompleteReduceTasks);\n+      \n+      // clean up the backlisted set to keep the memory footprint minimal\n+      // retain only the jobs that are seen in this cycle\n+      blacklistedJobs.retainAll(seenJobIDs);\n+      if (LOG.isDebugEnabled() \u0026\u0026 blacklistedJobs.size() \u003e 0) {\n+        LOG.debug(\"Blacklisted jobs count: \" + blacklistedJobs.size());\n+      }\n+    }\n+    \n+    // update\n+    loadStatus.updateMapLoad(mapSlotsBackFill); \n+    loadStatus.updateReduceLoad(reduceSlotsBackFill);\n     \n     if (loadStatus.getMapLoad() \u003c\u003d 0) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(System.currentTimeMillis() + \" [MAP-LOAD] Overloaded is \"\n                   + Boolean.TRUE.toString() + \" MapSlotsBackfill is \"\n                   + loadStatus.getMapLoad());\n       }\n       return; // stop calculation because we know it is overloaded.\n     }\n-\n-    float incompleteReduceTasks \u003d 0; // include pending \u0026 running reduce tasks.\n-    for (JobStats job : ClusterStats.getRunningJobStats()) {\n-      // Cached the num-reds value in JobStats\n-      int noOfReduces \u003d job.getNoOfReds();\n-      if (noOfReduces \u003e 0) {\n-        float reduceProgress \u003d job.getJob().reduceProgress();\n-        incompleteReduceTasks +\u003d \n-          calcEffectiveIncompleteReduceTasks(reduceCapacity, noOfReduces, \n-                                             reduceProgress);\n-      }\n-    }\n     \n-    int reduceSlotsBackFill \u003d \n-      (int)((overloadReduceTaskReduceSlotRatio * reduceCapacity) \n-             - incompleteReduceTasks);\n-    loadStatus.updateReduceLoad(reduceSlotsBackFill);\n     if (loadStatus.getReduceLoad() \u003c\u003d 0) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(System.currentTimeMillis() + \" [REDUCE-LOAD] Overloaded is \"\n                   + Boolean.TRUE.toString() + \" ReduceSlotsBackfill is \"\n                   + loadStatus.getReduceLoad());\n       }\n       return; // stop calculation because we know it is overloaded.\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(System.currentTimeMillis() + \" [OVERALL] Overloaded is \"\n                 + Boolean.FALSE.toString() + \"Current load Status is \" \n                 + loadStatus);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void checkLoadAndGetSlotsToBackfill() \n  throws IOException, InterruptedException {\n    if (loadStatus.getJobLoad() \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" [JobLoad] Overloaded is \"\n                  + Boolean.TRUE.toString() + \" NumJobsBackfill is \"\n                  + loadStatus.getJobLoad());\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    int mapCapacity \u003d loadStatus.getMapCapacity();\n    int reduceCapacity \u003d loadStatus.getReduceCapacity();\n    \n    // return if the cluster status is not set\n    if (mapCapacity \u003c 0 || reduceCapacity \u003c 0) {\n      // note that, by default, the overload status is true\n      // missing cluster status will result into blocking of job submission\n      return;\n    }\n    \n    // Determine the max permissible map \u0026 reduce task load\n    int maxMapLoad \u003d (int) (overloadMapTaskMapSlotRatio * mapCapacity);\n    int maxReduceLoad \u003d \n      (int) (overloadReduceTaskReduceSlotRatio * reduceCapacity);\n    \n    // compute the total number of map \u0026 reduce tasks submitted\n    int totalMapTasks \u003d ClusterStats.getSubmittedMapTasks();\n    int totalReduceTasks \u003d ClusterStats.getSubmittedReduceTasks();\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Total submitted map tasks: \" + totalMapTasks);\n      LOG.debug(\"Total submitted reduce tasks: \" + totalReduceTasks);\n      LOG.debug(\"Max map load: \" + maxMapLoad);\n      LOG.debug(\"Max reduce load: \" + maxReduceLoad);\n    }\n    \n    // generate a pessimistic bound on the max running+pending map tasks\n    // this check is to avoid the heavy-duty actual map load calculation\n    int mapSlotsBackFill \u003d (int) (maxMapLoad - totalMapTasks);\n    \n    // generate a pessimistic bound on the max running+pending reduce tasks\n    // this check is to avoid the heavy-duty actual reduce load calculation\n    int reduceSlotsBackFill \u003d (int) (maxReduceLoad - totalReduceTasks);\n    \n    // maintain a list of seen job ids\n    Set\u003cJobID\u003e seenJobIDs \u003d new HashSet\u003cJobID\u003e();\n    \n    // check if the total number of submitted map/reduce tasks exceeds the \n    // permissible limit\n    if (totalMapTasks \u003e maxMapLoad || totalReduceTasks \u003e maxReduceLoad) {\n      // if yes, calculate the real load\n      float incompleteMapTasks \u003d 0; // include pending \u0026 running map tasks.\n      float incompleteReduceTasks \u003d 0; // include pending \u0026 running reduce tasks\n      \n      for (JobStats job : ClusterStats.getRunningJobStats()) {\n        JobID id \u003d job.getJob().getJobID();\n        seenJobIDs.add(id);\n        \n        // Note that this is a hack! Ideally, ClusterStats.getRunningJobStats()\n        // should be smart enough to take care of completed jobs.\n        if (blacklistedJobs.contains(id)) {\n          LOG.warn(\"Ignoring blacklisted job: \" + id);\n          continue;\n        }\n        \n        int noOfMaps \u003d job.getNoOfMaps();\n        int noOfReduces \u003d job.getNoOfReds();\n        \n        // consider polling for jobs where maps\u003e0 and reds\u003e0\n        // TODO: What about setup/cleanup tasks for cases where m\u003d0 and r\u003d0\n        //       What otherwise?\n        if (noOfMaps \u003e 0 || noOfReduces \u003e 0) {\n          // get the job\u0027s status\n          JobStatus status \u003d job.getJobStatus();\n          \n          // blacklist completed jobs and continue\n          if (status !\u003d null \u0026\u0026 status.isJobComplete()) {\n            LOG.warn(\"Blacklisting completed job: \" + id);\n            blacklistedJobs.add(id);\n            continue;\n          }\n          \n          // get the map and reduce tasks\u0027 progress\n          float mapProgress \u003d 0f;\n          float reduceProgress \u003d 0f;\n          \n          // check if the status is missing (this can happen for unpolled jobs)\n          if (status !\u003d null) {\n            mapProgress \u003d status.getMapProgress();\n            reduceProgress \u003d status.getReduceProgress();\n          }\n          \n          incompleteMapTasks +\u003d \n            calcEffectiveIncompleteMapTasks(mapCapacity, noOfMaps, mapProgress);\n\n          // bail out early\n          int currentMapSlotsBackFill \u003d (int) (maxMapLoad - incompleteMapTasks);\n          if (currentMapSlotsBackFill \u003c\u003d 0) {\n            // reset the reduce task load since we are bailing out\n            incompleteReduceTasks \u003d totalReduceTasks;\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Terminating overload check due to high map load.\");\n            }\n            break;\n          }\n\n          // compute the real reduce load\n          if (noOfReduces \u003e 0) {\n            incompleteReduceTasks +\u003d \n              calcEffectiveIncompleteReduceTasks(reduceCapacity, noOfReduces, \n                  reduceProgress);\n          }\n\n          // bail out early\n          int currentReduceSlotsBackFill \u003d \n            (int) (maxReduceLoad - incompleteReduceTasks);\n          if (currentReduceSlotsBackFill \u003c\u003d 0) {\n            // reset the map task load since we are bailing out\n            incompleteMapTasks \u003d totalMapTasks;\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Terminating overload check due to high reduce load.\");\n            }\n            break;\n          }\n        } else {\n          LOG.warn(\"Blacklisting empty job: \" + id);\n          blacklistedJobs.add(id);\n        }\n      }\n\n      // calculate the real map load on the cluster\n      mapSlotsBackFill \u003d (int) (maxMapLoad - incompleteMapTasks);\n      \n      // calculate the real reduce load on the cluster\n      reduceSlotsBackFill \u003d (int)(maxReduceLoad - incompleteReduceTasks);\n      \n      // clean up the backlisted set to keep the memory footprint minimal\n      // retain only the jobs that are seen in this cycle\n      blacklistedJobs.retainAll(seenJobIDs);\n      if (LOG.isDebugEnabled() \u0026\u0026 blacklistedJobs.size() \u003e 0) {\n        LOG.debug(\"Blacklisted jobs count: \" + blacklistedJobs.size());\n      }\n    }\n    \n    // update\n    loadStatus.updateMapLoad(mapSlotsBackFill); \n    loadStatus.updateReduceLoad(reduceSlotsBackFill);\n    \n    if (loadStatus.getMapLoad() \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" [MAP-LOAD] Overloaded is \"\n                  + Boolean.TRUE.toString() + \" MapSlotsBackfill is \"\n                  + loadStatus.getMapLoad());\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n    \n    if (loadStatus.getReduceLoad() \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" [REDUCE-LOAD] Overloaded is \"\n                  + Boolean.TRUE.toString() + \" ReduceSlotsBackfill is \"\n                  + loadStatus.getReduceLoad());\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(System.currentTimeMillis() + \" [OVERALL] Overloaded is \"\n                + Boolean.FALSE.toString() + \"Current load Status is \" \n                + loadStatus);\n    }\n  }",
          "path": "hadoop-mapreduce-project/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[protected]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-3787. [Gridmix] Optimize job monitoring and STRESS mode for faster job submission. (amarrk)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1292736 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "23/02/12 2:41 AM",
          "commitName": "8a2073cc61699f5692fcf638f4bae4d1c544870a",
          "commitAuthor": "Amar Kamat",
          "commitDateOld": "29/01/12 10:20 PM",
          "commitNameOld": "5652e71992ad1590bf3ae3a79f1127b59ead3a61",
          "commitAuthorOld": "Amar Kamat",
          "daysBetweenCommits": 24.18,
          "commitsBetweenForRepo": 173,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,77 +1,173 @@\n-  private void checkLoadAndGetSlotsToBackfill(\n-    ClusterStats stats, ClusterStatus clusterStatus) throws IOException, InterruptedException {\n-    \n-    // update the max cluster capacity incase its updated\n-    int mapCapacity \u003d clusterStatus.getMaxMapTasks();\n-    loadStatus.updateMapCapacity(mapCapacity);\n-    \n-    int reduceCapacity \u003d clusterStatus.getMaxReduceTasks();\n-    \n-    loadStatus.updateReduceCapacity(reduceCapacity);\n-    \n-    int numTrackers \u003d clusterStatus.getTaskTrackers();\n-    \n-    int jobLoad \u003d \n-      (int) (maxJobTrackerRatio * numTrackers) - stats.getNumRunningJob();\n-    loadStatus.updateJobLoad(jobLoad);\n+  protected void checkLoadAndGetSlotsToBackfill() \n+  throws IOException, InterruptedException {\n     if (loadStatus.getJobLoad() \u003c\u003d 0) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(System.currentTimeMillis() + \" [JobLoad] Overloaded is \"\n                   + Boolean.TRUE.toString() + \" NumJobsBackfill is \"\n                   + loadStatus.getJobLoad());\n       }\n       return; // stop calculation because we know it is overloaded.\n     }\n \n-    float incompleteMapTasks \u003d 0; // include pending \u0026 running map tasks.\n-    for (JobStats job : ClusterStats.getRunningJobStats()) {\n-      float mapProgress \u003d job.getJob().mapProgress();\n-      int noOfMaps \u003d job.getNoOfMaps();\n-      incompleteMapTasks +\u003d \n-        calcEffectiveIncompleteMapTasks(mapCapacity, noOfMaps, mapProgress);\n+    int mapCapacity \u003d loadStatus.getMapCapacity();\n+    int reduceCapacity \u003d loadStatus.getReduceCapacity();\n+    \n+    // return if the cluster status is not set\n+    if (mapCapacity \u003c 0 || reduceCapacity \u003c 0) {\n+      // note that, by default, the overload status is true\n+      // missing cluster status will result into blocking of job submission\n+      return;\n     }\n     \n-    int mapSlotsBackFill \u003d \n-      (int) ((overloadMapTaskMapSlotRatio * mapCapacity) - incompleteMapTasks);\n-    loadStatus.updateMapLoad(mapSlotsBackFill);\n+    // Determine the max permissible map \u0026 reduce task load\n+    int maxMapLoad \u003d (int) (overloadMapTaskMapSlotRatio * mapCapacity);\n+    int maxReduceLoad \u003d \n+      (int) (overloadReduceTaskReduceSlotRatio * reduceCapacity);\n+    \n+    // compute the total number of map \u0026 reduce tasks submitted\n+    int totalMapTasks \u003d ClusterStats.getSubmittedMapTasks();\n+    int totalReduceTasks \u003d ClusterStats.getSubmittedReduceTasks();\n+    \n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Total submitted map tasks: \" + totalMapTasks);\n+      LOG.debug(\"Total submitted reduce tasks: \" + totalReduceTasks);\n+      LOG.debug(\"Max map load: \" + maxMapLoad);\n+      LOG.debug(\"Max reduce load: \" + maxReduceLoad);\n+    }\n+    \n+    // generate a pessimistic bound on the max running+pending map tasks\n+    // this check is to avoid the heavy-duty actual map load calculation\n+    int mapSlotsBackFill \u003d (int) (maxMapLoad - totalMapTasks);\n+    \n+    // generate a pessimistic bound on the max running+pending reduce tasks\n+    // this check is to avoid the heavy-duty actual reduce load calculation\n+    int reduceSlotsBackFill \u003d (int) (maxReduceLoad - totalReduceTasks);\n+    \n+    // maintain a list of seen job ids\n+    Set\u003cJobID\u003e seenJobIDs \u003d new HashSet\u003cJobID\u003e();\n+    \n+    // check if the total number of submitted map/reduce tasks exceeds the \n+    // permissible limit\n+    if (totalMapTasks \u003e maxMapLoad || totalReduceTasks \u003e maxReduceLoad) {\n+      // if yes, calculate the real load\n+      float incompleteMapTasks \u003d 0; // include pending \u0026 running map tasks.\n+      float incompleteReduceTasks \u003d 0; // include pending \u0026 running reduce tasks\n+      \n+      for (JobStats job : ClusterStats.getRunningJobStats()) {\n+        JobID id \u003d job.getJob().getJobID();\n+        seenJobIDs.add(id);\n+        \n+        // Note that this is a hack! Ideally, ClusterStats.getRunningJobStats()\n+        // should be smart enough to take care of completed jobs.\n+        if (blacklistedJobs.contains(id)) {\n+          LOG.warn(\"Ignoring blacklisted job: \" + id);\n+          continue;\n+        }\n+        \n+        int noOfMaps \u003d job.getNoOfMaps();\n+        int noOfReduces \u003d job.getNoOfReds();\n+        \n+        // consider polling for jobs where maps\u003e0 and reds\u003e0\n+        // TODO: What about setup/cleanup tasks for cases where m\u003d0 and r\u003d0\n+        //       What otherwise?\n+        if (noOfMaps \u003e 0 || noOfReduces \u003e 0) {\n+          // get the job\u0027s status\n+          JobStatus status \u003d job.getJobStatus();\n+          \n+          // blacklist completed jobs and continue\n+          if (status !\u003d null \u0026\u0026 status.isJobComplete()) {\n+            LOG.warn(\"Blacklisting completed job: \" + id);\n+            blacklistedJobs.add(id);\n+            continue;\n+          }\n+          \n+          // get the map and reduce tasks\u0027 progress\n+          float mapProgress \u003d 0f;\n+          float reduceProgress \u003d 0f;\n+          \n+          // check if the status is missing (this can happen for unpolled jobs)\n+          if (status !\u003d null) {\n+            mapProgress \u003d status.getMapProgress();\n+            reduceProgress \u003d status.getReduceProgress();\n+          }\n+          \n+          incompleteMapTasks +\u003d \n+            calcEffectiveIncompleteMapTasks(mapCapacity, noOfMaps, mapProgress);\n+\n+          // bail out early\n+          int currentMapSlotsBackFill \u003d (int) (maxMapLoad - incompleteMapTasks);\n+          if (currentMapSlotsBackFill \u003c\u003d 0) {\n+            // reset the reduce task load since we are bailing out\n+            incompleteReduceTasks \u003d totalReduceTasks;\n+            if (LOG.isDebugEnabled()) {\n+              LOG.debug(\"Terminating overload check due to high map load.\");\n+            }\n+            break;\n+          }\n+\n+          // compute the real reduce load\n+          if (noOfReduces \u003e 0) {\n+            incompleteReduceTasks +\u003d \n+              calcEffectiveIncompleteReduceTasks(reduceCapacity, noOfReduces, \n+                  reduceProgress);\n+          }\n+\n+          // bail out early\n+          int currentReduceSlotsBackFill \u003d \n+            (int) (maxReduceLoad - incompleteReduceTasks);\n+          if (currentReduceSlotsBackFill \u003c\u003d 0) {\n+            // reset the map task load since we are bailing out\n+            incompleteMapTasks \u003d totalMapTasks;\n+            if (LOG.isDebugEnabled()) {\n+              LOG.debug(\"Terminating overload check due to high reduce load.\");\n+            }\n+            break;\n+          }\n+        } else {\n+          LOG.warn(\"Blacklisting empty job: \" + id);\n+          blacklistedJobs.add(id);\n+        }\n+      }\n+\n+      // calculate the real map load on the cluster\n+      mapSlotsBackFill \u003d (int) (maxMapLoad - incompleteMapTasks);\n+      \n+      // calculate the real reduce load on the cluster\n+      reduceSlotsBackFill \u003d (int)(maxReduceLoad - incompleteReduceTasks);\n+      \n+      // clean up the backlisted set to keep the memory footprint minimal\n+      // retain only the jobs that are seen in this cycle\n+      blacklistedJobs.retainAll(seenJobIDs);\n+      if (LOG.isDebugEnabled() \u0026\u0026 blacklistedJobs.size() \u003e 0) {\n+        LOG.debug(\"Blacklisted jobs count: \" + blacklistedJobs.size());\n+      }\n+    }\n+    \n+    // update\n+    loadStatus.updateMapLoad(mapSlotsBackFill); \n+    loadStatus.updateReduceLoad(reduceSlotsBackFill);\n     \n     if (loadStatus.getMapLoad() \u003c\u003d 0) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(System.currentTimeMillis() + \" [MAP-LOAD] Overloaded is \"\n                   + Boolean.TRUE.toString() + \" MapSlotsBackfill is \"\n                   + loadStatus.getMapLoad());\n       }\n       return; // stop calculation because we know it is overloaded.\n     }\n-\n-    float incompleteReduceTasks \u003d 0; // include pending \u0026 running reduce tasks.\n-    for (JobStats job : ClusterStats.getRunningJobStats()) {\n-      // Cached the num-reds value in JobStats\n-      int noOfReduces \u003d job.getNoOfReds();\n-      if (noOfReduces \u003e 0) {\n-        float reduceProgress \u003d job.getJob().reduceProgress();\n-        incompleteReduceTasks +\u003d \n-          calcEffectiveIncompleteReduceTasks(reduceCapacity, noOfReduces, \n-                                             reduceProgress);\n-      }\n-    }\n     \n-    int reduceSlotsBackFill \u003d \n-      (int)((overloadReduceTaskReduceSlotRatio * reduceCapacity) \n-             - incompleteReduceTasks);\n-    loadStatus.updateReduceLoad(reduceSlotsBackFill);\n     if (loadStatus.getReduceLoad() \u003c\u003d 0) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(System.currentTimeMillis() + \" [REDUCE-LOAD] Overloaded is \"\n                   + Boolean.TRUE.toString() + \" ReduceSlotsBackfill is \"\n                   + loadStatus.getReduceLoad());\n       }\n       return; // stop calculation because we know it is overloaded.\n     }\n \n     if (LOG.isDebugEnabled()) {\n       LOG.debug(System.currentTimeMillis() + \" [OVERALL] Overloaded is \"\n                 + Boolean.FALSE.toString() + \"Current load Status is \" \n                 + loadStatus);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected void checkLoadAndGetSlotsToBackfill() \n  throws IOException, InterruptedException {\n    if (loadStatus.getJobLoad() \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" [JobLoad] Overloaded is \"\n                  + Boolean.TRUE.toString() + \" NumJobsBackfill is \"\n                  + loadStatus.getJobLoad());\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    int mapCapacity \u003d loadStatus.getMapCapacity();\n    int reduceCapacity \u003d loadStatus.getReduceCapacity();\n    \n    // return if the cluster status is not set\n    if (mapCapacity \u003c 0 || reduceCapacity \u003c 0) {\n      // note that, by default, the overload status is true\n      // missing cluster status will result into blocking of job submission\n      return;\n    }\n    \n    // Determine the max permissible map \u0026 reduce task load\n    int maxMapLoad \u003d (int) (overloadMapTaskMapSlotRatio * mapCapacity);\n    int maxReduceLoad \u003d \n      (int) (overloadReduceTaskReduceSlotRatio * reduceCapacity);\n    \n    // compute the total number of map \u0026 reduce tasks submitted\n    int totalMapTasks \u003d ClusterStats.getSubmittedMapTasks();\n    int totalReduceTasks \u003d ClusterStats.getSubmittedReduceTasks();\n    \n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Total submitted map tasks: \" + totalMapTasks);\n      LOG.debug(\"Total submitted reduce tasks: \" + totalReduceTasks);\n      LOG.debug(\"Max map load: \" + maxMapLoad);\n      LOG.debug(\"Max reduce load: \" + maxReduceLoad);\n    }\n    \n    // generate a pessimistic bound on the max running+pending map tasks\n    // this check is to avoid the heavy-duty actual map load calculation\n    int mapSlotsBackFill \u003d (int) (maxMapLoad - totalMapTasks);\n    \n    // generate a pessimistic bound on the max running+pending reduce tasks\n    // this check is to avoid the heavy-duty actual reduce load calculation\n    int reduceSlotsBackFill \u003d (int) (maxReduceLoad - totalReduceTasks);\n    \n    // maintain a list of seen job ids\n    Set\u003cJobID\u003e seenJobIDs \u003d new HashSet\u003cJobID\u003e();\n    \n    // check if the total number of submitted map/reduce tasks exceeds the \n    // permissible limit\n    if (totalMapTasks \u003e maxMapLoad || totalReduceTasks \u003e maxReduceLoad) {\n      // if yes, calculate the real load\n      float incompleteMapTasks \u003d 0; // include pending \u0026 running map tasks.\n      float incompleteReduceTasks \u003d 0; // include pending \u0026 running reduce tasks\n      \n      for (JobStats job : ClusterStats.getRunningJobStats()) {\n        JobID id \u003d job.getJob().getJobID();\n        seenJobIDs.add(id);\n        \n        // Note that this is a hack! Ideally, ClusterStats.getRunningJobStats()\n        // should be smart enough to take care of completed jobs.\n        if (blacklistedJobs.contains(id)) {\n          LOG.warn(\"Ignoring blacklisted job: \" + id);\n          continue;\n        }\n        \n        int noOfMaps \u003d job.getNoOfMaps();\n        int noOfReduces \u003d job.getNoOfReds();\n        \n        // consider polling for jobs where maps\u003e0 and reds\u003e0\n        // TODO: What about setup/cleanup tasks for cases where m\u003d0 and r\u003d0\n        //       What otherwise?\n        if (noOfMaps \u003e 0 || noOfReduces \u003e 0) {\n          // get the job\u0027s status\n          JobStatus status \u003d job.getJobStatus();\n          \n          // blacklist completed jobs and continue\n          if (status !\u003d null \u0026\u0026 status.isJobComplete()) {\n            LOG.warn(\"Blacklisting completed job: \" + id);\n            blacklistedJobs.add(id);\n            continue;\n          }\n          \n          // get the map and reduce tasks\u0027 progress\n          float mapProgress \u003d 0f;\n          float reduceProgress \u003d 0f;\n          \n          // check if the status is missing (this can happen for unpolled jobs)\n          if (status !\u003d null) {\n            mapProgress \u003d status.getMapProgress();\n            reduceProgress \u003d status.getReduceProgress();\n          }\n          \n          incompleteMapTasks +\u003d \n            calcEffectiveIncompleteMapTasks(mapCapacity, noOfMaps, mapProgress);\n\n          // bail out early\n          int currentMapSlotsBackFill \u003d (int) (maxMapLoad - incompleteMapTasks);\n          if (currentMapSlotsBackFill \u003c\u003d 0) {\n            // reset the reduce task load since we are bailing out\n            incompleteReduceTasks \u003d totalReduceTasks;\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Terminating overload check due to high map load.\");\n            }\n            break;\n          }\n\n          // compute the real reduce load\n          if (noOfReduces \u003e 0) {\n            incompleteReduceTasks +\u003d \n              calcEffectiveIncompleteReduceTasks(reduceCapacity, noOfReduces, \n                  reduceProgress);\n          }\n\n          // bail out early\n          int currentReduceSlotsBackFill \u003d \n            (int) (maxReduceLoad - incompleteReduceTasks);\n          if (currentReduceSlotsBackFill \u003c\u003d 0) {\n            // reset the map task load since we are bailing out\n            incompleteMapTasks \u003d totalMapTasks;\n            if (LOG.isDebugEnabled()) {\n              LOG.debug(\"Terminating overload check due to high reduce load.\");\n            }\n            break;\n          }\n        } else {\n          LOG.warn(\"Blacklisting empty job: \" + id);\n          blacklistedJobs.add(id);\n        }\n      }\n\n      // calculate the real map load on the cluster\n      mapSlotsBackFill \u003d (int) (maxMapLoad - incompleteMapTasks);\n      \n      // calculate the real reduce load on the cluster\n      reduceSlotsBackFill \u003d (int)(maxReduceLoad - incompleteReduceTasks);\n      \n      // clean up the backlisted set to keep the memory footprint minimal\n      // retain only the jobs that are seen in this cycle\n      blacklistedJobs.retainAll(seenJobIDs);\n      if (LOG.isDebugEnabled() \u0026\u0026 blacklistedJobs.size() \u003e 0) {\n        LOG.debug(\"Blacklisted jobs count: \" + blacklistedJobs.size());\n      }\n    }\n    \n    // update\n    loadStatus.updateMapLoad(mapSlotsBackFill); \n    loadStatus.updateReduceLoad(reduceSlotsBackFill);\n    \n    if (loadStatus.getMapLoad() \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" [MAP-LOAD] Overloaded is \"\n                  + Boolean.TRUE.toString() + \" MapSlotsBackfill is \"\n                  + loadStatus.getMapLoad());\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n    \n    if (loadStatus.getReduceLoad() \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" [REDUCE-LOAD] Overloaded is \"\n                  + Boolean.TRUE.toString() + \" ReduceSlotsBackfill is \"\n                  + loadStatus.getReduceLoad());\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(System.currentTimeMillis() + \" [OVERALL] Overloaded is \"\n                + Boolean.FALSE.toString() + \"Current load Status is \" \n                + loadStatus);\n    }\n  }",
          "path": "hadoop-mapreduce-project/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java",
          "extendedDetails": {}
        }
      ]
    },
    "5652e71992ad1590bf3ae3a79f1127b59ead3a61": {
      "type": "Ybodychange",
      "commitMessage": " MAPREDUCE-3481. [Gridmix] Improve Gridmix STRESS mode. (amarrk)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1237543 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/01/12 10:20 PM",
      "commitName": "5652e71992ad1590bf3ae3a79f1127b59ead3a61",
      "commitAuthor": "Amar Kamat",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 158.25,
      "commitsBetweenForRepo": 973,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,77 @@\n   private void checkLoadAndGetSlotsToBackfill(\n     ClusterStats stats, ClusterStatus clusterStatus) throws IOException, InterruptedException {\n-    loadStatus.mapSlotCapacity \u003d clusterStatus.getMaxMapTasks();\n-    loadStatus.reduceSlotCapacity \u003d clusterStatus.getMaxReduceTasks();\n     \n+    // update the max cluster capacity incase its updated\n+    int mapCapacity \u003d clusterStatus.getMaxMapTasks();\n+    loadStatus.updateMapCapacity(mapCapacity);\n     \n-    loadStatus.numJobsBackfill \u003d \n-      (int) (maxJobTrackerRatio * clusterStatus.getTaskTrackers())\n-        - stats.getNumRunningJob();\n-    if (loadStatus.numJobsBackfill \u003c\u003d 0) {\n+    int reduceCapacity \u003d clusterStatus.getMaxReduceTasks();\n+    \n+    loadStatus.updateReduceCapacity(reduceCapacity);\n+    \n+    int numTrackers \u003d clusterStatus.getTaskTrackers();\n+    \n+    int jobLoad \u003d \n+      (int) (maxJobTrackerRatio * numTrackers) - stats.getNumRunningJob();\n+    loadStatus.updateJobLoad(jobLoad);\n+    if (loadStatus.getJobLoad() \u003c\u003d 0) {\n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n+        LOG.debug(System.currentTimeMillis() + \" [JobLoad] Overloaded is \"\n                   + Boolean.TRUE.toString() + \" NumJobsBackfill is \"\n-                  + loadStatus.numJobsBackfill);\n+                  + loadStatus.getJobLoad());\n       }\n       return; // stop calculation because we know it is overloaded.\n     }\n \n     float incompleteMapTasks \u003d 0; // include pending \u0026 running map tasks.\n     for (JobStats job : ClusterStats.getRunningJobStats()) {\n       float mapProgress \u003d job.getJob().mapProgress();\n       int noOfMaps \u003d job.getNoOfMaps();\n       incompleteMapTasks +\u003d \n-        calcEffectiveIncompleteMapTasks(\n-          clusterStatus.getMaxMapTasks(), noOfMaps, mapProgress);\n+        calcEffectiveIncompleteMapTasks(mapCapacity, noOfMaps, mapProgress);\n     }\n-    loadStatus.mapSlotsBackfill \u003d \n-    (int) ((overloadMapTaskMapSlotRatio * clusterStatus.getMaxMapTasks()) \n-           - incompleteMapTasks);\n-    if (loadStatus.mapSlotsBackfill \u003c\u003d 0) {\n+    \n+    int mapSlotsBackFill \u003d \n+      (int) ((overloadMapTaskMapSlotRatio * mapCapacity) - incompleteMapTasks);\n+    loadStatus.updateMapLoad(mapSlotsBackFill);\n+    \n+    if (loadStatus.getMapLoad() \u003c\u003d 0) {\n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n+        LOG.debug(System.currentTimeMillis() + \" [MAP-LOAD] Overloaded is \"\n                   + Boolean.TRUE.toString() + \" MapSlotsBackfill is \"\n-                  + loadStatus.mapSlotsBackfill);\n+                  + loadStatus.getMapLoad());\n       }\n       return; // stop calculation because we know it is overloaded.\n     }\n \n     float incompleteReduceTasks \u003d 0; // include pending \u0026 running reduce tasks.\n     for (JobStats job : ClusterStats.getRunningJobStats()) {\n-      int noOfReduces \u003d job.getJob().getNumReduceTasks();\n+      // Cached the num-reds value in JobStats\n+      int noOfReduces \u003d job.getNoOfReds();\n       if (noOfReduces \u003e 0) {\n         float reduceProgress \u003d job.getJob().reduceProgress();\n         incompleteReduceTasks +\u003d \n-          calcEffectiveIncompleteReduceTasks(\n-            clusterStatus.getMaxReduceTasks(), noOfReduces, reduceProgress);\n+          calcEffectiveIncompleteReduceTasks(reduceCapacity, noOfReduces, \n+                                             reduceProgress);\n       }\n     }\n-    loadStatus.reduceSlotsBackfill \u003d \n-      (int) ((overloadReduceTaskReduceSlotRatio * clusterStatus.getMaxReduceTasks()) \n+    \n+    int reduceSlotsBackFill \u003d \n+      (int)((overloadReduceTaskReduceSlotRatio * reduceCapacity) \n              - incompleteReduceTasks);\n-    if (loadStatus.reduceSlotsBackfill \u003c\u003d 0) {\n+    loadStatus.updateReduceLoad(reduceSlotsBackFill);\n+    if (loadStatus.getReduceLoad() \u003c\u003d 0) {\n       if (LOG.isDebugEnabled()) {\n-        LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n+        LOG.debug(System.currentTimeMillis() + \" [REDUCE-LOAD] Overloaded is \"\n                   + Boolean.TRUE.toString() + \" ReduceSlotsBackfill is \"\n-                  + loadStatus.reduceSlotsBackfill);\n+                  + loadStatus.getReduceLoad());\n       }\n       return; // stop calculation because we know it is overloaded.\n     }\n \n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n+      LOG.debug(System.currentTimeMillis() + \" [OVERALL] Overloaded is \"\n                 + Boolean.FALSE.toString() + \"Current load Status is \" \n                 + loadStatus);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void checkLoadAndGetSlotsToBackfill(\n    ClusterStats stats, ClusterStatus clusterStatus) throws IOException, InterruptedException {\n    \n    // update the max cluster capacity incase its updated\n    int mapCapacity \u003d clusterStatus.getMaxMapTasks();\n    loadStatus.updateMapCapacity(mapCapacity);\n    \n    int reduceCapacity \u003d clusterStatus.getMaxReduceTasks();\n    \n    loadStatus.updateReduceCapacity(reduceCapacity);\n    \n    int numTrackers \u003d clusterStatus.getTaskTrackers();\n    \n    int jobLoad \u003d \n      (int) (maxJobTrackerRatio * numTrackers) - stats.getNumRunningJob();\n    loadStatus.updateJobLoad(jobLoad);\n    if (loadStatus.getJobLoad() \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" [JobLoad] Overloaded is \"\n                  + Boolean.TRUE.toString() + \" NumJobsBackfill is \"\n                  + loadStatus.getJobLoad());\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    float incompleteMapTasks \u003d 0; // include pending \u0026 running map tasks.\n    for (JobStats job : ClusterStats.getRunningJobStats()) {\n      float mapProgress \u003d job.getJob().mapProgress();\n      int noOfMaps \u003d job.getNoOfMaps();\n      incompleteMapTasks +\u003d \n        calcEffectiveIncompleteMapTasks(mapCapacity, noOfMaps, mapProgress);\n    }\n    \n    int mapSlotsBackFill \u003d \n      (int) ((overloadMapTaskMapSlotRatio * mapCapacity) - incompleteMapTasks);\n    loadStatus.updateMapLoad(mapSlotsBackFill);\n    \n    if (loadStatus.getMapLoad() \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" [MAP-LOAD] Overloaded is \"\n                  + Boolean.TRUE.toString() + \" MapSlotsBackfill is \"\n                  + loadStatus.getMapLoad());\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    float incompleteReduceTasks \u003d 0; // include pending \u0026 running reduce tasks.\n    for (JobStats job : ClusterStats.getRunningJobStats()) {\n      // Cached the num-reds value in JobStats\n      int noOfReduces \u003d job.getNoOfReds();\n      if (noOfReduces \u003e 0) {\n        float reduceProgress \u003d job.getJob().reduceProgress();\n        incompleteReduceTasks +\u003d \n          calcEffectiveIncompleteReduceTasks(reduceCapacity, noOfReduces, \n                                             reduceProgress);\n      }\n    }\n    \n    int reduceSlotsBackFill \u003d \n      (int)((overloadReduceTaskReduceSlotRatio * reduceCapacity) \n             - incompleteReduceTasks);\n    loadStatus.updateReduceLoad(reduceSlotsBackFill);\n    if (loadStatus.getReduceLoad() \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" [REDUCE-LOAD] Overloaded is \"\n                  + Boolean.TRUE.toString() + \" ReduceSlotsBackfill is \"\n                  + loadStatus.getReduceLoad());\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(System.currentTimeMillis() + \" [OVERALL] Overloaded is \"\n                + Boolean.FALSE.toString() + \"Current load Status is \" \n                + loadStatus);\n    }\n  }",
      "path": "hadoop-mapreduce-project/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void checkLoadAndGetSlotsToBackfill(\n    ClusterStats stats, ClusterStatus clusterStatus) throws IOException, InterruptedException {\n    loadStatus.mapSlotCapacity \u003d clusterStatus.getMaxMapTasks();\n    loadStatus.reduceSlotCapacity \u003d clusterStatus.getMaxReduceTasks();\n    \n    \n    loadStatus.numJobsBackfill \u003d \n      (int) (maxJobTrackerRatio * clusterStatus.getTaskTrackers())\n        - stats.getNumRunningJob();\n    if (loadStatus.numJobsBackfill \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n                  + Boolean.TRUE.toString() + \" NumJobsBackfill is \"\n                  + loadStatus.numJobsBackfill);\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    float incompleteMapTasks \u003d 0; // include pending \u0026 running map tasks.\n    for (JobStats job : ClusterStats.getRunningJobStats()) {\n      float mapProgress \u003d job.getJob().mapProgress();\n      int noOfMaps \u003d job.getNoOfMaps();\n      incompleteMapTasks +\u003d \n        calcEffectiveIncompleteMapTasks(\n          clusterStatus.getMaxMapTasks(), noOfMaps, mapProgress);\n    }\n    loadStatus.mapSlotsBackfill \u003d \n    (int) ((overloadMapTaskMapSlotRatio * clusterStatus.getMaxMapTasks()) \n           - incompleteMapTasks);\n    if (loadStatus.mapSlotsBackfill \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n                  + Boolean.TRUE.toString() + \" MapSlotsBackfill is \"\n                  + loadStatus.mapSlotsBackfill);\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    float incompleteReduceTasks \u003d 0; // include pending \u0026 running reduce tasks.\n    for (JobStats job : ClusterStats.getRunningJobStats()) {\n      int noOfReduces \u003d job.getJob().getNumReduceTasks();\n      if (noOfReduces \u003e 0) {\n        float reduceProgress \u003d job.getJob().reduceProgress();\n        incompleteReduceTasks +\u003d \n          calcEffectiveIncompleteReduceTasks(\n            clusterStatus.getMaxReduceTasks(), noOfReduces, reduceProgress);\n      }\n    }\n    loadStatus.reduceSlotsBackfill \u003d \n      (int) ((overloadReduceTaskReduceSlotRatio * clusterStatus.getMaxReduceTasks()) \n             - incompleteReduceTasks);\n    if (loadStatus.reduceSlotsBackfill \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n                  + Boolean.TRUE.toString() + \" ReduceSlotsBackfill is \"\n                  + loadStatus.reduceSlotsBackfill);\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n                + Boolean.FALSE.toString() + \"Current load Status is \" \n                + loadStatus);\n    }\n  }",
      "path": "hadoop-mapreduce-project/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java",
        "newPath": "hadoop-mapreduce-project/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void checkLoadAndGetSlotsToBackfill(\n    ClusterStats stats, ClusterStatus clusterStatus) throws IOException, InterruptedException {\n    loadStatus.mapSlotCapacity \u003d clusterStatus.getMaxMapTasks();\n    loadStatus.reduceSlotCapacity \u003d clusterStatus.getMaxReduceTasks();\n    \n    \n    loadStatus.numJobsBackfill \u003d \n      (int) (maxJobTrackerRatio * clusterStatus.getTaskTrackers())\n        - stats.getNumRunningJob();\n    if (loadStatus.numJobsBackfill \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n                  + Boolean.TRUE.toString() + \" NumJobsBackfill is \"\n                  + loadStatus.numJobsBackfill);\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    float incompleteMapTasks \u003d 0; // include pending \u0026 running map tasks.\n    for (JobStats job : ClusterStats.getRunningJobStats()) {\n      float mapProgress \u003d job.getJob().mapProgress();\n      int noOfMaps \u003d job.getNoOfMaps();\n      incompleteMapTasks +\u003d \n        calcEffectiveIncompleteMapTasks(\n          clusterStatus.getMaxMapTasks(), noOfMaps, mapProgress);\n    }\n    loadStatus.mapSlotsBackfill \u003d \n    (int) ((overloadMapTaskMapSlotRatio * clusterStatus.getMaxMapTasks()) \n           - incompleteMapTasks);\n    if (loadStatus.mapSlotsBackfill \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n                  + Boolean.TRUE.toString() + \" MapSlotsBackfill is \"\n                  + loadStatus.mapSlotsBackfill);\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    float incompleteReduceTasks \u003d 0; // include pending \u0026 running reduce tasks.\n    for (JobStats job : ClusterStats.getRunningJobStats()) {\n      int noOfReduces \u003d job.getJob().getNumReduceTasks();\n      if (noOfReduces \u003e 0) {\n        float reduceProgress \u003d job.getJob().reduceProgress();\n        incompleteReduceTasks +\u003d \n          calcEffectiveIncompleteReduceTasks(\n            clusterStatus.getMaxReduceTasks(), noOfReduces, reduceProgress);\n      }\n    }\n    loadStatus.reduceSlotsBackfill \u003d \n      (int) ((overloadReduceTaskReduceSlotRatio * clusterStatus.getMaxReduceTasks()) \n             - incompleteReduceTasks);\n    if (loadStatus.reduceSlotsBackfill \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n                  + Boolean.TRUE.toString() + \" ReduceSlotsBackfill is \"\n                  + loadStatus.reduceSlotsBackfill);\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n                + Boolean.FALSE.toString() + \"Current load Status is \" \n                + loadStatus);\n    }\n  }",
      "path": "hadoop-mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java",
        "newPath": "hadoop-mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,66 @@\n+  private void checkLoadAndGetSlotsToBackfill(\n+    ClusterStats stats, ClusterStatus clusterStatus) throws IOException, InterruptedException {\n+    loadStatus.mapSlotCapacity \u003d clusterStatus.getMaxMapTasks();\n+    loadStatus.reduceSlotCapacity \u003d clusterStatus.getMaxReduceTasks();\n+    \n+    \n+    loadStatus.numJobsBackfill \u003d \n+      (int) (maxJobTrackerRatio * clusterStatus.getTaskTrackers())\n+        - stats.getNumRunningJob();\n+    if (loadStatus.numJobsBackfill \u003c\u003d 0) {\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n+                  + Boolean.TRUE.toString() + \" NumJobsBackfill is \"\n+                  + loadStatus.numJobsBackfill);\n+      }\n+      return; // stop calculation because we know it is overloaded.\n+    }\n+\n+    float incompleteMapTasks \u003d 0; // include pending \u0026 running map tasks.\n+    for (JobStats job : ClusterStats.getRunningJobStats()) {\n+      float mapProgress \u003d job.getJob().mapProgress();\n+      int noOfMaps \u003d job.getNoOfMaps();\n+      incompleteMapTasks +\u003d \n+        calcEffectiveIncompleteMapTasks(\n+          clusterStatus.getMaxMapTasks(), noOfMaps, mapProgress);\n+    }\n+    loadStatus.mapSlotsBackfill \u003d \n+    (int) ((overloadMapTaskMapSlotRatio * clusterStatus.getMaxMapTasks()) \n+           - incompleteMapTasks);\n+    if (loadStatus.mapSlotsBackfill \u003c\u003d 0) {\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n+                  + Boolean.TRUE.toString() + \" MapSlotsBackfill is \"\n+                  + loadStatus.mapSlotsBackfill);\n+      }\n+      return; // stop calculation because we know it is overloaded.\n+    }\n+\n+    float incompleteReduceTasks \u003d 0; // include pending \u0026 running reduce tasks.\n+    for (JobStats job : ClusterStats.getRunningJobStats()) {\n+      int noOfReduces \u003d job.getJob().getNumReduceTasks();\n+      if (noOfReduces \u003e 0) {\n+        float reduceProgress \u003d job.getJob().reduceProgress();\n+        incompleteReduceTasks +\u003d \n+          calcEffectiveIncompleteReduceTasks(\n+            clusterStatus.getMaxReduceTasks(), noOfReduces, reduceProgress);\n+      }\n+    }\n+    loadStatus.reduceSlotsBackfill \u003d \n+      (int) ((overloadReduceTaskReduceSlotRatio * clusterStatus.getMaxReduceTasks()) \n+             - incompleteReduceTasks);\n+    if (loadStatus.reduceSlotsBackfill \u003c\u003d 0) {\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n+                  + Boolean.TRUE.toString() + \" ReduceSlotsBackfill is \"\n+                  + loadStatus.reduceSlotsBackfill);\n+      }\n+      return; // stop calculation because we know it is overloaded.\n+    }\n+\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n+                + Boolean.FALSE.toString() + \"Current load Status is \" \n+                + loadStatus);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void checkLoadAndGetSlotsToBackfill(\n    ClusterStats stats, ClusterStatus clusterStatus) throws IOException, InterruptedException {\n    loadStatus.mapSlotCapacity \u003d clusterStatus.getMaxMapTasks();\n    loadStatus.reduceSlotCapacity \u003d clusterStatus.getMaxReduceTasks();\n    \n    \n    loadStatus.numJobsBackfill \u003d \n      (int) (maxJobTrackerRatio * clusterStatus.getTaskTrackers())\n        - stats.getNumRunningJob();\n    if (loadStatus.numJobsBackfill \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n                  + Boolean.TRUE.toString() + \" NumJobsBackfill is \"\n                  + loadStatus.numJobsBackfill);\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    float incompleteMapTasks \u003d 0; // include pending \u0026 running map tasks.\n    for (JobStats job : ClusterStats.getRunningJobStats()) {\n      float mapProgress \u003d job.getJob().mapProgress();\n      int noOfMaps \u003d job.getNoOfMaps();\n      incompleteMapTasks +\u003d \n        calcEffectiveIncompleteMapTasks(\n          clusterStatus.getMaxMapTasks(), noOfMaps, mapProgress);\n    }\n    loadStatus.mapSlotsBackfill \u003d \n    (int) ((overloadMapTaskMapSlotRatio * clusterStatus.getMaxMapTasks()) \n           - incompleteMapTasks);\n    if (loadStatus.mapSlotsBackfill \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n                  + Boolean.TRUE.toString() + \" MapSlotsBackfill is \"\n                  + loadStatus.mapSlotsBackfill);\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    float incompleteReduceTasks \u003d 0; // include pending \u0026 running reduce tasks.\n    for (JobStats job : ClusterStats.getRunningJobStats()) {\n      int noOfReduces \u003d job.getJob().getNumReduceTasks();\n      if (noOfReduces \u003e 0) {\n        float reduceProgress \u003d job.getJob().reduceProgress();\n        incompleteReduceTasks +\u003d \n          calcEffectiveIncompleteReduceTasks(\n            clusterStatus.getMaxReduceTasks(), noOfReduces, reduceProgress);\n      }\n    }\n    loadStatus.reduceSlotsBackfill \u003d \n      (int) ((overloadReduceTaskReduceSlotRatio * clusterStatus.getMaxReduceTasks()) \n             - incompleteReduceTasks);\n    if (loadStatus.reduceSlotsBackfill \u003c\u003d 0) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n                  + Boolean.TRUE.toString() + \" ReduceSlotsBackfill is \"\n                  + loadStatus.reduceSlotsBackfill);\n      }\n      return; // stop calculation because we know it is overloaded.\n    }\n\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(System.currentTimeMillis() + \" Overloaded is \"\n                + Boolean.FALSE.toString() + \"Current load Status is \" \n                + loadStatus);\n    }\n  }",
      "path": "mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java"
    }
  }
}