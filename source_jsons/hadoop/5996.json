{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NamenodeFsck.java",
  "functionName": "collectFileSummary",
  "functionId": "collectFileSummary___path-String__file-HdfsFileStatus__res-Result__blocks-LocatedBlocks",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
  "functionStartLine": 585,
  "functionEndLine": 617,
  "numCommitsSeen": 120,
  "timeTaken": 3599,
  "changeHistory": [
    "1e3a0b0d931676b191cb4813ed1a283ebb24d4eb",
    "5e83a21cb66c78e89ac5af9a130ab0aee596a9f4",
    "0ed92e5b13f6bbc0ea7475bc67488359413a980e",
    "ef4e9963b25d7d2e30f1071ddcaa9d92a7fe70f3"
  ],
  "changeHistoryShort": {
    "1e3a0b0d931676b191cb4813ed1a283ebb24d4eb": "Ybodychange",
    "5e83a21cb66c78e89ac5af9a130ab0aee596a9f4": "Ybodychange",
    "0ed92e5b13f6bbc0ea7475bc67488359413a980e": "Ybodychange",
    "ef4e9963b25d7d2e30f1071ddcaa9d92a7fe70f3": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1e3a0b0d931676b191cb4813ed1a283ebb24d4eb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7175. Client-side SocketTimeoutException during Fsck. Contributed by Stephen O\u0027Donnell, Akira Ajisaka.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\nCo-authored-by: Akira Ajisaka \u003caajisaka@apache.org\u003e\n",
      "commitDate": "31/01/20 4:13 PM",
      "commitName": "1e3a0b0d931676b191cb4813ed1a283ebb24d4eb",
      "commitAuthor": "Stephen O\u0027Donnell",
      "commitDateOld": "29/11/19 10:25 AM",
      "commitNameOld": "6b2d6d4aafb110bef1b77d4ccbba4350e624b57d",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 63.24,
      "commitsBetweenForRepo": 216,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,33 @@\n   private void collectFileSummary(String path, HdfsFileStatus file, Result res,\n       LocatedBlocks blocks) throws IOException {\n     long fileLen \u003d file.getLen();\n     boolean isOpen \u003d blocks.isUnderConstruction();\n     if (isOpen \u0026\u0026 !showOpenFiles) {\n       // We collect these stats about open files to report with default options\n       res.totalOpenFilesSize +\u003d fileLen;\n       res.totalOpenFilesBlocks +\u003d blocks.locatedBlockCount();\n       res.totalOpenFiles++;\n       return;\n     }\n     res.totalFiles++;\n     res.totalSize +\u003d fileLen;\n     res.totalBlocks +\u003d blocks.locatedBlockCount();\n     String redundancyPolicy;\n     ErasureCodingPolicy ecPolicy \u003d file.getErasureCodingPolicy();\n     if (ecPolicy \u003d\u003d null) { // a replicated file\n       redundancyPolicy \u003d \"replicated: replication\u003d\" +\n           file.getReplication() + \",\";\n     } else {\n       redundancyPolicy \u003d \"erasure-coded: policy\u003d\" + ecPolicy.getName() + \",\";\n     }\n \n     if (showOpenFiles \u0026\u0026 isOpen) {\n       out.print(path + \" \" + fileLen + \" bytes, \" + redundancyPolicy + \" \" +\n         blocks.locatedBlockCount() + \" block(s), OPENFORWRITE: \");\n     } else if (showFiles) {\n       out.print(path + \" \" + fileLen + \" bytes, \" + redundancyPolicy + \" \" +\n         blocks.locatedBlockCount() + \" block(s): \");\n-    } else if (showprogress) {\n+    } else if (res.totalFiles % 100 \u003d\u003d 0) {\n       out.print(\u0027.\u0027);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void collectFileSummary(String path, HdfsFileStatus file, Result res,\n      LocatedBlocks blocks) throws IOException {\n    long fileLen \u003d file.getLen();\n    boolean isOpen \u003d blocks.isUnderConstruction();\n    if (isOpen \u0026\u0026 !showOpenFiles) {\n      // We collect these stats about open files to report with default options\n      res.totalOpenFilesSize +\u003d fileLen;\n      res.totalOpenFilesBlocks +\u003d blocks.locatedBlockCount();\n      res.totalOpenFiles++;\n      return;\n    }\n    res.totalFiles++;\n    res.totalSize +\u003d fileLen;\n    res.totalBlocks +\u003d blocks.locatedBlockCount();\n    String redundancyPolicy;\n    ErasureCodingPolicy ecPolicy \u003d file.getErasureCodingPolicy();\n    if (ecPolicy \u003d\u003d null) { // a replicated file\n      redundancyPolicy \u003d \"replicated: replication\u003d\" +\n          file.getReplication() + \",\";\n    } else {\n      redundancyPolicy \u003d \"erasure-coded: policy\u003d\" + ecPolicy.getName() + \",\";\n    }\n\n    if (showOpenFiles \u0026\u0026 isOpen) {\n      out.print(path + \" \" + fileLen + \" bytes, \" + redundancyPolicy + \" \" +\n        blocks.locatedBlockCount() + \" block(s), OPENFORWRITE: \");\n    } else if (showFiles) {\n      out.print(path + \" \" + fileLen + \" bytes, \" + redundancyPolicy + \" \" +\n        blocks.locatedBlockCount() + \" block(s): \");\n    } else if (res.totalFiles % 100 \u003d\u003d 0) {\n      out.print(\u0027.\u0027);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {}
    },
    "5e83a21cb66c78e89ac5af9a130ab0aee596a9f4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10976. Report erasure coding policy of EC files in Fsck. Contributed by Wei-Chiu Chuang.\n",
      "commitDate": "20/10/16 1:06 PM",
      "commitName": "5e83a21cb66c78e89ac5af9a130ab0aee596a9f4",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "05/10/16 10:52 AM",
      "commitNameOld": "886776225611ca3cfff32dd94ea24fe618f14464",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 15.09,
      "commitsBetweenForRepo": 116,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,33 @@\n   private void collectFileSummary(String path, HdfsFileStatus file, Result res,\n       LocatedBlocks blocks) throws IOException {\n     long fileLen \u003d file.getLen();\n     boolean isOpen \u003d blocks.isUnderConstruction();\n     if (isOpen \u0026\u0026 !showOpenFiles) {\n       // We collect these stats about open files to report with default options\n       res.totalOpenFilesSize +\u003d fileLen;\n       res.totalOpenFilesBlocks +\u003d blocks.locatedBlockCount();\n       res.totalOpenFiles++;\n       return;\n     }\n     res.totalFiles++;\n     res.totalSize +\u003d fileLen;\n     res.totalBlocks +\u003d blocks.locatedBlockCount();\n+    String redundancyPolicy;\n+    ErasureCodingPolicy ecPolicy \u003d file.getErasureCodingPolicy();\n+    if (ecPolicy \u003d\u003d null) { // a replicated file\n+      redundancyPolicy \u003d \"replicated: replication\u003d\" +\n+          file.getReplication() + \",\";\n+    } else {\n+      redundancyPolicy \u003d \"erasure-coded: policy\u003d\" + ecPolicy.getName() + \",\";\n+    }\n+\n     if (showOpenFiles \u0026\u0026 isOpen) {\n-      out.print(path + \" \" + fileLen + \" bytes, \" +\n+      out.print(path + \" \" + fileLen + \" bytes, \" + redundancyPolicy + \" \" +\n         blocks.locatedBlockCount() + \" block(s), OPENFORWRITE: \");\n     } else if (showFiles) {\n-      out.print(path + \" \" + fileLen + \" bytes, \" +\n+      out.print(path + \" \" + fileLen + \" bytes, \" + redundancyPolicy + \" \" +\n         blocks.locatedBlockCount() + \" block(s): \");\n     } else if (showprogress) {\n       out.print(\u0027.\u0027);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void collectFileSummary(String path, HdfsFileStatus file, Result res,\n      LocatedBlocks blocks) throws IOException {\n    long fileLen \u003d file.getLen();\n    boolean isOpen \u003d blocks.isUnderConstruction();\n    if (isOpen \u0026\u0026 !showOpenFiles) {\n      // We collect these stats about open files to report with default options\n      res.totalOpenFilesSize +\u003d fileLen;\n      res.totalOpenFilesBlocks +\u003d blocks.locatedBlockCount();\n      res.totalOpenFiles++;\n      return;\n    }\n    res.totalFiles++;\n    res.totalSize +\u003d fileLen;\n    res.totalBlocks +\u003d blocks.locatedBlockCount();\n    String redundancyPolicy;\n    ErasureCodingPolicy ecPolicy \u003d file.getErasureCodingPolicy();\n    if (ecPolicy \u003d\u003d null) { // a replicated file\n      redundancyPolicy \u003d \"replicated: replication\u003d\" +\n          file.getReplication() + \",\";\n    } else {\n      redundancyPolicy \u003d \"erasure-coded: policy\u003d\" + ecPolicy.getName() + \",\";\n    }\n\n    if (showOpenFiles \u0026\u0026 isOpen) {\n      out.print(path + \" \" + fileLen + \" bytes, \" + redundancyPolicy + \" \" +\n        blocks.locatedBlockCount() + \" block(s), OPENFORWRITE: \");\n    } else if (showFiles) {\n      out.print(path + \" \" + fileLen + \" bytes, \" + redundancyPolicy + \" \" +\n        blocks.locatedBlockCount() + \" block(s): \");\n    } else if (showprogress) {\n      out.print(\u0027.\u0027);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {}
    },
    "0ed92e5b13f6bbc0ea7475bc67488359413a980e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7768. Change fsck to support EC files.  Contributed by Takanobu Asanuma\n",
      "commitDate": "26/05/15 12:07 PM",
      "commitName": "0ed92e5b13f6bbc0ea7475bc67488359413a980e",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "26/05/15 12:02 PM",
      "commitNameOld": "e53fa769c97416af69ea567aecd44f67e896688b",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,24 @@\n   private void collectFileSummary(String path, HdfsFileStatus file, Result res,\n       LocatedBlocks blocks) throws IOException {\n     long fileLen \u003d file.getLen();\n     boolean isOpen \u003d blocks.isUnderConstruction();\n     if (isOpen \u0026\u0026 !showOpenFiles) {\n       // We collect these stats about open files to report with default options\n       res.totalOpenFilesSize +\u003d fileLen;\n       res.totalOpenFilesBlocks +\u003d blocks.locatedBlockCount();\n       res.totalOpenFiles++;\n       return;\n     }\n     res.totalFiles++;\n     res.totalSize +\u003d fileLen;\n     res.totalBlocks +\u003d blocks.locatedBlockCount();\n     if (showOpenFiles \u0026\u0026 isOpen) {\n       out.print(path + \" \" + fileLen + \" bytes, \" +\n         blocks.locatedBlockCount() + \" block(s), OPENFORWRITE: \");\n     } else if (showFiles) {\n       out.print(path + \" \" + fileLen + \" bytes, \" +\n         blocks.locatedBlockCount() + \" block(s): \");\n     } else if (showprogress) {\n       out.print(\u0027.\u0027);\n     }\n-    if ((showprogress) \u0026\u0026 res.totalFiles % 100 \u003d\u003d 0) {\n-      out.println();\n-      out.flush();\n-    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void collectFileSummary(String path, HdfsFileStatus file, Result res,\n      LocatedBlocks blocks) throws IOException {\n    long fileLen \u003d file.getLen();\n    boolean isOpen \u003d blocks.isUnderConstruction();\n    if (isOpen \u0026\u0026 !showOpenFiles) {\n      // We collect these stats about open files to report with default options\n      res.totalOpenFilesSize +\u003d fileLen;\n      res.totalOpenFilesBlocks +\u003d blocks.locatedBlockCount();\n      res.totalOpenFiles++;\n      return;\n    }\n    res.totalFiles++;\n    res.totalSize +\u003d fileLen;\n    res.totalBlocks +\u003d blocks.locatedBlockCount();\n    if (showOpenFiles \u0026\u0026 isOpen) {\n      out.print(path + \" \" + fileLen + \" bytes, \" +\n        blocks.locatedBlockCount() + \" block(s), OPENFORWRITE: \");\n    } else if (showFiles) {\n      out.print(path + \" \" + fileLen + \" bytes, \" +\n        blocks.locatedBlockCount() + \" block(s): \");\n    } else if (showprogress) {\n      out.print(\u0027.\u0027);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java",
      "extendedDetails": {}
    },
    "ef4e9963b25d7d2e30f1071ddcaa9d92a7fe70f3": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-8215. Refactor NamenodeFsck#check method.  Contributed by Takanobu Asanuma\n",
      "commitDate": "23/04/15 2:19 PM",
      "commitName": "ef4e9963b25d7d2e30f1071ddcaa9d92a7fe70f3",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "diff": "@@ -0,0 +1,28 @@\n+  private void collectFileSummary(String path, HdfsFileStatus file, Result res,\n+      LocatedBlocks blocks) throws IOException {\n+    long fileLen \u003d file.getLen();\n+    boolean isOpen \u003d blocks.isUnderConstruction();\n+    if (isOpen \u0026\u0026 !showOpenFiles) {\n+      // We collect these stats about open files to report with default options\n+      res.totalOpenFilesSize +\u003d fileLen;\n+      res.totalOpenFilesBlocks +\u003d blocks.locatedBlockCount();\n+      res.totalOpenFiles++;\n+      return;\n+    }\n+    res.totalFiles++;\n+    res.totalSize +\u003d fileLen;\n+    res.totalBlocks +\u003d blocks.locatedBlockCount();\n+    if (showOpenFiles \u0026\u0026 isOpen) {\n+      out.print(path + \" \" + fileLen + \" bytes, \" +\n+        blocks.locatedBlockCount() + \" block(s), OPENFORWRITE: \");\n+    } else if (showFiles) {\n+      out.print(path + \" \" + fileLen + \" bytes, \" +\n+        blocks.locatedBlockCount() + \" block(s): \");\n+    } else if (showprogress) {\n+      out.print(\u0027.\u0027);\n+    }\n+    if ((showprogress) \u0026\u0026 res.totalFiles % 100 \u003d\u003d 0) {\n+      out.println();\n+      out.flush();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void collectFileSummary(String path, HdfsFileStatus file, Result res,\n      LocatedBlocks blocks) throws IOException {\n    long fileLen \u003d file.getLen();\n    boolean isOpen \u003d blocks.isUnderConstruction();\n    if (isOpen \u0026\u0026 !showOpenFiles) {\n      // We collect these stats about open files to report with default options\n      res.totalOpenFilesSize +\u003d fileLen;\n      res.totalOpenFilesBlocks +\u003d blocks.locatedBlockCount();\n      res.totalOpenFiles++;\n      return;\n    }\n    res.totalFiles++;\n    res.totalSize +\u003d fileLen;\n    res.totalBlocks +\u003d blocks.locatedBlockCount();\n    if (showOpenFiles \u0026\u0026 isOpen) {\n      out.print(path + \" \" + fileLen + \" bytes, \" +\n        blocks.locatedBlockCount() + \" block(s), OPENFORWRITE: \");\n    } else if (showFiles) {\n      out.print(path + \" \" + fileLen + \" bytes, \" +\n        blocks.locatedBlockCount() + \" block(s): \");\n    } else if (showprogress) {\n      out.print(\u0027.\u0027);\n    }\n    if ((showprogress) \u0026\u0026 res.totalFiles % 100 \u003d\u003d 0) {\n      out.println();\n      out.flush();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java"
    }
  }
}