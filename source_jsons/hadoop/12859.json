{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ProvidedStorageMap.java",
  "functionName": "processProvidedStorageReport",
  "functionId": "processProvidedStorageReport",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java",
  "functionStartLine": 147,
  "functionEndLine": 162,
  "numCommitsSeen": 23,
  "timeTaken": 2440,
  "changeHistory": [
    "9c35be86e17021202823bfd3c2067ff3b312ce5c",
    "3b1d30301bcd35bbe525a7e122d3e5acfab92c88",
    "71d0a825711387fe06396323a9ca6a5af0ade415",
    "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5"
  ],
  "changeHistoryShort": {
    "9c35be86e17021202823bfd3c2067ff3b312ce5c": "Ybodychange",
    "3b1d30301bcd35bbe525a7e122d3e5acfab92c88": "Yparameterchange",
    "71d0a825711387fe06396323a9ca6a5af0ade415": "Ybodychange",
    "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9c35be86e17021202823bfd3c2067ff3b312ce5c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12713. [READ] Refactor FileRegion and BlockAliasMap to separate out HDFS metadata and PROVIDED storage metadata. Contributed by Ewan Higgs\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "9c35be86e17021202823bfd3c2067ff3b312ce5c",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "a027055dd2bf5009fe272e9ceb08305bd0a8cc31",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,16 @@\n   private void processProvidedStorageReport()\n       throws IOException {\n     assert lock.hasWriteLock() : \"Not holding write lock\";\n     if (providedStorageInfo.getBlockReportCount() \u003d\u003d 0\n         || providedDescriptor.activeProvidedDatanodes() \u003d\u003d 0) {\n       LOG.info(\"Calling process first blk report from storage: \"\n           + providedStorageInfo);\n       // first pass; periodic refresh should call bm.processReport\n-      bm.processFirstBlockReport(providedStorageInfo,\n-          new ProvidedBlockList(aliasMap.getReader(null).iterator()));\n+      BlockAliasMap.Reader\u003cBlockAlias\u003e reader \u003d\n+          aliasMap.getReader(null, bm.getBlockPoolId());\n+      if (reader !\u003d null) {\n+        bm.processFirstBlockReport(providedStorageInfo,\n+                new ProvidedBlockList(reader.iterator()));\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processProvidedStorageReport()\n      throws IOException {\n    assert lock.hasWriteLock() : \"Not holding write lock\";\n    if (providedStorageInfo.getBlockReportCount() \u003d\u003d 0\n        || providedDescriptor.activeProvidedDatanodes() \u003d\u003d 0) {\n      LOG.info(\"Calling process first blk report from storage: \"\n          + providedStorageInfo);\n      // first pass; periodic refresh should call bm.processReport\n      BlockAliasMap.Reader\u003cBlockAlias\u003e reader \u003d\n          aliasMap.getReader(null, bm.getBlockPoolId());\n      if (reader !\u003d null) {\n        bm.processFirstBlockReport(providedStorageInfo,\n                new ProvidedBlockList(reader.iterator()));\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java",
      "extendedDetails": {}
    },
    "3b1d30301bcd35bbe525a7e122d3e5acfab92c88": {
      "type": "Yparameterchange",
      "commitMessage": "HDFS-12775. [READ] Fix reporting of Provided volumes\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "3b1d30301bcd35bbe525a7e122d3e5acfab92c88",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "71d0a825711387fe06396323a9ca6a5af0ade415",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n-  private void processProvidedStorageReport(BlockReportContext context)\n+  private void processProvidedStorageReport()\n       throws IOException {\n     assert lock.hasWriteLock() : \"Not holding write lock\";\n     if (providedStorageInfo.getBlockReportCount() \u003d\u003d 0\n         || providedDescriptor.activeProvidedDatanodes() \u003d\u003d 0) {\n       LOG.info(\"Calling process first blk report from storage: \"\n           + providedStorageInfo);\n       // first pass; periodic refresh should call bm.processReport\n       bm.processFirstBlockReport(providedStorageInfo,\n           new ProvidedBlockList(aliasMap.getReader(null).iterator()));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processProvidedStorageReport()\n      throws IOException {\n    assert lock.hasWriteLock() : \"Not holding write lock\";\n    if (providedStorageInfo.getBlockReportCount() \u003d\u003d 0\n        || providedDescriptor.activeProvidedDatanodes() \u003d\u003d 0) {\n      LOG.info(\"Calling process first blk report from storage: \"\n          + providedStorageInfo);\n      // first pass; periodic refresh should call bm.processReport\n      bm.processFirstBlockReport(providedStorageInfo,\n          new ProvidedBlockList(aliasMap.getReader(null).iterator()));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java",
      "extendedDetails": {
        "oldValue": "[context-BlockReportContext]",
        "newValue": "[]"
      }
    },
    "71d0a825711387fe06396323a9ca6a5af0ade415": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12607. [READ] Even one dead datanode with PROVIDED storage results in ProvidedStorageInfo being marked as FAILED\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "71d0a825711387fe06396323a9ca6a5af0ade415",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,12 @@\n   private void processProvidedStorageReport(BlockReportContext context)\n       throws IOException {\n     assert lock.hasWriteLock() : \"Not holding write lock\";\n-    if (hasDNs) {\n-      return;\n-    }\n-    if (providedStorageInfo.getBlockReportCount() \u003d\u003d 0) {\n+    if (providedStorageInfo.getBlockReportCount() \u003d\u003d 0\n+        || providedDescriptor.activeProvidedDatanodes() \u003d\u003d 0) {\n       LOG.info(\"Calling process first blk report from storage: \"\n           + providedStorageInfo);\n       // first pass; periodic refresh should call bm.processReport\n       bm.processFirstBlockReport(providedStorageInfo,\n           new ProvidedBlockList(aliasMap.getReader(null).iterator()));\n-    } else {\n-      bm.processReport(providedStorageInfo,\n-          new ProvidedBlockList(aliasMap.getReader(null).iterator()),\n-          context);\n     }\n-    hasDNs \u003d true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processProvidedStorageReport(BlockReportContext context)\n      throws IOException {\n    assert lock.hasWriteLock() : \"Not holding write lock\";\n    if (providedStorageInfo.getBlockReportCount() \u003d\u003d 0\n        || providedDescriptor.activeProvidedDatanodes() \u003d\u003d 0) {\n      LOG.info(\"Calling process first blk report from storage: \"\n          + providedStorageInfo);\n      // first pass; periodic refresh should call bm.processReport\n      bm.processFirstBlockReport(providedStorageInfo,\n          new ProvidedBlockList(aliasMap.getReader(null).iterator()));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java",
      "extendedDetails": {}
    },
    "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11902. [READ] Merge BlockFormatProvider and FileRegionProvider.\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5",
      "commitAuthor": "Virajith Jalaparti",
      "diff": "@@ -0,0 +1,19 @@\n+  private void processProvidedStorageReport(BlockReportContext context)\n+      throws IOException {\n+    assert lock.hasWriteLock() : \"Not holding write lock\";\n+    if (hasDNs) {\n+      return;\n+    }\n+    if (providedStorageInfo.getBlockReportCount() \u003d\u003d 0) {\n+      LOG.info(\"Calling process first blk report from storage: \"\n+          + providedStorageInfo);\n+      // first pass; periodic refresh should call bm.processReport\n+      bm.processFirstBlockReport(providedStorageInfo,\n+          new ProvidedBlockList(aliasMap.getReader(null).iterator()));\n+    } else {\n+      bm.processReport(providedStorageInfo,\n+          new ProvidedBlockList(aliasMap.getReader(null).iterator()),\n+          context);\n+    }\n+    hasDNs \u003d true;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void processProvidedStorageReport(BlockReportContext context)\n      throws IOException {\n    assert lock.hasWriteLock() : \"Not holding write lock\";\n    if (hasDNs) {\n      return;\n    }\n    if (providedStorageInfo.getBlockReportCount() \u003d\u003d 0) {\n      LOG.info(\"Calling process first blk report from storage: \"\n          + providedStorageInfo);\n      // first pass; periodic refresh should call bm.processReport\n      bm.processFirstBlockReport(providedStorageInfo,\n          new ProvidedBlockList(aliasMap.getReader(null).iterator()));\n    } else {\n      bm.processReport(providedStorageInfo,\n          new ProvidedBlockList(aliasMap.getReader(null).iterator()),\n          context);\n    }\n    hasDNs \u003d true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.java"
    }
  }
}