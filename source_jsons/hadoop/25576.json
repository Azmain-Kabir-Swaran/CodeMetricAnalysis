{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LocalContainerLauncher.java",
  "functionName": "runTask",
  "functionId": "runTask___launchEv-ContainerRemoteLaunchEvent__localMapFiles-Map__TaskAttemptID,MapOutputFile__",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java",
  "functionStartLine": 317,
  "functionEndLine": 390,
  "numCommitsSeen": 27,
  "timeTaken": 1748,
  "changeHistory": [
    "453d48bdfbb67ed3e66c33c4aef239c3d7bdd3bc",
    "444836b3dcd3ee28238af7b5e753d644e8095788",
    "6957745c2c73cae038ac7960115ffc32de05b953"
  ],
  "changeHistoryShort": {
    "453d48bdfbb67ed3e66c33c4aef239c3d7bdd3bc": "Ybodychange",
    "444836b3dcd3ee28238af7b5e753d644e8095788": "Ybodychange",
    "6957745c2c73cae038ac7960115ffc32de05b953": "Yintroduced"
  },
  "changeHistoryDetails": {
    "453d48bdfbb67ed3e66c33c4aef239c3d7bdd3bc": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6971. Moving logging APIs over to slf4j in hadoop-mapreduce-client-app. Contributed by Jinjiang Ling.\n",
      "commitDate": "02/10/17 8:14 PM",
      "commitName": "453d48bdfbb67ed3e66c33c4aef239c3d7bdd3bc",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "26/04/17 11:45 PM",
      "commitNameOld": "3ed3062fe3979ff55a411b730a8eee2b2c96d6b3",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 158.85,
      "commitsBetweenForRepo": 1073,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,74 +1,74 @@\n     private void runTask(ContainerRemoteLaunchEvent launchEv,\n         Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles) {\n       TaskAttemptId attemptID \u003d launchEv.getTaskAttemptID(); \n \n       Job job \u003d context.getAllJobs().get(attemptID.getTaskId().getJobId());\n       int numMapTasks \u003d job.getTotalMaps();\n       int numReduceTasks \u003d job.getTotalReduces();\n \n       // YARN (tracking) Task:\n       org.apache.hadoop.mapreduce.v2.app.job.Task ytask \u003d\n           job.getTask(attemptID.getTaskId());\n       // classic mapred Task:\n       org.apache.hadoop.mapred.Task remoteTask \u003d launchEv.getRemoteTask();\n \n       // after \"launching,\" send launched event to task attempt to move\n       // state from ASSIGNED to RUNNING (also nukes \"remoteTask\", so must\n       // do getRemoteTask() call first)\n       \n       //There is no port number because we are not really talking to a task\n       // tracker.  The shuffle is just done through local files.  So the\n       // port number is set to -1 in this case.\n       context.getEventHandler().handle(\n           new TaskAttemptContainerLaunchedEvent(attemptID, -1));\n \n       if (numMapTasks \u003d\u003d 0) {\n         doneWithMaps \u003d true;\n       }\n \n       try {\n         if (remoteTask.isMapOrReduce()) {\n           JobCounterUpdateEvent jce \u003d new JobCounterUpdateEvent(attemptID.getTaskId().getJobId());\n           jce.addCounterUpdate(JobCounter.TOTAL_LAUNCHED_UBERTASKS, 1);\n           if (remoteTask.isMapTask()) {\n             jce.addCounterUpdate(JobCounter.NUM_UBER_SUBMAPS, 1);\n           } else {\n             jce.addCounterUpdate(JobCounter.NUM_UBER_SUBREDUCES, 1);\n           }\n           context.getEventHandler().handle(jce);\n         }\n         runSubtask(remoteTask, ytask.getType(), attemptID, numMapTasks,\n                    (numReduceTasks \u003e 0), localMapFiles);\n \n         // In non-uber mode, TA gets TA_CONTAINER_COMPLETED from MRAppMaster\n         // as part of NM -\u003e RM -\u003e AM notification route.\n         // In uber mode, given the task run inside the MRAppMaster container,\n         // we have to simulate the notification.\n         context.getEventHandler().handle(new TaskAttemptEvent(attemptID,\n             TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n \n       } catch (RuntimeException re) {\n         JobCounterUpdateEvent jce \u003d new JobCounterUpdateEvent(attemptID.getTaskId().getJobId());\n         jce.addCounterUpdate(JobCounter.NUM_FAILED_UBERTASKS, 1);\n         context.getEventHandler().handle(jce);\n         // this is our signal that the subtask failed in some way, so\n         // simulate a failed JVM/container and send a container-completed\n         // event to task attempt (i.e., move state machine from RUNNING\n         // to FAIL_CONTAINER_CLEANUP [and ultimately to FAILED])\n         context.getEventHandler().handle(new TaskAttemptEvent(attemptID,\n             TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n       } catch (IOException ioe) {\n         // if umbilical itself barfs (in error-handler of runSubMap()),\n         // we\u0027re pretty much hosed, so do what YarnChild main() does\n         // (i.e., exit clumsily--but can never happen, so no worries!)\n-        LOG.fatal(\"oopsie...  this can never happen: \"\n+        LOG.error(\"oopsie...  this can never happen: \"\n             + StringUtils.stringifyException(ioe));\n         ExitUtil.terminate(-1);\n       } finally {\n         // remove my future\n         if (futures.remove(attemptID) !\u003d null) {\n           LOG.info(\"removed attempt \" + attemptID +\n               \" from the futures to keep track of\");\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void runTask(ContainerRemoteLaunchEvent launchEv,\n        Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles) {\n      TaskAttemptId attemptID \u003d launchEv.getTaskAttemptID(); \n\n      Job job \u003d context.getAllJobs().get(attemptID.getTaskId().getJobId());\n      int numMapTasks \u003d job.getTotalMaps();\n      int numReduceTasks \u003d job.getTotalReduces();\n\n      // YARN (tracking) Task:\n      org.apache.hadoop.mapreduce.v2.app.job.Task ytask \u003d\n          job.getTask(attemptID.getTaskId());\n      // classic mapred Task:\n      org.apache.hadoop.mapred.Task remoteTask \u003d launchEv.getRemoteTask();\n\n      // after \"launching,\" send launched event to task attempt to move\n      // state from ASSIGNED to RUNNING (also nukes \"remoteTask\", so must\n      // do getRemoteTask() call first)\n      \n      //There is no port number because we are not really talking to a task\n      // tracker.  The shuffle is just done through local files.  So the\n      // port number is set to -1 in this case.\n      context.getEventHandler().handle(\n          new TaskAttemptContainerLaunchedEvent(attemptID, -1));\n\n      if (numMapTasks \u003d\u003d 0) {\n        doneWithMaps \u003d true;\n      }\n\n      try {\n        if (remoteTask.isMapOrReduce()) {\n          JobCounterUpdateEvent jce \u003d new JobCounterUpdateEvent(attemptID.getTaskId().getJobId());\n          jce.addCounterUpdate(JobCounter.TOTAL_LAUNCHED_UBERTASKS, 1);\n          if (remoteTask.isMapTask()) {\n            jce.addCounterUpdate(JobCounter.NUM_UBER_SUBMAPS, 1);\n          } else {\n            jce.addCounterUpdate(JobCounter.NUM_UBER_SUBREDUCES, 1);\n          }\n          context.getEventHandler().handle(jce);\n        }\n        runSubtask(remoteTask, ytask.getType(), attemptID, numMapTasks,\n                   (numReduceTasks \u003e 0), localMapFiles);\n\n        // In non-uber mode, TA gets TA_CONTAINER_COMPLETED from MRAppMaster\n        // as part of NM -\u003e RM -\u003e AM notification route.\n        // In uber mode, given the task run inside the MRAppMaster container,\n        // we have to simulate the notification.\n        context.getEventHandler().handle(new TaskAttemptEvent(attemptID,\n            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n\n      } catch (RuntimeException re) {\n        JobCounterUpdateEvent jce \u003d new JobCounterUpdateEvent(attemptID.getTaskId().getJobId());\n        jce.addCounterUpdate(JobCounter.NUM_FAILED_UBERTASKS, 1);\n        context.getEventHandler().handle(jce);\n        // this is our signal that the subtask failed in some way, so\n        // simulate a failed JVM/container and send a container-completed\n        // event to task attempt (i.e., move state machine from RUNNING\n        // to FAIL_CONTAINER_CLEANUP [and ultimately to FAILED])\n        context.getEventHandler().handle(new TaskAttemptEvent(attemptID,\n            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n      } catch (IOException ioe) {\n        // if umbilical itself barfs (in error-handler of runSubMap()),\n        // we\u0027re pretty much hosed, so do what YarnChild main() does\n        // (i.e., exit clumsily--but can never happen, so no worries!)\n        LOG.error(\"oopsie...  this can never happen: \"\n            + StringUtils.stringifyException(ioe));\n        ExitUtil.terminate(-1);\n      } finally {\n        // remove my future\n        if (futures.remove(attemptID) !\u003d null) {\n          LOG.info(\"removed attempt \" + attemptID +\n              \" from the futures to keep track of\");\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java",
      "extendedDetails": {}
    },
    "444836b3dcd3ee28238af7b5e753d644e8095788": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5465. Tasks are often killed before they exit on their own. Contributed by Ming Ma\n",
      "commitDate": "11/05/15 3:37 PM",
      "commitName": "444836b3dcd3ee28238af7b5e753d644e8095788",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "21/04/15 1:57 PM",
      "commitNameOld": "725eb52ddc647074f0bf1cc73c3029f1352f51d5",
      "commitAuthorOld": "Gera Shegalov",
      "daysBetweenCommits": 20.07,
      "commitsBetweenForRepo": 261,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,74 @@\n     private void runTask(ContainerRemoteLaunchEvent launchEv,\n         Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles) {\n       TaskAttemptId attemptID \u003d launchEv.getTaskAttemptID(); \n \n       Job job \u003d context.getAllJobs().get(attemptID.getTaskId().getJobId());\n       int numMapTasks \u003d job.getTotalMaps();\n       int numReduceTasks \u003d job.getTotalReduces();\n \n       // YARN (tracking) Task:\n       org.apache.hadoop.mapreduce.v2.app.job.Task ytask \u003d\n           job.getTask(attemptID.getTaskId());\n       // classic mapred Task:\n       org.apache.hadoop.mapred.Task remoteTask \u003d launchEv.getRemoteTask();\n \n       // after \"launching,\" send launched event to task attempt to move\n       // state from ASSIGNED to RUNNING (also nukes \"remoteTask\", so must\n       // do getRemoteTask() call first)\n       \n       //There is no port number because we are not really talking to a task\n       // tracker.  The shuffle is just done through local files.  So the\n       // port number is set to -1 in this case.\n       context.getEventHandler().handle(\n           new TaskAttemptContainerLaunchedEvent(attemptID, -1));\n \n       if (numMapTasks \u003d\u003d 0) {\n         doneWithMaps \u003d true;\n       }\n \n       try {\n         if (remoteTask.isMapOrReduce()) {\n           JobCounterUpdateEvent jce \u003d new JobCounterUpdateEvent(attemptID.getTaskId().getJobId());\n           jce.addCounterUpdate(JobCounter.TOTAL_LAUNCHED_UBERTASKS, 1);\n           if (remoteTask.isMapTask()) {\n             jce.addCounterUpdate(JobCounter.NUM_UBER_SUBMAPS, 1);\n           } else {\n             jce.addCounterUpdate(JobCounter.NUM_UBER_SUBREDUCES, 1);\n           }\n           context.getEventHandler().handle(jce);\n         }\n         runSubtask(remoteTask, ytask.getType(), attemptID, numMapTasks,\n                    (numReduceTasks \u003e 0), localMapFiles);\n-        \n+\n+        // In non-uber mode, TA gets TA_CONTAINER_COMPLETED from MRAppMaster\n+        // as part of NM -\u003e RM -\u003e AM notification route.\n+        // In uber mode, given the task run inside the MRAppMaster container,\n+        // we have to simulate the notification.\n+        context.getEventHandler().handle(new TaskAttemptEvent(attemptID,\n+            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n+\n       } catch (RuntimeException re) {\n         JobCounterUpdateEvent jce \u003d new JobCounterUpdateEvent(attemptID.getTaskId().getJobId());\n         jce.addCounterUpdate(JobCounter.NUM_FAILED_UBERTASKS, 1);\n         context.getEventHandler().handle(jce);\n         // this is our signal that the subtask failed in some way, so\n         // simulate a failed JVM/container and send a container-completed\n         // event to task attempt (i.e., move state machine from RUNNING\n         // to FAIL_CONTAINER_CLEANUP [and ultimately to FAILED])\n         context.getEventHandler().handle(new TaskAttemptEvent(attemptID,\n             TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n       } catch (IOException ioe) {\n         // if umbilical itself barfs (in error-handler of runSubMap()),\n         // we\u0027re pretty much hosed, so do what YarnChild main() does\n         // (i.e., exit clumsily--but can never happen, so no worries!)\n         LOG.fatal(\"oopsie...  this can never happen: \"\n             + StringUtils.stringifyException(ioe));\n         ExitUtil.terminate(-1);\n       } finally {\n         // remove my future\n         if (futures.remove(attemptID) !\u003d null) {\n           LOG.info(\"removed attempt \" + attemptID +\n               \" from the futures to keep track of\");\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void runTask(ContainerRemoteLaunchEvent launchEv,\n        Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles) {\n      TaskAttemptId attemptID \u003d launchEv.getTaskAttemptID(); \n\n      Job job \u003d context.getAllJobs().get(attemptID.getTaskId().getJobId());\n      int numMapTasks \u003d job.getTotalMaps();\n      int numReduceTasks \u003d job.getTotalReduces();\n\n      // YARN (tracking) Task:\n      org.apache.hadoop.mapreduce.v2.app.job.Task ytask \u003d\n          job.getTask(attemptID.getTaskId());\n      // classic mapred Task:\n      org.apache.hadoop.mapred.Task remoteTask \u003d launchEv.getRemoteTask();\n\n      // after \"launching,\" send launched event to task attempt to move\n      // state from ASSIGNED to RUNNING (also nukes \"remoteTask\", so must\n      // do getRemoteTask() call first)\n      \n      //There is no port number because we are not really talking to a task\n      // tracker.  The shuffle is just done through local files.  So the\n      // port number is set to -1 in this case.\n      context.getEventHandler().handle(\n          new TaskAttemptContainerLaunchedEvent(attemptID, -1));\n\n      if (numMapTasks \u003d\u003d 0) {\n        doneWithMaps \u003d true;\n      }\n\n      try {\n        if (remoteTask.isMapOrReduce()) {\n          JobCounterUpdateEvent jce \u003d new JobCounterUpdateEvent(attemptID.getTaskId().getJobId());\n          jce.addCounterUpdate(JobCounter.TOTAL_LAUNCHED_UBERTASKS, 1);\n          if (remoteTask.isMapTask()) {\n            jce.addCounterUpdate(JobCounter.NUM_UBER_SUBMAPS, 1);\n          } else {\n            jce.addCounterUpdate(JobCounter.NUM_UBER_SUBREDUCES, 1);\n          }\n          context.getEventHandler().handle(jce);\n        }\n        runSubtask(remoteTask, ytask.getType(), attemptID, numMapTasks,\n                   (numReduceTasks \u003e 0), localMapFiles);\n\n        // In non-uber mode, TA gets TA_CONTAINER_COMPLETED from MRAppMaster\n        // as part of NM -\u003e RM -\u003e AM notification route.\n        // In uber mode, given the task run inside the MRAppMaster container,\n        // we have to simulate the notification.\n        context.getEventHandler().handle(new TaskAttemptEvent(attemptID,\n            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n\n      } catch (RuntimeException re) {\n        JobCounterUpdateEvent jce \u003d new JobCounterUpdateEvent(attemptID.getTaskId().getJobId());\n        jce.addCounterUpdate(JobCounter.NUM_FAILED_UBERTASKS, 1);\n        context.getEventHandler().handle(jce);\n        // this is our signal that the subtask failed in some way, so\n        // simulate a failed JVM/container and send a container-completed\n        // event to task attempt (i.e., move state machine from RUNNING\n        // to FAIL_CONTAINER_CLEANUP [and ultimately to FAILED])\n        context.getEventHandler().handle(new TaskAttemptEvent(attemptID,\n            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n      } catch (IOException ioe) {\n        // if umbilical itself barfs (in error-handler of runSubMap()),\n        // we\u0027re pretty much hosed, so do what YarnChild main() does\n        // (i.e., exit clumsily--but can never happen, so no worries!)\n        LOG.fatal(\"oopsie...  this can never happen: \"\n            + StringUtils.stringifyException(ioe));\n        ExitUtil.terminate(-1);\n      } finally {\n        // remove my future\n        if (futures.remove(attemptID) !\u003d null) {\n          LOG.info(\"removed attempt \" + attemptID +\n              \" from the futures to keep track of\");\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java",
      "extendedDetails": {}
    },
    "6957745c2c73cae038ac7960115ffc32de05b953": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-5841. uber job doesn\u0027t terminate on getting mapred job kill. Contributed by Sangjin Lee\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1589524 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/04/14 2:53 PM",
      "commitName": "6957745c2c73cae038ac7960115ffc32de05b953",
      "commitAuthor": "Jason Darrell Lowe",
      "diff": "@@ -0,0 +1,67 @@\n+    private void runTask(ContainerRemoteLaunchEvent launchEv,\n+        Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles) {\n+      TaskAttemptId attemptID \u003d launchEv.getTaskAttemptID(); \n+\n+      Job job \u003d context.getAllJobs().get(attemptID.getTaskId().getJobId());\n+      int numMapTasks \u003d job.getTotalMaps();\n+      int numReduceTasks \u003d job.getTotalReduces();\n+\n+      // YARN (tracking) Task:\n+      org.apache.hadoop.mapreduce.v2.app.job.Task ytask \u003d\n+          job.getTask(attemptID.getTaskId());\n+      // classic mapred Task:\n+      org.apache.hadoop.mapred.Task remoteTask \u003d launchEv.getRemoteTask();\n+\n+      // after \"launching,\" send launched event to task attempt to move\n+      // state from ASSIGNED to RUNNING (also nukes \"remoteTask\", so must\n+      // do getRemoteTask() call first)\n+      \n+      //There is no port number because we are not really talking to a task\n+      // tracker.  The shuffle is just done through local files.  So the\n+      // port number is set to -1 in this case.\n+      context.getEventHandler().handle(\n+          new TaskAttemptContainerLaunchedEvent(attemptID, -1));\n+\n+      if (numMapTasks \u003d\u003d 0) {\n+        doneWithMaps \u003d true;\n+      }\n+\n+      try {\n+        if (remoteTask.isMapOrReduce()) {\n+          JobCounterUpdateEvent jce \u003d new JobCounterUpdateEvent(attemptID.getTaskId().getJobId());\n+          jce.addCounterUpdate(JobCounter.TOTAL_LAUNCHED_UBERTASKS, 1);\n+          if (remoteTask.isMapTask()) {\n+            jce.addCounterUpdate(JobCounter.NUM_UBER_SUBMAPS, 1);\n+          } else {\n+            jce.addCounterUpdate(JobCounter.NUM_UBER_SUBREDUCES, 1);\n+          }\n+          context.getEventHandler().handle(jce);\n+        }\n+        runSubtask(remoteTask, ytask.getType(), attemptID, numMapTasks,\n+                   (numReduceTasks \u003e 0), localMapFiles);\n+        \n+      } catch (RuntimeException re) {\n+        JobCounterUpdateEvent jce \u003d new JobCounterUpdateEvent(attemptID.getTaskId().getJobId());\n+        jce.addCounterUpdate(JobCounter.NUM_FAILED_UBERTASKS, 1);\n+        context.getEventHandler().handle(jce);\n+        // this is our signal that the subtask failed in some way, so\n+        // simulate a failed JVM/container and send a container-completed\n+        // event to task attempt (i.e., move state machine from RUNNING\n+        // to FAIL_CONTAINER_CLEANUP [and ultimately to FAILED])\n+        context.getEventHandler().handle(new TaskAttemptEvent(attemptID,\n+            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n+      } catch (IOException ioe) {\n+        // if umbilical itself barfs (in error-handler of runSubMap()),\n+        // we\u0027re pretty much hosed, so do what YarnChild main() does\n+        // (i.e., exit clumsily--but can never happen, so no worries!)\n+        LOG.fatal(\"oopsie...  this can never happen: \"\n+            + StringUtils.stringifyException(ioe));\n+        ExitUtil.terminate(-1);\n+      } finally {\n+        // remove my future\n+        if (futures.remove(attemptID) !\u003d null) {\n+          LOG.info(\"removed attempt \" + attemptID +\n+              \" from the futures to keep track of\");\n+        }\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private void runTask(ContainerRemoteLaunchEvent launchEv,\n        Map\u003cTaskAttemptID, MapOutputFile\u003e localMapFiles) {\n      TaskAttemptId attemptID \u003d launchEv.getTaskAttemptID(); \n\n      Job job \u003d context.getAllJobs().get(attemptID.getTaskId().getJobId());\n      int numMapTasks \u003d job.getTotalMaps();\n      int numReduceTasks \u003d job.getTotalReduces();\n\n      // YARN (tracking) Task:\n      org.apache.hadoop.mapreduce.v2.app.job.Task ytask \u003d\n          job.getTask(attemptID.getTaskId());\n      // classic mapred Task:\n      org.apache.hadoop.mapred.Task remoteTask \u003d launchEv.getRemoteTask();\n\n      // after \"launching,\" send launched event to task attempt to move\n      // state from ASSIGNED to RUNNING (also nukes \"remoteTask\", so must\n      // do getRemoteTask() call first)\n      \n      //There is no port number because we are not really talking to a task\n      // tracker.  The shuffle is just done through local files.  So the\n      // port number is set to -1 in this case.\n      context.getEventHandler().handle(\n          new TaskAttemptContainerLaunchedEvent(attemptID, -1));\n\n      if (numMapTasks \u003d\u003d 0) {\n        doneWithMaps \u003d true;\n      }\n\n      try {\n        if (remoteTask.isMapOrReduce()) {\n          JobCounterUpdateEvent jce \u003d new JobCounterUpdateEvent(attemptID.getTaskId().getJobId());\n          jce.addCounterUpdate(JobCounter.TOTAL_LAUNCHED_UBERTASKS, 1);\n          if (remoteTask.isMapTask()) {\n            jce.addCounterUpdate(JobCounter.NUM_UBER_SUBMAPS, 1);\n          } else {\n            jce.addCounterUpdate(JobCounter.NUM_UBER_SUBREDUCES, 1);\n          }\n          context.getEventHandler().handle(jce);\n        }\n        runSubtask(remoteTask, ytask.getType(), attemptID, numMapTasks,\n                   (numReduceTasks \u003e 0), localMapFiles);\n        \n      } catch (RuntimeException re) {\n        JobCounterUpdateEvent jce \u003d new JobCounterUpdateEvent(attemptID.getTaskId().getJobId());\n        jce.addCounterUpdate(JobCounter.NUM_FAILED_UBERTASKS, 1);\n        context.getEventHandler().handle(jce);\n        // this is our signal that the subtask failed in some way, so\n        // simulate a failed JVM/container and send a container-completed\n        // event to task attempt (i.e., move state machine from RUNNING\n        // to FAIL_CONTAINER_CLEANUP [and ultimately to FAILED])\n        context.getEventHandler().handle(new TaskAttemptEvent(attemptID,\n            TaskAttemptEventType.TA_CONTAINER_COMPLETED));\n      } catch (IOException ioe) {\n        // if umbilical itself barfs (in error-handler of runSubMap()),\n        // we\u0027re pretty much hosed, so do what YarnChild main() does\n        // (i.e., exit clumsily--but can never happen, so no worries!)\n        LOG.fatal(\"oopsie...  this can never happen: \"\n            + StringUtils.stringifyException(ioe));\n        ExitUtil.terminate(-1);\n      } finally {\n        // remove my future\n        if (futures.remove(attemptID) !\u003d null) {\n          LOG.info(\"removed attempt \" + attemptID +\n              \" from the futures to keep track of\");\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/LocalContainerLauncher.java"
    }
  }
}