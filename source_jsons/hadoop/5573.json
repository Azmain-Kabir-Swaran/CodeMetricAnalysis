{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "INodeFile.java",
  "functionName": "computeFileSize",
  "functionId": "computeFileSize___includesLastUcBlock-boolean__usePreferredBlockSize4LastUcBlock-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
  "functionStartLine": 971,
  "functionEndLine": 995,
  "numCommitsSeen": 163,
  "timeTaken": 5264,
  "changeHistory": [
    "0faee62a0c8c1b8fd83227babfd00fbc2b26bddf",
    "164cbe643988f878f0f4100a4de51783e5b6738e",
    "4e14f7982a6e57bf08deb3b266806c2b779a157d",
    "e535e0f05b5fbd087c93238deb888cc985254b4c",
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
    "7e091de1366f4b57b5433bc19d738199dc05313d",
    "ee01a09500224136464f2c3e0a5d9ba53242d93f",
    "c17439c2ddd921b63b1635e6f1cba634b8da8557",
    "26773d9d6c10479982a3cdbea3a0933f4476add3",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177"
  ],
  "changeHistoryShort": {
    "0faee62a0c8c1b8fd83227babfd00fbc2b26bddf": "Ybodychange",
    "164cbe643988f878f0f4100a4de51783e5b6738e": "Ybodychange",
    "4e14f7982a6e57bf08deb3b266806c2b779a157d": "Ybodychange",
    "e535e0f05b5fbd087c93238deb888cc985254b4c": "Ybodychange",
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835": "Ybodychange",
    "7e091de1366f4b57b5433bc19d738199dc05313d": "Ybodychange",
    "ee01a09500224136464f2c3e0a5d9ba53242d93f": "Ybodychange",
    "c17439c2ddd921b63b1635e6f1cba634b8da8557": "Ybodychange",
    "26773d9d6c10479982a3cdbea3a0933f4476add3": "Ybodychange",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": "Ybodychange"
  },
  "changeHistoryDetails": {
    "0faee62a0c8c1b8fd83227babfd00fbc2b26bddf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10764. Fix INodeFile#getBlocks to not return null. Contributed by Arpit Agarwal.\n",
      "commitDate": "19/08/16 10:13 PM",
      "commitName": "0faee62a0c8c1b8fd83227babfd00fbc2b26bddf",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "22/06/16 11:17 AM",
      "commitNameOld": "17eae9ebb30a3b106c4f6ae0c5374a3ab83abd8a",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 58.46,
      "commitsBetweenForRepo": 541,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,25 @@\n   public final long computeFileSize(boolean includesLastUcBlock,\n       boolean usePreferredBlockSize4LastUcBlock) {\n-    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n+    if (blocks.length \u003d\u003d 0) {\n       return 0;\n     }\n     final int last \u003d blocks.length - 1;\n     //check if the last block is BlockInfoUnderConstruction\n     BlockInfo lastBlk \u003d blocks[last];\n     long size \u003d lastBlk.getNumBytes();\n     if (!lastBlk.isComplete()) {\n        if (!includesLastUcBlock) {\n          size \u003d 0;\n        } else if (usePreferredBlockSize4LastUcBlock) {\n          size \u003d isStriped()?\n              getPreferredBlockSize() *\n                  ((BlockInfoStriped)lastBlk).getDataBlockNum() :\n              getPreferredBlockSize();\n        }\n     }\n     //sum other blocks\n     for (int i \u003d 0; i \u003c last; i++) {\n       size +\u003d blocks[i].getNumBytes();\n     }\n     return size;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final long computeFileSize(boolean includesLastUcBlock,\n      boolean usePreferredBlockSize4LastUcBlock) {\n    if (blocks.length \u003d\u003d 0) {\n      return 0;\n    }\n    final int last \u003d blocks.length - 1;\n    //check if the last block is BlockInfoUnderConstruction\n    BlockInfo lastBlk \u003d blocks[last];\n    long size \u003d lastBlk.getNumBytes();\n    if (!lastBlk.isComplete()) {\n       if (!includesLastUcBlock) {\n         size \u003d 0;\n       } else if (usePreferredBlockSize4LastUcBlock) {\n         size \u003d isStriped()?\n             getPreferredBlockSize() *\n                 ((BlockInfoStriped)lastBlk).getDataBlockNum() :\n             getPreferredBlockSize();\n       }\n    }\n    //sum other blocks\n    for (int i \u003d 0; i \u003c last; i++) {\n      size +\u003d blocks[i].getNumBytes();\n    }\n    return size;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "164cbe643988f878f0f4100a4de51783e5b6738e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8909. Erasure coding: update BlockInfoContiguousUC and BlockInfoStripedUC to use BlockUnderConstructionFeature. Contributed by Jing Zhao.\n",
      "commitDate": "27/08/15 1:02 AM",
      "commitName": "164cbe643988f878f0f4100a4de51783e5b6738e",
      "commitAuthor": "Walter Su",
      "commitDateOld": "24/08/15 12:59 PM",
      "commitNameOld": "6b6a63bbbda920315d3d24b61ed3344a78a981b6",
      "commitAuthorOld": "",
      "daysBetweenCommits": 2.5,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,25 @@\n   public final long computeFileSize(boolean includesLastUcBlock,\n       boolean usePreferredBlockSize4LastUcBlock) {\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return 0;\n     }\n     final int last \u003d blocks.length - 1;\n     //check if the last block is BlockInfoUnderConstruction\n     BlockInfo lastBlk \u003d blocks[last];\n     long size \u003d lastBlk.getNumBytes();\n-    if (lastBlk instanceof BlockInfoUnderConstruction) {\n+    if (!lastBlk.isComplete()) {\n        if (!includesLastUcBlock) {\n          size \u003d 0;\n        } else if (usePreferredBlockSize4LastUcBlock) {\n          size \u003d isStriped()?\n              getPreferredBlockSize() *\n                  ((BlockInfoStriped)lastBlk).getDataBlockNum() :\n              getPreferredBlockSize();\n        }\n     }\n     //sum other blocks\n     for (int i \u003d 0; i \u003c last; i++) {\n       size +\u003d blocks[i].getNumBytes();\n     }\n     return size;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final long computeFileSize(boolean includesLastUcBlock,\n      boolean usePreferredBlockSize4LastUcBlock) {\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return 0;\n    }\n    final int last \u003d blocks.length - 1;\n    //check if the last block is BlockInfoUnderConstruction\n    BlockInfo lastBlk \u003d blocks[last];\n    long size \u003d lastBlk.getNumBytes();\n    if (!lastBlk.isComplete()) {\n       if (!includesLastUcBlock) {\n         size \u003d 0;\n       } else if (usePreferredBlockSize4LastUcBlock) {\n         size \u003d isStriped()?\n             getPreferredBlockSize() *\n                 ((BlockInfoStriped)lastBlk).getDataBlockNum() :\n             getPreferredBlockSize();\n       }\n    }\n    //sum other blocks\n    for (int i \u003d 0; i \u003c last; i++) {\n      size +\u003d blocks[i].getNumBytes();\n    }\n    return size;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "4e14f7982a6e57bf08deb3b266806c2b779a157d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8917. Cleanup BlockInfoUnderConstruction from comments and tests. Contributed by Zhe Zhang.\n",
      "commitDate": "19/08/15 3:11 PM",
      "commitName": "4e14f7982a6e57bf08deb3b266806c2b779a157d",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "17/08/15 11:28 AM",
      "commitNameOld": "e535e0f05b5fbd087c93238deb888cc985254b4c",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 2.15,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   public final long computeFileSize(boolean includesLastUcBlock,\n       boolean usePreferredBlockSize4LastUcBlock) {\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return 0;\n     }\n     final int last \u003d blocks.length - 1;\n-    //check if the last block is BlockInfoUnderConstruction\n+    //check if the last block is under-construction\n     long size \u003d blocks[last].getNumBytes();\n     if (!blocks[last].isComplete()) {\n        if (!includesLastUcBlock) {\n          size \u003d 0;\n        } else if (usePreferredBlockSize4LastUcBlock) {\n          size \u003d getPreferredBlockSize();\n        }\n     }\n     //sum other blocks\n     for(int i \u003d 0; i \u003c last; i++) {\n       size +\u003d blocks[i].getNumBytes();\n     }\n     return size;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final long computeFileSize(boolean includesLastUcBlock,\n      boolean usePreferredBlockSize4LastUcBlock) {\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return 0;\n    }\n    final int last \u003d blocks.length - 1;\n    //check if the last block is under-construction\n    long size \u003d blocks[last].getNumBytes();\n    if (!blocks[last].isComplete()) {\n       if (!includesLastUcBlock) {\n         size \u003d 0;\n       } else if (usePreferredBlockSize4LastUcBlock) {\n         size \u003d getPreferredBlockSize();\n       }\n    }\n    //sum other blocks\n    for(int i \u003d 0; i \u003c last; i++) {\n      size +\u003d blocks[i].getNumBytes();\n    }\n    return size;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "e535e0f05b5fbd087c93238deb888cc985254b4c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8801. Convert BlockInfoUnderConstruction as a feature. Contributed by Jing Zhao.\n",
      "commitDate": "17/08/15 11:28 AM",
      "commitName": "e535e0f05b5fbd087c93238deb888cc985254b4c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "06/08/15 10:21 AM",
      "commitNameOld": "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 11.05,
      "commitsBetweenForRepo": 46,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   public final long computeFileSize(boolean includesLastUcBlock,\n       boolean usePreferredBlockSize4LastUcBlock) {\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return 0;\n     }\n     final int last \u003d blocks.length - 1;\n     //check if the last block is BlockInfoUnderConstruction\n     long size \u003d blocks[last].getNumBytes();\n-    if (blocks[last] instanceof BlockInfoContiguousUnderConstruction) {\n+    if (!blocks[last].isComplete()) {\n        if (!includesLastUcBlock) {\n          size \u003d 0;\n        } else if (usePreferredBlockSize4LastUcBlock) {\n          size \u003d getPreferredBlockSize();\n        }\n     }\n     //sum other blocks\n     for(int i \u003d 0; i \u003c last; i++) {\n       size +\u003d blocks[i].getNumBytes();\n     }\n     return size;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final long computeFileSize(boolean includesLastUcBlock,\n      boolean usePreferredBlockSize4LastUcBlock) {\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return 0;\n    }\n    final int last \u003d blocks.length - 1;\n    //check if the last block is BlockInfoUnderConstruction\n    long size \u003d blocks[last].getNumBytes();\n    if (!blocks[last].isComplete()) {\n       if (!includesLastUcBlock) {\n         size \u003d 0;\n       } else if (usePreferredBlockSize4LastUcBlock) {\n         size \u003d getPreferredBlockSize();\n       }\n    }\n    //sum other blocks\n    for(int i \u003d 0; i \u003c last; i++) {\n      size +\u003d blocks[i].getNumBytes();\n    }\n    return size;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "f4c523b69ba55b1fd35e8995c3011a9f546ac835": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang.\"\n\nThis reverts commit c17439c2ddd921b63b1635e6f1cba634b8da8557.\n",
      "commitDate": "06/08/15 10:21 AM",
      "commitName": "f4c523b69ba55b1fd35e8995c3011a9f546ac835",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "10/07/15 2:15 PM",
      "commitNameOld": "47f4c54106ebb234a7d3dc71320aa584ecba161a",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 26.84,
      "commitsBetweenForRepo": 152,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   public final long computeFileSize(boolean includesLastUcBlock,\n       boolean usePreferredBlockSize4LastUcBlock) {\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return 0;\n     }\n     final int last \u003d blocks.length - 1;\n     //check if the last block is BlockInfoUnderConstruction\n     long size \u003d blocks[last].getNumBytes();\n-    if (blocks[last] instanceof BlockInfoUnderConstruction) {\n+    if (blocks[last] instanceof BlockInfoContiguousUnderConstruction) {\n        if (!includesLastUcBlock) {\n          size \u003d 0;\n        } else if (usePreferredBlockSize4LastUcBlock) {\n          size \u003d getPreferredBlockSize();\n        }\n     }\n     //sum other blocks\n     for(int i \u003d 0; i \u003c last; i++) {\n       size +\u003d blocks[i].getNumBytes();\n     }\n     return size;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final long computeFileSize(boolean includesLastUcBlock,\n      boolean usePreferredBlockSize4LastUcBlock) {\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return 0;\n    }\n    final int last \u003d blocks.length - 1;\n    //check if the last block is BlockInfoUnderConstruction\n    long size \u003d blocks[last].getNumBytes();\n    if (blocks[last] instanceof BlockInfoContiguousUnderConstruction) {\n       if (!includesLastUcBlock) {\n         size \u003d 0;\n       } else if (usePreferredBlockSize4LastUcBlock) {\n         size \u003d getPreferredBlockSize();\n       }\n    }\n    //sum other blocks\n    for(int i \u003d 0; i \u003c last; i++) {\n      size +\u003d blocks[i].getNumBytes();\n    }\n    return size;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "7e091de1366f4b57b5433bc19d738199dc05313d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8058. Erasure coding: use BlockInfo[] for both striped and contiguous blocks in INodeFile. Contributed by Zhe Zhang and Yi Liu.\n",
      "commitDate": "15/07/15 9:49 AM",
      "commitName": "7e091de1366f4b57b5433bc19d738199dc05313d",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "06/07/15 4:14 AM",
      "commitNameOld": "ee01a09500224136464f2c3e0a5d9ba53242d93f",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 9.23,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,25 @@\n   public final long computeFileSize(boolean includesLastUcBlock,\n-                                    boolean usePreferredBlockSize4LastUcBlock) {\n-    BlockInfo[] blockInfos \u003d getBlocks();\n-    // In case of contiguous blocks\n-    if (blockInfos \u003d\u003d null || blockInfos.length \u003d\u003d 0) {\n+      boolean usePreferredBlockSize4LastUcBlock) {\n+    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return 0;\n     }\n-    final int last \u003d blockInfos.length - 1;\n+    final int last \u003d blocks.length - 1;\n     //check if the last block is BlockInfoUnderConstruction\n-    long size \u003d blockInfos[last].getNumBytes();\n-    if (blockInfos[last] instanceof BlockInfoContiguousUnderConstruction) {\n-      if (!includesLastUcBlock) {\n-        size \u003d 0;\n-      } else if (usePreferredBlockSize4LastUcBlock) {\n-        size \u003d getPreferredBlockSize();\n-      }\n-    } else if (blockInfos[last] instanceof BlockInfoStripedUnderConstruction) {\n-      if (!includesLastUcBlock) {\n-        size \u003d 0;\n-      } else if (usePreferredBlockSize4LastUcBlock) {\n-        BlockInfoStripedUnderConstruction blockInfoStripedUC\n-            \u003d (BlockInfoStripedUnderConstruction) blockInfos[last];\n-        size \u003d getPreferredBlockSize() * blockInfoStripedUC.getDataBlockNum();\n-      }\n+    BlockInfo lastBlk \u003d blocks[last];\n+    long size \u003d lastBlk.getNumBytes();\n+    if (lastBlk instanceof BlockInfoUnderConstruction) {\n+       if (!includesLastUcBlock) {\n+         size \u003d 0;\n+       } else if (usePreferredBlockSize4LastUcBlock) {\n+         size \u003d isStriped()?\n+             getPreferredBlockSize() *\n+                 ((BlockInfoStriped)lastBlk).getDataBlockNum() :\n+             getPreferredBlockSize();\n+       }\n     }\n     //sum other blocks\n     for (int i \u003d 0; i \u003c last; i++) {\n-      size +\u003d blockInfos[i].getNumBytes();\n+      size +\u003d blocks[i].getNumBytes();\n     }\n     return size;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final long computeFileSize(boolean includesLastUcBlock,\n      boolean usePreferredBlockSize4LastUcBlock) {\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return 0;\n    }\n    final int last \u003d blocks.length - 1;\n    //check if the last block is BlockInfoUnderConstruction\n    BlockInfo lastBlk \u003d blocks[last];\n    long size \u003d lastBlk.getNumBytes();\n    if (lastBlk instanceof BlockInfoUnderConstruction) {\n       if (!includesLastUcBlock) {\n         size \u003d 0;\n       } else if (usePreferredBlockSize4LastUcBlock) {\n         size \u003d isStriped()?\n             getPreferredBlockSize() *\n                 ((BlockInfoStriped)lastBlk).getDataBlockNum() :\n             getPreferredBlockSize();\n       }\n    }\n    //sum other blocks\n    for (int i \u003d 0; i \u003c last; i++) {\n      size +\u003d blocks[i].getNumBytes();\n    }\n    return size;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "ee01a09500224136464f2c3e0a5d9ba53242d93f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8684. Erasure Coding: fix some block number calculation for striped block. (yliu)\n",
      "commitDate": "06/07/15 4:14 AM",
      "commitName": "ee01a09500224136464f2c3e0a5d9ba53242d93f",
      "commitAuthor": "yliu",
      "commitDateOld": "26/05/15 12:07 PM",
      "commitNameOld": "3d734df24cba53ec56074b4d28e3bcdce7d2894e",
      "commitAuthorOld": "Walter Su",
      "daysBetweenCommits": 40.67,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,31 @@\n   public final long computeFileSize(boolean includesLastUcBlock,\n                                     boolean usePreferredBlockSize4LastUcBlock) {\n     BlockInfo[] blockInfos \u003d getBlocks();\n     // In case of contiguous blocks\n     if (blockInfos \u003d\u003d null || blockInfos.length \u003d\u003d 0) {\n       return 0;\n     }\n     final int last \u003d blockInfos.length - 1;\n     //check if the last block is BlockInfoUnderConstruction\n     long size \u003d blockInfos[last].getNumBytes();\n     if (blockInfos[last] instanceof BlockInfoContiguousUnderConstruction) {\n       if (!includesLastUcBlock) {\n         size \u003d 0;\n       } else if (usePreferredBlockSize4LastUcBlock) {\n         size \u003d getPreferredBlockSize();\n       }\n     } else if (blockInfos[last] instanceof BlockInfoStripedUnderConstruction) {\n       if (!includesLastUcBlock) {\n         size \u003d 0;\n       } else if (usePreferredBlockSize4LastUcBlock) {\n-        // Striped blocks keeps block group which counts\n-        // (data blocks num + parity blocks num). When you\n-        // count actual used size by BlockInfoStripedUC must\n-        // be multiplied by these blocks number.\n         BlockInfoStripedUnderConstruction blockInfoStripedUC\n             \u003d (BlockInfoStripedUnderConstruction) blockInfos[last];\n-        size \u003d getPreferredBlockSize() * blockInfoStripedUC.getTotalBlockNum();\n+        size \u003d getPreferredBlockSize() * blockInfoStripedUC.getDataBlockNum();\n       }\n     }\n     //sum other blocks\n     for (int i \u003d 0; i \u003c last; i++) {\n       size +\u003d blockInfos[i].getNumBytes();\n     }\n     return size;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final long computeFileSize(boolean includesLastUcBlock,\n                                    boolean usePreferredBlockSize4LastUcBlock) {\n    BlockInfo[] blockInfos \u003d getBlocks();\n    // In case of contiguous blocks\n    if (blockInfos \u003d\u003d null || blockInfos.length \u003d\u003d 0) {\n      return 0;\n    }\n    final int last \u003d blockInfos.length - 1;\n    //check if the last block is BlockInfoUnderConstruction\n    long size \u003d blockInfos[last].getNumBytes();\n    if (blockInfos[last] instanceof BlockInfoContiguousUnderConstruction) {\n      if (!includesLastUcBlock) {\n        size \u003d 0;\n      } else if (usePreferredBlockSize4LastUcBlock) {\n        size \u003d getPreferredBlockSize();\n      }\n    } else if (blockInfos[last] instanceof BlockInfoStripedUnderConstruction) {\n      if (!includesLastUcBlock) {\n        size \u003d 0;\n      } else if (usePreferredBlockSize4LastUcBlock) {\n        BlockInfoStripedUnderConstruction blockInfoStripedUC\n            \u003d (BlockInfoStripedUnderConstruction) blockInfos[last];\n        size \u003d getPreferredBlockSize() * blockInfoStripedUC.getDataBlockNum();\n      }\n    }\n    //sum other blocks\n    for (int i \u003d 0; i \u003c last; i++) {\n      size +\u003d blockInfos[i].getNumBytes();\n    }\n    return size;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "c17439c2ddd921b63b1635e6f1cba634b8da8557": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8499. Refactor BlockInfo class hierarchy with static helper class. Contributed by Zhe Zhang.\n",
      "commitDate": "12/06/15 11:38 AM",
      "commitName": "c17439c2ddd921b63b1635e6f1cba634b8da8557",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "27/05/15 3:42 PM",
      "commitNameOld": "4928f5473394981829e5ffd4b16ea0801baf5c45",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 15.83,
      "commitsBetweenForRepo": 122,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   public final long computeFileSize(boolean includesLastUcBlock,\n       boolean usePreferredBlockSize4LastUcBlock) {\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return 0;\n     }\n     final int last \u003d blocks.length - 1;\n     //check if the last block is BlockInfoUnderConstruction\n     long size \u003d blocks[last].getNumBytes();\n-    if (blocks[last] instanceof BlockInfoContiguousUnderConstruction) {\n+    if (blocks[last] instanceof BlockInfoUnderConstruction) {\n        if (!includesLastUcBlock) {\n          size \u003d 0;\n        } else if (usePreferredBlockSize4LastUcBlock) {\n          size \u003d getPreferredBlockSize();\n        }\n     }\n     //sum other blocks\n     for(int i \u003d 0; i \u003c last; i++) {\n       size +\u003d blocks[i].getNumBytes();\n     }\n     return size;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final long computeFileSize(boolean includesLastUcBlock,\n      boolean usePreferredBlockSize4LastUcBlock) {\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return 0;\n    }\n    final int last \u003d blocks.length - 1;\n    //check if the last block is BlockInfoUnderConstruction\n    long size \u003d blocks[last].getNumBytes();\n    if (blocks[last] instanceof BlockInfoUnderConstruction) {\n       if (!includesLastUcBlock) {\n         size \u003d 0;\n       } else if (usePreferredBlockSize4LastUcBlock) {\n         size \u003d getPreferredBlockSize();\n       }\n    }\n    //sum other blocks\n    for(int i \u003d 0; i \u003c last; i++) {\n      size +\u003d blocks[i].getNumBytes();\n    }\n    return size;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "26773d9d6c10479982a3cdbea3a0933f4476add3": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7826. Erasure Coding: Update INodeFile quota computation for striped blocks. Contributed by Kai Sasaki.\n",
      "commitDate": "26/05/15 11:32 AM",
      "commitName": "26773d9d6c10479982a3cdbea3a0933f4476add3",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "26/05/15 11:32 AM",
      "commitNameOld": "39a0a85fb77872911089aac3f7792ab48d9eca68",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,35 @@\n   public final long computeFileSize(boolean includesLastUcBlock,\n-      boolean usePreferredBlockSize4LastUcBlock) {\n-    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n+                                    boolean usePreferredBlockSize4LastUcBlock) {\n+    BlockInfo[] blockInfos \u003d getBlocks();\n+    // In case of contiguous blocks\n+    if (blockInfos \u003d\u003d null || blockInfos.length \u003d\u003d 0) {\n       return 0;\n     }\n-    final int last \u003d blocks.length - 1;\n+    final int last \u003d blockInfos.length - 1;\n     //check if the last block is BlockInfoUnderConstruction\n-    long size \u003d blocks[last].getNumBytes();\n-    if (blocks[last] instanceof BlockInfoContiguousUnderConstruction) {\n-       if (!includesLastUcBlock) {\n-         size \u003d 0;\n-       } else if (usePreferredBlockSize4LastUcBlock) {\n-         size \u003d getPreferredBlockSize();\n-       }\n+    long size \u003d blockInfos[last].getNumBytes();\n+    if (blockInfos[last] instanceof BlockInfoContiguousUnderConstruction) {\n+      if (!includesLastUcBlock) {\n+        size \u003d 0;\n+      } else if (usePreferredBlockSize4LastUcBlock) {\n+        size \u003d getPreferredBlockSize();\n+      }\n+    } else if (blockInfos[last] instanceof BlockInfoStripedUnderConstruction) {\n+      if (!includesLastUcBlock) {\n+        size \u003d 0;\n+      } else if (usePreferredBlockSize4LastUcBlock) {\n+        // Striped blocks keeps block group which counts\n+        // (data blocks num + parity blocks num). When you\n+        // count actual used size by BlockInfoStripedUC must\n+        // be multiplied by these blocks number.\n+        BlockInfoStripedUnderConstruction blockInfoStripedUC\n+            \u003d (BlockInfoStripedUnderConstruction) blockInfos[last];\n+        size \u003d getPreferredBlockSize() * blockInfoStripedUC.getTotalBlockNum();\n+      }\n     }\n     //sum other blocks\n-    for(int i \u003d 0; i \u003c last; i++) {\n-      size +\u003d blocks[i].getNumBytes();\n+    for (int i \u003d 0; i \u003c last; i++) {\n+      size +\u003d blockInfos[i].getNumBytes();\n     }\n     return size;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final long computeFileSize(boolean includesLastUcBlock,\n                                    boolean usePreferredBlockSize4LastUcBlock) {\n    BlockInfo[] blockInfos \u003d getBlocks();\n    // In case of contiguous blocks\n    if (blockInfos \u003d\u003d null || blockInfos.length \u003d\u003d 0) {\n      return 0;\n    }\n    final int last \u003d blockInfos.length - 1;\n    //check if the last block is BlockInfoUnderConstruction\n    long size \u003d blockInfos[last].getNumBytes();\n    if (blockInfos[last] instanceof BlockInfoContiguousUnderConstruction) {\n      if (!includesLastUcBlock) {\n        size \u003d 0;\n      } else if (usePreferredBlockSize4LastUcBlock) {\n        size \u003d getPreferredBlockSize();\n      }\n    } else if (blockInfos[last] instanceof BlockInfoStripedUnderConstruction) {\n      if (!includesLastUcBlock) {\n        size \u003d 0;\n      } else if (usePreferredBlockSize4LastUcBlock) {\n        // Striped blocks keeps block group which counts\n        // (data blocks num + parity blocks num). When you\n        // count actual used size by BlockInfoStripedUC must\n        // be multiplied by these blocks number.\n        BlockInfoStripedUnderConstruction blockInfoStripedUC\n            \u003d (BlockInfoStripedUnderConstruction) blockInfos[last];\n        size \u003d getPreferredBlockSize() * blockInfoStripedUC.getTotalBlockNum();\n      }\n    }\n    //sum other blocks\n    for (int i \u003d 0; i \u003c last; i++) {\n      size +\u003d blockInfos[i].getNumBytes();\n    }\n    return size;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7743. Code cleanup of BlockInfo and rename BlockInfo to BlockInfoContiguous. Contributed by Jing Zhao.\n",
      "commitDate": "08/02/15 11:51 AM",
      "commitName": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "02/02/15 4:32 PM",
      "commitNameOld": "8cb473124c1cf1c6f68ead7bde06558ebf7ce47e",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 5.8,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,21 @@\n   public final long computeFileSize(boolean includesLastUcBlock,\n       boolean usePreferredBlockSize4LastUcBlock) {\n     if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n       return 0;\n     }\n     final int last \u003d blocks.length - 1;\n     //check if the last block is BlockInfoUnderConstruction\n     long size \u003d blocks[last].getNumBytes();\n-    if (blocks[last] instanceof BlockInfoUnderConstruction) {\n+    if (blocks[last] instanceof BlockInfoContiguousUnderConstruction) {\n        if (!includesLastUcBlock) {\n          size \u003d 0;\n        } else if (usePreferredBlockSize4LastUcBlock) {\n          size \u003d getPreferredBlockSize();\n        }\n     }\n     //sum other blocks\n     for(int i \u003d 0; i \u003c last; i++) {\n       size +\u003d blocks[i].getNumBytes();\n     }\n     return size;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final long computeFileSize(boolean includesLastUcBlock,\n      boolean usePreferredBlockSize4LastUcBlock) {\n    if (blocks \u003d\u003d null || blocks.length \u003d\u003d 0) {\n      return 0;\n    }\n    final int last \u003d blocks.length - 1;\n    //check if the last block is BlockInfoUnderConstruction\n    long size \u003d blocks[last].getNumBytes();\n    if (blocks[last] instanceof BlockInfoContiguousUnderConstruction) {\n       if (!includesLastUcBlock) {\n         size \u003d 0;\n       } else if (usePreferredBlockSize4LastUcBlock) {\n         size \u003d getPreferredBlockSize();\n       }\n    }\n    //sum other blocks\n    for(int i \u003d 0; i \u003c last; i++) {\n      size +\u003d blocks[i].getNumBytes();\n    }\n    return size;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    }
  }
}