{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataNode.java",
  "functionName": "incrDatanodeNetworkErrors",
  "functionId": "incrDatanodeNetworkErrors___host-String",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
  "functionStartLine": 2270,
  "functionEndLine": 2287,
  "numCommitsSeen": 358,
  "timeTaken": 2072,
  "changeHistory": [
    "dfcb331ba3516264398121c9f23af3a79c0509cc"
  ],
  "changeHistoryShort": {
    "dfcb331ba3516264398121c9f23af3a79c0509cc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "dfcb331ba3516264398121c9f23af3a79c0509cc": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13076: [SPS]: Addendum. Resolve conflicts after rebasing branch to trunk. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "dfcb331ba3516264398121c9f23af3a79c0509cc",
      "commitAuthor": "Rakesh Radhakrishnan",
      "diff": "@@ -0,0 +1,18 @@\n+  void incrDatanodeNetworkErrors(String host) {\n+    metrics.incrDatanodeNetworkErrors();\n+\n+    /*\n+     * Synchronizing on the whole cache is a big hammer, but since it\u0027s only\n+     * accumulating errors, it should be ok. If this is ever expanded to include\n+     * non-error stats, then finer-grained concurrency should be applied.\n+     */\n+    synchronized (datanodeNetworkCounts) {\n+      try {\n+        final Map\u003cString, Long\u003e curCount \u003d datanodeNetworkCounts.get(host);\n+        curCount.put(\"networkErrors\", curCount.get(\"networkErrors\") + 1L);\n+        datanodeNetworkCounts.put(host, curCount);\n+      } catch (ExecutionException e) {\n+        LOG.warn(\"failed to increment network error counts for \" + host);\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void incrDatanodeNetworkErrors(String host) {\n    metrics.incrDatanodeNetworkErrors();\n\n    /*\n     * Synchronizing on the whole cache is a big hammer, but since it\u0027s only\n     * accumulating errors, it should be ok. If this is ever expanded to include\n     * non-error stats, then finer-grained concurrency should be applied.\n     */\n    synchronized (datanodeNetworkCounts) {\n      try {\n        final Map\u003cString, Long\u003e curCount \u003d datanodeNetworkCounts.get(host);\n        curCount.put(\"networkErrors\", curCount.get(\"networkErrors\") + 1L);\n        datanodeNetworkCounts.put(host, curCount);\n      } catch (ExecutionException e) {\n        LOG.warn(\"failed to increment network error counts for \" + host);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java"
    }
  }
}