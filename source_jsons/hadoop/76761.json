{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ByteBufferEncodingState.java",
  "functionName": "convertToByteArrayState",
  "functionId": "convertToByteArrayState",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/ByteBufferEncodingState.java",
  "functionStartLine": 62,
  "functionEndLine": 84,
  "numCommitsSeen": 2,
  "timeTaken": 983,
  "changeHistory": [
    "77202fa1035a54496d11d07472fbc399148ff630"
  ],
  "changeHistoryShort": {
    "77202fa1035a54496d11d07472fbc399148ff630": "Yintroduced"
  },
  "changeHistoryDetails": {
    "77202fa1035a54496d11d07472fbc399148ff630": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13010. Refactor raw erasure coders. Contributed by Kai Zheng\n",
      "commitDate": "26/05/16 10:23 PM",
      "commitName": "77202fa1035a54496d11d07472fbc399148ff630",
      "commitAuthor": "Kai Zheng",
      "diff": "@@ -0,0 +1,23 @@\n+  ByteArrayEncodingState convertToByteArrayState() {\n+    int[] inputOffsets \u003d new int[inputs.length];\n+    int[] outputOffsets \u003d new int[outputs.length];\n+    byte[][] newInputs \u003d new byte[inputs.length][];\n+    byte[][] newOutputs \u003d new byte[outputs.length][];\n+\n+    ByteBuffer buffer;\n+    for (int i \u003d 0; i \u003c inputs.length; ++i) {\n+      buffer \u003d inputs[i];\n+      inputOffsets[i] \u003d buffer.arrayOffset() + buffer.position();\n+      newInputs[i] \u003d buffer.array();\n+    }\n+\n+    for (int i \u003d 0; i \u003c outputs.length; ++i) {\n+      buffer \u003d outputs[i];\n+      outputOffsets[i] \u003d buffer.arrayOffset() + buffer.position();\n+      newOutputs[i] \u003d buffer.array();\n+    }\n+\n+    ByteArrayEncodingState baeState \u003d new ByteArrayEncodingState(encoder,\n+        encodeLength, newInputs, inputOffsets, newOutputs, outputOffsets);\n+    return baeState;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  ByteArrayEncodingState convertToByteArrayState() {\n    int[] inputOffsets \u003d new int[inputs.length];\n    int[] outputOffsets \u003d new int[outputs.length];\n    byte[][] newInputs \u003d new byte[inputs.length][];\n    byte[][] newOutputs \u003d new byte[outputs.length][];\n\n    ByteBuffer buffer;\n    for (int i \u003d 0; i \u003c inputs.length; ++i) {\n      buffer \u003d inputs[i];\n      inputOffsets[i] \u003d buffer.arrayOffset() + buffer.position();\n      newInputs[i] \u003d buffer.array();\n    }\n\n    for (int i \u003d 0; i \u003c outputs.length; ++i) {\n      buffer \u003d outputs[i];\n      outputOffsets[i] \u003d buffer.arrayOffset() + buffer.position();\n      newOutputs[i] \u003d buffer.array();\n    }\n\n    ByteArrayEncodingState baeState \u003d new ByteArrayEncodingState(encoder,\n        encodeLength, newInputs, inputOffsets, newOutputs, outputOffsets);\n    return baeState;\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/erasurecode/rawcoder/ByteBufferEncodingState.java"
    }
  }
}