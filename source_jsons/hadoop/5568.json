{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "INodeFile.java",
  "functionName": "computeContentSummary",
  "functionId": "computeContentSummary___snapshotId-int__summary-ContentSummaryComputationContext(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
  "functionStartLine": 870,
  "functionEndLine": 901,
  "numCommitsSeen": 339,
  "timeTaken": 7350,
  "changeHistory": [
    "bf45f3b80a88ca6e6ab1289dc5b71d9d6e6f6c10",
    "b8b69d797aed8dfeb65ea462c2856f62e9aa1023",
    "6a38d118d86b7907009bcec34f1b788d076f1d1c",
    "3f4275310203de4ccfb15337f3c503e25408a265",
    "b2c85db86c9a62b0a03ee87547265077f664970a",
    "02a4a22b9c0e22c2e7dd6ec85edd5c5a167fe19f",
    "5c97db07fb306842f49d73a67a90cecec19a7833",
    "72f6bd4893dcf10d6dad24753f9be99505a87a1f",
    "3d0708bdb0a75af3d87bbac9f6c4ffbcabab98ca",
    "f2231cebcddc80f0b753c4a7cb45ee4040846951",
    "08ac06283a3e9bf0d49d873823aabd419b08e41f",
    "fe67e30bc2794e7ff073cf938ee80eba805d1e69"
  ],
  "changeHistoryShort": {
    "bf45f3b80a88ca6e6ab1289dc5b71d9d6e6f6c10": "Ybodychange",
    "b8b69d797aed8dfeb65ea462c2856f62e9aa1023": "Ybodychange",
    "6a38d118d86b7907009bcec34f1b788d076f1d1c": "Ybodychange",
    "3f4275310203de4ccfb15337f3c503e25408a265": "Ymultichange(Yparameterchange,Ybodychange)",
    "b2c85db86c9a62b0a03ee87547265077f664970a": "Ybodychange",
    "02a4a22b9c0e22c2e7dd6ec85edd5c5a167fe19f": "Ybodychange",
    "5c97db07fb306842f49d73a67a90cecec19a7833": "Ybodychange",
    "72f6bd4893dcf10d6dad24753f9be99505a87a1f": "Ybodychange",
    "3d0708bdb0a75af3d87bbac9f6c4ffbcabab98ca": "Ybodychange",
    "f2231cebcddc80f0b753c4a7cb45ee4040846951": "Ybodychange",
    "08ac06283a3e9bf0d49d873823aabd419b08e41f": "Ybodychange",
    "fe67e30bc2794e7ff073cf938ee80eba805d1e69": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "bf45f3b80a88ca6e6ab1289dc5b71d9d6e6f6c10": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14957. INodeReference Space Consumed was not same in QuotaUsage and ContentSummary. Contributed by hemanthboyina.\n",
      "commitDate": "08/01/20 10:34 PM",
      "commitName": "bf45f3b80a88ca6e6ab1289dc5b71d9d6e6f6c10",
      "commitAuthor": "Surendra Singh Lilhore",
      "commitDateOld": "01/10/19 8:46 AM",
      "commitNameOld": "6ef6594c7ee09b561e42c16ce4e91c0479908ad8",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 99.62,
      "commitsBetweenForRepo": 413,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,32 @@\n   public final ContentSummaryComputationContext computeContentSummary(\n       int snapshotId, final ContentSummaryComputationContext summary) {\n     final ContentCounts counts \u003d summary.getCounts();\n     counts.addContent(Content.FILE, 1);\n     final long fileLen \u003d computeFileSize(snapshotId);\n     counts.addContent(Content.LENGTH, fileLen);\n-    counts.addContent(Content.DISKSPACE, storagespaceConsumed(null)\n-        .getStorageSpace());\n+\n+    FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n+    if (sf \u003d\u003d null) {\n+      counts.addContent(Content.DISKSPACE,\n+          storagespaceConsumed(null).getStorageSpace());\n+    } else if (isStriped()) {\n+      counts.addContent(Content.DISKSPACE,\n+          storagespaceConsumedStriped().getStorageSpace());\n+    } else {\n+      long diskSpaceQuota \u003d getDiskSpaceQuota(counts, sf, snapshotId);\n+      counts.addContent(Content.DISKSPACE, diskSpaceQuota);\n+    }\n \n     if (getStoragePolicyID() !\u003d BLOCK_STORAGE_POLICY_ID_UNSPECIFIED){\n       BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n           getPolicy(getStoragePolicyID());\n       List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n       for (StorageType t : storageTypes) {\n         if (!t.supportTypeQuota()) {\n           continue;\n         }\n         counts.addTypeSpace(t, fileLen);\n       }\n     }\n     return summary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final ContentSummaryComputationContext computeContentSummary(\n      int snapshotId, final ContentSummaryComputationContext summary) {\n    final ContentCounts counts \u003d summary.getCounts();\n    counts.addContent(Content.FILE, 1);\n    final long fileLen \u003d computeFileSize(snapshotId);\n    counts.addContent(Content.LENGTH, fileLen);\n\n    FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n    if (sf \u003d\u003d null) {\n      counts.addContent(Content.DISKSPACE,\n          storagespaceConsumed(null).getStorageSpace());\n    } else if (isStriped()) {\n      counts.addContent(Content.DISKSPACE,\n          storagespaceConsumedStriped().getStorageSpace());\n    } else {\n      long diskSpaceQuota \u003d getDiskSpaceQuota(counts, sf, snapshotId);\n      counts.addContent(Content.DISKSPACE, diskSpaceQuota);\n    }\n\n    if (getStoragePolicyID() !\u003d BLOCK_STORAGE_POLICY_ID_UNSPECIFIED){\n      BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n          getPolicy(getStoragePolicyID());\n      List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n      for (StorageType t : storageTypes) {\n        if (!t.supportTypeQuota()) {\n          continue;\n        }\n        counts.addTypeSpace(t, fileLen);\n      }\n    }\n    return summary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "b8b69d797aed8dfeb65ea462c2856f62e9aa1023": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-10797. Disk usage summary of snapshots causes renamed blocks to get counted twice. Contributed by Sean Mackrory.\"\n\nThis reverts commit 6a38d118d86b7907009bcec34f1b788d076f1d1c.\n",
      "commitDate": "24/05/17 5:21 PM",
      "commitName": "b8b69d797aed8dfeb65ea462c2856f62e9aa1023",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "27/04/17 10:18 PM",
      "commitNameOld": "cb672a45a0bbd8950b9b5e304c2e03f516945903",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 26.79,
      "commitsBetweenForRepo": 142,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,22 @@\n   public final ContentSummaryComputationContext computeContentSummary(\n       int snapshotId, final ContentSummaryComputationContext summary) {\n-    summary.nodeIncluded(this);\n     final ContentCounts counts \u003d summary.getCounts();\n     counts.addContent(Content.FILE, 1);\n     final long fileLen \u003d computeFileSize(snapshotId);\n     counts.addContent(Content.LENGTH, fileLen);\n     counts.addContent(Content.DISKSPACE, storagespaceConsumed(null)\n         .getStorageSpace());\n \n     if (getStoragePolicyID() !\u003d BLOCK_STORAGE_POLICY_ID_UNSPECIFIED){\n       BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n           getPolicy(getStoragePolicyID());\n       List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n       for (StorageType t : storageTypes) {\n         if (!t.supportTypeQuota()) {\n           continue;\n         }\n         counts.addTypeSpace(t, fileLen);\n       }\n     }\n     return summary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final ContentSummaryComputationContext computeContentSummary(\n      int snapshotId, final ContentSummaryComputationContext summary) {\n    final ContentCounts counts \u003d summary.getCounts();\n    counts.addContent(Content.FILE, 1);\n    final long fileLen \u003d computeFileSize(snapshotId);\n    counts.addContent(Content.LENGTH, fileLen);\n    counts.addContent(Content.DISKSPACE, storagespaceConsumed(null)\n        .getStorageSpace());\n\n    if (getStoragePolicyID() !\u003d BLOCK_STORAGE_POLICY_ID_UNSPECIFIED){\n      BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n          getPolicy(getStoragePolicyID());\n      List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n      for (StorageType t : storageTypes) {\n        if (!t.supportTypeQuota()) {\n          continue;\n        }\n        counts.addTypeSpace(t, fileLen);\n      }\n    }\n    return summary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "6a38d118d86b7907009bcec34f1b788d076f1d1c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10797. Disk usage summary of snapshots causes renamed blocks to get counted twice. Contributed by Sean Mackrory.\n",
      "commitDate": "07/10/16 5:37 PM",
      "commitName": "6a38d118d86b7907009bcec34f1b788d076f1d1c",
      "commitAuthor": "Xiao Chen",
      "commitDateOld": "19/08/16 10:13 PM",
      "commitNameOld": "0faee62a0c8c1b8fd83227babfd00fbc2b26bddf",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 48.81,
      "commitsBetweenForRepo": 294,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,23 @@\n   public final ContentSummaryComputationContext computeContentSummary(\n       int snapshotId, final ContentSummaryComputationContext summary) {\n+    summary.nodeIncluded(this);\n     final ContentCounts counts \u003d summary.getCounts();\n     counts.addContent(Content.FILE, 1);\n     final long fileLen \u003d computeFileSize(snapshotId);\n     counts.addContent(Content.LENGTH, fileLen);\n     counts.addContent(Content.DISKSPACE, storagespaceConsumed(null)\n         .getStorageSpace());\n \n     if (getStoragePolicyID() !\u003d BLOCK_STORAGE_POLICY_ID_UNSPECIFIED){\n       BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n           getPolicy(getStoragePolicyID());\n       List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n       for (StorageType t : storageTypes) {\n         if (!t.supportTypeQuota()) {\n           continue;\n         }\n         counts.addTypeSpace(t, fileLen);\n       }\n     }\n     return summary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final ContentSummaryComputationContext computeContentSummary(\n      int snapshotId, final ContentSummaryComputationContext summary) {\n    summary.nodeIncluded(this);\n    final ContentCounts counts \u003d summary.getCounts();\n    counts.addContent(Content.FILE, 1);\n    final long fileLen \u003d computeFileSize(snapshotId);\n    counts.addContent(Content.LENGTH, fileLen);\n    counts.addContent(Content.DISKSPACE, storagespaceConsumed(null)\n        .getStorageSpace());\n\n    if (getStoragePolicyID() !\u003d BLOCK_STORAGE_POLICY_ID_UNSPECIFIED){\n      BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n          getPolicy(getStoragePolicyID());\n      List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n      for (StorageType t : storageTypes) {\n        if (!t.supportTypeQuota()) {\n          continue;\n        }\n        counts.addTypeSpace(t, fileLen);\n      }\n    }\n    return summary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "3f4275310203de4ccfb15337f3c503e25408a265": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-9063. Correctly handle snapshot path for getContentSummary. Contributed by Jing Zhao.\n",
      "commitDate": "18/09/15 9:26 AM",
      "commitName": "3f4275310203de4ccfb15337f3c503e25408a265",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9063. Correctly handle snapshot path for getContentSummary. Contributed by Jing Zhao.\n",
          "commitDate": "18/09/15 9:26 AM",
          "commitName": "3f4275310203de4ccfb15337f3c503e25408a265",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "26/08/15 6:14 PM",
          "commitNameOld": "4cbbfa2220e884e91bf18ad1cc2f3b11f895f8c9",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 22.63,
          "commitsBetweenForRepo": 145,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,35 +1,22 @@\n   public final ContentSummaryComputationContext computeContentSummary(\n-      final ContentSummaryComputationContext summary) {\n+      int snapshotId, final ContentSummaryComputationContext summary) {\n     final ContentCounts counts \u003d summary.getCounts();\n-    FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n-    final long fileLen;\n-    if (sf \u003d\u003d null) {\n-      fileLen \u003d computeFileSize();\n-      counts.addContent(Content.FILE, 1);\n-    } else {\n-      final FileDiffList diffs \u003d sf.getDiffs();\n-      final int n \u003d diffs.asList().size();\n-      counts.addContent(Content.FILE, n);\n-      if (n \u003e 0 \u0026\u0026 sf.isCurrentFileDeleted()) {\n-        fileLen \u003d  diffs.getLast().getFileSize();\n-      } else {\n-        fileLen \u003d computeFileSize();\n-      }\n-    }\n+    counts.addContent(Content.FILE, 1);\n+    final long fileLen \u003d computeFileSize(snapshotId);\n     counts.addContent(Content.LENGTH, fileLen);\n     counts.addContent(Content.DISKSPACE, storagespaceConsumed(null)\n         .getStorageSpace());\n \n     if (getStoragePolicyID() !\u003d BLOCK_STORAGE_POLICY_ID_UNSPECIFIED){\n       BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n           getPolicy(getStoragePolicyID());\n       List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n       for (StorageType t : storageTypes) {\n         if (!t.supportTypeQuota()) {\n           continue;\n         }\n         counts.addTypeSpace(t, fileLen);\n       }\n     }\n     return summary;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public final ContentSummaryComputationContext computeContentSummary(\n      int snapshotId, final ContentSummaryComputationContext summary) {\n    final ContentCounts counts \u003d summary.getCounts();\n    counts.addContent(Content.FILE, 1);\n    final long fileLen \u003d computeFileSize(snapshotId);\n    counts.addContent(Content.LENGTH, fileLen);\n    counts.addContent(Content.DISKSPACE, storagespaceConsumed(null)\n        .getStorageSpace());\n\n    if (getStoragePolicyID() !\u003d BLOCK_STORAGE_POLICY_ID_UNSPECIFIED){\n      BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n          getPolicy(getStoragePolicyID());\n      List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n      for (StorageType t : storageTypes) {\n        if (!t.supportTypeQuota()) {\n          continue;\n        }\n        counts.addTypeSpace(t, fileLen);\n      }\n    }\n    return summary;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldValue": "[summary-ContentSummaryComputationContext(modifiers-final)]",
            "newValue": "[snapshotId-int, summary-ContentSummaryComputationContext(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9063. Correctly handle snapshot path for getContentSummary. Contributed by Jing Zhao.\n",
          "commitDate": "18/09/15 9:26 AM",
          "commitName": "3f4275310203de4ccfb15337f3c503e25408a265",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "26/08/15 6:14 PM",
          "commitNameOld": "4cbbfa2220e884e91bf18ad1cc2f3b11f895f8c9",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 22.63,
          "commitsBetweenForRepo": 145,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,35 +1,22 @@\n   public final ContentSummaryComputationContext computeContentSummary(\n-      final ContentSummaryComputationContext summary) {\n+      int snapshotId, final ContentSummaryComputationContext summary) {\n     final ContentCounts counts \u003d summary.getCounts();\n-    FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n-    final long fileLen;\n-    if (sf \u003d\u003d null) {\n-      fileLen \u003d computeFileSize();\n-      counts.addContent(Content.FILE, 1);\n-    } else {\n-      final FileDiffList diffs \u003d sf.getDiffs();\n-      final int n \u003d diffs.asList().size();\n-      counts.addContent(Content.FILE, n);\n-      if (n \u003e 0 \u0026\u0026 sf.isCurrentFileDeleted()) {\n-        fileLen \u003d  diffs.getLast().getFileSize();\n-      } else {\n-        fileLen \u003d computeFileSize();\n-      }\n-    }\n+    counts.addContent(Content.FILE, 1);\n+    final long fileLen \u003d computeFileSize(snapshotId);\n     counts.addContent(Content.LENGTH, fileLen);\n     counts.addContent(Content.DISKSPACE, storagespaceConsumed(null)\n         .getStorageSpace());\n \n     if (getStoragePolicyID() !\u003d BLOCK_STORAGE_POLICY_ID_UNSPECIFIED){\n       BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n           getPolicy(getStoragePolicyID());\n       List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n       for (StorageType t : storageTypes) {\n         if (!t.supportTypeQuota()) {\n           continue;\n         }\n         counts.addTypeSpace(t, fileLen);\n       }\n     }\n     return summary;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public final ContentSummaryComputationContext computeContentSummary(\n      int snapshotId, final ContentSummaryComputationContext summary) {\n    final ContentCounts counts \u003d summary.getCounts();\n    counts.addContent(Content.FILE, 1);\n    final long fileLen \u003d computeFileSize(snapshotId);\n    counts.addContent(Content.LENGTH, fileLen);\n    counts.addContent(Content.DISKSPACE, storagespaceConsumed(null)\n        .getStorageSpace());\n\n    if (getStoragePolicyID() !\u003d BLOCK_STORAGE_POLICY_ID_UNSPECIFIED){\n      BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n          getPolicy(getStoragePolicyID());\n      List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n      for (StorageType t : storageTypes) {\n        if (!t.supportTypeQuota()) {\n          continue;\n        }\n        counts.addTypeSpace(t, fileLen);\n      }\n    }\n    return summary;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {}
        }
      ]
    },
    "b2c85db86c9a62b0a03ee87547265077f664970a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7728. Avoid updating quota usage while loading edits. Contributed by Jing Zhao.\n",
      "commitDate": "13/05/15 9:50 PM",
      "commitName": "b2c85db86c9a62b0a03ee87547265077f664970a",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "12/05/15 6:29 AM",
      "commitNameOld": "6d5da9484185ca9f585195d6da069b9cd5be4044",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 1.64,
      "commitsBetweenForRepo": 24,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,35 @@\n   public final ContentSummaryComputationContext computeContentSummary(\n       final ContentSummaryComputationContext summary) {\n     final ContentCounts counts \u003d summary.getCounts();\n     FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n-    long fileLen \u003d 0;\n+    final long fileLen;\n     if (sf \u003d\u003d null) {\n       fileLen \u003d computeFileSize();\n       counts.addContent(Content.FILE, 1);\n     } else {\n       final FileDiffList diffs \u003d sf.getDiffs();\n       final int n \u003d diffs.asList().size();\n       counts.addContent(Content.FILE, n);\n       if (n \u003e 0 \u0026\u0026 sf.isCurrentFileDeleted()) {\n         fileLen \u003d  diffs.getLast().getFileSize();\n       } else {\n         fileLen \u003d computeFileSize();\n       }\n     }\n     counts.addContent(Content.LENGTH, fileLen);\n     counts.addContent(Content.DISKSPACE, storagespaceConsumed(null)\n         .getStorageSpace());\n \n     if (getStoragePolicyID() !\u003d BLOCK_STORAGE_POLICY_ID_UNSPECIFIED){\n       BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n           getPolicy(getStoragePolicyID());\n       List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n       for (StorageType t : storageTypes) {\n         if (!t.supportTypeQuota()) {\n           continue;\n         }\n         counts.addTypeSpace(t, fileLen);\n       }\n     }\n     return summary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final ContentSummaryComputationContext computeContentSummary(\n      final ContentSummaryComputationContext summary) {\n    final ContentCounts counts \u003d summary.getCounts();\n    FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n    final long fileLen;\n    if (sf \u003d\u003d null) {\n      fileLen \u003d computeFileSize();\n      counts.addContent(Content.FILE, 1);\n    } else {\n      final FileDiffList diffs \u003d sf.getDiffs();\n      final int n \u003d diffs.asList().size();\n      counts.addContent(Content.FILE, n);\n      if (n \u003e 0 \u0026\u0026 sf.isCurrentFileDeleted()) {\n        fileLen \u003d  diffs.getLast().getFileSize();\n      } else {\n        fileLen \u003d computeFileSize();\n      }\n    }\n    counts.addContent(Content.LENGTH, fileLen);\n    counts.addContent(Content.DISKSPACE, storagespaceConsumed(null)\n        .getStorageSpace());\n\n    if (getStoragePolicyID() !\u003d BLOCK_STORAGE_POLICY_ID_UNSPECIFIED){\n      BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n          getPolicy(getStoragePolicyID());\n      List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n      for (StorageType t : storageTypes) {\n        if (!t.supportTypeQuota()) {\n          continue;\n        }\n        counts.addTypeSpace(t, fileLen);\n      }\n    }\n    return summary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "02a4a22b9c0e22c2e7dd6ec85edd5c5a167fe19f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8327. Compute storage type quotas in INodeFile.computeQuotaDeltaForTruncate(). Contributed by Haohui Mai.\n",
      "commitDate": "08/05/15 11:09 PM",
      "commitName": "02a4a22b9c0e22c2e7dd6ec85edd5c5a167fe19f",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "08/05/15 11:04 PM",
      "commitNameOld": "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,35 @@\n   public final ContentSummaryComputationContext computeContentSummary(\n       final ContentSummaryComputationContext summary) {\n     final ContentCounts counts \u003d summary.getCounts();\n     FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n     long fileLen \u003d 0;\n     if (sf \u003d\u003d null) {\n       fileLen \u003d computeFileSize();\n       counts.addContent(Content.FILE, 1);\n     } else {\n       final FileDiffList diffs \u003d sf.getDiffs();\n       final int n \u003d diffs.asList().size();\n       counts.addContent(Content.FILE, n);\n       if (n \u003e 0 \u0026\u0026 sf.isCurrentFileDeleted()) {\n         fileLen \u003d  diffs.getLast().getFileSize();\n       } else {\n         fileLen \u003d computeFileSize();\n       }\n     }\n     counts.addContent(Content.LENGTH, fileLen);\n-    counts.addContent(Content.DISKSPACE, storagespaceConsumed());\n+    counts.addContent(Content.DISKSPACE, storagespaceConsumed(null)\n+        .getStorageSpace());\n \n     if (getStoragePolicyID() !\u003d BLOCK_STORAGE_POLICY_ID_UNSPECIFIED){\n       BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n           getPolicy(getStoragePolicyID());\n       List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n       for (StorageType t : storageTypes) {\n         if (!t.supportTypeQuota()) {\n           continue;\n         }\n         counts.addTypeSpace(t, fileLen);\n       }\n     }\n     return summary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final ContentSummaryComputationContext computeContentSummary(\n      final ContentSummaryComputationContext summary) {\n    final ContentCounts counts \u003d summary.getCounts();\n    FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n    long fileLen \u003d 0;\n    if (sf \u003d\u003d null) {\n      fileLen \u003d computeFileSize();\n      counts.addContent(Content.FILE, 1);\n    } else {\n      final FileDiffList diffs \u003d sf.getDiffs();\n      final int n \u003d diffs.asList().size();\n      counts.addContent(Content.FILE, n);\n      if (n \u003e 0 \u0026\u0026 sf.isCurrentFileDeleted()) {\n        fileLen \u003d  diffs.getLast().getFileSize();\n      } else {\n        fileLen \u003d computeFileSize();\n      }\n    }\n    counts.addContent(Content.LENGTH, fileLen);\n    counts.addContent(Content.DISKSPACE, storagespaceConsumed(null)\n        .getStorageSpace());\n\n    if (getStoragePolicyID() !\u003d BLOCK_STORAGE_POLICY_ID_UNSPECIFIED){\n      BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n          getPolicy(getStoragePolicyID());\n      List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n      for (StorageType t : storageTypes) {\n        if (!t.supportTypeQuota()) {\n          continue;\n        }\n        counts.addTypeSpace(t, fileLen);\n      }\n    }\n    return summary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "5c97db07fb306842f49d73a67a90cecec19a7833": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8169. Move LocatedBlocks and related classes to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "20/04/15 12:36 AM",
      "commitName": "5c97db07fb306842f49d73a67a90cecec19a7833",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "02/04/15 9:20 PM",
      "commitNameOld": "72f6bd4893dcf10d6dad24753f9be99505a87a1f",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 17.14,
      "commitsBetweenForRepo": 120,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n   public final ContentSummaryComputationContext computeContentSummary(\n       final ContentSummaryComputationContext summary) {\n     final ContentCounts counts \u003d summary.getCounts();\n     FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n     long fileLen \u003d 0;\n     if (sf \u003d\u003d null) {\n       fileLen \u003d computeFileSize();\n       counts.addContent(Content.FILE, 1);\n     } else {\n       final FileDiffList diffs \u003d sf.getDiffs();\n       final int n \u003d diffs.asList().size();\n       counts.addContent(Content.FILE, n);\n       if (n \u003e 0 \u0026\u0026 sf.isCurrentFileDeleted()) {\n         fileLen \u003d  diffs.getLast().getFileSize();\n       } else {\n         fileLen \u003d computeFileSize();\n       }\n     }\n     counts.addContent(Content.LENGTH, fileLen);\n     counts.addContent(Content.DISKSPACE, storagespaceConsumed());\n \n-    if (getStoragePolicyID() !\u003d ID_UNSPECIFIED){\n+    if (getStoragePolicyID() !\u003d BLOCK_STORAGE_POLICY_ID_UNSPECIFIED){\n       BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n           getPolicy(getStoragePolicyID());\n       List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n       for (StorageType t : storageTypes) {\n         if (!t.supportTypeQuota()) {\n           continue;\n         }\n         counts.addTypeSpace(t, fileLen);\n       }\n     }\n     return summary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final ContentSummaryComputationContext computeContentSummary(\n      final ContentSummaryComputationContext summary) {\n    final ContentCounts counts \u003d summary.getCounts();\n    FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n    long fileLen \u003d 0;\n    if (sf \u003d\u003d null) {\n      fileLen \u003d computeFileSize();\n      counts.addContent(Content.FILE, 1);\n    } else {\n      final FileDiffList diffs \u003d sf.getDiffs();\n      final int n \u003d diffs.asList().size();\n      counts.addContent(Content.FILE, n);\n      if (n \u003e 0 \u0026\u0026 sf.isCurrentFileDeleted()) {\n        fileLen \u003d  diffs.getLast().getFileSize();\n      } else {\n        fileLen \u003d computeFileSize();\n      }\n    }\n    counts.addContent(Content.LENGTH, fileLen);\n    counts.addContent(Content.DISKSPACE, storagespaceConsumed());\n\n    if (getStoragePolicyID() !\u003d BLOCK_STORAGE_POLICY_ID_UNSPECIFIED){\n      BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n          getPolicy(getStoragePolicyID());\n      List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n      for (StorageType t : storageTypes) {\n        if (!t.supportTypeQuota()) {\n          continue;\n        }\n        counts.addTypeSpace(t, fileLen);\n      }\n    }\n    return summary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "72f6bd4893dcf10d6dad24753f9be99505a87a1f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7811. Avoid recursive call getStoragePolicyID in INodeFile#computeQuotaUsage. Contributed by Xiaoyu Yao and Jing Zhao.\n",
      "commitDate": "02/04/15 9:20 PM",
      "commitName": "72f6bd4893dcf10d6dad24753f9be99505a87a1f",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "26/03/15 10:24 AM",
      "commitNameOld": "3d0708bdb0a75af3d87bbac9f6c4ffbcabab98ca",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 7.46,
      "commitsBetweenForRepo": 70,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n   public final ContentSummaryComputationContext computeContentSummary(\n       final ContentSummaryComputationContext summary) {\n     final ContentCounts counts \u003d summary.getCounts();\n     FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n     long fileLen \u003d 0;\n     if (sf \u003d\u003d null) {\n       fileLen \u003d computeFileSize();\n       counts.addContent(Content.FILE, 1);\n     } else {\n       final FileDiffList diffs \u003d sf.getDiffs();\n       final int n \u003d diffs.asList().size();\n       counts.addContent(Content.FILE, n);\n       if (n \u003e 0 \u0026\u0026 sf.isCurrentFileDeleted()) {\n         fileLen \u003d  diffs.getLast().getFileSize();\n       } else {\n         fileLen \u003d computeFileSize();\n       }\n     }\n     counts.addContent(Content.LENGTH, fileLen);\n     counts.addContent(Content.DISKSPACE, storagespaceConsumed());\n \n-    if (getStoragePolicyID() !\u003d BlockStoragePolicySuite.ID_UNSPECIFIED){\n+    if (getStoragePolicyID() !\u003d ID_UNSPECIFIED){\n       BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n           getPolicy(getStoragePolicyID());\n       List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n       for (StorageType t : storageTypes) {\n         if (!t.supportTypeQuota()) {\n           continue;\n         }\n         counts.addTypeSpace(t, fileLen);\n       }\n     }\n     return summary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final ContentSummaryComputationContext computeContentSummary(\n      final ContentSummaryComputationContext summary) {\n    final ContentCounts counts \u003d summary.getCounts();\n    FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n    long fileLen \u003d 0;\n    if (sf \u003d\u003d null) {\n      fileLen \u003d computeFileSize();\n      counts.addContent(Content.FILE, 1);\n    } else {\n      final FileDiffList diffs \u003d sf.getDiffs();\n      final int n \u003d diffs.asList().size();\n      counts.addContent(Content.FILE, n);\n      if (n \u003e 0 \u0026\u0026 sf.isCurrentFileDeleted()) {\n        fileLen \u003d  diffs.getLast().getFileSize();\n      } else {\n        fileLen \u003d computeFileSize();\n      }\n    }\n    counts.addContent(Content.LENGTH, fileLen);\n    counts.addContent(Content.DISKSPACE, storagespaceConsumed());\n\n    if (getStoragePolicyID() !\u003d ID_UNSPECIFIED){\n      BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n          getPolicy(getStoragePolicyID());\n      List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n      for (StorageType t : storageTypes) {\n        if (!t.supportTypeQuota()) {\n          continue;\n        }\n        counts.addTypeSpace(t, fileLen);\n      }\n    }\n    return summary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "3d0708bdb0a75af3d87bbac9f6c4ffbcabab98ca": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7824. GetContentSummary API and its namenode implementation for Storage Type Quota/Usage. (Contributed by Xiaoyu Yao)\n",
      "commitDate": "26/03/15 10:24 AM",
      "commitName": "3d0708bdb0a75af3d87bbac9f6c4ffbcabab98ca",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "20/03/15 11:50 AM",
      "commitNameOld": "d368d3647a858644b9fcd3be33d9fea2a6962f69",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 5.94,
      "commitsBetweenForRepo": 58,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,34 @@\n   public final ContentSummaryComputationContext computeContentSummary(\n       final ContentSummaryComputationContext summary) {\n-    final Content.Counts counts \u003d summary.getCounts();\n+    final ContentCounts counts \u003d summary.getCounts();\n     FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n+    long fileLen \u003d 0;\n     if (sf \u003d\u003d null) {\n-      counts.add(Content.LENGTH, computeFileSize());\n-      counts.add(Content.FILE, 1);\n+      fileLen \u003d computeFileSize();\n+      counts.addContent(Content.FILE, 1);\n     } else {\n       final FileDiffList diffs \u003d sf.getDiffs();\n       final int n \u003d diffs.asList().size();\n-      counts.add(Content.FILE, n);\n+      counts.addContent(Content.FILE, n);\n       if (n \u003e 0 \u0026\u0026 sf.isCurrentFileDeleted()) {\n-        counts.add(Content.LENGTH, diffs.getLast().getFileSize());\n+        fileLen \u003d  diffs.getLast().getFileSize();\n       } else {\n-        counts.add(Content.LENGTH, computeFileSize());\n+        fileLen \u003d computeFileSize();\n       }\n     }\n-    counts.add(Content.DISKSPACE, storagespaceConsumed());\n+    counts.addContent(Content.LENGTH, fileLen);\n+    counts.addContent(Content.DISKSPACE, storagespaceConsumed());\n+\n+    if (getStoragePolicyID() !\u003d BlockStoragePolicySuite.ID_UNSPECIFIED){\n+      BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n+          getPolicy(getStoragePolicyID());\n+      List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n+      for (StorageType t : storageTypes) {\n+        if (!t.supportTypeQuota()) {\n+          continue;\n+        }\n+        counts.addTypeSpace(t, fileLen);\n+      }\n+    }\n     return summary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final ContentSummaryComputationContext computeContentSummary(\n      final ContentSummaryComputationContext summary) {\n    final ContentCounts counts \u003d summary.getCounts();\n    FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n    long fileLen \u003d 0;\n    if (sf \u003d\u003d null) {\n      fileLen \u003d computeFileSize();\n      counts.addContent(Content.FILE, 1);\n    } else {\n      final FileDiffList diffs \u003d sf.getDiffs();\n      final int n \u003d diffs.asList().size();\n      counts.addContent(Content.FILE, n);\n      if (n \u003e 0 \u0026\u0026 sf.isCurrentFileDeleted()) {\n        fileLen \u003d  diffs.getLast().getFileSize();\n      } else {\n        fileLen \u003d computeFileSize();\n      }\n    }\n    counts.addContent(Content.LENGTH, fileLen);\n    counts.addContent(Content.DISKSPACE, storagespaceConsumed());\n\n    if (getStoragePolicyID() !\u003d BlockStoragePolicySuite.ID_UNSPECIFIED){\n      BlockStoragePolicy bsp \u003d summary.getBlockStoragePolicySuite().\n          getPolicy(getStoragePolicyID());\n      List\u003cStorageType\u003e storageTypes \u003d bsp.chooseStorageTypes(getFileReplication());\n      for (StorageType t : storageTypes) {\n        if (!t.supportTypeQuota()) {\n          continue;\n        }\n        counts.addTypeSpace(t, fileLen);\n      }\n    }\n    return summary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "f2231cebcddc80f0b753c4a7cb45ee4040846951": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7775. Use consistent naming for NN-internal quota related types and functions. (Contributed bu Xiaoyu Yao)\n",
      "commitDate": "13/02/15 9:01 PM",
      "commitName": "f2231cebcddc80f0b753c4a7cb45ee4040846951",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "11/02/15 10:41 AM",
      "commitNameOld": "5dae97a584d30cef3e34141edfaca49c4ec57913",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 2.43,
      "commitsBetweenForRepo": 58,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n   public final ContentSummaryComputationContext computeContentSummary(\n       final ContentSummaryComputationContext summary) {\n     final Content.Counts counts \u003d summary.getCounts();\n     FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n     if (sf \u003d\u003d null) {\n       counts.add(Content.LENGTH, computeFileSize());\n       counts.add(Content.FILE, 1);\n     } else {\n       final FileDiffList diffs \u003d sf.getDiffs();\n       final int n \u003d diffs.asList().size();\n       counts.add(Content.FILE, n);\n       if (n \u003e 0 \u0026\u0026 sf.isCurrentFileDeleted()) {\n         counts.add(Content.LENGTH, diffs.getLast().getFileSize());\n       } else {\n         counts.add(Content.LENGTH, computeFileSize());\n       }\n     }\n-    counts.add(Content.DISKSPACE, diskspaceConsumed());\n+    counts.add(Content.DISKSPACE, storagespaceConsumed());\n     return summary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final ContentSummaryComputationContext computeContentSummary(\n      final ContentSummaryComputationContext summary) {\n    final Content.Counts counts \u003d summary.getCounts();\n    FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n    if (sf \u003d\u003d null) {\n      counts.add(Content.LENGTH, computeFileSize());\n      counts.add(Content.FILE, 1);\n    } else {\n      final FileDiffList diffs \u003d sf.getDiffs();\n      final int n \u003d diffs.asList().size();\n      counts.add(Content.FILE, n);\n      if (n \u003e 0 \u0026\u0026 sf.isCurrentFileDeleted()) {\n        counts.add(Content.LENGTH, diffs.getLast().getFileSize());\n      } else {\n        counts.add(Content.LENGTH, computeFileSize());\n      }\n    }\n    counts.add(Content.DISKSPACE, storagespaceConsumed());\n    return summary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "08ac06283a3e9bf0d49d873823aabd419b08e41f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7056. Snapshot support for truncate. Contributed by Konstantin Shvachko and Plamen Jeliazkov.",
      "commitDate": "13/01/15 12:24 AM",
      "commitName": "08ac06283a3e9bf0d49d873823aabd419b08e41f",
      "commitAuthor": "Konstantin V Shvachko",
      "commitDateOld": "12/01/15 10:50 PM",
      "commitNameOld": "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
      "commitAuthorOld": "Plamen Jeliazkov",
      "daysBetweenCommits": 0.07,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,20 @@\n   public final ContentSummaryComputationContext computeContentSummary(\n       final ContentSummaryComputationContext summary) {\n-    computeContentSummary4Snapshot(summary.getCounts());\n-    computeContentSummary4Current(summary.getCounts());\n+    final Content.Counts counts \u003d summary.getCounts();\n+    FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n+    if (sf \u003d\u003d null) {\n+      counts.add(Content.LENGTH, computeFileSize());\n+      counts.add(Content.FILE, 1);\n+    } else {\n+      final FileDiffList diffs \u003d sf.getDiffs();\n+      final int n \u003d diffs.asList().size();\n+      counts.add(Content.FILE, n);\n+      if (n \u003e 0 \u0026\u0026 sf.isCurrentFileDeleted()) {\n+        counts.add(Content.LENGTH, diffs.getLast().getFileSize());\n+      } else {\n+        counts.add(Content.LENGTH, computeFileSize());\n+      }\n+    }\n+    counts.add(Content.DISKSPACE, diskspaceConsumed());\n     return summary;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public final ContentSummaryComputationContext computeContentSummary(\n      final ContentSummaryComputationContext summary) {\n    final Content.Counts counts \u003d summary.getCounts();\n    FileWithSnapshotFeature sf \u003d getFileWithSnapshotFeature();\n    if (sf \u003d\u003d null) {\n      counts.add(Content.LENGTH, computeFileSize());\n      counts.add(Content.FILE, 1);\n    } else {\n      final FileDiffList diffs \u003d sf.getDiffs();\n      final int n \u003d diffs.asList().size();\n      counts.add(Content.FILE, n);\n      if (n \u003e 0 \u0026\u0026 sf.isCurrentFileDeleted()) {\n        counts.add(Content.LENGTH, diffs.getLast().getFileSize());\n      } else {\n        counts.add(Content.LENGTH, computeFileSize());\n      }\n    }\n    counts.add(Content.DISKSPACE, diskspaceConsumed());\n    return summary;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
      "extendedDetails": {}
    },
    "fe67e30bc2794e7ff073cf938ee80eba805d1e69": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-4995. Make getContentSummary less expensive. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541971 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/11/13 8:49 AM",
      "commitName": "fe67e30bc2794e7ff073cf938ee80eba805d1e69",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4995. Make getContentSummary less expensive. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541971 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/11/13 8:49 AM",
          "commitName": "fe67e30bc2794e7ff073cf938ee80eba805d1e69",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "19/06/13 10:10 PM",
          "commitNameOld": "c02953dbc344b39e0eb0d13fe2d899cdcdc46380",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 147.49,
          "commitsBetweenForRepo": 878,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,6 @@\n-  public final Content.Counts computeContentSummary(\n-      final Content.Counts counts) {\n-    computeContentSummary4Snapshot(counts);\n-    computeContentSummary4Current(counts);\n-    return counts;\n+  public final ContentSummaryComputationContext  computeContentSummary(\n+      final ContentSummaryComputationContext summary) {\n+    computeContentSummary4Snapshot(summary.getCounts());\n+    computeContentSummary4Current(summary.getCounts());\n+    return summary;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public final ContentSummaryComputationContext  computeContentSummary(\n      final ContentSummaryComputationContext summary) {\n    computeContentSummary4Snapshot(summary.getCounts());\n    computeContentSummary4Current(summary.getCounts());\n    return summary;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldValue": "[counts-Content.Counts(modifiers-final)]",
            "newValue": "[summary-ContentSummaryComputationContext(modifiers-final)]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-4995. Make getContentSummary less expensive. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541971 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/11/13 8:49 AM",
          "commitName": "fe67e30bc2794e7ff073cf938ee80eba805d1e69",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "19/06/13 10:10 PM",
          "commitNameOld": "c02953dbc344b39e0eb0d13fe2d899cdcdc46380",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 147.49,
          "commitsBetweenForRepo": 878,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,6 @@\n-  public final Content.Counts computeContentSummary(\n-      final Content.Counts counts) {\n-    computeContentSummary4Snapshot(counts);\n-    computeContentSummary4Current(counts);\n-    return counts;\n+  public final ContentSummaryComputationContext  computeContentSummary(\n+      final ContentSummaryComputationContext summary) {\n+    computeContentSummary4Snapshot(summary.getCounts());\n+    computeContentSummary4Current(summary.getCounts());\n+    return summary;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public final ContentSummaryComputationContext  computeContentSummary(\n      final ContentSummaryComputationContext summary) {\n    computeContentSummary4Snapshot(summary.getCounts());\n    computeContentSummary4Current(summary.getCounts());\n    return summary;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {
            "oldValue": "Content.Counts",
            "newValue": "ContentSummaryComputationContext"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4995. Make getContentSummary less expensive. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1541971 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "14/11/13 8:49 AM",
          "commitName": "fe67e30bc2794e7ff073cf938ee80eba805d1e69",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "19/06/13 10:10 PM",
          "commitNameOld": "c02953dbc344b39e0eb0d13fe2d899cdcdc46380",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 147.49,
          "commitsBetweenForRepo": 878,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,6 @@\n-  public final Content.Counts computeContentSummary(\n-      final Content.Counts counts) {\n-    computeContentSummary4Snapshot(counts);\n-    computeContentSummary4Current(counts);\n-    return counts;\n+  public final ContentSummaryComputationContext  computeContentSummary(\n+      final ContentSummaryComputationContext summary) {\n+    computeContentSummary4Snapshot(summary.getCounts());\n+    computeContentSummary4Current(summary.getCounts());\n+    return summary;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public final ContentSummaryComputationContext  computeContentSummary(\n      final ContentSummaryComputationContext summary) {\n    computeContentSummary4Snapshot(summary.getCounts());\n    computeContentSummary4Current(summary.getCounts());\n    return summary;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodeFile.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}