{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AliyunOSSInputStream.java",
  "functionName": "reopen",
  "functionId": "reopen___pos-long",
  "sourceFilePath": "hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSInputStream.java",
  "functionStartLine": 87,
  "functionEndLine": 180,
  "numCommitsSeen": 8,
  "timeTaken": 1077,
  "changeHistory": [
    "9195a6e302028ed3921d1016ac2fa5754f06ebf0",
    "d33e928fbeb1764a724c8f3c051bb0d8be82bbff",
    "a5d5342228050a778b20e95adf7885bdba39985d"
  ],
  "changeHistoryShort": {
    "9195a6e302028ed3921d1016ac2fa5754f06ebf0": "Ybodychange",
    "d33e928fbeb1764a724c8f3c051bb0d8be82bbff": "Ybodychange",
    "a5d5342228050a778b20e95adf7885bdba39985d": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9195a6e302028ed3921d1016ac2fa5754f06ebf0": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15027. AliyunOSS: Support multi-thread pre-read to improve sequential read from Hadoop to Aliyun OSS performance. (Contributed by Jinhu Wu)\n",
      "commitDate": "16/01/18 11:55 PM",
      "commitName": "9195a6e302028ed3921d1016ac2fa5754f06ebf0",
      "commitAuthor": "Sammi Chen",
      "commitDateOld": "15/02/17 12:34 AM",
      "commitNameOld": "cd3e59a3dcc69f68711777d448da5228a55846b3",
      "commitAuthorOld": "Kai Zheng",
      "daysBetweenCommits": 335.97,
      "commitsBetweenForRepo": 2216,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,94 @@\n   private synchronized void reopen(long pos) throws IOException {\n     long partSize;\n \n     if (pos \u003c 0) {\n       throw new EOFException(\"Cannot seek at negative position:\" + pos);\n     } else if (pos \u003e contentLength) {\n       throw new EOFException(\"Cannot seek after EOF, contentLength:\" +\n           contentLength + \" position:\" + pos);\n     } else if (pos + downloadPartSize \u003e contentLength) {\n       partSize \u003d contentLength - pos;\n     } else {\n       partSize \u003d downloadPartSize;\n     }\n \n-    if (wrappedStream !\u003d null) {\n+    if (this.buffer !\u003d null) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Aborting old stream to open at pos \" + pos);\n       }\n-      wrappedStream.close();\n+      this.buffer \u003d null;\n     }\n \n-    wrappedStream \u003d store.retrieve(key, pos, pos + partSize -1);\n-    if (wrappedStream \u003d\u003d null) {\n+    boolean isRandomIO \u003d true;\n+    if (pos \u003d\u003d this.expectNextPos) {\n+      isRandomIO \u003d false;\n+    } else {\n+      //new seek, remove cache buffers if its byteStart is not equal to pos\n+      while (readBufferQueue.size() !\u003d 0) {\n+        if (readBufferQueue.element().getByteStart() !\u003d pos) {\n+          readBufferQueue.poll();\n+        } else {\n+          break;\n+        }\n+      }\n+    }\n+\n+    this.expectNextPos \u003d pos + partSize;\n+\n+    int currentSize \u003d readBufferQueue.size();\n+    if (currentSize \u003d\u003d 0) {\n+      //init lastByteStart to pos - partSize, used by for loop below\n+      lastByteStart \u003d pos - partSize;\n+    } else {\n+      ReadBuffer[] readBuffers \u003d readBufferQueue.toArray(\n+          new ReadBuffer[currentSize]);\n+      lastByteStart \u003d readBuffers[currentSize - 1].getByteStart();\n+    }\n+\n+    int maxLen \u003d this.maxReadAheadPartNumber - currentSize;\n+    for (int i \u003d 0; i \u003c maxLen \u0026\u0026 i \u003c (currentSize + 1) * 2; i++) {\n+      if (lastByteStart + partSize * (i + 1) \u003e contentLength) {\n+        break;\n+      }\n+\n+      long byteStart \u003d lastByteStart + partSize * (i + 1);\n+      long byteEnd \u003d byteStart + partSize -1;\n+      if (byteEnd \u003e\u003d contentLength) {\n+        byteEnd \u003d contentLength - 1;\n+      }\n+\n+      ReadBuffer readBuffer \u003d new ReadBuffer(byteStart, byteEnd);\n+      if (readBuffer.getBuffer().length \u003d\u003d 0) {\n+        //EOF\n+        readBuffer.setStatus(ReadBuffer.STATUS.SUCCESS);\n+      } else {\n+        this.readAheadExecutorService.execute(\n+            new AliyunOSSFileReaderTask(key, store, readBuffer));\n+      }\n+      readBufferQueue.add(readBuffer);\n+      if (isRandomIO) {\n+        break;\n+      }\n+    }\n+\n+    ReadBuffer readBuffer \u003d readBufferQueue.poll();\n+    readBuffer.lock();\n+    try {\n+      readBuffer.await(ReadBuffer.STATUS.INIT);\n+      if (readBuffer.getStatus() \u003d\u003d ReadBuffer.STATUS.ERROR) {\n+        this.buffer \u003d null;\n+      } else {\n+        this.buffer \u003d readBuffer.getBuffer();\n+      }\n+    } catch (InterruptedException e) {\n+      LOG.warn(\"interrupted when wait a read buffer\");\n+    } finally {\n+      readBuffer.unlock();\n+    }\n+\n+    if (this.buffer \u003d\u003d null) {\n       throw new IOException(\"Null IO stream\");\n     }\n     position \u003d pos;\n     partRemaining \u003d partSize;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void reopen(long pos) throws IOException {\n    long partSize;\n\n    if (pos \u003c 0) {\n      throw new EOFException(\"Cannot seek at negative position:\" + pos);\n    } else if (pos \u003e contentLength) {\n      throw new EOFException(\"Cannot seek after EOF, contentLength:\" +\n          contentLength + \" position:\" + pos);\n    } else if (pos + downloadPartSize \u003e contentLength) {\n      partSize \u003d contentLength - pos;\n    } else {\n      partSize \u003d downloadPartSize;\n    }\n\n    if (this.buffer !\u003d null) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Aborting old stream to open at pos \" + pos);\n      }\n      this.buffer \u003d null;\n    }\n\n    boolean isRandomIO \u003d true;\n    if (pos \u003d\u003d this.expectNextPos) {\n      isRandomIO \u003d false;\n    } else {\n      //new seek, remove cache buffers if its byteStart is not equal to pos\n      while (readBufferQueue.size() !\u003d 0) {\n        if (readBufferQueue.element().getByteStart() !\u003d pos) {\n          readBufferQueue.poll();\n        } else {\n          break;\n        }\n      }\n    }\n\n    this.expectNextPos \u003d pos + partSize;\n\n    int currentSize \u003d readBufferQueue.size();\n    if (currentSize \u003d\u003d 0) {\n      //init lastByteStart to pos - partSize, used by for loop below\n      lastByteStart \u003d pos - partSize;\n    } else {\n      ReadBuffer[] readBuffers \u003d readBufferQueue.toArray(\n          new ReadBuffer[currentSize]);\n      lastByteStart \u003d readBuffers[currentSize - 1].getByteStart();\n    }\n\n    int maxLen \u003d this.maxReadAheadPartNumber - currentSize;\n    for (int i \u003d 0; i \u003c maxLen \u0026\u0026 i \u003c (currentSize + 1) * 2; i++) {\n      if (lastByteStart + partSize * (i + 1) \u003e contentLength) {\n        break;\n      }\n\n      long byteStart \u003d lastByteStart + partSize * (i + 1);\n      long byteEnd \u003d byteStart + partSize -1;\n      if (byteEnd \u003e\u003d contentLength) {\n        byteEnd \u003d contentLength - 1;\n      }\n\n      ReadBuffer readBuffer \u003d new ReadBuffer(byteStart, byteEnd);\n      if (readBuffer.getBuffer().length \u003d\u003d 0) {\n        //EOF\n        readBuffer.setStatus(ReadBuffer.STATUS.SUCCESS);\n      } else {\n        this.readAheadExecutorService.execute(\n            new AliyunOSSFileReaderTask(key, store, readBuffer));\n      }\n      readBufferQueue.add(readBuffer);\n      if (isRandomIO) {\n        break;\n      }\n    }\n\n    ReadBuffer readBuffer \u003d readBufferQueue.poll();\n    readBuffer.lock();\n    try {\n      readBuffer.await(ReadBuffer.STATUS.INIT);\n      if (readBuffer.getStatus() \u003d\u003d ReadBuffer.STATUS.ERROR) {\n        this.buffer \u003d null;\n      } else {\n        this.buffer \u003d readBuffer.getBuffer();\n      }\n    } catch (InterruptedException e) {\n      LOG.warn(\"interrupted when wait a read buffer\");\n    } finally {\n      readBuffer.unlock();\n    }\n\n    if (this.buffer \u003d\u003d null) {\n      throw new IOException(\"Null IO stream\");\n    }\n    position \u003d pos;\n    partRemaining \u003d partSize;\n  }",
      "path": "hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSInputStream.java",
      "extendedDetails": {}
    },
    "d33e928fbeb1764a724c8f3c051bb0d8be82bbff": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13529. Do some code refactoring. Contributed by Genmao Yu.\n",
      "commitDate": "06/09/16 8:15 PM",
      "commitName": "d33e928fbeb1764a724c8f3c051bb0d8be82bbff",
      "commitAuthor": "Mingfei",
      "commitDateOld": "06/09/16 8:15 PM",
      "commitNameOld": "4d84c814fcaf074022593c057d8f8dec4cd461fa",
      "commitAuthorOld": "Mingfei",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,28 @@\n   private synchronized void reopen(long pos) throws IOException {\n-\n-    long partLen;\n+    long partSize;\n \n     if (pos \u003c 0) {\n-      throw new EOFException(\"Cannot seek at negtive position:\" + pos);\n-    } else if (pos \u003e dataLen) {\n-      throw new EOFException(\"Cannot seek after EOF, fileLen:\" + dataLen +\n-          \" position:\" + pos);\n-    } else if (pos + downloadPartSize \u003e dataLen) {\n-      partLen \u003d dataLen - pos;\n+      throw new EOFException(\"Cannot seek at negative position:\" + pos);\n+    } else if (pos \u003e contentLength) {\n+      throw new EOFException(\"Cannot seek after EOF, contentLength:\" +\n+          contentLength + \" position:\" + pos);\n+    } else if (pos + downloadPartSize \u003e contentLength) {\n+      partSize \u003d contentLength - pos;\n     } else {\n-      partLen \u003d downloadPartSize;\n+      partSize \u003d downloadPartSize;\n     }\n \n     if (wrappedStream !\u003d null) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Aborting old stream to open at pos \" + pos);\n       }\n       wrappedStream.close();\n     }\n \n-    GetObjectRequest request \u003d new GetObjectRequest(bucketName, key);\n-    request.setRange(pos, pos + partLen - 1);\n-    wrappedStream \u003d ossClient.getObject(request).getObjectContent();\n+    wrappedStream \u003d store.retrieve(key, pos, pos + partSize -1);\n     if (wrappedStream \u003d\u003d null) {\n       throw new IOException(\"Null IO stream\");\n     }\n     position \u003d pos;\n-    partRemaining \u003d partLen;\n+    partRemaining \u003d partSize;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void reopen(long pos) throws IOException {\n    long partSize;\n\n    if (pos \u003c 0) {\n      throw new EOFException(\"Cannot seek at negative position:\" + pos);\n    } else if (pos \u003e contentLength) {\n      throw new EOFException(\"Cannot seek after EOF, contentLength:\" +\n          contentLength + \" position:\" + pos);\n    } else if (pos + downloadPartSize \u003e contentLength) {\n      partSize \u003d contentLength - pos;\n    } else {\n      partSize \u003d downloadPartSize;\n    }\n\n    if (wrappedStream !\u003d null) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Aborting old stream to open at pos \" + pos);\n      }\n      wrappedStream.close();\n    }\n\n    wrappedStream \u003d store.retrieve(key, pos, pos + partSize -1);\n    if (wrappedStream \u003d\u003d null) {\n      throw new IOException(\"Null IO stream\");\n    }\n    position \u003d pos;\n    partRemaining \u003d partSize;\n  }",
      "path": "hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSInputStream.java",
      "extendedDetails": {}
    },
    "a5d5342228050a778b20e95adf7885bdba39985d": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-12756. Incorporate Aliyun OSS file system implementation. Contributed by Mingfei Shi and Lin Zhou\n",
      "commitDate": "06/09/16 8:15 PM",
      "commitName": "a5d5342228050a778b20e95adf7885bdba39985d",
      "commitAuthor": "Kai Zheng",
      "diff": "@@ -0,0 +1,31 @@\n+  private synchronized void reopen(long pos) throws IOException {\n+\n+    long partLen;\n+\n+    if (pos \u003c 0) {\n+      throw new EOFException(\"Cannot seek at negtive position:\" + pos);\n+    } else if (pos \u003e dataLen) {\n+      throw new EOFException(\"Cannot seek after EOF, fileLen:\" + dataLen +\n+          \" position:\" + pos);\n+    } else if (pos + downloadPartSize \u003e dataLen) {\n+      partLen \u003d dataLen - pos;\n+    } else {\n+      partLen \u003d downloadPartSize;\n+    }\n+\n+    if (wrappedStream !\u003d null) {\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Aborting old stream to open at pos \" + pos);\n+      }\n+      wrappedStream.close();\n+    }\n+\n+    GetObjectRequest request \u003d new GetObjectRequest(bucketName, key);\n+    request.setRange(pos, pos + partLen - 1);\n+    wrappedStream \u003d ossClient.getObject(request).getObjectContent();\n+    if (wrappedStream \u003d\u003d null) {\n+      throw new IOException(\"Null IO stream\");\n+    }\n+    position \u003d pos;\n+    partRemaining \u003d partLen;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void reopen(long pos) throws IOException {\n\n    long partLen;\n\n    if (pos \u003c 0) {\n      throw new EOFException(\"Cannot seek at negtive position:\" + pos);\n    } else if (pos \u003e dataLen) {\n      throw new EOFException(\"Cannot seek after EOF, fileLen:\" + dataLen +\n          \" position:\" + pos);\n    } else if (pos + downloadPartSize \u003e dataLen) {\n      partLen \u003d dataLen - pos;\n    } else {\n      partLen \u003d downloadPartSize;\n    }\n\n    if (wrappedStream !\u003d null) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Aborting old stream to open at pos \" + pos);\n      }\n      wrappedStream.close();\n    }\n\n    GetObjectRequest request \u003d new GetObjectRequest(bucketName, key);\n    request.setRange(pos, pos + partLen - 1);\n    wrappedStream \u003d ossClient.getObject(request).getObjectContent();\n    if (wrappedStream \u003d\u003d null) {\n      throw new IOException(\"Null IO stream\");\n    }\n    position \u003d pos;\n    partRemaining \u003d partLen;\n  }",
      "path": "hadoop-tools/hadoop-aliyun/src/main/java/org/apache/hadoop/fs/aliyun/oss/AliyunOSSInputStream.java"
    }
  }
}