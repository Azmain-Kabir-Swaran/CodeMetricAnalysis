{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImageFormatPBINode.java",
  "functionName": "serializeINodeSection",
  "functionId": "serializeINodeSection___out-OutputStream",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.java",
  "functionStartLine": 762,
  "functionEndLine": 787,
  "numCommitsSeen": 63,
  "timeTaken": 3110,
  "changeHistory": [
    "b67812ea2111fa11bdd76096b923c93e1bdf2923",
    "185e0c7b4c056b88f606362c71e4a22aae7076e0",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305"
  ],
  "changeHistoryShort": {
    "b67812ea2111fa11bdd76096b923c93e1bdf2923": "Ybodychange",
    "185e0c7b4c056b88f606362c71e4a22aae7076e0": "Ybodychange",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b67812ea2111fa11bdd76096b923c93e1bdf2923": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14617. Improve fsimage load time by writing sub-sections to the fsimage index (#1028). Contributed by  Stephen O\u0027Donnell.\n\nReviewed-by: He Xiaoqiao \u003chexiaoqiao@apache.org\u003e",
      "commitDate": "22/08/19 5:09 PM",
      "commitName": "b67812ea2111fa11bdd76096b923c93e1bdf2923",
      "commitAuthor": "Stephen O\u0027Donnell",
      "commitDateOld": "22/07/19 8:07 PM",
      "commitNameOld": "377f95bbe8d2d171b5d7b0bfa7559e67ca4aae46",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 30.88,
      "commitsBetweenForRepo": 299,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,26 @@\n     void serializeINodeSection(OutputStream out) throws IOException {\n       INodeMap inodesMap \u003d fsn.dir.getINodeMap();\n \n       INodeSection.Builder b \u003d INodeSection.newBuilder()\n           .setLastInodeId(fsn.dir.getLastInodeId()).setNumInodes(inodesMap.size());\n       INodeSection s \u003d b.build();\n       s.writeDelimitedTo(out);\n \n       int i \u003d 0;\n       Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d inodesMap.getMapIterator();\n       while (iter.hasNext()) {\n         INodeWithAdditionalFields n \u003d iter.next();\n         save(out, n);\n         ++i;\n         if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n           context.checkCancelled();\n         }\n+        if (i % parent.getInodesPerSubSection() \u003d\u003d 0) {\n+          parent.commitSubSection(summary,\n+              FSImageFormatProtobuf.SectionName.INODE_SUB);\n+        }\n       }\n-      parent.commitSection(summary, FSImageFormatProtobuf.SectionName.INODE);\n+      parent.commitSectionAndSubSection(summary,\n+          FSImageFormatProtobuf.SectionName.INODE,\n+          FSImageFormatProtobuf.SectionName.INODE_SUB);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void serializeINodeSection(OutputStream out) throws IOException {\n      INodeMap inodesMap \u003d fsn.dir.getINodeMap();\n\n      INodeSection.Builder b \u003d INodeSection.newBuilder()\n          .setLastInodeId(fsn.dir.getLastInodeId()).setNumInodes(inodesMap.size());\n      INodeSection s \u003d b.build();\n      s.writeDelimitedTo(out);\n\n      int i \u003d 0;\n      Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d inodesMap.getMapIterator();\n      while (iter.hasNext()) {\n        INodeWithAdditionalFields n \u003d iter.next();\n        save(out, n);\n        ++i;\n        if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n          context.checkCancelled();\n        }\n        if (i % parent.getInodesPerSubSection() \u003d\u003d 0) {\n          parent.commitSubSection(summary,\n              FSImageFormatProtobuf.SectionName.INODE_SUB);\n        }\n      }\n      parent.commitSectionAndSubSection(summary,\n          FSImageFormatProtobuf.SectionName.INODE,\n          FSImageFormatProtobuf.SectionName.INODE_SUB);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.java",
      "extendedDetails": {}
    },
    "185e0c7b4c056b88f606362c71e4a22aae7076e0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7462. Consolidate implementation of mkdirs() into a single class. Contributed by Haohui Mai.\n",
      "commitDate": "02/12/14 2:53 PM",
      "commitName": "185e0c7b4c056b88f606362c71e4a22aae7076e0",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/09/14 10:27 PM",
      "commitNameOld": "bb84f1fccb18c6c7373851e05d2451d55e908242",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 63.73,
      "commitsBetweenForRepo": 545,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n     void serializeINodeSection(OutputStream out) throws IOException {\n       INodeMap inodesMap \u003d fsn.dir.getINodeMap();\n \n       INodeSection.Builder b \u003d INodeSection.newBuilder()\n-          .setLastInodeId(fsn.getLastInodeId()).setNumInodes(inodesMap.size());\n+          .setLastInodeId(fsn.dir.getLastInodeId()).setNumInodes(inodesMap.size());\n       INodeSection s \u003d b.build();\n       s.writeDelimitedTo(out);\n \n       int i \u003d 0;\n       Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d inodesMap.getMapIterator();\n       while (iter.hasNext()) {\n         INodeWithAdditionalFields n \u003d iter.next();\n         save(out, n);\n         ++i;\n         if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n           context.checkCancelled();\n         }\n       }\n       parent.commitSection(summary, FSImageFormatProtobuf.SectionName.INODE);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void serializeINodeSection(OutputStream out) throws IOException {\n      INodeMap inodesMap \u003d fsn.dir.getINodeMap();\n\n      INodeSection.Builder b \u003d INodeSection.newBuilder()\n          .setLastInodeId(fsn.dir.getLastInodeId()).setNumInodes(inodesMap.size());\n      INodeSection s \u003d b.build();\n      s.writeDelimitedTo(out);\n\n      int i \u003d 0;\n      Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d inodesMap.getMapIterator();\n      while (iter.hasNext()) {\n        INodeWithAdditionalFields n \u003d iter.next();\n        save(out, n);\n        ++i;\n        if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n          context.checkCancelled();\n        }\n      }\n      parent.commitSection(summary, FSImageFormatProtobuf.SectionName.INODE);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.java",
      "extendedDetails": {}
    },
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5698. Use protobuf to serialize / deserialize FSImage. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1566359 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/02/14 11:18 AM",
      "commitName": "a2edb11b68ae01a44092cb14ac2717a6aad93305",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,20 @@\n+    void serializeINodeSection(OutputStream out) throws IOException {\n+      INodeMap inodesMap \u003d fsn.dir.getINodeMap();\n+\n+      INodeSection.Builder b \u003d INodeSection.newBuilder()\n+          .setLastInodeId(fsn.getLastInodeId()).setNumInodes(inodesMap.size());\n+      INodeSection s \u003d b.build();\n+      s.writeDelimitedTo(out);\n+\n+      int i \u003d 0;\n+      Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d inodesMap.getMapIterator();\n+      while (iter.hasNext()) {\n+        INodeWithAdditionalFields n \u003d iter.next();\n+        save(out, n);\n+        ++i;\n+        if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n+          context.checkCancelled();\n+        }\n+      }\n+      parent.commitSection(summary, FSImageFormatProtobuf.SectionName.INODE);\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    void serializeINodeSection(OutputStream out) throws IOException {\n      INodeMap inodesMap \u003d fsn.dir.getINodeMap();\n\n      INodeSection.Builder b \u003d INodeSection.newBuilder()\n          .setLastInodeId(fsn.getLastInodeId()).setNumInodes(inodesMap.size());\n      INodeSection s \u003d b.build();\n      s.writeDelimitedTo(out);\n\n      int i \u003d 0;\n      Iterator\u003cINodeWithAdditionalFields\u003e iter \u003d inodesMap.getMapIterator();\n      while (iter.hasNext()) {\n        INodeWithAdditionalFields n \u003d iter.next();\n        save(out, n);\n        ++i;\n        if (i % FSImageFormatProtobuf.Saver.CHECK_CANCEL_INTERVAL \u003d\u003d 0) {\n          context.checkCancelled();\n        }\n      }\n      parent.commitSection(summary, FSImageFormatProtobuf.SectionName.INODE);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.java"
    }
  }
}