{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RouterRpcServer.java",
  "functionName": "updatePipeline",
  "functionId": "updatePipeline___clientName-String__oldBlock-ExtendedBlock__newBlock-ExtendedBlock__newNodes-DatanodeID[]__newStorageIDs-String[]",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
  "functionStartLine": 774,
  "functionEndLine": 779,
  "numCommitsSeen": 75,
  "timeTaken": 4451,
  "changeHistory": [
    "6425ed27ea638da75f656204d6df4adad1d91fe1",
    "fb5b3dce6192265bce9b9d93ab663bdc5be8048e",
    "fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a",
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d",
    "ca4f209b49e3aad6a80306f7342c9b6b560a79a7"
  ],
  "changeHistoryShort": {
    "6425ed27ea638da75f656204d6df4adad1d91fe1": "Ybodychange",
    "fb5b3dce6192265bce9b9d93ab663bdc5be8048e": "Ybodychange",
    "fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a": "Ybodychange",
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d": "Yfilerename",
    "ca4f209b49e3aad6a80306f7342c9b6b560a79a7": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6425ed27ea638da75f656204d6df4adad1d91fe1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13790. RBF: Move ClientProtocol APIs to its own module. Contributed by Chao Sun.\n",
      "commitDate": "19/08/18 11:50 PM",
      "commitName": "6425ed27ea638da75f656204d6df4adad1d91fe1",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "17/08/18 8:01 AM",
      "commitNameOld": "fb5b3dce6192265bce9b9d93ab663bdc5be8048e",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 2.66,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,6 @@\n   public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n       ExtendedBlock newBlock, DatanodeID[] newNodes, String[] newStorageIDs)\n           throws IOException {\n-    checkOperation(OperationCategory.WRITE);\n-\n-    RemoteMethod method \u003d new RemoteMethod(\"updatePipeline\",\n-        new Class\u003c?\u003e[] {String.class, ExtendedBlock.class, ExtendedBlock.class,\n-                        DatanodeID[].class, String[].class},\n-        clientName, oldBlock, newBlock, newNodes, newStorageIDs);\n-    rpcClient.invokeSingle(oldBlock, method);\n+    clientProto.updatePipeline(clientName, oldBlock, newBlock, newNodes,\n+        newStorageIDs);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n      ExtendedBlock newBlock, DatanodeID[] newNodes, String[] newStorageIDs)\n          throws IOException {\n    clientProto.updatePipeline(clientName, oldBlock, newBlock, newNodes,\n        newStorageIDs);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
      "extendedDetails": {}
    },
    "fb5b3dce6192265bce9b9d93ab663bdc5be8048e": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-13790. RBF: Move ClientProtocol APIs to its own module. Contributed by Chao Sun.\"\n\nThis reverts commit fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a.\n",
      "commitDate": "17/08/18 8:01 AM",
      "commitName": "fb5b3dce6192265bce9b9d93ab663bdc5be8048e",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "17/08/18 2:52 AM",
      "commitNameOld": "fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 0.21,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,11 @@\n   public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n       ExtendedBlock newBlock, DatanodeID[] newNodes, String[] newStorageIDs)\n           throws IOException {\n-    clientProto.updatePipeline(clientName, oldBlock, newBlock, newNodes,\n-        newStorageIDs);\n+    checkOperation(OperationCategory.WRITE);\n+\n+    RemoteMethod method \u003d new RemoteMethod(\"updatePipeline\",\n+        new Class\u003c?\u003e[] {String.class, ExtendedBlock.class, ExtendedBlock.class,\n+                        DatanodeID[].class, String[].class},\n+        clientName, oldBlock, newBlock, newNodes, newStorageIDs);\n+    rpcClient.invokeSingle(oldBlock, method);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n      ExtendedBlock newBlock, DatanodeID[] newNodes, String[] newStorageIDs)\n          throws IOException {\n    checkOperation(OperationCategory.WRITE);\n\n    RemoteMethod method \u003d new RemoteMethod(\"updatePipeline\",\n        new Class\u003c?\u003e[] {String.class, ExtendedBlock.class, ExtendedBlock.class,\n                        DatanodeID[].class, String[].class},\n        clientName, oldBlock, newBlock, newNodes, newStorageIDs);\n    rpcClient.invokeSingle(oldBlock, method);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
      "extendedDetails": {}
    },
    "fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13790. RBF: Move ClientProtocol APIs to its own module. Contributed by Chao Sun.\n",
      "commitDate": "17/08/18 2:52 AM",
      "commitName": "fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "39ed3a66dbb01383ed16b141183fc48bfd2e613d",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 4.99,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,6 @@\n   public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n       ExtendedBlock newBlock, DatanodeID[] newNodes, String[] newStorageIDs)\n           throws IOException {\n-    checkOperation(OperationCategory.WRITE);\n-\n-    RemoteMethod method \u003d new RemoteMethod(\"updatePipeline\",\n-        new Class\u003c?\u003e[] {String.class, ExtendedBlock.class, ExtendedBlock.class,\n-                        DatanodeID[].class, String[].class},\n-        clientName, oldBlock, newBlock, newNodes, newStorageIDs);\n-    rpcClient.invokeSingle(oldBlock, method);\n+    clientProto.updatePipeline(clientName, oldBlock, newBlock, newNodes,\n+        newStorageIDs);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n      ExtendedBlock newBlock, DatanodeID[] newNodes, String[] newStorageIDs)\n          throws IOException {\n    clientProto.updatePipeline(clientName, oldBlock, newBlock, newNodes,\n        newStorageIDs);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
      "extendedDetails": {}
    },
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-13215. RBF: Move Router to its own module. Contributed by Wei Yan\n",
      "commitDate": "19/03/18 10:13 PM",
      "commitName": "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d",
      "commitAuthor": "weiy",
      "commitDateOld": "19/03/18 5:19 PM",
      "commitNameOld": "e65ff1c8be48ef4f04ed96f96ac4caef4974944d",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 0.2,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n      ExtendedBlock newBlock, DatanodeID[] newNodes, String[] newStorageIDs)\n          throws IOException {\n    checkOperation(OperationCategory.WRITE);\n\n    RemoteMethod method \u003d new RemoteMethod(\"updatePipeline\",\n        new Class\u003c?\u003e[] {String.class, ExtendedBlock.class, ExtendedBlock.class,\n                        DatanodeID[].class, String[].class},\n        clientName, oldBlock, newBlock, newNodes, newStorageIDs);\n    rpcClient.invokeSingle(oldBlock, method);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java"
      }
    },
    "ca4f209b49e3aad6a80306f7342c9b6b560a79a7": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11546. Federation Router RPC server. Contributed by Jason Kace and Inigo Goiri.\n\n(cherry picked from commit 8a9cdebebf26841a0f1e99fb08135f4597f2eba2)\n",
      "commitDate": "06/10/17 6:50 PM",
      "commitName": "ca4f209b49e3aad6a80306f7342c9b6b560a79a7",
      "commitAuthor": "Inigo Goiri",
      "diff": "@@ -0,0 +1,11 @@\n+  public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n+      ExtendedBlock newBlock, DatanodeID[] newNodes, String[] newStorageIDs)\n+          throws IOException {\n+    checkOperation(OperationCategory.WRITE);\n+\n+    RemoteMethod method \u003d new RemoteMethod(\"updatePipeline\",\n+        new Class\u003c?\u003e[] {String.class, ExtendedBlock.class, ExtendedBlock.class,\n+                        DatanodeID[].class, String[].class},\n+        clientName, oldBlock, newBlock, newNodes, newStorageIDs);\n+    rpcClient.invokeSingle(oldBlock, method);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void updatePipeline(String clientName, ExtendedBlock oldBlock,\n      ExtendedBlock newBlock, DatanodeID[] newNodes, String[] newStorageIDs)\n          throws IOException {\n    checkOperation(OperationCategory.WRITE);\n\n    RemoteMethod method \u003d new RemoteMethod(\"updatePipeline\",\n        new Class\u003c?\u003e[] {String.class, ExtendedBlock.class, ExtendedBlock.class,\n                        DatanodeID[].class, String[].class},\n        clientName, oldBlock, newBlock, newNodes, newStorageIDs);\n    rpcClient.invokeSingle(oldBlock, method);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java"
    }
  }
}