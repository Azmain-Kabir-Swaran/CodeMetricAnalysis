{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3AFileSystem.java",
  "functionName": "initTransferManager",
  "functionId": "initTransferManager",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
  "functionStartLine": 684,
  "functionEndLine": 694,
  "numCommitsSeen": 141,
  "timeTaken": 4388,
  "changeHistory": [
    "2158496f6bed5f9d14751b82bd5d43b9fd786b95",
    "19f0f9608e31203523943f008ac701b6f3d7973c",
    "76fab26c5c02cef38924d04136407489fd9457d9"
  ],
  "changeHistoryShort": {
    "2158496f6bed5f9d14751b82bd5d43b9fd786b95": "Ybodychange",
    "19f0f9608e31203523943f008ac701b6f3d7973c": "Ybodychange",
    "76fab26c5c02cef38924d04136407489fd9457d9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2158496f6bed5f9d14751b82bd5d43b9fd786b95": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13826. S3A Deadlock in multipart copy due to thread pool limits. Contributed by  Sean Mackrory.\n\n(cherry picked from commit e3a74e0369e6e2217d1280179b390227fe1b1684)\n",
      "commitDate": "21/02/17 10:28 AM",
      "commitName": "2158496f6bed5f9d14751b82bd5d43b9fd786b95",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "11/02/17 1:59 PM",
      "commitNameOld": "839b690ed5edc2ac4984640d58c005bb63cd8a07",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 9.85,
      "commitsBetweenForRepo": 53,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,11 @@\n   private void initTransferManager() {\n     TransferManagerConfiguration transferConfiguration \u003d\n         new TransferManagerConfiguration();\n     transferConfiguration.setMinimumUploadPartSize(partSize);\n     transferConfiguration.setMultipartUploadThreshold(multiPartThreshold);\n     transferConfiguration.setMultipartCopyPartSize(partSize);\n     transferConfiguration.setMultipartCopyThreshold(multiPartThreshold);\n \n-    transfers \u003d new TransferManager(s3, threadPoolExecutor);\n+    transfers \u003d new TransferManager(s3, unboundedThreadPool);\n     transfers.setConfiguration(transferConfiguration);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initTransferManager() {\n    TransferManagerConfiguration transferConfiguration \u003d\n        new TransferManagerConfiguration();\n    transferConfiguration.setMinimumUploadPartSize(partSize);\n    transferConfiguration.setMultipartUploadThreshold(multiPartThreshold);\n    transferConfiguration.setMultipartCopyPartSize(partSize);\n    transferConfiguration.setMultipartCopyThreshold(multiPartThreshold);\n\n    transfers \u003d new TransferManager(s3, unboundedThreadPool);\n    transfers.setConfiguration(transferConfiguration);\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
      "extendedDetails": {}
    },
    "19f0f9608e31203523943f008ac701b6f3d7973c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-12891. S3AFileSystem should configure Multipart Copy threshold and chunk size. (Andrew Olson via stevel)\n",
      "commitDate": "22/04/16 3:25 AM",
      "commitName": "19f0f9608e31203523943f008ac701b6f3d7973c",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "14/04/16 4:44 AM",
      "commitNameOld": "df18b6e9849c53c51a3d317f1254298edd8b17d1",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 7.94,
      "commitsBetweenForRepo": 52,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,10 @@\n   private void initTransferManager() {\n     TransferManagerConfiguration transferConfiguration \u003d new TransferManagerConfiguration();\n     transferConfiguration.setMinimumUploadPartSize(partSize);\n     transferConfiguration.setMultipartUploadThreshold(multiPartThreshold);\n+    transferConfiguration.setMultipartCopyPartSize(partSize);\n+    transferConfiguration.setMultipartCopyThreshold(multiPartThreshold);\n \n     transfers \u003d new TransferManager(s3, threadPoolExecutor);\n     transfers.setConfiguration(transferConfiguration);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void initTransferManager() {\n    TransferManagerConfiguration transferConfiguration \u003d new TransferManagerConfiguration();\n    transferConfiguration.setMinimumUploadPartSize(partSize);\n    transferConfiguration.setMultipartUploadThreshold(multiPartThreshold);\n    transferConfiguration.setMultipartCopyPartSize(partSize);\n    transferConfiguration.setMultipartCopyThreshold(multiPartThreshold);\n\n    transfers \u003d new TransferManager(s3, threadPoolExecutor);\n    transfers.setConfiguration(transferConfiguration);\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
      "extendedDetails": {}
    },
    "76fab26c5c02cef38924d04136407489fd9457d9": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-12548. Read s3a creds from a Credential Provider. Contributed by Larry McCay.\n",
      "commitDate": "17/02/16 12:19 PM",
      "commitName": "76fab26c5c02cef38924d04136407489fd9457d9",
      "commitAuthor": "cnauroth",
      "diff": "@@ -0,0 +1,8 @@\n+  private void initTransferManager() {\n+    TransferManagerConfiguration transferConfiguration \u003d new TransferManagerConfiguration();\n+    transferConfiguration.setMinimumUploadPartSize(partSize);\n+    transferConfiguration.setMultipartUploadThreshold(multiPartThreshold);\n+\n+    transfers \u003d new TransferManager(s3, threadPoolExecutor);\n+    transfers.setConfiguration(transferConfiguration);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void initTransferManager() {\n    TransferManagerConfiguration transferConfiguration \u003d new TransferManagerConfiguration();\n    transferConfiguration.setMinimumUploadPartSize(partSize);\n    transferConfiguration.setMultipartUploadThreshold(multiPartThreshold);\n\n    transfers \u003d new TransferManager(s3, threadPoolExecutor);\n    transfers.setConfiguration(transferConfiguration);\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java"
    }
  }
}