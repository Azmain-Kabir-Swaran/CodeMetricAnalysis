{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "QuorumJournalManager.java",
  "functionName": "selectInputStreams",
  "functionId": "selectInputStreams___streams-Collection__EditLogInputStream____fromTxnId-long__inProgressOk-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
  "functionStartLine": 508,
  "functionEndLine": 511,
  "numCommitsSeen": 42,
  "timeTaken": 2447,
  "changeHistory": [
    "098ec2b11ff3f677eb823f75b147a1ac8dbf959e",
    "512a18a8d92305a34f3037064ceabdc5aff1f8bf",
    "8c62c46046656c01b327c378e89d57b4bf37e16e",
    "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38",
    "437948ea1c0c9c61c2b5049b82ffd9525f33be97",
    "f9a0d78ef5889bb1b9510ba15a1a780fcc9560fd",
    "939f4a9f92ab260aee697d3715946218a7ff769a",
    "74d4573a23db5586c6e47ff2277aa7c35237da34"
  ],
  "changeHistoryShort": {
    "098ec2b11ff3f677eb823f75b147a1ac8dbf959e": "Ybodychange",
    "512a18a8d92305a34f3037064ceabdc5aff1f8bf": "Ybodychange",
    "8c62c46046656c01b327c378e89d57b4bf37e16e": "Ybodychange",
    "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38": "Ybodychange",
    "437948ea1c0c9c61c2b5049b82ffd9525f33be97": "Ymultichange(Yexceptionschange,Ybodychange)",
    "f9a0d78ef5889bb1b9510ba15a1a780fcc9560fd": "Ybodychange",
    "939f4a9f92ab260aee697d3715946218a7ff769a": "Ybodychange",
    "74d4573a23db5586c6e47ff2277aa7c35237da34": "Yintroduced"
  },
  "changeHistoryDetails": {
    "098ec2b11ff3f677eb823f75b147a1ac8dbf959e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10519. Add a configuration option to enable in-progress edit log tailing. Contributed by Jiayi Zhou.\n",
      "commitDate": "27/07/16 5:55 PM",
      "commitName": "098ec2b11ff3f677eb823f75b147a1ac8dbf959e",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "24/03/14 11:48 PM",
      "commitNameOld": "56205ca7d7f3b2a7e55f48b9cf444326e1d2b1a7",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 855.76,
      "commitsBetweenForRepo": 6651,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,4 @@\n   public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n       long fromTxnId, boolean inProgressOk) throws IOException {\n-\n-    QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n-        loggers.getEditLogManifest(fromTxnId, inProgressOk);\n-    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps \u003d\n-        loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs,\n-            \"selectInputStreams\");\n-    \n-    LOG.debug(\"selectInputStream manifests:\\n\" +\n-        Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n-    \n-    final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n-        new PriorityQueue\u003cEditLogInputStream\u003e(64,\n-            JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n-    for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n-      AsyncLogger logger \u003d e.getKey();\n-      RemoteEditLogManifest manifest \u003d e.getValue();\n-      \n-      for (RemoteEditLog remoteLog : manifest.getLogs()) {\n-        URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n-\n-        EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n-            connectionFactory, url, remoteLog.getStartTxId(),\n-            remoteLog.getEndTxId(), remoteLog.isInProgress());\n-        allStreams.add(elis);\n-      }\n-    }\n-    JournalSet.chainAndMakeRedundantStreams(streams, allStreams, fromTxnId);\n+    selectInputStreams(streams, fromTxnId, inProgressOk, false);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n      long fromTxnId, boolean inProgressOk) throws IOException {\n    selectInputStreams(streams, fromTxnId, inProgressOk, false);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
      "extendedDetails": {}
    },
    "512a18a8d92305a34f3037064ceabdc5aff1f8bf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5074. Allow starting up from an fsimage checkpoint in the middle of a segment. Contributed by Todd Lipcon.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1550016 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/12/13 5:32 PM",
      "commitName": "512a18a8d92305a34f3037064ceabdc5aff1f8bf",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "25/11/13 5:16 PM",
      "commitNameOld": "d8a23834614581a292aad214dddcbcc4bbe86d27",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 15.01,
      "commitsBetweenForRepo": 73,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,30 @@\n   public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n       long fromTxnId, boolean inProgressOk) throws IOException {\n-    selectInputStreams(streams, fromTxnId, inProgressOk, true);\n+\n+    QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n+        loggers.getEditLogManifest(fromTxnId, inProgressOk);\n+    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps \u003d\n+        loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs,\n+            \"selectInputStreams\");\n+    \n+    LOG.debug(\"selectInputStream manifests:\\n\" +\n+        Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n+    \n+    final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n+        new PriorityQueue\u003cEditLogInputStream\u003e(64,\n+            JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n+    for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n+      AsyncLogger logger \u003d e.getKey();\n+      RemoteEditLogManifest manifest \u003d e.getValue();\n+      \n+      for (RemoteEditLog remoteLog : manifest.getLogs()) {\n+        URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n+\n+        EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n+            connectionFactory, url, remoteLog.getStartTxId(),\n+            remoteLog.getEndTxId(), remoteLog.isInProgress());\n+        allStreams.add(elis);\n+      }\n+    }\n+    JournalSet.chainAndMakeRedundantStreams(streams, allStreams, fromTxnId);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n      long fromTxnId, boolean inProgressOk) throws IOException {\n\n    QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n        loggers.getEditLogManifest(fromTxnId, inProgressOk);\n    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps \u003d\n        loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs,\n            \"selectInputStreams\");\n    \n    LOG.debug(\"selectInputStream manifests:\\n\" +\n        Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n    \n    final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n        new PriorityQueue\u003cEditLogInputStream\u003e(64,\n            JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n    for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n      AsyncLogger logger \u003d e.getKey();\n      RemoteEditLogManifest manifest \u003d e.getValue();\n      \n      for (RemoteEditLog remoteLog : manifest.getLogs()) {\n        URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n\n        EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n            connectionFactory, url, remoteLog.getStartTxId(),\n            remoteLog.getEndTxId(), remoteLog.isInProgress());\n        allStreams.add(elis);\n      }\n    }\n    JournalSet.chainAndMakeRedundantStreams(streams, allStreams, fromTxnId);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
      "extendedDetails": {}
    },
    "8c62c46046656c01b327c378e89d57b4bf37e16e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4298. StorageRetentionManager spews warnings when used with QJM. Contributed by Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1485371 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/05/13 12:37 PM",
      "commitName": "8c62c46046656c01b327c378e89d57b4bf37e16e",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "19/09/12 11:52 AM",
      "commitNameOld": "663e7484c04c197eed53f10a7808140f1c955277",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 245.03,
      "commitsBetweenForRepo": 1359,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,4 @@\n   public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n       long fromTxnId, boolean inProgressOk) throws IOException {\n-\n-    QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n-        loggers.getEditLogManifest(fromTxnId);\n-    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps \u003d\n-        loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs,\n-            \"selectInputStreams\");\n-    \n-    LOG.debug(\"selectInputStream manifests:\\n\" +\n-        Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n-    \n-    final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n-        new PriorityQueue\u003cEditLogInputStream\u003e(64,\n-            JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n-    for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n-      AsyncLogger logger \u003d e.getKey();\n-      RemoteEditLogManifest manifest \u003d e.getValue();\n-      \n-      for (RemoteEditLog remoteLog : manifest.getLogs()) {\n-        URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n-\n-        EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n-            url, remoteLog.getStartTxId(), remoteLog.getEndTxId(),\n-            remoteLog.isInProgress());\n-        allStreams.add(elis);\n-      }\n-    }\n-    JournalSet.chainAndMakeRedundantStreams(\n-        streams, allStreams, fromTxnId, inProgressOk);\n+    selectInputStreams(streams, fromTxnId, inProgressOk, true);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n      long fromTxnId, boolean inProgressOk) throws IOException {\n    selectInputStreams(streams, fromTxnId, inProgressOk, true);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
      "extendedDetails": {}
    },
    "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3906. QJM: quorum timeout on failover with large log segment. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1383251 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/09/12 11:31 PM",
      "commitName": "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "05/09/12 11:57 PM",
      "commitNameOld": "437948ea1c0c9c61c2b5049b82ffd9525f33be97",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 4.98,
      "commitsBetweenForRepo": 37,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,31 @@\n   public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n       long fromTxnId, boolean inProgressOk) throws IOException {\n \n     QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n         loggers.getEditLogManifest(fromTxnId);\n     Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps \u003d\n-        loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs);\n+        loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs,\n+            \"selectInputStreams\");\n     \n     LOG.debug(\"selectInputStream manifests:\\n\" +\n         Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n     \n     final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n         new PriorityQueue\u003cEditLogInputStream\u003e(64,\n             JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n     for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n       AsyncLogger logger \u003d e.getKey();\n       RemoteEditLogManifest manifest \u003d e.getValue();\n       \n       for (RemoteEditLog remoteLog : manifest.getLogs()) {\n         URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n \n         EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n             url, remoteLog.getStartTxId(), remoteLog.getEndTxId(),\n             remoteLog.isInProgress());\n         allStreams.add(elis);\n       }\n     }\n     JournalSet.chainAndMakeRedundantStreams(\n         streams, allStreams, fromTxnId, inProgressOk);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n      long fromTxnId, boolean inProgressOk) throws IOException {\n\n    QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n        loggers.getEditLogManifest(fromTxnId);\n    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps \u003d\n        loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs,\n            \"selectInputStreams\");\n    \n    LOG.debug(\"selectInputStream manifests:\\n\" +\n        Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n    \n    final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n        new PriorityQueue\u003cEditLogInputStream\u003e(64,\n            JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n    for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n      AsyncLogger logger \u003d e.getKey();\n      RemoteEditLogManifest manifest \u003d e.getValue();\n      \n      for (RemoteEditLog remoteLog : manifest.getLogs()) {\n        URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n\n        EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n            url, remoteLog.getStartTxId(), remoteLog.getEndTxId(),\n            remoteLog.isInProgress());\n        allStreams.add(elis);\n      }\n    }\n    JournalSet.chainAndMakeRedundantStreams(\n        streams, allStreams, fromTxnId, inProgressOk);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
      "extendedDetails": {}
    },
    "437948ea1c0c9c61c2b5049b82ffd9525f33be97": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-3891. Make selectInputStreams throw IOE instead of RTE. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1381481 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/09/12 11:57 PM",
      "commitName": "437948ea1c0c9c61c2b5049b82ffd9525f33be97",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-3891. Make selectInputStreams throw IOE instead of RTE. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1381481 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "05/09/12 11:57 PM",
          "commitName": "437948ea1c0c9c61c2b5049b82ffd9525f33be97",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "04/09/12 9:13 PM",
          "commitNameOld": "8021d9199f278345aca6211f318145342ad036f4",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 1.11,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,35 +1,30 @@\n   public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n-      long fromTxnId, boolean inProgressOk) {\n+      long fromTxnId, boolean inProgressOk) throws IOException {\n \n     QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n         loggers.getEditLogManifest(fromTxnId);\n-    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps;\n-    try {\n-      resps \u003d loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs);\n-    } catch (IOException ioe) {\n-      // TODO: can we do better here?\n-      throw new RuntimeException(ioe);\n-    }\n+    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps \u003d\n+        loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs);\n     \n     LOG.debug(\"selectInputStream manifests:\\n\" +\n         Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n     \n     final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n         new PriorityQueue\u003cEditLogInputStream\u003e(64,\n             JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n     for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n       AsyncLogger logger \u003d e.getKey();\n       RemoteEditLogManifest manifest \u003d e.getValue();\n       \n       for (RemoteEditLog remoteLog : manifest.getLogs()) {\n         URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n \n         EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n             url, remoteLog.getStartTxId(), remoteLog.getEndTxId(),\n             remoteLog.isInProgress());\n         allStreams.add(elis);\n       }\n     }\n     JournalSet.chainAndMakeRedundantStreams(\n         streams, allStreams, fromTxnId, inProgressOk);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n      long fromTxnId, boolean inProgressOk) throws IOException {\n\n    QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n        loggers.getEditLogManifest(fromTxnId);\n    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps \u003d\n        loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs);\n    \n    LOG.debug(\"selectInputStream manifests:\\n\" +\n        Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n    \n    final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n        new PriorityQueue\u003cEditLogInputStream\u003e(64,\n            JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n    for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n      AsyncLogger logger \u003d e.getKey();\n      RemoteEditLogManifest manifest \u003d e.getValue();\n      \n      for (RemoteEditLog remoteLog : manifest.getLogs()) {\n        URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n\n        EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n            url, remoteLog.getStartTxId(), remoteLog.getEndTxId(),\n            remoteLog.isInProgress());\n        allStreams.add(elis);\n      }\n    }\n    JournalSet.chainAndMakeRedundantStreams(\n        streams, allStreams, fromTxnId, inProgressOk);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3891. Make selectInputStreams throw IOE instead of RTE. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1381481 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "05/09/12 11:57 PM",
          "commitName": "437948ea1c0c9c61c2b5049b82ffd9525f33be97",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "04/09/12 9:13 PM",
          "commitNameOld": "8021d9199f278345aca6211f318145342ad036f4",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 1.11,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,35 +1,30 @@\n   public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n-      long fromTxnId, boolean inProgressOk) {\n+      long fromTxnId, boolean inProgressOk) throws IOException {\n \n     QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n         loggers.getEditLogManifest(fromTxnId);\n-    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps;\n-    try {\n-      resps \u003d loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs);\n-    } catch (IOException ioe) {\n-      // TODO: can we do better here?\n-      throw new RuntimeException(ioe);\n-    }\n+    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps \u003d\n+        loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs);\n     \n     LOG.debug(\"selectInputStream manifests:\\n\" +\n         Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n     \n     final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n         new PriorityQueue\u003cEditLogInputStream\u003e(64,\n             JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n     for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n       AsyncLogger logger \u003d e.getKey();\n       RemoteEditLogManifest manifest \u003d e.getValue();\n       \n       for (RemoteEditLog remoteLog : manifest.getLogs()) {\n         URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n \n         EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n             url, remoteLog.getStartTxId(), remoteLog.getEndTxId(),\n             remoteLog.isInProgress());\n         allStreams.add(elis);\n       }\n     }\n     JournalSet.chainAndMakeRedundantStreams(\n         streams, allStreams, fromTxnId, inProgressOk);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n      long fromTxnId, boolean inProgressOk) throws IOException {\n\n    QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n        loggers.getEditLogManifest(fromTxnId);\n    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps \u003d\n        loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs);\n    \n    LOG.debug(\"selectInputStream manifests:\\n\" +\n        Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n    \n    final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n        new PriorityQueue\u003cEditLogInputStream\u003e(64,\n            JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n    for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n      AsyncLogger logger \u003d e.getKey();\n      RemoteEditLogManifest manifest \u003d e.getValue();\n      \n      for (RemoteEditLog remoteLog : manifest.getLogs()) {\n        URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n\n        EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n            url, remoteLog.getStartTxId(), remoteLog.getEndTxId(),\n            remoteLog.isInProgress());\n        allStreams.add(elis);\n      }\n    }\n    JournalSet.chainAndMakeRedundantStreams(\n        streams, allStreams, fromTxnId, inProgressOk);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "f9a0d78ef5889bb1b9510ba15a1a780fcc9560fd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3826. QJM: Some trivial logging / exception text improvements. Contributed by Todd Lipcon and Aaron T. Myers.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1375356 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/08/12 5:48 PM",
      "commitName": "f9a0d78ef5889bb1b9510ba15a1a780fcc9560fd",
      "commitAuthor": "Aaron Myers",
      "commitDateOld": "15/08/12 11:58 AM",
      "commitNameOld": "42cdc1b0835abb4a331d40f30f2c210143b747bc",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 5.24,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,35 @@\n   public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n       long fromTxnId, boolean inProgressOk) {\n \n     QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n         loggers.getEditLogManifest(fromTxnId);\n     Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps;\n     try {\n       resps \u003d loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs);\n     } catch (IOException ioe) {\n       // TODO: can we do better here?\n       throw new RuntimeException(ioe);\n     }\n     \n     LOG.debug(\"selectInputStream manifests:\\n\" +\n         Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n     \n     final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n         new PriorityQueue\u003cEditLogInputStream\u003e(64,\n             JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n     for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n       AsyncLogger logger \u003d e.getKey();\n       RemoteEditLogManifest manifest \u003d e.getValue();\n       \n       for (RemoteEditLog remoteLog : manifest.getLogs()) {\n         URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n-        LOG.info(\"URL: \" + url);\n \n         EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n             url, remoteLog.getStartTxId(), remoteLog.getEndTxId(),\n             remoteLog.isInProgress());\n         allStreams.add(elis);\n       }\n     }\n     JournalSet.chainAndMakeRedundantStreams(\n         streams, allStreams, fromTxnId, inProgressOk);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n      long fromTxnId, boolean inProgressOk) {\n\n    QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n        loggers.getEditLogManifest(fromTxnId);\n    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps;\n    try {\n      resps \u003d loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs);\n    } catch (IOException ioe) {\n      // TODO: can we do better here?\n      throw new RuntimeException(ioe);\n    }\n    \n    LOG.debug(\"selectInputStream manifests:\\n\" +\n        Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n    \n    final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n        new PriorityQueue\u003cEditLogInputStream\u003e(64,\n            JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n    for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n      AsyncLogger logger \u003d e.getKey();\n      RemoteEditLogManifest manifest \u003d e.getValue();\n      \n      for (RemoteEditLog remoteLog : manifest.getLogs()) {\n        URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n\n        EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n            url, remoteLog.getStartTxId(), remoteLog.getEndTxId(),\n            remoteLog.isInProgress());\n        allStreams.add(elis);\n      }\n    }\n    JournalSet.chainAndMakeRedundantStreams(\n        streams, allStreams, fromTxnId, inProgressOk);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
      "extendedDetails": {}
    },
    "939f4a9f92ab260aee697d3715946218a7ff769a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3694. Fix getEditLogManifest to fetch httpPort if necessary. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1365788 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/07/12 2:40 PM",
      "commitName": "939f4a9f92ab260aee697d3715946218a7ff769a",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "19/07/12 5:25 PM",
      "commitNameOld": "74d4573a23db5586c6e47ff2277aa7c35237da34",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 5.89,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,36 @@\n   public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n       long fromTxnId, boolean inProgressOk) {\n \n-    QuorumCall\u003cAsyncLogger,GetEditLogManifestResponseProto\u003e q \u003d\n+    QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n         loggers.getEditLogManifest(fromTxnId);\n-    Map\u003cAsyncLogger, GetEditLogManifestResponseProto\u003e resps;\n+    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps;\n     try {\n       resps \u003d loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs);\n     } catch (IOException ioe) {\n       // TODO: can we do better here?\n       throw new RuntimeException(ioe);\n     }\n     \n-    LOG.info(\"selectInputStream manifests:\\n\" +\n-        QuorumCall.mapToString(resps));\n+    LOG.debug(\"selectInputStream manifests:\\n\" +\n+        Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n     \n     final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n         new PriorityQueue\u003cEditLogInputStream\u003e(64,\n             JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n-    for (Map.Entry\u003cAsyncLogger, GetEditLogManifestResponseProto\u003e e : resps.entrySet()) {\n+    for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n       AsyncLogger logger \u003d e.getKey();\n-      GetEditLogManifestResponseProto response \u003d e.getValue();\n-      RemoteEditLogManifest manifest \u003d PBHelper.convert(response.getManifest());\n+      RemoteEditLogManifest manifest \u003d e.getValue();\n       \n       for (RemoteEditLog remoteLog : manifest.getLogs()) {\n         URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n         LOG.info(\"URL: \" + url);\n \n         EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n             url, remoteLog.getStartTxId(), remoteLog.getEndTxId(),\n             remoteLog.isInProgress());\n         allStreams.add(elis);\n       }\n     }\n     JournalSet.chainAndMakeRedundantStreams(\n         streams, allStreams, fromTxnId, inProgressOk);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n      long fromTxnId, boolean inProgressOk) {\n\n    QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n        loggers.getEditLogManifest(fromTxnId);\n    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps;\n    try {\n      resps \u003d loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs);\n    } catch (IOException ioe) {\n      // TODO: can we do better here?\n      throw new RuntimeException(ioe);\n    }\n    \n    LOG.debug(\"selectInputStream manifests:\\n\" +\n        Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n    \n    final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n        new PriorityQueue\u003cEditLogInputStream\u003e(64,\n            JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n    for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n      AsyncLogger logger \u003d e.getKey();\n      RemoteEditLogManifest manifest \u003d e.getValue();\n      \n      for (RemoteEditLog remoteLog : manifest.getLogs()) {\n        URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n        LOG.info(\"URL: \" + url);\n\n        EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n            url, remoteLog.getStartTxId(), remoteLog.getEndTxId(),\n            remoteLog.isInProgress());\n        allStreams.add(elis);\n      }\n    }\n    JournalSet.chainAndMakeRedundantStreams(\n        streams, allStreams, fromTxnId, inProgressOk);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
      "extendedDetails": {}
    },
    "74d4573a23db5586c6e47ff2277aa7c35237da34": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1363596 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/07/12 5:25 PM",
      "commitName": "74d4573a23db5586c6e47ff2277aa7c35237da34",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,37 @@\n+  public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n+      long fromTxnId, boolean inProgressOk) {\n+\n+    QuorumCall\u003cAsyncLogger,GetEditLogManifestResponseProto\u003e q \u003d\n+        loggers.getEditLogManifest(fromTxnId);\n+    Map\u003cAsyncLogger, GetEditLogManifestResponseProto\u003e resps;\n+    try {\n+      resps \u003d loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs);\n+    } catch (IOException ioe) {\n+      // TODO: can we do better here?\n+      throw new RuntimeException(ioe);\n+    }\n+    \n+    LOG.info(\"selectInputStream manifests:\\n\" +\n+        QuorumCall.mapToString(resps));\n+    \n+    final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n+        new PriorityQueue\u003cEditLogInputStream\u003e(64,\n+            JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n+    for (Map.Entry\u003cAsyncLogger, GetEditLogManifestResponseProto\u003e e : resps.entrySet()) {\n+      AsyncLogger logger \u003d e.getKey();\n+      GetEditLogManifestResponseProto response \u003d e.getValue();\n+      RemoteEditLogManifest manifest \u003d PBHelper.convert(response.getManifest());\n+      \n+      for (RemoteEditLog remoteLog : manifest.getLogs()) {\n+        URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n+        LOG.info(\"URL: \" + url);\n+\n+        EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n+            url, remoteLog.getStartTxId(), remoteLog.getEndTxId(),\n+            remoteLog.isInProgress());\n+        allStreams.add(elis);\n+      }\n+    }\n+    JournalSet.chainAndMakeRedundantStreams(\n+        streams, allStreams, fromTxnId, inProgressOk);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n      long fromTxnId, boolean inProgressOk) {\n\n    QuorumCall\u003cAsyncLogger,GetEditLogManifestResponseProto\u003e q \u003d\n        loggers.getEditLogManifest(fromTxnId);\n    Map\u003cAsyncLogger, GetEditLogManifestResponseProto\u003e resps;\n    try {\n      resps \u003d loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs);\n    } catch (IOException ioe) {\n      // TODO: can we do better here?\n      throw new RuntimeException(ioe);\n    }\n    \n    LOG.info(\"selectInputStream manifests:\\n\" +\n        QuorumCall.mapToString(resps));\n    \n    final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n        new PriorityQueue\u003cEditLogInputStream\u003e(64,\n            JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n    for (Map.Entry\u003cAsyncLogger, GetEditLogManifestResponseProto\u003e e : resps.entrySet()) {\n      AsyncLogger logger \u003d e.getKey();\n      GetEditLogManifestResponseProto response \u003d e.getValue();\n      RemoteEditLogManifest manifest \u003d PBHelper.convert(response.getManifest());\n      \n      for (RemoteEditLog remoteLog : manifest.getLogs()) {\n        URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n        LOG.info(\"URL: \" + url);\n\n        EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n            url, remoteLog.getStartTxId(), remoteLog.getEndTxId(),\n            remoteLog.isInProgress());\n        allStreams.add(elis);\n      }\n    }\n    JournalSet.chainAndMakeRedundantStreams(\n        streams, allStreams, fromTxnId, inProgressOk);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java"
    }
  }
}