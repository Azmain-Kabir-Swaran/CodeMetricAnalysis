{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DFSAdmin.java",
  "functionName": "metaSave",
  "functionId": "metaSave___argv-String[]__idx-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
  "functionStartLine": 1537,
  "functionEndLine": 1580,
  "numCommitsSeen": 118,
  "timeTaken": 8488,
  "changeHistory": [
    "1bea785020a538115b3e08f41ff88167033d2775",
    "01bd6ab18fa48f4c7cac1497905b52e547962599",
    "6f8003dc7bc9e8be7b0512c514d370c303faf003",
    "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85",
    "cf93dfba4e5b7849a3917caa78b29b8a4fb5ef12",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "1bea785020a538115b3e08f41ff88167033d2775": "Ybodychange",
    "01bd6ab18fa48f4c7cac1497905b52e547962599": "Ybodychange",
    "6f8003dc7bc9e8be7b0512c514d370c303faf003": "Ybodychange",
    "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85": "Ybodychange",
    "cf93dfba4e5b7849a3917caa78b29b8a4fb5ef12": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1bea785020a538115b3e08f41ff88167033d2775": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14081. hdfs dfsadmin -metasave metasave_test results NPE. Contributed by Shweta Yakkali.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "20/02/19 2:28 PM",
      "commitName": "1bea785020a538115b3e08f41ff88167033d2775",
      "commitAuthor": "Shweta Yakkali",
      "commitDateOld": "06/09/18 2:48 PM",
      "commitNameOld": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 167.03,
      "commitsBetweenForRepo": 1335,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,44 @@\n   public int metaSave(String[] argv, int idx) throws IOException {\n     String pathname \u003d argv[idx];\n     DistributedFileSystem dfs \u003d getDFS();\n     Configuration dfsConf \u003d dfs.getConf();\n     URI dfsUri \u003d dfs.getUri();\n     boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(dfsConf, dfsUri);\n \n     if (isHaEnabled) {\n       String nsId \u003d dfsUri.getHost();\n       List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n           HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n           nsId, ClientProtocol.class);\n       List\u003cIOException\u003e exceptions \u003d new ArrayList\u003c\u003e();\n       for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n-        try{\n+        try {\n           proxy.getProxy().metaSave(pathname);\n           System.out.println(\"Created metasave file \" + pathname\n               + \" in the log directory of namenode \" + proxy.getAddress());\n-        } catch (IOException ioe){\n+        } catch (RemoteException re) {\n+          Exception unwrapped \u003d  re.unwrapRemoteException(\n+              StandbyException.class);\n+          if (unwrapped instanceof StandbyException) {\n+            System.out.println(\"Skip Standby NameNode, since it cannot perform\"\n+                + \" metasave operation\");\n+          } else {\n+            throw re;\n+          }\n+        } catch (IOException ioe) {\n           System.out.println(\"Created metasave file \" + pathname\n               + \" in the log directory of namenode \" + proxy.getAddress()\n               + \" failed\");\n           exceptions.add(ioe);\n         }\n       }\n       if(!exceptions.isEmpty()){\n         throw MultipleIOException.createIOException(exceptions);\n       }\n     } else {\n       dfs.metaSave(pathname);\n       System.out.println(\"Created metasave file \" + pathname + \" in the log \" +\n           \"directory of namenode \" + dfs.getUri());\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int metaSave(String[] argv, int idx) throws IOException {\n    String pathname \u003d argv[idx];\n    DistributedFileSystem dfs \u003d getDFS();\n    Configuration dfsConf \u003d dfs.getConf();\n    URI dfsUri \u003d dfs.getUri();\n    boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(dfsConf, dfsUri);\n\n    if (isHaEnabled) {\n      String nsId \u003d dfsUri.getHost();\n      List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n          HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n          nsId, ClientProtocol.class);\n      List\u003cIOException\u003e exceptions \u003d new ArrayList\u003c\u003e();\n      for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n        try {\n          proxy.getProxy().metaSave(pathname);\n          System.out.println(\"Created metasave file \" + pathname\n              + \" in the log directory of namenode \" + proxy.getAddress());\n        } catch (RemoteException re) {\n          Exception unwrapped \u003d  re.unwrapRemoteException(\n              StandbyException.class);\n          if (unwrapped instanceof StandbyException) {\n            System.out.println(\"Skip Standby NameNode, since it cannot perform\"\n                + \" metasave operation\");\n          } else {\n            throw re;\n          }\n        } catch (IOException ioe) {\n          System.out.println(\"Created metasave file \" + pathname\n              + \" in the log directory of namenode \" + proxy.getAddress()\n              + \" failed\");\n          exceptions.add(ioe);\n        }\n      }\n      if(!exceptions.isEmpty()){\n        throw MultipleIOException.createIOException(exceptions);\n      }\n    } else {\n      dfs.metaSave(pathname);\n      System.out.println(\"Created metasave file \" + pathname + \" in the log \" +\n          \"directory of namenode \" + dfs.getUri());\n    }\n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {}
    },
    "01bd6ab18fa48f4c7cac1497905b52e547962599": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12935. Get ambiguous result for DFSAdmin command in HA mode when only one namenode is up. Contributed by Jianfei Jiang.\n",
      "commitDate": "07/02/18 9:40 AM",
      "commitName": "01bd6ab18fa48f4c7cac1497905b52e547962599",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "05/01/18 10:31 PM",
      "commitNameOld": "bf5c94899537011465350d5d999fad9ffaeb605d",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 32.46,
      "commitsBetweenForRepo": 204,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,35 @@\n   public int metaSave(String[] argv, int idx) throws IOException {\n     String pathname \u003d argv[idx];\n     DistributedFileSystem dfs \u003d getDFS();\n     Configuration dfsConf \u003d dfs.getConf();\n     URI dfsUri \u003d dfs.getUri();\n     boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(dfsConf, dfsUri);\n \n     if (isHaEnabled) {\n       String nsId \u003d dfsUri.getHost();\n       List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n           HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n           nsId, ClientProtocol.class);\n+      List\u003cIOException\u003e exceptions \u003d new ArrayList\u003c\u003e();\n       for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n-        proxy.getProxy().metaSave(pathname);\n-        System.out.println(\"Created metasave file \" + pathname + \" in the log \"\n-            + \"directory of namenode \" + proxy.getAddress());\n+        try{\n+          proxy.getProxy().metaSave(pathname);\n+          System.out.println(\"Created metasave file \" + pathname\n+              + \" in the log directory of namenode \" + proxy.getAddress());\n+        } catch (IOException ioe){\n+          System.out.println(\"Created metasave file \" + pathname\n+              + \" in the log directory of namenode \" + proxy.getAddress()\n+              + \" failed\");\n+          exceptions.add(ioe);\n+        }\n+      }\n+      if(!exceptions.isEmpty()){\n+        throw MultipleIOException.createIOException(exceptions);\n       }\n     } else {\n       dfs.metaSave(pathname);\n       System.out.println(\"Created metasave file \" + pathname + \" in the log \" +\n           \"directory of namenode \" + dfs.getUri());\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int metaSave(String[] argv, int idx) throws IOException {\n    String pathname \u003d argv[idx];\n    DistributedFileSystem dfs \u003d getDFS();\n    Configuration dfsConf \u003d dfs.getConf();\n    URI dfsUri \u003d dfs.getUri();\n    boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(dfsConf, dfsUri);\n\n    if (isHaEnabled) {\n      String nsId \u003d dfsUri.getHost();\n      List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n          HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n          nsId, ClientProtocol.class);\n      List\u003cIOException\u003e exceptions \u003d new ArrayList\u003c\u003e();\n      for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n        try{\n          proxy.getProxy().metaSave(pathname);\n          System.out.println(\"Created metasave file \" + pathname\n              + \" in the log directory of namenode \" + proxy.getAddress());\n        } catch (IOException ioe){\n          System.out.println(\"Created metasave file \" + pathname\n              + \" in the log directory of namenode \" + proxy.getAddress()\n              + \" failed\");\n          exceptions.add(ioe);\n        }\n      }\n      if(!exceptions.isEmpty()){\n        throw MultipleIOException.createIOException(exceptions);\n      }\n    } else {\n      dfs.metaSave(pathname);\n      System.out.println(\"Created metasave file \" + pathname + \" in the log \" +\n          \"directory of namenode \" + dfs.getUri());\n    }\n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {}
    },
    "6f8003dc7bc9e8be7b0512c514d370c303faf003": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8185. Separate client related routines in HAUtil into a new class. Contributed by Haohui Mai.\n",
      "commitDate": "21/04/15 9:59 PM",
      "commitName": "6f8003dc7bc9e8be7b0512c514d370c303faf003",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "25/03/15 10:38 AM",
      "commitNameOld": "5e21e4ca377f68e030f8f3436cd93fd7a74dc5e0",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 27.47,
      "commitsBetweenForRepo": 221,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   public int metaSave(String[] argv, int idx) throws IOException {\n     String pathname \u003d argv[idx];\n     DistributedFileSystem dfs \u003d getDFS();\n     Configuration dfsConf \u003d dfs.getConf();\n     URI dfsUri \u003d dfs.getUri();\n-    boolean isHaEnabled \u003d HAUtil.isLogicalUri(dfsConf, dfsUri);\n+    boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(dfsConf, dfsUri);\n \n     if (isHaEnabled) {\n       String nsId \u003d dfsUri.getHost();\n       List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n           HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n           nsId, ClientProtocol.class);\n       for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n         proxy.getProxy().metaSave(pathname);\n         System.out.println(\"Created metasave file \" + pathname + \" in the log \"\n             + \"directory of namenode \" + proxy.getAddress());\n       }\n     } else {\n       dfs.metaSave(pathname);\n       System.out.println(\"Created metasave file \" + pathname + \" in the log \" +\n           \"directory of namenode \" + dfs.getUri());\n     }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int metaSave(String[] argv, int idx) throws IOException {\n    String pathname \u003d argv[idx];\n    DistributedFileSystem dfs \u003d getDFS();\n    Configuration dfsConf \u003d dfs.getConf();\n    URI dfsUri \u003d dfs.getUri();\n    boolean isHaEnabled \u003d HAUtilClient.isLogicalUri(dfsConf, dfsUri);\n\n    if (isHaEnabled) {\n      String nsId \u003d dfsUri.getHost();\n      List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n          HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n          nsId, ClientProtocol.class);\n      for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n        proxy.getProxy().metaSave(pathname);\n        System.out.println(\"Created metasave file \" + pathname + \" in the log \"\n            + \"directory of namenode \" + proxy.getAddress());\n      }\n    } else {\n      dfs.metaSave(pathname);\n      System.out.println(\"Created metasave file \" + pathname + \" in the log \" +\n          \"directory of namenode \" + dfs.getUri());\n    }\n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {}
    },
    "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6507. Improve DFSAdmin to support HA cluster better. (Contributd by Zesheng Wu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1604692 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/06/14 10:16 PM",
      "commitName": "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "11/06/14 6:27 PM",
      "commitNameOld": "34e9173c00f7e1ae55dec365850849c793cde8e3",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 11.16,
      "commitsBetweenForRepo": 76,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,24 @@\n   public int metaSave(String[] argv, int idx) throws IOException {\n     String pathname \u003d argv[idx];\n     DistributedFileSystem dfs \u003d getDFS();\n-    dfs.metaSave(pathname);\n-    System.out.println(\"Created metasave file \" + pathname + \" in the log \" +\n-        \"directory of namenode \" + dfs.getUri());\n+    Configuration dfsConf \u003d dfs.getConf();\n+    URI dfsUri \u003d dfs.getUri();\n+    boolean isHaEnabled \u003d HAUtil.isLogicalUri(dfsConf, dfsUri);\n+\n+    if (isHaEnabled) {\n+      String nsId \u003d dfsUri.getHost();\n+      List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n+          HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n+          nsId, ClientProtocol.class);\n+      for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n+        proxy.getProxy().metaSave(pathname);\n+        System.out.println(\"Created metasave file \" + pathname + \" in the log \"\n+            + \"directory of namenode \" + proxy.getAddress());\n+      }\n+    } else {\n+      dfs.metaSave(pathname);\n+      System.out.println(\"Created metasave file \" + pathname + \" in the log \" +\n+          \"directory of namenode \" + dfs.getUri());\n+    }\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int metaSave(String[] argv, int idx) throws IOException {\n    String pathname \u003d argv[idx];\n    DistributedFileSystem dfs \u003d getDFS();\n    Configuration dfsConf \u003d dfs.getConf();\n    URI dfsUri \u003d dfs.getUri();\n    boolean isHaEnabled \u003d HAUtil.isLogicalUri(dfsConf, dfsUri);\n\n    if (isHaEnabled) {\n      String nsId \u003d dfsUri.getHost();\n      List\u003cProxyAndInfo\u003cClientProtocol\u003e\u003e proxies \u003d\n          HAUtil.getProxiesForAllNameNodesInNameservice(dfsConf,\n          nsId, ClientProtocol.class);\n      for (ProxyAndInfo\u003cClientProtocol\u003e proxy : proxies) {\n        proxy.getProxy().metaSave(pathname);\n        System.out.println(\"Created metasave file \" + pathname + \" in the log \"\n            + \"directory of namenode \" + proxy.getAddress());\n      }\n    } else {\n      dfs.metaSave(pathname);\n      System.out.println(\"Created metasave file \" + pathname + \" in the log \" +\n          \"directory of namenode \" + dfs.getUri());\n    }\n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {}
    },
    "cf93dfba4e5b7849a3917caa78b29b8a4fb5ef12": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2963. Console Output is confusing while executing metasave (dfsadmin command). Contributed by Andrew Wang\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1374040 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/08/12 1:35 PM",
      "commitName": "cf93dfba4e5b7849a3917caa78b29b8a4fb5ef12",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "12/06/12 10:29 PM",
      "commitNameOld": "9cabf93e7adfaf94e8bbdbfe5758e4c563fe7768",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 64.63,
      "commitsBetweenForRepo": 325,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,8 @@\n   public int metaSave(String[] argv, int idx) throws IOException {\n     String pathname \u003d argv[idx];\n     DistributedFileSystem dfs \u003d getDFS();\n     dfs.metaSave(pathname);\n-    System.out.println(\"Created file \" + pathname + \" on server \" +\n-                       dfs.getUri());\n+    System.out.println(\"Created metasave file \" + pathname + \" in the log \" +\n+        \"directory of namenode \" + dfs.getUri());\n     return 0;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int metaSave(String[] argv, int idx) throws IOException {\n    String pathname \u003d argv[idx];\n    DistributedFileSystem dfs \u003d getDFS();\n    dfs.metaSave(pathname);\n    System.out.println(\"Created metasave file \" + pathname + \" in the log \" +\n        \"directory of namenode \" + dfs.getUri());\n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int metaSave(String[] argv, int idx) throws IOException {\n    String pathname \u003d argv[idx];\n    DistributedFileSystem dfs \u003d getDFS();\n    dfs.metaSave(pathname);\n    System.out.println(\"Created file \" + pathname + \" on server \" +\n                       dfs.getUri());\n    return 0;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int metaSave(String[] argv, int idx) throws IOException {\n    String pathname \u003d argv[idx];\n    DistributedFileSystem dfs \u003d getDFS();\n    dfs.metaSave(pathname);\n    System.out.println(\"Created file \" + pathname + \" on server \" +\n                       dfs.getUri());\n    return 0;\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,8 @@\n+  public int metaSave(String[] argv, int idx) throws IOException {\n+    String pathname \u003d argv[idx];\n+    DistributedFileSystem dfs \u003d getDFS();\n+    dfs.metaSave(pathname);\n+    System.out.println(\"Created file \" + pathname + \" on server \" +\n+                       dfs.getUri());\n+    return 0;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public int metaSave(String[] argv, int idx) throws IOException {\n    String pathname \u003d argv[idx];\n    DistributedFileSystem dfs \u003d getDFS();\n    dfs.metaSave(pathname);\n    System.out.println(\"Created file \" + pathname + \" on server \" +\n                       dfs.getUri());\n    return 0;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java"
    }
  }
}