{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatasetVolumeChecker.java",
  "functionName": "invokeCallback",
  "functionId": "invokeCallback",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/DatasetVolumeChecker.java",
  "functionStartLine": 405,
  "functionEndLine": 415,
  "numCommitsSeen": 11,
  "timeTaken": 1344,
  "changeHistory": [
    "f678080dbd25a218e0406463a3c3a1fc03680702",
    "eaaa32950cbae42a74e28e3db3f0cdb1ff158119"
  ],
  "changeHistoryShort": {
    "f678080dbd25a218e0406463a3c3a1fc03680702": "Ybodychange",
    "eaaa32950cbae42a74e28e3db3f0cdb1ff158119": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f678080dbd25a218e0406463a3c3a1fc03680702": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11182. Update DataNode to use DatasetVolumeChecker. Contributed by Arpit Agarwal.\n",
      "commitDate": "20/12/16 1:53 PM",
      "commitName": "f678080dbd25a218e0406463a3c3a1fc03680702",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "29/11/16 8:31 PM",
      "commitNameOld": "eaaa32950cbae42a74e28e3db3f0cdb1ff158119",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 20.72,
      "commitsBetweenForRepo": 121,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,11 @@\n     private void invokeCallback() {\n       try {\n-        latch.countDown();\n-\n-        if (numVolumes.decrementAndGet() \u003d\u003d 0 \u0026\u0026\n-            callback !\u003d null) {\n+        final long remaining \u003d volumeCounter.decrementAndGet();\n+        if (callback !\u003d null \u0026\u0026 remaining \u003d\u003d 0) {\n           callback.call(healthyVolumes, failedVolumes);\n         }\n       } catch(Exception e) {\n         // Propagating this exception is unlikely to be helpful.\n         LOG.warn(\"Unexpected exception\", e);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void invokeCallback() {\n      try {\n        final long remaining \u003d volumeCounter.decrementAndGet();\n        if (callback !\u003d null \u0026\u0026 remaining \u003d\u003d 0) {\n          callback.call(healthyVolumes, failedVolumes);\n        }\n      } catch(Exception e) {\n        // Propagating this exception is unlikely to be helpful.\n        LOG.warn(\"Unexpected exception\", e);\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/DatasetVolumeChecker.java",
      "extendedDetails": {}
    },
    "eaaa32950cbae42a74e28e3db3f0cdb1ff158119": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11149. Support for parallel checking of FsVolumes.\n",
      "commitDate": "29/11/16 8:31 PM",
      "commitName": "eaaa32950cbae42a74e28e3db3f0cdb1ff158119",
      "commitAuthor": "Arpit Agarwal",
      "diff": "@@ -0,0 +1,13 @@\n+    private void invokeCallback() {\n+      try {\n+        latch.countDown();\n+\n+        if (numVolumes.decrementAndGet() \u003d\u003d 0 \u0026\u0026\n+            callback !\u003d null) {\n+          callback.call(healthyVolumes, failedVolumes);\n+        }\n+      } catch(Exception e) {\n+        // Propagating this exception is unlikely to be helpful.\n+        LOG.warn(\"Unexpected exception\", e);\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private void invokeCallback() {\n      try {\n        latch.countDown();\n\n        if (numVolumes.decrementAndGet() \u003d\u003d 0 \u0026\u0026\n            callback !\u003d null) {\n          callback.call(healthyVolumes, failedVolumes);\n        }\n      } catch(Exception e) {\n        // Propagating this exception is unlikely to be helpful.\n        LOG.warn(\"Unexpected exception\", e);\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/checker/DatasetVolumeChecker.java"
    }
  }
}