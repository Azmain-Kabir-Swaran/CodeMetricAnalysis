{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "WebHdfsFileSystem.java",
  "functionName": "run",
  "functionId": "run",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
  "functionStartLine": 669,
  "functionEndLine": 671,
  "numCommitsSeen": 179,
  "timeTaken": 4493,
  "changeHistory": [
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
    "e4ee1d111be15ae6cca2f79be7ca73c204288d2b",
    "004d0854b7964d4f748f6e91b2d54a84928843f7",
    "7a2443e9f8b95816c7df61530cda29e8b040b12e",
    "cb787968c5deac3dd5d10291aae39c36656a1487"
  ],
  "changeHistoryShort": {
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": "Yfilerename",
    "e4ee1d111be15ae6cca2f79be7ca73c204288d2b": "Ymultichange(Yreturntypechange,Ybodychange)",
    "004d0854b7964d4f748f6e91b2d54a84928843f7": "Ybodychange",
    "7a2443e9f8b95816c7df61530cda29e8b040b12e": "Ymultichange(Yreturntypechange,Ybodychange)",
    "cb787968c5deac3dd5d10291aae39c36656a1487": "Yintroduced"
  },
  "changeHistoryDetails": {
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8052. Move WebHdfsFileSystem into hadoop-hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "23/04/15 5:33 PM",
      "commitName": "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "23/04/15 4:40 PM",
      "commitNameOld": "0b3f8957a87ada1a275c9904b211fdbdcefafb02",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    T run() throws IOException {\n      UserGroupInformation connectUgi \u003d ugi.getRealUser();\n      if (connectUgi \u003d\u003d null) {\n        connectUgi \u003d ugi;\n      }\n      if (op.getRequireAuth()) {\n        connectUgi.checkTGTAndReloginFromKeytab();\n      }\n      try {\n        // the entire lifecycle of the connection must be run inside the\n        // doAs to ensure authentication is performed correctly\n        return connectUgi.doAs(\n            new PrivilegedExceptionAction\u003cT\u003e() {\n              @Override\n              public T run() throws IOException {\n                return runWithRetry();\n              }\n            });\n      } catch (InterruptedException e) {\n        throw new IOException(e);\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java"
      }
    },
    "e4ee1d111be15ae6cca2f79be7ca73c204288d2b": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-6305. WebHdfs response decoding may throw RuntimeExceptions (Daryn Sharp via jeagles)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594273 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/05/14 9:40 AM",
      "commitName": "e4ee1d111be15ae6cca2f79be7ca73c204288d2b",
      "commitAuthor": "Jonathan Turner Eagles",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-6305. WebHdfs response decoding may throw RuntimeExceptions (Daryn Sharp via jeagles)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594273 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/05/14 9:40 AM",
          "commitName": "e4ee1d111be15ae6cca2f79be7ca73c204288d2b",
          "commitAuthor": "Jonathan Turner Eagles",
          "commitDateOld": "13/05/14 9:19 AM",
          "commitNameOld": "33ade356b35223654a077103ed7fbed89f3f2321",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,22 @@\n-    AbstractRunner run() throws IOException {\n+    T run() throws IOException {\n       UserGroupInformation connectUgi \u003d ugi.getRealUser();\n       if (connectUgi \u003d\u003d null) {\n         connectUgi \u003d ugi;\n       }\n       if (op.getRequireAuth()) {\n         connectUgi.checkTGTAndReloginFromKeytab();\n       }\n       try {\n         // the entire lifecycle of the connection must be run inside the\n         // doAs to ensure authentication is performed correctly\n         return connectUgi.doAs(\n-            new PrivilegedExceptionAction\u003cAbstractRunner\u003e() {\n+            new PrivilegedExceptionAction\u003cT\u003e() {\n               @Override\n-              public AbstractRunner run() throws IOException {\n+              public T run() throws IOException {\n                 return runWithRetry();\n               }\n             });\n       } catch (InterruptedException e) {\n         throw new IOException(e);\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    T run() throws IOException {\n      UserGroupInformation connectUgi \u003d ugi.getRealUser();\n      if (connectUgi \u003d\u003d null) {\n        connectUgi \u003d ugi;\n      }\n      if (op.getRequireAuth()) {\n        connectUgi.checkTGTAndReloginFromKeytab();\n      }\n      try {\n        // the entire lifecycle of the connection must be run inside the\n        // doAs to ensure authentication is performed correctly\n        return connectUgi.doAs(\n            new PrivilegedExceptionAction\u003cT\u003e() {\n              @Override\n              public T run() throws IOException {\n                return runWithRetry();\n              }\n            });\n      } catch (InterruptedException e) {\n        throw new IOException(e);\n      }\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {
            "oldValue": "AbstractRunner",
            "newValue": "T"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6305. WebHdfs response decoding may throw RuntimeExceptions (Daryn Sharp via jeagles)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594273 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "13/05/14 9:40 AM",
          "commitName": "e4ee1d111be15ae6cca2f79be7ca73c204288d2b",
          "commitAuthor": "Jonathan Turner Eagles",
          "commitDateOld": "13/05/14 9:19 AM",
          "commitNameOld": "33ade356b35223654a077103ed7fbed89f3f2321",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,22 +1,22 @@\n-    AbstractRunner run() throws IOException {\n+    T run() throws IOException {\n       UserGroupInformation connectUgi \u003d ugi.getRealUser();\n       if (connectUgi \u003d\u003d null) {\n         connectUgi \u003d ugi;\n       }\n       if (op.getRequireAuth()) {\n         connectUgi.checkTGTAndReloginFromKeytab();\n       }\n       try {\n         // the entire lifecycle of the connection must be run inside the\n         // doAs to ensure authentication is performed correctly\n         return connectUgi.doAs(\n-            new PrivilegedExceptionAction\u003cAbstractRunner\u003e() {\n+            new PrivilegedExceptionAction\u003cT\u003e() {\n               @Override\n-              public AbstractRunner run() throws IOException {\n+              public T run() throws IOException {\n                 return runWithRetry();\n               }\n             });\n       } catch (InterruptedException e) {\n         throw new IOException(e);\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    T run() throws IOException {\n      UserGroupInformation connectUgi \u003d ugi.getRealUser();\n      if (connectUgi \u003d\u003d null) {\n        connectUgi \u003d ugi;\n      }\n      if (op.getRequireAuth()) {\n        connectUgi.checkTGTAndReloginFromKeytab();\n      }\n      try {\n        // the entire lifecycle of the connection must be run inside the\n        // doAs to ensure authentication is performed correctly\n        return connectUgi.doAs(\n            new PrivilegedExceptionAction\u003cT\u003e() {\n              @Override\n              public T run() throws IOException {\n                return runWithRetry();\n              }\n            });\n      } catch (InterruptedException e) {\n        throw new IOException(e);\n      }\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "004d0854b7964d4f748f6e91b2d54a84928843f7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4564. Ensure webhdfs returns correct HTTP response codes for denied operations. Contributed by Daryn Sharp.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1583241 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/03/14 12:25 AM",
      "commitName": "004d0854b7964d4f748f6e91b2d54a84928843f7",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "10/03/14 1:48 PM",
      "commitNameOld": "b674dfd480ab8bfdaab390778b283dbf86ae8575",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 20.44,
      "commitsBetweenForRepo": 165,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,22 @@\n     AbstractRunner run() throws IOException {\n-      /**\n-       * Do the real work.\n-       *\n-       * There are three cases that the code inside the loop can throw an\n-       * IOException:\n-       *\n-       * \u003cul\u003e\n-       * \u003cli\u003eThe connection has failed (e.g., ConnectException,\n-       * @see FailoverOnNetworkExceptionRetry for more details)\u003c/li\u003e\n-       * \u003cli\u003eThe namenode enters the standby state (i.e., StandbyException).\u003c/li\u003e\n-       * \u003cli\u003eThe server returns errors for the command (i.e., RemoteException)\u003c/li\u003e\n-       * \u003c/ul\u003e\n-       *\n-       * The call to shouldRetry() will conduct the retry policy. The policy\n-       * examines the exception and swallows it if it decides to rerun the work.\n-       */\n-      for(int retry \u003d 0; ; retry++) {\n-        try {\n-          init();\n-          if (op.getDoOutput()) {\n-            twoStepWrite();\n-          } else {\n-            getResponse(op !\u003d GetOpParam.Op.OPEN);\n-          }\n-          return this;\n-        } catch(IOException ioe) {\n-          shouldRetry(ioe, retry);\n-        }\n+      UserGroupInformation connectUgi \u003d ugi.getRealUser();\n+      if (connectUgi \u003d\u003d null) {\n+        connectUgi \u003d ugi;\n+      }\n+      if (op.getRequireAuth()) {\n+        connectUgi.checkTGTAndReloginFromKeytab();\n+      }\n+      try {\n+        // the entire lifecycle of the connection must be run inside the\n+        // doAs to ensure authentication is performed correctly\n+        return connectUgi.doAs(\n+            new PrivilegedExceptionAction\u003cAbstractRunner\u003e() {\n+              @Override\n+              public AbstractRunner run() throws IOException {\n+                return runWithRetry();\n+              }\n+            });\n+      } catch (InterruptedException e) {\n+        throw new IOException(e);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    AbstractRunner run() throws IOException {\n      UserGroupInformation connectUgi \u003d ugi.getRealUser();\n      if (connectUgi \u003d\u003d null) {\n        connectUgi \u003d ugi;\n      }\n      if (op.getRequireAuth()) {\n        connectUgi.checkTGTAndReloginFromKeytab();\n      }\n      try {\n        // the entire lifecycle of the connection must be run inside the\n        // doAs to ensure authentication is performed correctly\n        return connectUgi.doAs(\n            new PrivilegedExceptionAction\u003cAbstractRunner\u003e() {\n              @Override\n              public AbstractRunner run() throws IOException {\n                return runWithRetry();\n              }\n            });\n      } catch (InterruptedException e) {\n        throw new IOException(e);\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "7a2443e9f8b95816c7df61530cda29e8b040b12e": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-5122. Support failover and retry in WebHdfsFileSystem for NN HA. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1524562 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/09/13 1:47 PM",
      "commitName": "7a2443e9f8b95816c7df61530cda29e8b040b12e",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-5122. Support failover and retry in WebHdfsFileSystem for NN HA. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1524562 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/09/13 1:47 PM",
          "commitName": "7a2443e9f8b95816c7df61530cda29e8b040b12e",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "18/09/13 10:29 AM",
          "commitNameOld": "f278a491dcec249a2ec22e14b645d8f890278be5",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 0.14,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,31 @@\n-    Runner run() throws IOException {\n+    AbstractRunner run() throws IOException {\n+      /**\n+       * Do the real work.\n+       *\n+       * There are three cases that the code inside the loop can throw an\n+       * IOException:\n+       *\n+       * \u003cul\u003e\n+       * \u003cli\u003eThe connection has failed (e.g., ConnectException,\n+       * @see FailoverOnNetworkExceptionRetry for more details)\u003c/li\u003e\n+       * \u003cli\u003eThe namenode enters the standby state (i.e., StandbyException).\u003c/li\u003e\n+       * \u003cli\u003eThe server returns errors for the command (i.e., RemoteException)\u003c/li\u003e\n+       * \u003c/ul\u003e\n+       *\n+       * The call to shouldRetry() will conduct the retry policy. The policy\n+       * examines the exception and swallows it if it decides to rerun the work.\n+       */\n       for(int retry \u003d 0; ; retry++) {\n         try {\n           init();\n           if (op.getDoOutput()) {\n             twoStepWrite();\n           } else {\n             getResponse(op !\u003d GetOpParam.Op.OPEN);\n           }\n           return this;\n         } catch(IOException ioe) {\n           shouldRetry(ioe, retry);\n         }\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    AbstractRunner run() throws IOException {\n      /**\n       * Do the real work.\n       *\n       * There are three cases that the code inside the loop can throw an\n       * IOException:\n       *\n       * \u003cul\u003e\n       * \u003cli\u003eThe connection has failed (e.g., ConnectException,\n       * @see FailoverOnNetworkExceptionRetry for more details)\u003c/li\u003e\n       * \u003cli\u003eThe namenode enters the standby state (i.e., StandbyException).\u003c/li\u003e\n       * \u003cli\u003eThe server returns errors for the command (i.e., RemoteException)\u003c/li\u003e\n       * \u003c/ul\u003e\n       *\n       * The call to shouldRetry() will conduct the retry policy. The policy\n       * examines the exception and swallows it if it decides to rerun the work.\n       */\n      for(int retry \u003d 0; ; retry++) {\n        try {\n          init();\n          if (op.getDoOutput()) {\n            twoStepWrite();\n          } else {\n            getResponse(op !\u003d GetOpParam.Op.OPEN);\n          }\n          return this;\n        } catch(IOException ioe) {\n          shouldRetry(ioe, retry);\n        }\n      }\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {
            "oldValue": "Runner",
            "newValue": "AbstractRunner"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5122. Support failover and retry in WebHdfsFileSystem for NN HA. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1524562 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/09/13 1:47 PM",
          "commitName": "7a2443e9f8b95816c7df61530cda29e8b040b12e",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "18/09/13 10:29 AM",
          "commitNameOld": "f278a491dcec249a2ec22e14b645d8f890278be5",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 0.14,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,31 @@\n-    Runner run() throws IOException {\n+    AbstractRunner run() throws IOException {\n+      /**\n+       * Do the real work.\n+       *\n+       * There are three cases that the code inside the loop can throw an\n+       * IOException:\n+       *\n+       * \u003cul\u003e\n+       * \u003cli\u003eThe connection has failed (e.g., ConnectException,\n+       * @see FailoverOnNetworkExceptionRetry for more details)\u003c/li\u003e\n+       * \u003cli\u003eThe namenode enters the standby state (i.e., StandbyException).\u003c/li\u003e\n+       * \u003cli\u003eThe server returns errors for the command (i.e., RemoteException)\u003c/li\u003e\n+       * \u003c/ul\u003e\n+       *\n+       * The call to shouldRetry() will conduct the retry policy. The policy\n+       * examines the exception and swallows it if it decides to rerun the work.\n+       */\n       for(int retry \u003d 0; ; retry++) {\n         try {\n           init();\n           if (op.getDoOutput()) {\n             twoStepWrite();\n           } else {\n             getResponse(op !\u003d GetOpParam.Op.OPEN);\n           }\n           return this;\n         } catch(IOException ioe) {\n           shouldRetry(ioe, retry);\n         }\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    AbstractRunner run() throws IOException {\n      /**\n       * Do the real work.\n       *\n       * There are three cases that the code inside the loop can throw an\n       * IOException:\n       *\n       * \u003cul\u003e\n       * \u003cli\u003eThe connection has failed (e.g., ConnectException,\n       * @see FailoverOnNetworkExceptionRetry for more details)\u003c/li\u003e\n       * \u003cli\u003eThe namenode enters the standby state (i.e., StandbyException).\u003c/li\u003e\n       * \u003cli\u003eThe server returns errors for the command (i.e., RemoteException)\u003c/li\u003e\n       * \u003c/ul\u003e\n       *\n       * The call to shouldRetry() will conduct the retry policy. The policy\n       * examines the exception and swallows it if it decides to rerun the work.\n       */\n      for(int retry \u003d 0; ; retry++) {\n        try {\n          init();\n          if (op.getDoOutput()) {\n            twoStepWrite();\n          } else {\n            getResponse(op !\u003d GetOpParam.Op.OPEN);\n          }\n          return this;\n        } catch(IOException ioe) {\n          shouldRetry(ioe, retry);\n        }\n      }\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "cb787968c5deac3dd5d10291aae39c36656a1487": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3667.  Add retry support to WebHdfsFileSystem.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1367841 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/07/12 6:41 PM",
      "commitName": "cb787968c5deac3dd5d10291aae39c36656a1487",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,15 @@\n+    Runner run() throws IOException {\n+      for(int retry \u003d 0; ; retry++) {\n+        try {\n+          init();\n+          if (op.getDoOutput()) {\n+            twoStepWrite();\n+          } else {\n+            getResponse(op !\u003d GetOpParam.Op.OPEN);\n+          }\n+          return this;\n+        } catch(IOException ioe) {\n+          shouldRetry(ioe, retry);\n+        }\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    Runner run() throws IOException {\n      for(int retry \u003d 0; ; retry++) {\n        try {\n          init();\n          if (op.getDoOutput()) {\n            twoStepWrite();\n          } else {\n            getResponse(op !\u003d GetOpParam.Op.OPEN);\n          }\n          return this;\n        } catch(IOException ioe) {\n          shouldRetry(ioe, retry);\n        }\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java"
    }
  }
}