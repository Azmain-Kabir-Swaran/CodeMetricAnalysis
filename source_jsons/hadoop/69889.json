{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AbfsHttpOperation.java",
  "functionName": "processStorageErrorResponse",
  "functionId": "processStorageErrorResponse",
  "sourceFilePath": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java",
  "functionStartLine": 428,
  "functionEndLine": 465,
  "numCommitsSeen": 11,
  "timeTaken": 970,
  "changeHistory": [
    "b54b0c1b676c616aef9574e4e88ea30c314c79dc",
    "f044deedbbfee0812316d587139cb828f27172e9"
  ],
  "changeHistoryShort": {
    "b54b0c1b676c616aef9574e4e88ea30c314c79dc": "Ybodychange",
    "f044deedbbfee0812316d587139cb828f27172e9": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b54b0c1b676c616aef9574e4e88ea30c314c79dc": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15659. Code changes for bug fix and new tests.\nContributed by Da Zhou.\n",
      "commitDate": "17/09/18 12:54 PM",
      "commitName": "b54b0c1b676c616aef9574e4e88ea30c314c79dc",
      "commitAuthor": "Thomas Marquardt",
      "commitDateOld": "17/09/18 12:54 PM",
      "commitNameOld": "ce03a93f78c4d97ccb48a3906fcd77ad0ac756be",
      "commitAuthorOld": "Thomas Marquardt",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,38 @@\n   private void processStorageErrorResponse() {\n     try (InputStream stream \u003d connection.getErrorStream()) {\n       if (stream \u003d\u003d null) {\n         return;\n       }\n       JsonFactory jf \u003d new JsonFactory();\n-      try (JsonParser jp \u003d jf.createParser(stream)) {\n+      try (JsonParser jp \u003d jf.createJsonParser(stream)) {\n         String fieldName, fieldValue;\n         jp.nextToken();  // START_OBJECT - {\n         jp.nextToken();  // FIELD_NAME - \"error\":\n         jp.nextToken();  // START_OBJECT - {\n         jp.nextToken();\n         while (jp.hasCurrentToken()) {\n           if (jp.getCurrentToken() \u003d\u003d JsonToken.FIELD_NAME) {\n             fieldName \u003d jp.getCurrentName();\n             jp.nextToken();\n             fieldValue \u003d jp.getText();\n             switch (fieldName) {\n               case \"code\":\n                 storageErrorCode \u003d fieldValue;\n                 break;\n               case \"message\":\n                 storageErrorMessage \u003d fieldValue;\n                 break;\n               default:\n                 break;\n             }\n           }\n           jp.nextToken();\n         }\n       }\n     } catch (IOException ex) {\n       // Ignore errors that occur while attempting to parse the storage\n       // error, since the response may have been handled by the HTTP driver\n       // or for other reasons have an unexpected\n-      this.LOG.debug(\"ExpectedError: \", ex);\n+      LOG.debug(\"ExpectedError: \", ex);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void processStorageErrorResponse() {\n    try (InputStream stream \u003d connection.getErrorStream()) {\n      if (stream \u003d\u003d null) {\n        return;\n      }\n      JsonFactory jf \u003d new JsonFactory();\n      try (JsonParser jp \u003d jf.createJsonParser(stream)) {\n        String fieldName, fieldValue;\n        jp.nextToken();  // START_OBJECT - {\n        jp.nextToken();  // FIELD_NAME - \"error\":\n        jp.nextToken();  // START_OBJECT - {\n        jp.nextToken();\n        while (jp.hasCurrentToken()) {\n          if (jp.getCurrentToken() \u003d\u003d JsonToken.FIELD_NAME) {\n            fieldName \u003d jp.getCurrentName();\n            jp.nextToken();\n            fieldValue \u003d jp.getText();\n            switch (fieldName) {\n              case \"code\":\n                storageErrorCode \u003d fieldValue;\n                break;\n              case \"message\":\n                storageErrorMessage \u003d fieldValue;\n                break;\n              default:\n                break;\n            }\n          }\n          jp.nextToken();\n        }\n      }\n    } catch (IOException ex) {\n      // Ignore errors that occur while attempting to parse the storage\n      // error, since the response may have been handled by the HTTP driver\n      // or for other reasons have an unexpected\n      LOG.debug(\"ExpectedError: \", ex);\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java",
      "extendedDetails": {}
    },
    "f044deedbbfee0812316d587139cb828f27172e9": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-15407. HADOOP-15540. Support Windows Azure Storage - Blob file system \"ABFS\" in Hadoop: Core Commit.\n\nContributed by Shane Mainali, Thomas Marquardt, Zichen Sun, Georgi Chalakov, Esfandiar Manii, Amit Singh, Dana Kaban, Da Zhou, Junhua Gu, Saher Ahwal, Saurabh Pant, James Baker, Shaoyu Zhang, Lawrence Chen, Kevin Chen and Steve Loughran\n",
      "commitDate": "17/09/18 12:54 PM",
      "commitName": "f044deedbbfee0812316d587139cb828f27172e9",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,38 @@\n+  private void processStorageErrorResponse() {\n+    try (InputStream stream \u003d connection.getErrorStream()) {\n+      if (stream \u003d\u003d null) {\n+        return;\n+      }\n+      JsonFactory jf \u003d new JsonFactory();\n+      try (JsonParser jp \u003d jf.createParser(stream)) {\n+        String fieldName, fieldValue;\n+        jp.nextToken();  // START_OBJECT - {\n+        jp.nextToken();  // FIELD_NAME - \"error\":\n+        jp.nextToken();  // START_OBJECT - {\n+        jp.nextToken();\n+        while (jp.hasCurrentToken()) {\n+          if (jp.getCurrentToken() \u003d\u003d JsonToken.FIELD_NAME) {\n+            fieldName \u003d jp.getCurrentName();\n+            jp.nextToken();\n+            fieldValue \u003d jp.getText();\n+            switch (fieldName) {\n+              case \"code\":\n+                storageErrorCode \u003d fieldValue;\n+                break;\n+              case \"message\":\n+                storageErrorMessage \u003d fieldValue;\n+                break;\n+              default:\n+                break;\n+            }\n+          }\n+          jp.nextToken();\n+        }\n+      }\n+    } catch (IOException ex) {\n+      // Ignore errors that occur while attempting to parse the storage\n+      // error, since the response may have been handled by the HTTP driver\n+      // or for other reasons have an unexpected\n+      this.LOG.debug(\"ExpectedError: \", ex);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void processStorageErrorResponse() {\n    try (InputStream stream \u003d connection.getErrorStream()) {\n      if (stream \u003d\u003d null) {\n        return;\n      }\n      JsonFactory jf \u003d new JsonFactory();\n      try (JsonParser jp \u003d jf.createParser(stream)) {\n        String fieldName, fieldValue;\n        jp.nextToken();  // START_OBJECT - {\n        jp.nextToken();  // FIELD_NAME - \"error\":\n        jp.nextToken();  // START_OBJECT - {\n        jp.nextToken();\n        while (jp.hasCurrentToken()) {\n          if (jp.getCurrentToken() \u003d\u003d JsonToken.FIELD_NAME) {\n            fieldName \u003d jp.getCurrentName();\n            jp.nextToken();\n            fieldValue \u003d jp.getText();\n            switch (fieldName) {\n              case \"code\":\n                storageErrorCode \u003d fieldValue;\n                break;\n              case \"message\":\n                storageErrorMessage \u003d fieldValue;\n                break;\n              default:\n                break;\n            }\n          }\n          jp.nextToken();\n        }\n      }\n    } catch (IOException ex) {\n      // Ignore errors that occur while attempting to parse the storage\n      // error, since the response may have been handled by the HTTP driver\n      // or for other reasons have an unexpected\n      this.LOG.debug(\"ExpectedError: \", ex);\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java"
    }
  }
}