{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSDirectory.java",
  "functionName": "getAuditFileInfo",
  "functionId": "getAuditFileInfo___iip-INodesInPath",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
  "functionStartLine": 1939,
  "functionEndLine": 1978,
  "numCommitsSeen": 542,
  "timeTaken": 6686,
  "changeHistory": [
    "9b90e52f1ec22c18cd535af2a569defcef65b093",
    "ec252ce0fc0998ce13f31af3440c08a236328e5a",
    "3ca4d6ddfd199c95677721ff3bcb95d1da45bd88",
    "22fc46d7659972ff016ccf1c6f781f0c160be26f",
    "53a28afe293e5bf185c8d4f2c7aea212e66015c2",
    "65f2a4ee600dfffa5203450261da3c1989de25a9",
    "0af44ea8462437f8e7a8271b15a19677fd7f05a1",
    "8caf537afabc70b0c74e0a29aea0cc2935ecb162"
  ],
  "changeHistoryShort": {
    "9b90e52f1ec22c18cd535af2a569defcef65b093": "Ymultichange(Yreturntypechange,Ybodychange)",
    "ec252ce0fc0998ce13f31af3440c08a236328e5a": "Ybodychange",
    "3ca4d6ddfd199c95677721ff3bcb95d1da45bd88": "Ybodychange",
    "22fc46d7659972ff016ccf1c6f781f0c160be26f": "Ybodychange",
    "53a28afe293e5bf185c8d4f2c7aea212e66015c2": "Ybodychange",
    "65f2a4ee600dfffa5203450261da3c1989de25a9": "Ymultichange(Yparameterchange,Ybodychange)",
    "0af44ea8462437f8e7a8271b15a19677fd7f05a1": "Ybodychange",
    "8caf537afabc70b0c74e0a29aea0cc2935ecb162": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9b90e52f1ec22c18cd535af2a569defcef65b093": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-11641. Reduce cost of audit logging by using FileStatus instead of HdfsFileStatus. Contributed by Daryn Sharp.\n",
      "commitDate": "16/05/17 9:28 AM",
      "commitName": "9b90e52f1ec22c18cd535af2a569defcef65b093",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-11641. Reduce cost of audit logging by using FileStatus instead of HdfsFileStatus. Contributed by Daryn Sharp.\n",
          "commitDate": "16/05/17 9:28 AM",
          "commitName": "9b90e52f1ec22c18cd535af2a569defcef65b093",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "03/03/17 1:00 PM",
          "commitNameOld": "3085a604300ed76d06a0011bd5555e419897b6cd",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 73.81,
          "commitsBetweenForRepo": 419,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,40 @@\n-  HdfsFileStatus getAuditFileInfo(INodesInPath iip)\n+  FileStatus getAuditFileInfo(INodesInPath iip)\n       throws IOException {\n-    return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n-        ? FSDirStatAndListingOp.getFileInfo(this, iip, false) : null;\n+    if (!namesystem.isAuditEnabled() || !namesystem.isExternalInvocation()) {\n+      return null;\n+    }\n+\n+    final INode inode \u003d iip.getLastINode();\n+    if (inode \u003d\u003d null) {\n+      return null;\n+    }\n+    final int snapshot \u003d iip.getPathSnapshotId();\n+\n+    Path symlink \u003d null;\n+    long size \u003d 0;     // length is zero for directories\n+    short replication \u003d 0;\n+    long blocksize \u003d 0;\n+\n+    if (inode.isFile()) {\n+      final INodeFile fileNode \u003d inode.asFile();\n+      size \u003d fileNode.computeFileSize(snapshot);\n+      replication \u003d fileNode.getFileReplication(snapshot);\n+      blocksize \u003d fileNode.getPreferredBlockSize();\n+    } else if (inode.isSymlink()) {\n+      symlink \u003d new Path(\n+          DFSUtilClient.bytes2String(inode.asSymlink().getSymlink()));\n+    }\n+\n+    return new FileStatus(\n+        size,\n+        inode.isDirectory(),\n+        replication,\n+        blocksize,\n+        inode.getModificationTime(snapshot),\n+        inode.getAccessTime(snapshot),\n+        inode.getFsPermission(snapshot),\n+        inode.getUserName(snapshot),\n+        inode.getGroupName(snapshot),\n+        symlink,\n+        new Path(iip.getPath()));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  FileStatus getAuditFileInfo(INodesInPath iip)\n      throws IOException {\n    if (!namesystem.isAuditEnabled() || !namesystem.isExternalInvocation()) {\n      return null;\n    }\n\n    final INode inode \u003d iip.getLastINode();\n    if (inode \u003d\u003d null) {\n      return null;\n    }\n    final int snapshot \u003d iip.getPathSnapshotId();\n\n    Path symlink \u003d null;\n    long size \u003d 0;     // length is zero for directories\n    short replication \u003d 0;\n    long blocksize \u003d 0;\n\n    if (inode.isFile()) {\n      final INodeFile fileNode \u003d inode.asFile();\n      size \u003d fileNode.computeFileSize(snapshot);\n      replication \u003d fileNode.getFileReplication(snapshot);\n      blocksize \u003d fileNode.getPreferredBlockSize();\n    } else if (inode.isSymlink()) {\n      symlink \u003d new Path(\n          DFSUtilClient.bytes2String(inode.asSymlink().getSymlink()));\n    }\n\n    return new FileStatus(\n        size,\n        inode.isDirectory(),\n        replication,\n        blocksize,\n        inode.getModificationTime(snapshot),\n        inode.getAccessTime(snapshot),\n        inode.getFsPermission(snapshot),\n        inode.getUserName(snapshot),\n        inode.getGroupName(snapshot),\n        symlink,\n        new Path(iip.getPath()));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "HdfsFileStatus",
            "newValue": "FileStatus"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-11641. Reduce cost of audit logging by using FileStatus instead of HdfsFileStatus. Contributed by Daryn Sharp.\n",
          "commitDate": "16/05/17 9:28 AM",
          "commitName": "9b90e52f1ec22c18cd535af2a569defcef65b093",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "03/03/17 1:00 PM",
          "commitNameOld": "3085a604300ed76d06a0011bd5555e419897b6cd",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 73.81,
          "commitsBetweenForRepo": 419,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,40 @@\n-  HdfsFileStatus getAuditFileInfo(INodesInPath iip)\n+  FileStatus getAuditFileInfo(INodesInPath iip)\n       throws IOException {\n-    return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n-        ? FSDirStatAndListingOp.getFileInfo(this, iip, false) : null;\n+    if (!namesystem.isAuditEnabled() || !namesystem.isExternalInvocation()) {\n+      return null;\n+    }\n+\n+    final INode inode \u003d iip.getLastINode();\n+    if (inode \u003d\u003d null) {\n+      return null;\n+    }\n+    final int snapshot \u003d iip.getPathSnapshotId();\n+\n+    Path symlink \u003d null;\n+    long size \u003d 0;     // length is zero for directories\n+    short replication \u003d 0;\n+    long blocksize \u003d 0;\n+\n+    if (inode.isFile()) {\n+      final INodeFile fileNode \u003d inode.asFile();\n+      size \u003d fileNode.computeFileSize(snapshot);\n+      replication \u003d fileNode.getFileReplication(snapshot);\n+      blocksize \u003d fileNode.getPreferredBlockSize();\n+    } else if (inode.isSymlink()) {\n+      symlink \u003d new Path(\n+          DFSUtilClient.bytes2String(inode.asSymlink().getSymlink()));\n+    }\n+\n+    return new FileStatus(\n+        size,\n+        inode.isDirectory(),\n+        replication,\n+        blocksize,\n+        inode.getModificationTime(snapshot),\n+        inode.getAccessTime(snapshot),\n+        inode.getFsPermission(snapshot),\n+        inode.getUserName(snapshot),\n+        inode.getGroupName(snapshot),\n+        symlink,\n+        new Path(iip.getPath()));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  FileStatus getAuditFileInfo(INodesInPath iip)\n      throws IOException {\n    if (!namesystem.isAuditEnabled() || !namesystem.isExternalInvocation()) {\n      return null;\n    }\n\n    final INode inode \u003d iip.getLastINode();\n    if (inode \u003d\u003d null) {\n      return null;\n    }\n    final int snapshot \u003d iip.getPathSnapshotId();\n\n    Path symlink \u003d null;\n    long size \u003d 0;     // length is zero for directories\n    short replication \u003d 0;\n    long blocksize \u003d 0;\n\n    if (inode.isFile()) {\n      final INodeFile fileNode \u003d inode.asFile();\n      size \u003d fileNode.computeFileSize(snapshot);\n      replication \u003d fileNode.getFileReplication(snapshot);\n      blocksize \u003d fileNode.getPreferredBlockSize();\n    } else if (inode.isSymlink()) {\n      symlink \u003d new Path(\n          DFSUtilClient.bytes2String(inode.asSymlink().getSymlink()));\n    }\n\n    return new FileStatus(\n        size,\n        inode.isDirectory(),\n        replication,\n        blocksize,\n        inode.getModificationTime(snapshot),\n        inode.getAccessTime(snapshot),\n        inode.getFsPermission(snapshot),\n        inode.getUserName(snapshot),\n        inode.getGroupName(snapshot),\n        symlink,\n        new Path(iip.getPath()));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {}
        }
      ]
    },
    "ec252ce0fc0998ce13f31af3440c08a236328e5a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10762. Pass IIP for file status related methods\n",
      "commitDate": "24/08/16 6:46 AM",
      "commitName": "ec252ce0fc0998ce13f31af3440c08a236328e5a",
      "commitAuthor": "Daryn Sharp",
      "commitDateOld": "22/08/16 2:57 PM",
      "commitNameOld": "3ca4d6ddfd199c95677721ff3bcb95d1da45bd88",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 1.66,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,5 @@\n   HdfsFileStatus getAuditFileInfo(INodesInPath iip)\n       throws IOException {\n     return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n-        ? FSDirStatAndListingOp.getFileInfo(this, iip.getPath(), iip, false,\n-            false) : null;\n+        ? FSDirStatAndListingOp.getFileInfo(this, iip, false) : null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HdfsFileStatus getAuditFileInfo(INodesInPath iip)\n      throws IOException {\n    return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n        ? FSDirStatAndListingOp.getFileInfo(this, iip, false) : null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "3ca4d6ddfd199c95677721ff3bcb95d1da45bd88": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-10762. Pass IIP for file status related methods. Contributed by Daryn Sharp.\"\n\nThis reverts commit 22fc46d7659972ff016ccf1c6f781f0c160be26f.\n",
      "commitDate": "22/08/16 2:57 PM",
      "commitName": "3ca4d6ddfd199c95677721ff3bcb95d1da45bd88",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "22/08/16 1:37 PM",
      "commitNameOld": "22fc46d7659972ff016ccf1c6f781f0c160be26f",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.06,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,6 @@\n   HdfsFileStatus getAuditFileInfo(INodesInPath iip)\n       throws IOException {\n     return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n-        ? FSDirStatAndListingOp.getFileInfo(this, iip, false) : null;\n+        ? FSDirStatAndListingOp.getFileInfo(this, iip.getPath(), iip, false,\n+            false) : null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HdfsFileStatus getAuditFileInfo(INodesInPath iip)\n      throws IOException {\n    return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n        ? FSDirStatAndListingOp.getFileInfo(this, iip.getPath(), iip, false,\n            false) : null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "22fc46d7659972ff016ccf1c6f781f0c160be26f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10762. Pass IIP for file status related methods. Contributed by Daryn Sharp.\n",
      "commitDate": "22/08/16 1:37 PM",
      "commitName": "22fc46d7659972ff016ccf1c6f781f0c160be26f",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "17/08/16 1:53 PM",
      "commitNameOld": "869393643de23dcb010cc33091c8eb398de0fd6c",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 4.99,
      "commitsBetweenForRepo": 29,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,5 @@\n   HdfsFileStatus getAuditFileInfo(INodesInPath iip)\n       throws IOException {\n     return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n-        ? FSDirStatAndListingOp.getFileInfo(this, iip.getPath(), iip, false,\n-            false) : null;\n+        ? FSDirStatAndListingOp.getFileInfo(this, iip, false) : null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HdfsFileStatus getAuditFileInfo(INodesInPath iip)\n      throws IOException {\n    return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n        ? FSDirStatAndListingOp.getFileInfo(this, iip, false) : null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "53a28afe293e5bf185c8d4f2c7aea212e66015c2": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6826. Plugin interface to enable delegation of HDFS authorization assertions. Contributed by Arun Suresh.\n",
      "commitDate": "24/03/15 4:02 PM",
      "commitName": "53a28afe293e5bf185c8d4f2c7aea212e66015c2",
      "commitAuthor": "Jitendra Pandey",
      "commitDateOld": "20/03/15 11:50 AM",
      "commitNameOld": "d368d3647a858644b9fcd3be33d9fea2a6962f69",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 4.18,
      "commitsBetweenForRepo": 40,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,6 @@\n   HdfsFileStatus getAuditFileInfo(INodesInPath iip)\n       throws IOException {\n     return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n-        ? FSDirStatAndListingOp.getFileInfo(this, iip, false, false) : null;\n+        ? FSDirStatAndListingOp.getFileInfo(this, iip.getPath(), iip, false,\n+            false) : null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HdfsFileStatus getAuditFileInfo(INodesInPath iip)\n      throws IOException {\n    return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n        ? FSDirStatAndListingOp.getFileInfo(this, iip.getPath(), iip, false,\n            false) : null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "65f2a4ee600dfffa5203450261da3c1989de25a9": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7543. Avoid path resolution when getting FileStatus for audit logs. Contributed by Haohui Mai.\n",
      "commitDate": "18/12/14 11:25 AM",
      "commitName": "65f2a4ee600dfffa5203450261da3c1989de25a9",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7543. Avoid path resolution when getting FileStatus for audit logs. Contributed by Haohui Mai.\n",
          "commitDate": "18/12/14 11:25 AM",
          "commitName": "65f2a4ee600dfffa5203450261da3c1989de25a9",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "17/12/14 2:48 PM",
          "commitNameOld": "0da1330bfd3080a7ad95a4b48ba7b7ac89c3608f",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 0.86,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,5 @@\n-  HdfsFileStatus getAuditFileInfo(String path, boolean resolveSymlink)\n-    throws IOException {\n+  HdfsFileStatus getAuditFileInfo(INodesInPath iip)\n+      throws IOException {\n     return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n-      ? FSDirStatAndListingOp.getFileInfo(this, path, resolveSymlink, false,\n-        false) : null;\n+        ? FSDirStatAndListingOp.getFileInfo(this, iip, false, false) : null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HdfsFileStatus getAuditFileInfo(INodesInPath iip)\n      throws IOException {\n    return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n        ? FSDirStatAndListingOp.getFileInfo(this, iip, false, false) : null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[path-String, resolveSymlink-boolean]",
            "newValue": "[iip-INodesInPath]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7543. Avoid path resolution when getting FileStatus for audit logs. Contributed by Haohui Mai.\n",
          "commitDate": "18/12/14 11:25 AM",
          "commitName": "65f2a4ee600dfffa5203450261da3c1989de25a9",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "17/12/14 2:48 PM",
          "commitNameOld": "0da1330bfd3080a7ad95a4b48ba7b7ac89c3608f",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 0.86,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,6 +1,5 @@\n-  HdfsFileStatus getAuditFileInfo(String path, boolean resolveSymlink)\n-    throws IOException {\n+  HdfsFileStatus getAuditFileInfo(INodesInPath iip)\n+      throws IOException {\n     return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n-      ? FSDirStatAndListingOp.getFileInfo(this, path, resolveSymlink, false,\n-        false) : null;\n+        ? FSDirStatAndListingOp.getFileInfo(this, iip, false, false) : null;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HdfsFileStatus getAuditFileInfo(INodesInPath iip)\n      throws IOException {\n    return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n        ? FSDirStatAndListingOp.getFileInfo(this, iip, false, false) : null;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {}
        }
      ]
    },
    "0af44ea8462437f8e7a8271b15a19677fd7f05a1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7450. Consolidate the implementation of GetFileInfo(), GetListings() and GetContentSummary() into a single class. Contributed by Haohui Mai.\n",
      "commitDate": "01/12/14 9:36 PM",
      "commitName": "0af44ea8462437f8e7a8271b15a19677fd7f05a1",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "25/11/14 9:04 PM",
      "commitNameOld": "4a3161182905afaf450a60d02528161ed1f97471",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 6.02,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,6 @@\n   HdfsFileStatus getAuditFileInfo(String path, boolean resolveSymlink)\n     throws IOException {\n     return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n-      ? getFileInfo(path, resolveSymlink, false, false) : null;\n+      ? FSDirStatAndListingOp.getFileInfo(this, path, resolveSymlink, false,\n+        false) : null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HdfsFileStatus getAuditFileInfo(String path, boolean resolveSymlink)\n    throws IOException {\n    return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n      ? FSDirStatAndListingOp.getFileInfo(this, path, resolveSymlink, false,\n        false) : null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "8caf537afabc70b0c74e0a29aea0cc2935ecb162": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7436. Consolidate implementation of concat(). Contributed by Haohui Mai.\n",
      "commitDate": "24/11/14 3:42 PM",
      "commitName": "8caf537afabc70b0c74e0a29aea0cc2935ecb162",
      "commitAuthor": "Haohui Mai",
      "diff": "@@ -0,0 +1,5 @@\n+  HdfsFileStatus getAuditFileInfo(String path, boolean resolveSymlink)\n+    throws IOException {\n+    return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n+      ? getFileInfo(path, resolveSymlink, false, false) : null;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  HdfsFileStatus getAuditFileInfo(String path, boolean resolveSymlink)\n    throws IOException {\n    return (namesystem.isAuditEnabled() \u0026\u0026 namesystem.isExternalInvocation())\n      ? getFileInfo(path, resolveSymlink, false, false) : null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java"
    }
  }
}