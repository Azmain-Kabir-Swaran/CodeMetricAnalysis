{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JobHistoryEventHandler.java",
  "functionName": "serviceStop",
  "functionId": "serviceStop",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
  "functionStartLine": 401,
  "functionEndLine": 499,
  "numCommitsSeen": 69,
  "timeTaken": 5506,
  "changeHistory": [
    "83e60cd2db20f655e272958ef43b1b5a084ef3e3",
    "d04f85f387e4a78816bc9966ee2b4a647ee05faf",
    "4fa1afdb883dab8786d2fb5c72a195dd2e87d711",
    "7d21c280a82b2f02675bf0048f0e965d99a05ae7",
    "0d02ab8729630ad3cfb4300702927333b1d349e3",
    "89e5c44f9e891a3579384c3fa3766937cd4970f1",
    "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5",
    "76e309ead01f02b32335330cd920536f907fb71f",
    "6b2f11b54bc679b0715fe66bd129e340e8c61c5c",
    "6015e9594180f157472a88030c85c5599fdc289c",
    "658b1bf561aa1c0f02fc0dbb079011f959709c25",
    "0928502029ef141759008997335ea2cd836a7154"
  ],
  "changeHistoryShort": {
    "83e60cd2db20f655e272958ef43b1b5a084ef3e3": "Ybodychange",
    "d04f85f387e4a78816bc9966ee2b4a647ee05faf": "Ybodychange",
    "4fa1afdb883dab8786d2fb5c72a195dd2e87d711": "Ybodychange",
    "7d21c280a82b2f02675bf0048f0e965d99a05ae7": "Ybodychange",
    "0d02ab8729630ad3cfb4300702927333b1d349e3": "Ybodychange",
    "89e5c44f9e891a3579384c3fa3766937cd4970f1": "Ybodychange",
    "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5": "Ybodychange",
    "76e309ead01f02b32335330cd920536f907fb71f": "Ybodychange",
    "6b2f11b54bc679b0715fe66bd129e340e8c61c5c": "Ybodychange",
    "6015e9594180f157472a88030c85c5599fdc289c": "Ybodychange",
    "658b1bf561aa1c0f02fc0dbb079011f959709c25": "Ybodychange",
    "0928502029ef141759008997335ea2cd836a7154": "Yintroduced"
  },
  "changeHistoryDetails": {
    "83e60cd2db20f655e272958ef43b1b5a084ef3e3": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-7042. Killed MR job data does not move to mapreduce.jobhistory.done-dir when ATS v2 is enabled. Contributed by Rohith Sharma K S.\n",
      "commitDate": "26/04/18 1:54 PM",
      "commitName": "83e60cd2db20f655e272958ef43b1b5a084ef3e3",
      "commitAuthor": "Sunil G",
      "commitDateOld": "04/04/18 3:08 PM",
      "commitNameOld": "345e7624d58a058a1bad666bd1e5ce4b346a9056",
      "commitAuthorOld": "Vrushali C",
      "daysBetweenCommits": 21.95,
      "commitsBetweenForRepo": 653,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,94 +1,99 @@\n   protected void serviceStop() throws Exception {\n     LOG.info(\"Stopping JobHistoryEventHandler. \"\n         + \"Size of the outstanding queue size is \" + eventQueue.size());\n     stopped \u003d true;\n     //do not interrupt while event handling is in progress\n     synchronized(lock) {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Interrupting Event Handling thread\");\n         eventHandlingThread.interrupt();\n       } else {\n         LOG.debug(\"Null event handling thread\");\n       }\n     }\n \n     try {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Waiting for Event Handling thread to complete\");\n         eventHandlingThread.join();\n       }\n     } catch (InterruptedException ie) {\n       LOG.info(\"Interrupted Exception while stopping\", ie);\n     }\n \n     // Cancel all timers - so that they aren\u0027t invoked during or after\n     // the metaInfo object is wrapped up.\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Shutting down timer for \" + mi);\n         }\n         mi.shutDownTimer();\n       } catch (IOException e) {\n         LOG.info(\"Exception while canceling delayed flush timer. \"\n             + \"Likely caused by a failed flush \" + e.getMessage());\n       }\n     }\n \n     //write all the events remaining in queue\n     Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n     while(it.hasNext()) {\n       JobHistoryEvent ev \u003d it.next();\n       LOG.info(\"In stop, writing event \" + ev.getType());\n       handleEvent(ev);\n     }\n \n     // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n     // closed their event writers\n     if(forceJobCompletion) {\n       for (Map.Entry\u003cJobId,MetaInfo\u003e jobIt : fileMap.entrySet()) {\n         JobId toClose \u003d jobIt.getKey();\n         MetaInfo mi \u003d jobIt.getValue();\n         if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n           LOG.warn(\"Found jobId \" + toClose\n             + \" to have not been closed. Will close\");\n           //Create a JobFinishEvent so that it is written to the job history\n           final Job job \u003d context.getJob(toClose);\n           int successfulMaps \u003d job.getCompletedMaps() - job.getFailedMaps()\n                   - job.getKilledMaps();\n           int successfulReduces \u003d job.getCompletedReduces()\n                   - job.getFailedReduces() - job.getKilledReduces();\n \n           JobUnsuccessfulCompletionEvent jucEvent \u003d\n             new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                 System.currentTimeMillis(),\n                 successfulMaps,\n                 successfulReduces,\n                 job.getFailedMaps(), job.getFailedReduces(),\n                 job.getKilledMaps(), job.getKilledReduces(),\n                 createJobStateForJobUnsuccessfulCompletionEvent(\n                     mi.getForcedJobStateOnShutDown()),\n                 job.getDiagnostics());\n           JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n           //Bypass the queue mechanism which might wait. Call the method directly\n           handleEvent(jfEvent);\n         }\n       }\n     }\n \n     //close all file handles\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         mi.closeWriter();\n       } catch (IOException e) {\n         LOG.info(\"Exception while closing file \" + e.getMessage());\n       }\n     }\n+\n+    if (handleTimelineEvent \u0026\u0026 atsEventDispatcher !\u003d null) {\n+      atsEventDispatcher.stop();\n+    }\n+\n     if (timelineClient !\u003d null) {\n       timelineClient.stop();\n     } else if (timelineV2Client !\u003d null) {\n       timelineV2Client.stop();\n     }\n     LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n     super.serviceStop();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStop() throws Exception {\n    LOG.info(\"Stopping JobHistoryEventHandler. \"\n        + \"Size of the outstanding queue size is \" + eventQueue.size());\n    stopped \u003d true;\n    //do not interrupt while event handling is in progress\n    synchronized(lock) {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Interrupting Event Handling thread\");\n        eventHandlingThread.interrupt();\n      } else {\n        LOG.debug(\"Null event handling thread\");\n      }\n    }\n\n    try {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Waiting for Event Handling thread to complete\");\n        eventHandlingThread.join();\n      }\n    } catch (InterruptedException ie) {\n      LOG.info(\"Interrupted Exception while stopping\", ie);\n    }\n\n    // Cancel all timers - so that they aren\u0027t invoked during or after\n    // the metaInfo object is wrapped up.\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Shutting down timer for \" + mi);\n        }\n        mi.shutDownTimer();\n      } catch (IOException e) {\n        LOG.info(\"Exception while canceling delayed flush timer. \"\n            + \"Likely caused by a failed flush \" + e.getMessage());\n      }\n    }\n\n    //write all the events remaining in queue\n    Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n    while(it.hasNext()) {\n      JobHistoryEvent ev \u003d it.next();\n      LOG.info(\"In stop, writing event \" + ev.getType());\n      handleEvent(ev);\n    }\n\n    // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n    // closed their event writers\n    if(forceJobCompletion) {\n      for (Map.Entry\u003cJobId,MetaInfo\u003e jobIt : fileMap.entrySet()) {\n        JobId toClose \u003d jobIt.getKey();\n        MetaInfo mi \u003d jobIt.getValue();\n        if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n          LOG.warn(\"Found jobId \" + toClose\n            + \" to have not been closed. Will close\");\n          //Create a JobFinishEvent so that it is written to the job history\n          final Job job \u003d context.getJob(toClose);\n          int successfulMaps \u003d job.getCompletedMaps() - job.getFailedMaps()\n                  - job.getKilledMaps();\n          int successfulReduces \u003d job.getCompletedReduces()\n                  - job.getFailedReduces() - job.getKilledReduces();\n\n          JobUnsuccessfulCompletionEvent jucEvent \u003d\n            new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                System.currentTimeMillis(),\n                successfulMaps,\n                successfulReduces,\n                job.getFailedMaps(), job.getFailedReduces(),\n                job.getKilledMaps(), job.getKilledReduces(),\n                createJobStateForJobUnsuccessfulCompletionEvent(\n                    mi.getForcedJobStateOnShutDown()),\n                job.getDiagnostics());\n          JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n          //Bypass the queue mechanism which might wait. Call the method directly\n          handleEvent(jfEvent);\n        }\n      }\n    }\n\n    //close all file handles\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        mi.closeWriter();\n      } catch (IOException e) {\n        LOG.info(\"Exception while closing file \" + e.getMessage());\n      }\n    }\n\n    if (handleTimelineEvent \u0026\u0026 atsEventDispatcher !\u003d null) {\n      atsEventDispatcher.stop();\n    }\n\n    if (timelineClient !\u003d null) {\n      timelineClient.stop();\n    } else if (timelineV2Client !\u003d null) {\n      timelineV2Client.stop();\n    }\n    LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n    super.serviceStop();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "d04f85f387e4a78816bc9966ee2b4a647ee05faf": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6892. Issues with the count of failed/killed tasks in the jhist file. (Peter Bacsko via Haibo Chen)\n",
      "commitDate": "30/08/17 10:07 AM",
      "commitName": "d04f85f387e4a78816bc9966ee2b4a647ee05faf",
      "commitAuthor": "Haibo Chen",
      "commitDateOld": "29/08/17 10:59 PM",
      "commitNameOld": "684de1a9025261dcb6ab3b5ec9ba69738c947ecc",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.46,
      "commitsBetweenForRepo": 38,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,94 @@\n   protected void serviceStop() throws Exception {\n     LOG.info(\"Stopping JobHistoryEventHandler. \"\n         + \"Size of the outstanding queue size is \" + eventQueue.size());\n     stopped \u003d true;\n     //do not interrupt while event handling is in progress\n     synchronized(lock) {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Interrupting Event Handling thread\");\n         eventHandlingThread.interrupt();\n       } else {\n         LOG.debug(\"Null event handling thread\");\n       }\n     }\n \n     try {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Waiting for Event Handling thread to complete\");\n         eventHandlingThread.join();\n       }\n     } catch (InterruptedException ie) {\n       LOG.info(\"Interrupted Exception while stopping\", ie);\n     }\n \n     // Cancel all timers - so that they aren\u0027t invoked during or after\n     // the metaInfo object is wrapped up.\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Shutting down timer for \" + mi);\n         }\n         mi.shutDownTimer();\n       } catch (IOException e) {\n         LOG.info(\"Exception while canceling delayed flush timer. \"\n             + \"Likely caused by a failed flush \" + e.getMessage());\n       }\n     }\n \n     //write all the events remaining in queue\n     Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n     while(it.hasNext()) {\n       JobHistoryEvent ev \u003d it.next();\n       LOG.info(\"In stop, writing event \" + ev.getType());\n       handleEvent(ev);\n     }\n \n     // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n     // closed their event writers\n     if(forceJobCompletion) {\n       for (Map.Entry\u003cJobId,MetaInfo\u003e jobIt : fileMap.entrySet()) {\n         JobId toClose \u003d jobIt.getKey();\n         MetaInfo mi \u003d jobIt.getValue();\n         if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n           LOG.warn(\"Found jobId \" + toClose\n             + \" to have not been closed. Will close\");\n           //Create a JobFinishEvent so that it is written to the job history\n           final Job job \u003d context.getJob(toClose);\n+          int successfulMaps \u003d job.getCompletedMaps() - job.getFailedMaps()\n+                  - job.getKilledMaps();\n+          int successfulReduces \u003d job.getCompletedReduces()\n+                  - job.getFailedReduces() - job.getKilledReduces();\n+\n           JobUnsuccessfulCompletionEvent jucEvent \u003d\n             new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n-                System.currentTimeMillis(), job.getCompletedMaps(),\n-                job.getCompletedReduces(),\n+                System.currentTimeMillis(),\n+                successfulMaps,\n+                successfulReduces,\n+                job.getFailedMaps(), job.getFailedReduces(),\n+                job.getKilledMaps(), job.getKilledReduces(),\n                 createJobStateForJobUnsuccessfulCompletionEvent(\n                     mi.getForcedJobStateOnShutDown()),\n                 job.getDiagnostics());\n           JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n           //Bypass the queue mechanism which might wait. Call the method directly\n           handleEvent(jfEvent);\n         }\n       }\n     }\n \n     //close all file handles\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         mi.closeWriter();\n       } catch (IOException e) {\n         LOG.info(\"Exception while closing file \" + e.getMessage());\n       }\n     }\n     if (timelineClient !\u003d null) {\n       timelineClient.stop();\n     } else if (timelineV2Client !\u003d null) {\n       timelineV2Client.stop();\n     }\n     LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n     super.serviceStop();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStop() throws Exception {\n    LOG.info(\"Stopping JobHistoryEventHandler. \"\n        + \"Size of the outstanding queue size is \" + eventQueue.size());\n    stopped \u003d true;\n    //do not interrupt while event handling is in progress\n    synchronized(lock) {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Interrupting Event Handling thread\");\n        eventHandlingThread.interrupt();\n      } else {\n        LOG.debug(\"Null event handling thread\");\n      }\n    }\n\n    try {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Waiting for Event Handling thread to complete\");\n        eventHandlingThread.join();\n      }\n    } catch (InterruptedException ie) {\n      LOG.info(\"Interrupted Exception while stopping\", ie);\n    }\n\n    // Cancel all timers - so that they aren\u0027t invoked during or after\n    // the metaInfo object is wrapped up.\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Shutting down timer for \" + mi);\n        }\n        mi.shutDownTimer();\n      } catch (IOException e) {\n        LOG.info(\"Exception while canceling delayed flush timer. \"\n            + \"Likely caused by a failed flush \" + e.getMessage());\n      }\n    }\n\n    //write all the events remaining in queue\n    Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n    while(it.hasNext()) {\n      JobHistoryEvent ev \u003d it.next();\n      LOG.info(\"In stop, writing event \" + ev.getType());\n      handleEvent(ev);\n    }\n\n    // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n    // closed their event writers\n    if(forceJobCompletion) {\n      for (Map.Entry\u003cJobId,MetaInfo\u003e jobIt : fileMap.entrySet()) {\n        JobId toClose \u003d jobIt.getKey();\n        MetaInfo mi \u003d jobIt.getValue();\n        if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n          LOG.warn(\"Found jobId \" + toClose\n            + \" to have not been closed. Will close\");\n          //Create a JobFinishEvent so that it is written to the job history\n          final Job job \u003d context.getJob(toClose);\n          int successfulMaps \u003d job.getCompletedMaps() - job.getFailedMaps()\n                  - job.getKilledMaps();\n          int successfulReduces \u003d job.getCompletedReduces()\n                  - job.getFailedReduces() - job.getKilledReduces();\n\n          JobUnsuccessfulCompletionEvent jucEvent \u003d\n            new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                System.currentTimeMillis(),\n                successfulMaps,\n                successfulReduces,\n                job.getFailedMaps(), job.getFailedReduces(),\n                job.getKilledMaps(), job.getKilledReduces(),\n                createJobStateForJobUnsuccessfulCompletionEvent(\n                    mi.getForcedJobStateOnShutDown()),\n                job.getDiagnostics());\n          JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n          //Bypass the queue mechanism which might wait. Call the method directly\n          handleEvent(jfEvent);\n        }\n      }\n    }\n\n    //close all file handles\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        mi.closeWriter();\n      } catch (IOException e) {\n        LOG.info(\"Exception while closing file \" + e.getMessage());\n      }\n    }\n    if (timelineClient !\u003d null) {\n      timelineClient.stop();\n    } else if (timelineV2Client !\u003d null) {\n      timelineV2Client.stop();\n    }\n    LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n    super.serviceStop();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "4fa1afdb883dab8786d2fb5c72a195dd2e87d711": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4675. Reorganize TimelineClient and TimelineClientImpl into separate classes for ATSv1.x and ATSv2. Contributed by Naganarasimha G R.\n",
      "commitDate": "16/02/17 11:41 AM",
      "commitName": "4fa1afdb883dab8786d2fb5c72a195dd2e87d711",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "15/11/16 10:57 AM",
      "commitNameOld": "5af572b6443715b7a741296c1bd520a1840f9a7c",
      "commitAuthorOld": "Mingliang Liu",
      "daysBetweenCommits": 93.03,
      "commitsBetweenForRepo": 475,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,86 @@\n   protected void serviceStop() throws Exception {\n     LOG.info(\"Stopping JobHistoryEventHandler. \"\n         + \"Size of the outstanding queue size is \" + eventQueue.size());\n     stopped \u003d true;\n     //do not interrupt while event handling is in progress\n     synchronized(lock) {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Interrupting Event Handling thread\");\n         eventHandlingThread.interrupt();\n       } else {\n         LOG.debug(\"Null event handling thread\");\n       }\n     }\n \n     try {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Waiting for Event Handling thread to complete\");\n         eventHandlingThread.join();\n       }\n     } catch (InterruptedException ie) {\n       LOG.info(\"Interrupted Exception while stopping\", ie);\n     }\n \n     // Cancel all timers - so that they aren\u0027t invoked during or after\n     // the metaInfo object is wrapped up.\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Shutting down timer for \" + mi);\n         }\n         mi.shutDownTimer();\n       } catch (IOException e) {\n         LOG.info(\"Exception while canceling delayed flush timer. \"\n             + \"Likely caused by a failed flush \" + e.getMessage());\n       }\n     }\n \n     //write all the events remaining in queue\n     Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n     while(it.hasNext()) {\n       JobHistoryEvent ev \u003d it.next();\n       LOG.info(\"In stop, writing event \" + ev.getType());\n       handleEvent(ev);\n     }\n \n     // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n     // closed their event writers\n     if(forceJobCompletion) {\n       for (Map.Entry\u003cJobId,MetaInfo\u003e jobIt : fileMap.entrySet()) {\n         JobId toClose \u003d jobIt.getKey();\n         MetaInfo mi \u003d jobIt.getValue();\n         if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n           LOG.warn(\"Found jobId \" + toClose\n             + \" to have not been closed. Will close\");\n           //Create a JobFinishEvent so that it is written to the job history\n           final Job job \u003d context.getJob(toClose);\n           JobUnsuccessfulCompletionEvent jucEvent \u003d\n             new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                 System.currentTimeMillis(), job.getCompletedMaps(),\n                 job.getCompletedReduces(),\n                 createJobStateForJobUnsuccessfulCompletionEvent(\n                     mi.getForcedJobStateOnShutDown()),\n                 job.getDiagnostics());\n           JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n           //Bypass the queue mechanism which might wait. Call the method directly\n           handleEvent(jfEvent);\n         }\n       }\n     }\n \n     //close all file handles\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         mi.closeWriter();\n       } catch (IOException e) {\n         LOG.info(\"Exception while closing file \" + e.getMessage());\n       }\n     }\n     if (timelineClient !\u003d null) {\n       timelineClient.stop();\n+    } else if (timelineV2Client !\u003d null) {\n+      timelineV2Client.stop();\n     }\n     LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n     super.serviceStop();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStop() throws Exception {\n    LOG.info(\"Stopping JobHistoryEventHandler. \"\n        + \"Size of the outstanding queue size is \" + eventQueue.size());\n    stopped \u003d true;\n    //do not interrupt while event handling is in progress\n    synchronized(lock) {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Interrupting Event Handling thread\");\n        eventHandlingThread.interrupt();\n      } else {\n        LOG.debug(\"Null event handling thread\");\n      }\n    }\n\n    try {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Waiting for Event Handling thread to complete\");\n        eventHandlingThread.join();\n      }\n    } catch (InterruptedException ie) {\n      LOG.info(\"Interrupted Exception while stopping\", ie);\n    }\n\n    // Cancel all timers - so that they aren\u0027t invoked during or after\n    // the metaInfo object is wrapped up.\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Shutting down timer for \" + mi);\n        }\n        mi.shutDownTimer();\n      } catch (IOException e) {\n        LOG.info(\"Exception while canceling delayed flush timer. \"\n            + \"Likely caused by a failed flush \" + e.getMessage());\n      }\n    }\n\n    //write all the events remaining in queue\n    Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n    while(it.hasNext()) {\n      JobHistoryEvent ev \u003d it.next();\n      LOG.info(\"In stop, writing event \" + ev.getType());\n      handleEvent(ev);\n    }\n\n    // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n    // closed their event writers\n    if(forceJobCompletion) {\n      for (Map.Entry\u003cJobId,MetaInfo\u003e jobIt : fileMap.entrySet()) {\n        JobId toClose \u003d jobIt.getKey();\n        MetaInfo mi \u003d jobIt.getValue();\n        if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n          LOG.warn(\"Found jobId \" + toClose\n            + \" to have not been closed. Will close\");\n          //Create a JobFinishEvent so that it is written to the job history\n          final Job job \u003d context.getJob(toClose);\n          JobUnsuccessfulCompletionEvent jucEvent \u003d\n            new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                System.currentTimeMillis(), job.getCompletedMaps(),\n                job.getCompletedReduces(),\n                createJobStateForJobUnsuccessfulCompletionEvent(\n                    mi.getForcedJobStateOnShutDown()),\n                job.getDiagnostics());\n          JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n          //Bypass the queue mechanism which might wait. Call the method directly\n          handleEvent(jfEvent);\n        }\n      }\n    }\n\n    //close all file handles\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        mi.closeWriter();\n      } catch (IOException e) {\n        LOG.info(\"Exception while closing file \" + e.getMessage());\n      }\n    }\n    if (timelineClient !\u003d null) {\n      timelineClient.stop();\n    } else if (timelineV2Client !\u003d null) {\n      timelineV2Client.stop();\n    }\n    LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n    super.serviceStop();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "7d21c280a82b2f02675bf0048f0e965d99a05ae7": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6777. Typos in 4 log messages. Contributed by Mehran Hassani\n",
      "commitDate": "16/09/16 9:49 PM",
      "commitName": "7d21c280a82b2f02675bf0048f0e965d99a05ae7",
      "commitAuthor": "Naganarasimha",
      "commitDateOld": "09/08/16 8:55 AM",
      "commitNameOld": "4aba858750900de25940c16211c21de4addd1926",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 38.54,
      "commitsBetweenForRepo": 237,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,84 @@\n   protected void serviceStop() throws Exception {\n     LOG.info(\"Stopping JobHistoryEventHandler. \"\n         + \"Size of the outstanding queue size is \" + eventQueue.size());\n     stopped \u003d true;\n     //do not interrupt while event handling is in progress\n     synchronized(lock) {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Interrupting Event Handling thread\");\n         eventHandlingThread.interrupt();\n       } else {\n         LOG.debug(\"Null event handling thread\");\n       }\n     }\n \n     try {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Waiting for Event Handling thread to complete\");\n         eventHandlingThread.join();\n       }\n     } catch (InterruptedException ie) {\n       LOG.info(\"Interrupted Exception while stopping\", ie);\n     }\n \n     // Cancel all timers - so that they aren\u0027t invoked during or after\n     // the metaInfo object is wrapped up.\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Shutting down timer for \" + mi);\n         }\n         mi.shutDownTimer();\n       } catch (IOException e) {\n-        LOG.info(\"Exception while cancelling delayed flush timer. \"\n+        LOG.info(\"Exception while canceling delayed flush timer. \"\n             + \"Likely caused by a failed flush \" + e.getMessage());\n       }\n     }\n \n     //write all the events remaining in queue\n     Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n     while(it.hasNext()) {\n       JobHistoryEvent ev \u003d it.next();\n       LOG.info(\"In stop, writing event \" + ev.getType());\n       handleEvent(ev);\n     }\n \n     // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n     // closed their event writers\n     if(forceJobCompletion) {\n       for (Map.Entry\u003cJobId,MetaInfo\u003e jobIt : fileMap.entrySet()) {\n         JobId toClose \u003d jobIt.getKey();\n         MetaInfo mi \u003d jobIt.getValue();\n         if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n           LOG.warn(\"Found jobId \" + toClose\n             + \" to have not been closed. Will close\");\n           //Create a JobFinishEvent so that it is written to the job history\n           final Job job \u003d context.getJob(toClose);\n           JobUnsuccessfulCompletionEvent jucEvent \u003d\n             new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                 System.currentTimeMillis(), job.getCompletedMaps(),\n                 job.getCompletedReduces(),\n                 createJobStateForJobUnsuccessfulCompletionEvent(\n                     mi.getForcedJobStateOnShutDown()),\n                 job.getDiagnostics());\n           JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n           //Bypass the queue mechanism which might wait. Call the method directly\n           handleEvent(jfEvent);\n         }\n       }\n     }\n \n     //close all file handles\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         mi.closeWriter();\n       } catch (IOException e) {\n         LOG.info(\"Exception while closing file \" + e.getMessage());\n       }\n     }\n     if (timelineClient !\u003d null) {\n       timelineClient.stop();\n     }\n     LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n     super.serviceStop();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStop() throws Exception {\n    LOG.info(\"Stopping JobHistoryEventHandler. \"\n        + \"Size of the outstanding queue size is \" + eventQueue.size());\n    stopped \u003d true;\n    //do not interrupt while event handling is in progress\n    synchronized(lock) {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Interrupting Event Handling thread\");\n        eventHandlingThread.interrupt();\n      } else {\n        LOG.debug(\"Null event handling thread\");\n      }\n    }\n\n    try {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Waiting for Event Handling thread to complete\");\n        eventHandlingThread.join();\n      }\n    } catch (InterruptedException ie) {\n      LOG.info(\"Interrupted Exception while stopping\", ie);\n    }\n\n    // Cancel all timers - so that they aren\u0027t invoked during or after\n    // the metaInfo object is wrapped up.\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Shutting down timer for \" + mi);\n        }\n        mi.shutDownTimer();\n      } catch (IOException e) {\n        LOG.info(\"Exception while canceling delayed flush timer. \"\n            + \"Likely caused by a failed flush \" + e.getMessage());\n      }\n    }\n\n    //write all the events remaining in queue\n    Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n    while(it.hasNext()) {\n      JobHistoryEvent ev \u003d it.next();\n      LOG.info(\"In stop, writing event \" + ev.getType());\n      handleEvent(ev);\n    }\n\n    // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n    // closed their event writers\n    if(forceJobCompletion) {\n      for (Map.Entry\u003cJobId,MetaInfo\u003e jobIt : fileMap.entrySet()) {\n        JobId toClose \u003d jobIt.getKey();\n        MetaInfo mi \u003d jobIt.getValue();\n        if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n          LOG.warn(\"Found jobId \" + toClose\n            + \" to have not been closed. Will close\");\n          //Create a JobFinishEvent so that it is written to the job history\n          final Job job \u003d context.getJob(toClose);\n          JobUnsuccessfulCompletionEvent jucEvent \u003d\n            new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                System.currentTimeMillis(), job.getCompletedMaps(),\n                job.getCompletedReduces(),\n                createJobStateForJobUnsuccessfulCompletionEvent(\n                    mi.getForcedJobStateOnShutDown()),\n                job.getDiagnostics());\n          JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n          //Bypass the queue mechanism which might wait. Call the method directly\n          handleEvent(jfEvent);\n        }\n      }\n    }\n\n    //close all file handles\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        mi.closeWriter();\n      } catch (IOException e) {\n        LOG.info(\"Exception while closing file \" + e.getMessage());\n      }\n    }\n    if (timelineClient !\u003d null) {\n      timelineClient.stop();\n    }\n    LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n    super.serviceStop();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "0d02ab8729630ad3cfb4300702927333b1d349e3": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3367. Replace starting a separate thread for post entity with event loop in TimelineClient (Naganarasimha G R via sjlee)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "0d02ab8729630ad3cfb4300702927333b1d349e3",
      "commitAuthor": "Sangjin Lee",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "960af7d4717b8a8949d0b2e43949e7daab45aa88",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,87 +1,84 @@\n   protected void serviceStop() throws Exception {\n     LOG.info(\"Stopping JobHistoryEventHandler. \"\n         + \"Size of the outstanding queue size is \" + eventQueue.size());\n     stopped \u003d true;\n     //do not interrupt while event handling is in progress\n     synchronized(lock) {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Interrupting Event Handling thread\");\n         eventHandlingThread.interrupt();\n       } else {\n         LOG.debug(\"Null event handling thread\");\n       }\n     }\n \n     try {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Waiting for Event Handling thread to complete\");\n         eventHandlingThread.join();\n       }\n     } catch (InterruptedException ie) {\n       LOG.info(\"Interrupted Exception while stopping\", ie);\n     }\n \n     // Cancel all timers - so that they aren\u0027t invoked during or after\n     // the metaInfo object is wrapped up.\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Shutting down timer for \" + mi);\n         }\n         mi.shutDownTimer();\n       } catch (IOException e) {\n         LOG.info(\"Exception while cancelling delayed flush timer. \"\n             + \"Likely caused by a failed flush \" + e.getMessage());\n       }\n     }\n \n     //write all the events remaining in queue\n     Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n     while(it.hasNext()) {\n       JobHistoryEvent ev \u003d it.next();\n       LOG.info(\"In stop, writing event \" + ev.getType());\n       handleEvent(ev);\n     }\n \n     // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n     // closed their event writers\n     if(forceJobCompletion) {\n       for (Map.Entry\u003cJobId,MetaInfo\u003e jobIt : fileMap.entrySet()) {\n         JobId toClose \u003d jobIt.getKey();\n         MetaInfo mi \u003d jobIt.getValue();\n         if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n           LOG.warn(\"Found jobId \" + toClose\n             + \" to have not been closed. Will close\");\n           //Create a JobFinishEvent so that it is written to the job history\n           final Job job \u003d context.getJob(toClose);\n           JobUnsuccessfulCompletionEvent jucEvent \u003d\n             new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                 System.currentTimeMillis(), job.getCompletedMaps(),\n                 job.getCompletedReduces(),\n                 createJobStateForJobUnsuccessfulCompletionEvent(\n                     mi.getForcedJobStateOnShutDown()),\n                 job.getDiagnostics());\n           JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n           //Bypass the queue mechanism which might wait. Call the method directly\n           handleEvent(jfEvent);\n         }\n       }\n     }\n \n     //close all file handles\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         mi.closeWriter();\n       } catch (IOException e) {\n         LOG.info(\"Exception while closing file \" + e.getMessage());\n       }\n     }\n     if (timelineClient !\u003d null) {\n       timelineClient.stop();\n     }\n-    if (threadPool !\u003d null) {\n-      shutdownAndAwaitTermination();\n-    }\n     LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n     super.serviceStop();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStop() throws Exception {\n    LOG.info(\"Stopping JobHistoryEventHandler. \"\n        + \"Size of the outstanding queue size is \" + eventQueue.size());\n    stopped \u003d true;\n    //do not interrupt while event handling is in progress\n    synchronized(lock) {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Interrupting Event Handling thread\");\n        eventHandlingThread.interrupt();\n      } else {\n        LOG.debug(\"Null event handling thread\");\n      }\n    }\n\n    try {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Waiting for Event Handling thread to complete\");\n        eventHandlingThread.join();\n      }\n    } catch (InterruptedException ie) {\n      LOG.info(\"Interrupted Exception while stopping\", ie);\n    }\n\n    // Cancel all timers - so that they aren\u0027t invoked during or after\n    // the metaInfo object is wrapped up.\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Shutting down timer for \" + mi);\n        }\n        mi.shutDownTimer();\n      } catch (IOException e) {\n        LOG.info(\"Exception while cancelling delayed flush timer. \"\n            + \"Likely caused by a failed flush \" + e.getMessage());\n      }\n    }\n\n    //write all the events remaining in queue\n    Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n    while(it.hasNext()) {\n      JobHistoryEvent ev \u003d it.next();\n      LOG.info(\"In stop, writing event \" + ev.getType());\n      handleEvent(ev);\n    }\n\n    // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n    // closed their event writers\n    if(forceJobCompletion) {\n      for (Map.Entry\u003cJobId,MetaInfo\u003e jobIt : fileMap.entrySet()) {\n        JobId toClose \u003d jobIt.getKey();\n        MetaInfo mi \u003d jobIt.getValue();\n        if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n          LOG.warn(\"Found jobId \" + toClose\n            + \" to have not been closed. Will close\");\n          //Create a JobFinishEvent so that it is written to the job history\n          final Job job \u003d context.getJob(toClose);\n          JobUnsuccessfulCompletionEvent jucEvent \u003d\n            new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                System.currentTimeMillis(), job.getCompletedMaps(),\n                job.getCompletedReduces(),\n                createJobStateForJobUnsuccessfulCompletionEvent(\n                    mi.getForcedJobStateOnShutDown()),\n                job.getDiagnostics());\n          JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n          //Bypass the queue mechanism which might wait. Call the method directly\n          handleEvent(jfEvent);\n        }\n      }\n    }\n\n    //close all file handles\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        mi.closeWriter();\n      } catch (IOException e) {\n        LOG.info(\"Exception while closing file \" + e.getMessage());\n      }\n    }\n    if (timelineClient !\u003d null) {\n      timelineClient.stop();\n    }\n    LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n    super.serviceStop();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "89e5c44f9e891a3579384c3fa3766937cd4970f1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4356. Ensure the timeline service v.2 is disabled cleanly and has no\nimpact when it\u0027s turned off. Contributed by Sangjin Lee.\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "89e5c44f9e891a3579384c3fa3766937cd4970f1",
      "commitAuthor": "Li Lu",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 48,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,85 +1,87 @@\n   protected void serviceStop() throws Exception {\n     LOG.info(\"Stopping JobHistoryEventHandler. \"\n         + \"Size of the outstanding queue size is \" + eventQueue.size());\n     stopped \u003d true;\n     //do not interrupt while event handling is in progress\n     synchronized(lock) {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Interrupting Event Handling thread\");\n         eventHandlingThread.interrupt();\n       } else {\n         LOG.debug(\"Null event handling thread\");\n       }\n     }\n \n     try {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Waiting for Event Handling thread to complete\");\n         eventHandlingThread.join();\n       }\n     } catch (InterruptedException ie) {\n       LOG.info(\"Interrupted Exception while stopping\", ie);\n     }\n \n     // Cancel all timers - so that they aren\u0027t invoked during or after\n     // the metaInfo object is wrapped up.\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Shutting down timer for \" + mi);\n         }\n         mi.shutDownTimer();\n       } catch (IOException e) {\n         LOG.info(\"Exception while cancelling delayed flush timer. \"\n             + \"Likely caused by a failed flush \" + e.getMessage());\n       }\n     }\n \n     //write all the events remaining in queue\n     Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n     while(it.hasNext()) {\n       JobHistoryEvent ev \u003d it.next();\n       LOG.info(\"In stop, writing event \" + ev.getType());\n       handleEvent(ev);\n     }\n \n     // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n     // closed their event writers\n     if(forceJobCompletion) {\n       for (Map.Entry\u003cJobId,MetaInfo\u003e jobIt : fileMap.entrySet()) {\n         JobId toClose \u003d jobIt.getKey();\n         MetaInfo mi \u003d jobIt.getValue();\n         if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n           LOG.warn(\"Found jobId \" + toClose\n             + \" to have not been closed. Will close\");\n           //Create a JobFinishEvent so that it is written to the job history\n           final Job job \u003d context.getJob(toClose);\n           JobUnsuccessfulCompletionEvent jucEvent \u003d\n             new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                 System.currentTimeMillis(), job.getCompletedMaps(),\n                 job.getCompletedReduces(),\n                 createJobStateForJobUnsuccessfulCompletionEvent(\n                     mi.getForcedJobStateOnShutDown()),\n                 job.getDiagnostics());\n           JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n           //Bypass the queue mechanism which might wait. Call the method directly\n           handleEvent(jfEvent);\n         }\n       }\n     }\n \n     //close all file handles\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         mi.closeWriter();\n       } catch (IOException e) {\n         LOG.info(\"Exception while closing file \" + e.getMessage());\n       }\n     }\n     if (timelineClient !\u003d null) {\n       timelineClient.stop();\n     }\n-    shutdownAndAwaitTermination();\n+    if (threadPool !\u003d null) {\n+      shutdownAndAwaitTermination();\n+    }\n     LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n     super.serviceStop();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStop() throws Exception {\n    LOG.info(\"Stopping JobHistoryEventHandler. \"\n        + \"Size of the outstanding queue size is \" + eventQueue.size());\n    stopped \u003d true;\n    //do not interrupt while event handling is in progress\n    synchronized(lock) {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Interrupting Event Handling thread\");\n        eventHandlingThread.interrupt();\n      } else {\n        LOG.debug(\"Null event handling thread\");\n      }\n    }\n\n    try {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Waiting for Event Handling thread to complete\");\n        eventHandlingThread.join();\n      }\n    } catch (InterruptedException ie) {\n      LOG.info(\"Interrupted Exception while stopping\", ie);\n    }\n\n    // Cancel all timers - so that they aren\u0027t invoked during or after\n    // the metaInfo object is wrapped up.\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Shutting down timer for \" + mi);\n        }\n        mi.shutDownTimer();\n      } catch (IOException e) {\n        LOG.info(\"Exception while cancelling delayed flush timer. \"\n            + \"Likely caused by a failed flush \" + e.getMessage());\n      }\n    }\n\n    //write all the events remaining in queue\n    Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n    while(it.hasNext()) {\n      JobHistoryEvent ev \u003d it.next();\n      LOG.info(\"In stop, writing event \" + ev.getType());\n      handleEvent(ev);\n    }\n\n    // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n    // closed their event writers\n    if(forceJobCompletion) {\n      for (Map.Entry\u003cJobId,MetaInfo\u003e jobIt : fileMap.entrySet()) {\n        JobId toClose \u003d jobIt.getKey();\n        MetaInfo mi \u003d jobIt.getValue();\n        if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n          LOG.warn(\"Found jobId \" + toClose\n            + \" to have not been closed. Will close\");\n          //Create a JobFinishEvent so that it is written to the job history\n          final Job job \u003d context.getJob(toClose);\n          JobUnsuccessfulCompletionEvent jucEvent \u003d\n            new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                System.currentTimeMillis(), job.getCompletedMaps(),\n                job.getCompletedReduces(),\n                createJobStateForJobUnsuccessfulCompletionEvent(\n                    mi.getForcedJobStateOnShutDown()),\n                job.getDiagnostics());\n          JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n          //Bypass the queue mechanism which might wait. Call the method directly\n          handleEvent(jfEvent);\n        }\n      }\n    }\n\n    //close all file handles\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        mi.closeWriter();\n      } catch (IOException e) {\n        LOG.info(\"Exception while closing file \" + e.getMessage());\n      }\n    }\n    if (timelineClient !\u003d null) {\n      timelineClient.stop();\n    }\n    if (threadPool !\u003d null) {\n      shutdownAndAwaitTermination();\n    }\n    LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n    super.serviceStop();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6327. Made MR AM use timeline service v2 API to write history events and counters. Contributed by Junping Du.\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "b50a6d78f5e12cfb9e0f52e0af6efbab3618e2e5",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "29/05/16 8:54 AM",
      "commitNameOld": "42f90ab885d9693fcc1e52f9637f7de4111110ae",
      "commitAuthorOld": "Varun Vasudev",
      "daysBetweenCommits": 41.99,
      "commitsBetweenForRepo": 290,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,85 @@\n   protected void serviceStop() throws Exception {\n     LOG.info(\"Stopping JobHistoryEventHandler. \"\n         + \"Size of the outstanding queue size is \" + eventQueue.size());\n     stopped \u003d true;\n     //do not interrupt while event handling is in progress\n     synchronized(lock) {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Interrupting Event Handling thread\");\n         eventHandlingThread.interrupt();\n       } else {\n         LOG.debug(\"Null event handling thread\");\n       }\n     }\n \n     try {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Waiting for Event Handling thread to complete\");\n         eventHandlingThread.join();\n       }\n     } catch (InterruptedException ie) {\n       LOG.info(\"Interrupted Exception while stopping\", ie);\n     }\n \n     // Cancel all timers - so that they aren\u0027t invoked during or after\n     // the metaInfo object is wrapped up.\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Shutting down timer for \" + mi);\n         }\n         mi.shutDownTimer();\n       } catch (IOException e) {\n         LOG.info(\"Exception while cancelling delayed flush timer. \"\n             + \"Likely caused by a failed flush \" + e.getMessage());\n       }\n     }\n \n     //write all the events remaining in queue\n     Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n     while(it.hasNext()) {\n       JobHistoryEvent ev \u003d it.next();\n       LOG.info(\"In stop, writing event \" + ev.getType());\n       handleEvent(ev);\n     }\n \n     // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n     // closed their event writers\n     if(forceJobCompletion) {\n       for (Map.Entry\u003cJobId,MetaInfo\u003e jobIt : fileMap.entrySet()) {\n         JobId toClose \u003d jobIt.getKey();\n         MetaInfo mi \u003d jobIt.getValue();\n         if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n           LOG.warn(\"Found jobId \" + toClose\n             + \" to have not been closed. Will close\");\n           //Create a JobFinishEvent so that it is written to the job history\n           final Job job \u003d context.getJob(toClose);\n           JobUnsuccessfulCompletionEvent jucEvent \u003d\n             new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                 System.currentTimeMillis(), job.getCompletedMaps(),\n                 job.getCompletedReduces(),\n                 createJobStateForJobUnsuccessfulCompletionEvent(\n                     mi.getForcedJobStateOnShutDown()),\n                 job.getDiagnostics());\n           JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n           //Bypass the queue mechanism which might wait. Call the method directly\n           handleEvent(jfEvent);\n         }\n       }\n     }\n \n     //close all file handles\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         mi.closeWriter();\n       } catch (IOException e) {\n         LOG.info(\"Exception while closing file \" + e.getMessage());\n       }\n     }\n     if (timelineClient !\u003d null) {\n       timelineClient.stop();\n     }\n+    shutdownAndAwaitTermination();\n     LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n     super.serviceStop();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStop() throws Exception {\n    LOG.info(\"Stopping JobHistoryEventHandler. \"\n        + \"Size of the outstanding queue size is \" + eventQueue.size());\n    stopped \u003d true;\n    //do not interrupt while event handling is in progress\n    synchronized(lock) {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Interrupting Event Handling thread\");\n        eventHandlingThread.interrupt();\n      } else {\n        LOG.debug(\"Null event handling thread\");\n      }\n    }\n\n    try {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Waiting for Event Handling thread to complete\");\n        eventHandlingThread.join();\n      }\n    } catch (InterruptedException ie) {\n      LOG.info(\"Interrupted Exception while stopping\", ie);\n    }\n\n    // Cancel all timers - so that they aren\u0027t invoked during or after\n    // the metaInfo object is wrapped up.\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Shutting down timer for \" + mi);\n        }\n        mi.shutDownTimer();\n      } catch (IOException e) {\n        LOG.info(\"Exception while cancelling delayed flush timer. \"\n            + \"Likely caused by a failed flush \" + e.getMessage());\n      }\n    }\n\n    //write all the events remaining in queue\n    Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n    while(it.hasNext()) {\n      JobHistoryEvent ev \u003d it.next();\n      LOG.info(\"In stop, writing event \" + ev.getType());\n      handleEvent(ev);\n    }\n\n    // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n    // closed their event writers\n    if(forceJobCompletion) {\n      for (Map.Entry\u003cJobId,MetaInfo\u003e jobIt : fileMap.entrySet()) {\n        JobId toClose \u003d jobIt.getKey();\n        MetaInfo mi \u003d jobIt.getValue();\n        if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n          LOG.warn(\"Found jobId \" + toClose\n            + \" to have not been closed. Will close\");\n          //Create a JobFinishEvent so that it is written to the job history\n          final Job job \u003d context.getJob(toClose);\n          JobUnsuccessfulCompletionEvent jucEvent \u003d\n            new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                System.currentTimeMillis(), job.getCompletedMaps(),\n                job.getCompletedReduces(),\n                createJobStateForJobUnsuccessfulCompletionEvent(\n                    mi.getForcedJobStateOnShutDown()),\n                job.getDiagnostics());\n          JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n          //Bypass the queue mechanism which might wait. Call the method directly\n          handleEvent(jfEvent);\n        }\n      }\n    }\n\n    //close all file handles\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        mi.closeWriter();\n      } catch (IOException e) {\n        LOG.info(\"Exception while closing file \" + e.getMessage());\n      }\n    }\n    if (timelineClient !\u003d null) {\n      timelineClient.stop();\n    }\n    shutdownAndAwaitTermination();\n    LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n    super.serviceStop();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "76e309ead01f02b32335330cd920536f907fb71f": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6253. Update use of Iterator to Iterable. Contributed by Ray\nChiang.\n",
      "commitDate": "12/02/15 12:15 AM",
      "commitName": "76e309ead01f02b32335330cd920536f907fb71f",
      "commitAuthor": "Devaraj K",
      "commitDateOld": "09/12/14 10:46 AM",
      "commitNameOld": "d777a1e4ca8e7cf0ce8967f79dd475468906c733",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 64.56,
      "commitsBetweenForRepo": 462,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,85 +1,84 @@\n   protected void serviceStop() throws Exception {\n     LOG.info(\"Stopping JobHistoryEventHandler. \"\n         + \"Size of the outstanding queue size is \" + eventQueue.size());\n     stopped \u003d true;\n     //do not interrupt while event handling is in progress\n     synchronized(lock) {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Interrupting Event Handling thread\");\n         eventHandlingThread.interrupt();\n       } else {\n         LOG.debug(\"Null event handling thread\");\n       }\n     }\n \n     try {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Waiting for Event Handling thread to complete\");\n         eventHandlingThread.join();\n       }\n     } catch (InterruptedException ie) {\n       LOG.info(\"Interrupted Exception while stopping\", ie);\n     }\n \n     // Cancel all timers - so that they aren\u0027t invoked during or after\n     // the metaInfo object is wrapped up.\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Shutting down timer for \" + mi);\n         }\n         mi.shutDownTimer();\n       } catch (IOException e) {\n         LOG.info(\"Exception while cancelling delayed flush timer. \"\n             + \"Likely caused by a failed flush \" + e.getMessage());\n       }\n     }\n \n     //write all the events remaining in queue\n     Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n     while(it.hasNext()) {\n       JobHistoryEvent ev \u003d it.next();\n       LOG.info(\"In stop, writing event \" + ev.getType());\n       handleEvent(ev);\n     }\n \n     // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n     // closed their event writers\n-    Iterator\u003cJobId\u003e jobIt \u003d fileMap.keySet().iterator();\n     if(forceJobCompletion) {\n-      while (jobIt.hasNext()) {\n-        JobId toClose \u003d jobIt.next();\n-        MetaInfo mi \u003d fileMap.get(toClose);\n+      for (Map.Entry\u003cJobId,MetaInfo\u003e jobIt : fileMap.entrySet()) {\n+        JobId toClose \u003d jobIt.getKey();\n+        MetaInfo mi \u003d jobIt.getValue();\n         if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n           LOG.warn(\"Found jobId \" + toClose\n             + \" to have not been closed. Will close\");\n           //Create a JobFinishEvent so that it is written to the job history\n           final Job job \u003d context.getJob(toClose);\n           JobUnsuccessfulCompletionEvent jucEvent \u003d\n             new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                 System.currentTimeMillis(), job.getCompletedMaps(),\n                 job.getCompletedReduces(),\n                 createJobStateForJobUnsuccessfulCompletionEvent(\n                     mi.getForcedJobStateOnShutDown()),\n                 job.getDiagnostics());\n           JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n           //Bypass the queue mechanism which might wait. Call the method directly\n           handleEvent(jfEvent);\n         }\n       }\n     }\n \n     //close all file handles\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         mi.closeWriter();\n       } catch (IOException e) {\n         LOG.info(\"Exception while closing file \" + e.getMessage());\n       }\n     }\n     if (timelineClient !\u003d null) {\n       timelineClient.stop();\n     }\n     LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n     super.serviceStop();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStop() throws Exception {\n    LOG.info(\"Stopping JobHistoryEventHandler. \"\n        + \"Size of the outstanding queue size is \" + eventQueue.size());\n    stopped \u003d true;\n    //do not interrupt while event handling is in progress\n    synchronized(lock) {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Interrupting Event Handling thread\");\n        eventHandlingThread.interrupt();\n      } else {\n        LOG.debug(\"Null event handling thread\");\n      }\n    }\n\n    try {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Waiting for Event Handling thread to complete\");\n        eventHandlingThread.join();\n      }\n    } catch (InterruptedException ie) {\n      LOG.info(\"Interrupted Exception while stopping\", ie);\n    }\n\n    // Cancel all timers - so that they aren\u0027t invoked during or after\n    // the metaInfo object is wrapped up.\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Shutting down timer for \" + mi);\n        }\n        mi.shutDownTimer();\n      } catch (IOException e) {\n        LOG.info(\"Exception while cancelling delayed flush timer. \"\n            + \"Likely caused by a failed flush \" + e.getMessage());\n      }\n    }\n\n    //write all the events remaining in queue\n    Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n    while(it.hasNext()) {\n      JobHistoryEvent ev \u003d it.next();\n      LOG.info(\"In stop, writing event \" + ev.getType());\n      handleEvent(ev);\n    }\n\n    // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n    // closed their event writers\n    if(forceJobCompletion) {\n      for (Map.Entry\u003cJobId,MetaInfo\u003e jobIt : fileMap.entrySet()) {\n        JobId toClose \u003d jobIt.getKey();\n        MetaInfo mi \u003d jobIt.getValue();\n        if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n          LOG.warn(\"Found jobId \" + toClose\n            + \" to have not been closed. Will close\");\n          //Create a JobFinishEvent so that it is written to the job history\n          final Job job \u003d context.getJob(toClose);\n          JobUnsuccessfulCompletionEvent jucEvent \u003d\n            new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                System.currentTimeMillis(), job.getCompletedMaps(),\n                job.getCompletedReduces(),\n                createJobStateForJobUnsuccessfulCompletionEvent(\n                    mi.getForcedJobStateOnShutDown()),\n                job.getDiagnostics());\n          JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n          //Bypass the queue mechanism which might wait. Call the method directly\n          handleEvent(jfEvent);\n        }\n      }\n    }\n\n    //close all file handles\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        mi.closeWriter();\n      } catch (IOException e) {\n        LOG.info(\"Exception while closing file \" + e.getMessage());\n      }\n    }\n    if (timelineClient !\u003d null) {\n      timelineClient.stop();\n    }\n    LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n    super.serviceStop();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "6b2f11b54bc679b0715fe66bd129e340e8c61c5c": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5933. Enabled MR AM to post history events to the timeline server. Contributed by Robert Kanter.\n",
      "commitDate": "27/10/14 8:35 PM",
      "commitName": "6b2f11b54bc679b0715fe66bd129e340e8c61c5c",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "15/08/14 1:17 PM",
      "commitNameOld": "84bc2fe4021be32e0ff8ba395359337904149034",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 73.3,
      "commitsBetweenForRepo": 704,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,82 +1,85 @@\n   protected void serviceStop() throws Exception {\n     LOG.info(\"Stopping JobHistoryEventHandler. \"\n         + \"Size of the outstanding queue size is \" + eventQueue.size());\n     stopped \u003d true;\n     //do not interrupt while event handling is in progress\n     synchronized(lock) {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Interrupting Event Handling thread\");\n         eventHandlingThread.interrupt();\n       } else {\n         LOG.debug(\"Null event handling thread\");\n       }\n     }\n \n     try {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Waiting for Event Handling thread to complete\");\n         eventHandlingThread.join();\n       }\n     } catch (InterruptedException ie) {\n       LOG.info(\"Interrupted Exception while stopping\", ie);\n     }\n \n     // Cancel all timers - so that they aren\u0027t invoked during or after\n     // the metaInfo object is wrapped up.\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Shutting down timer for \" + mi);\n         }\n         mi.shutDownTimer();\n       } catch (IOException e) {\n         LOG.info(\"Exception while cancelling delayed flush timer. \"\n             + \"Likely caused by a failed flush \" + e.getMessage());\n       }\n     }\n \n     //write all the events remaining in queue\n     Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n     while(it.hasNext()) {\n       JobHistoryEvent ev \u003d it.next();\n       LOG.info(\"In stop, writing event \" + ev.getType());\n       handleEvent(ev);\n     }\n \n     // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n     // closed their event writers\n     Iterator\u003cJobId\u003e jobIt \u003d fileMap.keySet().iterator();\n     if(forceJobCompletion) {\n       while (jobIt.hasNext()) {\n         JobId toClose \u003d jobIt.next();\n         MetaInfo mi \u003d fileMap.get(toClose);\n         if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n           LOG.warn(\"Found jobId \" + toClose\n             + \" to have not been closed. Will close\");\n           //Create a JobFinishEvent so that it is written to the job history\n           final Job job \u003d context.getJob(toClose);\n           JobUnsuccessfulCompletionEvent jucEvent \u003d\n             new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                 System.currentTimeMillis(), job.getCompletedMaps(),\n                 job.getCompletedReduces(),\n                 createJobStateForJobUnsuccessfulCompletionEvent(\n                     mi.getForcedJobStateOnShutDown()),\n                 job.getDiagnostics());\n           JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n           //Bypass the queue mechanism which might wait. Call the method directly\n           handleEvent(jfEvent);\n         }\n       }\n     }\n \n     //close all file handles\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         mi.closeWriter();\n       } catch (IOException e) {\n         LOG.info(\"Exception while closing file \" + e.getMessage());\n       }\n     }\n+    if (timelineClient !\u003d null) {\n+      timelineClient.stop();\n+    }\n     LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n     super.serviceStop();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStop() throws Exception {\n    LOG.info(\"Stopping JobHistoryEventHandler. \"\n        + \"Size of the outstanding queue size is \" + eventQueue.size());\n    stopped \u003d true;\n    //do not interrupt while event handling is in progress\n    synchronized(lock) {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Interrupting Event Handling thread\");\n        eventHandlingThread.interrupt();\n      } else {\n        LOG.debug(\"Null event handling thread\");\n      }\n    }\n\n    try {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Waiting for Event Handling thread to complete\");\n        eventHandlingThread.join();\n      }\n    } catch (InterruptedException ie) {\n      LOG.info(\"Interrupted Exception while stopping\", ie);\n    }\n\n    // Cancel all timers - so that they aren\u0027t invoked during or after\n    // the metaInfo object is wrapped up.\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Shutting down timer for \" + mi);\n        }\n        mi.shutDownTimer();\n      } catch (IOException e) {\n        LOG.info(\"Exception while cancelling delayed flush timer. \"\n            + \"Likely caused by a failed flush \" + e.getMessage());\n      }\n    }\n\n    //write all the events remaining in queue\n    Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n    while(it.hasNext()) {\n      JobHistoryEvent ev \u003d it.next();\n      LOG.info(\"In stop, writing event \" + ev.getType());\n      handleEvent(ev);\n    }\n\n    // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n    // closed their event writers\n    Iterator\u003cJobId\u003e jobIt \u003d fileMap.keySet().iterator();\n    if(forceJobCompletion) {\n      while (jobIt.hasNext()) {\n        JobId toClose \u003d jobIt.next();\n        MetaInfo mi \u003d fileMap.get(toClose);\n        if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n          LOG.warn(\"Found jobId \" + toClose\n            + \" to have not been closed. Will close\");\n          //Create a JobFinishEvent so that it is written to the job history\n          final Job job \u003d context.getJob(toClose);\n          JobUnsuccessfulCompletionEvent jucEvent \u003d\n            new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                System.currentTimeMillis(), job.getCompletedMaps(),\n                job.getCompletedReduces(),\n                createJobStateForJobUnsuccessfulCompletionEvent(\n                    mi.getForcedJobStateOnShutDown()),\n                job.getDiagnostics());\n          JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n          //Bypass the queue mechanism which might wait. Call the method directly\n          handleEvent(jfEvent);\n        }\n      }\n    }\n\n    //close all file handles\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        mi.closeWriter();\n      } catch (IOException e) {\n        LOG.info(\"Exception while closing file \" + e.getMessage());\n      }\n    }\n    if (timelineClient !\u003d null) {\n      timelineClient.stop();\n    }\n    LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n    super.serviceStop();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "6015e9594180f157472a88030c85c5599fdc289c": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5795. Fixed MRAppMaster to record the correct job-state after it recovers from a commit during a previous attempt. Contributed by Xuan Gong.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1581180 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/03/14 7:00 PM",
      "commitName": "6015e9594180f157472a88030c85c5599fdc289c",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "26/02/14 1:32 PM",
      "commitNameOld": "658b1bf561aa1c0f02fc0dbb079011f959709c25",
      "commitAuthorOld": "Jason Darrell Lowe",
      "daysBetweenCommits": 26.19,
      "commitsBetweenForRepo": 223,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,80 +1,82 @@\n   protected void serviceStop() throws Exception {\n     LOG.info(\"Stopping JobHistoryEventHandler. \"\n         + \"Size of the outstanding queue size is \" + eventQueue.size());\n     stopped \u003d true;\n     //do not interrupt while event handling is in progress\n     synchronized(lock) {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Interrupting Event Handling thread\");\n         eventHandlingThread.interrupt();\n       } else {\n         LOG.debug(\"Null event handling thread\");\n       }\n     }\n \n     try {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Waiting for Event Handling thread to complete\");\n         eventHandlingThread.join();\n       }\n     } catch (InterruptedException ie) {\n       LOG.info(\"Interrupted Exception while stopping\", ie);\n     }\n \n     // Cancel all timers - so that they aren\u0027t invoked during or after\n     // the metaInfo object is wrapped up.\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Shutting down timer for \" + mi);\n         }\n         mi.shutDownTimer();\n       } catch (IOException e) {\n         LOG.info(\"Exception while cancelling delayed flush timer. \"\n             + \"Likely caused by a failed flush \" + e.getMessage());\n       }\n     }\n \n     //write all the events remaining in queue\n     Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n     while(it.hasNext()) {\n       JobHistoryEvent ev \u003d it.next();\n       LOG.info(\"In stop, writing event \" + ev.getType());\n       handleEvent(ev);\n     }\n \n     // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n     // closed their event writers\n     Iterator\u003cJobId\u003e jobIt \u003d fileMap.keySet().iterator();\n     if(forceJobCompletion) {\n       while (jobIt.hasNext()) {\n         JobId toClose \u003d jobIt.next();\n         MetaInfo mi \u003d fileMap.get(toClose);\n         if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n           LOG.warn(\"Found jobId \" + toClose\n             + \" to have not been closed. Will close\");\n           //Create a JobFinishEvent so that it is written to the job history\n           final Job job \u003d context.getJob(toClose);\n           JobUnsuccessfulCompletionEvent jucEvent \u003d\n             new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                 System.currentTimeMillis(), job.getCompletedMaps(),\n-                job.getCompletedReduces(), JobState.KILLED.toString(),\n+                job.getCompletedReduces(),\n+                createJobStateForJobUnsuccessfulCompletionEvent(\n+                    mi.getForcedJobStateOnShutDown()),\n                 job.getDiagnostics());\n           JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n           //Bypass the queue mechanism which might wait. Call the method directly\n           handleEvent(jfEvent);\n         }\n       }\n     }\n \n     //close all file handles\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         mi.closeWriter();\n       } catch (IOException e) {\n         LOG.info(\"Exception while closing file \" + e.getMessage());\n       }\n     }\n     LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n     super.serviceStop();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStop() throws Exception {\n    LOG.info(\"Stopping JobHistoryEventHandler. \"\n        + \"Size of the outstanding queue size is \" + eventQueue.size());\n    stopped \u003d true;\n    //do not interrupt while event handling is in progress\n    synchronized(lock) {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Interrupting Event Handling thread\");\n        eventHandlingThread.interrupt();\n      } else {\n        LOG.debug(\"Null event handling thread\");\n      }\n    }\n\n    try {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Waiting for Event Handling thread to complete\");\n        eventHandlingThread.join();\n      }\n    } catch (InterruptedException ie) {\n      LOG.info(\"Interrupted Exception while stopping\", ie);\n    }\n\n    // Cancel all timers - so that they aren\u0027t invoked during or after\n    // the metaInfo object is wrapped up.\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Shutting down timer for \" + mi);\n        }\n        mi.shutDownTimer();\n      } catch (IOException e) {\n        LOG.info(\"Exception while cancelling delayed flush timer. \"\n            + \"Likely caused by a failed flush \" + e.getMessage());\n      }\n    }\n\n    //write all the events remaining in queue\n    Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n    while(it.hasNext()) {\n      JobHistoryEvent ev \u003d it.next();\n      LOG.info(\"In stop, writing event \" + ev.getType());\n      handleEvent(ev);\n    }\n\n    // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n    // closed their event writers\n    Iterator\u003cJobId\u003e jobIt \u003d fileMap.keySet().iterator();\n    if(forceJobCompletion) {\n      while (jobIt.hasNext()) {\n        JobId toClose \u003d jobIt.next();\n        MetaInfo mi \u003d fileMap.get(toClose);\n        if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n          LOG.warn(\"Found jobId \" + toClose\n            + \" to have not been closed. Will close\");\n          //Create a JobFinishEvent so that it is written to the job history\n          final Job job \u003d context.getJob(toClose);\n          JobUnsuccessfulCompletionEvent jucEvent \u003d\n            new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                System.currentTimeMillis(), job.getCompletedMaps(),\n                job.getCompletedReduces(),\n                createJobStateForJobUnsuccessfulCompletionEvent(\n                    mi.getForcedJobStateOnShutDown()),\n                job.getDiagnostics());\n          JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n          //Bypass the queue mechanism which might wait. Call the method directly\n          handleEvent(jfEvent);\n        }\n      }\n    }\n\n    //close all file handles\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        mi.closeWriter();\n      } catch (IOException e) {\n        LOG.info(\"Exception while closing file \" + e.getMessage());\n      }\n    }\n    LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n    super.serviceStop();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "658b1bf561aa1c0f02fc0dbb079011f959709c25": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5754. Preserve Job diagnostics in history. Contributed by Gera Shegalov\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1572269 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/02/14 1:32 PM",
      "commitName": "658b1bf561aa1c0f02fc0dbb079011f959709c25",
      "commitAuthor": "Jason Darrell Lowe",
      "commitDateOld": "29/01/14 3:51 PM",
      "commitNameOld": "db807057193311fc06caf912e13000193edd1bd8",
      "commitAuthorOld": "Sanford Ryza",
      "daysBetweenCommits": 27.9,
      "commitsBetweenForRepo": 239,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,79 +1,80 @@\n   protected void serviceStop() throws Exception {\n     LOG.info(\"Stopping JobHistoryEventHandler. \"\n         + \"Size of the outstanding queue size is \" + eventQueue.size());\n     stopped \u003d true;\n     //do not interrupt while event handling is in progress\n     synchronized(lock) {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Interrupting Event Handling thread\");\n         eventHandlingThread.interrupt();\n       } else {\n         LOG.debug(\"Null event handling thread\");\n       }\n     }\n \n     try {\n       if (eventHandlingThread !\u003d null) {\n         LOG.debug(\"Waiting for Event Handling thread to complete\");\n         eventHandlingThread.join();\n       }\n     } catch (InterruptedException ie) {\n       LOG.info(\"Interrupted Exception while stopping\", ie);\n     }\n \n     // Cancel all timers - so that they aren\u0027t invoked during or after\n     // the metaInfo object is wrapped up.\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Shutting down timer for \" + mi);\n         }\n         mi.shutDownTimer();\n       } catch (IOException e) {\n         LOG.info(\"Exception while cancelling delayed flush timer. \"\n             + \"Likely caused by a failed flush \" + e.getMessage());\n       }\n     }\n \n     //write all the events remaining in queue\n     Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n     while(it.hasNext()) {\n       JobHistoryEvent ev \u003d it.next();\n       LOG.info(\"In stop, writing event \" + ev.getType());\n       handleEvent(ev);\n     }\n \n     // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n     // closed their event writers\n     Iterator\u003cJobId\u003e jobIt \u003d fileMap.keySet().iterator();\n     if(forceJobCompletion) {\n       while (jobIt.hasNext()) {\n         JobId toClose \u003d jobIt.next();\n         MetaInfo mi \u003d fileMap.get(toClose);\n         if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n           LOG.warn(\"Found jobId \" + toClose\n             + \" to have not been closed. Will close\");\n           //Create a JobFinishEvent so that it is written to the job history\n+          final Job job \u003d context.getJob(toClose);\n           JobUnsuccessfulCompletionEvent jucEvent \u003d\n             new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n-              System.currentTimeMillis(), context.getJob(toClose)\n-              .getCompletedMaps(), context.getJob(toClose).getCompletedReduces(),\n-              JobState.KILLED.toString());\n+                System.currentTimeMillis(), job.getCompletedMaps(),\n+                job.getCompletedReduces(), JobState.KILLED.toString(),\n+                job.getDiagnostics());\n           JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n           //Bypass the queue mechanism which might wait. Call the method directly\n           handleEvent(jfEvent);\n         }\n       }\n     }\n \n     //close all file handles\n     for (MetaInfo mi : fileMap.values()) {\n       try {\n         mi.closeWriter();\n       } catch (IOException e) {\n         LOG.info(\"Exception while closing file \" + e.getMessage());\n       }\n     }\n     LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n     super.serviceStop();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStop() throws Exception {\n    LOG.info(\"Stopping JobHistoryEventHandler. \"\n        + \"Size of the outstanding queue size is \" + eventQueue.size());\n    stopped \u003d true;\n    //do not interrupt while event handling is in progress\n    synchronized(lock) {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Interrupting Event Handling thread\");\n        eventHandlingThread.interrupt();\n      } else {\n        LOG.debug(\"Null event handling thread\");\n      }\n    }\n\n    try {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Waiting for Event Handling thread to complete\");\n        eventHandlingThread.join();\n      }\n    } catch (InterruptedException ie) {\n      LOG.info(\"Interrupted Exception while stopping\", ie);\n    }\n\n    // Cancel all timers - so that they aren\u0027t invoked during or after\n    // the metaInfo object is wrapped up.\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Shutting down timer for \" + mi);\n        }\n        mi.shutDownTimer();\n      } catch (IOException e) {\n        LOG.info(\"Exception while cancelling delayed flush timer. \"\n            + \"Likely caused by a failed flush \" + e.getMessage());\n      }\n    }\n\n    //write all the events remaining in queue\n    Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n    while(it.hasNext()) {\n      JobHistoryEvent ev \u003d it.next();\n      LOG.info(\"In stop, writing event \" + ev.getType());\n      handleEvent(ev);\n    }\n\n    // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n    // closed their event writers\n    Iterator\u003cJobId\u003e jobIt \u003d fileMap.keySet().iterator();\n    if(forceJobCompletion) {\n      while (jobIt.hasNext()) {\n        JobId toClose \u003d jobIt.next();\n        MetaInfo mi \u003d fileMap.get(toClose);\n        if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n          LOG.warn(\"Found jobId \" + toClose\n            + \" to have not been closed. Will close\");\n          //Create a JobFinishEvent so that it is written to the job history\n          final Job job \u003d context.getJob(toClose);\n          JobUnsuccessfulCompletionEvent jucEvent \u003d\n            new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n                System.currentTimeMillis(), job.getCompletedMaps(),\n                job.getCompletedReduces(), JobState.KILLED.toString(),\n                job.getDiagnostics());\n          JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n          //Bypass the queue mechanism which might wait. Call the method directly\n          handleEvent(jfEvent);\n        }\n      }\n    }\n\n    //close all file handles\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        mi.closeWriter();\n      } catch (IOException e) {\n        LOG.info(\"Exception while closing file \" + e.getMessage());\n      }\n    }\n    LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n    super.serviceStop();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "0928502029ef141759008997335ea2cd836a7154": {
      "type": "Yintroduced",
      "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/06/13 8:54 AM",
      "commitName": "0928502029ef141759008997335ea2cd836a7154",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,79 @@\n+  protected void serviceStop() throws Exception {\n+    LOG.info(\"Stopping JobHistoryEventHandler. \"\n+        + \"Size of the outstanding queue size is \" + eventQueue.size());\n+    stopped \u003d true;\n+    //do not interrupt while event handling is in progress\n+    synchronized(lock) {\n+      if (eventHandlingThread !\u003d null) {\n+        LOG.debug(\"Interrupting Event Handling thread\");\n+        eventHandlingThread.interrupt();\n+      } else {\n+        LOG.debug(\"Null event handling thread\");\n+      }\n+    }\n+\n+    try {\n+      if (eventHandlingThread !\u003d null) {\n+        LOG.debug(\"Waiting for Event Handling thread to complete\");\n+        eventHandlingThread.join();\n+      }\n+    } catch (InterruptedException ie) {\n+      LOG.info(\"Interrupted Exception while stopping\", ie);\n+    }\n+\n+    // Cancel all timers - so that they aren\u0027t invoked during or after\n+    // the metaInfo object is wrapped up.\n+    for (MetaInfo mi : fileMap.values()) {\n+      try {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Shutting down timer for \" + mi);\n+        }\n+        mi.shutDownTimer();\n+      } catch (IOException e) {\n+        LOG.info(\"Exception while cancelling delayed flush timer. \"\n+            + \"Likely caused by a failed flush \" + e.getMessage());\n+      }\n+    }\n+\n+    //write all the events remaining in queue\n+    Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n+    while(it.hasNext()) {\n+      JobHistoryEvent ev \u003d it.next();\n+      LOG.info(\"In stop, writing event \" + ev.getType());\n+      handleEvent(ev);\n+    }\n+\n+    // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n+    // closed their event writers\n+    Iterator\u003cJobId\u003e jobIt \u003d fileMap.keySet().iterator();\n+    if(forceJobCompletion) {\n+      while (jobIt.hasNext()) {\n+        JobId toClose \u003d jobIt.next();\n+        MetaInfo mi \u003d fileMap.get(toClose);\n+        if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n+          LOG.warn(\"Found jobId \" + toClose\n+            + \" to have not been closed. Will close\");\n+          //Create a JobFinishEvent so that it is written to the job history\n+          JobUnsuccessfulCompletionEvent jucEvent \u003d\n+            new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n+              System.currentTimeMillis(), context.getJob(toClose)\n+              .getCompletedMaps(), context.getJob(toClose).getCompletedReduces(),\n+              JobState.KILLED.toString());\n+          JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n+          //Bypass the queue mechanism which might wait. Call the method directly\n+          handleEvent(jfEvent);\n+        }\n+      }\n+    }\n+\n+    //close all file handles\n+    for (MetaInfo mi : fileMap.values()) {\n+      try {\n+        mi.closeWriter();\n+      } catch (IOException e) {\n+        LOG.info(\"Exception while closing file \" + e.getMessage());\n+      }\n+    }\n+    LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n+    super.serviceStop();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected void serviceStop() throws Exception {\n    LOG.info(\"Stopping JobHistoryEventHandler. \"\n        + \"Size of the outstanding queue size is \" + eventQueue.size());\n    stopped \u003d true;\n    //do not interrupt while event handling is in progress\n    synchronized(lock) {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Interrupting Event Handling thread\");\n        eventHandlingThread.interrupt();\n      } else {\n        LOG.debug(\"Null event handling thread\");\n      }\n    }\n\n    try {\n      if (eventHandlingThread !\u003d null) {\n        LOG.debug(\"Waiting for Event Handling thread to complete\");\n        eventHandlingThread.join();\n      }\n    } catch (InterruptedException ie) {\n      LOG.info(\"Interrupted Exception while stopping\", ie);\n    }\n\n    // Cancel all timers - so that they aren\u0027t invoked during or after\n    // the metaInfo object is wrapped up.\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Shutting down timer for \" + mi);\n        }\n        mi.shutDownTimer();\n      } catch (IOException e) {\n        LOG.info(\"Exception while cancelling delayed flush timer. \"\n            + \"Likely caused by a failed flush \" + e.getMessage());\n      }\n    }\n\n    //write all the events remaining in queue\n    Iterator\u003cJobHistoryEvent\u003e it \u003d eventQueue.iterator();\n    while(it.hasNext()) {\n      JobHistoryEvent ev \u003d it.next();\n      LOG.info(\"In stop, writing event \" + ev.getType());\n      handleEvent(ev);\n    }\n\n    // Process JobUnsuccessfulCompletionEvent for jobIds which still haven\u0027t\n    // closed their event writers\n    Iterator\u003cJobId\u003e jobIt \u003d fileMap.keySet().iterator();\n    if(forceJobCompletion) {\n      while (jobIt.hasNext()) {\n        JobId toClose \u003d jobIt.next();\n        MetaInfo mi \u003d fileMap.get(toClose);\n        if(mi !\u003d null \u0026\u0026 mi.isWriterActive()) {\n          LOG.warn(\"Found jobId \" + toClose\n            + \" to have not been closed. Will close\");\n          //Create a JobFinishEvent so that it is written to the job history\n          JobUnsuccessfulCompletionEvent jucEvent \u003d\n            new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),\n              System.currentTimeMillis(), context.getJob(toClose)\n              .getCompletedMaps(), context.getJob(toClose).getCompletedReduces(),\n              JobState.KILLED.toString());\n          JobHistoryEvent jfEvent \u003d new JobHistoryEvent(toClose, jucEvent);\n          //Bypass the queue mechanism which might wait. Call the method directly\n          handleEvent(jfEvent);\n        }\n      }\n    }\n\n    //close all file handles\n    for (MetaInfo mi : fileMap.values()) {\n      try {\n        mi.closeWriter();\n      } catch (IOException e) {\n        LOG.info(\"Exception while closing file \" + e.getMessage());\n      }\n    }\n    LOG.info(\"Stopped JobHistoryEventHandler. super.stop()\");\n    super.serviceStop();\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java"
    }
  }
}