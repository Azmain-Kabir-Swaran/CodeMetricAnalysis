{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "LightWeightLinkedSet.java",
  "functionName": "addElem",
  "functionId": "addElem___element-T(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/LightWeightLinkedSet.java",
  "functionStartLine": 87,
  "functionEndLine": 125,
  "numCommitsSeen": 4,
  "timeTaken": 1331,
  "changeHistory": [
    "ccdb978603696a91c4828a66aad27f585543b376",
    "5258d6bf3fb8090739cf96f5089f96cee87393c4",
    "9a3f147fdd5421460889b266ead3a2300323cda2"
  ],
  "changeHistoryShort": {
    "ccdb978603696a91c4828a66aad27f585543b376": "Ybodychange",
    "5258d6bf3fb8090739cf96f5089f96cee87393c4": "Ybodychange",
    "9a3f147fdd5421460889b266ead3a2300323cda2": "Yintroduced"
  },
  "changeHistoryDetails": {
    "ccdb978603696a91c4828a66aad27f585543b376": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4366. Block Replication Policy Implementation May Skip Higher-Priority Blocks for Lower-Priority Blocks. Contributed by Derek Dagit.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1510724 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/08/13 1:48 PM",
      "commitName": "ccdb978603696a91c4828a66aad27f585543b376",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "15/07/12 7:58 PM",
      "commitNameOld": "0e8e499ff482c165d21c8e4f5ff9c33f306ca0d9",
      "commitAuthorOld": "Harsh J",
      "daysBetweenCommits": 385.74,
      "commitsBetweenForRepo": 2230,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,39 @@\n   protected boolean addElem(final T element) {\n     // validate element\n     if (element \u003d\u003d null) {\n       throw new IllegalArgumentException(\"Null element is not supported.\");\n     }\n     // find hashCode \u0026 index\n     final int hashCode \u003d element.hashCode();\n     final int index \u003d getIndex(hashCode);\n     // return false if already present\n     if (getContainedElem(index, element, hashCode) !\u003d null) {\n       return false;\n     }\n \n     modification++;\n     size++;\n \n     // update bucket linked list\n     DoubleLinkedElement\u003cT\u003e le \u003d new DoubleLinkedElement\u003cT\u003e(element, hashCode);\n     le.next \u003d entries[index];\n     entries[index] \u003d le;\n \n     // insert to the end of the all-element linked list\n     le.after \u003d null;\n     le.before \u003d tail;\n     if (tail !\u003d null) {\n       tail.after \u003d le;\n     }\n     tail \u003d le;\n     if (head \u003d\u003d null) {\n       head \u003d le;\n+      bookmark.next \u003d head;\n+    }\n+\n+    // Update bookmark, if necessary.\n+    if (bookmark.next \u003d\u003d null) {\n+      bookmark.next \u003d le;\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected boolean addElem(final T element) {\n    // validate element\n    if (element \u003d\u003d null) {\n      throw new IllegalArgumentException(\"Null element is not supported.\");\n    }\n    // find hashCode \u0026 index\n    final int hashCode \u003d element.hashCode();\n    final int index \u003d getIndex(hashCode);\n    // return false if already present\n    if (getContainedElem(index, element, hashCode) !\u003d null) {\n      return false;\n    }\n\n    modification++;\n    size++;\n\n    // update bucket linked list\n    DoubleLinkedElement\u003cT\u003e le \u003d new DoubleLinkedElement\u003cT\u003e(element, hashCode);\n    le.next \u003d entries[index];\n    entries[index] \u003d le;\n\n    // insert to the end of the all-element linked list\n    le.after \u003d null;\n    le.before \u003d tail;\n    if (tail !\u003d null) {\n      tail.after \u003d le;\n    }\n    tail \u003d le;\n    if (head \u003d\u003d null) {\n      head \u003d le;\n      bookmark.next \u003d head;\n    }\n\n    // Update bookmark, if necessary.\n    if (bookmark.next \u003d\u003d null) {\n      bookmark.next \u003d le;\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/LightWeightLinkedSet.java",
      "extendedDetails": {}
    },
    "5258d6bf3fb8090739cf96f5089f96cee87393c4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3391. Fix InvalidateBlocks to compare blocks including their generation stamps. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1339897 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/05/12 3:30 PM",
      "commitName": "5258d6bf3fb8090739cf96f5089f96cee87393c4",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "14/11/11 5:13 PM",
      "commitNameOld": "9a3f147fdd5421460889b266ead3a2300323cda2",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 184.89,
      "commitsBetweenForRepo": 1307,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,33 @@\n   protected boolean addElem(final T element) {\n     // validate element\n     if (element \u003d\u003d null) {\n       throw new IllegalArgumentException(\"Null element is not supported.\");\n     }\n     // find hashCode \u0026 index\n     final int hashCode \u003d element.hashCode();\n     final int index \u003d getIndex(hashCode);\n     // return false if already present\n-    if (containsElem(index, element, hashCode)) {\n+    if (getContainedElem(index, element, hashCode) !\u003d null) {\n       return false;\n     }\n \n     modification++;\n     size++;\n \n     // update bucket linked list\n     DoubleLinkedElement\u003cT\u003e le \u003d new DoubleLinkedElement\u003cT\u003e(element, hashCode);\n     le.next \u003d entries[index];\n     entries[index] \u003d le;\n \n     // insert to the end of the all-element linked list\n     le.after \u003d null;\n     le.before \u003d tail;\n     if (tail !\u003d null) {\n       tail.after \u003d le;\n     }\n     tail \u003d le;\n     if (head \u003d\u003d null) {\n       head \u003d le;\n     }\n     return true;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected boolean addElem(final T element) {\n    // validate element\n    if (element \u003d\u003d null) {\n      throw new IllegalArgumentException(\"Null element is not supported.\");\n    }\n    // find hashCode \u0026 index\n    final int hashCode \u003d element.hashCode();\n    final int index \u003d getIndex(hashCode);\n    // return false if already present\n    if (getContainedElem(index, element, hashCode) !\u003d null) {\n      return false;\n    }\n\n    modification++;\n    size++;\n\n    // update bucket linked list\n    DoubleLinkedElement\u003cT\u003e le \u003d new DoubleLinkedElement\u003cT\u003e(element, hashCode);\n    le.next \u003d entries[index];\n    entries[index] \u003d le;\n\n    // insert to the end of the all-element linked list\n    le.after \u003d null;\n    le.before \u003d tail;\n    if (tail !\u003d null) {\n      tail.after \u003d le;\n    }\n    tail \u003d le;\n    if (head \u003d\u003d null) {\n      head \u003d le;\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/LightWeightLinkedSet.java",
      "extendedDetails": {}
    },
    "9a3f147fdd5421460889b266ead3a2300323cda2": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2476. More CPU efficient data structure for under-replicated, over-replicated, and invalidated blocks. Contributed by Tomasz Nykiel.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1201991 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/11/11 5:13 PM",
      "commitName": "9a3f147fdd5421460889b266ead3a2300323cda2",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,33 @@\n+  protected boolean addElem(final T element) {\n+    // validate element\n+    if (element \u003d\u003d null) {\n+      throw new IllegalArgumentException(\"Null element is not supported.\");\n+    }\n+    // find hashCode \u0026 index\n+    final int hashCode \u003d element.hashCode();\n+    final int index \u003d getIndex(hashCode);\n+    // return false if already present\n+    if (containsElem(index, element, hashCode)) {\n+      return false;\n+    }\n+\n+    modification++;\n+    size++;\n+\n+    // update bucket linked list\n+    DoubleLinkedElement\u003cT\u003e le \u003d new DoubleLinkedElement\u003cT\u003e(element, hashCode);\n+    le.next \u003d entries[index];\n+    entries[index] \u003d le;\n+\n+    // insert to the end of the all-element linked list\n+    le.after \u003d null;\n+    le.before \u003d tail;\n+    if (tail !\u003d null) {\n+      tail.after \u003d le;\n+    }\n+    tail \u003d le;\n+    if (head \u003d\u003d null) {\n+      head \u003d le;\n+    }\n+    return true;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected boolean addElem(final T element) {\n    // validate element\n    if (element \u003d\u003d null) {\n      throw new IllegalArgumentException(\"Null element is not supported.\");\n    }\n    // find hashCode \u0026 index\n    final int hashCode \u003d element.hashCode();\n    final int index \u003d getIndex(hashCode);\n    // return false if already present\n    if (containsElem(index, element, hashCode)) {\n      return false;\n    }\n\n    modification++;\n    size++;\n\n    // update bucket linked list\n    DoubleLinkedElement\u003cT\u003e le \u003d new DoubleLinkedElement\u003cT\u003e(element, hashCode);\n    le.next \u003d entries[index];\n    entries[index] \u003d le;\n\n    // insert to the end of the all-element linked list\n    le.after \u003d null;\n    le.before \u003d tail;\n    if (tail !\u003d null) {\n      tail.after \u003d le;\n    }\n    tail \u003d le;\n    if (head \u003d\u003d null) {\n      head \u003d le;\n    }\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/LightWeightLinkedSet.java"
    }
  }
}