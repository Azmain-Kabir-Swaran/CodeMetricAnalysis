{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "checkReplicaOnStorage",
  "functionId": "checkReplicaOnStorage___counters-NumberReplicas__b-BlockInfo__storage-DatanodeStorageInfo__nodesCorrupt-Collection__DatanodeDescriptor____inStartupSafeMode-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 4357,
  "functionEndLine": 4396,
  "numCommitsSeen": 477,
  "timeTaken": 7617,
  "changeHistory": [
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
    "47b92f2b6f2dafc129a41b247f35e77c8e47ffba"
  ],
  "changeHistoryShort": {
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": "Ybodychange",
    "47b92f2b6f2dafc129a41b247f35e77c8e47ffba": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
      "commitDate": "17/10/16 5:45 PM",
      "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
      "commitAuthor": "Ming Ma",
      "commitDateOld": "14/10/16 6:13 PM",
      "commitNameOld": "391ce535a739dc92cb90017d759217265a4fd969",
      "commitAuthorOld": "Vinitha Reddy Gankidi",
      "daysBetweenCommits": 2.98,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,40 @@\n   private StoredReplicaState checkReplicaOnStorage(NumberReplicas counters,\n       BlockInfo b, DatanodeStorageInfo storage,\n       Collection\u003cDatanodeDescriptor\u003e nodesCorrupt, boolean inStartupSafeMode) {\n     final StoredReplicaState s;\n     if (storage.getState() \u003d\u003d State.NORMAL) {\n       final DatanodeDescriptor node \u003d storage.getDatanodeDescriptor();\n       if (nodesCorrupt !\u003d null \u0026\u0026 nodesCorrupt.contains(node)) {\n         s \u003d StoredReplicaState.CORRUPT;\n       } else if (inStartupSafeMode) {\n         s \u003d StoredReplicaState.LIVE;\n         counters.add(s, 1);\n         return s;\n       } else if (node.isDecommissionInProgress()) {\n         s \u003d StoredReplicaState.DECOMMISSIONING;\n       } else if (node.isDecommissioned()) {\n         s \u003d StoredReplicaState.DECOMMISSIONED;\n+      } else if (node.isMaintenance()) {\n+        if (node.isInMaintenance() || !node.isAlive()) {\n+          s \u003d StoredReplicaState.MAINTENANCE_NOT_FOR_READ;\n+        } else {\n+          s \u003d StoredReplicaState.MAINTENANCE_FOR_READ;\n+        }\n       } else if (isExcess(node, b)) {\n         s \u003d StoredReplicaState.EXCESS;\n       } else {\n         s \u003d StoredReplicaState.LIVE;\n       }\n       counters.add(s, 1);\n       if (storage.areBlockContentsStale()) {\n         counters.add(StoredReplicaState.STALESTORAGE, 1);\n       }\n     } else if (!inStartupSafeMode \u0026\u0026\n         storage.getState() \u003d\u003d State.READ_ONLY_SHARED) {\n       s \u003d StoredReplicaState.READONLY;\n       counters.add(s, 1);\n     } else {\n       s \u003d null;\n     }\n     return s;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private StoredReplicaState checkReplicaOnStorage(NumberReplicas counters,\n      BlockInfo b, DatanodeStorageInfo storage,\n      Collection\u003cDatanodeDescriptor\u003e nodesCorrupt, boolean inStartupSafeMode) {\n    final StoredReplicaState s;\n    if (storage.getState() \u003d\u003d State.NORMAL) {\n      final DatanodeDescriptor node \u003d storage.getDatanodeDescriptor();\n      if (nodesCorrupt !\u003d null \u0026\u0026 nodesCorrupt.contains(node)) {\n        s \u003d StoredReplicaState.CORRUPT;\n      } else if (inStartupSafeMode) {\n        s \u003d StoredReplicaState.LIVE;\n        counters.add(s, 1);\n        return s;\n      } else if (node.isDecommissionInProgress()) {\n        s \u003d StoredReplicaState.DECOMMISSIONING;\n      } else if (node.isDecommissioned()) {\n        s \u003d StoredReplicaState.DECOMMISSIONED;\n      } else if (node.isMaintenance()) {\n        if (node.isInMaintenance() || !node.isAlive()) {\n          s \u003d StoredReplicaState.MAINTENANCE_NOT_FOR_READ;\n        } else {\n          s \u003d StoredReplicaState.MAINTENANCE_FOR_READ;\n        }\n      } else if (isExcess(node, b)) {\n        s \u003d StoredReplicaState.EXCESS;\n      } else {\n        s \u003d StoredReplicaState.LIVE;\n      }\n      counters.add(s, 1);\n      if (storage.areBlockContentsStale()) {\n        counters.add(StoredReplicaState.STALESTORAGE, 1);\n      }\n    } else if (!inStartupSafeMode \u0026\u0026\n        storage.getState() \u003d\u003d State.READ_ONLY_SHARED) {\n      s \u003d StoredReplicaState.READONLY;\n      counters.add(s, 1);\n    } else {\n      s \u003d null;\n    }\n    return s;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "47b92f2b6f2dafc129a41b247f35e77c8e47ffba": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9837. BlockManager#countNodes should be able to detect duplicated internal blocks. Contributed by Jing Zhao.\n",
      "commitDate": "24/02/16 3:13 PM",
      "commitName": "47b92f2b6f2dafc129a41b247f35e77c8e47ffba",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,34 @@\n+  private StoredReplicaState checkReplicaOnStorage(NumberReplicas counters,\n+      BlockInfo b, DatanodeStorageInfo storage,\n+      Collection\u003cDatanodeDescriptor\u003e nodesCorrupt, boolean inStartupSafeMode) {\n+    final StoredReplicaState s;\n+    if (storage.getState() \u003d\u003d State.NORMAL) {\n+      final DatanodeDescriptor node \u003d storage.getDatanodeDescriptor();\n+      if (nodesCorrupt !\u003d null \u0026\u0026 nodesCorrupt.contains(node)) {\n+        s \u003d StoredReplicaState.CORRUPT;\n+      } else if (inStartupSafeMode) {\n+        s \u003d StoredReplicaState.LIVE;\n+        counters.add(s, 1);\n+        return s;\n+      } else if (node.isDecommissionInProgress()) {\n+        s \u003d StoredReplicaState.DECOMMISSIONING;\n+      } else if (node.isDecommissioned()) {\n+        s \u003d StoredReplicaState.DECOMMISSIONED;\n+      } else if (isExcess(node, b)) {\n+        s \u003d StoredReplicaState.EXCESS;\n+      } else {\n+        s \u003d StoredReplicaState.LIVE;\n+      }\n+      counters.add(s, 1);\n+      if (storage.areBlockContentsStale()) {\n+        counters.add(StoredReplicaState.STALESTORAGE, 1);\n+      }\n+    } else if (!inStartupSafeMode \u0026\u0026\n+        storage.getState() \u003d\u003d State.READ_ONLY_SHARED) {\n+      s \u003d StoredReplicaState.READONLY;\n+      counters.add(s, 1);\n+    } else {\n+      s \u003d null;\n+    }\n+    return s;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private StoredReplicaState checkReplicaOnStorage(NumberReplicas counters,\n      BlockInfo b, DatanodeStorageInfo storage,\n      Collection\u003cDatanodeDescriptor\u003e nodesCorrupt, boolean inStartupSafeMode) {\n    final StoredReplicaState s;\n    if (storage.getState() \u003d\u003d State.NORMAL) {\n      final DatanodeDescriptor node \u003d storage.getDatanodeDescriptor();\n      if (nodesCorrupt !\u003d null \u0026\u0026 nodesCorrupt.contains(node)) {\n        s \u003d StoredReplicaState.CORRUPT;\n      } else if (inStartupSafeMode) {\n        s \u003d StoredReplicaState.LIVE;\n        counters.add(s, 1);\n        return s;\n      } else if (node.isDecommissionInProgress()) {\n        s \u003d StoredReplicaState.DECOMMISSIONING;\n      } else if (node.isDecommissioned()) {\n        s \u003d StoredReplicaState.DECOMMISSIONED;\n      } else if (isExcess(node, b)) {\n        s \u003d StoredReplicaState.EXCESS;\n      } else {\n        s \u003d StoredReplicaState.LIVE;\n      }\n      counters.add(s, 1);\n      if (storage.areBlockContentsStale()) {\n        counters.add(StoredReplicaState.STALESTORAGE, 1);\n      }\n    } else if (!inStartupSafeMode \u0026\u0026\n        storage.getState() \u003d\u003d State.READ_ONLY_SHARED) {\n      s \u003d StoredReplicaState.READONLY;\n      counters.add(s, 1);\n    } else {\n      s \u003d null;\n    }\n    return s;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
    }
  }
}