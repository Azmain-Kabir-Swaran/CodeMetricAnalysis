{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AzureNativeFileSystemStore.java",
  "functionName": "retrieve",
  "functionId": "retrieve___key-String__startByteOffset-long",
  "sourceFilePath": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
  "functionStartLine": 2263,
  "functionEndLine": 2290,
  "numCommitsSeen": 53,
  "timeTaken": 3213,
  "changeHistory": [
    "d670c3a4da7dd80dccf6c6308603bb3bb013b3b0",
    "2217e2f8ff418b88eac6ad36cafe3a9795a11f40",
    "8300b9fb385b47672d98ea62ab291991424f3cce",
    "81bc395deb3ba00567dc067d6ca71bacf9e3bc82"
  ],
  "changeHistoryShort": {
    "d670c3a4da7dd80dccf6c6308603bb3bb013b3b0": "Ymultichange(Yreturntypechange,Ybodychange)",
    "2217e2f8ff418b88eac6ad36cafe3a9795a11f40": "Ymultichange(Yexceptionschange,Ybodychange)",
    "8300b9fb385b47672d98ea62ab291991424f3cce": "Ybodychange",
    "81bc395deb3ba00567dc067d6ca71bacf9e3bc82": "Yintroduced"
  },
  "changeHistoryDetails": {
    "d670c3a4da7dd80dccf6c6308603bb3bb013b3b0": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HADOOP-14535 wasb: implement high-performance random access and seek of block blobs.\nContributed by Thomas Marquardt\n",
      "commitDate": "11/07/17 1:34 PM",
      "commitName": "d670c3a4da7dd80dccf6c6308603bb3bb013b3b0",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HADOOP-14535 wasb: implement high-performance random access and seek of block blobs.\nContributed by Thomas Marquardt\n",
          "commitDate": "11/07/17 1:34 PM",
          "commitName": "d670c3a4da7dd80dccf6c6308603bb3bb013b3b0",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "28/06/17 2:18 PM",
          "commitNameOld": "990aa34de23c625163745ebc338483065d955bbe",
          "commitAuthorOld": "Mingliang Liu",
          "daysBetweenCommits": 12.97,
          "commitsBetweenForRepo": 50,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,28 @@\n-  public DataInputStream retrieve(String key, long startByteOffset)\n+  public InputStream retrieve(String key, long startByteOffset)\n       throws AzureException, IOException {\n       try {\n         // Check if a session exists, if not create a session with the\n         // Azure storage server.\n         if (null \u003d\u003d storageInteractionLayer) {\n           final String errMsg \u003d String.format(\n               \"Storage session expected for URI \u0027%s\u0027 but does not exist.\",\n               sessionUri);\n           throw new AssertionError(errMsg);\n         }\n         checkContainer(ContainerAccessType.PureRead);\n \n-        // Get blob reference and open the input buffer stream.\n-        CloudBlobWrapper blob \u003d getBlobReference(key);\n-\n-        // Open input stream and seek to the start offset.\n-        InputStream in \u003d blob.openInputStream(\n-          getDownloadOptions(), getInstrumentedContext(isConcurrentOOBAppendAllowed()));\n-\n-        // Create a data input stream.\n-\t    DataInputStream inDataStream \u003d new DataInputStream(in);\n-\t    \n-\t    // Skip bytes and ignore return value. This is okay\n-\t    // because if you try to skip too far you will be positioned\n-\t    // at the end and reads will not return data.\n-\t    inDataStream.skip(startByteOffset);\n-        return inDataStream;\n+        InputStream inputStream \u003d openInputStream(getBlobReference(key));\n+        if (startByteOffset \u003e 0) {\n+          // Skip bytes and ignore return value. This is okay\n+          // because if you try to skip too far you will be positioned\n+          // at the end and reads will not return data.\n+          inputStream.skip(startByteOffset);\n+        }\n+        return inputStream;\n+    } catch (IOException e) {\n+        throw e;\n     } catch (Exception e) {\n-      // Re-throw as an Azure storage exception.\n-      throw new AzureException(e);\n+        // Re-throw as an Azure storage exception.\n+        throw new AzureException(e);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public InputStream retrieve(String key, long startByteOffset)\n      throws AzureException, IOException {\n      try {\n        // Check if a session exists, if not create a session with the\n        // Azure storage server.\n        if (null \u003d\u003d storageInteractionLayer) {\n          final String errMsg \u003d String.format(\n              \"Storage session expected for URI \u0027%s\u0027 but does not exist.\",\n              sessionUri);\n          throw new AssertionError(errMsg);\n        }\n        checkContainer(ContainerAccessType.PureRead);\n\n        InputStream inputStream \u003d openInputStream(getBlobReference(key));\n        if (startByteOffset \u003e 0) {\n          // Skip bytes and ignore return value. This is okay\n          // because if you try to skip too far you will be positioned\n          // at the end and reads will not return data.\n          inputStream.skip(startByteOffset);\n        }\n        return inputStream;\n    } catch (IOException e) {\n        throw e;\n    } catch (Exception e) {\n        // Re-throw as an Azure storage exception.\n        throw new AzureException(e);\n    }\n  }",
          "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
          "extendedDetails": {
            "oldValue": "DataInputStream",
            "newValue": "InputStream"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-14535 wasb: implement high-performance random access and seek of block blobs.\nContributed by Thomas Marquardt\n",
          "commitDate": "11/07/17 1:34 PM",
          "commitName": "d670c3a4da7dd80dccf6c6308603bb3bb013b3b0",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "28/06/17 2:18 PM",
          "commitNameOld": "990aa34de23c625163745ebc338483065d955bbe",
          "commitAuthorOld": "Mingliang Liu",
          "daysBetweenCommits": 12.97,
          "commitsBetweenForRepo": 50,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,28 @@\n-  public DataInputStream retrieve(String key, long startByteOffset)\n+  public InputStream retrieve(String key, long startByteOffset)\n       throws AzureException, IOException {\n       try {\n         // Check if a session exists, if not create a session with the\n         // Azure storage server.\n         if (null \u003d\u003d storageInteractionLayer) {\n           final String errMsg \u003d String.format(\n               \"Storage session expected for URI \u0027%s\u0027 but does not exist.\",\n               sessionUri);\n           throw new AssertionError(errMsg);\n         }\n         checkContainer(ContainerAccessType.PureRead);\n \n-        // Get blob reference and open the input buffer stream.\n-        CloudBlobWrapper blob \u003d getBlobReference(key);\n-\n-        // Open input stream and seek to the start offset.\n-        InputStream in \u003d blob.openInputStream(\n-          getDownloadOptions(), getInstrumentedContext(isConcurrentOOBAppendAllowed()));\n-\n-        // Create a data input stream.\n-\t    DataInputStream inDataStream \u003d new DataInputStream(in);\n-\t    \n-\t    // Skip bytes and ignore return value. This is okay\n-\t    // because if you try to skip too far you will be positioned\n-\t    // at the end and reads will not return data.\n-\t    inDataStream.skip(startByteOffset);\n-        return inDataStream;\n+        InputStream inputStream \u003d openInputStream(getBlobReference(key));\n+        if (startByteOffset \u003e 0) {\n+          // Skip bytes and ignore return value. This is okay\n+          // because if you try to skip too far you will be positioned\n+          // at the end and reads will not return data.\n+          inputStream.skip(startByteOffset);\n+        }\n+        return inputStream;\n+    } catch (IOException e) {\n+        throw e;\n     } catch (Exception e) {\n-      // Re-throw as an Azure storage exception.\n-      throw new AzureException(e);\n+        // Re-throw as an Azure storage exception.\n+        throw new AzureException(e);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public InputStream retrieve(String key, long startByteOffset)\n      throws AzureException, IOException {\n      try {\n        // Check if a session exists, if not create a session with the\n        // Azure storage server.\n        if (null \u003d\u003d storageInteractionLayer) {\n          final String errMsg \u003d String.format(\n              \"Storage session expected for URI \u0027%s\u0027 but does not exist.\",\n              sessionUri);\n          throw new AssertionError(errMsg);\n        }\n        checkContainer(ContainerAccessType.PureRead);\n\n        InputStream inputStream \u003d openInputStream(getBlobReference(key));\n        if (startByteOffset \u003e 0) {\n          // Skip bytes and ignore return value. This is okay\n          // because if you try to skip too far you will be positioned\n          // at the end and reads will not return data.\n          inputStream.skip(startByteOffset);\n        }\n        return inputStream;\n    } catch (IOException e) {\n        throw e;\n    } catch (Exception e) {\n        // Re-throw as an Azure storage exception.\n        throw new AzureException(e);\n    }\n  }",
          "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
          "extendedDetails": {}
        }
      ]
    },
    "2217e2f8ff418b88eac6ad36cafe3a9795a11f40": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HADOOP-10809. hadoop-azure: page blob support. Contributed by Dexter Bradshaw, Mostafa Elhemali, Eric Hanson, and Mike Liddell.\n",
      "commitDate": "08/10/14 2:20 PM",
      "commitName": "2217e2f8ff418b88eac6ad36cafe3a9795a11f40",
      "commitAuthor": "cnauroth",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HADOOP-10809. hadoop-azure: page blob support. Contributed by Dexter Bradshaw, Mostafa Elhemali, Eric Hanson, and Mike Liddell.\n",
          "commitDate": "08/10/14 2:20 PM",
          "commitName": "2217e2f8ff418b88eac6ad36cafe3a9795a11f40",
          "commitAuthor": "cnauroth",
          "commitDateOld": "24/06/14 1:52 PM",
          "commitNameOld": "0d91576ec31f63402f2db6107a04155368e2632d",
          "commitAuthorOld": "Chris Nauroth",
          "daysBetweenCommits": 106.02,
          "commitsBetweenForRepo": 1005,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,48 +1,33 @@\n   public DataInputStream retrieve(String key, long startByteOffset)\n-      throws AzureException {\n-\n-    InputStream in \u003d null;\n-    DataInputStream inDataStream \u003d null;\n-    try {\n+      throws AzureException, IOException {\n       try {\n         // Check if a session exists, if not create a session with the\n         // Azure storage server.\n         if (null \u003d\u003d storageInteractionLayer) {\n           final String errMsg \u003d String.format(\n               \"Storage session expected for URI \u0027%s\u0027 but does not exist.\",\n               sessionUri);\n           throw new AssertionError(errMsg);\n         }\n         checkContainer(ContainerAccessType.PureRead);\n \n         // Get blob reference and open the input buffer stream.\n-        CloudBlockBlobWrapper blob \u003d getBlobReference(key);\n+        CloudBlobWrapper blob \u003d getBlobReference(key);\n \n         // Open input stream and seek to the start offset.\n-        in \u003d blob.openInputStream(getDownloadOptions(),\n-            getInstrumentedContext(isConcurrentOOBAppendAllowed()));\n+        InputStream in \u003d blob.openInputStream(\n+          getDownloadOptions(), getInstrumentedContext(isConcurrentOOBAppendAllowed()));\n \n         // Create a data input stream.\n-        inDataStream \u003d new DataInputStream(in);\n-        long skippedBytes \u003d inDataStream.skip(startByteOffset);\n-        if (skippedBytes !\u003d startByteOffset) {\n-          throw new IOException(\"Couldn\u0027t skip the requested number of bytes\");\n-        }\n+\t    DataInputStream inDataStream \u003d new DataInputStream(in);\n+\t    \n+\t    // Skip bytes and ignore return value. This is okay\n+\t    // because if you try to skip too far you will be positioned\n+\t    // at the end and reads will not return data.\n+\t    inDataStream.skip(startByteOffset);\n         return inDataStream;\n-      }\n-      catch (Exception e){\n-        // close the streams on error.\n-        // We use nested try-catch as stream.close() can throw IOException.\n-        if(inDataStream !\u003d null){\n-          inDataStream.close();\n-        }\n-        if(in !\u003d null){\n-          in.close();\n-        }\n-        throw e;\n-      }\n     } catch (Exception e) {\n       // Re-throw as an Azure storage exception.\n       throw new AzureException(e);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DataInputStream retrieve(String key, long startByteOffset)\n      throws AzureException, IOException {\n      try {\n        // Check if a session exists, if not create a session with the\n        // Azure storage server.\n        if (null \u003d\u003d storageInteractionLayer) {\n          final String errMsg \u003d String.format(\n              \"Storage session expected for URI \u0027%s\u0027 but does not exist.\",\n              sessionUri);\n          throw new AssertionError(errMsg);\n        }\n        checkContainer(ContainerAccessType.PureRead);\n\n        // Get blob reference and open the input buffer stream.\n        CloudBlobWrapper blob \u003d getBlobReference(key);\n\n        // Open input stream and seek to the start offset.\n        InputStream in \u003d blob.openInputStream(\n          getDownloadOptions(), getInstrumentedContext(isConcurrentOOBAppendAllowed()));\n\n        // Create a data input stream.\n\t    DataInputStream inDataStream \u003d new DataInputStream(in);\n\t    \n\t    // Skip bytes and ignore return value. This is okay\n\t    // because if you try to skip too far you will be positioned\n\t    // at the end and reads will not return data.\n\t    inDataStream.skip(startByteOffset);\n        return inDataStream;\n    } catch (Exception e) {\n      // Re-throw as an Azure storage exception.\n      throw new AzureException(e);\n    }\n  }",
          "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
          "extendedDetails": {
            "oldValue": "[AzureException]",
            "newValue": "[AzureException, IOException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-10809. hadoop-azure: page blob support. Contributed by Dexter Bradshaw, Mostafa Elhemali, Eric Hanson, and Mike Liddell.\n",
          "commitDate": "08/10/14 2:20 PM",
          "commitName": "2217e2f8ff418b88eac6ad36cafe3a9795a11f40",
          "commitAuthor": "cnauroth",
          "commitDateOld": "24/06/14 1:52 PM",
          "commitNameOld": "0d91576ec31f63402f2db6107a04155368e2632d",
          "commitAuthorOld": "Chris Nauroth",
          "daysBetweenCommits": 106.02,
          "commitsBetweenForRepo": 1005,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,48 +1,33 @@\n   public DataInputStream retrieve(String key, long startByteOffset)\n-      throws AzureException {\n-\n-    InputStream in \u003d null;\n-    DataInputStream inDataStream \u003d null;\n-    try {\n+      throws AzureException, IOException {\n       try {\n         // Check if a session exists, if not create a session with the\n         // Azure storage server.\n         if (null \u003d\u003d storageInteractionLayer) {\n           final String errMsg \u003d String.format(\n               \"Storage session expected for URI \u0027%s\u0027 but does not exist.\",\n               sessionUri);\n           throw new AssertionError(errMsg);\n         }\n         checkContainer(ContainerAccessType.PureRead);\n \n         // Get blob reference and open the input buffer stream.\n-        CloudBlockBlobWrapper blob \u003d getBlobReference(key);\n+        CloudBlobWrapper blob \u003d getBlobReference(key);\n \n         // Open input stream and seek to the start offset.\n-        in \u003d blob.openInputStream(getDownloadOptions(),\n-            getInstrumentedContext(isConcurrentOOBAppendAllowed()));\n+        InputStream in \u003d blob.openInputStream(\n+          getDownloadOptions(), getInstrumentedContext(isConcurrentOOBAppendAllowed()));\n \n         // Create a data input stream.\n-        inDataStream \u003d new DataInputStream(in);\n-        long skippedBytes \u003d inDataStream.skip(startByteOffset);\n-        if (skippedBytes !\u003d startByteOffset) {\n-          throw new IOException(\"Couldn\u0027t skip the requested number of bytes\");\n-        }\n+\t    DataInputStream inDataStream \u003d new DataInputStream(in);\n+\t    \n+\t    // Skip bytes and ignore return value. This is okay\n+\t    // because if you try to skip too far you will be positioned\n+\t    // at the end and reads will not return data.\n+\t    inDataStream.skip(startByteOffset);\n         return inDataStream;\n-      }\n-      catch (Exception e){\n-        // close the streams on error.\n-        // We use nested try-catch as stream.close() can throw IOException.\n-        if(inDataStream !\u003d null){\n-          inDataStream.close();\n-        }\n-        if(in !\u003d null){\n-          in.close();\n-        }\n-        throw e;\n-      }\n     } catch (Exception e) {\n       // Re-throw as an Azure storage exception.\n       throw new AzureException(e);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public DataInputStream retrieve(String key, long startByteOffset)\n      throws AzureException, IOException {\n      try {\n        // Check if a session exists, if not create a session with the\n        // Azure storage server.\n        if (null \u003d\u003d storageInteractionLayer) {\n          final String errMsg \u003d String.format(\n              \"Storage session expected for URI \u0027%s\u0027 but does not exist.\",\n              sessionUri);\n          throw new AssertionError(errMsg);\n        }\n        checkContainer(ContainerAccessType.PureRead);\n\n        // Get blob reference and open the input buffer stream.\n        CloudBlobWrapper blob \u003d getBlobReference(key);\n\n        // Open input stream and seek to the start offset.\n        InputStream in \u003d blob.openInputStream(\n          getDownloadOptions(), getInstrumentedContext(isConcurrentOOBAppendAllowed()));\n\n        // Create a data input stream.\n\t    DataInputStream inDataStream \u003d new DataInputStream(in);\n\t    \n\t    // Skip bytes and ignore return value. This is okay\n\t    // because if you try to skip too far you will be positioned\n\t    // at the end and reads will not return data.\n\t    inDataStream.skip(startByteOffset);\n        return inDataStream;\n    } catch (Exception e) {\n      // Re-throw as an Azure storage exception.\n      throw new AzureException(e);\n    }\n  }",
          "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
          "extendedDetails": {}
        }
      ]
    },
    "8300b9fb385b47672d98ea62ab291991424f3cce": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10689. InputStream is not closed in AzureNativeFileSystemStore#retrieve(). Contributed by Chen He.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1604233 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/06/14 11:30 AM",
      "commitName": "8300b9fb385b47672d98ea62ab291991424f3cce",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "10/06/14 3:26 PM",
      "commitNameOld": "81bc395deb3ba00567dc067d6ca71bacf9e3bc82",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 9.84,
      "commitsBetweenForRepo": 78,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,48 @@\n   public DataInputStream retrieve(String key, long startByteOffset)\n       throws AzureException {\n \n     InputStream in \u003d null;\n     DataInputStream inDataStream \u003d null;\n     try {\n       try {\n         // Check if a session exists, if not create a session with the\n         // Azure storage server.\n         if (null \u003d\u003d storageInteractionLayer) {\n           final String errMsg \u003d String.format(\n               \"Storage session expected for URI \u0027%s\u0027 but does not exist.\",\n               sessionUri);\n           throw new AssertionError(errMsg);\n         }\n         checkContainer(ContainerAccessType.PureRead);\n \n         // Get blob reference and open the input buffer stream.\n         CloudBlockBlobWrapper blob \u003d getBlobReference(key);\n \n         // Open input stream and seek to the start offset.\n         in \u003d blob.openInputStream(getDownloadOptions(),\n             getInstrumentedContext(isConcurrentOOBAppendAllowed()));\n \n         // Create a data input stream.\n         inDataStream \u003d new DataInputStream(in);\n         long skippedBytes \u003d inDataStream.skip(startByteOffset);\n         if (skippedBytes !\u003d startByteOffset) {\n           throw new IOException(\"Couldn\u0027t skip the requested number of bytes\");\n         }\n         return inDataStream;\n       }\n       catch (Exception e){\n         // close the streams on error.\n         // We use nested try-catch as stream.close() can throw IOException.\n         if(inDataStream !\u003d null){\n           inDataStream.close();\n         }\n         if(in !\u003d null){\n-          inDataStream.close();\n+          in.close();\n         }\n         throw e;\n       }\n     } catch (Exception e) {\n       // Re-throw as an Azure storage exception.\n       throw new AzureException(e);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DataInputStream retrieve(String key, long startByteOffset)\n      throws AzureException {\n\n    InputStream in \u003d null;\n    DataInputStream inDataStream \u003d null;\n    try {\n      try {\n        // Check if a session exists, if not create a session with the\n        // Azure storage server.\n        if (null \u003d\u003d storageInteractionLayer) {\n          final String errMsg \u003d String.format(\n              \"Storage session expected for URI \u0027%s\u0027 but does not exist.\",\n              sessionUri);\n          throw new AssertionError(errMsg);\n        }\n        checkContainer(ContainerAccessType.PureRead);\n\n        // Get blob reference and open the input buffer stream.\n        CloudBlockBlobWrapper blob \u003d getBlobReference(key);\n\n        // Open input stream and seek to the start offset.\n        in \u003d blob.openInputStream(getDownloadOptions(),\n            getInstrumentedContext(isConcurrentOOBAppendAllowed()));\n\n        // Create a data input stream.\n        inDataStream \u003d new DataInputStream(in);\n        long skippedBytes \u003d inDataStream.skip(startByteOffset);\n        if (skippedBytes !\u003d startByteOffset) {\n          throw new IOException(\"Couldn\u0027t skip the requested number of bytes\");\n        }\n        return inDataStream;\n      }\n      catch (Exception e){\n        // close the streams on error.\n        // We use nested try-catch as stream.close() can throw IOException.\n        if(inDataStream !\u003d null){\n          inDataStream.close();\n        }\n        if(in !\u003d null){\n          in.close();\n        }\n        throw e;\n      }\n    } catch (Exception e) {\n      // Re-throw as an Azure storage exception.\n      throw new AzureException(e);\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java",
      "extendedDetails": {}
    },
    "81bc395deb3ba00567dc067d6ca71bacf9e3bc82": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-9629. Support Windows Azure Storage - Blob as a file system in Hadoop. Contributed by Dexter Bradshaw, Mostafa Elhemali, Xi Fang, Johannes Klein, David Lao, Mike Liddell, Chuan Liu, Lengning Liu, Ivan Mitic, Michael Rys, Alexander Stojanovic, Brian Swan, and Min Wei.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1601781 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/06/14 3:26 PM",
      "commitName": "81bc395deb3ba00567dc067d6ca71bacf9e3bc82",
      "commitAuthor": "Chris Nauroth",
      "diff": "@@ -0,0 +1,48 @@\n+  public DataInputStream retrieve(String key, long startByteOffset)\n+      throws AzureException {\n+\n+    InputStream in \u003d null;\n+    DataInputStream inDataStream \u003d null;\n+    try {\n+      try {\n+        // Check if a session exists, if not create a session with the\n+        // Azure storage server.\n+        if (null \u003d\u003d storageInteractionLayer) {\n+          final String errMsg \u003d String.format(\n+              \"Storage session expected for URI \u0027%s\u0027 but does not exist.\",\n+              sessionUri);\n+          throw new AssertionError(errMsg);\n+        }\n+        checkContainer(ContainerAccessType.PureRead);\n+\n+        // Get blob reference and open the input buffer stream.\n+        CloudBlockBlobWrapper blob \u003d getBlobReference(key);\n+\n+        // Open input stream and seek to the start offset.\n+        in \u003d blob.openInputStream(getDownloadOptions(),\n+            getInstrumentedContext(isConcurrentOOBAppendAllowed()));\n+\n+        // Create a data input stream.\n+        inDataStream \u003d new DataInputStream(in);\n+        long skippedBytes \u003d inDataStream.skip(startByteOffset);\n+        if (skippedBytes !\u003d startByteOffset) {\n+          throw new IOException(\"Couldn\u0027t skip the requested number of bytes\");\n+        }\n+        return inDataStream;\n+      }\n+      catch (Exception e){\n+        // close the streams on error.\n+        // We use nested try-catch as stream.close() can throw IOException.\n+        if(inDataStream !\u003d null){\n+          inDataStream.close();\n+        }\n+        if(in !\u003d null){\n+          inDataStream.close();\n+        }\n+        throw e;\n+      }\n+    } catch (Exception e) {\n+      // Re-throw as an Azure storage exception.\n+      throw new AzureException(e);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public DataInputStream retrieve(String key, long startByteOffset)\n      throws AzureException {\n\n    InputStream in \u003d null;\n    DataInputStream inDataStream \u003d null;\n    try {\n      try {\n        // Check if a session exists, if not create a session with the\n        // Azure storage server.\n        if (null \u003d\u003d storageInteractionLayer) {\n          final String errMsg \u003d String.format(\n              \"Storage session expected for URI \u0027%s\u0027 but does not exist.\",\n              sessionUri);\n          throw new AssertionError(errMsg);\n        }\n        checkContainer(ContainerAccessType.PureRead);\n\n        // Get blob reference and open the input buffer stream.\n        CloudBlockBlobWrapper blob \u003d getBlobReference(key);\n\n        // Open input stream and seek to the start offset.\n        in \u003d blob.openInputStream(getDownloadOptions(),\n            getInstrumentedContext(isConcurrentOOBAppendAllowed()));\n\n        // Create a data input stream.\n        inDataStream \u003d new DataInputStream(in);\n        long skippedBytes \u003d inDataStream.skip(startByteOffset);\n        if (skippedBytes !\u003d startByteOffset) {\n          throw new IOException(\"Couldn\u0027t skip the requested number of bytes\");\n        }\n        return inDataStream;\n      }\n      catch (Exception e){\n        // close the streams on error.\n        // We use nested try-catch as stream.close() can throw IOException.\n        if(inDataStream !\u003d null){\n          inDataStream.close();\n        }\n        if(in !\u003d null){\n          inDataStream.close();\n        }\n        throw e;\n      }\n    } catch (Exception e) {\n      // Re-throw as an Azure storage exception.\n      throw new AzureException(e);\n    }\n  }",
      "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/AzureNativeFileSystemStore.java"
    }
  }
}