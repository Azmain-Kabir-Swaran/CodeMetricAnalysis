{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FileWithSnapshotFeature.java",
  "functionName": "updateQuotaAndCollectBlocks",
  "functionId": "updateQuotaAndCollectBlocks___reclaimContext-INode.ReclaimContext__file-INodeFile__removed-FileDiff",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
  "functionStartLine": 148,
  "functionEndLine": 212,
  "numCommitsSeen": 109,
  "timeTaken": 10639,
  "changeHistory": [
    "2148a8fe645333444c4e8110bb56acf0fb8e41b4",
    "130f89e068ca346a44fa6619ae0726c1e5cc5d06",
    "3afd4cbe89eb79c12465077a2f55949a800f32ae",
    "745d04be59accf80feda0ad38efcc74ba362f2ca",
    "b2c85db86c9a62b0a03ee87547265077f664970a",
    "6d5da9484185ca9f585195d6da069b9cd5be4044",
    "4536399d47f6c061e149e2504600804a0f1e093d",
    "02a4a22b9c0e22c2e7dd6ec85edd5c5a167fe19f",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
    "5c97db07fb306842f49d73a67a90cecec19a7833",
    "f2231cebcddc80f0b753c4a7cb45ee4040846951",
    "5dae97a584d30cef3e34141edfaca49c4ec57913",
    "08ac06283a3e9bf0d49d873823aabd419b08e41f",
    "50ae1a6664a92619aa683d2a864d0da9fb4af026",
    "4c87a27ad851ffaa3cc3e2074a9ef7073b5a164a",
    "8df119da214babde03e73243c7ca4cfe6d0ca562",
    "e097f8404b3ffbad5322e0f8381a0b9958c5b589",
    "92e0416ced279a910616985bf11fa3f8b1b1de9b",
    "3b3ea5c4220e674064c7603a449f63904c10bac1"
  ],
  "changeHistoryShort": {
    "2148a8fe645333444c4e8110bb56acf0fb8e41b4": "Ybodychange",
    "130f89e068ca346a44fa6619ae0726c1e5cc5d06": "Ybodychange",
    "3afd4cbe89eb79c12465077a2f55949a800f32ae": "Ybodychange",
    "745d04be59accf80feda0ad38efcc74ba362f2ca": "Ybodychange",
    "b2c85db86c9a62b0a03ee87547265077f664970a": "Ymultichange(Yreturntypechange,Ybodychange)",
    "6d5da9484185ca9f585195d6da069b9cd5be4044": "Ybodychange",
    "4536399d47f6c061e149e2504600804a0f1e093d": "Ymultichange(Yparameterchange,Ybodychange)",
    "02a4a22b9c0e22c2e7dd6ec85edd5c5a167fe19f": "Ybodychange",
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": "Ybodychange",
    "5c97db07fb306842f49d73a67a90cecec19a7833": "Ybodychange",
    "f2231cebcddc80f0b753c4a7cb45ee4040846951": "Ybodychange",
    "5dae97a584d30cef3e34141edfaca49c4ec57913": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
    "08ac06283a3e9bf0d49d873823aabd419b08e41f": "Ybodychange",
    "50ae1a6664a92619aa683d2a864d0da9fb4af026": "Ybodychange",
    "4c87a27ad851ffaa3cc3e2074a9ef7073b5a164a": "Ymultichange(Yfilerename,Ymodifierchange,Ybodychange,Yparameterchange)",
    "8df119da214babde03e73243c7ca4cfe6d0ca562": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yparameterchange)",
    "e097f8404b3ffbad5322e0f8381a0b9958c5b589": "Ybodychange",
    "92e0416ced279a910616985bf11fa3f8b1b1de9b": "Ymultichange(Yparameterchange,Ybodychange)",
    "3b3ea5c4220e674064c7603a449f63904c10bac1": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2148a8fe645333444c4e8110bb56acf0fb8e41b4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15362. FileWithSnapshotFeature#updateQuotaAndCollectBlocks should collect all distinct blocks. Contributed by hemanthboyina.\n",
      "commitDate": "27/05/20 11:06 AM",
      "commitName": "2148a8fe645333444c4e8110bb56acf0fb8e41b4",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "06/05/20 1:18 PM",
      "commitNameOld": "130f89e068ca346a44fa6619ae0726c1e5cc5d06",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 20.91,
      "commitsBetweenForRepo": 77,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,64 +1,65 @@\n   public void updateQuotaAndCollectBlocks(INode.ReclaimContext reclaimContext,\n       INodeFile file, FileDiff removed) {\n     byte storagePolicyID \u003d file.getStoragePolicyID();\n     BlockStoragePolicy bsp \u003d null;\n     if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n       bsp \u003d reclaimContext.storagePolicySuite().\n           getPolicy(file.getStoragePolicyID());\n     }\n \n     QuotaCounts oldCounts;\n     if (removed.snapshotINode !\u003d null) {\n       oldCounts \u003d new QuotaCounts.Builder().build();\n-      List\u003cBlockInfo\u003e allBlocks \u003d new ArrayList\u003cBlockInfo\u003e();\n+      // collect all distinct blocks\n+      Set\u003cBlockInfo\u003e allBlocks \u003d new HashSet\u003cBlockInfo\u003e();\n       if (file.getBlocks() !\u003d null) {\n         allBlocks.addAll(Arrays.asList(file.getBlocks()));\n       }\n       if (removed.getBlocks() !\u003d null) {\n         allBlocks.addAll(Arrays.asList(removed.getBlocks()));\n       }\n       for (FileDiff diff : diffs) {\n         BlockInfo[] diffBlocks \u003d diff.getBlocks();\n         if (diffBlocks !\u003d null) {\n           allBlocks.addAll(Arrays.asList(diffBlocks));\n         }\n       }\n       for (BlockInfo b: allBlocks) {\n         short replication \u003d b.getReplication();\n         long blockSize \u003d b.isComplete() ? b.getNumBytes() : file\n             .getPreferredBlockSize();\n \n         oldCounts.addStorageSpace(blockSize * replication);\n \n         if (bsp !\u003d null) {\n           List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n           for (StorageType t : oldTypeChosen) {\n             if (t.supportTypeQuota()) {\n               oldCounts.addTypeSpace(t, blockSize);\n             }\n           }\n         }\n       }\n \n       AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n       if (aclFeature !\u003d null) {\n         AclStorage.removeAclFeature(aclFeature);\n       }\n     } else {\n       oldCounts \u003d file.storagespaceConsumed(null);\n     }\n \n     getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n     if (file.getBlocks() !\u003d null) {\n       short replInDiff \u003d getMaxBlockRepInDiffs(removed);\n       short repl \u003d (short) Math.max(file.getPreferredBlockReplication(),\n                                     replInDiff);\n       for (BlockInfo b : file.getBlocks()) {\n         if (repl !\u003d b.getReplication()) {\n           reclaimContext.collectedBlocks().addUpdateReplicationFactor(b, repl);\n         }\n       }\n     }\n     QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n     reclaimContext.quotaDelta().add(oldCounts.subtract(current));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updateQuotaAndCollectBlocks(INode.ReclaimContext reclaimContext,\n      INodeFile file, FileDiff removed) {\n    byte storagePolicyID \u003d file.getStoragePolicyID();\n    BlockStoragePolicy bsp \u003d null;\n    if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n      bsp \u003d reclaimContext.storagePolicySuite().\n          getPolicy(file.getStoragePolicyID());\n    }\n\n    QuotaCounts oldCounts;\n    if (removed.snapshotINode !\u003d null) {\n      oldCounts \u003d new QuotaCounts.Builder().build();\n      // collect all distinct blocks\n      Set\u003cBlockInfo\u003e allBlocks \u003d new HashSet\u003cBlockInfo\u003e();\n      if (file.getBlocks() !\u003d null) {\n        allBlocks.addAll(Arrays.asList(file.getBlocks()));\n      }\n      if (removed.getBlocks() !\u003d null) {\n        allBlocks.addAll(Arrays.asList(removed.getBlocks()));\n      }\n      for (FileDiff diff : diffs) {\n        BlockInfo[] diffBlocks \u003d diff.getBlocks();\n        if (diffBlocks !\u003d null) {\n          allBlocks.addAll(Arrays.asList(diffBlocks));\n        }\n      }\n      for (BlockInfo b: allBlocks) {\n        short replication \u003d b.getReplication();\n        long blockSize \u003d b.isComplete() ? b.getNumBytes() : file\n            .getPreferredBlockSize();\n\n        oldCounts.addStorageSpace(blockSize * replication);\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              oldCounts.addTypeSpace(t, blockSize);\n            }\n          }\n        }\n      }\n\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    } else {\n      oldCounts \u003d file.storagespaceConsumed(null);\n    }\n\n    getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n    if (file.getBlocks() !\u003d null) {\n      short replInDiff \u003d getMaxBlockRepInDiffs(removed);\n      short repl \u003d (short) Math.max(file.getPreferredBlockReplication(),\n                                    replInDiff);\n      for (BlockInfo b : file.getBlocks()) {\n        if (repl !\u003d b.getReplication()) {\n          reclaimContext.collectedBlocks().addUpdateReplicationFactor(b, repl);\n        }\n      }\n    }\n    QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n    reclaimContext.quotaDelta().add(oldCounts.subtract(current));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
      "extendedDetails": {}
    },
    "130f89e068ca346a44fa6619ae0726c1e5cc5d06": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15332. Quota Space consumed was wrong in truncate with Snapshots. Contributed by hemanthboyina.\n",
      "commitDate": "06/05/20 1:18 PM",
      "commitName": "130f89e068ca346a44fa6619ae0726c1e5cc5d06",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "04/03/20 10:13 AM",
      "commitNameOld": "3afd4cbe89eb79c12465077a2f55949a800f32ae",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 63.09,
      "commitsBetweenForRepo": 205,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,58 +1,64 @@\n   public void updateQuotaAndCollectBlocks(INode.ReclaimContext reclaimContext,\n       INodeFile file, FileDiff removed) {\n     byte storagePolicyID \u003d file.getStoragePolicyID();\n     BlockStoragePolicy bsp \u003d null;\n     if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n       bsp \u003d reclaimContext.storagePolicySuite().\n           getPolicy(file.getStoragePolicyID());\n     }\n \n     QuotaCounts oldCounts;\n     if (removed.snapshotINode !\u003d null) {\n       oldCounts \u003d new QuotaCounts.Builder().build();\n       List\u003cBlockInfo\u003e allBlocks \u003d new ArrayList\u003cBlockInfo\u003e();\n       if (file.getBlocks() !\u003d null) {\n         allBlocks.addAll(Arrays.asList(file.getBlocks()));\n       }\n       if (removed.getBlocks() !\u003d null) {\n         allBlocks.addAll(Arrays.asList(removed.getBlocks()));\n       }\n+      for (FileDiff diff : diffs) {\n+        BlockInfo[] diffBlocks \u003d diff.getBlocks();\n+        if (diffBlocks !\u003d null) {\n+          allBlocks.addAll(Arrays.asList(diffBlocks));\n+        }\n+      }\n       for (BlockInfo b: allBlocks) {\n         short replication \u003d b.getReplication();\n         long blockSize \u003d b.isComplete() ? b.getNumBytes() : file\n             .getPreferredBlockSize();\n \n         oldCounts.addStorageSpace(blockSize * replication);\n \n         if (bsp !\u003d null) {\n           List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n           for (StorageType t : oldTypeChosen) {\n             if (t.supportTypeQuota()) {\n               oldCounts.addTypeSpace(t, blockSize);\n             }\n           }\n         }\n       }\n \n       AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n       if (aclFeature !\u003d null) {\n         AclStorage.removeAclFeature(aclFeature);\n       }\n     } else {\n       oldCounts \u003d file.storagespaceConsumed(null);\n     }\n \n     getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n     if (file.getBlocks() !\u003d null) {\n       short replInDiff \u003d getMaxBlockRepInDiffs(removed);\n       short repl \u003d (short) Math.max(file.getPreferredBlockReplication(),\n                                     replInDiff);\n       for (BlockInfo b : file.getBlocks()) {\n         if (repl !\u003d b.getReplication()) {\n           reclaimContext.collectedBlocks().addUpdateReplicationFactor(b, repl);\n         }\n       }\n     }\n     QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n     reclaimContext.quotaDelta().add(oldCounts.subtract(current));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updateQuotaAndCollectBlocks(INode.ReclaimContext reclaimContext,\n      INodeFile file, FileDiff removed) {\n    byte storagePolicyID \u003d file.getStoragePolicyID();\n    BlockStoragePolicy bsp \u003d null;\n    if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n      bsp \u003d reclaimContext.storagePolicySuite().\n          getPolicy(file.getStoragePolicyID());\n    }\n\n    QuotaCounts oldCounts;\n    if (removed.snapshotINode !\u003d null) {\n      oldCounts \u003d new QuotaCounts.Builder().build();\n      List\u003cBlockInfo\u003e allBlocks \u003d new ArrayList\u003cBlockInfo\u003e();\n      if (file.getBlocks() !\u003d null) {\n        allBlocks.addAll(Arrays.asList(file.getBlocks()));\n      }\n      if (removed.getBlocks() !\u003d null) {\n        allBlocks.addAll(Arrays.asList(removed.getBlocks()));\n      }\n      for (FileDiff diff : diffs) {\n        BlockInfo[] diffBlocks \u003d diff.getBlocks();\n        if (diffBlocks !\u003d null) {\n          allBlocks.addAll(Arrays.asList(diffBlocks));\n        }\n      }\n      for (BlockInfo b: allBlocks) {\n        short replication \u003d b.getReplication();\n        long blockSize \u003d b.isComplete() ? b.getNumBytes() : file\n            .getPreferredBlockSize();\n\n        oldCounts.addStorageSpace(blockSize * replication);\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              oldCounts.addTypeSpace(t, blockSize);\n            }\n          }\n        }\n      }\n\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    } else {\n      oldCounts \u003d file.storagespaceConsumed(null);\n    }\n\n    getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n    if (file.getBlocks() !\u003d null) {\n      short replInDiff \u003d getMaxBlockRepInDiffs(removed);\n      short repl \u003d (short) Math.max(file.getPreferredBlockReplication(),\n                                    replInDiff);\n      for (BlockInfo b : file.getBlocks()) {\n        if (repl !\u003d b.getReplication()) {\n          reclaimContext.collectedBlocks().addUpdateReplicationFactor(b, repl);\n        }\n      }\n    }\n    QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n    reclaimContext.quotaDelta().add(oldCounts.subtract(current));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
      "extendedDetails": {}
    },
    "3afd4cbe89eb79c12465077a2f55949a800f32ae": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14977. Quota Usage and Content summary are not same in Truncate with Snapshot. Contributed by hemanthboyina.\n",
      "commitDate": "04/03/20 10:13 AM",
      "commitName": "3afd4cbe89eb79c12465077a2f55949a800f32ae",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "14/08/19 9:46 PM",
      "commitNameOld": "0a85af959ce505f0659e5c69d0ca83a5dce0a7c2",
      "commitAuthorOld": "Shashikant Banerjee",
      "daysBetweenCommits": 202.56,
      "commitsBetweenForRepo": 1007,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,58 @@\n   public void updateQuotaAndCollectBlocks(INode.ReclaimContext reclaimContext,\n       INodeFile file, FileDiff removed) {\n     byte storagePolicyID \u003d file.getStoragePolicyID();\n     BlockStoragePolicy bsp \u003d null;\n     if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n       bsp \u003d reclaimContext.storagePolicySuite().\n           getPolicy(file.getStoragePolicyID());\n     }\n \n     QuotaCounts oldCounts;\n     if (removed.snapshotINode !\u003d null) {\n       oldCounts \u003d new QuotaCounts.Builder().build();\n-      BlockInfo[] blocks \u003d file.getBlocks() \u003d\u003d null ? new\n-          BlockInfo[0] : file.getBlocks();\n-      for (BlockInfo b: blocks) {\n+      List\u003cBlockInfo\u003e allBlocks \u003d new ArrayList\u003cBlockInfo\u003e();\n+      if (file.getBlocks() !\u003d null) {\n+        allBlocks.addAll(Arrays.asList(file.getBlocks()));\n+      }\n+      if (removed.getBlocks() !\u003d null) {\n+        allBlocks.addAll(Arrays.asList(removed.getBlocks()));\n+      }\n+      for (BlockInfo b: allBlocks) {\n         short replication \u003d b.getReplication();\n         long blockSize \u003d b.isComplete() ? b.getNumBytes() : file\n             .getPreferredBlockSize();\n \n         oldCounts.addStorageSpace(blockSize * replication);\n \n         if (bsp !\u003d null) {\n           List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n           for (StorageType t : oldTypeChosen) {\n             if (t.supportTypeQuota()) {\n               oldCounts.addTypeSpace(t, blockSize);\n             }\n           }\n         }\n       }\n \n       AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n       if (aclFeature !\u003d null) {\n         AclStorage.removeAclFeature(aclFeature);\n       }\n     } else {\n       oldCounts \u003d file.storagespaceConsumed(null);\n     }\n \n     getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n     if (file.getBlocks() !\u003d null) {\n       short replInDiff \u003d getMaxBlockRepInDiffs(removed);\n       short repl \u003d (short) Math.max(file.getPreferredBlockReplication(),\n                                     replInDiff);\n       for (BlockInfo b : file.getBlocks()) {\n         if (repl !\u003d b.getReplication()) {\n           reclaimContext.collectedBlocks().addUpdateReplicationFactor(b, repl);\n         }\n       }\n     }\n     QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n     reclaimContext.quotaDelta().add(oldCounts.subtract(current));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updateQuotaAndCollectBlocks(INode.ReclaimContext reclaimContext,\n      INodeFile file, FileDiff removed) {\n    byte storagePolicyID \u003d file.getStoragePolicyID();\n    BlockStoragePolicy bsp \u003d null;\n    if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n      bsp \u003d reclaimContext.storagePolicySuite().\n          getPolicy(file.getStoragePolicyID());\n    }\n\n    QuotaCounts oldCounts;\n    if (removed.snapshotINode !\u003d null) {\n      oldCounts \u003d new QuotaCounts.Builder().build();\n      List\u003cBlockInfo\u003e allBlocks \u003d new ArrayList\u003cBlockInfo\u003e();\n      if (file.getBlocks() !\u003d null) {\n        allBlocks.addAll(Arrays.asList(file.getBlocks()));\n      }\n      if (removed.getBlocks() !\u003d null) {\n        allBlocks.addAll(Arrays.asList(removed.getBlocks()));\n      }\n      for (BlockInfo b: allBlocks) {\n        short replication \u003d b.getReplication();\n        long blockSize \u003d b.isComplete() ? b.getNumBytes() : file\n            .getPreferredBlockSize();\n\n        oldCounts.addStorageSpace(blockSize * replication);\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              oldCounts.addTypeSpace(t, blockSize);\n            }\n          }\n        }\n      }\n\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    } else {\n      oldCounts \u003d file.storagespaceConsumed(null);\n    }\n\n    getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n    if (file.getBlocks() !\u003d null) {\n      short replInDiff \u003d getMaxBlockRepInDiffs(removed);\n      short repl \u003d (short) Math.max(file.getPreferredBlockReplication(),\n                                    replInDiff);\n      for (BlockInfo b : file.getBlocks()) {\n        if (repl !\u003d b.getReplication()) {\n          reclaimContext.collectedBlocks().addUpdateReplicationFactor(b, repl);\n        }\n      }\n    }\n    QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n    reclaimContext.quotaDelta().add(oldCounts.subtract(current));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
      "extendedDetails": {}
    },
    "745d04be59accf80feda0ad38efcc74ba362f2ca": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8823. Move replication factor into individual blocks. Contributed by Haohui Mai.\n",
      "commitDate": "22/08/15 12:09 AM",
      "commitName": "745d04be59accf80feda0ad38efcc74ba362f2ca",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "27/05/15 3:42 PM",
      "commitNameOld": "4928f5473394981829e5ffd4b16ea0801baf5c45",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 86.35,
      "commitsBetweenForRepo": 543,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,53 @@\n   public void updateQuotaAndCollectBlocks(INode.ReclaimContext reclaimContext,\n       INodeFile file, FileDiff removed) {\n     byte storagePolicyID \u003d file.getStoragePolicyID();\n     BlockStoragePolicy bsp \u003d null;\n     if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n-      bsp \u003d reclaimContext.storagePolicySuite().getPolicy(file.getStoragePolicyID());\n+      bsp \u003d reclaimContext.storagePolicySuite().\n+          getPolicy(file.getStoragePolicyID());\n     }\n \n-\n-    QuotaCounts oldCounts \u003d file.storagespaceConsumed(null);\n-    long oldStoragespace;\n+    QuotaCounts oldCounts;\n     if (removed.snapshotINode !\u003d null) {\n-      short replication \u003d removed.snapshotINode.getFileReplication();\n-      short currentRepl \u003d file.getPreferredBlockReplication();\n-      if (replication \u003e currentRepl) {\n-        long oldFileSizeNoRep \u003d currentRepl \u003d\u003d 0\n-            ? file.computeFileSize(true, true)\n-            : oldCounts.getStorageSpace() /\n-            file.getPreferredBlockReplication();\n-        oldStoragespace \u003d oldFileSizeNoRep * replication;\n-        oldCounts.setStorageSpace(oldStoragespace);\n+      oldCounts \u003d new QuotaCounts.Builder().build();\n+      BlockInfo[] blocks \u003d file.getBlocks() \u003d\u003d null ? new\n+          BlockInfo[0] : file.getBlocks();\n+      for (BlockInfo b: blocks) {\n+        short replication \u003d b.getReplication();\n+        long blockSize \u003d b.isComplete() ? b.getNumBytes() : file\n+            .getPreferredBlockSize();\n+\n+        oldCounts.addStorageSpace(blockSize * replication);\n \n         if (bsp !\u003d null) {\n           List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n           for (StorageType t : oldTypeChosen) {\n             if (t.supportTypeQuota()) {\n-              oldCounts.addTypeSpace(t, oldFileSizeNoRep);\n+              oldCounts.addTypeSpace(t, blockSize);\n             }\n           }\n         }\n       }\n \n       AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n       if (aclFeature !\u003d null) {\n         AclStorage.removeAclFeature(aclFeature);\n       }\n+    } else {\n+      oldCounts \u003d file.storagespaceConsumed(null);\n     }\n \n     getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n-\n+    if (file.getBlocks() !\u003d null) {\n+      short replInDiff \u003d getMaxBlockRepInDiffs(removed);\n+      short repl \u003d (short) Math.max(file.getPreferredBlockReplication(),\n+                                    replInDiff);\n+      for (BlockInfo b : file.getBlocks()) {\n+        if (repl !\u003d b.getReplication()) {\n+          reclaimContext.collectedBlocks().addUpdateReplicationFactor(b, repl);\n+        }\n+      }\n+    }\n     QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n     reclaimContext.quotaDelta().add(oldCounts.subtract(current));\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void updateQuotaAndCollectBlocks(INode.ReclaimContext reclaimContext,\n      INodeFile file, FileDiff removed) {\n    byte storagePolicyID \u003d file.getStoragePolicyID();\n    BlockStoragePolicy bsp \u003d null;\n    if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n      bsp \u003d reclaimContext.storagePolicySuite().\n          getPolicy(file.getStoragePolicyID());\n    }\n\n    QuotaCounts oldCounts;\n    if (removed.snapshotINode !\u003d null) {\n      oldCounts \u003d new QuotaCounts.Builder().build();\n      BlockInfo[] blocks \u003d file.getBlocks() \u003d\u003d null ? new\n          BlockInfo[0] : file.getBlocks();\n      for (BlockInfo b: blocks) {\n        short replication \u003d b.getReplication();\n        long blockSize \u003d b.isComplete() ? b.getNumBytes() : file\n            .getPreferredBlockSize();\n\n        oldCounts.addStorageSpace(blockSize * replication);\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              oldCounts.addTypeSpace(t, blockSize);\n            }\n          }\n        }\n      }\n\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    } else {\n      oldCounts \u003d file.storagespaceConsumed(null);\n    }\n\n    getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n    if (file.getBlocks() !\u003d null) {\n      short replInDiff \u003d getMaxBlockRepInDiffs(removed);\n      short repl \u003d (short) Math.max(file.getPreferredBlockReplication(),\n                                    replInDiff);\n      for (BlockInfo b : file.getBlocks()) {\n        if (repl !\u003d b.getReplication()) {\n          reclaimContext.collectedBlocks().addUpdateReplicationFactor(b, repl);\n        }\n      }\n    }\n    QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n    reclaimContext.quotaDelta().add(oldCounts.subtract(current));\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
      "extendedDetails": {}
    },
    "b2c85db86c9a62b0a03ee87547265077f664970a": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-7728. Avoid updating quota usage while loading edits. Contributed by Jing Zhao.\n",
      "commitDate": "13/05/15 9:50 PM",
      "commitName": "b2c85db86c9a62b0a03ee87547265077f664970a",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-7728. Avoid updating quota usage while loading edits. Contributed by Jing Zhao.\n",
          "commitDate": "13/05/15 9:50 PM",
          "commitName": "b2c85db86c9a62b0a03ee87547265077f664970a",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "12/05/15 6:29 AM",
          "commitNameOld": "6d5da9484185ca9f585195d6da069b9cd5be4044",
          "commitAuthorOld": "yliu",
          "daysBetweenCommits": 1.64,
          "commitsBetweenForRepo": 24,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,43 @@\n-  public QuotaCounts updateQuotaAndCollectBlocks(\n-      INode.ReclaimContext reclaimContext, INodeFile file, FileDiff removed) {\n+  public void updateQuotaAndCollectBlocks(INode.ReclaimContext reclaimContext,\n+      INodeFile file, FileDiff removed) {\n     byte storagePolicyID \u003d file.getStoragePolicyID();\n     BlockStoragePolicy bsp \u003d null;\n     if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n       bsp \u003d reclaimContext.storagePolicySuite().getPolicy(file.getStoragePolicyID());\n     }\n \n \n     QuotaCounts oldCounts \u003d file.storagespaceConsumed(null);\n     long oldStoragespace;\n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n       short currentRepl \u003d file.getPreferredBlockReplication();\n       if (replication \u003e currentRepl) {\n         long oldFileSizeNoRep \u003d currentRepl \u003d\u003d 0\n             ? file.computeFileSize(true, true)\n             : oldCounts.getStorageSpace() /\n             file.getPreferredBlockReplication();\n         oldStoragespace \u003d oldFileSizeNoRep * replication;\n         oldCounts.setStorageSpace(oldStoragespace);\n \n         if (bsp !\u003d null) {\n           List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n           for (StorageType t : oldTypeChosen) {\n             if (t.supportTypeQuota()) {\n               oldCounts.addTypeSpace(t, oldFileSizeNoRep);\n             }\n           }\n         }\n       }\n \n       AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n       if (aclFeature !\u003d null) {\n         AclStorage.removeAclFeature(aclFeature);\n       }\n     }\n \n     getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n \n     QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n-    oldCounts.subtract(current);\n-    return oldCounts;\n+    reclaimContext.quotaDelta().add(oldCounts.subtract(current));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void updateQuotaAndCollectBlocks(INode.ReclaimContext reclaimContext,\n      INodeFile file, FileDiff removed) {\n    byte storagePolicyID \u003d file.getStoragePolicyID();\n    BlockStoragePolicy bsp \u003d null;\n    if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n      bsp \u003d reclaimContext.storagePolicySuite().getPolicy(file.getStoragePolicyID());\n    }\n\n\n    QuotaCounts oldCounts \u003d file.storagespaceConsumed(null);\n    long oldStoragespace;\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getPreferredBlockReplication();\n      if (replication \u003e currentRepl) {\n        long oldFileSizeNoRep \u003d currentRepl \u003d\u003d 0\n            ? file.computeFileSize(true, true)\n            : oldCounts.getStorageSpace() /\n            file.getPreferredBlockReplication();\n        oldStoragespace \u003d oldFileSizeNoRep * replication;\n        oldCounts.setStorageSpace(oldStoragespace);\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              oldCounts.addTypeSpace(t, oldFileSizeNoRep);\n            }\n          }\n        }\n      }\n\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    }\n\n    getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n\n    QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n    reclaimContext.quotaDelta().add(oldCounts.subtract(current));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
          "extendedDetails": {
            "oldValue": "QuotaCounts",
            "newValue": "void"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7728. Avoid updating quota usage while loading edits. Contributed by Jing Zhao.\n",
          "commitDate": "13/05/15 9:50 PM",
          "commitName": "b2c85db86c9a62b0a03ee87547265077f664970a",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "12/05/15 6:29 AM",
          "commitNameOld": "6d5da9484185ca9f585195d6da069b9cd5be4044",
          "commitAuthorOld": "yliu",
          "daysBetweenCommits": 1.64,
          "commitsBetweenForRepo": 24,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,44 +1,43 @@\n-  public QuotaCounts updateQuotaAndCollectBlocks(\n-      INode.ReclaimContext reclaimContext, INodeFile file, FileDiff removed) {\n+  public void updateQuotaAndCollectBlocks(INode.ReclaimContext reclaimContext,\n+      INodeFile file, FileDiff removed) {\n     byte storagePolicyID \u003d file.getStoragePolicyID();\n     BlockStoragePolicy bsp \u003d null;\n     if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n       bsp \u003d reclaimContext.storagePolicySuite().getPolicy(file.getStoragePolicyID());\n     }\n \n \n     QuotaCounts oldCounts \u003d file.storagespaceConsumed(null);\n     long oldStoragespace;\n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n       short currentRepl \u003d file.getPreferredBlockReplication();\n       if (replication \u003e currentRepl) {\n         long oldFileSizeNoRep \u003d currentRepl \u003d\u003d 0\n             ? file.computeFileSize(true, true)\n             : oldCounts.getStorageSpace() /\n             file.getPreferredBlockReplication();\n         oldStoragespace \u003d oldFileSizeNoRep * replication;\n         oldCounts.setStorageSpace(oldStoragespace);\n \n         if (bsp !\u003d null) {\n           List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n           for (StorageType t : oldTypeChosen) {\n             if (t.supportTypeQuota()) {\n               oldCounts.addTypeSpace(t, oldFileSizeNoRep);\n             }\n           }\n         }\n       }\n \n       AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n       if (aclFeature !\u003d null) {\n         AclStorage.removeAclFeature(aclFeature);\n       }\n     }\n \n     getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n \n     QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n-    oldCounts.subtract(current);\n-    return oldCounts;\n+    reclaimContext.quotaDelta().add(oldCounts.subtract(current));\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void updateQuotaAndCollectBlocks(INode.ReclaimContext reclaimContext,\n      INodeFile file, FileDiff removed) {\n    byte storagePolicyID \u003d file.getStoragePolicyID();\n    BlockStoragePolicy bsp \u003d null;\n    if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n      bsp \u003d reclaimContext.storagePolicySuite().getPolicy(file.getStoragePolicyID());\n    }\n\n\n    QuotaCounts oldCounts \u003d file.storagespaceConsumed(null);\n    long oldStoragespace;\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getPreferredBlockReplication();\n      if (replication \u003e currentRepl) {\n        long oldFileSizeNoRep \u003d currentRepl \u003d\u003d 0\n            ? file.computeFileSize(true, true)\n            : oldCounts.getStorageSpace() /\n            file.getPreferredBlockReplication();\n        oldStoragespace \u003d oldFileSizeNoRep * replication;\n        oldCounts.setStorageSpace(oldStoragespace);\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              oldCounts.addTypeSpace(t, oldFileSizeNoRep);\n            }\n          }\n        }\n      }\n\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    }\n\n    getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n\n    QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n    reclaimContext.quotaDelta().add(oldCounts.subtract(current));\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
          "extendedDetails": {}
        }
      ]
    },
    "6d5da9484185ca9f585195d6da069b9cd5be4044": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8255. Rename getBlockReplication to getPreferredBlockReplication. (Contributed by Zhe Zhang)\n",
      "commitDate": "12/05/15 6:29 AM",
      "commitName": "6d5da9484185ca9f585195d6da069b9cd5be4044",
      "commitAuthor": "yliu",
      "commitDateOld": "09/05/15 10:51 PM",
      "commitNameOld": "4536399d47f6c061e149e2504600804a0f1e093d",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 2.32,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,44 @@\n   public QuotaCounts updateQuotaAndCollectBlocks(\n       INode.ReclaimContext reclaimContext, INodeFile file, FileDiff removed) {\n     byte storagePolicyID \u003d file.getStoragePolicyID();\n     BlockStoragePolicy bsp \u003d null;\n     if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n       bsp \u003d reclaimContext.storagePolicySuite().getPolicy(file.getStoragePolicyID());\n     }\n \n \n     QuotaCounts oldCounts \u003d file.storagespaceConsumed(null);\n     long oldStoragespace;\n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n-      short currentRepl \u003d file.getBlockReplication();\n+      short currentRepl \u003d file.getPreferredBlockReplication();\n       if (replication \u003e currentRepl) {\n         long oldFileSizeNoRep \u003d currentRepl \u003d\u003d 0\n             ? file.computeFileSize(true, true)\n-            : oldCounts.getStorageSpace() / file.getBlockReplication();\n+            : oldCounts.getStorageSpace() /\n+            file.getPreferredBlockReplication();\n         oldStoragespace \u003d oldFileSizeNoRep * replication;\n         oldCounts.setStorageSpace(oldStoragespace);\n \n         if (bsp !\u003d null) {\n           List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n           for (StorageType t : oldTypeChosen) {\n             if (t.supportTypeQuota()) {\n               oldCounts.addTypeSpace(t, oldFileSizeNoRep);\n             }\n           }\n         }\n       }\n \n       AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n       if (aclFeature !\u003d null) {\n         AclStorage.removeAclFeature(aclFeature);\n       }\n     }\n \n     getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n \n     QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n     oldCounts.subtract(current);\n     return oldCounts;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public QuotaCounts updateQuotaAndCollectBlocks(\n      INode.ReclaimContext reclaimContext, INodeFile file, FileDiff removed) {\n    byte storagePolicyID \u003d file.getStoragePolicyID();\n    BlockStoragePolicy bsp \u003d null;\n    if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n      bsp \u003d reclaimContext.storagePolicySuite().getPolicy(file.getStoragePolicyID());\n    }\n\n\n    QuotaCounts oldCounts \u003d file.storagespaceConsumed(null);\n    long oldStoragespace;\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getPreferredBlockReplication();\n      if (replication \u003e currentRepl) {\n        long oldFileSizeNoRep \u003d currentRepl \u003d\u003d 0\n            ? file.computeFileSize(true, true)\n            : oldCounts.getStorageSpace() /\n            file.getPreferredBlockReplication();\n        oldStoragespace \u003d oldFileSizeNoRep * replication;\n        oldCounts.setStorageSpace(oldStoragespace);\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              oldCounts.addTypeSpace(t, oldFileSizeNoRep);\n            }\n          }\n        }\n      }\n\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    }\n\n    getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n\n    QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n    oldCounts.subtract(current);\n    return oldCounts;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
      "extendedDetails": {}
    },
    "4536399d47f6c061e149e2504600804a0f1e093d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-8357. Consolidate parameters of INode.CleanSubtree() into a parameter objects. Contributed by Li Lu.\n",
      "commitDate": "09/05/15 10:51 PM",
      "commitName": "4536399d47f6c061e149e2504600804a0f1e093d",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-8357. Consolidate parameters of INode.CleanSubtree() into a parameter objects. Contributed by Li Lu.\n",
          "commitDate": "09/05/15 10:51 PM",
          "commitName": "4536399d47f6c061e149e2504600804a0f1e093d",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "08/05/15 11:09 PM",
          "commitNameOld": "02a4a22b9c0e22c2e7dd6ec85edd5c5a167fe19f",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 0.99,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,46 +1,43 @@\n-  public QuotaCounts updateQuotaAndCollectBlocks(BlockStoragePolicySuite bsps, INodeFile file,\n-      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n-      final List\u003cINode\u003e removedINodes) {\n-\n+  public QuotaCounts updateQuotaAndCollectBlocks(\n+      INode.ReclaimContext reclaimContext, INodeFile file, FileDiff removed) {\n     byte storagePolicyID \u003d file.getStoragePolicyID();\n     BlockStoragePolicy bsp \u003d null;\n     if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n-      bsp \u003d bsps.getPolicy(file.getStoragePolicyID());\n+      bsp \u003d reclaimContext.storagePolicySuite().getPolicy(file.getStoragePolicyID());\n     }\n \n \n     QuotaCounts oldCounts \u003d file.storagespaceConsumed(null);\n     long oldStoragespace;\n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n       short currentRepl \u003d file.getBlockReplication();\n       if (replication \u003e currentRepl) {\n         long oldFileSizeNoRep \u003d currentRepl \u003d\u003d 0\n             ? file.computeFileSize(true, true)\n             : oldCounts.getStorageSpace() / file.getBlockReplication();\n         oldStoragespace \u003d oldFileSizeNoRep * replication;\n         oldCounts.setStorageSpace(oldStoragespace);\n \n         if (bsp !\u003d null) {\n           List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n           for (StorageType t : oldTypeChosen) {\n             if (t.supportTypeQuota()) {\n               oldCounts.addTypeSpace(t, oldFileSizeNoRep);\n             }\n           }\n         }\n       }\n \n       AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n       if (aclFeature !\u003d null) {\n         AclStorage.removeAclFeature(aclFeature);\n       }\n     }\n \n-    getDiffs().combineAndCollectSnapshotBlocks(\n-        bsps, file, removed, collectedBlocks, removedINodes);\n+    getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n \n     QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n     oldCounts.subtract(current);\n     return oldCounts;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public QuotaCounts updateQuotaAndCollectBlocks(\n      INode.ReclaimContext reclaimContext, INodeFile file, FileDiff removed) {\n    byte storagePolicyID \u003d file.getStoragePolicyID();\n    BlockStoragePolicy bsp \u003d null;\n    if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n      bsp \u003d reclaimContext.storagePolicySuite().getPolicy(file.getStoragePolicyID());\n    }\n\n\n    QuotaCounts oldCounts \u003d file.storagespaceConsumed(null);\n    long oldStoragespace;\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getBlockReplication();\n      if (replication \u003e currentRepl) {\n        long oldFileSizeNoRep \u003d currentRepl \u003d\u003d 0\n            ? file.computeFileSize(true, true)\n            : oldCounts.getStorageSpace() / file.getBlockReplication();\n        oldStoragespace \u003d oldFileSizeNoRep * replication;\n        oldCounts.setStorageSpace(oldStoragespace);\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              oldCounts.addTypeSpace(t, oldFileSizeNoRep);\n            }\n          }\n        }\n      }\n\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    }\n\n    getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n\n    QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n    oldCounts.subtract(current);\n    return oldCounts;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
          "extendedDetails": {
            "oldValue": "[bsps-BlockStoragePolicySuite, file-INodeFile, removed-FileDiff, collectedBlocks-BlocksMapUpdateInfo, removedINodes-List\u003cINode\u003e(modifiers-final)]",
            "newValue": "[reclaimContext-INode.ReclaimContext, file-INodeFile, removed-FileDiff]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8357. Consolidate parameters of INode.CleanSubtree() into a parameter objects. Contributed by Li Lu.\n",
          "commitDate": "09/05/15 10:51 PM",
          "commitName": "4536399d47f6c061e149e2504600804a0f1e093d",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "08/05/15 11:09 PM",
          "commitNameOld": "02a4a22b9c0e22c2e7dd6ec85edd5c5a167fe19f",
          "commitAuthorOld": "Haohui Mai",
          "daysBetweenCommits": 0.99,
          "commitsBetweenForRepo": 5,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,46 +1,43 @@\n-  public QuotaCounts updateQuotaAndCollectBlocks(BlockStoragePolicySuite bsps, INodeFile file,\n-      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n-      final List\u003cINode\u003e removedINodes) {\n-\n+  public QuotaCounts updateQuotaAndCollectBlocks(\n+      INode.ReclaimContext reclaimContext, INodeFile file, FileDiff removed) {\n     byte storagePolicyID \u003d file.getStoragePolicyID();\n     BlockStoragePolicy bsp \u003d null;\n     if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n-      bsp \u003d bsps.getPolicy(file.getStoragePolicyID());\n+      bsp \u003d reclaimContext.storagePolicySuite().getPolicy(file.getStoragePolicyID());\n     }\n \n \n     QuotaCounts oldCounts \u003d file.storagespaceConsumed(null);\n     long oldStoragespace;\n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n       short currentRepl \u003d file.getBlockReplication();\n       if (replication \u003e currentRepl) {\n         long oldFileSizeNoRep \u003d currentRepl \u003d\u003d 0\n             ? file.computeFileSize(true, true)\n             : oldCounts.getStorageSpace() / file.getBlockReplication();\n         oldStoragespace \u003d oldFileSizeNoRep * replication;\n         oldCounts.setStorageSpace(oldStoragespace);\n \n         if (bsp !\u003d null) {\n           List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n           for (StorageType t : oldTypeChosen) {\n             if (t.supportTypeQuota()) {\n               oldCounts.addTypeSpace(t, oldFileSizeNoRep);\n             }\n           }\n         }\n       }\n \n       AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n       if (aclFeature !\u003d null) {\n         AclStorage.removeAclFeature(aclFeature);\n       }\n     }\n \n-    getDiffs().combineAndCollectSnapshotBlocks(\n-        bsps, file, removed, collectedBlocks, removedINodes);\n+    getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n \n     QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n     oldCounts.subtract(current);\n     return oldCounts;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public QuotaCounts updateQuotaAndCollectBlocks(\n      INode.ReclaimContext reclaimContext, INodeFile file, FileDiff removed) {\n    byte storagePolicyID \u003d file.getStoragePolicyID();\n    BlockStoragePolicy bsp \u003d null;\n    if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n      bsp \u003d reclaimContext.storagePolicySuite().getPolicy(file.getStoragePolicyID());\n    }\n\n\n    QuotaCounts oldCounts \u003d file.storagespaceConsumed(null);\n    long oldStoragespace;\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getBlockReplication();\n      if (replication \u003e currentRepl) {\n        long oldFileSizeNoRep \u003d currentRepl \u003d\u003d 0\n            ? file.computeFileSize(true, true)\n            : oldCounts.getStorageSpace() / file.getBlockReplication();\n        oldStoragespace \u003d oldFileSizeNoRep * replication;\n        oldCounts.setStorageSpace(oldStoragespace);\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              oldCounts.addTypeSpace(t, oldFileSizeNoRep);\n            }\n          }\n        }\n      }\n\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    }\n\n    getDiffs().combineAndCollectSnapshotBlocks(reclaimContext, file, removed);\n\n    QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n    oldCounts.subtract(current);\n    return oldCounts;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
          "extendedDetails": {}
        }
      ]
    },
    "02a4a22b9c0e22c2e7dd6ec85edd5c5a167fe19f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8327. Compute storage type quotas in INodeFile.computeQuotaDeltaForTruncate(). Contributed by Haohui Mai.\n",
      "commitDate": "08/05/15 11:09 PM",
      "commitName": "02a4a22b9c0e22c2e7dd6ec85edd5c5a167fe19f",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "08/05/15 11:04 PM",
      "commitNameOld": "00fe1ed3a4b3ee35fe24be257ec36445d2f44d63",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,46 @@\n   public QuotaCounts updateQuotaAndCollectBlocks(BlockStoragePolicySuite bsps, INodeFile file,\n       FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n       final List\u003cINode\u003e removedINodes) {\n-    long oldStoragespace \u003d file.storagespaceConsumed();\n \n     byte storagePolicyID \u003d file.getStoragePolicyID();\n     BlockStoragePolicy bsp \u003d null;\n-    EnumCounters\u003cStorageType\u003e typeSpaces \u003d\n-        new EnumCounters\u003cStorageType\u003e(StorageType.class);\n     if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n       bsp \u003d bsps.getPolicy(file.getStoragePolicyID());\n     }\n \n+\n+    QuotaCounts oldCounts \u003d file.storagespaceConsumed(null);\n+    long oldStoragespace;\n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n       short currentRepl \u003d file.getBlockReplication();\n-      if (currentRepl \u003d\u003d 0) {\n-        long oldFileSizeNoRep \u003d file.computeFileSize(true, true);\n-        oldStoragespace \u003d  oldFileSizeNoRep * replication;\n-\n-        if (bsp !\u003d null) {\n-          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n-          for (StorageType t : oldTypeChosen) {\n-            if (t.supportTypeQuota()) {\n-              typeSpaces.add(t, -oldFileSizeNoRep);\n-            }\n-          }\n-        }\n-      } else if (replication \u003e currentRepl) {\n-        long oldFileSizeNoRep \u003d file.storagespaceConsumedNoReplication();\n+      if (replication \u003e currentRepl) {\n+        long oldFileSizeNoRep \u003d currentRepl \u003d\u003d 0\n+            ? file.computeFileSize(true, true)\n+            : oldCounts.getStorageSpace() / file.getBlockReplication();\n         oldStoragespace \u003d oldFileSizeNoRep * replication;\n+        oldCounts.setStorageSpace(oldStoragespace);\n \n         if (bsp !\u003d null) {\n           List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n           for (StorageType t : oldTypeChosen) {\n             if (t.supportTypeQuota()) {\n-              typeSpaces.add(t, -oldFileSizeNoRep);\n-            }\n-          }\n-          List\u003cStorageType\u003e newTypeChosen \u003d bsp.chooseStorageTypes(currentRepl);\n-          for (StorageType t: newTypeChosen) {\n-            if (t.supportTypeQuota()) {\n-              typeSpaces.add(t, oldFileSizeNoRep);\n+              oldCounts.addTypeSpace(t, oldFileSizeNoRep);\n             }\n           }\n         }\n       }\n+\n       AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n       if (aclFeature !\u003d null) {\n         AclStorage.removeAclFeature(aclFeature);\n       }\n     }\n \n     getDiffs().combineAndCollectSnapshotBlocks(\n         bsps, file, removed, collectedBlocks, removedINodes);\n \n-    long ssDelta \u003d oldStoragespace - file.storagespaceConsumed();\n-    return new QuotaCounts.Builder().\n-        storageSpace(ssDelta).\n-        typeSpaces(typeSpaces).\n-        build();\n+    QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n+    oldCounts.subtract(current);\n+    return oldCounts;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public QuotaCounts updateQuotaAndCollectBlocks(BlockStoragePolicySuite bsps, INodeFile file,\n      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n      final List\u003cINode\u003e removedINodes) {\n\n    byte storagePolicyID \u003d file.getStoragePolicyID();\n    BlockStoragePolicy bsp \u003d null;\n    if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n      bsp \u003d bsps.getPolicy(file.getStoragePolicyID());\n    }\n\n\n    QuotaCounts oldCounts \u003d file.storagespaceConsumed(null);\n    long oldStoragespace;\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getBlockReplication();\n      if (replication \u003e currentRepl) {\n        long oldFileSizeNoRep \u003d currentRepl \u003d\u003d 0\n            ? file.computeFileSize(true, true)\n            : oldCounts.getStorageSpace() / file.getBlockReplication();\n        oldStoragespace \u003d oldFileSizeNoRep * replication;\n        oldCounts.setStorageSpace(oldStoragespace);\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              oldCounts.addTypeSpace(t, oldFileSizeNoRep);\n            }\n          }\n        }\n      }\n\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    }\n\n    getDiffs().combineAndCollectSnapshotBlocks(\n        bsps, file, removed, collectedBlocks, removedINodes);\n\n    QuotaCounts current \u003d file.storagespaceConsumed(bsp);\n    oldCounts.subtract(current);\n    return oldCounts;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
      "extendedDetails": {}
    },
    "6ae2a0d048e133b43249c248a75a4d77d9abb80d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8249. Separate HdfsConstants into the client and the server side class. Contributed by Haohui Mai.\n",
      "commitDate": "02/05/15 10:03 AM",
      "commitName": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "20/04/15 12:36 AM",
      "commitNameOld": "5c97db07fb306842f49d73a67a90cecec19a7833",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 12.39,
      "commitsBetweenForRepo": 126,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,62 @@\n   public QuotaCounts updateQuotaAndCollectBlocks(BlockStoragePolicySuite bsps, INodeFile file,\n       FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n       final List\u003cINode\u003e removedINodes) {\n     long oldStoragespace \u003d file.storagespaceConsumed();\n \n     byte storagePolicyID \u003d file.getStoragePolicyID();\n     BlockStoragePolicy bsp \u003d null;\n     EnumCounters\u003cStorageType\u003e typeSpaces \u003d\n         new EnumCounters\u003cStorageType\u003e(StorageType.class);\n-    if (storagePolicyID !\u003d HdfsConstantsClient.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n+    if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n       bsp \u003d bsps.getPolicy(file.getStoragePolicyID());\n     }\n \n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n       short currentRepl \u003d file.getBlockReplication();\n       if (currentRepl \u003d\u003d 0) {\n         long oldFileSizeNoRep \u003d file.computeFileSize(true, true);\n         oldStoragespace \u003d  oldFileSizeNoRep * replication;\n \n         if (bsp !\u003d null) {\n           List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n           for (StorageType t : oldTypeChosen) {\n             if (t.supportTypeQuota()) {\n               typeSpaces.add(t, -oldFileSizeNoRep);\n             }\n           }\n         }\n       } else if (replication \u003e currentRepl) {\n         long oldFileSizeNoRep \u003d file.storagespaceConsumedNoReplication();\n         oldStoragespace \u003d oldFileSizeNoRep * replication;\n \n         if (bsp !\u003d null) {\n           List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n           for (StorageType t : oldTypeChosen) {\n             if (t.supportTypeQuota()) {\n               typeSpaces.add(t, -oldFileSizeNoRep);\n             }\n           }\n           List\u003cStorageType\u003e newTypeChosen \u003d bsp.chooseStorageTypes(currentRepl);\n           for (StorageType t: newTypeChosen) {\n             if (t.supportTypeQuota()) {\n               typeSpaces.add(t, oldFileSizeNoRep);\n             }\n           }\n         }\n       }\n       AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n       if (aclFeature !\u003d null) {\n         AclStorage.removeAclFeature(aclFeature);\n       }\n     }\n \n     getDiffs().combineAndCollectSnapshotBlocks(\n         bsps, file, removed, collectedBlocks, removedINodes);\n \n     long ssDelta \u003d oldStoragespace - file.storagespaceConsumed();\n     return new QuotaCounts.Builder().\n         storageSpace(ssDelta).\n         typeSpaces(typeSpaces).\n         build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public QuotaCounts updateQuotaAndCollectBlocks(BlockStoragePolicySuite bsps, INodeFile file,\n      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n      final List\u003cINode\u003e removedINodes) {\n    long oldStoragespace \u003d file.storagespaceConsumed();\n\n    byte storagePolicyID \u003d file.getStoragePolicyID();\n    BlockStoragePolicy bsp \u003d null;\n    EnumCounters\u003cStorageType\u003e typeSpaces \u003d\n        new EnumCounters\u003cStorageType\u003e(StorageType.class);\n    if (storagePolicyID !\u003d HdfsConstants.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n      bsp \u003d bsps.getPolicy(file.getStoragePolicyID());\n    }\n\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getBlockReplication();\n      if (currentRepl \u003d\u003d 0) {\n        long oldFileSizeNoRep \u003d file.computeFileSize(true, true);\n        oldStoragespace \u003d  oldFileSizeNoRep * replication;\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, -oldFileSizeNoRep);\n            }\n          }\n        }\n      } else if (replication \u003e currentRepl) {\n        long oldFileSizeNoRep \u003d file.storagespaceConsumedNoReplication();\n        oldStoragespace \u003d oldFileSizeNoRep * replication;\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, -oldFileSizeNoRep);\n            }\n          }\n          List\u003cStorageType\u003e newTypeChosen \u003d bsp.chooseStorageTypes(currentRepl);\n          for (StorageType t: newTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, oldFileSizeNoRep);\n            }\n          }\n        }\n      }\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    }\n\n    getDiffs().combineAndCollectSnapshotBlocks(\n        bsps, file, removed, collectedBlocks, removedINodes);\n\n    long ssDelta \u003d oldStoragespace - file.storagespaceConsumed();\n    return new QuotaCounts.Builder().\n        storageSpace(ssDelta).\n        typeSpaces(typeSpaces).\n        build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
      "extendedDetails": {}
    },
    "5c97db07fb306842f49d73a67a90cecec19a7833": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8169. Move LocatedBlocks and related classes to hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "20/04/15 12:36 AM",
      "commitName": "5c97db07fb306842f49d73a67a90cecec19a7833",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "21/02/15 3:38 PM",
      "commitNameOld": "8b465b4b8caed31ca9daeaae108f9a868a30a455",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 57.33,
      "commitsBetweenForRepo": 476,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,62 @@\n   public QuotaCounts updateQuotaAndCollectBlocks(BlockStoragePolicySuite bsps, INodeFile file,\n       FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n       final List\u003cINode\u003e removedINodes) {\n     long oldStoragespace \u003d file.storagespaceConsumed();\n \n     byte storagePolicyID \u003d file.getStoragePolicyID();\n     BlockStoragePolicy bsp \u003d null;\n     EnumCounters\u003cStorageType\u003e typeSpaces \u003d\n         new EnumCounters\u003cStorageType\u003e(StorageType.class);\n-    if (storagePolicyID !\u003d BlockStoragePolicySuite.ID_UNSPECIFIED) {\n+    if (storagePolicyID !\u003d HdfsConstantsClient.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n       bsp \u003d bsps.getPolicy(file.getStoragePolicyID());\n     }\n \n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n       short currentRepl \u003d file.getBlockReplication();\n       if (currentRepl \u003d\u003d 0) {\n         long oldFileSizeNoRep \u003d file.computeFileSize(true, true);\n         oldStoragespace \u003d  oldFileSizeNoRep * replication;\n \n         if (bsp !\u003d null) {\n           List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n           for (StorageType t : oldTypeChosen) {\n             if (t.supportTypeQuota()) {\n               typeSpaces.add(t, -oldFileSizeNoRep);\n             }\n           }\n         }\n       } else if (replication \u003e currentRepl) {\n         long oldFileSizeNoRep \u003d file.storagespaceConsumedNoReplication();\n         oldStoragespace \u003d oldFileSizeNoRep * replication;\n \n         if (bsp !\u003d null) {\n           List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n           for (StorageType t : oldTypeChosen) {\n             if (t.supportTypeQuota()) {\n               typeSpaces.add(t, -oldFileSizeNoRep);\n             }\n           }\n           List\u003cStorageType\u003e newTypeChosen \u003d bsp.chooseStorageTypes(currentRepl);\n           for (StorageType t: newTypeChosen) {\n             if (t.supportTypeQuota()) {\n               typeSpaces.add(t, oldFileSizeNoRep);\n             }\n           }\n         }\n       }\n       AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n       if (aclFeature !\u003d null) {\n         AclStorage.removeAclFeature(aclFeature);\n       }\n     }\n \n     getDiffs().combineAndCollectSnapshotBlocks(\n         bsps, file, removed, collectedBlocks, removedINodes);\n \n     long ssDelta \u003d oldStoragespace - file.storagespaceConsumed();\n     return new QuotaCounts.Builder().\n         storageSpace(ssDelta).\n         typeSpaces(typeSpaces).\n         build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public QuotaCounts updateQuotaAndCollectBlocks(BlockStoragePolicySuite bsps, INodeFile file,\n      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n      final List\u003cINode\u003e removedINodes) {\n    long oldStoragespace \u003d file.storagespaceConsumed();\n\n    byte storagePolicyID \u003d file.getStoragePolicyID();\n    BlockStoragePolicy bsp \u003d null;\n    EnumCounters\u003cStorageType\u003e typeSpaces \u003d\n        new EnumCounters\u003cStorageType\u003e(StorageType.class);\n    if (storagePolicyID !\u003d HdfsConstantsClient.BLOCK_STORAGE_POLICY_ID_UNSPECIFIED) {\n      bsp \u003d bsps.getPolicy(file.getStoragePolicyID());\n    }\n\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getBlockReplication();\n      if (currentRepl \u003d\u003d 0) {\n        long oldFileSizeNoRep \u003d file.computeFileSize(true, true);\n        oldStoragespace \u003d  oldFileSizeNoRep * replication;\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, -oldFileSizeNoRep);\n            }\n          }\n        }\n      } else if (replication \u003e currentRepl) {\n        long oldFileSizeNoRep \u003d file.storagespaceConsumedNoReplication();\n        oldStoragespace \u003d oldFileSizeNoRep * replication;\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, -oldFileSizeNoRep);\n            }\n          }\n          List\u003cStorageType\u003e newTypeChosen \u003d bsp.chooseStorageTypes(currentRepl);\n          for (StorageType t: newTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, oldFileSizeNoRep);\n            }\n          }\n        }\n      }\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    }\n\n    getDiffs().combineAndCollectSnapshotBlocks(\n        bsps, file, removed, collectedBlocks, removedINodes);\n\n    long ssDelta \u003d oldStoragespace - file.storagespaceConsumed();\n    return new QuotaCounts.Builder().\n        storageSpace(ssDelta).\n        typeSpaces(typeSpaces).\n        build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
      "extendedDetails": {}
    },
    "f2231cebcddc80f0b753c4a7cb45ee4040846951": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7775. Use consistent naming for NN-internal quota related types and functions. (Contributed bu Xiaoyu Yao)\n",
      "commitDate": "13/02/15 9:01 PM",
      "commitName": "f2231cebcddc80f0b753c4a7cb45ee4040846951",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "11/02/15 10:41 AM",
      "commitNameOld": "5dae97a584d30cef3e34141edfaca49c4ec57913",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 2.43,
      "commitsBetweenForRepo": 58,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,62 +1,62 @@\n   public QuotaCounts updateQuotaAndCollectBlocks(BlockStoragePolicySuite bsps, INodeFile file,\n       FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n       final List\u003cINode\u003e removedINodes) {\n-    long oldDiskspace \u003d file.diskspaceConsumed();\n+    long oldStoragespace \u003d file.storagespaceConsumed();\n \n     byte storagePolicyID \u003d file.getStoragePolicyID();\n     BlockStoragePolicy bsp \u003d null;\n     EnumCounters\u003cStorageType\u003e typeSpaces \u003d\n         new EnumCounters\u003cStorageType\u003e(StorageType.class);\n     if (storagePolicyID !\u003d BlockStoragePolicySuite.ID_UNSPECIFIED) {\n       bsp \u003d bsps.getPolicy(file.getStoragePolicyID());\n     }\n \n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n       short currentRepl \u003d file.getBlockReplication();\n       if (currentRepl \u003d\u003d 0) {\n         long oldFileSizeNoRep \u003d file.computeFileSize(true, true);\n-        oldDiskspace \u003d  oldFileSizeNoRep * replication;\n+        oldStoragespace \u003d  oldFileSizeNoRep * replication;\n \n         if (bsp !\u003d null) {\n           List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n           for (StorageType t : oldTypeChosen) {\n             if (t.supportTypeQuota()) {\n               typeSpaces.add(t, -oldFileSizeNoRep);\n             }\n           }\n         }\n       } else if (replication \u003e currentRepl) {\n-        long oldFileSizeNoRep \u003d file.diskspaceConsumedNoReplication();\n-        oldDiskspace \u003d oldFileSizeNoRep * replication;\n+        long oldFileSizeNoRep \u003d file.storagespaceConsumedNoReplication();\n+        oldStoragespace \u003d oldFileSizeNoRep * replication;\n \n         if (bsp !\u003d null) {\n           List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n           for (StorageType t : oldTypeChosen) {\n             if (t.supportTypeQuota()) {\n               typeSpaces.add(t, -oldFileSizeNoRep);\n             }\n           }\n           List\u003cStorageType\u003e newTypeChosen \u003d bsp.chooseStorageTypes(currentRepl);\n           for (StorageType t: newTypeChosen) {\n             if (t.supportTypeQuota()) {\n               typeSpaces.add(t, oldFileSizeNoRep);\n             }\n           }\n         }\n       }\n       AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n       if (aclFeature !\u003d null) {\n         AclStorage.removeAclFeature(aclFeature);\n       }\n     }\n \n     getDiffs().combineAndCollectSnapshotBlocks(\n         bsps, file, removed, collectedBlocks, removedINodes);\n \n-    long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n+    long ssDelta \u003d oldStoragespace - file.storagespaceConsumed();\n     return new QuotaCounts.Builder().\n-        spaceCount(dsDelta).\n-        typeCounts(typeSpaces).\n+        storageSpace(ssDelta).\n+        typeSpaces(typeSpaces).\n         build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public QuotaCounts updateQuotaAndCollectBlocks(BlockStoragePolicySuite bsps, INodeFile file,\n      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n      final List\u003cINode\u003e removedINodes) {\n    long oldStoragespace \u003d file.storagespaceConsumed();\n\n    byte storagePolicyID \u003d file.getStoragePolicyID();\n    BlockStoragePolicy bsp \u003d null;\n    EnumCounters\u003cStorageType\u003e typeSpaces \u003d\n        new EnumCounters\u003cStorageType\u003e(StorageType.class);\n    if (storagePolicyID !\u003d BlockStoragePolicySuite.ID_UNSPECIFIED) {\n      bsp \u003d bsps.getPolicy(file.getStoragePolicyID());\n    }\n\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getBlockReplication();\n      if (currentRepl \u003d\u003d 0) {\n        long oldFileSizeNoRep \u003d file.computeFileSize(true, true);\n        oldStoragespace \u003d  oldFileSizeNoRep * replication;\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, -oldFileSizeNoRep);\n            }\n          }\n        }\n      } else if (replication \u003e currentRepl) {\n        long oldFileSizeNoRep \u003d file.storagespaceConsumedNoReplication();\n        oldStoragespace \u003d oldFileSizeNoRep * replication;\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, -oldFileSizeNoRep);\n            }\n          }\n          List\u003cStorageType\u003e newTypeChosen \u003d bsp.chooseStorageTypes(currentRepl);\n          for (StorageType t: newTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, oldFileSizeNoRep);\n            }\n          }\n        }\n      }\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    }\n\n    getDiffs().combineAndCollectSnapshotBlocks(\n        bsps, file, removed, collectedBlocks, removedINodes);\n\n    long ssDelta \u003d oldStoragespace - file.storagespaceConsumed();\n    return new QuotaCounts.Builder().\n        storageSpace(ssDelta).\n        typeSpaces(typeSpaces).\n        build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
      "extendedDetails": {}
    },
    "5dae97a584d30cef3e34141edfaca49c4ec57913": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-7723. Quota By Storage Type namenode implemenation. (Contributed by Xiaoyu Yao)\n",
      "commitDate": "11/02/15 10:41 AM",
      "commitName": "5dae97a584d30cef3e34141edfaca49c4ec57913",
      "commitAuthor": "Arpit Agarwal",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7723. Quota By Storage Type namenode implemenation. (Contributed by Xiaoyu Yao)\n",
          "commitDate": "11/02/15 10:41 AM",
          "commitName": "5dae97a584d30cef3e34141edfaca49c4ec57913",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "08/02/15 11:51 AM",
          "commitNameOld": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 2.95,
          "commitsBetweenForRepo": 40,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,62 @@\n-  public Quota.Counts updateQuotaAndCollectBlocks(INodeFile file,\n+  public QuotaCounts updateQuotaAndCollectBlocks(BlockStoragePolicySuite bsps, INodeFile file,\n       FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n       final List\u003cINode\u003e removedINodes) {\n     long oldDiskspace \u003d file.diskspaceConsumed();\n+\n+    byte storagePolicyID \u003d file.getStoragePolicyID();\n+    BlockStoragePolicy bsp \u003d null;\n+    EnumCounters\u003cStorageType\u003e typeSpaces \u003d\n+        new EnumCounters\u003cStorageType\u003e(StorageType.class);\n+    if (storagePolicyID !\u003d BlockStoragePolicySuite.ID_UNSPECIFIED) {\n+      bsp \u003d bsps.getPolicy(file.getStoragePolicyID());\n+    }\n+\n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n       short currentRepl \u003d file.getBlockReplication();\n       if (currentRepl \u003d\u003d 0) {\n-        oldDiskspace \u003d file.computeFileSize(true, true) * replication;\n-      } else if (replication \u003e currentRepl) {  \n-        oldDiskspace \u003d oldDiskspace / file.getBlockReplication() * replication;\n+        long oldFileSizeNoRep \u003d file.computeFileSize(true, true);\n+        oldDiskspace \u003d  oldFileSizeNoRep * replication;\n+\n+        if (bsp !\u003d null) {\n+          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n+          for (StorageType t : oldTypeChosen) {\n+            if (t.supportTypeQuota()) {\n+              typeSpaces.add(t, -oldFileSizeNoRep);\n+            }\n+          }\n+        }\n+      } else if (replication \u003e currentRepl) {\n+        long oldFileSizeNoRep \u003d file.diskspaceConsumedNoReplication();\n+        oldDiskspace \u003d oldFileSizeNoRep * replication;\n+\n+        if (bsp !\u003d null) {\n+          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n+          for (StorageType t : oldTypeChosen) {\n+            if (t.supportTypeQuota()) {\n+              typeSpaces.add(t, -oldFileSizeNoRep);\n+            }\n+          }\n+          List\u003cStorageType\u003e newTypeChosen \u003d bsp.chooseStorageTypes(currentRepl);\n+          for (StorageType t: newTypeChosen) {\n+            if (t.supportTypeQuota()) {\n+              typeSpaces.add(t, oldFileSizeNoRep);\n+            }\n+          }\n+        }\n       }\n       AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n       if (aclFeature !\u003d null) {\n         AclStorage.removeAclFeature(aclFeature);\n       }\n     }\n \n     getDiffs().combineAndCollectSnapshotBlocks(\n-        file, removed, collectedBlocks, removedINodes);\n+        bsps, file, removed, collectedBlocks, removedINodes);\n \n     long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n-    return Quota.Counts.newInstance(0, dsDelta);\n+    return new QuotaCounts.Builder().\n+        spaceCount(dsDelta).\n+        typeCounts(typeSpaces).\n+        build();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public QuotaCounts updateQuotaAndCollectBlocks(BlockStoragePolicySuite bsps, INodeFile file,\n      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n      final List\u003cINode\u003e removedINodes) {\n    long oldDiskspace \u003d file.diskspaceConsumed();\n\n    byte storagePolicyID \u003d file.getStoragePolicyID();\n    BlockStoragePolicy bsp \u003d null;\n    EnumCounters\u003cStorageType\u003e typeSpaces \u003d\n        new EnumCounters\u003cStorageType\u003e(StorageType.class);\n    if (storagePolicyID !\u003d BlockStoragePolicySuite.ID_UNSPECIFIED) {\n      bsp \u003d bsps.getPolicy(file.getStoragePolicyID());\n    }\n\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getBlockReplication();\n      if (currentRepl \u003d\u003d 0) {\n        long oldFileSizeNoRep \u003d file.computeFileSize(true, true);\n        oldDiskspace \u003d  oldFileSizeNoRep * replication;\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, -oldFileSizeNoRep);\n            }\n          }\n        }\n      } else if (replication \u003e currentRepl) {\n        long oldFileSizeNoRep \u003d file.diskspaceConsumedNoReplication();\n        oldDiskspace \u003d oldFileSizeNoRep * replication;\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, -oldFileSizeNoRep);\n            }\n          }\n          List\u003cStorageType\u003e newTypeChosen \u003d bsp.chooseStorageTypes(currentRepl);\n          for (StorageType t: newTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, oldFileSizeNoRep);\n            }\n          }\n        }\n      }\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    }\n\n    getDiffs().combineAndCollectSnapshotBlocks(\n        bsps, file, removed, collectedBlocks, removedINodes);\n\n    long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n    return new QuotaCounts.Builder().\n        spaceCount(dsDelta).\n        typeCounts(typeSpaces).\n        build();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
          "extendedDetails": {
            "oldValue": "[file-INodeFile, removed-FileDiff, collectedBlocks-BlocksMapUpdateInfo, removedINodes-List\u003cINode\u003e(modifiers-final)]",
            "newValue": "[bsps-BlockStoragePolicySuite, file-INodeFile, removed-FileDiff, collectedBlocks-BlocksMapUpdateInfo, removedINodes-List\u003cINode\u003e(modifiers-final)]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-7723. Quota By Storage Type namenode implemenation. (Contributed by Xiaoyu Yao)\n",
          "commitDate": "11/02/15 10:41 AM",
          "commitName": "5dae97a584d30cef3e34141edfaca49c4ec57913",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "08/02/15 11:51 AM",
          "commitNameOld": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 2.95,
          "commitsBetweenForRepo": 40,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,62 @@\n-  public Quota.Counts updateQuotaAndCollectBlocks(INodeFile file,\n+  public QuotaCounts updateQuotaAndCollectBlocks(BlockStoragePolicySuite bsps, INodeFile file,\n       FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n       final List\u003cINode\u003e removedINodes) {\n     long oldDiskspace \u003d file.diskspaceConsumed();\n+\n+    byte storagePolicyID \u003d file.getStoragePolicyID();\n+    BlockStoragePolicy bsp \u003d null;\n+    EnumCounters\u003cStorageType\u003e typeSpaces \u003d\n+        new EnumCounters\u003cStorageType\u003e(StorageType.class);\n+    if (storagePolicyID !\u003d BlockStoragePolicySuite.ID_UNSPECIFIED) {\n+      bsp \u003d bsps.getPolicy(file.getStoragePolicyID());\n+    }\n+\n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n       short currentRepl \u003d file.getBlockReplication();\n       if (currentRepl \u003d\u003d 0) {\n-        oldDiskspace \u003d file.computeFileSize(true, true) * replication;\n-      } else if (replication \u003e currentRepl) {  \n-        oldDiskspace \u003d oldDiskspace / file.getBlockReplication() * replication;\n+        long oldFileSizeNoRep \u003d file.computeFileSize(true, true);\n+        oldDiskspace \u003d  oldFileSizeNoRep * replication;\n+\n+        if (bsp !\u003d null) {\n+          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n+          for (StorageType t : oldTypeChosen) {\n+            if (t.supportTypeQuota()) {\n+              typeSpaces.add(t, -oldFileSizeNoRep);\n+            }\n+          }\n+        }\n+      } else if (replication \u003e currentRepl) {\n+        long oldFileSizeNoRep \u003d file.diskspaceConsumedNoReplication();\n+        oldDiskspace \u003d oldFileSizeNoRep * replication;\n+\n+        if (bsp !\u003d null) {\n+          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n+          for (StorageType t : oldTypeChosen) {\n+            if (t.supportTypeQuota()) {\n+              typeSpaces.add(t, -oldFileSizeNoRep);\n+            }\n+          }\n+          List\u003cStorageType\u003e newTypeChosen \u003d bsp.chooseStorageTypes(currentRepl);\n+          for (StorageType t: newTypeChosen) {\n+            if (t.supportTypeQuota()) {\n+              typeSpaces.add(t, oldFileSizeNoRep);\n+            }\n+          }\n+        }\n       }\n       AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n       if (aclFeature !\u003d null) {\n         AclStorage.removeAclFeature(aclFeature);\n       }\n     }\n \n     getDiffs().combineAndCollectSnapshotBlocks(\n-        file, removed, collectedBlocks, removedINodes);\n+        bsps, file, removed, collectedBlocks, removedINodes);\n \n     long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n-    return Quota.Counts.newInstance(0, dsDelta);\n+    return new QuotaCounts.Builder().\n+        spaceCount(dsDelta).\n+        typeCounts(typeSpaces).\n+        build();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public QuotaCounts updateQuotaAndCollectBlocks(BlockStoragePolicySuite bsps, INodeFile file,\n      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n      final List\u003cINode\u003e removedINodes) {\n    long oldDiskspace \u003d file.diskspaceConsumed();\n\n    byte storagePolicyID \u003d file.getStoragePolicyID();\n    BlockStoragePolicy bsp \u003d null;\n    EnumCounters\u003cStorageType\u003e typeSpaces \u003d\n        new EnumCounters\u003cStorageType\u003e(StorageType.class);\n    if (storagePolicyID !\u003d BlockStoragePolicySuite.ID_UNSPECIFIED) {\n      bsp \u003d bsps.getPolicy(file.getStoragePolicyID());\n    }\n\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getBlockReplication();\n      if (currentRepl \u003d\u003d 0) {\n        long oldFileSizeNoRep \u003d file.computeFileSize(true, true);\n        oldDiskspace \u003d  oldFileSizeNoRep * replication;\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, -oldFileSizeNoRep);\n            }\n          }\n        }\n      } else if (replication \u003e currentRepl) {\n        long oldFileSizeNoRep \u003d file.diskspaceConsumedNoReplication();\n        oldDiskspace \u003d oldFileSizeNoRep * replication;\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, -oldFileSizeNoRep);\n            }\n          }\n          List\u003cStorageType\u003e newTypeChosen \u003d bsp.chooseStorageTypes(currentRepl);\n          for (StorageType t: newTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, oldFileSizeNoRep);\n            }\n          }\n        }\n      }\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    }\n\n    getDiffs().combineAndCollectSnapshotBlocks(\n        bsps, file, removed, collectedBlocks, removedINodes);\n\n    long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n    return new QuotaCounts.Builder().\n        spaceCount(dsDelta).\n        typeCounts(typeSpaces).\n        build();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
          "extendedDetails": {
            "oldValue": "Quota.Counts",
            "newValue": "QuotaCounts"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7723. Quota By Storage Type namenode implemenation. (Contributed by Xiaoyu Yao)\n",
          "commitDate": "11/02/15 10:41 AM",
          "commitName": "5dae97a584d30cef3e34141edfaca49c4ec57913",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "08/02/15 11:51 AM",
          "commitNameOld": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 2.95,
          "commitsBetweenForRepo": 40,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,62 @@\n-  public Quota.Counts updateQuotaAndCollectBlocks(INodeFile file,\n+  public QuotaCounts updateQuotaAndCollectBlocks(BlockStoragePolicySuite bsps, INodeFile file,\n       FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n       final List\u003cINode\u003e removedINodes) {\n     long oldDiskspace \u003d file.diskspaceConsumed();\n+\n+    byte storagePolicyID \u003d file.getStoragePolicyID();\n+    BlockStoragePolicy bsp \u003d null;\n+    EnumCounters\u003cStorageType\u003e typeSpaces \u003d\n+        new EnumCounters\u003cStorageType\u003e(StorageType.class);\n+    if (storagePolicyID !\u003d BlockStoragePolicySuite.ID_UNSPECIFIED) {\n+      bsp \u003d bsps.getPolicy(file.getStoragePolicyID());\n+    }\n+\n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n       short currentRepl \u003d file.getBlockReplication();\n       if (currentRepl \u003d\u003d 0) {\n-        oldDiskspace \u003d file.computeFileSize(true, true) * replication;\n-      } else if (replication \u003e currentRepl) {  \n-        oldDiskspace \u003d oldDiskspace / file.getBlockReplication() * replication;\n+        long oldFileSizeNoRep \u003d file.computeFileSize(true, true);\n+        oldDiskspace \u003d  oldFileSizeNoRep * replication;\n+\n+        if (bsp !\u003d null) {\n+          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n+          for (StorageType t : oldTypeChosen) {\n+            if (t.supportTypeQuota()) {\n+              typeSpaces.add(t, -oldFileSizeNoRep);\n+            }\n+          }\n+        }\n+      } else if (replication \u003e currentRepl) {\n+        long oldFileSizeNoRep \u003d file.diskspaceConsumedNoReplication();\n+        oldDiskspace \u003d oldFileSizeNoRep * replication;\n+\n+        if (bsp !\u003d null) {\n+          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n+          for (StorageType t : oldTypeChosen) {\n+            if (t.supportTypeQuota()) {\n+              typeSpaces.add(t, -oldFileSizeNoRep);\n+            }\n+          }\n+          List\u003cStorageType\u003e newTypeChosen \u003d bsp.chooseStorageTypes(currentRepl);\n+          for (StorageType t: newTypeChosen) {\n+            if (t.supportTypeQuota()) {\n+              typeSpaces.add(t, oldFileSizeNoRep);\n+            }\n+          }\n+        }\n       }\n       AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n       if (aclFeature !\u003d null) {\n         AclStorage.removeAclFeature(aclFeature);\n       }\n     }\n \n     getDiffs().combineAndCollectSnapshotBlocks(\n-        file, removed, collectedBlocks, removedINodes);\n+        bsps, file, removed, collectedBlocks, removedINodes);\n \n     long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n-    return Quota.Counts.newInstance(0, dsDelta);\n+    return new QuotaCounts.Builder().\n+        spaceCount(dsDelta).\n+        typeCounts(typeSpaces).\n+        build();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public QuotaCounts updateQuotaAndCollectBlocks(BlockStoragePolicySuite bsps, INodeFile file,\n      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n      final List\u003cINode\u003e removedINodes) {\n    long oldDiskspace \u003d file.diskspaceConsumed();\n\n    byte storagePolicyID \u003d file.getStoragePolicyID();\n    BlockStoragePolicy bsp \u003d null;\n    EnumCounters\u003cStorageType\u003e typeSpaces \u003d\n        new EnumCounters\u003cStorageType\u003e(StorageType.class);\n    if (storagePolicyID !\u003d BlockStoragePolicySuite.ID_UNSPECIFIED) {\n      bsp \u003d bsps.getPolicy(file.getStoragePolicyID());\n    }\n\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getBlockReplication();\n      if (currentRepl \u003d\u003d 0) {\n        long oldFileSizeNoRep \u003d file.computeFileSize(true, true);\n        oldDiskspace \u003d  oldFileSizeNoRep * replication;\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, -oldFileSizeNoRep);\n            }\n          }\n        }\n      } else if (replication \u003e currentRepl) {\n        long oldFileSizeNoRep \u003d file.diskspaceConsumedNoReplication();\n        oldDiskspace \u003d oldFileSizeNoRep * replication;\n\n        if (bsp !\u003d null) {\n          List\u003cStorageType\u003e oldTypeChosen \u003d bsp.chooseStorageTypes(replication);\n          for (StorageType t : oldTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, -oldFileSizeNoRep);\n            }\n          }\n          List\u003cStorageType\u003e newTypeChosen \u003d bsp.chooseStorageTypes(currentRepl);\n          for (StorageType t: newTypeChosen) {\n            if (t.supportTypeQuota()) {\n              typeSpaces.add(t, oldFileSizeNoRep);\n            }\n          }\n        }\n      }\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    }\n\n    getDiffs().combineAndCollectSnapshotBlocks(\n        bsps, file, removed, collectedBlocks, removedINodes);\n\n    long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n    return new QuotaCounts.Builder().\n        spaceCount(dsDelta).\n        typeCounts(typeSpaces).\n        build();\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
          "extendedDetails": {}
        }
      ]
    },
    "08ac06283a3e9bf0d49d873823aabd419b08e41f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7056. Snapshot support for truncate. Contributed by Konstantin Shvachko and Plamen Jeliazkov.",
      "commitDate": "13/01/15 12:24 AM",
      "commitName": "08ac06283a3e9bf0d49d873823aabd419b08e41f",
      "commitAuthor": "Konstantin V Shvachko",
      "commitDateOld": "12/01/15 10:50 PM",
      "commitNameOld": "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
      "commitAuthorOld": "Plamen Jeliazkov",
      "daysBetweenCommits": 0.07,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,24 @@\n   public Quota.Counts updateQuotaAndCollectBlocks(INodeFile file,\n       FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n       final List\u003cINode\u003e removedINodes) {\n     long oldDiskspace \u003d file.diskspaceConsumed();\n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n       short currentRepl \u003d file.getBlockReplication();\n       if (currentRepl \u003d\u003d 0) {\n         oldDiskspace \u003d file.computeFileSize(true, true) * replication;\n       } else if (replication \u003e currentRepl) {  \n         oldDiskspace \u003d oldDiskspace / file.getBlockReplication() * replication;\n       }\n       AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n       if (aclFeature !\u003d null) {\n         AclStorage.removeAclFeature(aclFeature);\n       }\n     }\n-    \n-    collectBlocksAndClear(file, collectedBlocks, removedINodes);\n-    \n+\n+    getDiffs().combineAndCollectSnapshotBlocks(\n+        file, removed, collectedBlocks, removedINodes);\n+\n     long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n     return Quota.Counts.newInstance(0, dsDelta);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Quota.Counts updateQuotaAndCollectBlocks(INodeFile file,\n      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n      final List\u003cINode\u003e removedINodes) {\n    long oldDiskspace \u003d file.diskspaceConsumed();\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getBlockReplication();\n      if (currentRepl \u003d\u003d 0) {\n        oldDiskspace \u003d file.computeFileSize(true, true) * replication;\n      } else if (replication \u003e currentRepl) {  \n        oldDiskspace \u003d oldDiskspace / file.getBlockReplication() * replication;\n      }\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    }\n\n    getDiffs().combineAndCollectSnapshotBlocks(\n        file, removed, collectedBlocks, removedINodes);\n\n    long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n    return Quota.Counts.newInstance(0, dsDelta);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
      "extendedDetails": {}
    },
    "50ae1a6664a92619aa683d2a864d0da9fb4af026": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7456. De-duplicate AclFeature instances with same AclEntries do reduce memory footprint of NameNode (Contributed by Vinayakumar B)\n",
      "commitDate": "22/12/14 11:05 PM",
      "commitName": "50ae1a6664a92619aa683d2a864d0da9fb4af026",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "21/06/14 3:59 PM",
      "commitNameOld": "8a83bb7ad6177f473c20c4cc9c0f46746224332c",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 184.34,
      "commitsBetweenForRepo": 1648,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,23 @@\n   public Quota.Counts updateQuotaAndCollectBlocks(INodeFile file,\n       FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n       final List\u003cINode\u003e removedINodes) {\n     long oldDiskspace \u003d file.diskspaceConsumed();\n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n       short currentRepl \u003d file.getBlockReplication();\n       if (currentRepl \u003d\u003d 0) {\n         oldDiskspace \u003d file.computeFileSize(true, true) * replication;\n       } else if (replication \u003e currentRepl) {  \n         oldDiskspace \u003d oldDiskspace / file.getBlockReplication() * replication;\n       }\n+      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n+      if (aclFeature !\u003d null) {\n+        AclStorage.removeAclFeature(aclFeature);\n+      }\n     }\n     \n     collectBlocksAndClear(file, collectedBlocks, removedINodes);\n     \n     long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n     return Quota.Counts.newInstance(0, dsDelta);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Quota.Counts updateQuotaAndCollectBlocks(INodeFile file,\n      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n      final List\u003cINode\u003e removedINodes) {\n    long oldDiskspace \u003d file.diskspaceConsumed();\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getBlockReplication();\n      if (currentRepl \u003d\u003d 0) {\n        oldDiskspace \u003d file.computeFileSize(true, true) * replication;\n      } else if (replication \u003e currentRepl) {  \n        oldDiskspace \u003d oldDiskspace / file.getBlockReplication() * replication;\n      }\n      AclFeature aclFeature \u003d removed.getSnapshotINode().getAclFeature();\n      if (aclFeature !\u003d null) {\n        AclStorage.removeAclFeature(aclFeature);\n      }\n    }\n    \n    collectBlocksAndClear(file, collectedBlocks, removedINodes);\n    \n    long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n    return Quota.Counts.newInstance(0, dsDelta);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
      "extendedDetails": {}
    },
    "4c87a27ad851ffaa3cc3e2074a9ef7073b5a164a": {
      "type": "Ymultichange(Yfilerename,Ymodifierchange,Ybodychange,Yparameterchange)",
      "commitMessage": "HDFS-5554. Flatten INodeFile hierarchy: Replace INodeFileWithSnapshot with FileWithSnapshotFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548796 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/12/13 10:17 PM",
      "commitName": "4c87a27ad851ffaa3cc3e2074a9ef7073b5a164a",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "HDFS-5554. Flatten INodeFile hierarchy: Replace INodeFileWithSnapshot with FileWithSnapshotFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548796 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/13 10:17 PM",
          "commitName": "4c87a27ad851ffaa3cc3e2074a9ef7073b5a164a",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "06/12/13 4:11 PM",
          "commitNameOld": "7f059104d293614f3250bd1408874e97f659c92b",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 0.25,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,19 @@\n-  Quota.Counts updateQuotaAndCollectBlocks(FileDiff removed,\n-      BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n-    long oldDiskspace \u003d this.diskspaceConsumed();\n+  public Quota.Counts updateQuotaAndCollectBlocks(INodeFile file,\n+      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n+      final List\u003cINode\u003e removedINodes) {\n+    long oldDiskspace \u003d file.diskspaceConsumed();\n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n-      short currentRepl \u003d getBlockReplication();\n+      short currentRepl \u003d file.getBlockReplication();\n       if (currentRepl \u003d\u003d 0) {\n-        oldDiskspace \u003d computeFileSize(true, true) * replication;\n+        oldDiskspace \u003d file.computeFileSize(true, true) * replication;\n       } else if (replication \u003e currentRepl) {  \n-        oldDiskspace \u003d oldDiskspace / getBlockReplication()\n-            * replication;\n+        oldDiskspace \u003d oldDiskspace / file.getBlockReplication() * replication;\n       }\n     }\n     \n-    this.collectBlocksAndClear(collectedBlocks, removedINodes);\n+    collectBlocksAndClear(file, collectedBlocks, removedINodes);\n     \n-    long dsDelta \u003d oldDiskspace - diskspaceConsumed();\n+    long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n     return Quota.Counts.newInstance(0, dsDelta);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Quota.Counts updateQuotaAndCollectBlocks(INodeFile file,\n      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n      final List\u003cINode\u003e removedINodes) {\n    long oldDiskspace \u003d file.diskspaceConsumed();\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getBlockReplication();\n      if (currentRepl \u003d\u003d 0) {\n        oldDiskspace \u003d file.computeFileSize(true, true) * replication;\n      } else if (replication \u003e currentRepl) {  \n        oldDiskspace \u003d oldDiskspace / file.getBlockReplication() * replication;\n      }\n    }\n    \n    collectBlocksAndClear(file, collectedBlocks, removedINodes);\n    \n    long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n    return Quota.Counts.newInstance(0, dsDelta);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/INodeFileWithSnapshot.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-5554. Flatten INodeFile hierarchy: Replace INodeFileWithSnapshot with FileWithSnapshotFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548796 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/13 10:17 PM",
          "commitName": "4c87a27ad851ffaa3cc3e2074a9ef7073b5a164a",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "06/12/13 4:11 PM",
          "commitNameOld": "7f059104d293614f3250bd1408874e97f659c92b",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 0.25,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,19 @@\n-  Quota.Counts updateQuotaAndCollectBlocks(FileDiff removed,\n-      BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n-    long oldDiskspace \u003d this.diskspaceConsumed();\n+  public Quota.Counts updateQuotaAndCollectBlocks(INodeFile file,\n+      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n+      final List\u003cINode\u003e removedINodes) {\n+    long oldDiskspace \u003d file.diskspaceConsumed();\n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n-      short currentRepl \u003d getBlockReplication();\n+      short currentRepl \u003d file.getBlockReplication();\n       if (currentRepl \u003d\u003d 0) {\n-        oldDiskspace \u003d computeFileSize(true, true) * replication;\n+        oldDiskspace \u003d file.computeFileSize(true, true) * replication;\n       } else if (replication \u003e currentRepl) {  \n-        oldDiskspace \u003d oldDiskspace / getBlockReplication()\n-            * replication;\n+        oldDiskspace \u003d oldDiskspace / file.getBlockReplication() * replication;\n       }\n     }\n     \n-    this.collectBlocksAndClear(collectedBlocks, removedINodes);\n+    collectBlocksAndClear(file, collectedBlocks, removedINodes);\n     \n-    long dsDelta \u003d oldDiskspace - diskspaceConsumed();\n+    long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n     return Quota.Counts.newInstance(0, dsDelta);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Quota.Counts updateQuotaAndCollectBlocks(INodeFile file,\n      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n      final List\u003cINode\u003e removedINodes) {\n    long oldDiskspace \u003d file.diskspaceConsumed();\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getBlockReplication();\n      if (currentRepl \u003d\u003d 0) {\n        oldDiskspace \u003d file.computeFileSize(true, true) * replication;\n      } else if (replication \u003e currentRepl) {  \n        oldDiskspace \u003d oldDiskspace / file.getBlockReplication() * replication;\n      }\n    }\n    \n    collectBlocksAndClear(file, collectedBlocks, removedINodes);\n    \n    long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n    return Quota.Counts.newInstance(0, dsDelta);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5554. Flatten INodeFile hierarchy: Replace INodeFileWithSnapshot with FileWithSnapshotFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548796 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/13 10:17 PM",
          "commitName": "4c87a27ad851ffaa3cc3e2074a9ef7073b5a164a",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "06/12/13 4:11 PM",
          "commitNameOld": "7f059104d293614f3250bd1408874e97f659c92b",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 0.25,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,19 @@\n-  Quota.Counts updateQuotaAndCollectBlocks(FileDiff removed,\n-      BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n-    long oldDiskspace \u003d this.diskspaceConsumed();\n+  public Quota.Counts updateQuotaAndCollectBlocks(INodeFile file,\n+      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n+      final List\u003cINode\u003e removedINodes) {\n+    long oldDiskspace \u003d file.diskspaceConsumed();\n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n-      short currentRepl \u003d getBlockReplication();\n+      short currentRepl \u003d file.getBlockReplication();\n       if (currentRepl \u003d\u003d 0) {\n-        oldDiskspace \u003d computeFileSize(true, true) * replication;\n+        oldDiskspace \u003d file.computeFileSize(true, true) * replication;\n       } else if (replication \u003e currentRepl) {  \n-        oldDiskspace \u003d oldDiskspace / getBlockReplication()\n-            * replication;\n+        oldDiskspace \u003d oldDiskspace / file.getBlockReplication() * replication;\n       }\n     }\n     \n-    this.collectBlocksAndClear(collectedBlocks, removedINodes);\n+    collectBlocksAndClear(file, collectedBlocks, removedINodes);\n     \n-    long dsDelta \u003d oldDiskspace - diskspaceConsumed();\n+    long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n     return Quota.Counts.newInstance(0, dsDelta);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Quota.Counts updateQuotaAndCollectBlocks(INodeFile file,\n      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n      final List\u003cINode\u003e removedINodes) {\n    long oldDiskspace \u003d file.diskspaceConsumed();\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getBlockReplication();\n      if (currentRepl \u003d\u003d 0) {\n        oldDiskspace \u003d file.computeFileSize(true, true) * replication;\n      } else if (replication \u003e currentRepl) {  \n        oldDiskspace \u003d oldDiskspace / file.getBlockReplication() * replication;\n      }\n    }\n    \n    collectBlocksAndClear(file, collectedBlocks, removedINodes);\n    \n    long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n    return Quota.Counts.newInstance(0, dsDelta);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5554. Flatten INodeFile hierarchy: Replace INodeFileWithSnapshot with FileWithSnapshotFeature.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548796 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/13 10:17 PM",
          "commitName": "4c87a27ad851ffaa3cc3e2074a9ef7073b5a164a",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "06/12/13 4:11 PM",
          "commitNameOld": "7f059104d293614f3250bd1408874e97f659c92b",
          "commitAuthorOld": "Colin McCabe",
          "daysBetweenCommits": 0.25,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,19 @@\n-  Quota.Counts updateQuotaAndCollectBlocks(FileDiff removed,\n-      BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n-    long oldDiskspace \u003d this.diskspaceConsumed();\n+  public Quota.Counts updateQuotaAndCollectBlocks(INodeFile file,\n+      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n+      final List\u003cINode\u003e removedINodes) {\n+    long oldDiskspace \u003d file.diskspaceConsumed();\n     if (removed.snapshotINode !\u003d null) {\n       short replication \u003d removed.snapshotINode.getFileReplication();\n-      short currentRepl \u003d getBlockReplication();\n+      short currentRepl \u003d file.getBlockReplication();\n       if (currentRepl \u003d\u003d 0) {\n-        oldDiskspace \u003d computeFileSize(true, true) * replication;\n+        oldDiskspace \u003d file.computeFileSize(true, true) * replication;\n       } else if (replication \u003e currentRepl) {  \n-        oldDiskspace \u003d oldDiskspace / getBlockReplication()\n-            * replication;\n+        oldDiskspace \u003d oldDiskspace / file.getBlockReplication() * replication;\n       }\n     }\n     \n-    this.collectBlocksAndClear(collectedBlocks, removedINodes);\n+    collectBlocksAndClear(file, collectedBlocks, removedINodes);\n     \n-    long dsDelta \u003d oldDiskspace - diskspaceConsumed();\n+    long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n     return Quota.Counts.newInstance(0, dsDelta);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public Quota.Counts updateQuotaAndCollectBlocks(INodeFile file,\n      FileDiff removed, BlocksMapUpdateInfo collectedBlocks,\n      final List\u003cINode\u003e removedINodes) {\n    long oldDiskspace \u003d file.diskspaceConsumed();\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d file.getBlockReplication();\n      if (currentRepl \u003d\u003d 0) {\n        oldDiskspace \u003d file.computeFileSize(true, true) * replication;\n      } else if (replication \u003e currentRepl) {  \n        oldDiskspace \u003d oldDiskspace / file.getBlockReplication() * replication;\n      }\n    }\n    \n    collectBlocksAndClear(file, collectedBlocks, removedINodes);\n    \n    long dsDelta \u003d oldDiskspace - file.diskspaceConsumed();\n    return Quota.Counts.newInstance(0, dsDelta);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshotFeature.java",
          "extendedDetails": {
            "oldValue": "[removed-FileDiff, collectedBlocks-BlocksMapUpdateInfo, removedINodes-List\u003cINode\u003e(modifiers-final)]",
            "newValue": "[file-INodeFile, removed-FileDiff, collectedBlocks-BlocksMapUpdateInfo, removedINodes-List\u003cINode\u003e(modifiers-final)]"
          }
        }
      ]
    },
    "8df119da214babde03e73243c7ca4cfe6d0ca562": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yparameterchange)",
      "commitMessage": "HDFS-5537. Remove FileWithSnapshot interface.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/11/13 12:32 PM",
      "commitName": "8df119da214babde03e73243c7ca4cfe6d0ca562",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-5537. Remove FileWithSnapshot interface.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546184 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/11/13 12:32 PM",
          "commitName": "8df119da214babde03e73243c7ca4cfe6d0ca562",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "27/11/13 10:20 AM",
          "commitNameOld": "2214871d916fdcae62aa51afbb5fd571f2808745",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 0.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,19 @@\n-    private static Quota.Counts updateQuotaAndCollectBlocks(\n-        INodeFile currentINode, FileDiff removed,\n-        BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n-      FileWithSnapshot sFile \u003d (FileWithSnapshot) currentINode;\n-      long oldDiskspace \u003d currentINode.diskspaceConsumed();\n-      if (removed.snapshotINode !\u003d null) {\n-        short replication \u003d removed.snapshotINode.getFileReplication();\n-        short currentRepl \u003d currentINode.getBlockReplication();\n-        if (currentRepl \u003d\u003d 0) {\n-          oldDiskspace \u003d currentINode.computeFileSize(true, true) * replication;\n-        } else if (replication \u003e currentRepl) {  \n-          oldDiskspace \u003d oldDiskspace / currentINode.getBlockReplication()\n-              * replication;\n-        }\n+  Quota.Counts updateQuotaAndCollectBlocks(FileDiff removed,\n+      BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n+    long oldDiskspace \u003d this.diskspaceConsumed();\n+    if (removed.snapshotINode !\u003d null) {\n+      short replication \u003d removed.snapshotINode.getFileReplication();\n+      short currentRepl \u003d getBlockReplication();\n+      if (currentRepl \u003d\u003d 0) {\n+        oldDiskspace \u003d computeFileSize(true, true) * replication;\n+      } else if (replication \u003e currentRepl) {  \n+        oldDiskspace \u003d oldDiskspace / getBlockReplication()\n+            * replication;\n       }\n-      \n-      Util.collectBlocksAndClear(sFile, collectedBlocks, removedINodes);\n-      \n-      long dsDelta \u003d oldDiskspace - currentINode.diskspaceConsumed();\n-      return Quota.Counts.newInstance(0, dsDelta);\n-    }\n\\ No newline at end of file\n+    }\n+    \n+    this.collectBlocksAndClear(collectedBlocks, removedINodes);\n+    \n+    long dsDelta \u003d oldDiskspace - diskspaceConsumed();\n+    return Quota.Counts.newInstance(0, dsDelta);\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  Quota.Counts updateQuotaAndCollectBlocks(FileDiff removed,\n      BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n    long oldDiskspace \u003d this.diskspaceConsumed();\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d getBlockReplication();\n      if (currentRepl \u003d\u003d 0) {\n        oldDiskspace \u003d computeFileSize(true, true) * replication;\n      } else if (replication \u003e currentRepl) {  \n        oldDiskspace \u003d oldDiskspace / getBlockReplication()\n            * replication;\n      }\n    }\n    \n    this.collectBlocksAndClear(collectedBlocks, removedINodes);\n    \n    long dsDelta \u003d oldDiskspace - diskspaceConsumed();\n    return Quota.Counts.newInstance(0, dsDelta);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/INodeFileWithSnapshot.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshot.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/INodeFileWithSnapshot.java",
            "oldMethodName": "updateQuotaAndCollectBlocks",
            "newMethodName": "updateQuotaAndCollectBlocks"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-5537. Remove FileWithSnapshot interface.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546184 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/11/13 12:32 PM",
          "commitName": "8df119da214babde03e73243c7ca4cfe6d0ca562",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "27/11/13 10:20 AM",
          "commitNameOld": "2214871d916fdcae62aa51afbb5fd571f2808745",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 0.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,19 @@\n-    private static Quota.Counts updateQuotaAndCollectBlocks(\n-        INodeFile currentINode, FileDiff removed,\n-        BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n-      FileWithSnapshot sFile \u003d (FileWithSnapshot) currentINode;\n-      long oldDiskspace \u003d currentINode.diskspaceConsumed();\n-      if (removed.snapshotINode !\u003d null) {\n-        short replication \u003d removed.snapshotINode.getFileReplication();\n-        short currentRepl \u003d currentINode.getBlockReplication();\n-        if (currentRepl \u003d\u003d 0) {\n-          oldDiskspace \u003d currentINode.computeFileSize(true, true) * replication;\n-        } else if (replication \u003e currentRepl) {  \n-          oldDiskspace \u003d oldDiskspace / currentINode.getBlockReplication()\n-              * replication;\n-        }\n+  Quota.Counts updateQuotaAndCollectBlocks(FileDiff removed,\n+      BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n+    long oldDiskspace \u003d this.diskspaceConsumed();\n+    if (removed.snapshotINode !\u003d null) {\n+      short replication \u003d removed.snapshotINode.getFileReplication();\n+      short currentRepl \u003d getBlockReplication();\n+      if (currentRepl \u003d\u003d 0) {\n+        oldDiskspace \u003d computeFileSize(true, true) * replication;\n+      } else if (replication \u003e currentRepl) {  \n+        oldDiskspace \u003d oldDiskspace / getBlockReplication()\n+            * replication;\n       }\n-      \n-      Util.collectBlocksAndClear(sFile, collectedBlocks, removedINodes);\n-      \n-      long dsDelta \u003d oldDiskspace - currentINode.diskspaceConsumed();\n-      return Quota.Counts.newInstance(0, dsDelta);\n-    }\n\\ No newline at end of file\n+    }\n+    \n+    this.collectBlocksAndClear(collectedBlocks, removedINodes);\n+    \n+    long dsDelta \u003d oldDiskspace - diskspaceConsumed();\n+    return Quota.Counts.newInstance(0, dsDelta);\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  Quota.Counts updateQuotaAndCollectBlocks(FileDiff removed,\n      BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n    long oldDiskspace \u003d this.diskspaceConsumed();\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d getBlockReplication();\n      if (currentRepl \u003d\u003d 0) {\n        oldDiskspace \u003d computeFileSize(true, true) * replication;\n      } else if (replication \u003e currentRepl) {  \n        oldDiskspace \u003d oldDiskspace / getBlockReplication()\n            * replication;\n      }\n    }\n    \n    this.collectBlocksAndClear(collectedBlocks, removedINodes);\n    \n    long dsDelta \u003d oldDiskspace - diskspaceConsumed();\n    return Quota.Counts.newInstance(0, dsDelta);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/INodeFileWithSnapshot.java",
          "extendedDetails": {
            "oldValue": "[private, static]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5537. Remove FileWithSnapshot interface.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546184 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/11/13 12:32 PM",
          "commitName": "8df119da214babde03e73243c7ca4cfe6d0ca562",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "27/11/13 10:20 AM",
          "commitNameOld": "2214871d916fdcae62aa51afbb5fd571f2808745",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 0.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,19 @@\n-    private static Quota.Counts updateQuotaAndCollectBlocks(\n-        INodeFile currentINode, FileDiff removed,\n-        BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n-      FileWithSnapshot sFile \u003d (FileWithSnapshot) currentINode;\n-      long oldDiskspace \u003d currentINode.diskspaceConsumed();\n-      if (removed.snapshotINode !\u003d null) {\n-        short replication \u003d removed.snapshotINode.getFileReplication();\n-        short currentRepl \u003d currentINode.getBlockReplication();\n-        if (currentRepl \u003d\u003d 0) {\n-          oldDiskspace \u003d currentINode.computeFileSize(true, true) * replication;\n-        } else if (replication \u003e currentRepl) {  \n-          oldDiskspace \u003d oldDiskspace / currentINode.getBlockReplication()\n-              * replication;\n-        }\n+  Quota.Counts updateQuotaAndCollectBlocks(FileDiff removed,\n+      BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n+    long oldDiskspace \u003d this.diskspaceConsumed();\n+    if (removed.snapshotINode !\u003d null) {\n+      short replication \u003d removed.snapshotINode.getFileReplication();\n+      short currentRepl \u003d getBlockReplication();\n+      if (currentRepl \u003d\u003d 0) {\n+        oldDiskspace \u003d computeFileSize(true, true) * replication;\n+      } else if (replication \u003e currentRepl) {  \n+        oldDiskspace \u003d oldDiskspace / getBlockReplication()\n+            * replication;\n       }\n-      \n-      Util.collectBlocksAndClear(sFile, collectedBlocks, removedINodes);\n-      \n-      long dsDelta \u003d oldDiskspace - currentINode.diskspaceConsumed();\n-      return Quota.Counts.newInstance(0, dsDelta);\n-    }\n\\ No newline at end of file\n+    }\n+    \n+    this.collectBlocksAndClear(collectedBlocks, removedINodes);\n+    \n+    long dsDelta \u003d oldDiskspace - diskspaceConsumed();\n+    return Quota.Counts.newInstance(0, dsDelta);\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  Quota.Counts updateQuotaAndCollectBlocks(FileDiff removed,\n      BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n    long oldDiskspace \u003d this.diskspaceConsumed();\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d getBlockReplication();\n      if (currentRepl \u003d\u003d 0) {\n        oldDiskspace \u003d computeFileSize(true, true) * replication;\n      } else if (replication \u003e currentRepl) {  \n        oldDiskspace \u003d oldDiskspace / getBlockReplication()\n            * replication;\n      }\n    }\n    \n    this.collectBlocksAndClear(collectedBlocks, removedINodes);\n    \n    long dsDelta \u003d oldDiskspace - diskspaceConsumed();\n    return Quota.Counts.newInstance(0, dsDelta);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/INodeFileWithSnapshot.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-5537. Remove FileWithSnapshot interface.  Contributed by jing9\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546184 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/11/13 12:32 PM",
          "commitName": "8df119da214babde03e73243c7ca4cfe6d0ca562",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "27/11/13 10:20 AM",
          "commitNameOld": "2214871d916fdcae62aa51afbb5fd571f2808745",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 0.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,19 @@\n-    private static Quota.Counts updateQuotaAndCollectBlocks(\n-        INodeFile currentINode, FileDiff removed,\n-        BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n-      FileWithSnapshot sFile \u003d (FileWithSnapshot) currentINode;\n-      long oldDiskspace \u003d currentINode.diskspaceConsumed();\n-      if (removed.snapshotINode !\u003d null) {\n-        short replication \u003d removed.snapshotINode.getFileReplication();\n-        short currentRepl \u003d currentINode.getBlockReplication();\n-        if (currentRepl \u003d\u003d 0) {\n-          oldDiskspace \u003d currentINode.computeFileSize(true, true) * replication;\n-        } else if (replication \u003e currentRepl) {  \n-          oldDiskspace \u003d oldDiskspace / currentINode.getBlockReplication()\n-              * replication;\n-        }\n+  Quota.Counts updateQuotaAndCollectBlocks(FileDiff removed,\n+      BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n+    long oldDiskspace \u003d this.diskspaceConsumed();\n+    if (removed.snapshotINode !\u003d null) {\n+      short replication \u003d removed.snapshotINode.getFileReplication();\n+      short currentRepl \u003d getBlockReplication();\n+      if (currentRepl \u003d\u003d 0) {\n+        oldDiskspace \u003d computeFileSize(true, true) * replication;\n+      } else if (replication \u003e currentRepl) {  \n+        oldDiskspace \u003d oldDiskspace / getBlockReplication()\n+            * replication;\n       }\n-      \n-      Util.collectBlocksAndClear(sFile, collectedBlocks, removedINodes);\n-      \n-      long dsDelta \u003d oldDiskspace - currentINode.diskspaceConsumed();\n-      return Quota.Counts.newInstance(0, dsDelta);\n-    }\n\\ No newline at end of file\n+    }\n+    \n+    this.collectBlocksAndClear(collectedBlocks, removedINodes);\n+    \n+    long dsDelta \u003d oldDiskspace - diskspaceConsumed();\n+    return Quota.Counts.newInstance(0, dsDelta);\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  Quota.Counts updateQuotaAndCollectBlocks(FileDiff removed,\n      BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n    long oldDiskspace \u003d this.diskspaceConsumed();\n    if (removed.snapshotINode !\u003d null) {\n      short replication \u003d removed.snapshotINode.getFileReplication();\n      short currentRepl \u003d getBlockReplication();\n      if (currentRepl \u003d\u003d 0) {\n        oldDiskspace \u003d computeFileSize(true, true) * replication;\n      } else if (replication \u003e currentRepl) {  \n        oldDiskspace \u003d oldDiskspace / getBlockReplication()\n            * replication;\n      }\n    }\n    \n    this.collectBlocksAndClear(collectedBlocks, removedINodes);\n    \n    long dsDelta \u003d oldDiskspace - diskspaceConsumed();\n    return Quota.Counts.newInstance(0, dsDelta);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/INodeFileWithSnapshot.java",
          "extendedDetails": {
            "oldValue": "[currentINode-INodeFile, removed-FileDiff, collectedBlocks-BlocksMapUpdateInfo, removedINodes-List\u003cINode\u003e(modifiers-final)]",
            "newValue": "[removed-FileDiff, collectedBlocks-BlocksMapUpdateInfo, removedINodes-List\u003cINode\u003e(modifiers-final)]"
          }
        }
      ]
    },
    "e097f8404b3ffbad5322e0f8381a0b9958c5b589": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4773. Fix bugs in quota usage computation and OfflineImageViewer.  Contributed by Jing Zhao\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1477367 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/04/13 3:03 PM",
      "commitName": "e097f8404b3ffbad5322e0f8381a0b9958c5b589",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "22/04/13 5:11 PM",
      "commitNameOld": "10a2d82b45353ed3dbaa19d87c7e887c0afa2c57",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 6.91,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,21 @@\n     private static Quota.Counts updateQuotaAndCollectBlocks(\n         INodeFile currentINode, FileDiff removed,\n         BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n       FileWithSnapshot sFile \u003d (FileWithSnapshot) currentINode;\n       long oldDiskspace \u003d currentINode.diskspaceConsumed();\n       if (removed.snapshotINode !\u003d null) {\n         short replication \u003d removed.snapshotINode.getFileReplication();\n-        if (replication \u003e currentINode.getBlockReplication()) {\n+        short currentRepl \u003d currentINode.getBlockReplication();\n+        if (currentRepl \u003d\u003d 0) {\n+          oldDiskspace \u003d currentINode.computeFileSize(true, true) * replication;\n+        } else if (replication \u003e currentRepl) {  \n           oldDiskspace \u003d oldDiskspace / currentINode.getBlockReplication()\n               * replication;\n         }\n       }\n       \n       Util.collectBlocksAndClear(sFile, collectedBlocks, removedINodes);\n       \n       long dsDelta \u003d oldDiskspace - currentINode.diskspaceConsumed();\n       return Quota.Counts.newInstance(0, dsDelta);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private static Quota.Counts updateQuotaAndCollectBlocks(\n        INodeFile currentINode, FileDiff removed,\n        BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n      FileWithSnapshot sFile \u003d (FileWithSnapshot) currentINode;\n      long oldDiskspace \u003d currentINode.diskspaceConsumed();\n      if (removed.snapshotINode !\u003d null) {\n        short replication \u003d removed.snapshotINode.getFileReplication();\n        short currentRepl \u003d currentINode.getBlockReplication();\n        if (currentRepl \u003d\u003d 0) {\n          oldDiskspace \u003d currentINode.computeFileSize(true, true) * replication;\n        } else if (replication \u003e currentRepl) {  \n          oldDiskspace \u003d oldDiskspace / currentINode.getBlockReplication()\n              * replication;\n        }\n      }\n      \n      Util.collectBlocksAndClear(sFile, collectedBlocks, removedINodes);\n      \n      long dsDelta \u003d oldDiskspace - currentINode.diskspaceConsumed();\n      return Quota.Counts.newInstance(0, dsDelta);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshot.java",
      "extendedDetails": {}
    },
    "92e0416ced279a910616985bf11fa3f8b1b1de9b": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-4727. Update inodeMap after deleting files/directories/snapshots.  Contributed by Jing Zhao\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1470756 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/04/13 5:00 PM",
      "commitName": "92e0416ced279a910616985bf11fa3f8b1b1de9b",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-4727. Update inodeMap after deleting files/directories/snapshots.  Contributed by Jing Zhao\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1470756 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/04/13 5:00 PM",
          "commitName": "92e0416ced279a910616985bf11fa3f8b1b1de9b",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "01/04/13 4:24 PM",
          "commitNameOld": "1096917649fd951be633e5619518764f23cca645",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 21.03,
          "commitsBetweenForRepo": 126,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,18 @@\n     private static Quota.Counts updateQuotaAndCollectBlocks(\n         INodeFile currentINode, FileDiff removed,\n-        BlocksMapUpdateInfo collectedBlocks) {\n+        BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n       FileWithSnapshot sFile \u003d (FileWithSnapshot) currentINode;\n       long oldDiskspace \u003d currentINode.diskspaceConsumed();\n       if (removed.snapshotINode !\u003d null) {\n         short replication \u003d removed.snapshotINode.getFileReplication();\n         if (replication \u003e currentINode.getBlockReplication()) {\n           oldDiskspace \u003d oldDiskspace / currentINode.getBlockReplication()\n               * replication;\n         }\n       }\n       \n-      Util.collectBlocksAndClear(sFile, collectedBlocks);\n+      Util.collectBlocksAndClear(sFile, collectedBlocks, removedINodes);\n       \n       long dsDelta \u003d oldDiskspace - currentINode.diskspaceConsumed();\n       return Quota.Counts.newInstance(0, dsDelta);\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private static Quota.Counts updateQuotaAndCollectBlocks(\n        INodeFile currentINode, FileDiff removed,\n        BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n      FileWithSnapshot sFile \u003d (FileWithSnapshot) currentINode;\n      long oldDiskspace \u003d currentINode.diskspaceConsumed();\n      if (removed.snapshotINode !\u003d null) {\n        short replication \u003d removed.snapshotINode.getFileReplication();\n        if (replication \u003e currentINode.getBlockReplication()) {\n          oldDiskspace \u003d oldDiskspace / currentINode.getBlockReplication()\n              * replication;\n        }\n      }\n      \n      Util.collectBlocksAndClear(sFile, collectedBlocks, removedINodes);\n      \n      long dsDelta \u003d oldDiskspace - currentINode.diskspaceConsumed();\n      return Quota.Counts.newInstance(0, dsDelta);\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshot.java",
          "extendedDetails": {
            "oldValue": "[currentINode-INodeFile, removed-FileDiff, collectedBlocks-BlocksMapUpdateInfo]",
            "newValue": "[currentINode-INodeFile, removed-FileDiff, collectedBlocks-BlocksMapUpdateInfo, removedINodes-List\u003cINode\u003e(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-4727. Update inodeMap after deleting files/directories/snapshots.  Contributed by Jing Zhao\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1470756 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/04/13 5:00 PM",
          "commitName": "92e0416ced279a910616985bf11fa3f8b1b1de9b",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "01/04/13 4:24 PM",
          "commitNameOld": "1096917649fd951be633e5619518764f23cca645",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 21.03,
          "commitsBetweenForRepo": 126,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,18 @@\n     private static Quota.Counts updateQuotaAndCollectBlocks(\n         INodeFile currentINode, FileDiff removed,\n-        BlocksMapUpdateInfo collectedBlocks) {\n+        BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n       FileWithSnapshot sFile \u003d (FileWithSnapshot) currentINode;\n       long oldDiskspace \u003d currentINode.diskspaceConsumed();\n       if (removed.snapshotINode !\u003d null) {\n         short replication \u003d removed.snapshotINode.getFileReplication();\n         if (replication \u003e currentINode.getBlockReplication()) {\n           oldDiskspace \u003d oldDiskspace / currentINode.getBlockReplication()\n               * replication;\n         }\n       }\n       \n-      Util.collectBlocksAndClear(sFile, collectedBlocks);\n+      Util.collectBlocksAndClear(sFile, collectedBlocks, removedINodes);\n       \n       long dsDelta \u003d oldDiskspace - currentINode.diskspaceConsumed();\n       return Quota.Counts.newInstance(0, dsDelta);\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private static Quota.Counts updateQuotaAndCollectBlocks(\n        INodeFile currentINode, FileDiff removed,\n        BlocksMapUpdateInfo collectedBlocks, final List\u003cINode\u003e removedINodes) {\n      FileWithSnapshot sFile \u003d (FileWithSnapshot) currentINode;\n      long oldDiskspace \u003d currentINode.diskspaceConsumed();\n      if (removed.snapshotINode !\u003d null) {\n        short replication \u003d removed.snapshotINode.getFileReplication();\n        if (replication \u003e currentINode.getBlockReplication()) {\n          oldDiskspace \u003d oldDiskspace / currentINode.getBlockReplication()\n              * replication;\n        }\n      }\n      \n      Util.collectBlocksAndClear(sFile, collectedBlocks, removedINodes);\n      \n      long dsDelta \u003d oldDiskspace - currentINode.diskspaceConsumed();\n      return Quota.Counts.newInstance(0, dsDelta);\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshot.java",
          "extendedDetails": {}
        }
      ]
    },
    "3b3ea5c4220e674064c7603a449f63904c10bac1": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-4563. Update namespace/diskspace usage after deleting snapshots.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2802@1455396 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/03/13 7:41 PM",
      "commitName": "3b3ea5c4220e674064c7603a449f63904c10bac1",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,18 @@\n+    private static Quota.Counts updateQuotaAndCollectBlocks(\n+        INodeFile currentINode, FileDiff removed,\n+        BlocksMapUpdateInfo collectedBlocks) {\n+      FileWithSnapshot sFile \u003d (FileWithSnapshot) currentINode;\n+      long oldDiskspace \u003d currentINode.diskspaceConsumed();\n+      if (removed.snapshotINode !\u003d null) {\n+        short replication \u003d removed.snapshotINode.getFileReplication();\n+        if (replication \u003e currentINode.getBlockReplication()) {\n+          oldDiskspace \u003d oldDiskspace / currentINode.getBlockReplication()\n+              * replication;\n+        }\n+      }\n+      \n+      Util.collectBlocksAndClear(sFile, collectedBlocks);\n+      \n+      long dsDelta \u003d oldDiskspace - currentINode.diskspaceConsumed();\n+      return Quota.Counts.newInstance(0, dsDelta);\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private static Quota.Counts updateQuotaAndCollectBlocks(\n        INodeFile currentINode, FileDiff removed,\n        BlocksMapUpdateInfo collectedBlocks) {\n      FileWithSnapshot sFile \u003d (FileWithSnapshot) currentINode;\n      long oldDiskspace \u003d currentINode.diskspaceConsumed();\n      if (removed.snapshotINode !\u003d null) {\n        short replication \u003d removed.snapshotINode.getFileReplication();\n        if (replication \u003e currentINode.getBlockReplication()) {\n          oldDiskspace \u003d oldDiskspace / currentINode.getBlockReplication()\n              * replication;\n        }\n      }\n      \n      Util.collectBlocksAndClear(sFile, collectedBlocks);\n      \n      long dsDelta \u003d oldDiskspace - currentINode.diskspaceConsumed();\n      return Quota.Counts.newInstance(0, dsDelta);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/FileWithSnapshot.java"
    }
  }
}