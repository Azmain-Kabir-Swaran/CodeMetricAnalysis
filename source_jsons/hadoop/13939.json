{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockManager.java",
  "functionName": "computeDatanodeWork",
  "functionId": "computeDatanodeWork",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
  "functionStartLine": 5040,
  "functionEndLine": 5067,
  "numCommitsSeen": 514,
  "timeTaken": 19053,
  "changeHistory": [
    "a0fb2eff9b71e2e2c0e53262773b34bed82585d4",
    "57a84c0d149b693c913416975cafe6de4e23c321",
    "550853203b3a76078833f392912896f5442e1db5",
    "8c0366bf103ca638b5ef9e962671f7728db4fd10",
    "9692cfc9ae2ac86c9a2d2b3ac9ca8f8b3bfc7c42",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "7fac946ac983e31613fd62836c8ac9c4a579210a",
    "89537b7710b23db7abcd2a77f03818c06a5f5fa7",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "a0fb2eff9b71e2e2c0e53262773b34bed82585d4": "Ybodychange",
    "57a84c0d149b693c913416975cafe6de4e23c321": "Ybodychange",
    "550853203b3a76078833f392912896f5442e1db5": "Ybodychange",
    "8c0366bf103ca638b5ef9e962671f7728db4fd10": "Ymultichange(Yexceptionschange,Ybodychange)",
    "9692cfc9ae2ac86c9a2d2b3ac9ca8f8b3bfc7c42": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "7fac946ac983e31613fd62836c8ac9c4a579210a": "Ybodychange",
    "89537b7710b23db7abcd2a77f03818c06a5f5fa7": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange)",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "a0fb2eff9b71e2e2c0e53262773b34bed82585d4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9775. Erasure Coding : Rename BlockRecoveryWork to BlockReconstructionWork. Contributed by Rakesh R.\n\nChange-Id: I6dfc8efd94fa2bbb4eec0e4730a5a4f92c8a5519\n",
      "commitDate": "09/02/16 2:43 PM",
      "commitName": "a0fb2eff9b71e2e2c0e53262773b34bed82585d4",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "02/02/16 11:23 AM",
      "commitNameOld": "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 7.14,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n   int computeDatanodeWork() {\n     // Blocks should not be replicated or removed if in safe mode.\n     // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n     // case extra replications will be scheduled, and these will get\n     // fixed up later.\n     if (namesystem.isInSafeMode()) {\n       return 0;\n     }\n \n     final int numlive \u003d heartbeatManager.getLiveDatanodeCount();\n     final int blocksToProcess \u003d numlive\n         * this.blocksReplWorkMultiplier;\n     final int nodesToProcess \u003d (int) Math.ceil(numlive\n         * this.blocksInvalidateWorkPct);\n \n-    int workFound \u003d this.computeBlockRecoveryWork(blocksToProcess);\n+    int workFound \u003d this.computeBlockReconstructionWork(blocksToProcess);\n \n     // Update counters\n     namesystem.writeLock();\n     try {\n       this.updateState();\n       this.scheduledReplicationBlocksCount \u003d workFound;\n     } finally {\n       namesystem.writeUnlock();\n     }\n     workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n     return workFound;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  int computeDatanodeWork() {\n    // Blocks should not be replicated or removed if in safe mode.\n    // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n    // case extra replications will be scheduled, and these will get\n    // fixed up later.\n    if (namesystem.isInSafeMode()) {\n      return 0;\n    }\n\n    final int numlive \u003d heartbeatManager.getLiveDatanodeCount();\n    final int blocksToProcess \u003d numlive\n        * this.blocksReplWorkMultiplier;\n    final int nodesToProcess \u003d (int) Math.ceil(numlive\n        * this.blocksInvalidateWorkPct);\n\n    int workFound \u003d this.computeBlockReconstructionWork(blocksToProcess);\n\n    // Update counters\n    namesystem.writeLock();\n    try {\n      this.updateState();\n      this.scheduledReplicationBlocksCount \u003d workFound;\n    } finally {\n      namesystem.writeUnlock();\n    }\n    workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n    return workFound;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "57a84c0d149b693c913416975cafe6de4e23c321": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7369. Erasure coding: distribute recovery work for striped blocks to DataNode. Contributed by Zhe Zhang.\n",
      "commitDate": "26/05/15 11:43 AM",
      "commitName": "57a84c0d149b693c913416975cafe6de4e23c321",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "26/05/15 11:41 AM",
      "commitNameOld": "a38a37c63417a3b19dcdf98251af196c9d7b8c31",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n   int computeDatanodeWork() {\n     // Blocks should not be replicated or removed if in safe mode.\n     // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n     // case extra replications will be scheduled, and these will get\n     // fixed up later.\n     if (namesystem.isInSafeMode()) {\n       return 0;\n     }\n \n     final int numlive \u003d heartbeatManager.getLiveDatanodeCount();\n     final int blocksToProcess \u003d numlive\n         * this.blocksReplWorkMultiplier;\n     final int nodesToProcess \u003d (int) Math.ceil(numlive\n         * this.blocksInvalidateWorkPct);\n \n-    int workFound \u003d this.computeReplicationWork(blocksToProcess);\n+    int workFound \u003d this.computeBlockRecoveryWork(blocksToProcess);\n \n     // Update counters\n     namesystem.writeLock();\n     try {\n       this.updateState();\n       this.scheduledReplicationBlocksCount \u003d workFound;\n     } finally {\n       namesystem.writeUnlock();\n     }\n     workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n     return workFound;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  int computeDatanodeWork() {\n    // Blocks should not be replicated or removed if in safe mode.\n    // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n    // case extra replications will be scheduled, and these will get\n    // fixed up later.\n    if (namesystem.isInSafeMode()) {\n      return 0;\n    }\n\n    final int numlive \u003d heartbeatManager.getLiveDatanodeCount();\n    final int blocksToProcess \u003d numlive\n        * this.blocksReplWorkMultiplier;\n    final int nodesToProcess \u003d (int) Math.ceil(numlive\n        * this.blocksInvalidateWorkPct);\n\n    int workFound \u003d this.computeBlockRecoveryWork(blocksToProcess);\n\n    // Update counters\n    namesystem.writeLock();\n    try {\n      this.updateState();\n      this.scheduledReplicationBlocksCount \u003d workFound;\n    } finally {\n      namesystem.writeUnlock();\n    }\n    workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n    return workFound;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "550853203b3a76078833f392912896f5442e1db5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3475. Make the replication monitor multipliers configurable. Contributed by Harsh J Chouraria\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1355089 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/06/12 10:54 AM",
      "commitName": "550853203b3a76078833f392912896f5442e1db5",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "25/06/12 8:25 PM",
      "commitNameOld": "bbab35e6d87aeebbc1848d7072c59af780536425",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 2.6,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n   int computeDatanodeWork() {\n     // Blocks should not be replicated or removed if in safe mode.\n     // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n     // case extra replications will be scheduled, and these will get\n     // fixed up later.\n     if (namesystem.isInSafeMode()) {\n       return 0;\n     }\n \n     final int numlive \u003d heartbeatManager.getLiveDatanodeCount();\n     final int blocksToProcess \u003d numlive\n-        * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION;\n+        * this.blocksReplWorkMultiplier;\n     final int nodesToProcess \u003d (int) Math.ceil(numlive\n-        * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100.0);\n+        * this.blocksInvalidateWorkPct);\n \n     int workFound \u003d this.computeReplicationWork(blocksToProcess);\n \n     // Update counters\n     namesystem.writeLock();\n     try {\n       this.updateState();\n       this.scheduledReplicationBlocksCount \u003d workFound;\n     } finally {\n       namesystem.writeUnlock();\n     }\n     workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n     return workFound;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  int computeDatanodeWork() {\n    // Blocks should not be replicated or removed if in safe mode.\n    // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n    // case extra replications will be scheduled, and these will get\n    // fixed up later.\n    if (namesystem.isInSafeMode()) {\n      return 0;\n    }\n\n    final int numlive \u003d heartbeatManager.getLiveDatanodeCount();\n    final int blocksToProcess \u003d numlive\n        * this.blocksReplWorkMultiplier;\n    final int nodesToProcess \u003d (int) Math.ceil(numlive\n        * this.blocksInvalidateWorkPct);\n\n    int workFound \u003d this.computeReplicationWork(blocksToProcess);\n\n    // Update counters\n    namesystem.writeLock();\n    try {\n      this.updateState();\n      this.scheduledReplicationBlocksCount \u003d workFound;\n    } finally {\n      namesystem.writeUnlock();\n    }\n    workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n    return workFound;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "8c0366bf103ca638b5ef9e962671f7728db4fd10": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-3168. Remove unnecessary \"throw IOException\" and change fields to final in FSNamesystem and BlockManager. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1309218 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/04/12 7:51 PM",
      "commitName": "8c0366bf103ca638b5ef9e962671f7728db4fd10",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-3168. Remove unnecessary \"throw IOException\" and change fields to final in FSNamesystem and BlockManager. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1309218 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "03/04/12 7:51 PM",
          "commitName": "8c0366bf103ca638b5ef9e962671f7728db4fd10",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "01/04/12 3:12 PM",
          "commitNameOld": "be7dd8333a7e56e732171db0781786987de03195",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 2.19,
          "commitsBetweenForRepo": 29,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,28 @@\n-  int computeDatanodeWork() throws IOException {\n-    int workFound \u003d 0;\n+  int computeDatanodeWork() {\n     // Blocks should not be replicated or removed if in safe mode.\n     // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n     // case extra replications will be scheduled, and these will get\n     // fixed up later.\n-    if (namesystem.isInSafeMode())\n-      return workFound;\n+    if (namesystem.isInSafeMode()) {\n+      return 0;\n+    }\n \n     final int numlive \u003d heartbeatManager.getLiveDatanodeCount();\n     final int blocksToProcess \u003d numlive\n         * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION;\n     final int nodesToProcess \u003d (int) Math.ceil(numlive\n         * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100.0);\n \n-    workFound \u003d this.computeReplicationWork(blocksToProcess);\n+    int workFound \u003d this.computeReplicationWork(blocksToProcess);\n \n     // Update counters\n     namesystem.writeLock();\n     try {\n       this.updateState();\n       this.scheduledReplicationBlocksCount \u003d workFound;\n     } finally {\n       namesystem.writeUnlock();\n     }\n     workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n     return workFound;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  int computeDatanodeWork() {\n    // Blocks should not be replicated or removed if in safe mode.\n    // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n    // case extra replications will be scheduled, and these will get\n    // fixed up later.\n    if (namesystem.isInSafeMode()) {\n      return 0;\n    }\n\n    final int numlive \u003d heartbeatManager.getLiveDatanodeCount();\n    final int blocksToProcess \u003d numlive\n        * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION;\n    final int nodesToProcess \u003d (int) Math.ceil(numlive\n        * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100.0);\n\n    int workFound \u003d this.computeReplicationWork(blocksToProcess);\n\n    // Update counters\n    namesystem.writeLock();\n    try {\n      this.updateState();\n      this.scheduledReplicationBlocksCount \u003d workFound;\n    } finally {\n      namesystem.writeUnlock();\n    }\n    workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n    return workFound;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "[IOException]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3168. Remove unnecessary \"throw IOException\" and change fields to final in FSNamesystem and BlockManager. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1309218 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "03/04/12 7:51 PM",
          "commitName": "8c0366bf103ca638b5ef9e962671f7728db4fd10",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "01/04/12 3:12 PM",
          "commitNameOld": "be7dd8333a7e56e732171db0781786987de03195",
          "commitAuthorOld": "Eli Collins",
          "daysBetweenCommits": 2.19,
          "commitsBetweenForRepo": 29,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,28 @@\n-  int computeDatanodeWork() throws IOException {\n-    int workFound \u003d 0;\n+  int computeDatanodeWork() {\n     // Blocks should not be replicated or removed if in safe mode.\n     // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n     // case extra replications will be scheduled, and these will get\n     // fixed up later.\n-    if (namesystem.isInSafeMode())\n-      return workFound;\n+    if (namesystem.isInSafeMode()) {\n+      return 0;\n+    }\n \n     final int numlive \u003d heartbeatManager.getLiveDatanodeCount();\n     final int blocksToProcess \u003d numlive\n         * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION;\n     final int nodesToProcess \u003d (int) Math.ceil(numlive\n         * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100.0);\n \n-    workFound \u003d this.computeReplicationWork(blocksToProcess);\n+    int workFound \u003d this.computeReplicationWork(blocksToProcess);\n \n     // Update counters\n     namesystem.writeLock();\n     try {\n       this.updateState();\n       this.scheduledReplicationBlocksCount \u003d workFound;\n     } finally {\n       namesystem.writeUnlock();\n     }\n     workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n     return workFound;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  int computeDatanodeWork() {\n    // Blocks should not be replicated or removed if in safe mode.\n    // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n    // case extra replications will be scheduled, and these will get\n    // fixed up later.\n    if (namesystem.isInSafeMode()) {\n      return 0;\n    }\n\n    final int numlive \u003d heartbeatManager.getLiveDatanodeCount();\n    final int blocksToProcess \u003d numlive\n        * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION;\n    final int nodesToProcess \u003d (int) Math.ceil(numlive\n        * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100.0);\n\n    int workFound \u003d this.computeReplicationWork(blocksToProcess);\n\n    // Update counters\n    namesystem.writeLock();\n    try {\n      this.updateState();\n      this.scheduledReplicationBlocksCount \u003d workFound;\n    } finally {\n      namesystem.writeUnlock();\n    }\n    workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n    return workFound;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "9692cfc9ae2ac86c9a2d2b3ac9ca8f8b3bfc7c42": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2493. Remove reference to FSNamesystem in blockmanagement classes.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1190491 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/10/11 11:28 AM",
      "commitName": "9692cfc9ae2ac86c9a2d2b3ac9ca8f8b3bfc7c42",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "27/09/11 10:49 PM",
      "commitNameOld": "96f9fc91993b04166f30fdf2dc5145ac91dbf1df",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 30.53,
      "commitsBetweenForRepo": 270,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n   int computeDatanodeWork() throws IOException {\n     int workFound \u003d 0;\n     // Blocks should not be replicated or removed if in safe mode.\n     // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n     // case extra replications will be scheduled, and these will get\n     // fixed up later.\n     if (namesystem.isInSafeMode())\n       return workFound;\n \n     final int numlive \u003d heartbeatManager.getLiveDatanodeCount();\n     final int blocksToProcess \u003d numlive\n         * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION;\n     final int nodesToProcess \u003d (int) Math.ceil(numlive\n         * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100.0);\n \n     workFound \u003d this.computeReplicationWork(blocksToProcess);\n \n-    // Update FSNamesystemMetrics counters\n+    // Update counters\n     namesystem.writeLock();\n     try {\n       this.updateState();\n       this.scheduledReplicationBlocksCount \u003d workFound;\n     } finally {\n       namesystem.writeUnlock();\n     }\n     workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n     return workFound;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  int computeDatanodeWork() throws IOException {\n    int workFound \u003d 0;\n    // Blocks should not be replicated or removed if in safe mode.\n    // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n    // case extra replications will be scheduled, and these will get\n    // fixed up later.\n    if (namesystem.isInSafeMode())\n      return workFound;\n\n    final int numlive \u003d heartbeatManager.getLiveDatanodeCount();\n    final int blocksToProcess \u003d numlive\n        * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION;\n    final int nodesToProcess \u003d (int) Math.ceil(numlive\n        * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100.0);\n\n    workFound \u003d this.computeReplicationWork(blocksToProcess);\n\n    // Update counters\n    namesystem.writeLock();\n    try {\n      this.updateState();\n      this.scheduledReplicationBlocksCount \u003d workFound;\n    } finally {\n      namesystem.writeUnlock();\n    }\n    workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n    return workFound;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  int computeDatanodeWork() throws IOException {\n    int workFound \u003d 0;\n    // Blocks should not be replicated or removed if in safe mode.\n    // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n    // case extra replications will be scheduled, and these will get\n    // fixed up later.\n    if (namesystem.isInSafeMode())\n      return workFound;\n\n    final int numlive \u003d heartbeatManager.getLiveDatanodeCount();\n    final int blocksToProcess \u003d numlive\n        * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION;\n    final int nodesToProcess \u003d (int) Math.ceil(numlive\n        * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100.0);\n\n    workFound \u003d this.computeReplicationWork(blocksToProcess);\n\n    // Update FSNamesystemMetrics counters\n    namesystem.writeLock();\n    try {\n      this.updateState();\n      this.scheduledReplicationBlocksCount \u003d workFound;\n    } finally {\n      namesystem.writeUnlock();\n    }\n    workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n    return workFound;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  int computeDatanodeWork() throws IOException {\n    int workFound \u003d 0;\n    // Blocks should not be replicated or removed if in safe mode.\n    // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n    // case extra replications will be scheduled, and these will get\n    // fixed up later.\n    if (namesystem.isInSafeMode())\n      return workFound;\n\n    final int numlive \u003d heartbeatManager.getLiveDatanodeCount();\n    final int blocksToProcess \u003d numlive\n        * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION;\n    final int nodesToProcess \u003d (int) Math.ceil(numlive\n        * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100.0);\n\n    workFound \u003d this.computeReplicationWork(blocksToProcess);\n\n    // Update FSNamesystemMetrics counters\n    namesystem.writeLock();\n    try {\n      this.updateState();\n      this.scheduledReplicationBlocksCount \u003d workFound;\n    } finally {\n      namesystem.writeUnlock();\n    }\n    workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n    return workFound;\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java"
      }
    },
    "7fac946ac983e31613fd62836c8ac9c4a579210a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2108. Move datanode heartbeat handling from namenode package to blockmanagement package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154042 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/08/11 3:55 PM",
      "commitName": "7fac946ac983e31613fd62836c8ac9c4a579210a",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "01/08/11 6:57 AM",
      "commitNameOld": "d68e38b78d9687987c4de2046ce9aa0016685e98",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 3.37,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,28 @@\n   int computeDatanodeWork() throws IOException {\n     int workFound \u003d 0;\n-    int blocksToProcess \u003d 0;\n-    int nodesToProcess \u003d 0;\n     // Blocks should not be replicated or removed if in safe mode.\n     // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n     // case extra replications will be scheduled, and these will get\n     // fixed up later.\n     if (namesystem.isInSafeMode())\n       return workFound;\n \n-    synchronized (namesystem.heartbeats) {\n-      blocksToProcess \u003d (int) (namesystem.heartbeats.size() * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION);\n-      nodesToProcess \u003d (int) Math.ceil((double) namesystem.heartbeats.size()\n-          * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100);\n-    }\n+    final int numlive \u003d heartbeatManager.getLiveDatanodeCount();\n+    final int blocksToProcess \u003d numlive\n+        * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION;\n+    final int nodesToProcess \u003d (int) Math.ceil(numlive\n+        * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100.0);\n \n     workFound \u003d this.computeReplicationWork(blocksToProcess);\n \n     // Update FSNamesystemMetrics counters\n     namesystem.writeLock();\n     try {\n       this.updateState();\n       this.scheduledReplicationBlocksCount \u003d workFound;\n     } finally {\n       namesystem.writeUnlock();\n     }\n     workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n     return workFound;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  int computeDatanodeWork() throws IOException {\n    int workFound \u003d 0;\n    // Blocks should not be replicated or removed if in safe mode.\n    // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n    // case extra replications will be scheduled, and these will get\n    // fixed up later.\n    if (namesystem.isInSafeMode())\n      return workFound;\n\n    final int numlive \u003d heartbeatManager.getLiveDatanodeCount();\n    final int blocksToProcess \u003d numlive\n        * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION;\n    final int nodesToProcess \u003d (int) Math.ceil(numlive\n        * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100.0);\n\n    workFound \u003d this.computeReplicationWork(blocksToProcess);\n\n    // Update FSNamesystemMetrics counters\n    namesystem.writeLock();\n    try {\n      this.updateState();\n      this.scheduledReplicationBlocksCount \u003d workFound;\n    } finally {\n      namesystem.writeUnlock();\n    }\n    workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n    return workFound;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
      "extendedDetails": {}
    },
    "89537b7710b23db7abcd2a77f03818c06a5f5fa7": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-2112.  Move ReplicationMonitor to block management.  Contributed by Uma Maheswara Rao G\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149771 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/07/11 6:01 PM",
      "commitName": "89537b7710b23db7abcd2a77f03818c06a5f5fa7",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-2112.  Move ReplicationMonitor to block management.  Contributed by Uma Maheswara Rao G\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149771 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/07/11 6:01 PM",
          "commitName": "89537b7710b23db7abcd2a77f03818c06a5f5fa7",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "22/07/11 5:22 PM",
          "commitNameOld": "ad3f694261abdc6ea2bc38e7a3f573f04338ac9d",
          "commitAuthorOld": "Konstantin Shvachko",
          "daysBetweenCommits": 0.03,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,31 +1,30 @@\n-  public int computeDatanodeWork() throws IOException {\n+  int computeDatanodeWork() throws IOException {\n     int workFound \u003d 0;\n     int blocksToProcess \u003d 0;\n     int nodesToProcess \u003d 0;\n     // Blocks should not be replicated or removed if in safe mode.\n     // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n     // case extra replications will be scheduled, and these will get\n     // fixed up later.\n-    if (isInSafeMode())\n+    if (namesystem.isInSafeMode())\n       return workFound;\n \n-    synchronized (heartbeats) {\n-      blocksToProcess \u003d (int)(heartbeats.size() \n-          * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION);\n-      nodesToProcess \u003d (int)Math.ceil((double)heartbeats.size() \n+    synchronized (namesystem.heartbeats) {\n+      blocksToProcess \u003d (int) (namesystem.heartbeats.size() * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION);\n+      nodesToProcess \u003d (int) Math.ceil((double) namesystem.heartbeats.size()\n           * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100);\n     }\n \n-    workFound \u003d blockManager.computeReplicationWork(blocksToProcess);\n-    \n+    workFound \u003d this.computeReplicationWork(blocksToProcess);\n+\n     // Update FSNamesystemMetrics counters\n-    writeLock();\n+    namesystem.writeLock();\n     try {\n-      blockManager.updateState();\n-      blockManager.scheduledReplicationBlocksCount \u003d workFound;\n+      this.updateState();\n+      this.scheduledReplicationBlocksCount \u003d workFound;\n     } finally {\n-      writeUnlock();\n+      namesystem.writeUnlock();\n     }\n-    workFound +\u003d blockManager.computeInvalidateWork(nodesToProcess);\n+    workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n     return workFound;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  int computeDatanodeWork() throws IOException {\n    int workFound \u003d 0;\n    int blocksToProcess \u003d 0;\n    int nodesToProcess \u003d 0;\n    // Blocks should not be replicated or removed if in safe mode.\n    // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n    // case extra replications will be scheduled, and these will get\n    // fixed up later.\n    if (namesystem.isInSafeMode())\n      return workFound;\n\n    synchronized (namesystem.heartbeats) {\n      blocksToProcess \u003d (int) (namesystem.heartbeats.size() * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION);\n      nodesToProcess \u003d (int) Math.ceil((double) namesystem.heartbeats.size()\n          * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100);\n    }\n\n    workFound \u003d this.computeReplicationWork(blocksToProcess);\n\n    // Update FSNamesystemMetrics counters\n    namesystem.writeLock();\n    try {\n      this.updateState();\n      this.scheduledReplicationBlocksCount \u003d workFound;\n    } finally {\n      namesystem.writeUnlock();\n    }\n    workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n    return workFound;\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
            "newPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
            "oldMethodName": "computeDatanodeWork",
            "newMethodName": "computeDatanodeWork"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-2112.  Move ReplicationMonitor to block management.  Contributed by Uma Maheswara Rao G\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149771 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/07/11 6:01 PM",
          "commitName": "89537b7710b23db7abcd2a77f03818c06a5f5fa7",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "22/07/11 5:22 PM",
          "commitNameOld": "ad3f694261abdc6ea2bc38e7a3f573f04338ac9d",
          "commitAuthorOld": "Konstantin Shvachko",
          "daysBetweenCommits": 0.03,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,31 +1,30 @@\n-  public int computeDatanodeWork() throws IOException {\n+  int computeDatanodeWork() throws IOException {\n     int workFound \u003d 0;\n     int blocksToProcess \u003d 0;\n     int nodesToProcess \u003d 0;\n     // Blocks should not be replicated or removed if in safe mode.\n     // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n     // case extra replications will be scheduled, and these will get\n     // fixed up later.\n-    if (isInSafeMode())\n+    if (namesystem.isInSafeMode())\n       return workFound;\n \n-    synchronized (heartbeats) {\n-      blocksToProcess \u003d (int)(heartbeats.size() \n-          * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION);\n-      nodesToProcess \u003d (int)Math.ceil((double)heartbeats.size() \n+    synchronized (namesystem.heartbeats) {\n+      blocksToProcess \u003d (int) (namesystem.heartbeats.size() * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION);\n+      nodesToProcess \u003d (int) Math.ceil((double) namesystem.heartbeats.size()\n           * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100);\n     }\n \n-    workFound \u003d blockManager.computeReplicationWork(blocksToProcess);\n-    \n+    workFound \u003d this.computeReplicationWork(blocksToProcess);\n+\n     // Update FSNamesystemMetrics counters\n-    writeLock();\n+    namesystem.writeLock();\n     try {\n-      blockManager.updateState();\n-      blockManager.scheduledReplicationBlocksCount \u003d workFound;\n+      this.updateState();\n+      this.scheduledReplicationBlocksCount \u003d workFound;\n     } finally {\n-      writeUnlock();\n+      namesystem.writeUnlock();\n     }\n-    workFound +\u003d blockManager.computeInvalidateWork(nodesToProcess);\n+    workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n     return workFound;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  int computeDatanodeWork() throws IOException {\n    int workFound \u003d 0;\n    int blocksToProcess \u003d 0;\n    int nodesToProcess \u003d 0;\n    // Blocks should not be replicated or removed if in safe mode.\n    // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n    // case extra replications will be scheduled, and these will get\n    // fixed up later.\n    if (namesystem.isInSafeMode())\n      return workFound;\n\n    synchronized (namesystem.heartbeats) {\n      blocksToProcess \u003d (int) (namesystem.heartbeats.size() * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION);\n      nodesToProcess \u003d (int) Math.ceil((double) namesystem.heartbeats.size()\n          * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100);\n    }\n\n    workFound \u003d this.computeReplicationWork(blocksToProcess);\n\n    // Update FSNamesystemMetrics counters\n    namesystem.writeLock();\n    try {\n      this.updateState();\n      this.scheduledReplicationBlocksCount \u003d workFound;\n    } finally {\n      namesystem.writeUnlock();\n    }\n    workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n    return workFound;\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2112.  Move ReplicationMonitor to block management.  Contributed by Uma Maheswara Rao G\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149771 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "22/07/11 6:01 PM",
          "commitName": "89537b7710b23db7abcd2a77f03818c06a5f5fa7",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "22/07/11 5:22 PM",
          "commitNameOld": "ad3f694261abdc6ea2bc38e7a3f573f04338ac9d",
          "commitAuthorOld": "Konstantin Shvachko",
          "daysBetweenCommits": 0.03,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,31 +1,30 @@\n-  public int computeDatanodeWork() throws IOException {\n+  int computeDatanodeWork() throws IOException {\n     int workFound \u003d 0;\n     int blocksToProcess \u003d 0;\n     int nodesToProcess \u003d 0;\n     // Blocks should not be replicated or removed if in safe mode.\n     // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n     // case extra replications will be scheduled, and these will get\n     // fixed up later.\n-    if (isInSafeMode())\n+    if (namesystem.isInSafeMode())\n       return workFound;\n \n-    synchronized (heartbeats) {\n-      blocksToProcess \u003d (int)(heartbeats.size() \n-          * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION);\n-      nodesToProcess \u003d (int)Math.ceil((double)heartbeats.size() \n+    synchronized (namesystem.heartbeats) {\n+      blocksToProcess \u003d (int) (namesystem.heartbeats.size() * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION);\n+      nodesToProcess \u003d (int) Math.ceil((double) namesystem.heartbeats.size()\n           * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100);\n     }\n \n-    workFound \u003d blockManager.computeReplicationWork(blocksToProcess);\n-    \n+    workFound \u003d this.computeReplicationWork(blocksToProcess);\n+\n     // Update FSNamesystemMetrics counters\n-    writeLock();\n+    namesystem.writeLock();\n     try {\n-      blockManager.updateState();\n-      blockManager.scheduledReplicationBlocksCount \u003d workFound;\n+      this.updateState();\n+      this.scheduledReplicationBlocksCount \u003d workFound;\n     } finally {\n-      writeUnlock();\n+      namesystem.writeUnlock();\n     }\n-    workFound +\u003d blockManager.computeInvalidateWork(nodesToProcess);\n+    workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n     return workFound;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  int computeDatanodeWork() throws IOException {\n    int workFound \u003d 0;\n    int blocksToProcess \u003d 0;\n    int nodesToProcess \u003d 0;\n    // Blocks should not be replicated or removed if in safe mode.\n    // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n    // case extra replications will be scheduled, and these will get\n    // fixed up later.\n    if (namesystem.isInSafeMode())\n      return workFound;\n\n    synchronized (namesystem.heartbeats) {\n      blocksToProcess \u003d (int) (namesystem.heartbeats.size() * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION);\n      nodesToProcess \u003d (int) Math.ceil((double) namesystem.heartbeats.size()\n          * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100);\n    }\n\n    workFound \u003d this.computeReplicationWork(blocksToProcess);\n\n    // Update FSNamesystemMetrics counters\n    namesystem.writeLock();\n    try {\n      this.updateState();\n      this.scheduledReplicationBlocksCount \u003d workFound;\n    } finally {\n      namesystem.writeUnlock();\n    }\n    workFound +\u003d this.computeInvalidateWork(nodesToProcess);\n    return workFound;\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,31 @@\n+  public int computeDatanodeWork() throws IOException {\n+    int workFound \u003d 0;\n+    int blocksToProcess \u003d 0;\n+    int nodesToProcess \u003d 0;\n+    // Blocks should not be replicated or removed if in safe mode.\n+    // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n+    // case extra replications will be scheduled, and these will get\n+    // fixed up later.\n+    if (isInSafeMode())\n+      return workFound;\n+\n+    synchronized (heartbeats) {\n+      blocksToProcess \u003d (int)(heartbeats.size() \n+          * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION);\n+      nodesToProcess \u003d (int)Math.ceil((double)heartbeats.size() \n+          * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100);\n+    }\n+\n+    workFound \u003d blockManager.computeReplicationWork(blocksToProcess);\n+    \n+    // Update FSNamesystemMetrics counters\n+    writeLock();\n+    try {\n+      blockManager.updateState();\n+      blockManager.scheduledReplicationBlocksCount \u003d workFound;\n+    } finally {\n+      writeUnlock();\n+    }\n+    workFound +\u003d blockManager.computeInvalidateWork(nodesToProcess);\n+    return workFound;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public int computeDatanodeWork() throws IOException {\n    int workFound \u003d 0;\n    int blocksToProcess \u003d 0;\n    int nodesToProcess \u003d 0;\n    // Blocks should not be replicated or removed if in safe mode.\n    // It\u0027s OK to check safe mode here w/o holding lock, in the worst\n    // case extra replications will be scheduled, and these will get\n    // fixed up later.\n    if (isInSafeMode())\n      return workFound;\n\n    synchronized (heartbeats) {\n      blocksToProcess \u003d (int)(heartbeats.size() \n          * ReplicationMonitor.REPLICATION_WORK_MULTIPLIER_PER_ITERATION);\n      nodesToProcess \u003d (int)Math.ceil((double)heartbeats.size() \n          * ReplicationMonitor.INVALIDATE_WORK_PCT_PER_ITERATION / 100);\n    }\n\n    workFound \u003d blockManager.computeReplicationWork(blocksToProcess);\n    \n    // Update FSNamesystemMetrics counters\n    writeLock();\n    try {\n      blockManager.updateState();\n      blockManager.scheduledReplicationBlocksCount \u003d workFound;\n    } finally {\n      writeUnlock();\n    }\n    workFound +\u003d blockManager.computeInvalidateWork(nodesToProcess);\n    return workFound;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}