{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "WebHdfsFileSystem.java",
  "functionName": "getXAttrs",
  "functionId": "getXAttrs___p-Path__names-List__String__(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
  "functionStartLine": 1220,
  "functionEndLine": 1237,
  "numCommitsSeen": 179,
  "timeTaken": 4709,
  "changeHistory": [
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
    "ab04ff9efe632b4eca6faca7407ac35e00e6a379",
    "6a4f6d6b3e41e660c214b77c9ed43d4c65200b6a",
    "ac23a55547716df29b3e25c98a113399e184d9d1"
  ],
  "changeHistoryShort": {
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": "Yfilerename",
    "ab04ff9efe632b4eca6faca7407ac35e00e6a379": "Ybodychange",
    "6a4f6d6b3e41e660c214b77c9ed43d4c65200b6a": "Ybodychange",
    "ac23a55547716df29b3e25c98a113399e184d9d1": "Yintroduced"
  },
  "changeHistoryDetails": {
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8052. Move WebHdfsFileSystem into hadoop-hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "23/04/15 5:33 PM",
      "commitName": "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "23/04/15 4:40 PM",
      "commitNameOld": "0b3f8957a87ada1a275c9904b211fdbdcefafb02",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n-  public Map\u003cString, byte[]\u003e getXAttrs(Path p, final List\u003cString\u003e names) \n+  public Map\u003cString, byte[]\u003e getXAttrs(Path p, final List\u003cString\u003e names)\n       throws IOException {\n-    Preconditions.checkArgument(names !\u003d null \u0026\u0026 !names.isEmpty(), \n+    Preconditions.checkArgument(names !\u003d null \u0026\u0026 !names.isEmpty(),\n         \"XAttr names cannot be null or empty.\");\n     Param\u003c?,?\u003e[] parameters \u003d new Param\u003c?,?\u003e[names.size() + 1];\n     for (int i \u003d 0; i \u003c parameters.length - 1; i++) {\n       parameters[i] \u003d new XAttrNameParam(names.get(i));\n     }\n     parameters[parameters.length - 1] \u003d new XAttrEncodingParam(XAttrCodec.HEX);\n-    \n+\n     final HttpOpParam.Op op \u003d GetOpParam.Op.GETXATTRS;\n     return new FsPathResponseRunner\u003cMap\u003cString, byte[]\u003e\u003e(op, parameters, p) {\n       @Override\n       Map\u003cString, byte[]\u003e decodeResponse(Map\u003c?, ?\u003e json) throws IOException {\n         return JsonUtilClient.toXAttrs(json);\n       }\n     }.run();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Map\u003cString, byte[]\u003e getXAttrs(Path p, final List\u003cString\u003e names)\n      throws IOException {\n    Preconditions.checkArgument(names !\u003d null \u0026\u0026 !names.isEmpty(),\n        \"XAttr names cannot be null or empty.\");\n    Param\u003c?,?\u003e[] parameters \u003d new Param\u003c?,?\u003e[names.size() + 1];\n    for (int i \u003d 0; i \u003c parameters.length - 1; i++) {\n      parameters[i] \u003d new XAttrNameParam(names.get(i));\n    }\n    parameters[parameters.length - 1] \u003d new XAttrEncodingParam(XAttrCodec.HEX);\n\n    final HttpOpParam.Op op \u003d GetOpParam.Op.GETXATTRS;\n    return new FsPathResponseRunner\u003cMap\u003cString, byte[]\u003e\u003e(op, parameters, p) {\n      @Override\n      Map\u003cString, byte[]\u003e decodeResponse(Map\u003c?, ?\u003e json) throws IOException {\n        return JsonUtilClient.toXAttrs(json);\n      }\n    }.run();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java"
      }
    },
    "ab04ff9efe632b4eca6faca7407ac35e00e6a379": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8080. Separate JSON related routines used by WebHdfsFileSystem to a package local class. Contributed by Haohui Mai.\n",
      "commitDate": "07/04/15 9:30 PM",
      "commitName": "ab04ff9efe632b4eca6faca7407ac35e00e6a379",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "01/04/15 12:54 PM",
      "commitNameOld": "ed72daa5df97669906234e8ac9a406d78136b206",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 6.36,
      "commitsBetweenForRepo": 48,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,18 +1,18 @@\n   public Map\u003cString, byte[]\u003e getXAttrs(Path p, final List\u003cString\u003e names) \n       throws IOException {\n     Preconditions.checkArgument(names !\u003d null \u0026\u0026 !names.isEmpty(), \n         \"XAttr names cannot be null or empty.\");\n     Param\u003c?,?\u003e[] parameters \u003d new Param\u003c?,?\u003e[names.size() + 1];\n     for (int i \u003d 0; i \u003c parameters.length - 1; i++) {\n       parameters[i] \u003d new XAttrNameParam(names.get(i));\n     }\n     parameters[parameters.length - 1] \u003d new XAttrEncodingParam(XAttrCodec.HEX);\n     \n     final HttpOpParam.Op op \u003d GetOpParam.Op.GETXATTRS;\n     return new FsPathResponseRunner\u003cMap\u003cString, byte[]\u003e\u003e(op, parameters, p) {\n       @Override\n       Map\u003cString, byte[]\u003e decodeResponse(Map\u003c?, ?\u003e json) throws IOException {\n-        return JsonUtil.toXAttrs(json);\n+        return JsonUtilClient.toXAttrs(json);\n       }\n     }.run();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Map\u003cString, byte[]\u003e getXAttrs(Path p, final List\u003cString\u003e names) \n      throws IOException {\n    Preconditions.checkArgument(names !\u003d null \u0026\u0026 !names.isEmpty(), \n        \"XAttr names cannot be null or empty.\");\n    Param\u003c?,?\u003e[] parameters \u003d new Param\u003c?,?\u003e[names.size() + 1];\n    for (int i \u003d 0; i \u003c parameters.length - 1; i++) {\n      parameters[i] \u003d new XAttrNameParam(names.get(i));\n    }\n    parameters[parameters.length - 1] \u003d new XAttrEncodingParam(XAttrCodec.HEX);\n    \n    final HttpOpParam.Op op \u003d GetOpParam.Op.GETXATTRS;\n    return new FsPathResponseRunner\u003cMap\u003cString, byte[]\u003e\u003e(op, parameters, p) {\n      @Override\n      Map\u003cString, byte[]\u003e decodeResponse(Map\u003c?, ?\u003e json) throws IOException {\n        return JsonUtilClient.toXAttrs(json);\n      }\n    }.run();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "6a4f6d6b3e41e660c214b77c9ed43d4c65200b6a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6464. Support multiple xattr.name parameters for WebHDFS getXAttrs. Contributed by Yi Liu.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1600810 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/06/14 8:48 PM",
      "commitName": "6a4f6d6b3e41e660c214b77c9ed43d4c65200b6a",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "30/05/14 5:12 PM",
      "commitNameOld": "880a0c673c74a128a01c72b60695f05327f5e961",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 6.15,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,18 @@\n   public Map\u003cString, byte[]\u003e getXAttrs(Path p, final List\u003cString\u003e names) \n       throws IOException {\n+    Preconditions.checkArgument(names !\u003d null \u0026\u0026 !names.isEmpty(), \n+        \"XAttr names cannot be null or empty.\");\n+    Param\u003c?,?\u003e[] parameters \u003d new Param\u003c?,?\u003e[names.size() + 1];\n+    for (int i \u003d 0; i \u003c parameters.length - 1; i++) {\n+      parameters[i] \u003d new XAttrNameParam(names.get(i));\n+    }\n+    parameters[parameters.length - 1] \u003d new XAttrEncodingParam(XAttrCodec.HEX);\n+    \n     final HttpOpParam.Op op \u003d GetOpParam.Op.GETXATTRS;\n-    return new FsPathResponseRunner\u003cMap\u003cString, byte[]\u003e\u003e(op, p, \n-        new XAttrEncodingParam(XAttrCodec.HEX)) {\n+    return new FsPathResponseRunner\u003cMap\u003cString, byte[]\u003e\u003e(op, parameters, p) {\n       @Override\n       Map\u003cString, byte[]\u003e decodeResponse(Map\u003c?, ?\u003e json) throws IOException {\n-        return JsonUtil.toXAttrs(json, names);\n+        return JsonUtil.toXAttrs(json);\n       }\n     }.run();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public Map\u003cString, byte[]\u003e getXAttrs(Path p, final List\u003cString\u003e names) \n      throws IOException {\n    Preconditions.checkArgument(names !\u003d null \u0026\u0026 !names.isEmpty(), \n        \"XAttr names cannot be null or empty.\");\n    Param\u003c?,?\u003e[] parameters \u003d new Param\u003c?,?\u003e[names.size() + 1];\n    for (int i \u003d 0; i \u003c parameters.length - 1; i++) {\n      parameters[i] \u003d new XAttrNameParam(names.get(i));\n    }\n    parameters[parameters.length - 1] \u003d new XAttrEncodingParam(XAttrCodec.HEX);\n    \n    final HttpOpParam.Op op \u003d GetOpParam.Op.GETXATTRS;\n    return new FsPathResponseRunner\u003cMap\u003cString, byte[]\u003e\u003e(op, parameters, p) {\n      @Override\n      Map\u003cString, byte[]\u003e decodeResponse(Map\u003c?, ?\u003e json) throws IOException {\n        return JsonUtil.toXAttrs(json);\n      }\n    }.run();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java",
      "extendedDetails": {}
    },
    "ac23a55547716df29b3e25c98a113399e184d9d1": {
      "type": "Yintroduced",
      "commitMessage": "Merge HDFS-2006 HDFS XAttrs branch to Trunk\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1596575 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/05/14 6:57 AM",
      "commitName": "ac23a55547716df29b3e25c98a113399e184d9d1",
      "commitAuthor": "Uma Maheswara Rao G",
      "diff": "@@ -0,0 +1,11 @@\n+  public Map\u003cString, byte[]\u003e getXAttrs(Path p, final List\u003cString\u003e names) \n+      throws IOException {\n+    final HttpOpParam.Op op \u003d GetOpParam.Op.GETXATTRS;\n+    return new FsPathResponseRunner\u003cMap\u003cString, byte[]\u003e\u003e(op, p, \n+        new XAttrEncodingParam(XAttrCodec.HEX)) {\n+      @Override\n+      Map\u003cString, byte[]\u003e decodeResponse(Map\u003c?, ?\u003e json) throws IOException {\n+        return JsonUtil.toXAttrs(json, names);\n+      }\n+    }.run();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public Map\u003cString, byte[]\u003e getXAttrs(Path p, final List\u003cString\u003e names) \n      throws IOException {\n    final HttpOpParam.Op op \u003d GetOpParam.Op.GETXATTRS;\n    return new FsPathResponseRunner\u003cMap\u003cString, byte[]\u003e\u003e(op, p, \n        new XAttrEncodingParam(XAttrCodec.HEX)) {\n      @Override\n      Map\u003cString, byte[]\u003e decodeResponse(Map\u003c?, ?\u003e json) throws IOException {\n        return JsonUtil.toXAttrs(json, names);\n      }\n    }.run();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.java"
    }
  }
}