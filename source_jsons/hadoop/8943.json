{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSNamesystem.java",
  "functionName": "logAuditEvent",
  "functionId": "logAuditEvent___succeeded-boolean__ugi-UserGroupInformation__addr-InetAddress__cmd-String__src-String__dst-String__status-FileStatus",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
  "functionStartLine": 425,
  "functionEndLine": 438,
  "numCommitsSeen": 1605,
  "timeTaken": 48815,
  "changeHistory": [
    "9b90e52f1ec22c18cd535af2a569defcef65b093",
    "796a676d18bd7cd3ed4113d002e0e69cf261d6d1",
    "600ad7bf4104bcaeec00a4089d59bb1fdf423299",
    "bb84f1fccb18c6c7373851e05d2451d55e908242",
    "a7bcc9535860214380e235641d1d5d2dd15aee58",
    "e4374d803663c626de610cd5f062f25a6d7d5d4e",
    "df2fb006b28bf1907fe3c54255e5f6bbb7698285",
    "d866f81edbd70121a9e29e5d25be67e1c464397e",
    "a85a0293c77f7cf0471d242458f04ec61e0129bc",
    "0270889b4e7f241620b2c3c297ec6530d96a7db5"
  ],
  "changeHistoryShort": {
    "9b90e52f1ec22c18cd535af2a569defcef65b093": "Ymultichange(Yparameterchange,Ybodychange)",
    "796a676d18bd7cd3ed4113d002e0e69cf261d6d1": "Ybodychange",
    "600ad7bf4104bcaeec00a4089d59bb1fdf423299": "Ybodychange",
    "bb84f1fccb18c6c7373851e05d2451d55e908242": "Ybodychange",
    "a7bcc9535860214380e235641d1d5d2dd15aee58": "Ybodychange",
    "e4374d803663c626de610cd5f062f25a6d7d5d4e": "Ybodychange",
    "df2fb006b28bf1907fe3c54255e5f6bbb7698285": "Ymultichange(Ymodifierchange,Ybodychange)",
    "d866f81edbd70121a9e29e5d25be67e1c464397e": "Ymultichange(Ymodifierchange,Ybodychange)",
    "a85a0293c77f7cf0471d242458f04ec61e0129bc": "Ymultichange(Ymodifierchange,Ybodychange)",
    "0270889b4e7f241620b2c3c297ec6530d96a7db5": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9b90e52f1ec22c18cd535af2a569defcef65b093": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-11641. Reduce cost of audit logging by using FileStatus instead of HdfsFileStatus. Contributed by Daryn Sharp.\n",
      "commitDate": "16/05/17 9:28 AM",
      "commitName": "9b90e52f1ec22c18cd535af2a569defcef65b093",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-11641. Reduce cost of audit logging by using FileStatus instead of HdfsFileStatus. Contributed by Daryn Sharp.\n",
          "commitDate": "16/05/17 9:28 AM",
          "commitName": "9b90e52f1ec22c18cd535af2a569defcef65b093",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "04/05/17 11:39 AM",
          "commitNameOld": "c2a52ef9c29459ff9ef3e23b29e14912bfdb1405",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 11.91,
          "commitsBetweenForRepo": 58,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,14 @@\n   private void logAuditEvent(boolean succeeded,\n       UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n-      String dst, HdfsFileStatus stat) {\n-    FileStatus status \u003d null;\n-    if (stat !\u003d null) {\n-      Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n-      Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n-      status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n-          stat.getReplication(), stat.getBlockSize(),\n-          stat.getModificationTime(),\n-          stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n-          stat.getGroup(), symlink, path);\n-    }\n+      String dst, FileStatus status) {\n     final String ugiStr \u003d ugi.toString();\n     for (AuditLogger logger : auditLoggers) {\n       if (logger instanceof HdfsAuditLogger) {\n         HdfsAuditLogger hdfsLogger \u003d (HdfsAuditLogger) logger;\n         hdfsLogger.logAuditEvent(succeeded, ugiStr, addr, cmd, src, dst,\n             status, CallerContext.getCurrent(), ugi, dtSecretManager);\n       } else {\n         logger.logAuditEvent(succeeded, ugiStr, addr, cmd, src, dst, status);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void logAuditEvent(boolean succeeded,\n      UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n      String dst, FileStatus status) {\n    final String ugiStr \u003d ugi.toString();\n    for (AuditLogger logger : auditLoggers) {\n      if (logger instanceof HdfsAuditLogger) {\n        HdfsAuditLogger hdfsLogger \u003d (HdfsAuditLogger) logger;\n        hdfsLogger.logAuditEvent(succeeded, ugiStr, addr, cmd, src, dst,\n            status, CallerContext.getCurrent(), ugi, dtSecretManager);\n      } else {\n        logger.logAuditEvent(succeeded, ugiStr, addr, cmd, src, dst, status);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[succeeded-boolean, ugi-UserGroupInformation, addr-InetAddress, cmd-String, src-String, dst-String, stat-HdfsFileStatus]",
            "newValue": "[succeeded-boolean, ugi-UserGroupInformation, addr-InetAddress, cmd-String, src-String, dst-String, status-FileStatus]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-11641. Reduce cost of audit logging by using FileStatus instead of HdfsFileStatus. Contributed by Daryn Sharp.\n",
          "commitDate": "16/05/17 9:28 AM",
          "commitName": "9b90e52f1ec22c18cd535af2a569defcef65b093",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "04/05/17 11:39 AM",
          "commitNameOld": "c2a52ef9c29459ff9ef3e23b29e14912bfdb1405",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 11.91,
          "commitsBetweenForRepo": 58,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,14 @@\n   private void logAuditEvent(boolean succeeded,\n       UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n-      String dst, HdfsFileStatus stat) {\n-    FileStatus status \u003d null;\n-    if (stat !\u003d null) {\n-      Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n-      Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n-      status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n-          stat.getReplication(), stat.getBlockSize(),\n-          stat.getModificationTime(),\n-          stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n-          stat.getGroup(), symlink, path);\n-    }\n+      String dst, FileStatus status) {\n     final String ugiStr \u003d ugi.toString();\n     for (AuditLogger logger : auditLoggers) {\n       if (logger instanceof HdfsAuditLogger) {\n         HdfsAuditLogger hdfsLogger \u003d (HdfsAuditLogger) logger;\n         hdfsLogger.logAuditEvent(succeeded, ugiStr, addr, cmd, src, dst,\n             status, CallerContext.getCurrent(), ugi, dtSecretManager);\n       } else {\n         logger.logAuditEvent(succeeded, ugiStr, addr, cmd, src, dst, status);\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void logAuditEvent(boolean succeeded,\n      UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n      String dst, FileStatus status) {\n    final String ugiStr \u003d ugi.toString();\n    for (AuditLogger logger : auditLoggers) {\n      if (logger instanceof HdfsAuditLogger) {\n        HdfsAuditLogger hdfsLogger \u003d (HdfsAuditLogger) logger;\n        hdfsLogger.logAuditEvent(succeeded, ugiStr, addr, cmd, src, dst,\n            status, CallerContext.getCurrent(), ugi, dtSecretManager);\n      } else {\n        logger.logAuditEvent(succeeded, ugiStr, addr, cmd, src, dst, status);\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "796a676d18bd7cd3ed4113d002e0e69cf261d6d1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9528. Cleanup namenode audit/log/exception messages. (szetszwo via umamahesh)\n",
      "commitDate": "11/12/15 5:57 PM",
      "commitName": "796a676d18bd7cd3ed4113d002e0e69cf261d6d1",
      "commitAuthor": "Uma Mahesh",
      "commitDateOld": "09/12/15 5:55 PM",
      "commitNameOld": "132478e805ba0f955345217b8ad87c2d17cccb2d",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 2.0,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   private void logAuditEvent(boolean succeeded,\n       UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n       String dst, HdfsFileStatus stat) {\n     FileStatus status \u003d null;\n     if (stat !\u003d null) {\n       Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n       Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n       status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n           stat.getReplication(), stat.getBlockSize(),\n           stat.getModificationTime(),\n           stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n           stat.getGroup(), symlink, path);\n     }\n+    final String ugiStr \u003d ugi.toString();\n     for (AuditLogger logger : auditLoggers) {\n       if (logger instanceof HdfsAuditLogger) {\n         HdfsAuditLogger hdfsLogger \u003d (HdfsAuditLogger) logger;\n-        hdfsLogger.logAuditEvent(succeeded, ugi.toString(), addr, cmd, src, dst,\n+        hdfsLogger.logAuditEvent(succeeded, ugiStr, addr, cmd, src, dst,\n             status, CallerContext.getCurrent(), ugi, dtSecretManager);\n       } else {\n-        logger.logAuditEvent(succeeded, ugi.toString(), addr,\n-            cmd, src, dst, status);\n+        logger.logAuditEvent(succeeded, ugiStr, addr, cmd, src, dst, status);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void logAuditEvent(boolean succeeded,\n      UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n      String dst, HdfsFileStatus stat) {\n    FileStatus status \u003d null;\n    if (stat !\u003d null) {\n      Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n      Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n      status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n          stat.getReplication(), stat.getBlockSize(),\n          stat.getModificationTime(),\n          stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n          stat.getGroup(), symlink, path);\n    }\n    final String ugiStr \u003d ugi.toString();\n    for (AuditLogger logger : auditLoggers) {\n      if (logger instanceof HdfsAuditLogger) {\n        HdfsAuditLogger hdfsLogger \u003d (HdfsAuditLogger) logger;\n        hdfsLogger.logAuditEvent(succeeded, ugiStr, addr, cmd, src, dst,\n            status, CallerContext.getCurrent(), ugi, dtSecretManager);\n      } else {\n        logger.logAuditEvent(succeeded, ugiStr, addr, cmd, src, dst, status);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "600ad7bf4104bcaeec00a4089d59bb1fdf423299": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9184. Logging HDFS operation\u0027s caller context into audit logs. Contributed by Mingliang Liu.\n",
      "commitDate": "23/10/15 12:15 PM",
      "commitName": "600ad7bf4104bcaeec00a4089d59bb1fdf423299",
      "commitAuthor": "Jitendra Pandey",
      "commitDateOld": "21/10/15 4:58 PM",
      "commitNameOld": "3dadf369d550c2ae393b751cb5a184dbfe2814df",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 1.8,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   private void logAuditEvent(boolean succeeded,\n       UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n       String dst, HdfsFileStatus stat) {\n     FileStatus status \u003d null;\n     if (stat !\u003d null) {\n       Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n       Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n       status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n           stat.getReplication(), stat.getBlockSize(),\n           stat.getModificationTime(),\n           stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n           stat.getGroup(), symlink, path);\n     }\n     for (AuditLogger logger : auditLoggers) {\n       if (logger instanceof HdfsAuditLogger) {\n         HdfsAuditLogger hdfsLogger \u003d (HdfsAuditLogger) logger;\n         hdfsLogger.logAuditEvent(succeeded, ugi.toString(), addr, cmd, src, dst,\n-            status, ugi, dtSecretManager);\n+            status, CallerContext.getCurrent(), ugi, dtSecretManager);\n       } else {\n         logger.logAuditEvent(succeeded, ugi.toString(), addr,\n             cmd, src, dst, status);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void logAuditEvent(boolean succeeded,\n      UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n      String dst, HdfsFileStatus stat) {\n    FileStatus status \u003d null;\n    if (stat !\u003d null) {\n      Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n      Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n      status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n          stat.getReplication(), stat.getBlockSize(),\n          stat.getModificationTime(),\n          stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n          stat.getGroup(), symlink, path);\n    }\n    for (AuditLogger logger : auditLoggers) {\n      if (logger instanceof HdfsAuditLogger) {\n        HdfsAuditLogger hdfsLogger \u003d (HdfsAuditLogger) logger;\n        hdfsLogger.logAuditEvent(succeeded, ugi.toString(), addr, cmd, src, dst,\n            status, CallerContext.getCurrent(), ugi, dtSecretManager);\n      } else {\n        logger.logAuditEvent(succeeded, ugi.toString(), addr,\n            cmd, src, dst, status);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "bb84f1fccb18c6c7373851e05d2451d55e908242": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7159. Use block storage policy to set lazy persist preference. (Arpit Agarwal)\n",
      "commitDate": "29/09/14 10:27 PM",
      "commitName": "bb84f1fccb18c6c7373851e05d2451d55e908242",
      "commitAuthor": "arp",
      "commitDateOld": "29/09/14 12:36 PM",
      "commitNameOld": "d45e7c7e856c7103752888c0395fa94985cd7670",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 0.41,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   private void logAuditEvent(boolean succeeded,\n       UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n       String dst, HdfsFileStatus stat) {\n     FileStatus status \u003d null;\n     if (stat !\u003d null) {\n       Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n       Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n       status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n-          stat.getReplication(), stat.getBlockSize(), stat.isLazyPersist(),\n+          stat.getReplication(), stat.getBlockSize(),\n           stat.getModificationTime(),\n           stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n           stat.getGroup(), symlink, path);\n     }\n     for (AuditLogger logger : auditLoggers) {\n       if (logger instanceof HdfsAuditLogger) {\n         HdfsAuditLogger hdfsLogger \u003d (HdfsAuditLogger) logger;\n         hdfsLogger.logAuditEvent(succeeded, ugi.toString(), addr, cmd, src, dst,\n             status, ugi, dtSecretManager);\n       } else {\n         logger.logAuditEvent(succeeded, ugi.toString(), addr,\n             cmd, src, dst, status);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void logAuditEvent(boolean succeeded,\n      UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n      String dst, HdfsFileStatus stat) {\n    FileStatus status \u003d null;\n    if (stat !\u003d null) {\n      Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n      Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n      status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n          stat.getReplication(), stat.getBlockSize(),\n          stat.getModificationTime(),\n          stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n          stat.getGroup(), symlink, path);\n    }\n    for (AuditLogger logger : auditLoggers) {\n      if (logger instanceof HdfsAuditLogger) {\n        HdfsAuditLogger hdfsLogger \u003d (HdfsAuditLogger) logger;\n        hdfsLogger.logAuditEvent(succeeded, ugi.toString(), addr, cmd, src, dst,\n            status, ugi, dtSecretManager);\n      } else {\n        logger.logAuditEvent(succeeded, ugi.toString(), addr,\n            cmd, src, dst, status);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "a7bcc9535860214380e235641d1d5d2dd15aee58": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6921. Add LazyPersist flag to FileStatus. (Arpit Agarwal)\n",
      "commitDate": "27/08/14 9:47 PM",
      "commitName": "a7bcc9535860214380e235641d1d5d2dd15aee58",
      "commitAuthor": "arp",
      "commitDateOld": "27/08/14 11:14 AM",
      "commitNameOld": "26ebdd849b23243b31e58c44d0d363e11b42fc52",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 0.44,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,24 @@\n   private void logAuditEvent(boolean succeeded,\n       UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n       String dst, HdfsFileStatus stat) {\n     FileStatus status \u003d null;\n     if (stat !\u003d null) {\n       Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n       Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n       status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n-          stat.getReplication(), stat.getBlockSize(), stat.getModificationTime(),\n+          stat.getReplication(), stat.getBlockSize(), stat.isLazyPersist(),\n+          stat.getModificationTime(),\n           stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n           stat.getGroup(), symlink, path);\n     }\n     for (AuditLogger logger : auditLoggers) {\n       if (logger instanceof HdfsAuditLogger) {\n         HdfsAuditLogger hdfsLogger \u003d (HdfsAuditLogger) logger;\n         hdfsLogger.logAuditEvent(succeeded, ugi.toString(), addr, cmd, src, dst,\n             status, ugi, dtSecretManager);\n       } else {\n         logger.logAuditEvent(succeeded, ugi.toString(), addr,\n             cmd, src, dst, status);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void logAuditEvent(boolean succeeded,\n      UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n      String dst, HdfsFileStatus stat) {\n    FileStatus status \u003d null;\n    if (stat !\u003d null) {\n      Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n      Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n      status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n          stat.getReplication(), stat.getBlockSize(), stat.isLazyPersist(),\n          stat.getModificationTime(),\n          stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n          stat.getGroup(), symlink, path);\n    }\n    for (AuditLogger logger : auditLoggers) {\n      if (logger instanceof HdfsAuditLogger) {\n        HdfsAuditLogger hdfsLogger \u003d (HdfsAuditLogger) logger;\n        hdfsLogger.logAuditEvent(succeeded, ugi.toString(), addr, cmd, src, dst,\n            status, ugi, dtSecretManager);\n      } else {\n        logger.logAuditEvent(succeeded, ugi.toString(), addr,\n            cmd, src, dst, status);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "e4374d803663c626de610cd5f062f25a6d7d5d4e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4680. Audit logging of delegation tokens for MR tracing. (Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1522012 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/09/13 12:57 PM",
      "commitName": "e4374d803663c626de610cd5f062f25a6d7d5d4e",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "06/09/13 12:05 PM",
      "commitNameOld": "6431192c0ee00ecfe578b270889b0c7a0a9cb8c8",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 5.04,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,23 @@\n   private void logAuditEvent(boolean succeeded,\n       UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n       String dst, HdfsFileStatus stat) {\n     FileStatus status \u003d null;\n     if (stat !\u003d null) {\n       Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n       Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n       status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n           stat.getReplication(), stat.getBlockSize(), stat.getModificationTime(),\n           stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n           stat.getGroup(), symlink, path);\n     }\n     for (AuditLogger logger : auditLoggers) {\n-      logger.logAuditEvent(succeeded, ugi.toString(), addr,\n-          cmd, src, dst, status);\n+      if (logger instanceof HdfsAuditLogger) {\n+        HdfsAuditLogger hdfsLogger \u003d (HdfsAuditLogger) logger;\n+        hdfsLogger.logAuditEvent(succeeded, ugi.toString(), addr, cmd, src, dst,\n+            status, ugi, dtSecretManager);\n+      } else {\n+        logger.logAuditEvent(succeeded, ugi.toString(), addr,\n+            cmd, src, dst, status);\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void logAuditEvent(boolean succeeded,\n      UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n      String dst, HdfsFileStatus stat) {\n    FileStatus status \u003d null;\n    if (stat !\u003d null) {\n      Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n      Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n      status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n          stat.getReplication(), stat.getBlockSize(), stat.getModificationTime(),\n          stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n          stat.getGroup(), symlink, path);\n    }\n    for (AuditLogger logger : auditLoggers) {\n      if (logger instanceof HdfsAuditLogger) {\n        HdfsAuditLogger hdfsLogger \u003d (HdfsAuditLogger) logger;\n        hdfsLogger.logAuditEvent(succeeded, ugi.toString(), addr, cmd, src, dst,\n            status, ugi, dtSecretManager);\n      } else {\n        logger.logAuditEvent(succeeded, ugi.toString(), addr,\n            cmd, src, dst, status);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "df2fb006b28bf1907fe3c54255e5f6bbb7698285": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-3680. Allow customized audit logging in HDFS FSNamesystem. Contributed by Marcelo Vanzin.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1418114 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/12/12 2:27 PM",
      "commitName": "df2fb006b28bf1907fe3c54255e5f6bbb7698285",
      "commitAuthor": "Aaron Myers",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-3680. Allow customized audit logging in HDFS FSNamesystem. Contributed by Marcelo Vanzin.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1418114 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/12 2:27 PM",
          "commitName": "df2fb006b28bf1907fe3c54255e5f6bbb7698285",
          "commitAuthor": "Aaron Myers",
          "commitDateOld": "05/12/12 11:20 PM",
          "commitNameOld": "8bb0dc34e4f14698bea104be6294acb4954358ca",
          "commitAuthorOld": "Konstantin Shvachko",
          "daysBetweenCommits": 0.63,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,17 @@\n-  private static final void logAuditEvent(boolean succeeded,\n+  private void logAuditEvent(boolean succeeded,\n       UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n       String dst, HdfsFileStatus stat) {\n-    final StringBuilder sb \u003d auditBuffer.get();\n-    sb.setLength(0);\n-    sb.append(\"allowed\u003d\").append(succeeded).append(\"\\t\");\n-    sb.append(\"ugi\u003d\").append(ugi).append(\"\\t\");\n-    sb.append(\"ip\u003d\").append(addr).append(\"\\t\");\n-    sb.append(\"cmd\u003d\").append(cmd).append(\"\\t\");\n-    sb.append(\"src\u003d\").append(src).append(\"\\t\");\n-    sb.append(\"dst\u003d\").append(dst).append(\"\\t\");\n-    if (null \u003d\u003d stat) {\n-      sb.append(\"perm\u003dnull\");\n-    } else {\n-      sb.append(\"perm\u003d\");\n-      sb.append(stat.getOwner()).append(\":\");\n-      sb.append(stat.getGroup()).append(\":\");\n-      sb.append(stat.getPermission());\n+    FileStatus status \u003d null;\n+    if (stat !\u003d null) {\n+      Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n+      Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n+      status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n+          stat.getReplication(), stat.getBlockSize(), stat.getModificationTime(),\n+          stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n+          stat.getGroup(), symlink, path);\n     }\n-    auditLog.info(sb);\n+    for (AuditLogger logger : auditLoggers) {\n+      logger.logAuditEvent(succeeded, ugi.toString(), addr,\n+          cmd, src, dst, status);\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void logAuditEvent(boolean succeeded,\n      UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n      String dst, HdfsFileStatus stat) {\n    FileStatus status \u003d null;\n    if (stat !\u003d null) {\n      Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n      Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n      status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n          stat.getReplication(), stat.getBlockSize(), stat.getModificationTime(),\n          stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n          stat.getGroup(), symlink, path);\n    }\n    for (AuditLogger logger : auditLoggers) {\n      logger.logAuditEvent(succeeded, ugi.toString(), addr,\n          cmd, src, dst, status);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[private, static, final]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3680. Allow customized audit logging in HDFS FSNamesystem. Contributed by Marcelo Vanzin.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1418114 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "06/12/12 2:27 PM",
          "commitName": "df2fb006b28bf1907fe3c54255e5f6bbb7698285",
          "commitAuthor": "Aaron Myers",
          "commitDateOld": "05/12/12 11:20 PM",
          "commitNameOld": "8bb0dc34e4f14698bea104be6294acb4954358ca",
          "commitAuthorOld": "Konstantin Shvachko",
          "daysBetweenCommits": 0.63,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,17 @@\n-  private static final void logAuditEvent(boolean succeeded,\n+  private void logAuditEvent(boolean succeeded,\n       UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n       String dst, HdfsFileStatus stat) {\n-    final StringBuilder sb \u003d auditBuffer.get();\n-    sb.setLength(0);\n-    sb.append(\"allowed\u003d\").append(succeeded).append(\"\\t\");\n-    sb.append(\"ugi\u003d\").append(ugi).append(\"\\t\");\n-    sb.append(\"ip\u003d\").append(addr).append(\"\\t\");\n-    sb.append(\"cmd\u003d\").append(cmd).append(\"\\t\");\n-    sb.append(\"src\u003d\").append(src).append(\"\\t\");\n-    sb.append(\"dst\u003d\").append(dst).append(\"\\t\");\n-    if (null \u003d\u003d stat) {\n-      sb.append(\"perm\u003dnull\");\n-    } else {\n-      sb.append(\"perm\u003d\");\n-      sb.append(stat.getOwner()).append(\":\");\n-      sb.append(stat.getGroup()).append(\":\");\n-      sb.append(stat.getPermission());\n+    FileStatus status \u003d null;\n+    if (stat !\u003d null) {\n+      Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n+      Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n+      status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n+          stat.getReplication(), stat.getBlockSize(), stat.getModificationTime(),\n+          stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n+          stat.getGroup(), symlink, path);\n     }\n-    auditLog.info(sb);\n+    for (AuditLogger logger : auditLoggers) {\n+      logger.logAuditEvent(succeeded, ugi.toString(), addr,\n+          cmd, src, dst, status);\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void logAuditEvent(boolean succeeded,\n      UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n      String dst, HdfsFileStatus stat) {\n    FileStatus status \u003d null;\n    if (stat !\u003d null) {\n      Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n      Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n      status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n          stat.getReplication(), stat.getBlockSize(), stat.getModificationTime(),\n          stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n          stat.getGroup(), symlink, path);\n    }\n    for (AuditLogger logger : auditLoggers) {\n      logger.logAuditEvent(succeeded, ugi.toString(), addr,\n          cmd, src, dst, status);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "d866f81edbd70121a9e29e5d25be67e1c464397e": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "Reverting initial commit of HDFS-3680 pending further comments.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1415797 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/11/12 11:19 AM",
      "commitName": "d866f81edbd70121a9e29e5d25be67e1c464397e",
      "commitAuthor": "Aaron Myers",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "Reverting initial commit of HDFS-3680 pending further comments.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1415797 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/11/12 11:19 AM",
          "commitName": "d866f81edbd70121a9e29e5d25be67e1c464397e",
          "commitAuthor": "Aaron Myers",
          "commitDateOld": "30/11/12 11:11 AM",
          "commitNameOld": "a85a0293c77f7cf0471d242458f04ec61e0129bc",
          "commitAuthorOld": "Aaron Myers",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,21 @@\n-  private void logAuditEvent(boolean succeeded,\n+  private static final void logAuditEvent(boolean succeeded,\n       UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n       String dst, HdfsFileStatus stat) {\n-    FileStatus status \u003d null;\n-    if (stat !\u003d null) {\n-      Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n-      Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n-      status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n-          stat.getReplication(), stat.getBlockSize(), stat.getModificationTime(),\n-          stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n-          stat.getGroup(), symlink, path);\n+    final StringBuilder sb \u003d auditBuffer.get();\n+    sb.setLength(0);\n+    sb.append(\"allowed\u003d\").append(succeeded).append(\"\\t\");\n+    sb.append(\"ugi\u003d\").append(ugi).append(\"\\t\");\n+    sb.append(\"ip\u003d\").append(addr).append(\"\\t\");\n+    sb.append(\"cmd\u003d\").append(cmd).append(\"\\t\");\n+    sb.append(\"src\u003d\").append(src).append(\"\\t\");\n+    sb.append(\"dst\u003d\").append(dst).append(\"\\t\");\n+    if (null \u003d\u003d stat) {\n+      sb.append(\"perm\u003dnull\");\n+    } else {\n+      sb.append(\"perm\u003d\");\n+      sb.append(stat.getOwner()).append(\":\");\n+      sb.append(stat.getGroup()).append(\":\");\n+      sb.append(stat.getPermission());\n     }\n-    for (AuditLogger logger : auditLoggers) {\n-      logger.logAuditEvent(succeeded, ugi.toString(), addr,\n-          cmd, src, dst, status);\n-    }\n+    auditLog.info(sb);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static final void logAuditEvent(boolean succeeded,\n      UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n      String dst, HdfsFileStatus stat) {\n    final StringBuilder sb \u003d auditBuffer.get();\n    sb.setLength(0);\n    sb.append(\"allowed\u003d\").append(succeeded).append(\"\\t\");\n    sb.append(\"ugi\u003d\").append(ugi).append(\"\\t\");\n    sb.append(\"ip\u003d\").append(addr).append(\"\\t\");\n    sb.append(\"cmd\u003d\").append(cmd).append(\"\\t\");\n    sb.append(\"src\u003d\").append(src).append(\"\\t\");\n    sb.append(\"dst\u003d\").append(dst).append(\"\\t\");\n    if (null \u003d\u003d stat) {\n      sb.append(\"perm\u003dnull\");\n    } else {\n      sb.append(\"perm\u003d\");\n      sb.append(stat.getOwner()).append(\":\");\n      sb.append(stat.getGroup()).append(\":\");\n      sb.append(stat.getPermission());\n    }\n    auditLog.info(sb);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[private, static, final]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "Reverting initial commit of HDFS-3680 pending further comments.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1415797 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/11/12 11:19 AM",
          "commitName": "d866f81edbd70121a9e29e5d25be67e1c464397e",
          "commitAuthor": "Aaron Myers",
          "commitDateOld": "30/11/12 11:11 AM",
          "commitNameOld": "a85a0293c77f7cf0471d242458f04ec61e0129bc",
          "commitAuthorOld": "Aaron Myers",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,21 @@\n-  private void logAuditEvent(boolean succeeded,\n+  private static final void logAuditEvent(boolean succeeded,\n       UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n       String dst, HdfsFileStatus stat) {\n-    FileStatus status \u003d null;\n-    if (stat !\u003d null) {\n-      Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n-      Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n-      status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n-          stat.getReplication(), stat.getBlockSize(), stat.getModificationTime(),\n-          stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n-          stat.getGroup(), symlink, path);\n+    final StringBuilder sb \u003d auditBuffer.get();\n+    sb.setLength(0);\n+    sb.append(\"allowed\u003d\").append(succeeded).append(\"\\t\");\n+    sb.append(\"ugi\u003d\").append(ugi).append(\"\\t\");\n+    sb.append(\"ip\u003d\").append(addr).append(\"\\t\");\n+    sb.append(\"cmd\u003d\").append(cmd).append(\"\\t\");\n+    sb.append(\"src\u003d\").append(src).append(\"\\t\");\n+    sb.append(\"dst\u003d\").append(dst).append(\"\\t\");\n+    if (null \u003d\u003d stat) {\n+      sb.append(\"perm\u003dnull\");\n+    } else {\n+      sb.append(\"perm\u003d\");\n+      sb.append(stat.getOwner()).append(\":\");\n+      sb.append(stat.getGroup()).append(\":\");\n+      sb.append(stat.getPermission());\n     }\n-    for (AuditLogger logger : auditLoggers) {\n-      logger.logAuditEvent(succeeded, ugi.toString(), addr,\n-          cmd, src, dst, status);\n-    }\n+    auditLog.info(sb);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static final void logAuditEvent(boolean succeeded,\n      UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n      String dst, HdfsFileStatus stat) {\n    final StringBuilder sb \u003d auditBuffer.get();\n    sb.setLength(0);\n    sb.append(\"allowed\u003d\").append(succeeded).append(\"\\t\");\n    sb.append(\"ugi\u003d\").append(ugi).append(\"\\t\");\n    sb.append(\"ip\u003d\").append(addr).append(\"\\t\");\n    sb.append(\"cmd\u003d\").append(cmd).append(\"\\t\");\n    sb.append(\"src\u003d\").append(src).append(\"\\t\");\n    sb.append(\"dst\u003d\").append(dst).append(\"\\t\");\n    if (null \u003d\u003d stat) {\n      sb.append(\"perm\u003dnull\");\n    } else {\n      sb.append(\"perm\u003d\");\n      sb.append(stat.getOwner()).append(\":\");\n      sb.append(stat.getGroup()).append(\":\");\n      sb.append(stat.getPermission());\n    }\n    auditLog.info(sb);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "a85a0293c77f7cf0471d242458f04ec61e0129bc": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-3680. Allow customized audit logging in HDFS FSNamesystem. Contributed by Marcelo Vanzin.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1415794 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/11/12 11:11 AM",
      "commitName": "a85a0293c77f7cf0471d242458f04ec61e0129bc",
      "commitAuthor": "Aaron Myers",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-3680. Allow customized audit logging in HDFS FSNamesystem. Contributed by Marcelo Vanzin.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1415794 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/11/12 11:11 AM",
          "commitName": "a85a0293c77f7cf0471d242458f04ec61e0129bc",
          "commitAuthor": "Aaron Myers",
          "commitDateOld": "19/11/12 6:00 PM",
          "commitNameOld": "573c41c2666e084f3988a288bb40d2305fc23d8f",
          "commitAuthorOld": "Konstantin Shvachko",
          "daysBetweenCommits": 10.72,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,17 @@\n-  private static final void logAuditEvent(boolean succeeded,\n+  private void logAuditEvent(boolean succeeded,\n       UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n       String dst, HdfsFileStatus stat) {\n-    final StringBuilder sb \u003d auditBuffer.get();\n-    sb.setLength(0);\n-    sb.append(\"allowed\u003d\").append(succeeded).append(\"\\t\");\n-    sb.append(\"ugi\u003d\").append(ugi).append(\"\\t\");\n-    sb.append(\"ip\u003d\").append(addr).append(\"\\t\");\n-    sb.append(\"cmd\u003d\").append(cmd).append(\"\\t\");\n-    sb.append(\"src\u003d\").append(src).append(\"\\t\");\n-    sb.append(\"dst\u003d\").append(dst).append(\"\\t\");\n-    if (null \u003d\u003d stat) {\n-      sb.append(\"perm\u003dnull\");\n-    } else {\n-      sb.append(\"perm\u003d\");\n-      sb.append(stat.getOwner()).append(\":\");\n-      sb.append(stat.getGroup()).append(\":\");\n-      sb.append(stat.getPermission());\n+    FileStatus status \u003d null;\n+    if (stat !\u003d null) {\n+      Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n+      Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n+      status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n+          stat.getReplication(), stat.getBlockSize(), stat.getModificationTime(),\n+          stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n+          stat.getGroup(), symlink, path);\n     }\n-    auditLog.info(sb);\n+    for (AuditLogger logger : auditLoggers) {\n+      logger.logAuditEvent(succeeded, ugi.toString(), addr,\n+          cmd, src, dst, status);\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void logAuditEvent(boolean succeeded,\n      UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n      String dst, HdfsFileStatus stat) {\n    FileStatus status \u003d null;\n    if (stat !\u003d null) {\n      Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n      Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n      status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n          stat.getReplication(), stat.getBlockSize(), stat.getModificationTime(),\n          stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n          stat.getGroup(), symlink, path);\n    }\n    for (AuditLogger logger : auditLoggers) {\n      logger.logAuditEvent(succeeded, ugi.toString(), addr,\n          cmd, src, dst, status);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[private, static, final]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3680. Allow customized audit logging in HDFS FSNamesystem. Contributed by Marcelo Vanzin.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1415794 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "30/11/12 11:11 AM",
          "commitName": "a85a0293c77f7cf0471d242458f04ec61e0129bc",
          "commitAuthor": "Aaron Myers",
          "commitDateOld": "19/11/12 6:00 PM",
          "commitNameOld": "573c41c2666e084f3988a288bb40d2305fc23d8f",
          "commitAuthorOld": "Konstantin Shvachko",
          "daysBetweenCommits": 10.72,
          "commitsBetweenForRepo": 30,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,17 @@\n-  private static final void logAuditEvent(boolean succeeded,\n+  private void logAuditEvent(boolean succeeded,\n       UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n       String dst, HdfsFileStatus stat) {\n-    final StringBuilder sb \u003d auditBuffer.get();\n-    sb.setLength(0);\n-    sb.append(\"allowed\u003d\").append(succeeded).append(\"\\t\");\n-    sb.append(\"ugi\u003d\").append(ugi).append(\"\\t\");\n-    sb.append(\"ip\u003d\").append(addr).append(\"\\t\");\n-    sb.append(\"cmd\u003d\").append(cmd).append(\"\\t\");\n-    sb.append(\"src\u003d\").append(src).append(\"\\t\");\n-    sb.append(\"dst\u003d\").append(dst).append(\"\\t\");\n-    if (null \u003d\u003d stat) {\n-      sb.append(\"perm\u003dnull\");\n-    } else {\n-      sb.append(\"perm\u003d\");\n-      sb.append(stat.getOwner()).append(\":\");\n-      sb.append(stat.getGroup()).append(\":\");\n-      sb.append(stat.getPermission());\n+    FileStatus status \u003d null;\n+    if (stat !\u003d null) {\n+      Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n+      Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n+      status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n+          stat.getReplication(), stat.getBlockSize(), stat.getModificationTime(),\n+          stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n+          stat.getGroup(), symlink, path);\n     }\n-    auditLog.info(sb);\n+    for (AuditLogger logger : auditLoggers) {\n+      logger.logAuditEvent(succeeded, ugi.toString(), addr,\n+          cmd, src, dst, status);\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void logAuditEvent(boolean succeeded,\n      UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n      String dst, HdfsFileStatus stat) {\n    FileStatus status \u003d null;\n    if (stat !\u003d null) {\n      Path symlink \u003d stat.isSymlink() ? new Path(stat.getSymlink()) : null;\n      Path path \u003d dst !\u003d null ? new Path(dst) : new Path(src);\n      status \u003d new FileStatus(stat.getLen(), stat.isDir(),\n          stat.getReplication(), stat.getBlockSize(), stat.getModificationTime(),\n          stat.getAccessTime(), stat.getPermission(), stat.getOwner(),\n          stat.getGroup(), symlink, path);\n    }\n    for (AuditLogger logger : auditLoggers) {\n      logger.logAuditEvent(succeeded, ugi.toString(), addr,\n          cmd, src, dst, status);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "0270889b4e7f241620b2c3c297ec6530d96a7db5": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3535. Audit logging should log denied accesses. Contributed by Andy Isaacson\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1354144 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/06/12 11:14 AM",
      "commitName": "0270889b4e7f241620b2c3c297ec6530d96a7db5",
      "commitAuthor": "Eli Collins",
      "diff": "@@ -0,0 +1,21 @@\n+  private static final void logAuditEvent(boolean succeeded,\n+      UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n+      String dst, HdfsFileStatus stat) {\n+    final StringBuilder sb \u003d auditBuffer.get();\n+    sb.setLength(0);\n+    sb.append(\"allowed\u003d\").append(succeeded).append(\"\\t\");\n+    sb.append(\"ugi\u003d\").append(ugi).append(\"\\t\");\n+    sb.append(\"ip\u003d\").append(addr).append(\"\\t\");\n+    sb.append(\"cmd\u003d\").append(cmd).append(\"\\t\");\n+    sb.append(\"src\u003d\").append(src).append(\"\\t\");\n+    sb.append(\"dst\u003d\").append(dst).append(\"\\t\");\n+    if (null \u003d\u003d stat) {\n+      sb.append(\"perm\u003dnull\");\n+    } else {\n+      sb.append(\"perm\u003d\");\n+      sb.append(stat.getOwner()).append(\":\");\n+      sb.append(stat.getGroup()).append(\":\");\n+      sb.append(stat.getPermission());\n+    }\n+    auditLog.info(sb);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static final void logAuditEvent(boolean succeeded,\n      UserGroupInformation ugi, InetAddress addr, String cmd, String src,\n      String dst, HdfsFileStatus stat) {\n    final StringBuilder sb \u003d auditBuffer.get();\n    sb.setLength(0);\n    sb.append(\"allowed\u003d\").append(succeeded).append(\"\\t\");\n    sb.append(\"ugi\u003d\").append(ugi).append(\"\\t\");\n    sb.append(\"ip\u003d\").append(addr).append(\"\\t\");\n    sb.append(\"cmd\u003d\").append(cmd).append(\"\\t\");\n    sb.append(\"src\u003d\").append(src).append(\"\\t\");\n    sb.append(\"dst\u003d\").append(dst).append(\"\\t\");\n    if (null \u003d\u003d stat) {\n      sb.append(\"perm\u003dnull\");\n    } else {\n      sb.append(\"perm\u003d\");\n      sb.append(stat.getOwner()).append(\":\");\n      sb.append(stat.getGroup()).append(\":\");\n      sb.append(stat.getPermission());\n    }\n    auditLog.info(sb);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}