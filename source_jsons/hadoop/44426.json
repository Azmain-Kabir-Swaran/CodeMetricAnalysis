{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Client.java",
  "functionName": "run",
  "functionId": "run",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
  "functionStartLine": 669,
  "functionEndLine": 1091,
  "numCommitsSeen": 83,
  "timeTaken": 14697,
  "changeHistory": [
    "8d754c2c397f1273ad7c520fa5f1b7efa0db31f7",
    "649666e118a7cf92b676eaa56a8be318176c443e",
    "30c6dd92e1d4075d143adc891dc8ec536dddc0d9",
    "b0d24ef39cbee53ae092f3aafeeebd22cd81bcac",
    "95372657fc25c02399b01793833021ccf88dada2",
    "ba38db4f5b7d8a1432a9a1b4adaa5c1545218799",
    "f738b397ae021c9be900e4ec51ab55cd69b075e0",
    "fb55e5201e5b2ff40e1b757a9c5bf23c5d8aec93",
    "16333782c17d6c459019cf14682e5feee9968181",
    "8956e5b8db3059e0872e49f59adc6affc76e2274",
    "431076f63751f855ab6036ff85825a8552257b93",
    "a08c048832d68c203fbdfce8d9f0e7dcccb02a55",
    "eb2449d5398e9ac869bc088e10d838a7f13deac0",
    "e60f51299dba360d13aa39f9ab714fdfc666b532",
    "01f3f2167ec20b52a18bc2cf250fb4229cfd2c14",
    "928964102029e96406f5482e8900802f38164501",
    "40b0045ebe0752cd3d1d09be00acbabdea983799",
    "e490602e9b306d5b8a543b93fb15a7395bb9a03d",
    "7805deed4896e470ebd2f6bbd1ba9962947c63cd",
    "89e5c44f9e891a3579384c3fa3766937cd4970f1",
    "47f35a30bb4d99349593e9d6e1c9e76e71341c40",
    "d67c9bdb4db2b075484a779802ecf3296bad5cd4",
    "d45ff878c4cb8b359abb17ecf09d24b6f862874c",
    "42f90ab885d9693fcc1e52f9637f7de4111110ae",
    "0f25a1bb52bc56661fd020a6ba82df99f8c6ef1f",
    "e9a622606f69dc926a950d4dd61fe3f16f378509",
    "446212a39ecf295cdd0e0b06ab870b48c5e6b500",
    "5ce3a77f3c00aeabcd791c3373dd3c8c25160ce2",
    "f6b963fdfc517429149165e4bb6fb947be6e3c99",
    "1d4612f5ad9678c952b416e798dccd20c88f96ef",
    "8e5d6713cf16473d791c028cecc274fd2c7fd10b",
    "f6c723ff0c09134d721534a409e8d688cc028307",
    "d6a6e982a84eb9545cbac51ee6277ea2837f88de",
    "96e0ca2d272dc7ecd7f7f0e65a0c596fcc063bcb",
    "aa0c489a28dbbe8fae0be6a48edb122537784b1d",
    "d63cfdbf1a5389acb27e8cd61f4c14d8eaedb26f",
    "c4bdddeab56287c8a8ae314fac238cbbc6c1bcf4",
    "33a8234040959ecd0d0202162e1b18c990effabe",
    "a802ef4a5f2e71eed2cbdc053258ae2f66af4755",
    "ad558cf2b3650530c741f1cfafb0cf47e60c8b77",
    "735d8b27f78ea8be839008650a3e88db37dc507d",
    "42c3cd3d137ba1de1c0573c0bb655fa380ed9412",
    "5e4f6ad1d9aa6df96af837600674af4467c1e99c",
    "d3198dddc8c66139cbb57b3c3c061a3d0d2c6a5d",
    "ff70f912f781e35e3538d00c892d18b17aefa105",
    "6b75a5c3b50877fc03574932ad54e4b4298f80d1",
    "af8514eef297574240652672d048748100c97733",
    "a83fb61ac07c0468cbc7a38526e92683883dd932",
    "92b7165a71656468f17ce8b760ce11e648932f0e",
    "e4c55e17fea55e2fcbef182bb2b0c4b22686f38c",
    "d6b33ee981693169be688eb076998f1d0e4aa84d",
    "e464607b7d156f20bb9ca19a2dfbd73edeaec722",
    "10e704c50ba1fa601329d0fee099993e8c3725a6",
    "e1fdf62123625e4ba399af02f8aad500637d29d1",
    "2e00d28f1413fcb5afbcbda836dfb9ea6cf3a5a1",
    "db31b6c0e4aa1f6cd2d655a48195fdfb76bc5329",
    "daa28cc6ce23ef5c8db8b9f896f342cb770dd092",
    "b28f134e9cc61c49b404eaacf8a321bb12b78969",
    "aaace5e84e9fadd817c984353e299745ff2fc334",
    "fad230a49d0d4cdbb2062b10c3dea6c755737db5"
  ],
  "changeHistoryShort": {
    "8d754c2c397f1273ad7c520fa5f1b7efa0db31f7": "Ybodychange",
    "649666e118a7cf92b676eaa56a8be318176c443e": "Ybodychange",
    "30c6dd92e1d4075d143adc891dc8ec536dddc0d9": "Ybodychange",
    "b0d24ef39cbee53ae092f3aafeeebd22cd81bcac": "Ybodychange",
    "95372657fc25c02399b01793833021ccf88dada2": "Ybodychange",
    "ba38db4f5b7d8a1432a9a1b4adaa5c1545218799": "Ybodychange",
    "f738b397ae021c9be900e4ec51ab55cd69b075e0": "Ybodychange",
    "fb55e5201e5b2ff40e1b757a9c5bf23c5d8aec93": "Ybodychange",
    "16333782c17d6c459019cf14682e5feee9968181": "Ybodychange",
    "8956e5b8db3059e0872e49f59adc6affc76e2274": "Ybodychange",
    "431076f63751f855ab6036ff85825a8552257b93": "Ybodychange",
    "a08c048832d68c203fbdfce8d9f0e7dcccb02a55": "Ybodychange",
    "eb2449d5398e9ac869bc088e10d838a7f13deac0": "Ybodychange",
    "e60f51299dba360d13aa39f9ab714fdfc666b532": "Ybodychange",
    "01f3f2167ec20b52a18bc2cf250fb4229cfd2c14": "Ybodychange",
    "928964102029e96406f5482e8900802f38164501": "Ybodychange",
    "40b0045ebe0752cd3d1d09be00acbabdea983799": "Ybodychange",
    "e490602e9b306d5b8a543b93fb15a7395bb9a03d": "Ybodychange",
    "7805deed4896e470ebd2f6bbd1ba9962947c63cd": "Ybodychange",
    "89e5c44f9e891a3579384c3fa3766937cd4970f1": "Ybodychange",
    "47f35a30bb4d99349593e9d6e1c9e76e71341c40": "Ybodychange",
    "d67c9bdb4db2b075484a779802ecf3296bad5cd4": "Ybodychange",
    "d45ff878c4cb8b359abb17ecf09d24b6f862874c": "Ybodychange",
    "42f90ab885d9693fcc1e52f9637f7de4111110ae": "Ybodychange",
    "0f25a1bb52bc56661fd020a6ba82df99f8c6ef1f": "Ybodychange",
    "e9a622606f69dc926a950d4dd61fe3f16f378509": "Ybodychange",
    "446212a39ecf295cdd0e0b06ab870b48c5e6b500": "Ybodychange",
    "5ce3a77f3c00aeabcd791c3373dd3c8c25160ce2": "Ybodychange",
    "f6b963fdfc517429149165e4bb6fb947be6e3c99": "Ybodychange",
    "1d4612f5ad9678c952b416e798dccd20c88f96ef": "Ybodychange",
    "8e5d6713cf16473d791c028cecc274fd2c7fd10b": "Ybodychange",
    "f6c723ff0c09134d721534a409e8d688cc028307": "Ybodychange",
    "d6a6e982a84eb9545cbac51ee6277ea2837f88de": "Ybodychange",
    "96e0ca2d272dc7ecd7f7f0e65a0c596fcc063bcb": "Ybodychange",
    "aa0c489a28dbbe8fae0be6a48edb122537784b1d": "Ybodychange",
    "d63cfdbf1a5389acb27e8cd61f4c14d8eaedb26f": "Ybodychange",
    "c4bdddeab56287c8a8ae314fac238cbbc6c1bcf4": "Ybodychange",
    "33a8234040959ecd0d0202162e1b18c990effabe": "Ybodychange",
    "a802ef4a5f2e71eed2cbdc053258ae2f66af4755": "Ybodychange",
    "ad558cf2b3650530c741f1cfafb0cf47e60c8b77": "Ybodychange",
    "735d8b27f78ea8be839008650a3e88db37dc507d": "Ybodychange",
    "42c3cd3d137ba1de1c0573c0bb655fa380ed9412": "Ybodychange",
    "5e4f6ad1d9aa6df96af837600674af4467c1e99c": "Ybodychange",
    "d3198dddc8c66139cbb57b3c3c061a3d0d2c6a5d": "Ybodychange",
    "ff70f912f781e35e3538d00c892d18b17aefa105": "Ybodychange",
    "6b75a5c3b50877fc03574932ad54e4b4298f80d1": "Ybodychange",
    "af8514eef297574240652672d048748100c97733": "Ybodychange",
    "a83fb61ac07c0468cbc7a38526e92683883dd932": "Yexceptionschange",
    "92b7165a71656468f17ce8b760ce11e648932f0e": "Yexceptionschange",
    "e4c55e17fea55e2fcbef182bb2b0c4b22686f38c": "Ybodychange",
    "d6b33ee981693169be688eb076998f1d0e4aa84d": "Ybodychange",
    "e464607b7d156f20bb9ca19a2dfbd73edeaec722": "Ybodychange",
    "10e704c50ba1fa601329d0fee099993e8c3725a6": "Ybodychange",
    "e1fdf62123625e4ba399af02f8aad500637d29d1": "Yfilerename",
    "2e00d28f1413fcb5afbcbda836dfb9ea6cf3a5a1": "Ybodychange",
    "db31b6c0e4aa1f6cd2d655a48195fdfb76bc5329": "Ybodychange",
    "daa28cc6ce23ef5c8db8b9f896f342cb770dd092": "Ybodychange",
    "b28f134e9cc61c49b404eaacf8a321bb12b78969": "Ybodychange",
    "aaace5e84e9fadd817c984353e299745ff2fc334": "Ybodychange",
    "fad230a49d0d4cdbb2062b10c3dea6c755737db5": "Yintroduced"
  },
  "changeHistoryDetails": {
    "8d754c2c397f1273ad7c520fa5f1b7efa0db31f7": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16351. Change \":\" to ApplicationConstants.CLASS_PATH_SEPARATOR. Contributed by kevin su.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "16/08/19 5:26 PM",
      "commitName": "8d754c2c397f1273ad7c520fa5f1b7efa0db31f7",
      "commitAuthor": "HUAN-PING SU",
      "commitDateOld": "06/06/19 2:21 AM",
      "commitNameOld": "649666e118a7cf92b676eaa56a8be318176c443e",
      "commitAuthorOld": "Sunil G",
      "daysBetweenCommits": 71.63,
      "commitsBetweenForRepo": 632,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,423 +1,423 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     if (queueInfo \u003d\u003d null) {\n       throw new IllegalArgumentException(String\n           .format(\"Queue %s not present in scheduler configuration.\",\n               this.amQueue));\n     }\n \n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n     } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     applicationId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n     List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n     setAMResourceCapability(appContext, profiles, resourceTypes);\n     setContainerResources(profiles, resourceTypes);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (applicationTags !\u003d null) {\n       tags.addAll(applicationTags);\n     }\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath,\n         applicationId.toString(), localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath,\n           applicationId.toString(), localResources, null);\n     }\n \n     // Process local files for localization\n     // Here we just upload the files, the AM\n     // will set up localization later.\n     StringBuilder localizableFiles \u003d new StringBuilder();\n     filesToLocalize.stream().forEach(path -\u003e {\n       File f \u003d new File(path);\n \n       if (!f.exists()) {\n         throw new UncheckedIOException(\n             new IOException(path + \" does not exist\"));\n       }\n \n       if (!f.canRead()) {\n         throw new UncheckedIOException(\n             new IOException(path + \" cannot be read\"));\n       }\n \n       if (f.isDirectory()) {\n         throw new UncheckedIOException(\n           new IOException(path + \" is a directory\"));\n       }\n \n       try {\n         String fileName \u003d f.getName();\n         uploadFile(fs, path, fileName, applicationId.toString());\n         if (localizableFiles.length() \u003d\u003d 0) {\n           localizableFiles.append(fileName);\n         } else {\n           localizableFiles.append(\",\").append(fileName);\n         }\n       } catch (IOException e) {\n         throw new UncheckedIOException(\"Cannot upload file: \" + path, e);\n       }\n     });\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it.\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           ApplicationMaster.getRelativePath(appName,\n               applicationId.toString(),\n               SCRIPT_PATH);\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, applicationId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, applicationId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR)\n           .append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n-      classPathEnv.append(\u0027:\u0027)\n+      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR)\n           .append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     // Need extra quote here because JAVA_HOME might contain space on Windows,\n     // e.g. C:/Program Files/Java...\n     vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     if (containerType !\u003d null) {\n       vargs.add(\"--container_type \" + String.valueOf(containerType));\n     }\n     if (autoPromoteContainers) {\n       vargs.add(\"--promote_opportunistic_after_start\");\n     }\n     if (enforceExecType) {\n       vargs.add(\"--enforce_execution_type\");\n     }\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n     if (!containerResources.isEmpty()) {\n       Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n       vargs.add(\"--container_resources \" + joiner.join(containerResources));\n     }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n       // Encode the spec to avoid passing special chars via shell arguments.\n       String encodedSpec \u003d Base64.getEncoder()\n           .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n       LOG.info(\"Encode placement spec: \" + encodedSpec);\n       vargs.add(\"--placement_spec \" + encodedSpec);\n     }\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     if (keepContainers) {\n       vargs.add(\"--keep_containers_across_application_attempts\");\n     }\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n     if (localizableFiles.length() \u003e 0) {\n       vargs.add(\"--localized_files \" + localizableFiles.toString());\n     }\n     vargs.add(\"--appname \" + appName);\n \n     vargs.add(\"--homedir \" + fs.getHomeDirectory());\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     Credentials rmCredentials \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       rmCredentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, rmCredentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n     }\n \n     // Add the docker client config credentials if supplied.\n     Credentials dockerCredentials \u003d null;\n     if (dockerClientConfig !\u003d null) {\n       dockerCredentials \u003d\n           DockerClientConfigHandler.readCredentialsFromConfigFile(\n               new Path(dockerClientConfig), conf, applicationId.toString());\n     }\n \n     if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       if (rmCredentials !\u003d null) {\n         rmCredentials.writeTokenStorageToStream(dob);\n       }\n       if (dockerCredentials !\u003d null) {\n         dockerCredentials.writeTokenStorageToStream(dob);\n       }\n       ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(tokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     specifyLogAggregationContext(appContext);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(applicationId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    if (queueInfo \u003d\u003d null) {\n      throw new IllegalArgumentException(String\n          .format(\"Queue %s not present in scheduler configuration.\",\n              this.amQueue));\n    }\n\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    applicationId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n    setAMResourceCapability(appContext, profiles, resourceTypes);\n    setContainerResources(profiles, resourceTypes);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (applicationTags !\u003d null) {\n      tags.addAll(applicationTags);\n    }\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath,\n        applicationId.toString(), localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath,\n          applicationId.toString(), localResources, null);\n    }\n\n    // Process local files for localization\n    // Here we just upload the files, the AM\n    // will set up localization later.\n    StringBuilder localizableFiles \u003d new StringBuilder();\n    filesToLocalize.stream().forEach(path -\u003e {\n      File f \u003d new File(path);\n\n      if (!f.exists()) {\n        throw new UncheckedIOException(\n            new IOException(path + \" does not exist\"));\n      }\n\n      if (!f.canRead()) {\n        throw new UncheckedIOException(\n            new IOException(path + \" cannot be read\"));\n      }\n\n      if (f.isDirectory()) {\n        throw new UncheckedIOException(\n          new IOException(path + \" is a directory\"));\n      }\n\n      try {\n        String fileName \u003d f.getName();\n        uploadFile(fs, path, fileName, applicationId.toString());\n        if (localizableFiles.length() \u003d\u003d 0) {\n          localizableFiles.append(fileName);\n        } else {\n          localizableFiles.append(\",\").append(fileName);\n        }\n      } catch (IOException e) {\n        throw new UncheckedIOException(\"Cannot upload file: \" + path, e);\n      }\n    });\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it.\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          ApplicationMaster.getRelativePath(appName,\n              applicationId.toString(),\n              SCRIPT_PATH);\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, applicationId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, applicationId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR)\n          .append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR)\n          .append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    // Need extra quote here because JAVA_HOME might contain space on Windows,\n    // e.g. C:/Program Files/Java...\n    vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerType !\u003d null) {\n      vargs.add(\"--container_type \" + String.valueOf(containerType));\n    }\n    if (autoPromoteContainers) {\n      vargs.add(\"--promote_opportunistic_after_start\");\n    }\n    if (enforceExecType) {\n      vargs.add(\"--enforce_execution_type\");\n    }\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (!containerResources.isEmpty()) {\n      Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n      vargs.add(\"--container_resources \" + joiner.join(containerResources));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n      // Encode the spec to avoid passing special chars via shell arguments.\n      String encodedSpec \u003d Base64.getEncoder()\n          .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n      LOG.info(\"Encode placement spec: \" + encodedSpec);\n      vargs.add(\"--placement_spec \" + encodedSpec);\n    }\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    if (keepContainers) {\n      vargs.add(\"--keep_containers_across_application_attempts\");\n    }\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n    if (localizableFiles.length() \u003e 0) {\n      vargs.add(\"--localized_files \" + localizableFiles.toString());\n    }\n    vargs.add(\"--appname \" + appName);\n\n    vargs.add(\"--homedir \" + fs.getHomeDirectory());\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    Credentials rmCredentials \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      rmCredentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, rmCredentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n    }\n\n    // Add the docker client config credentials if supplied.\n    Credentials dockerCredentials \u003d null;\n    if (dockerClientConfig !\u003d null) {\n      dockerCredentials \u003d\n          DockerClientConfigHandler.readCredentialsFromConfigFile(\n              new Path(dockerClientConfig), conf, applicationId.toString());\n    }\n\n    if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      if (rmCredentials !\u003d null) {\n        rmCredentials.writeTokenStorageToStream(dob);\n      }\n      if (dockerCredentials !\u003d null) {\n        dockerCredentials.writeTokenStorageToStream(dob);\n      }\n      ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(tokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    specifyLogAggregationContext(appContext);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(applicationId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "649666e118a7cf92b676eaa56a8be318176c443e": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9573. DistributedShell cannot specify LogAggregationContext. Contributed by Adam Antal.\n",
      "commitDate": "06/06/19 2:21 AM",
      "commitName": "649666e118a7cf92b676eaa56a8be318176c443e",
      "commitAuthor": "Sunil G",
      "commitDateOld": "30/05/19 10:02 AM",
      "commitNameOld": "30c6dd92e1d4075d143adc891dc8ec536dddc0d9",
      "commitAuthorOld": "Sunil G",
      "daysBetweenCommits": 6.68,
      "commitsBetweenForRepo": 52,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,421 +1,423 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     if (queueInfo \u003d\u003d null) {\n       throw new IllegalArgumentException(String\n           .format(\"Queue %s not present in scheduler configuration.\",\n               this.amQueue));\n     }\n \n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n-        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n+        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n-            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n+            + \", queueName\u003d\" + aclInfo.getQueueName()\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n-    }\t\t\n+    }\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n     } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     applicationId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n     List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n     setAMResourceCapability(appContext, profiles, resourceTypes);\n     setContainerResources(profiles, resourceTypes);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (applicationTags !\u003d null) {\n       tags.addAll(applicationTags);\n     }\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n-    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n+    // In this scenario, the jar file for the application master is part of the local resources\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath,\n         applicationId.toString(), localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath,\n           applicationId.toString(), localResources, null);\n     }\n \n     // Process local files for localization\n     // Here we just upload the files, the AM\n     // will set up localization later.\n     StringBuilder localizableFiles \u003d new StringBuilder();\n     filesToLocalize.stream().forEach(path -\u003e {\n       File f \u003d new File(path);\n \n       if (!f.exists()) {\n         throw new UncheckedIOException(\n             new IOException(path + \" does not exist\"));\n       }\n \n       if (!f.canRead()) {\n         throw new UncheckedIOException(\n             new IOException(path + \" cannot be read\"));\n       }\n \n       if (f.isDirectory()) {\n         throw new UncheckedIOException(\n           new IOException(path + \" is a directory\"));\n       }\n \n       try {\n         String fileName \u003d f.getName();\n         uploadFile(fs, path, fileName, applicationId.toString());\n         if (localizableFiles.length() \u003d\u003d 0) {\n           localizableFiles.append(fileName);\n         } else {\n           localizableFiles.append(\",\").append(fileName);\n         }\n       } catch (IOException e) {\n         throw new UncheckedIOException(\"Cannot upload file: \" + path, e);\n       }\n     });\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n-    // master as the application master does not need it. \t\t\n+    // master as the application master does not need it.\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           ApplicationMaster.getRelativePath(appName,\n               applicationId.toString(),\n               SCRIPT_PATH);\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, applicationId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, applicationId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n-    // Add AppMaster.jar location to classpath \t\t\n+    // Add AppMaster.jar location to classpath\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR)\n           .append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027)\n           .append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     // Need extra quote here because JAVA_HOME might contain space on Windows,\n     // e.g. C:/Program Files/Java...\n     vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     if (containerType !\u003d null) {\n       vargs.add(\"--container_type \" + String.valueOf(containerType));\n     }\n     if (autoPromoteContainers) {\n       vargs.add(\"--promote_opportunistic_after_start\");\n     }\n     if (enforceExecType) {\n       vargs.add(\"--enforce_execution_type\");\n     }\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n     if (!containerResources.isEmpty()) {\n       Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n       vargs.add(\"--container_resources \" + joiner.join(containerResources));\n     }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n       // Encode the spec to avoid passing special chars via shell arguments.\n       String encodedSpec \u003d Base64.getEncoder()\n           .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n       LOG.info(\"Encode placement spec: \" + encodedSpec);\n       vargs.add(\"--placement_spec \" + encodedSpec);\n     }\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     if (keepContainers) {\n       vargs.add(\"--keep_containers_across_application_attempts\");\n     }\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n     if (localizableFiles.length() \u003e 0) {\n       vargs.add(\"--localized_files \" + localizableFiles.toString());\n     }\n     vargs.add(\"--appname \" + appName);\n \n     vargs.add(\"--homedir \" + fs.getHomeDirectory());\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n-    commands.add(command.toString());\t\t\n+    commands.add(command.toString());\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     Credentials rmCredentials \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       rmCredentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, rmCredentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n     }\n \n     // Add the docker client config credentials if supplied.\n     Credentials dockerCredentials \u003d null;\n     if (dockerClientConfig !\u003d null) {\n       dockerCredentials \u003d\n           DockerClientConfigHandler.readCredentialsFromConfigFile(\n               new Path(dockerClientConfig), conf, applicationId.toString());\n     }\n \n     if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       if (rmCredentials !\u003d null) {\n         rmCredentials.writeTokenStorageToStream(dob);\n       }\n       if (dockerCredentials !\u003d null) {\n         dockerCredentials.writeTokenStorageToStream(dob);\n       }\n       ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(tokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n+    specifyLogAggregationContext(appContext);\n+\n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(applicationId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    if (queueInfo \u003d\u003d null) {\n      throw new IllegalArgumentException(String\n          .format(\"Queue %s not present in scheduler configuration.\",\n              this.amQueue));\n    }\n\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    applicationId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n    setAMResourceCapability(appContext, profiles, resourceTypes);\n    setContainerResources(profiles, resourceTypes);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (applicationTags !\u003d null) {\n      tags.addAll(applicationTags);\n    }\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath,\n        applicationId.toString(), localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath,\n          applicationId.toString(), localResources, null);\n    }\n\n    // Process local files for localization\n    // Here we just upload the files, the AM\n    // will set up localization later.\n    StringBuilder localizableFiles \u003d new StringBuilder();\n    filesToLocalize.stream().forEach(path -\u003e {\n      File f \u003d new File(path);\n\n      if (!f.exists()) {\n        throw new UncheckedIOException(\n            new IOException(path + \" does not exist\"));\n      }\n\n      if (!f.canRead()) {\n        throw new UncheckedIOException(\n            new IOException(path + \" cannot be read\"));\n      }\n\n      if (f.isDirectory()) {\n        throw new UncheckedIOException(\n          new IOException(path + \" is a directory\"));\n      }\n\n      try {\n        String fileName \u003d f.getName();\n        uploadFile(fs, path, fileName, applicationId.toString());\n        if (localizableFiles.length() \u003d\u003d 0) {\n          localizableFiles.append(fileName);\n        } else {\n          localizableFiles.append(\",\").append(fileName);\n        }\n      } catch (IOException e) {\n        throw new UncheckedIOException(\"Cannot upload file: \" + path, e);\n      }\n    });\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it.\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          ApplicationMaster.getRelativePath(appName,\n              applicationId.toString(),\n              SCRIPT_PATH);\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, applicationId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, applicationId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR)\n          .append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027)\n          .append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    // Need extra quote here because JAVA_HOME might contain space on Windows,\n    // e.g. C:/Program Files/Java...\n    vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerType !\u003d null) {\n      vargs.add(\"--container_type \" + String.valueOf(containerType));\n    }\n    if (autoPromoteContainers) {\n      vargs.add(\"--promote_opportunistic_after_start\");\n    }\n    if (enforceExecType) {\n      vargs.add(\"--enforce_execution_type\");\n    }\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (!containerResources.isEmpty()) {\n      Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n      vargs.add(\"--container_resources \" + joiner.join(containerResources));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n      // Encode the spec to avoid passing special chars via shell arguments.\n      String encodedSpec \u003d Base64.getEncoder()\n          .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n      LOG.info(\"Encode placement spec: \" + encodedSpec);\n      vargs.add(\"--placement_spec \" + encodedSpec);\n    }\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    if (keepContainers) {\n      vargs.add(\"--keep_containers_across_application_attempts\");\n    }\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n    if (localizableFiles.length() \u003e 0) {\n      vargs.add(\"--localized_files \" + localizableFiles.toString());\n    }\n    vargs.add(\"--appname \" + appName);\n\n    vargs.add(\"--homedir \" + fs.getHomeDirectory());\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    Credentials rmCredentials \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      rmCredentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, rmCredentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n    }\n\n    // Add the docker client config credentials if supplied.\n    Credentials dockerCredentials \u003d null;\n    if (dockerClientConfig !\u003d null) {\n      dockerCredentials \u003d\n          DockerClientConfigHandler.readCredentialsFromConfigFile(\n              new Path(dockerClientConfig), conf, applicationId.toString());\n    }\n\n    if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      if (rmCredentials !\u003d null) {\n        rmCredentials.writeTokenStorageToStream(dob);\n      }\n      if (dockerCredentials !\u003d null) {\n        dockerCredentials.writeTokenStorageToStream(dob);\n      }\n      ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(tokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    specifyLogAggregationContext(appContext);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(applicationId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "30c6dd92e1d4075d143adc891dc8ec536dddc0d9": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9452. Fix TestDistributedShell and TestTimelineAuthFilterForV2 failures. Contributed by Prabhu Joseph.\n",
      "commitDate": "30/05/19 10:02 AM",
      "commitName": "30c6dd92e1d4075d143adc891dc8ec536dddc0d9",
      "commitAuthor": "Sunil G",
      "commitDateOld": "01/04/19 10:59 AM",
      "commitNameOld": "b0d24ef39cbee53ae092f3aafeeebd22cd81bcac",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 58.96,
      "commitsBetweenForRepo": 349,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,419 +1,421 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     if (queueInfo \u003d\u003d null) {\n       throw new IllegalArgumentException(String\n           .format(\"Queue %s not present in scheduler configuration.\",\n               this.amQueue));\n     }\n \n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n     } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     applicationId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n     List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n     setAMResourceCapability(appContext, profiles, resourceTypes);\n     setContainerResources(profiles, resourceTypes);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (applicationTags !\u003d null) {\n       tags.addAll(applicationTags);\n     }\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath,\n         applicationId.toString(), localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath,\n           applicationId.toString(), localResources, null);\n     }\n \n     // Process local files for localization\n     // Here we just upload the files, the AM\n     // will set up localization later.\n     StringBuilder localizableFiles \u003d new StringBuilder();\n     filesToLocalize.stream().forEach(path -\u003e {\n       File f \u003d new File(path);\n \n       if (!f.exists()) {\n         throw new UncheckedIOException(\n             new IOException(path + \" does not exist\"));\n       }\n \n       if (!f.canRead()) {\n         throw new UncheckedIOException(\n             new IOException(path + \" cannot be read\"));\n       }\n \n       if (f.isDirectory()) {\n         throw new UncheckedIOException(\n           new IOException(path + \" is a directory\"));\n       }\n \n       try {\n         String fileName \u003d f.getName();\n         uploadFile(fs, path, fileName, applicationId.toString());\n         if (localizableFiles.length() \u003d\u003d 0) {\n           localizableFiles.append(fileName);\n         } else {\n           localizableFiles.append(\",\").append(fileName);\n         }\n       } catch (IOException e) {\n         throw new UncheckedIOException(\"Cannot upload file: \" + path, e);\n       }\n     });\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           ApplicationMaster.getRelativePath(appName,\n               applicationId.toString(),\n               SCRIPT_PATH);\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, applicationId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, applicationId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR)\n           .append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027)\n           .append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     // Need extra quote here because JAVA_HOME might contain space on Windows,\n     // e.g. C:/Program Files/Java...\n     vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     if (containerType !\u003d null) {\n       vargs.add(\"--container_type \" + String.valueOf(containerType));\n     }\n     if (autoPromoteContainers) {\n       vargs.add(\"--promote_opportunistic_after_start\");\n     }\n     if (enforceExecType) {\n       vargs.add(\"--enforce_execution_type\");\n     }\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n     if (!containerResources.isEmpty()) {\n       Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n       vargs.add(\"--container_resources \" + joiner.join(containerResources));\n     }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n       // Encode the spec to avoid passing special chars via shell arguments.\n       String encodedSpec \u003d Base64.getEncoder()\n           .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n       LOG.info(\"Encode placement spec: \" + encodedSpec);\n       vargs.add(\"--placement_spec \" + encodedSpec);\n     }\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     if (keepContainers) {\n       vargs.add(\"--keep_containers_across_application_attempts\");\n     }\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n     if (localizableFiles.length() \u003e 0) {\n       vargs.add(\"--localized_files \" + localizableFiles.toString());\n     }\n     vargs.add(\"--appname \" + appName);\n \n+    vargs.add(\"--homedir \" + fs.getHomeDirectory());\n+\n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     Credentials rmCredentials \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       rmCredentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, rmCredentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n     }\n \n     // Add the docker client config credentials if supplied.\n     Credentials dockerCredentials \u003d null;\n     if (dockerClientConfig !\u003d null) {\n       dockerCredentials \u003d\n           DockerClientConfigHandler.readCredentialsFromConfigFile(\n               new Path(dockerClientConfig), conf, applicationId.toString());\n     }\n \n     if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       if (rmCredentials !\u003d null) {\n         rmCredentials.writeTokenStorageToStream(dob);\n       }\n       if (dockerCredentials !\u003d null) {\n         dockerCredentials.writeTokenStorageToStream(dob);\n       }\n       ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(tokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(applicationId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    if (queueInfo \u003d\u003d null) {\n      throw new IllegalArgumentException(String\n          .format(\"Queue %s not present in scheduler configuration.\",\n              this.amQueue));\n    }\n\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    applicationId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n    setAMResourceCapability(appContext, profiles, resourceTypes);\n    setContainerResources(profiles, resourceTypes);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (applicationTags !\u003d null) {\n      tags.addAll(applicationTags);\n    }\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath,\n        applicationId.toString(), localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath,\n          applicationId.toString(), localResources, null);\n    }\n\n    // Process local files for localization\n    // Here we just upload the files, the AM\n    // will set up localization later.\n    StringBuilder localizableFiles \u003d new StringBuilder();\n    filesToLocalize.stream().forEach(path -\u003e {\n      File f \u003d new File(path);\n\n      if (!f.exists()) {\n        throw new UncheckedIOException(\n            new IOException(path + \" does not exist\"));\n      }\n\n      if (!f.canRead()) {\n        throw new UncheckedIOException(\n            new IOException(path + \" cannot be read\"));\n      }\n\n      if (f.isDirectory()) {\n        throw new UncheckedIOException(\n          new IOException(path + \" is a directory\"));\n      }\n\n      try {\n        String fileName \u003d f.getName();\n        uploadFile(fs, path, fileName, applicationId.toString());\n        if (localizableFiles.length() \u003d\u003d 0) {\n          localizableFiles.append(fileName);\n        } else {\n          localizableFiles.append(\",\").append(fileName);\n        }\n      } catch (IOException e) {\n        throw new UncheckedIOException(\"Cannot upload file: \" + path, e);\n      }\n    });\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          ApplicationMaster.getRelativePath(appName,\n              applicationId.toString(),\n              SCRIPT_PATH);\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, applicationId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, applicationId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR)\n          .append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027)\n          .append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    // Need extra quote here because JAVA_HOME might contain space on Windows,\n    // e.g. C:/Program Files/Java...\n    vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerType !\u003d null) {\n      vargs.add(\"--container_type \" + String.valueOf(containerType));\n    }\n    if (autoPromoteContainers) {\n      vargs.add(\"--promote_opportunistic_after_start\");\n    }\n    if (enforceExecType) {\n      vargs.add(\"--enforce_execution_type\");\n    }\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (!containerResources.isEmpty()) {\n      Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n      vargs.add(\"--container_resources \" + joiner.join(containerResources));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n      // Encode the spec to avoid passing special chars via shell arguments.\n      String encodedSpec \u003d Base64.getEncoder()\n          .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n      LOG.info(\"Encode placement spec: \" + encodedSpec);\n      vargs.add(\"--placement_spec \" + encodedSpec);\n    }\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    if (keepContainers) {\n      vargs.add(\"--keep_containers_across_application_attempts\");\n    }\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n    if (localizableFiles.length() \u003e 0) {\n      vargs.add(\"--localized_files \" + localizableFiles.toString());\n    }\n    vargs.add(\"--appname \" + appName);\n\n    vargs.add(\"--homedir \" + fs.getHomeDirectory());\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    Credentials rmCredentials \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      rmCredentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, rmCredentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n    }\n\n    // Add the docker client config credentials if supplied.\n    Credentials dockerCredentials \u003d null;\n    if (dockerClientConfig !\u003d null) {\n      dockerCredentials \u003d\n          DockerClientConfigHandler.readCredentialsFromConfigFile(\n              new Path(dockerClientConfig), conf, applicationId.toString());\n    }\n\n    if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      if (rmCredentials !\u003d null) {\n        rmCredentials.writeTokenStorageToStream(dob);\n      }\n      if (dockerCredentials !\u003d null) {\n        dockerCredentials.writeTokenStorageToStream(dob);\n      }\n      ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(tokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(applicationId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "b0d24ef39cbee53ae092f3aafeeebd22cd81bcac": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9227. DistributedShell RelativePath is not removed at end. Contributed by Prabhu Joseph.\n",
      "commitDate": "01/04/19 10:59 AM",
      "commitName": "b0d24ef39cbee53ae092f3aafeeebd22cd81bcac",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "25/02/19 11:45 AM",
      "commitNameOld": "95372657fc25c02399b01793833021ccf88dada2",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 34.93,
      "commitsBetweenForRepo": 280,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,419 +1,419 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     if (queueInfo \u003d\u003d null) {\n       throw new IllegalArgumentException(String\n           .format(\"Queue %s not present in scheduler configuration.\",\n               this.amQueue));\n     }\n \n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n     } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n-    ApplicationId appId \u003d appContext.getApplicationId();\n+    applicationId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n     List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n     setAMResourceCapability(appContext, profiles, resourceTypes);\n     setContainerResources(profiles, resourceTypes);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (applicationTags !\u003d null) {\n       tags.addAll(applicationTags);\n     }\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n-    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n-        localResources, null);\n+    addToLocalResources(fs, appMasterJar, appMasterJarPath,\n+        applicationId.toString(), localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n-      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n-          localResources, null);\n+      addToLocalResources(fs, log4jPropFile, log4jPath,\n+          applicationId.toString(), localResources, null);\n     }\n \n     // Process local files for localization\n     // Here we just upload the files, the AM\n     // will set up localization later.\n     StringBuilder localizableFiles \u003d new StringBuilder();\n     filesToLocalize.stream().forEach(path -\u003e {\n       File f \u003d new File(path);\n \n       if (!f.exists()) {\n         throw new UncheckedIOException(\n             new IOException(path + \" does not exist\"));\n       }\n \n       if (!f.canRead()) {\n         throw new UncheckedIOException(\n             new IOException(path + \" cannot be read\"));\n       }\n \n       if (f.isDirectory()) {\n         throw new UncheckedIOException(\n           new IOException(path + \" is a directory\"));\n       }\n \n       try {\n         String fileName \u003d f.getName();\n-        uploadFile(fs, path, fileName, appId.toString());\n+        uploadFile(fs, path, fileName, applicationId.toString());\n         if (localizableFiles.length() \u003d\u003d 0) {\n           localizableFiles.append(fileName);\n         } else {\n           localizableFiles.append(\",\").append(fileName);\n         }\n       } catch (IOException e) {\n         throw new UncheckedIOException(\"Cannot upload file: \" + path, e);\n       }\n     });\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           ApplicationMaster.getRelativePath(appName,\n-              appId.toString(),\n+              applicationId.toString(),\n               SCRIPT_PATH);\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n-      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n+      addToLocalResources(fs, null, shellCommandPath, applicationId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n-      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n+      addToLocalResources(fs, null, shellArgsPath, applicationId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR)\n           .append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027)\n           .append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     // Need extra quote here because JAVA_HOME might contain space on Windows,\n     // e.g. C:/Program Files/Java...\n     vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     if (containerType !\u003d null) {\n       vargs.add(\"--container_type \" + String.valueOf(containerType));\n     }\n     if (autoPromoteContainers) {\n       vargs.add(\"--promote_opportunistic_after_start\");\n     }\n     if (enforceExecType) {\n       vargs.add(\"--enforce_execution_type\");\n     }\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n     if (!containerResources.isEmpty()) {\n       Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n       vargs.add(\"--container_resources \" + joiner.join(containerResources));\n     }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n       // Encode the spec to avoid passing special chars via shell arguments.\n       String encodedSpec \u003d Base64.getEncoder()\n           .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n       LOG.info(\"Encode placement spec: \" + encodedSpec);\n       vargs.add(\"--placement_spec \" + encodedSpec);\n     }\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     if (keepContainers) {\n       vargs.add(\"--keep_containers_across_application_attempts\");\n     }\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n     if (localizableFiles.length() \u003e 0) {\n       vargs.add(\"--localized_files \" + localizableFiles.toString());\n     }\n     vargs.add(\"--appname \" + appName);\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     Credentials rmCredentials \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       rmCredentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, rmCredentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n     }\n \n     // Add the docker client config credentials if supplied.\n     Credentials dockerCredentials \u003d null;\n     if (dockerClientConfig !\u003d null) {\n       dockerCredentials \u003d\n           DockerClientConfigHandler.readCredentialsFromConfigFile(\n-              new Path(dockerClientConfig), conf, appId.toString());\n+              new Path(dockerClientConfig), conf, applicationId.toString());\n     }\n \n     if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       if (rmCredentials !\u003d null) {\n         rmCredentials.writeTokenStorageToStream(dob);\n       }\n       if (dockerCredentials !\u003d null) {\n         dockerCredentials.writeTokenStorageToStream(dob);\n       }\n       ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(tokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n-    return monitorApplication(appId);\n+    return monitorApplication(applicationId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    if (queueInfo \u003d\u003d null) {\n      throw new IllegalArgumentException(String\n          .format(\"Queue %s not present in scheduler configuration.\",\n              this.amQueue));\n    }\n\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    applicationId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n    setAMResourceCapability(appContext, profiles, resourceTypes);\n    setContainerResources(profiles, resourceTypes);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (applicationTags !\u003d null) {\n      tags.addAll(applicationTags);\n    }\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath,\n        applicationId.toString(), localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath,\n          applicationId.toString(), localResources, null);\n    }\n\n    // Process local files for localization\n    // Here we just upload the files, the AM\n    // will set up localization later.\n    StringBuilder localizableFiles \u003d new StringBuilder();\n    filesToLocalize.stream().forEach(path -\u003e {\n      File f \u003d new File(path);\n\n      if (!f.exists()) {\n        throw new UncheckedIOException(\n            new IOException(path + \" does not exist\"));\n      }\n\n      if (!f.canRead()) {\n        throw new UncheckedIOException(\n            new IOException(path + \" cannot be read\"));\n      }\n\n      if (f.isDirectory()) {\n        throw new UncheckedIOException(\n          new IOException(path + \" is a directory\"));\n      }\n\n      try {\n        String fileName \u003d f.getName();\n        uploadFile(fs, path, fileName, applicationId.toString());\n        if (localizableFiles.length() \u003d\u003d 0) {\n          localizableFiles.append(fileName);\n        } else {\n          localizableFiles.append(\",\").append(fileName);\n        }\n      } catch (IOException e) {\n        throw new UncheckedIOException(\"Cannot upload file: \" + path, e);\n      }\n    });\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          ApplicationMaster.getRelativePath(appName,\n              applicationId.toString(),\n              SCRIPT_PATH);\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, applicationId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, applicationId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR)\n          .append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027)\n          .append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    // Need extra quote here because JAVA_HOME might contain space on Windows,\n    // e.g. C:/Program Files/Java...\n    vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerType !\u003d null) {\n      vargs.add(\"--container_type \" + String.valueOf(containerType));\n    }\n    if (autoPromoteContainers) {\n      vargs.add(\"--promote_opportunistic_after_start\");\n    }\n    if (enforceExecType) {\n      vargs.add(\"--enforce_execution_type\");\n    }\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (!containerResources.isEmpty()) {\n      Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n      vargs.add(\"--container_resources \" + joiner.join(containerResources));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n      // Encode the spec to avoid passing special chars via shell arguments.\n      String encodedSpec \u003d Base64.getEncoder()\n          .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n      LOG.info(\"Encode placement spec: \" + encodedSpec);\n      vargs.add(\"--placement_spec \" + encodedSpec);\n    }\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    if (keepContainers) {\n      vargs.add(\"--keep_containers_across_application_attempts\");\n    }\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n    if (localizableFiles.length() \u003e 0) {\n      vargs.add(\"--localized_files \" + localizableFiles.toString());\n    }\n    vargs.add(\"--appname \" + appName);\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    Credentials rmCredentials \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      rmCredentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, rmCredentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n    }\n\n    // Add the docker client config credentials if supplied.\n    Credentials dockerCredentials \u003d null;\n    if (dockerClientConfig !\u003d null) {\n      dockerCredentials \u003d\n          DockerClientConfigHandler.readCredentialsFromConfigFile(\n              new Path(dockerClientConfig), conf, applicationId.toString());\n    }\n\n    if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      if (rmCredentials !\u003d null) {\n        rmCredentials.writeTokenStorageToStream(dob);\n      }\n      if (dockerCredentials !\u003d null) {\n        dockerCredentials.writeTokenStorageToStream(dob);\n      }\n      ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(tokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(applicationId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "95372657fc25c02399b01793833021ccf88dada2": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9287. Consecutive StringBuilder append should be reuse. Contributed by Ayush Saxena.\n",
      "commitDate": "25/02/19 11:45 AM",
      "commitName": "95372657fc25c02399b01793833021ccf88dada2",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "25/02/19 1:58 AM",
      "commitNameOld": "6cec90653dc2ae60a10262745997ea91dd872a8b",
      "commitAuthorOld": "Sunil G",
      "daysBetweenCommits": 0.41,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,419 +1,419 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     if (queueInfo \u003d\u003d null) {\n       throw new IllegalArgumentException(String\n           .format(\"Queue %s not present in scheduler configuration.\",\n               this.amQueue));\n     }\n \n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n     } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n     List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n     setAMResourceCapability(appContext, profiles, resourceTypes);\n     setContainerResources(profiles, resourceTypes);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (applicationTags !\u003d null) {\n       tags.addAll(applicationTags);\n     }\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\n \n     // Process local files for localization\n     // Here we just upload the files, the AM\n     // will set up localization later.\n     StringBuilder localizableFiles \u003d new StringBuilder();\n     filesToLocalize.stream().forEach(path -\u003e {\n       File f \u003d new File(path);\n \n       if (!f.exists()) {\n         throw new UncheckedIOException(\n             new IOException(path + \" does not exist\"));\n       }\n \n       if (!f.canRead()) {\n         throw new UncheckedIOException(\n             new IOException(path + \" cannot be read\"));\n       }\n \n       if (f.isDirectory()) {\n         throw new UncheckedIOException(\n           new IOException(path + \" is a directory\"));\n       }\n \n       try {\n         String fileName \u003d f.getName();\n         uploadFile(fs, path, fileName, appId.toString());\n         if (localizableFiles.length() \u003d\u003d 0) {\n           localizableFiles.append(fileName);\n         } else {\n           localizableFiles.append(\",\").append(fileName);\n         }\n       } catch (IOException e) {\n         throw new UncheckedIOException(\"Cannot upload file: \" + path, e);\n       }\n     });\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           ApplicationMaster.getRelativePath(appName,\n               appId.toString(),\n               SCRIPT_PATH);\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n-      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n-      classPathEnv.append(c.trim());\n+      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR)\n+          .append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n-      classPathEnv.append(\u0027:\u0027);\n-      classPathEnv.append(System.getProperty(\"java.class.path\"));\n+      classPathEnv.append(\u0027:\u0027)\n+          .append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     // Need extra quote here because JAVA_HOME might contain space on Windows,\n     // e.g. C:/Program Files/Java...\n     vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     if (containerType !\u003d null) {\n       vargs.add(\"--container_type \" + String.valueOf(containerType));\n     }\n     if (autoPromoteContainers) {\n       vargs.add(\"--promote_opportunistic_after_start\");\n     }\n     if (enforceExecType) {\n       vargs.add(\"--enforce_execution_type\");\n     }\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n     if (!containerResources.isEmpty()) {\n       Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n       vargs.add(\"--container_resources \" + joiner.join(containerResources));\n     }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n       // Encode the spec to avoid passing special chars via shell arguments.\n       String encodedSpec \u003d Base64.getEncoder()\n           .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n       LOG.info(\"Encode placement spec: \" + encodedSpec);\n       vargs.add(\"--placement_spec \" + encodedSpec);\n     }\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     if (keepContainers) {\n       vargs.add(\"--keep_containers_across_application_attempts\");\n     }\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n     if (localizableFiles.length() \u003e 0) {\n       vargs.add(\"--localized_files \" + localizableFiles.toString());\n     }\n     vargs.add(\"--appname \" + appName);\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     Credentials rmCredentials \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       rmCredentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, rmCredentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n     }\n \n     // Add the docker client config credentials if supplied.\n     Credentials dockerCredentials \u003d null;\n     if (dockerClientConfig !\u003d null) {\n       dockerCredentials \u003d\n           DockerClientConfigHandler.readCredentialsFromConfigFile(\n               new Path(dockerClientConfig), conf, appId.toString());\n     }\n \n     if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       if (rmCredentials !\u003d null) {\n         rmCredentials.writeTokenStorageToStream(dob);\n       }\n       if (dockerCredentials !\u003d null) {\n         dockerCredentials.writeTokenStorageToStream(dob);\n       }\n       ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(tokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    if (queueInfo \u003d\u003d null) {\n      throw new IllegalArgumentException(String\n          .format(\"Queue %s not present in scheduler configuration.\",\n              this.amQueue));\n    }\n\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n    setAMResourceCapability(appContext, profiles, resourceTypes);\n    setContainerResources(profiles, resourceTypes);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (applicationTags !\u003d null) {\n      tags.addAll(applicationTags);\n    }\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\n\n    // Process local files for localization\n    // Here we just upload the files, the AM\n    // will set up localization later.\n    StringBuilder localizableFiles \u003d new StringBuilder();\n    filesToLocalize.stream().forEach(path -\u003e {\n      File f \u003d new File(path);\n\n      if (!f.exists()) {\n        throw new UncheckedIOException(\n            new IOException(path + \" does not exist\"));\n      }\n\n      if (!f.canRead()) {\n        throw new UncheckedIOException(\n            new IOException(path + \" cannot be read\"));\n      }\n\n      if (f.isDirectory()) {\n        throw new UncheckedIOException(\n          new IOException(path + \" is a directory\"));\n      }\n\n      try {\n        String fileName \u003d f.getName();\n        uploadFile(fs, path, fileName, appId.toString());\n        if (localizableFiles.length() \u003d\u003d 0) {\n          localizableFiles.append(fileName);\n        } else {\n          localizableFiles.append(\",\").append(fileName);\n        }\n      } catch (IOException e) {\n        throw new UncheckedIOException(\"Cannot upload file: \" + path, e);\n      }\n    });\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          ApplicationMaster.getRelativePath(appName,\n              appId.toString(),\n              SCRIPT_PATH);\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR)\n          .append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027)\n          .append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    // Need extra quote here because JAVA_HOME might contain space on Windows,\n    // e.g. C:/Program Files/Java...\n    vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerType !\u003d null) {\n      vargs.add(\"--container_type \" + String.valueOf(containerType));\n    }\n    if (autoPromoteContainers) {\n      vargs.add(\"--promote_opportunistic_after_start\");\n    }\n    if (enforceExecType) {\n      vargs.add(\"--enforce_execution_type\");\n    }\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (!containerResources.isEmpty()) {\n      Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n      vargs.add(\"--container_resources \" + joiner.join(containerResources));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n      // Encode the spec to avoid passing special chars via shell arguments.\n      String encodedSpec \u003d Base64.getEncoder()\n          .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n      LOG.info(\"Encode placement spec: \" + encodedSpec);\n      vargs.add(\"--placement_spec \" + encodedSpec);\n    }\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    if (keepContainers) {\n      vargs.add(\"--keep_containers_across_application_attempts\");\n    }\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n    if (localizableFiles.length() \u003e 0) {\n      vargs.add(\"--localized_files \" + localizableFiles.toString());\n    }\n    vargs.add(\"--appname \" + appName);\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    Credentials rmCredentials \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      rmCredentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, rmCredentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n    }\n\n    // Add the docker client config credentials if supplied.\n    Credentials dockerCredentials \u003d null;\n    if (dockerClientConfig !\u003d null) {\n      dockerCredentials \u003d\n          DockerClientConfigHandler.readCredentialsFromConfigFile(\n              new Path(dockerClientConfig), conf, appId.toString());\n    }\n\n    if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      if (rmCredentials !\u003d null) {\n        rmCredentials.writeTokenStorageToStream(dob);\n      }\n      if (dockerCredentials !\u003d null) {\n        dockerCredentials.writeTokenStorageToStream(dob);\n      }\n      ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(tokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "ba38db4f5b7d8a1432a9a1b4adaa5c1545218799": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9257. Distributed Shell client throws a NPE for a non-existent queue. Contributed by Charan Hebri.\n",
      "commitDate": "05/02/19 12:11 AM",
      "commitName": "ba38db4f5b7d8a1432a9a1b4adaa5c1545218799",
      "commitAuthor": "Sunil G",
      "commitDateOld": "31/01/19 11:24 AM",
      "commitNameOld": "f738b397ae021c9be900e4ec51ab55cd69b075e0",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 4.53,
      "commitsBetweenForRepo": 24,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,413 +1,419 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n+    if (queueInfo \u003d\u003d null) {\n+      throw new IllegalArgumentException(String\n+          .format(\"Queue %s not present in scheduler configuration.\",\n+              this.amQueue));\n+    }\n+\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n     } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n     List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n     setAMResourceCapability(appContext, profiles, resourceTypes);\n     setContainerResources(profiles, resourceTypes);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (applicationTags !\u003d null) {\n       tags.addAll(applicationTags);\n     }\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\n \n     // Process local files for localization\n     // Here we just upload the files, the AM\n     // will set up localization later.\n     StringBuilder localizableFiles \u003d new StringBuilder();\n     filesToLocalize.stream().forEach(path -\u003e {\n       File f \u003d new File(path);\n \n       if (!f.exists()) {\n         throw new UncheckedIOException(\n             new IOException(path + \" does not exist\"));\n       }\n \n       if (!f.canRead()) {\n         throw new UncheckedIOException(\n             new IOException(path + \" cannot be read\"));\n       }\n \n       if (f.isDirectory()) {\n         throw new UncheckedIOException(\n           new IOException(path + \" is a directory\"));\n       }\n \n       try {\n         String fileName \u003d f.getName();\n         uploadFile(fs, path, fileName, appId.toString());\n         if (localizableFiles.length() \u003d\u003d 0) {\n           localizableFiles.append(fileName);\n         } else {\n           localizableFiles.append(\",\").append(fileName);\n         }\n       } catch (IOException e) {\n         throw new UncheckedIOException(\"Cannot upload file: \" + path, e);\n       }\n     });\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           ApplicationMaster.getRelativePath(appName,\n               appId.toString(),\n               SCRIPT_PATH);\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     // Need extra quote here because JAVA_HOME might contain space on Windows,\n     // e.g. C:/Program Files/Java...\n     vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     if (containerType !\u003d null) {\n       vargs.add(\"--container_type \" + String.valueOf(containerType));\n     }\n     if (autoPromoteContainers) {\n       vargs.add(\"--promote_opportunistic_after_start\");\n     }\n     if (enforceExecType) {\n       vargs.add(\"--enforce_execution_type\");\n     }\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n     if (!containerResources.isEmpty()) {\n       Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n       vargs.add(\"--container_resources \" + joiner.join(containerResources));\n     }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n       // Encode the spec to avoid passing special chars via shell arguments.\n       String encodedSpec \u003d Base64.getEncoder()\n           .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n       LOG.info(\"Encode placement spec: \" + encodedSpec);\n       vargs.add(\"--placement_spec \" + encodedSpec);\n     }\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     if (keepContainers) {\n       vargs.add(\"--keep_containers_across_application_attempts\");\n     }\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n     if (localizableFiles.length() \u003e 0) {\n       vargs.add(\"--localized_files \" + localizableFiles.toString());\n     }\n     vargs.add(\"--appname \" + appName);\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     Credentials rmCredentials \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       rmCredentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, rmCredentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n     }\n \n     // Add the docker client config credentials if supplied.\n     Credentials dockerCredentials \u003d null;\n     if (dockerClientConfig !\u003d null) {\n       dockerCredentials \u003d\n           DockerClientConfigHandler.readCredentialsFromConfigFile(\n               new Path(dockerClientConfig), conf, appId.toString());\n     }\n \n     if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       if (rmCredentials !\u003d null) {\n         rmCredentials.writeTokenStorageToStream(dob);\n       }\n       if (dockerCredentials !\u003d null) {\n         dockerCredentials.writeTokenStorageToStream(dob);\n       }\n       ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(tokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    if (queueInfo \u003d\u003d null) {\n      throw new IllegalArgumentException(String\n          .format(\"Queue %s not present in scheduler configuration.\",\n              this.amQueue));\n    }\n\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n    setAMResourceCapability(appContext, profiles, resourceTypes);\n    setContainerResources(profiles, resourceTypes);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (applicationTags !\u003d null) {\n      tags.addAll(applicationTags);\n    }\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\n\n    // Process local files for localization\n    // Here we just upload the files, the AM\n    // will set up localization later.\n    StringBuilder localizableFiles \u003d new StringBuilder();\n    filesToLocalize.stream().forEach(path -\u003e {\n      File f \u003d new File(path);\n\n      if (!f.exists()) {\n        throw new UncheckedIOException(\n            new IOException(path + \" does not exist\"));\n      }\n\n      if (!f.canRead()) {\n        throw new UncheckedIOException(\n            new IOException(path + \" cannot be read\"));\n      }\n\n      if (f.isDirectory()) {\n        throw new UncheckedIOException(\n          new IOException(path + \" is a directory\"));\n      }\n\n      try {\n        String fileName \u003d f.getName();\n        uploadFile(fs, path, fileName, appId.toString());\n        if (localizableFiles.length() \u003d\u003d 0) {\n          localizableFiles.append(fileName);\n        } else {\n          localizableFiles.append(\",\").append(fileName);\n        }\n      } catch (IOException e) {\n        throw new UncheckedIOException(\"Cannot upload file: \" + path, e);\n      }\n    });\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          ApplicationMaster.getRelativePath(appName,\n              appId.toString(),\n              SCRIPT_PATH);\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    // Need extra quote here because JAVA_HOME might contain space on Windows,\n    // e.g. C:/Program Files/Java...\n    vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerType !\u003d null) {\n      vargs.add(\"--container_type \" + String.valueOf(containerType));\n    }\n    if (autoPromoteContainers) {\n      vargs.add(\"--promote_opportunistic_after_start\");\n    }\n    if (enforceExecType) {\n      vargs.add(\"--enforce_execution_type\");\n    }\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (!containerResources.isEmpty()) {\n      Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n      vargs.add(\"--container_resources \" + joiner.join(containerResources));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n      // Encode the spec to avoid passing special chars via shell arguments.\n      String encodedSpec \u003d Base64.getEncoder()\n          .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n      LOG.info(\"Encode placement spec: \" + encodedSpec);\n      vargs.add(\"--placement_spec \" + encodedSpec);\n    }\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    if (keepContainers) {\n      vargs.add(\"--keep_containers_across_application_attempts\");\n    }\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n    if (localizableFiles.length() \u003e 0) {\n      vargs.add(\"--localized_files \" + localizableFiles.toString());\n    }\n    vargs.add(\"--appname \" + appName);\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    Credentials rmCredentials \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      rmCredentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, rmCredentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n    }\n\n    // Add the docker client config credentials if supplied.\n    Credentials dockerCredentials \u003d null;\n    if (dockerClientConfig !\u003d null) {\n      dockerCredentials \u003d\n          DockerClientConfigHandler.readCredentialsFromConfigFile(\n              new Path(dockerClientConfig), conf, appId.toString());\n    }\n\n    if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      if (rmCredentials !\u003d null) {\n        rmCredentials.writeTokenStorageToStream(dob);\n      }\n      if (dockerCredentials !\u003d null) {\n        dockerCredentials.writeTokenStorageToStream(dob);\n      }\n      ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(tokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "f738b397ae021c9be900e4ec51ab55cd69b075e0": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9191. Add cli option in DS to support enforceExecutionType in resource requests. Contributed by Abhishek Modi.\n",
      "commitDate": "31/01/19 11:24 AM",
      "commitName": "f738b397ae021c9be900e4ec51ab55cd69b075e0",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "11/12/18 2:13 PM",
      "commitNameOld": "fb55e5201e5b2ff40e1b757a9c5bf23c5d8aec93",
      "commitAuthorOld": "Haibo Chen",
      "daysBetweenCommits": 50.88,
      "commitsBetweenForRepo": 338,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,410 +1,413 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n     } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n     List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n     setAMResourceCapability(appContext, profiles, resourceTypes);\n     setContainerResources(profiles, resourceTypes);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (applicationTags !\u003d null) {\n       tags.addAll(applicationTags);\n     }\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\n \n     // Process local files for localization\n     // Here we just upload the files, the AM\n     // will set up localization later.\n     StringBuilder localizableFiles \u003d new StringBuilder();\n     filesToLocalize.stream().forEach(path -\u003e {\n       File f \u003d new File(path);\n \n       if (!f.exists()) {\n         throw new UncheckedIOException(\n             new IOException(path + \" does not exist\"));\n       }\n \n       if (!f.canRead()) {\n         throw new UncheckedIOException(\n             new IOException(path + \" cannot be read\"));\n       }\n \n       if (f.isDirectory()) {\n         throw new UncheckedIOException(\n           new IOException(path + \" is a directory\"));\n       }\n \n       try {\n         String fileName \u003d f.getName();\n         uploadFile(fs, path, fileName, appId.toString());\n         if (localizableFiles.length() \u003d\u003d 0) {\n           localizableFiles.append(fileName);\n         } else {\n           localizableFiles.append(\",\").append(fileName);\n         }\n       } catch (IOException e) {\n         throw new UncheckedIOException(\"Cannot upload file: \" + path, e);\n       }\n     });\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           ApplicationMaster.getRelativePath(appName,\n               appId.toString(),\n               SCRIPT_PATH);\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     // Need extra quote here because JAVA_HOME might contain space on Windows,\n     // e.g. C:/Program Files/Java...\n     vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     if (containerType !\u003d null) {\n       vargs.add(\"--container_type \" + String.valueOf(containerType));\n     }\n     if (autoPromoteContainers) {\n       vargs.add(\"--promote_opportunistic_after_start\");\n     }\n+    if (enforceExecType) {\n+      vargs.add(\"--enforce_execution_type\");\n+    }\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n     if (!containerResources.isEmpty()) {\n       Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n       vargs.add(\"--container_resources \" + joiner.join(containerResources));\n     }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n       // Encode the spec to avoid passing special chars via shell arguments.\n       String encodedSpec \u003d Base64.getEncoder()\n           .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n       LOG.info(\"Encode placement spec: \" + encodedSpec);\n       vargs.add(\"--placement_spec \" + encodedSpec);\n     }\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     if (keepContainers) {\n       vargs.add(\"--keep_containers_across_application_attempts\");\n     }\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n     if (localizableFiles.length() \u003e 0) {\n       vargs.add(\"--localized_files \" + localizableFiles.toString());\n     }\n     vargs.add(\"--appname \" + appName);\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     Credentials rmCredentials \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       rmCredentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, rmCredentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n     }\n \n     // Add the docker client config credentials if supplied.\n     Credentials dockerCredentials \u003d null;\n     if (dockerClientConfig !\u003d null) {\n       dockerCredentials \u003d\n           DockerClientConfigHandler.readCredentialsFromConfigFile(\n               new Path(dockerClientConfig), conf, appId.toString());\n     }\n \n     if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       if (rmCredentials !\u003d null) {\n         rmCredentials.writeTokenStorageToStream(dob);\n       }\n       if (dockerCredentials !\u003d null) {\n         dockerCredentials.writeTokenStorageToStream(dob);\n       }\n       ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(tokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n    setAMResourceCapability(appContext, profiles, resourceTypes);\n    setContainerResources(profiles, resourceTypes);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (applicationTags !\u003d null) {\n      tags.addAll(applicationTags);\n    }\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\n\n    // Process local files for localization\n    // Here we just upload the files, the AM\n    // will set up localization later.\n    StringBuilder localizableFiles \u003d new StringBuilder();\n    filesToLocalize.stream().forEach(path -\u003e {\n      File f \u003d new File(path);\n\n      if (!f.exists()) {\n        throw new UncheckedIOException(\n            new IOException(path + \" does not exist\"));\n      }\n\n      if (!f.canRead()) {\n        throw new UncheckedIOException(\n            new IOException(path + \" cannot be read\"));\n      }\n\n      if (f.isDirectory()) {\n        throw new UncheckedIOException(\n          new IOException(path + \" is a directory\"));\n      }\n\n      try {\n        String fileName \u003d f.getName();\n        uploadFile(fs, path, fileName, appId.toString());\n        if (localizableFiles.length() \u003d\u003d 0) {\n          localizableFiles.append(fileName);\n        } else {\n          localizableFiles.append(\",\").append(fileName);\n        }\n      } catch (IOException e) {\n        throw new UncheckedIOException(\"Cannot upload file: \" + path, e);\n      }\n    });\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          ApplicationMaster.getRelativePath(appName,\n              appId.toString(),\n              SCRIPT_PATH);\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    // Need extra quote here because JAVA_HOME might contain space on Windows,\n    // e.g. C:/Program Files/Java...\n    vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerType !\u003d null) {\n      vargs.add(\"--container_type \" + String.valueOf(containerType));\n    }\n    if (autoPromoteContainers) {\n      vargs.add(\"--promote_opportunistic_after_start\");\n    }\n    if (enforceExecType) {\n      vargs.add(\"--enforce_execution_type\");\n    }\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (!containerResources.isEmpty()) {\n      Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n      vargs.add(\"--container_resources \" + joiner.join(containerResources));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n      // Encode the spec to avoid passing special chars via shell arguments.\n      String encodedSpec \u003d Base64.getEncoder()\n          .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n      LOG.info(\"Encode placement spec: \" + encodedSpec);\n      vargs.add(\"--placement_spec \" + encodedSpec);\n    }\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    if (keepContainers) {\n      vargs.add(\"--keep_containers_across_application_attempts\");\n    }\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n    if (localizableFiles.length() \u003e 0) {\n      vargs.add(\"--localized_files \" + localizableFiles.toString());\n    }\n    vargs.add(\"--appname \" + appName);\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    Credentials rmCredentials \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      rmCredentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, rmCredentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n    }\n\n    // Add the docker client config credentials if supplied.\n    Credentials dockerCredentials \u003d null;\n    if (dockerClientConfig !\u003d null) {\n      dockerCredentials \u003d\n          DockerClientConfigHandler.readCredentialsFromConfigFile(\n              new Path(dockerClientConfig), conf, appId.toString());\n    }\n\n    if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      if (rmCredentials !\u003d null) {\n        rmCredentials.writeTokenStorageToStream(dob);\n      }\n      if (dockerCredentials !\u003d null) {\n        dockerCredentials.writeTokenStorageToStream(dob);\n      }\n      ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(tokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "fb55e5201e5b2ff40e1b757a9c5bf23c5d8aec93": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9008. Extend YARN distributed shell with file localization feature. (Contributed by Peter Bacsko)\n",
      "commitDate": "11/12/18 2:13 PM",
      "commitName": "fb55e5201e5b2ff40e1b757a9c5bf23c5d8aec93",
      "commitAuthor": "Haibo Chen",
      "commitDateOld": "12/09/18 3:31 AM",
      "commitNameOld": "67ae81f0e0ac7f107261ee15f2eb4d189e3b1983",
      "commitAuthorOld": "Naganarasimha",
      "daysBetweenCommits": 90.49,
      "commitsBetweenForRepo": 785,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,369 +1,410 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n     } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n-    }\t\t\t\t\n+    }\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n     List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n     setAMResourceCapability(appContext, profiles, resourceTypes);\n     setContainerResources(profiles, resourceTypes);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (applicationTags !\u003d null) {\n       tags.addAll(applicationTags);\n     }\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n-    }\t\t\t\n+    }\n+\n+    // Process local files for localization\n+    // Here we just upload the files, the AM\n+    // will set up localization later.\n+    StringBuilder localizableFiles \u003d new StringBuilder();\n+    filesToLocalize.stream().forEach(path -\u003e {\n+      File f \u003d new File(path);\n+\n+      if (!f.exists()) {\n+        throw new UncheckedIOException(\n+            new IOException(path + \" does not exist\"));\n+      }\n+\n+      if (!f.canRead()) {\n+        throw new UncheckedIOException(\n+            new IOException(path + \" cannot be read\"));\n+      }\n+\n+      if (f.isDirectory()) {\n+        throw new UncheckedIOException(\n+          new IOException(path + \" is a directory\"));\n+      }\n+\n+      try {\n+        String fileName \u003d f.getName();\n+        uploadFile(fs, path, fileName, appId.toString());\n+        if (localizableFiles.length() \u003d\u003d 0) {\n+          localizableFiles.append(fileName);\n+        } else {\n+          localizableFiles.append(\",\").append(fileName);\n+        }\n+      } catch (IOException e) {\n+        throw new UncheckedIOException(\"Cannot upload file: \" + path, e);\n+      }\n+    });\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n-          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n+          ApplicationMaster.getRelativePath(appName,\n+              appId.toString(),\n+              SCRIPT_PATH);\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     // Need extra quote here because JAVA_HOME might contain space on Windows,\n     // e.g. C:/Program Files/Java...\n     vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     if (containerType !\u003d null) {\n       vargs.add(\"--container_type \" + String.valueOf(containerType));\n     }\n     if (autoPromoteContainers) {\n       vargs.add(\"--promote_opportunistic_after_start\");\n     }\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n     if (!containerResources.isEmpty()) {\n       Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n       vargs.add(\"--container_resources \" + joiner.join(containerResources));\n     }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n       // Encode the spec to avoid passing special chars via shell arguments.\n       String encodedSpec \u003d Base64.getEncoder()\n           .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n       LOG.info(\"Encode placement spec: \" + encodedSpec);\n       vargs.add(\"--placement_spec \" + encodedSpec);\n     }\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     if (keepContainers) {\n       vargs.add(\"--keep_containers_across_application_attempts\");\n     }\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n+    if (localizableFiles.length() \u003e 0) {\n+      vargs.add(\"--localized_files \" + localizableFiles.toString());\n+    }\n+    vargs.add(\"--appname \" + appName);\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     Credentials rmCredentials \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       rmCredentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, rmCredentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n     }\n \n     // Add the docker client config credentials if supplied.\n     Credentials dockerCredentials \u003d null;\n     if (dockerClientConfig !\u003d null) {\n       dockerCredentials \u003d\n           DockerClientConfigHandler.readCredentialsFromConfigFile(\n               new Path(dockerClientConfig), conf, appId.toString());\n     }\n \n     if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       if (rmCredentials !\u003d null) {\n         rmCredentials.writeTokenStorageToStream(dob);\n       }\n       if (dockerCredentials !\u003d null) {\n         dockerCredentials.writeTokenStorageToStream(dob);\n       }\n       ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(tokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n    setAMResourceCapability(appContext, profiles, resourceTypes);\n    setContainerResources(profiles, resourceTypes);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (applicationTags !\u003d null) {\n      tags.addAll(applicationTags);\n    }\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\n\n    // Process local files for localization\n    // Here we just upload the files, the AM\n    // will set up localization later.\n    StringBuilder localizableFiles \u003d new StringBuilder();\n    filesToLocalize.stream().forEach(path -\u003e {\n      File f \u003d new File(path);\n\n      if (!f.exists()) {\n        throw new UncheckedIOException(\n            new IOException(path + \" does not exist\"));\n      }\n\n      if (!f.canRead()) {\n        throw new UncheckedIOException(\n            new IOException(path + \" cannot be read\"));\n      }\n\n      if (f.isDirectory()) {\n        throw new UncheckedIOException(\n          new IOException(path + \" is a directory\"));\n      }\n\n      try {\n        String fileName \u003d f.getName();\n        uploadFile(fs, path, fileName, appId.toString());\n        if (localizableFiles.length() \u003d\u003d 0) {\n          localizableFiles.append(fileName);\n        } else {\n          localizableFiles.append(\",\").append(fileName);\n        }\n      } catch (IOException e) {\n        throw new UncheckedIOException(\"Cannot upload file: \" + path, e);\n      }\n    });\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          ApplicationMaster.getRelativePath(appName,\n              appId.toString(),\n              SCRIPT_PATH);\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    // Need extra quote here because JAVA_HOME might contain space on Windows,\n    // e.g. C:/Program Files/Java...\n    vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerType !\u003d null) {\n      vargs.add(\"--container_type \" + String.valueOf(containerType));\n    }\n    if (autoPromoteContainers) {\n      vargs.add(\"--promote_opportunistic_after_start\");\n    }\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (!containerResources.isEmpty()) {\n      Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n      vargs.add(\"--container_resources \" + joiner.join(containerResources));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n      // Encode the spec to avoid passing special chars via shell arguments.\n      String encodedSpec \u003d Base64.getEncoder()\n          .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n      LOG.info(\"Encode placement spec: \" + encodedSpec);\n      vargs.add(\"--placement_spec \" + encodedSpec);\n    }\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    if (keepContainers) {\n      vargs.add(\"--keep_containers_across_application_attempts\");\n    }\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n    if (localizableFiles.length() \u003e 0) {\n      vargs.add(\"--localized_files \" + localizableFiles.toString());\n    }\n    vargs.add(\"--appname \" + appName);\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    Credentials rmCredentials \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      rmCredentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, rmCredentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n    }\n\n    // Add the docker client config credentials if supplied.\n    Credentials dockerCredentials \u003d null;\n    if (dockerClientConfig !\u003d null) {\n      dockerCredentials \u003d\n          DockerClientConfigHandler.readCredentialsFromConfigFile(\n              new Path(dockerClientConfig), conf, appId.toString());\n    }\n\n    if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      if (rmCredentials !\u003d null) {\n        rmCredentials.writeTokenStorageToStream(dob);\n      }\n      if (dockerCredentials !\u003d null) {\n        dockerCredentials.writeTokenStorageToStream(dob);\n      }\n      ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(tokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "16333782c17d6c459019cf14682e5feee9968181": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15731. TestDistributedShell fails on Windows. Contributed by Botong Huang.\n",
      "commitDate": "07/09/18 2:19 PM",
      "commitName": "16333782c17d6c459019cf14682e5feee9968181",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "12/06/18 8:35 AM",
      "commitNameOld": "652bcbb3e4950758e61ce123ecc1798ae2b60a7f",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 87.24,
      "commitsBetweenForRepo": 608,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,367 +1,369 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n     } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n     List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n     setAMResourceCapability(appContext, profiles, resourceTypes);\n     setContainerResources(profiles, resourceTypes);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (applicationTags !\u003d null) {\n       tags.addAll(applicationTags);\n     }\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n-    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n+    // Need extra quote here because JAVA_HOME might contain space on Windows,\n+    // e.g. C:/Program Files/Java...\n+    vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     if (containerType !\u003d null) {\n       vargs.add(\"--container_type \" + String.valueOf(containerType));\n     }\n     if (autoPromoteContainers) {\n       vargs.add(\"--promote_opportunistic_after_start\");\n     }\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n     if (!containerResources.isEmpty()) {\n       Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n       vargs.add(\"--container_resources \" + joiner.join(containerResources));\n     }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n       // Encode the spec to avoid passing special chars via shell arguments.\n       String encodedSpec \u003d Base64.getEncoder()\n           .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n       LOG.info(\"Encode placement spec: \" + encodedSpec);\n       vargs.add(\"--placement_spec \" + encodedSpec);\n     }\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     if (keepContainers) {\n       vargs.add(\"--keep_containers_across_application_attempts\");\n     }\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     Credentials rmCredentials \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       rmCredentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, rmCredentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n     }\n \n     // Add the docker client config credentials if supplied.\n     Credentials dockerCredentials \u003d null;\n     if (dockerClientConfig !\u003d null) {\n       dockerCredentials \u003d\n           DockerClientConfigHandler.readCredentialsFromConfigFile(\n               new Path(dockerClientConfig), conf, appId.toString());\n     }\n \n     if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       if (rmCredentials !\u003d null) {\n         rmCredentials.writeTokenStorageToStream(dob);\n       }\n       if (dockerCredentials !\u003d null) {\n         dockerCredentials.writeTokenStorageToStream(dob);\n       }\n       ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(tokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n    setAMResourceCapability(appContext, profiles, resourceTypes);\n    setContainerResources(profiles, resourceTypes);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (applicationTags !\u003d null) {\n      tags.addAll(applicationTags);\n    }\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    // Need extra quote here because JAVA_HOME might contain space on Windows,\n    // e.g. C:/Program Files/Java...\n    vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerType !\u003d null) {\n      vargs.add(\"--container_type \" + String.valueOf(containerType));\n    }\n    if (autoPromoteContainers) {\n      vargs.add(\"--promote_opportunistic_after_start\");\n    }\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (!containerResources.isEmpty()) {\n      Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n      vargs.add(\"--container_resources \" + joiner.join(containerResources));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n      // Encode the spec to avoid passing special chars via shell arguments.\n      String encodedSpec \u003d Base64.getEncoder()\n          .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n      LOG.info(\"Encode placement spec: \" + encodedSpec);\n      vargs.add(\"--placement_spec \" + encodedSpec);\n    }\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    if (keepContainers) {\n      vargs.add(\"--keep_containers_across_application_attempts\");\n    }\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    Credentials rmCredentials \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      rmCredentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, rmCredentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n    }\n\n    // Add the docker client config credentials if supplied.\n    Credentials dockerCredentials \u003d null;\n    if (dockerClientConfig !\u003d null) {\n      dockerCredentials \u003d\n          DockerClientConfigHandler.readCredentialsFromConfigFile(\n              new Path(dockerClientConfig), conf, appId.toString());\n    }\n\n    if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      if (rmCredentials !\u003d null) {\n        rmCredentials.writeTokenStorageToStream(dob);\n      }\n      if (dockerCredentials !\u003d null) {\n        dockerCredentials.writeTokenStorageToStream(dob);\n      }\n      ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(tokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "8956e5b8db3059e0872e49f59adc6affc76e2274": {
      "type": "Ybodychange",
      "commitMessage": "YARN-8372. Distributed shell app master should not release containers when shutdown if keep-container is true. (Suma Shivaprasad via wangda)\n\nChange-Id: Ief04d1ca865621f348fba4ac85fa78bc47465904\n",
      "commitDate": "01/06/18 2:49 PM",
      "commitName": "8956e5b8db3059e0872e49f59adc6affc76e2274",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "29/03/18 3:25 AM",
      "commitNameOld": "431076f63751f855ab6036ff85825a8552257b93",
      "commitAuthorOld": "Sunil G",
      "daysBetweenCommits": 64.47,
      "commitsBetweenForRepo": 975,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,363 +1,367 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n     } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n     List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n     setAMResourceCapability(appContext, profiles, resourceTypes);\n     setContainerResources(profiles, resourceTypes);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (applicationTags !\u003d null) {\n       tags.addAll(applicationTags);\n     }\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     if (containerType !\u003d null) {\n       vargs.add(\"--container_type \" + String.valueOf(containerType));\n     }\n     if (autoPromoteContainers) {\n       vargs.add(\"--promote_opportunistic_after_start\");\n     }\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n     if (!containerResources.isEmpty()) {\n       Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n       vargs.add(\"--container_resources \" + joiner.join(containerResources));\n     }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n       // Encode the spec to avoid passing special chars via shell arguments.\n       String encodedSpec \u003d Base64.getEncoder()\n           .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n       LOG.info(\"Encode placement spec: \" + encodedSpec);\n       vargs.add(\"--placement_spec \" + encodedSpec);\n     }\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n+    if (keepContainers) {\n+      vargs.add(\"--keep_containers_across_application_attempts\");\n+    }\n+\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     Credentials rmCredentials \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       rmCredentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, rmCredentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n     }\n \n     // Add the docker client config credentials if supplied.\n     Credentials dockerCredentials \u003d null;\n     if (dockerClientConfig !\u003d null) {\n       dockerCredentials \u003d\n           DockerClientConfigHandler.readCredentialsFromConfigFile(\n               new Path(dockerClientConfig), conf, appId.toString());\n     }\n \n     if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       if (rmCredentials !\u003d null) {\n         rmCredentials.writeTokenStorageToStream(dob);\n       }\n       if (dockerCredentials !\u003d null) {\n         dockerCredentials.writeTokenStorageToStream(dob);\n       }\n       ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(tokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n    setAMResourceCapability(appContext, profiles, resourceTypes);\n    setContainerResources(profiles, resourceTypes);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (applicationTags !\u003d null) {\n      tags.addAll(applicationTags);\n    }\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerType !\u003d null) {\n      vargs.add(\"--container_type \" + String.valueOf(containerType));\n    }\n    if (autoPromoteContainers) {\n      vargs.add(\"--promote_opportunistic_after_start\");\n    }\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (!containerResources.isEmpty()) {\n      Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n      vargs.add(\"--container_resources \" + joiner.join(containerResources));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n      // Encode the spec to avoid passing special chars via shell arguments.\n      String encodedSpec \u003d Base64.getEncoder()\n          .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n      LOG.info(\"Encode placement spec: \" + encodedSpec);\n      vargs.add(\"--placement_spec \" + encodedSpec);\n    }\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    if (keepContainers) {\n      vargs.add(\"--keep_containers_across_application_attempts\");\n    }\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    Credentials rmCredentials \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      rmCredentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, rmCredentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n    }\n\n    // Add the docker client config credentials if supplied.\n    Credentials dockerCredentials \u003d null;\n    if (dockerClientConfig !\u003d null) {\n      dockerCredentials \u003d\n          DockerClientConfigHandler.readCredentialsFromConfigFile(\n              new Path(dockerClientConfig), conf, appId.toString());\n    }\n\n    if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      if (rmCredentials !\u003d null) {\n        rmCredentials.writeTokenStorageToStream(dob);\n      }\n      if (dockerCredentials !\u003d null) {\n        dockerCredentials.writeTokenStorageToStream(dob);\n      }\n      ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(tokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "431076f63751f855ab6036ff85825a8552257b93": {
      "type": "Ybodychange",
      "commitMessage": "YARN-8076. Support to specify application tags in distributed shell. Contributed by Weiwei Yang.\n",
      "commitDate": "29/03/18 3:25 AM",
      "commitName": "431076f63751f855ab6036ff85825a8552257b93",
      "commitAuthor": "Sunil G",
      "commitDateOld": "13/03/18 5:55 PM",
      "commitNameOld": "a5b27b3c678ad2f5cb8dbfa1b60ef5cd365f8bde",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 15.4,
      "commitsBetweenForRepo": 234,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,360 +1,363 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n     } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n     List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n     setAMResourceCapability(appContext, profiles, resourceTypes);\n     setContainerResources(profiles, resourceTypes);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n+    if (applicationTags !\u003d null) {\n+      tags.addAll(applicationTags);\n+    }\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     if (containerType !\u003d null) {\n       vargs.add(\"--container_type \" + String.valueOf(containerType));\n     }\n     if (autoPromoteContainers) {\n       vargs.add(\"--promote_opportunistic_after_start\");\n     }\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n     if (!containerResources.isEmpty()) {\n       Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n       vargs.add(\"--container_resources \" + joiner.join(containerResources));\n     }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n       // Encode the spec to avoid passing special chars via shell arguments.\n       String encodedSpec \u003d Base64.getEncoder()\n           .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n       LOG.info(\"Encode placement spec: \" + encodedSpec);\n       vargs.add(\"--placement_spec \" + encodedSpec);\n     }\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     Credentials rmCredentials \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       rmCredentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, rmCredentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n     }\n \n     // Add the docker client config credentials if supplied.\n     Credentials dockerCredentials \u003d null;\n     if (dockerClientConfig !\u003d null) {\n       dockerCredentials \u003d\n           DockerClientConfigHandler.readCredentialsFromConfigFile(\n               new Path(dockerClientConfig), conf, appId.toString());\n     }\n \n     if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       if (rmCredentials !\u003d null) {\n         rmCredentials.writeTokenStorageToStream(dob);\n       }\n       if (dockerCredentials !\u003d null) {\n         dockerCredentials.writeTokenStorageToStream(dob);\n       }\n       ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(tokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n    setAMResourceCapability(appContext, profiles, resourceTypes);\n    setContainerResources(profiles, resourceTypes);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (applicationTags !\u003d null) {\n      tags.addAll(applicationTags);\n    }\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerType !\u003d null) {\n      vargs.add(\"--container_type \" + String.valueOf(containerType));\n    }\n    if (autoPromoteContainers) {\n      vargs.add(\"--promote_opportunistic_after_start\");\n    }\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (!containerResources.isEmpty()) {\n      Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n      vargs.add(\"--container_resources \" + joiner.join(containerResources));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n      // Encode the spec to avoid passing special chars via shell arguments.\n      String encodedSpec \u003d Base64.getEncoder()\n          .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n      LOG.info(\"Encode placement spec: \" + encodedSpec);\n      vargs.add(\"--placement_spec \" + encodedSpec);\n    }\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    Credentials rmCredentials \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      rmCredentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, rmCredentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n    }\n\n    // Add the docker client config credentials if supplied.\n    Credentials dockerCredentials \u003d null;\n    if (dockerClientConfig !\u003d null) {\n      dockerCredentials \u003d\n          DockerClientConfigHandler.readCredentialsFromConfigFile(\n              new Path(dockerClientConfig), conf, appId.toString());\n    }\n\n    if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      if (rmCredentials !\u003d null) {\n        rmCredentials.writeTokenStorageToStream(dob);\n      }\n      if (dockerCredentials !\u003d null) {\n        dockerCredentials.writeTokenStorageToStream(dob);\n      }\n      ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(tokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "a08c048832d68c203fbdfce8d9f0e7dcccb02a55": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7838. Support AND/OR constraints in Distributed Shell. Contributed by Weiwei Yang.\n",
      "commitDate": "10/02/18 10:20 PM",
      "commitName": "a08c048832d68c203fbdfce8d9f0e7dcccb02a55",
      "commitAuthor": "Weiwei Yang",
      "commitDateOld": "08/02/18 11:35 AM",
      "commitNameOld": "eb2449d5398e9ac869bc088e10d838a7f13deac0",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 2.45,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,356 +1,360 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n     } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n     List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n     setAMResourceCapability(appContext, profiles, resourceTypes);\n     setContainerResources(profiles, resourceTypes);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     if (containerType !\u003d null) {\n       vargs.add(\"--container_type \" + String.valueOf(containerType));\n     }\n     if (autoPromoteContainers) {\n       vargs.add(\"--promote_opportunistic_after_start\");\n     }\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n     if (!containerResources.isEmpty()) {\n       Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n       vargs.add(\"--container_resources \" + joiner.join(containerResources));\n     }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n-      vargs.add(\"--placement_spec \" + placementSpec);\n+      // Encode the spec to avoid passing special chars via shell arguments.\n+      String encodedSpec \u003d Base64.getEncoder()\n+          .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n+      LOG.info(\"Encode placement spec: \" + encodedSpec);\n+      vargs.add(\"--placement_spec \" + encodedSpec);\n     }\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     Credentials rmCredentials \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       rmCredentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, rmCredentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n     }\n \n     // Add the docker client config credentials if supplied.\n     Credentials dockerCredentials \u003d null;\n     if (dockerClientConfig !\u003d null) {\n       dockerCredentials \u003d\n           DockerClientConfigHandler.readCredentialsFromConfigFile(\n               new Path(dockerClientConfig), conf, appId.toString());\n     }\n \n     if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       if (rmCredentials !\u003d null) {\n         rmCredentials.writeTokenStorageToStream(dob);\n       }\n       if (dockerCredentials !\u003d null) {\n         dockerCredentials.writeTokenStorageToStream(dob);\n       }\n       ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(tokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n    setAMResourceCapability(appContext, profiles, resourceTypes);\n    setContainerResources(profiles, resourceTypes);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerType !\u003d null) {\n      vargs.add(\"--container_type \" + String.valueOf(containerType));\n    }\n    if (autoPromoteContainers) {\n      vargs.add(\"--promote_opportunistic_after_start\");\n    }\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (!containerResources.isEmpty()) {\n      Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n      vargs.add(\"--container_resources \" + joiner.join(containerResources));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n      // Encode the spec to avoid passing special chars via shell arguments.\n      String encodedSpec \u003d Base64.getEncoder()\n          .encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\n      LOG.info(\"Encode placement spec: \" + encodedSpec);\n      vargs.add(\"--placement_spec \" + encodedSpec);\n    }\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    Credentials rmCredentials \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      rmCredentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, rmCredentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n    }\n\n    // Add the docker client config credentials if supplied.\n    Credentials dockerCredentials \u003d null;\n    if (dockerClientConfig !\u003d null) {\n      dockerCredentials \u003d\n          DockerClientConfigHandler.readCredentialsFromConfigFile(\n              new Path(dockerClientConfig), conf, appId.toString());\n    }\n\n    if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      if (rmCredentials !\u003d null) {\n        rmCredentials.writeTokenStorageToStream(dob);\n      }\n      if (dockerCredentials !\u003d null) {\n        dockerCredentials.writeTokenStorageToStream(dob);\n      }\n      ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(tokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "eb2449d5398e9ac869bc088e10d838a7f13deac0": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5428. Allow for specifying the docker client configuration directory. Contributed by Shane Kumpf\n",
      "commitDate": "08/02/18 11:35 AM",
      "commitName": "eb2449d5398e9ac869bc088e10d838a7f13deac0",
      "commitAuthor": "Jian He",
      "commitDateOld": "31/01/18 1:30 AM",
      "commitNameOld": "e60f51299dba360d13aa39f9ab714fdfc666b532",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 8.42,
      "commitsBetweenForRepo": 64,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,339 +1,356 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n     } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n     List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n     setAMResourceCapability(appContext, profiles, resourceTypes);\n     setContainerResources(profiles, resourceTypes);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     if (containerType !\u003d null) {\n       vargs.add(\"--container_type \" + String.valueOf(containerType));\n     }\n     if (autoPromoteContainers) {\n       vargs.add(\"--promote_opportunistic_after_start\");\n     }\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n     if (!containerResources.isEmpty()) {\n       Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n       vargs.add(\"--container_resources \" + joiner.join(containerResources));\n     }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n       vargs.add(\"--placement_spec \" + placementSpec);\n     }\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n+    Credentials rmCredentials \u003d null;\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n-      Credentials credentials \u003d new Credentials();\n+      rmCredentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n-          fs.addDelegationTokens(tokenRenewer, credentials);\n+          fs.addDelegationTokens(tokenRenewer, rmCredentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n+    }\n+\n+    // Add the docker client config credentials if supplied.\n+    Credentials dockerCredentials \u003d null;\n+    if (dockerClientConfig !\u003d null) {\n+      dockerCredentials \u003d\n+          DockerClientConfigHandler.readCredentialsFromConfigFile(\n+              new Path(dockerClientConfig), conf, appId.toString());\n+    }\n+\n+    if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n-      credentials.writeTokenStorageToStream(dob);\n-      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n-      amContainer.setTokens(fsTokens);\n+      if (rmCredentials !\u003d null) {\n+        rmCredentials.writeTokenStorageToStream(dob);\n+      }\n+      if (dockerCredentials !\u003d null) {\n+        dockerCredentials.writeTokenStorageToStream(dob);\n+      }\n+      ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n+      amContainer.setTokens(tokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n    setAMResourceCapability(appContext, profiles, resourceTypes);\n    setContainerResources(profiles, resourceTypes);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerType !\u003d null) {\n      vargs.add(\"--container_type \" + String.valueOf(containerType));\n    }\n    if (autoPromoteContainers) {\n      vargs.add(\"--promote_opportunistic_after_start\");\n    }\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (!containerResources.isEmpty()) {\n      Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n      vargs.add(\"--container_resources \" + joiner.join(containerResources));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n      vargs.add(\"--placement_spec \" + placementSpec);\n    }\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    Credentials rmCredentials \u003d null;\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      rmCredentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, rmCredentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n    }\n\n    // Add the docker client config credentials if supplied.\n    Credentials dockerCredentials \u003d null;\n    if (dockerClientConfig !\u003d null) {\n      dockerCredentials \u003d\n          DockerClientConfigHandler.readCredentialsFromConfigFile(\n              new Path(dockerClientConfig), conf, appId.toString());\n    }\n\n    if (rmCredentials !\u003d null || dockerCredentials !\u003d null) {\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      if (rmCredentials !\u003d null) {\n        rmCredentials.writeTokenStorageToStream(dob);\n      }\n      if (dockerCredentials !\u003d null) {\n        dockerCredentials.writeTokenStorageToStream(dob);\n      }\n      ByteBuffer tokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(tokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "e60f51299dba360d13aa39f9ab714fdfc666b532": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7745. Allow DistributedShell to take a placement specification for containers it wants to launch. (Arun Suresh via wangda)\n\nChange-Id: Ided146d662e944a8a4692e5d6885f23fd9bbcad5\n",
      "commitDate": "31/01/18 1:30 AM",
      "commitName": "e60f51299dba360d13aa39f9ab714fdfc666b532",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "07/01/18 10:29 PM",
      "commitNameOld": "01f3f2167ec20b52a18bc2cf250fb4229cfd2c14",
      "commitAuthorOld": "Sunil G",
      "daysBetweenCommits": 23.13,
      "commitsBetweenForRepo": 147,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,336 +1,339 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n     } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n     List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n     setAMResourceCapability(appContext, profiles, resourceTypes);\n     setContainerResources(profiles, resourceTypes);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     if (containerType !\u003d null) {\n       vargs.add(\"--container_type \" + String.valueOf(containerType));\n     }\n     if (autoPromoteContainers) {\n       vargs.add(\"--promote_opportunistic_after_start\");\n     }\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n     if (!containerResources.isEmpty()) {\n       Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n       vargs.add(\"--container_resources \" + joiner.join(containerResources));\n     }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n+    if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n+      vargs.add(\"--placement_spec \" + placementSpec);\n+    }\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n    setAMResourceCapability(appContext, profiles, resourceTypes);\n    setContainerResources(profiles, resourceTypes);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerType !\u003d null) {\n      vargs.add(\"--container_type \" + String.valueOf(containerType));\n    }\n    if (autoPromoteContainers) {\n      vargs.add(\"--promote_opportunistic_after_start\");\n    }\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (!containerResources.isEmpty()) {\n      Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n      vargs.add(\"--container_resources \" + joiner.join(containerResources));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (placementSpec !\u003d null \u0026\u0026 placementSpec.length() \u003e 0) {\n      vargs.add(\"--placement_spec \" + placementSpec);\n    }\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "01f3f2167ec20b52a18bc2cf250fb4229cfd2c14": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7242. Support to specify values of different resource types in DistributedShell for easier testing. Contributed by Gergely Novák.\n",
      "commitDate": "07/01/18 10:29 PM",
      "commitName": "01f3f2167ec20b52a18bc2cf250fb4229cfd2c14",
      "commitAuthor": "Sunil G",
      "commitDateOld": "17/12/17 6:07 PM",
      "commitNameOld": "928964102029e96406f5482e8900802f38164501",
      "commitAuthorOld": "Weiwei Yang",
      "daysBetweenCommits": 21.18,
      "commitsBetweenForRepo": 67,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,332 +1,336 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n     } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n-    setAMResourceCapability(appContext, amMemory, amVCores, amResourceProfile,\n-        amPriority, profiles);\n-    setContainerResources(containerMemory, containerVirtualCores, profiles);\n+    List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n+    setAMResourceCapability(appContext, profiles, resourceTypes);\n+    setContainerResources(profiles, resourceTypes);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     if (containerType !\u003d null) {\n       vargs.add(\"--container_type \" + String.valueOf(containerType));\n     }\n     if (autoPromoteContainers) {\n       vargs.add(\"--promote_opportunistic_after_start\");\n     }\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n+    if (!containerResources.isEmpty()) {\n+      Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n+      vargs.add(\"--container_resources \" + joiner.join(containerResources));\n+    }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    List\u003cResourceTypeInfo\u003e resourceTypes \u003d yarnClient.getResourceTypeInfo();\n    setAMResourceCapability(appContext, profiles, resourceTypes);\n    setContainerResources(profiles, resourceTypes);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerType !\u003d null) {\n      vargs.add(\"--container_type \" + String.valueOf(containerType));\n    }\n    if (autoPromoteContainers) {\n      vargs.add(\"--promote_opportunistic_after_start\");\n    }\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (!containerResources.isEmpty()) {\n      Joiner.MapJoiner joiner \u003d Joiner.on(\u0027,\u0027).withKeyValueSeparator(\"\u003d\");\n      vargs.add(\"--container_resources \" + joiner.join(containerResources));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "928964102029e96406f5482e8900802f38164501": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7617. Add a flag in distributed shell to automatically PROMOTE opportunistic containers to guaranteed once they are started. Contributed by Weiwei Yang.\n",
      "commitDate": "17/12/17 6:07 PM",
      "commitName": "928964102029e96406f5482e8900802f38164501",
      "commitAuthor": "Weiwei Yang",
      "commitDateOld": "06/12/17 1:52 AM",
      "commitNameOld": "40b0045ebe0752cd3d1d09be00acbabdea983799",
      "commitAuthorOld": "Weiwei Yang",
      "daysBetweenCommits": 11.68,
      "commitsBetweenForRepo": 113,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,329 +1,332 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n     } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n     setAMResourceCapability(appContext, amMemory, amVCores, amResourceProfile,\n         amPriority, profiles);\n     setContainerResources(containerMemory, containerVirtualCores, profiles);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     if (containerType !\u003d null) {\n       vargs.add(\"--container_type \" + String.valueOf(containerType));\n     }\n+    if (autoPromoteContainers) {\n+      vargs.add(\"--promote_opportunistic_after_start\");\n+    }\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    setAMResourceCapability(appContext, amMemory, amVCores, amResourceProfile,\n        amPriority, profiles);\n    setContainerResources(containerMemory, containerVirtualCores, profiles);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerType !\u003d null) {\n      vargs.add(\"--container_type \" + String.valueOf(containerType));\n    }\n    if (autoPromoteContainers) {\n      vargs.add(\"--promote_opportunistic_after_start\");\n    }\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "40b0045ebe0752cd3d1d09be00acbabdea983799": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7610. Extend Distributed Shell to support launching job with opportunistic containers. Contributed by Weiwei Yang.\n",
      "commitDate": "06/12/17 1:52 AM",
      "commitName": "40b0045ebe0752cd3d1d09be00acbabdea983799",
      "commitAuthor": "Weiwei Yang",
      "commitDateOld": "31/10/17 12:36 AM",
      "commitNameOld": "785f1b0d11a3bf0af9851c080ff0acc34539f17b",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 36.09,
      "commitsBetweenForRepo": 295,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,326 +1,329 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n     } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n     setAMResourceCapability(appContext, amMemory, amVCores, amResourceProfile,\n         amPriority, profiles);\n     setContainerResources(containerMemory, containerVirtualCores, profiles);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n+    if (containerType !\u003d null) {\n+      vargs.add(\"--container_type \" + String.valueOf(containerType));\n+    }\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    setAMResourceCapability(appContext, amMemory, amVCores, amResourceProfile,\n        amPriority, profiles);\n    setContainerResources(containerMemory, containerVirtualCores, profiles);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerType !\u003d null) {\n      vargs.add(\"--container_type \" + String.valueOf(containerType));\n    }\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "e490602e9b306d5b8a543b93fb15a7395bb9a03d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7039. Fix javac and javadoc errors in YARN-3926 branch. (Sunil G via wangda)\n\nChange-Id: I442bf6d838b3aba83f1f6779cf9dcf8596a2102d\n",
      "commitDate": "12/09/17 9:19 AM",
      "commitName": "e490602e9b306d5b8a543b93fb15a7395bb9a03d",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "12/09/17 9:19 AM",
      "commitNameOld": "7805deed4896e470ebd2f6bbd1ba9962947c63cd",
      "commitAuthorOld": "Sunil G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,326 +1,326 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     Map\u003cString, Resource\u003e profiles;\n     try {\n       profiles \u003d yarnClient.getResourceProfiles();\n-    } catch (ResourceProfilesNotEnabledException re) {\n+    } catch (YARNFeatureNotEnabledException re) {\n       profiles \u003d null;\n     }\n \n     List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n     appProfiles.add(amResourceProfile);\n     appProfiles.add(containerResourceProfile);\n     for (String appProfile : appProfiles) {\n       if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n         if (profiles \u003d\u003d null) {\n           String message \u003d \"Resource profiles is not enabled\";\n           LOG.error(message);\n           throw new IOException(message);\n         }\n         if (!profiles.containsKey(appProfile)) {\n           String message \u003d \"Unknown resource profile \u0027\" + appProfile\n               + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n           LOG.error(message);\n           throw new IOException(message);\n         }\n       }\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and\n     // vcores requirements\n     setAMResourceCapability(appContext, amMemory, amVCores, amResourceProfile,\n         amPriority, profiles);\n     setContainerResources(containerMemory, containerVirtualCores, profiles);\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     if (containerMemory \u003e 0) {\n       vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     }\n     if (containerVirtualCores \u003e 0) {\n       vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     }\n     if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n         .isEmpty()) {\n       vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n     }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (YARNFeatureNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    setAMResourceCapability(appContext, amMemory, amVCores, amResourceProfile,\n        amPriority, profiles);\n    setContainerResources(containerMemory, containerVirtualCores, profiles);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "7805deed4896e470ebd2f6bbd1ba9962947c63cd": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5588. [YARN-3926] Add support for resource profiles in distributed shell. Contributed by Varun Vasudev.\n",
      "commitDate": "12/09/17 9:19 AM",
      "commitName": "7805deed4896e470ebd2f6bbd1ba9962947c63cd",
      "commitAuthor": "Sunil G",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "89e5c44f9e891a3579384c3fa3766937cd4970f1",
      "commitAuthorOld": "Li Lu",
      "daysBetweenCommits": 429.02,
      "commitsBetweenForRepo": 2752,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,291 +1,326 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n+    Map\u003cString, Resource\u003e profiles;\n+    try {\n+      profiles \u003d yarnClient.getResourceProfiles();\n+    } catch (ResourceProfilesNotEnabledException re) {\n+      profiles \u003d null;\n+    }\n+\n+    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n+    appProfiles.add(amResourceProfile);\n+    appProfiles.add(containerResourceProfile);\n+    for (String appProfile : appProfiles) {\n+      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n+        if (profiles \u003d\u003d null) {\n+          String message \u003d \"Resource profiles is not enabled\";\n+          LOG.error(message);\n+          throw new IOException(message);\n+        }\n+        if (!profiles.containsKey(appProfile)) {\n+          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n+              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n+          LOG.error(message);\n+          throw new IOException(message);\n+        }\n+      }\n+    }\n+\n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n+    // Set up resource type requirements\n+    // For now, both memory and vcores are supported, so we set memory and\n+    // vcores requirements\n+    setAMResourceCapability(appContext, amMemory, amVCores, amResourceProfile,\n+        amPriority, profiles);\n+    setContainerResources(containerMemory, containerVirtualCores, profiles);\n+\n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n-    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n-    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n+    if (containerMemory \u003e 0) {\n+      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n+    }\n+    if (containerVirtualCores \u003e 0) {\n+      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n+    }\n+    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n+        .isEmpty()) {\n+      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n+    }\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n-    // Set up resource type requirements\n-    // For now, both memory and vcores are supported, so we set memory and \n-    // vcores requirements\n-    Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n-    appContext.setResource(capability);\n-\n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    Map\u003cString, Resource\u003e profiles;\n    try {\n      profiles \u003d yarnClient.getResourceProfiles();\n    } catch (ResourceProfilesNotEnabledException re) {\n      profiles \u003d null;\n    }\n\n    List\u003cString\u003e appProfiles \u003d new ArrayList\u003c\u003e(2);\n    appProfiles.add(amResourceProfile);\n    appProfiles.add(containerResourceProfile);\n    for (String appProfile : appProfiles) {\n      if (appProfile !\u003d null \u0026\u0026 !appProfile.isEmpty()) {\n        if (profiles \u003d\u003d null) {\n          String message \u003d \"Resource profiles is not enabled\";\n          LOG.error(message);\n          throw new IOException(message);\n        }\n        if (!profiles.containsKey(appProfile)) {\n          String message \u003d \"Unknown resource profile \u0027\" + appProfile\n              + \"\u0027. Valid resource profiles are \" + profiles.keySet();\n          LOG.error(message);\n          throw new IOException(message);\n        }\n      }\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and\n    // vcores requirements\n    setAMResourceCapability(appContext, amMemory, amVCores, amResourceProfile,\n        amPriority, profiles);\n    setContainerResources(containerMemory, containerVirtualCores, profiles);\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    if (containerMemory \u003e 0) {\n      vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    }\n    if (containerVirtualCores \u003e 0) {\n      vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    }\n    if (containerResourceProfile !\u003d null \u0026\u0026 !containerResourceProfile\n        .isEmpty()) {\n      vargs.add(\"--container_resource_profile \" + containerResourceProfile);\n    }\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "89e5c44f9e891a3579384c3fa3766937cd4970f1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4356. Ensure the timeline service v.2 is disabled cleanly and has no\nimpact when it\u0027s turned off. Contributed by Sangjin Lee.\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "89e5c44f9e891a3579384c3fa3766937cd4970f1",
      "commitAuthor": "Li Lu",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "22e7ae57715cedb1dcba736e357e8daaf5133e5c",
      "commitAuthorOld": "Sangjin Lee",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 34,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,294 +1,291 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n     if (flowName !\u003d null) {\n       tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n     if (flowVersion !\u003d null) {\n       tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n     }\n     if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.addAll(containerRetryOptions);\n \n-    if (timelineServiceVersion !\u003d null) {\n-      vargs.add(\"--timeline_service_version \" + timelineServiceVersion);\n-    }\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "47f35a30bb4d99349593e9d6e1c9e76e71341c40": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3391. Clearly define flow ID/ flow run / flow version in API and storage. Contributed by Zhijie Shen\n\n(cherry picked from commit 68c6232f8423e55b4d152ef3d1d66aeb2d6a555e)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "47f35a30bb4d99349593e9d6e1c9e76e71341c40",
      "commitAuthor": "Junping Du",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "d67c9bdb4db2b075484a779802ecf3296bad5cd4",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,291 +1,294 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n-    if (flowId !\u003d null) {\n-      tags.add(TimelineUtils.generateFlowIdTag(flowId));\n+    if (flowName !\u003d null) {\n+      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n     }\n-    if (flowRunId !\u003d null) {\n+    if (flowVersion !\u003d null) {\n+      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n+    }\n+    if (flowRunId !\u003d 0) {\n       tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n     }\n     appContext.setApplicationTags(tags);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.addAll(containerRetryOptions);\n \n     if (timelineServiceVersion !\u003d null) {\n       vargs.add(\"--timeline_service_version \" + timelineServiceVersion);\n     }\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (flowName !\u003d null) {\n      tags.add(TimelineUtils.generateFlowNameTag(flowName));\n    }\n    if (flowVersion !\u003d null) {\n      tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\n    }\n    if (flowRunId !\u003d 0) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.addAll(containerRetryOptions);\n\n    if (timelineServiceVersion !\u003d null) {\n      vargs.add(\"--timeline_service_version \" + timelineServiceVersion);\n    }\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "d67c9bdb4db2b075484a779802ecf3296bad5cd4": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3040. Make putEntities operation be aware of the app\u0027s context. Contributed by Zhijie Shen\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "d67c9bdb4db2b075484a779802ecf3296bad5cd4",
      "commitAuthor": "Junping Du",
      "commitDateOld": "10/07/16 8:45 AM",
      "commitNameOld": "2188a07e5bea1da26bf679ca0ece26ab596d3438",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,282 +1,291 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n+    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n+    if (flowId !\u003d null) {\n+      tags.add(TimelineUtils.generateFlowIdTag(flowId));\n+    }\n+    if (flowRunId !\u003d null) {\n+      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n+    }\n+    appContext.setApplicationTags(tags);\n+\n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.addAll(containerRetryOptions);\n \n     if (timelineServiceVersion !\u003d null) {\n       vargs.add(\"--timeline_service_version \" + timelineServiceVersion);\n     }\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    Set\u003cString\u003e tags \u003d new HashSet\u003cString\u003e();\n    if (flowId !\u003d null) {\n      tags.add(TimelineUtils.generateFlowIdTag(flowId));\n    }\n    if (flowRunId !\u003d null) {\n      tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\n    }\n    appContext.setApplicationTags(tags);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.addAll(containerRetryOptions);\n\n    if (timelineServiceVersion !\u003d null) {\n      vargs.add(\"--timeline_service_version \" + timelineServiceVersion);\n    }\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "d45ff878c4cb8b359abb17ecf09d24b6f862874c": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3125. Made the distributed shell use timeline service next gen and add an integration test for it. Contributed by Junping Du and Li Lu.\n\n(cherry picked from commit bf08f7f0ed4900ce52f98137297dd1a47ba2a536)\n",
      "commitDate": "10/07/16 8:45 AM",
      "commitName": "d45ff878c4cb8b359abb17ecf09d24b6f862874c",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "09/07/16 5:09 AM",
      "commitNameOld": "9bdb5bebea1183ec2f697ee3e55392df4fe697bb",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 1.15,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,279 +1,282 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n-    }\t\t\t\n+    }\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.addAll(containerRetryOptions);\n \n+    if (timelineServiceVersion !\u003d null) {\n+      vargs.add(\"--timeline_service_version \" + timelineServiceVersion);\n+    }\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n-    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n+    LOG.info(\"Completed setting up app master command \" + command.toString());\n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.addAll(containerRetryOptions);\n\n    if (timelineServiceVersion !\u003d null) {\n      vargs.add(\"--timeline_service_version \" + timelineServiceVersion);\n    }\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "42f90ab885d9693fcc1e52f9637f7de4111110ae": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4844. Add getMemorySize/getVirtualCoresSize to o.a.h.y.api.records.Resource. Contributed by Wangda Tan.\n",
      "commitDate": "29/05/16 8:54 AM",
      "commitName": "42f90ab885d9693fcc1e52f9637f7de4111110ae",
      "commitAuthor": "Varun Vasudev",
      "commitDateOld": "29/04/16 3:39 AM",
      "commitNameOld": "0f25a1bb52bc56661fd020a6ba82df99f8c6ef1f",
      "commitAuthorOld": "Varun Vasudev",
      "daysBetweenCommits": 30.22,
      "commitsBetweenForRepo": 208,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,279 +1,279 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n-    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n+    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.addAll(containerRetryOptions);\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    long maxMem \u003d appResponse.getMaximumResourceCapability().getMemorySize();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "0f25a1bb52bc56661fd020a6ba82df99f8c6ef1f": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3998. Add support in the NodeManager to re-launch containers. Contributed by Jun Gong.\n",
      "commitDate": "29/04/16 3:39 AM",
      "commitName": "0f25a1bb52bc56661fd020a6ba82df99f8c6ef1f",
      "commitAuthor": "Varun Vasudev",
      "commitDateOld": "10/02/16 5:01 AM",
      "commitNameOld": "e9a622606f69dc926a950d4dd61fe3f16f378509",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 78.9,
      "commitsBetweenForRepo": 496,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,277 +1,279 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n+    vargs.addAll(containerRetryOptions);\n+\n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.addAll(containerRetryOptions);\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "e9a622606f69dc926a950d4dd61fe3f16f378509": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4629. Distributed shell breaks under strong security. (Daniel Templeton via stevel)\n",
      "commitDate": "10/02/16 5:01 AM",
      "commitName": "e9a622606f69dc926a950d4dd61fe3f16f378509",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "24/10/15 4:55 AM",
      "commitNameOld": "446212a39ecf295cdd0e0b06ab870b48c5e6b500",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 109.05,
      "commitsBetweenForRepo": 716,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,277 +1,277 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\u003d\" + node.getHttpAddress()\n           + \", nodeRackName\u003d\" + node.getRackName()\n           + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n-      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n+      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d YarnClientUtils.getRmPrincipal(conf);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "446212a39ecf295cdd0e0b06ab870b48c5e6b500": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4296. DistributedShell Log.info is not friendly. (Xiaowei Wang via stevel)\n",
      "commitDate": "24/10/15 4:55 AM",
      "commitName": "446212a39ecf295cdd0e0b06ab870b48c5e6b500",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "24/04/15 2:08 PM",
      "commitNameOld": "5ce3a77f3c00aeabcd791c3373dd3c8c25160ce2",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 182.62,
      "commitsBetweenForRepo": 1535,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,277 +1,277 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n-          + \", nodeAddress\" + node.getHttpAddress()\n-          + \", nodeRackName\" + node.getRackName()\n-          + \", nodeNumContainers\" + node.getNumContainers());\n+          + \", nodeAddress\u003d\" + node.getHttpAddress()\n+          + \", nodeRackName\u003d\" + node.getRackName()\n+          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\u003d\" + node.getHttpAddress()\n          + \", nodeRackName\u003d\" + node.getRackName()\n          + \", nodeNumContainers\u003d\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "5ce3a77f3c00aeabcd791c3373dd3c8c25160ce2": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3444. Fix typo capabililty. Contributed by Gabor Liptak.\n",
      "commitDate": "24/04/15 2:08 PM",
      "commitName": "5ce3a77f3c00aeabcd791c3373dd3c8c25160ce2",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "27/10/14 8:13 PM",
      "commitNameOld": "f6b963fdfc517429149165e4bb6fb947be6e3c99",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 178.75,
      "commitsBetweenForRepo": 1459,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,277 +1,277 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n-    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n+    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n-    LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n+    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     if (null !\u003d nodeLabelExpression) {\n       appContext.setNodeLabelExpression(nodeLabelExpression);\n     }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "f6b963fdfc517429149165e4bb6fb947be6e3c99": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2502. Changed DistributedShell to support node labels. Contributed by Wangda Tan\n",
      "commitDate": "27/10/14 8:13 PM",
      "commitName": "f6b963fdfc517429149165e4bb6fb947be6e3c99",
      "commitAuthor": "Jian He",
      "commitDateOld": "09/10/14 12:59 PM",
      "commitNameOld": "1d4612f5ad9678c952b416e798dccd20c88f96ef",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 18.3,
      "commitsBetweenForRepo": 145,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,274 +1,277 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n       prepareTimelineDomain();\n     }\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n     if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n       env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n     }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n+    if (null !\u003d nodeLabelExpression) {\n+      appContext.setNodeLabelExpression(nodeLabelExpression);\n+    }\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    if (null !\u003d nodeLabelExpression) {\n      appContext.setNodeLabelExpression(nodeLabelExpression);\n    }\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "1d4612f5ad9678c952b416e798dccd20c88f96ef": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2629. Made the distributed shell use the domain-based timeline ACLs. Contributed by Zhijie Shen.\n",
      "commitDate": "09/10/14 12:59 PM",
      "commitName": "1d4612f5ad9678c952b416e798dccd20c88f96ef",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "16/09/14 10:58 AM",
      "commitNameOld": "8e5d6713cf16473d791c028cecc274fd2c7fd10b",
      "commitAuthorOld": "XuanGong",
      "daysBetweenCommits": 23.08,
      "commitsBetweenForRepo": 276,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,267 +1,274 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n+    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n+      prepareTimelineDomain();\n+    }\n+\n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     if (attemptFailuresValidityInterval \u003e\u003d 0) {\n       appContext\n         .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n     }\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n+    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n+      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n+    }\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0 \u0026\u0026 toCreateDomain) {\n      prepareTimelineDomain();\n    }\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n    if (domainId !\u003d null \u0026\u0026 domainId.length() \u003e 0) {\n      env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\n    }\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "8e5d6713cf16473d791c028cecc274fd2c7fd10b": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2557. Add a parameter \"attempt_Failures_Validity_Interval\" into\nDistributedShell. Contributed by Xuan Gong\n",
      "commitDate": "16/09/14 10:58 AM",
      "commitName": "8e5d6713cf16473d791c028cecc274fd2c7fd10b",
      "commitAuthor": "XuanGong",
      "commitDateOld": "29/08/14 11:16 AM",
      "commitNameOld": "3de66011c2e80d7c458a67f80042af986fcc677d",
      "commitAuthorOld": "Hitesh Shah",
      "daysBetweenCommits": 17.99,
      "commitsBetweenForRepo": 144,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,262 +1,267 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n+    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n+      appContext\n+        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n+    }\n+\n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n       localResources, env, commands, null, null, null);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     // TODO - what is the range for priority? how to decide? \n     Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    if (attemptFailuresValidityInterval \u003e\u003d 0) {\n      appContext\n        .setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\n    }\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "f6c723ff0c09134d721534a409e8d688cc028307": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2295. Refactored DistributedShell to use public APIs of protocol records. Contributed by Li Lu\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1612626 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/07/14 10:49 AM",
      "commitName": "f6c723ff0c09134d721534a409e8d688cc028307",
      "commitAuthor": "Jian He",
      "commitDateOld": "10/04/14 9:06 PM",
      "commitNameOld": "d6a6e982a84eb9545cbac51ee6277ea2837f88de",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 102.57,
      "commitsBetweenForRepo": 621,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,268 +1,262 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n-    // Set up the container launch context for the application master\n-    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n-\n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n-    // Set local resource info into app master container launch context\n-    amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n-    amContainer.setEnvironment(env);\n-\n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n-    amContainer.setCommands(commands);\n+\n+    // Set up the container launch context for the application master\n+    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n+      localResources, env, commands, null, null, null);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n-    Resource capability \u003d Records.newRecord(Resource.class);\n-    capability.setMemory(amMemory);\n-    capability.setVirtualCores(amVCores);\n+    Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n+      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n-    Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n-    pri.setPriority(amPriority);\n+    Priority pri \u003d Priority.newInstance(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d ContainerLaunchContext.newInstance(\n      localResources, env, commands, null, null, null);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Resource.newInstance(amMemory, amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      // Note: Credentials class is marked as LimitedPrivate for HDFS and MapReduce\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    // TODO - what is the range for priority? how to decide? \n    Priority pri \u003d Priority.newInstance(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "d6a6e982a84eb9545cbac51ee6277ea2837f88de": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1926. Changed DistributedShell to use appIDs as unique identifiers for HDFS paths and thus avoid test failures on Windows. Contributed by Varun Vasudev.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1586562 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/04/14 9:06 PM",
      "commitName": "d6a6e982a84eb9545cbac51ee6277ea2837f88de",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "16/03/14 11:32 AM",
      "commitNameOld": "96e0ca2d272dc7ecd7f7f0e65a0c596fcc063bcb",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 25.4,
      "commitsBetweenForRepo": 192,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,268 +1,268 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n-    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.getId(),\n+    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n-      addToLocalResources(fs, log4jPropFile, log4jPath, appId.getId(),\n+      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n-          appName + \"/\" + appId.getId() + \"/\" + SCRIPT_PATH;\n+          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n-      addToLocalResources(fs, null, shellCommandPath, appId.getId(),\n+      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n-      addToLocalResources(fs, null, shellArgsPath, appId.getId(),\n+      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n       .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n       \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     capability.setVirtualCores(amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.toString(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.toString(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.toString() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.toString(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.toString(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    capability.setVirtualCores(amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "96e0ca2d272dc7ecd7f7f0e65a0c596fcc063bcb": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1824. Improved NodeManager and clients to be able to handle cross platform application submissions. Contributed by Jian He.\nMAPREDUCE-4052. Improved MapReduce clients to use NodeManagers\u0027 ability to handle cross platform application submissions. Contributed by Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1578135 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/03/14 11:32 AM",
      "commitName": "96e0ca2d272dc7ecd7f7f0e65a0c596fcc063bcb",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "10/01/14 11:42 PM",
      "commitNameOld": "aa0c489a28dbbe8fae0be6a48edb122537784b1d",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 64.45,
      "commitsBetweenForRepo": 542,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,268 +1,268 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n \n     appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.getId(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.getId(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n-          appName + \"/\" + appId.getId() + \"/\"\n-              + (Shell.WINDOWS ? windowBatPath : linuxShellPath);\n+          appName + \"/\" + appId.getId() + \"/\" + SCRIPT_PATH;\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.getId(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.getId(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n-    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n-      .append(File.pathSeparatorChar).append(\"./*\");\n+    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n+      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n-        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n-      classPathEnv.append(File.pathSeparatorChar);\n+        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n+      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n       classPathEnv.append(c.trim());\n     }\n-    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n+    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n+      \"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n-    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n+    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     capability.setVirtualCores(amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.getId(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.getId(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.getId() + \"/\" + SCRIPT_PATH;\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.getId(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.getId(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$$())\n      .append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\n      \"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    capability.setVirtualCores(amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "aa0c489a28dbbe8fae0be6a48edb122537784b1d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1566. Changed Distributed Shell to retain containers across application attempts. Contributed by Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1557322 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/01/14 11:42 PM",
      "commitName": "aa0c489a28dbbe8fae0be6a48edb122537784b1d",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "13/12/13 6:00 PM",
      "commitNameOld": "d63cfdbf1a5389acb27e8cd61f4c14d8eaedb26f",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 28.24,
      "commitsBetweenForRepo": 121,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,266 +1,268 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n+\n+    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.getId(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.getId(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d\n           appName + \"/\" + appId.getId() + \"/\"\n               + (Shell.WINDOWS ? windowBatPath : linuxShellPath);\n       Path shellDst \u003d\n           new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.getId(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.getId(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n       .append(File.pathSeparatorChar).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(File.pathSeparatorChar);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     capability.setVirtualCores(amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.getId(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.getId(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.getId() + \"/\"\n              + (Shell.WINDOWS ? windowBatPath : linuxShellPath);\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.getId(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.getId(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n      .append(File.pathSeparatorChar).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(File.pathSeparatorChar);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    capability.setVirtualCores(amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "d63cfdbf1a5389acb27e8cd61f4c14d8eaedb26f": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1435. Modified Distributed Shell to accept either the command or the custom script. Contributed by Xuan Gong.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1550867 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/12/13 6:00 PM",
      "commitName": "d63cfdbf1a5389acb27e8cd61f4c14d8eaedb26f",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "25/11/13 5:10 PM",
      "commitNameOld": "c4bdddeab56287c8a8ae314fac238cbbc6c1bcf4",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 18.03,
      "commitsBetweenForRepo": 100,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,263 +1,266 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.getId(),\n         localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       addToLocalResources(fs, log4jPropFile, log4jPath, appId.getId(),\n           localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n-      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n-      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n+      String shellPathSuffix \u003d\n+          appName + \"/\" + appId.getId() + \"/\"\n+              + (Shell.WINDOWS ? windowBatPath : linuxShellPath);\n+      Path shellDst \u003d\n+          new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       addToLocalResources(fs, null, shellCommandPath, appId.getId(),\n           localResources, shellCommand);\n     }\n \n     if (shellArgs.length \u003e 0) {\n       addToLocalResources(fs, null, shellArgsPath, appId.getId(),\n           localResources, StringUtils.join(shellArgs, \" \"));\n     }\n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n       .append(File.pathSeparatorChar).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(File.pathSeparatorChar);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     capability.setVirtualCores(amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.getId(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.getId(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d\n          appName + \"/\" + appId.getId() + \"/\"\n              + (Shell.WINDOWS ? windowBatPath : linuxShellPath);\n      Path shellDst \u003d\n          new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.getId(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.getId(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n      .append(File.pathSeparatorChar).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(File.pathSeparatorChar);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    capability.setVirtualCores(amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "c4bdddeab56287c8a8ae314fac238cbbc6c1bcf4": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1314. Fixed DistributedShell to not fail with multiple arguments for a shell command separated by spaces. Contributed by Xuan Gong.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1545486 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/11/13 5:10 PM",
      "commitName": "c4bdddeab56287c8a8ae314fac238cbbc6c1bcf4",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "21/11/13 3:16 PM",
      "commitNameOld": "33a8234040959ecd0d0202162e1b18c990effabe",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 4.08,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,308 +1,263 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n-    Path src \u003d new Path(appMasterJar);\n-    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n-    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n-    fs.copyFromLocalFile(false, true, src, dst);\n-    FileStatus destStatus \u003d fs.getFileStatus(dst);\n-    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n-\n-    // Set the type of resource - file or archive\n-    // archives are untarred at destination\n-    // we don\u0027t need the jar file to be untarred for now\n-    amJarRsrc.setType(LocalResourceType.FILE);\n-    // Set visibility of the resource \n-    // Setting to most private option\n-    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n-    // Set the resource to be copied over\n-    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n-    // Set timestamp and length of file so that the framework \n-    // can do basic sanity checks for the local resource \n-    // after it has been copied over to ensure it is the same \n-    // resource the client intended to use with the application\n-    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n-    amJarRsrc.setSize(destStatus.getLen());\n-    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n+    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.getId(),\n+        localResources, null);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n-      Path log4jSrc \u003d new Path(log4jPropFile);\n-      String log4jPathSuffix \u003d appName + \"/\" + appId.getId() + \"/\" + log4jPath;\n-      Path log4jDst \u003d new Path(fs.getHomeDirectory(), log4jPathSuffix);\n-      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n-      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n-      LocalResource log4jRsrc \u003d\n-          LocalResource.newInstance(\n-              ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()),\n-              LocalResourceType.FILE, LocalResourceVisibility.APPLICATION,\n-              log4jFileStatus.getLen(), log4jFileStatus.getModificationTime());\n-      localResources.put(log4jPath, log4jRsrc);\n+      addToLocalResources(fs, log4jPropFile, log4jPath, appId.getId(),\n+          localResources, null);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n-      String shellCommandSuffix \u003d\n-          appName + \"/\" + appId.getId() + \"/\" + shellCommandPath;\n-      Path shellCommandDst \u003d\n-          new Path(fs.getHomeDirectory(), shellCommandSuffix);\n-      FSDataOutputStream ostream \u003d null;\n-      try {\n-        ostream \u003d FileSystem\n-            .create(fs, shellCommandDst, new FsPermission((short) 0710));\n-        ostream.writeUTF(shellCommand);\n-      } finally {\n-        IOUtils.closeQuietly(ostream);\n-      }\n-      FileStatus scFileStatus \u003d fs.getFileStatus(shellCommandDst);\n-      LocalResource scRsrc \u003d\n-          LocalResource.newInstance(\n-              ConverterUtils.getYarnUrlFromURI(shellCommandDst.toUri()),\n-              LocalResourceType.FILE, LocalResourceVisibility.APPLICATION,\n-              scFileStatus.getLen(), scFileStatus.getModificationTime());\n-      localResources.put(shellCommandPath, scRsrc);\n+      addToLocalResources(fs, null, shellCommandPath, appId.getId(),\n+          localResources, shellCommand);\n+    }\n+\n+    if (shellArgs.length \u003e 0) {\n+      addToLocalResources(fs, null, shellArgsPath, appId.getId(),\n+          localResources, StringUtils.join(shellArgs, \" \"));\n     }\n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n       .append(File.pathSeparatorChar).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(File.pathSeparatorChar);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n-    if (!shellArgs.isEmpty()) {\n-      vargs.add(\"--shell_args \" + shellArgs + \"\");\n-    }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     capability.setVirtualCores(amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, appId.getId(),\n        localResources, null);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      addToLocalResources(fs, log4jPropFile, log4jPath, appId.getId(),\n          localResources, null);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      addToLocalResources(fs, null, shellCommandPath, appId.getId(),\n          localResources, shellCommand);\n    }\n\n    if (shellArgs.length \u003e 0) {\n      addToLocalResources(fs, null, shellArgsPath, appId.getId(),\n          localResources, StringUtils.join(shellArgs, \" \"));\n    }\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n      .append(File.pathSeparatorChar).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(File.pathSeparatorChar);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    capability.setVirtualCores(amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "33a8234040959ecd0d0202162e1b18c990effabe": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1320. Fixed Distributed Shell application to respect custom log4j properties file. Contributed by Xuan Gong.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544364 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/11/13 3:16 PM",
      "commitName": "33a8234040959ecd0d0202162e1b18c990effabe",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "20/11/13 8:09 PM",
      "commitNameOld": "a802ef4a5f2e71eed2cbdc053258ae2f66af4755",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.8,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,308 +1,308 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n-      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n+      String log4jPathSuffix \u003d appName + \"/\" + appId.getId() + \"/\" + log4jPath;\n+      Path log4jDst \u003d new Path(fs.getHomeDirectory(), log4jPathSuffix);\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n-      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n-      log4jRsrc.setType(LocalResourceType.FILE);\n-      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n-      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n-      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n-      log4jRsrc.setSize(log4jFileStatus.getLen());\n-      localResources.put(\"log4j.properties\", log4jRsrc);\n+      LocalResource log4jRsrc \u003d\n+          LocalResource.newInstance(\n+              ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()),\n+              LocalResourceType.FILE, LocalResourceVisibility.APPLICATION,\n+              log4jFileStatus.getLen(), log4jFileStatus.getModificationTime());\n+      localResources.put(log4jPath, log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       String shellCommandSuffix \u003d\n           appName + \"/\" + appId.getId() + \"/\" + shellCommandPath;\n       Path shellCommandDst \u003d\n           new Path(fs.getHomeDirectory(), shellCommandSuffix);\n       FSDataOutputStream ostream \u003d null;\n       try {\n         ostream \u003d FileSystem\n             .create(fs, shellCommandDst, new FsPermission((short) 0710));\n         ostream.writeUTF(shellCommand);\n       } finally {\n         IOUtils.closeQuietly(ostream);\n       }\n       FileStatus scFileStatus \u003d fs.getFileStatus(shellCommandDst);\n       LocalResource scRsrc \u003d\n           LocalResource.newInstance(\n               ConverterUtils.getYarnUrlFromURI(shellCommandDst.toUri()),\n               LocalResourceType.FILE, LocalResourceVisibility.APPLICATION,\n               scFileStatus.getLen(), scFileStatus.getModificationTime());\n       localResources.put(shellCommandPath, scRsrc);\n     }\n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n       .append(File.pathSeparatorChar).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(File.pathSeparatorChar);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     capability.setVirtualCores(amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      String log4jPathSuffix \u003d appName + \"/\" + appId.getId() + \"/\" + log4jPath;\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), log4jPathSuffix);\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d\n          LocalResource.newInstance(\n              ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()),\n              LocalResourceType.FILE, LocalResourceVisibility.APPLICATION,\n              log4jFileStatus.getLen(), log4jFileStatus.getModificationTime());\n      localResources.put(log4jPath, log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      String shellCommandSuffix \u003d\n          appName + \"/\" + appId.getId() + \"/\" + shellCommandPath;\n      Path shellCommandDst \u003d\n          new Path(fs.getHomeDirectory(), shellCommandSuffix);\n      FSDataOutputStream ostream \u003d null;\n      try {\n        ostream \u003d FileSystem\n            .create(fs, shellCommandDst, new FsPermission((short) 0710));\n        ostream.writeUTF(shellCommand);\n      } finally {\n        IOUtils.closeQuietly(ostream);\n      }\n      FileStatus scFileStatus \u003d fs.getFileStatus(shellCommandDst);\n      LocalResource scRsrc \u003d\n          LocalResource.newInstance(\n              ConverterUtils.getYarnUrlFromURI(shellCommandDst.toUri()),\n              LocalResourceType.FILE, LocalResourceVisibility.APPLICATION,\n              scFileStatus.getLen(), scFileStatus.getModificationTime());\n      localResources.put(shellCommandPath, scRsrc);\n    }\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n      .append(File.pathSeparatorChar).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(File.pathSeparatorChar);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    capability.setVirtualCores(amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "a802ef4a5f2e71eed2cbdc053258ae2f66af4755": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1303. Reverted the wrong patch committed earlier and committing the correct patch now. In one go.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544029 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/11/13 8:09 PM",
      "commitName": "a802ef4a5f2e71eed2cbdc053258ae2f66af4755",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "20/11/13 7:47 PM",
      "commitNameOld": "ad558cf2b3650530c741f1cfafb0cf47e60c8b77",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,313 +1,308 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     if (!shellCommand.isEmpty()) {\n       String shellCommandSuffix \u003d\n           appName + \"/\" + appId.getId() + \"/\" + shellCommandPath;\n       Path shellCommandDst \u003d\n           new Path(fs.getHomeDirectory(), shellCommandSuffix);\n       FSDataOutputStream ostream \u003d null;\n       try {\n         ostream \u003d FileSystem\n             .create(fs, shellCommandDst, new FsPermission((short) 0710));\n         ostream.writeUTF(shellCommand);\n       } finally {\n         IOUtils.closeQuietly(ostream);\n       }\n       FileStatus scFileStatus \u003d fs.getFileStatus(shellCommandDst);\n-      LocalResource scRsrc \u003d Records.newRecord(LocalResource.class);\n-      scRsrc.setType(LocalResourceType.FILE);\n-      scRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\n-      scRsrc.setResource(ConverterUtils.getYarnUrlFromURI(shellCommandDst\n-          .toUri()));\n-      scRsrc.setTimestamp(scFileStatus.getModificationTime());\n-      scRsrc.setSize(scFileStatus.getLen());\n-      localResources.put(\"shellCommands\", scRsrc);\n+      LocalResource scRsrc \u003d\n+          LocalResource.newInstance(\n+              ConverterUtils.getYarnUrlFromURI(shellCommandDst.toUri()),\n+              LocalResourceType.FILE, LocalResourceVisibility.APPLICATION,\n+              scFileStatus.getLen(), scFileStatus.getModificationTime());\n+      localResources.put(shellCommandPath, scRsrc);\n     }\n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n       .append(File.pathSeparatorChar).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(File.pathSeparatorChar);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n \n-    if (!shellCommand.isEmpty()) {\n-      vargs.add(\"--shell_command \" + shellCommandPath + \"\");\n-    }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     capability.setVirtualCores(amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      String shellCommandSuffix \u003d\n          appName + \"/\" + appId.getId() + \"/\" + shellCommandPath;\n      Path shellCommandDst \u003d\n          new Path(fs.getHomeDirectory(), shellCommandSuffix);\n      FSDataOutputStream ostream \u003d null;\n      try {\n        ostream \u003d FileSystem\n            .create(fs, shellCommandDst, new FsPermission((short) 0710));\n        ostream.writeUTF(shellCommand);\n      } finally {\n        IOUtils.closeQuietly(ostream);\n      }\n      FileStatus scFileStatus \u003d fs.getFileStatus(shellCommandDst);\n      LocalResource scRsrc \u003d\n          LocalResource.newInstance(\n              ConverterUtils.getYarnUrlFromURI(shellCommandDst.toUri()),\n              LocalResourceType.FILE, LocalResourceVisibility.APPLICATION,\n              scFileStatus.getLen(), scFileStatus.getModificationTime());\n      localResources.put(shellCommandPath, scRsrc);\n    }\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n      .append(File.pathSeparatorChar).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(File.pathSeparatorChar);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    capability.setVirtualCores(amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "ad558cf2b3650530c741f1cfafb0cf47e60c8b77": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1303. Fixed DistributedShell to not fail with multiple commands separated by a semi-colon as shell-command. Contributed by Xuan Gong.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544023 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/11/13 7:47 PM",
      "commitName": "ad558cf2b3650530c741f1cfafb0cf47e60c8b77",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "11/10/13 1:18 AM",
      "commitNameOld": "735d8b27f78ea8be839008650a3e88db37dc507d",
      "commitAuthorOld": "Luke Lu",
      "daysBetweenCommits": 40.81,
      "commitsBetweenForRepo": 242,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,289 +1,313 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n     LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n     \n     if (amVCores \u003e maxVCores) {\n       LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n           + \"Using max value.\" + \", specified\u003d\" + amVCores \n           + \", max\u003d\" + maxVCores);\n       amVCores \u003d maxVCores;\n     }\n     \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n+    if (!shellCommand.isEmpty()) {\n+      String shellCommandSuffix \u003d\n+          appName + \"/\" + appId.getId() + \"/\" + shellCommandPath;\n+      Path shellCommandDst \u003d\n+          new Path(fs.getHomeDirectory(), shellCommandSuffix);\n+      FSDataOutputStream ostream \u003d null;\n+      try {\n+        ostream \u003d FileSystem\n+            .create(fs, shellCommandDst, new FsPermission((short) 0710));\n+        ostream.writeUTF(shellCommand);\n+      } finally {\n+        IOUtils.closeQuietly(ostream);\n+      }\n+      FileStatus scFileStatus \u003d fs.getFileStatus(shellCommandDst);\n+      LocalResource scRsrc \u003d Records.newRecord(LocalResource.class);\n+      scRsrc.setType(LocalResourceType.FILE);\n+      scRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\n+      scRsrc.setResource(ConverterUtils.getYarnUrlFromURI(shellCommandDst\n+          .toUri()));\n+      scRsrc.setTimestamp(scFileStatus.getModificationTime());\n+      scRsrc.setSize(scFileStatus.getLen());\n+      localResources.put(\"shellCommands\", scRsrc);\n+    }\n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n       .append(File.pathSeparatorChar).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(File.pathSeparatorChar);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n+\n     if (!shellCommand.isEmpty()) {\n-      vargs.add(\"--shell_command \" + shellCommand + \"\");\n+      vargs.add(\"--shell_command \" + shellCommandPath + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, both memory and vcores are supported, so we set memory and \n     // vcores requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     capability.setVirtualCores(amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    if (!shellCommand.isEmpty()) {\n      String shellCommandSuffix \u003d\n          appName + \"/\" + appId.getId() + \"/\" + shellCommandPath;\n      Path shellCommandDst \u003d\n          new Path(fs.getHomeDirectory(), shellCommandSuffix);\n      FSDataOutputStream ostream \u003d null;\n      try {\n        ostream \u003d FileSystem\n            .create(fs, shellCommandDst, new FsPermission((short) 0710));\n        ostream.writeUTF(shellCommand);\n      } finally {\n        IOUtils.closeQuietly(ostream);\n      }\n      FileStatus scFileStatus \u003d fs.getFileStatus(shellCommandDst);\n      LocalResource scRsrc \u003d Records.newRecord(LocalResource.class);\n      scRsrc.setType(LocalResourceType.FILE);\n      scRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\n      scRsrc.setResource(ConverterUtils.getYarnUrlFromURI(shellCommandDst\n          .toUri()));\n      scRsrc.setTimestamp(scFileStatus.getModificationTime());\n      scRsrc.setSize(scFileStatus.getLen());\n      localResources.put(\"shellCommands\", scRsrc);\n    }\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n      .append(File.pathSeparatorChar).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(File.pathSeparatorChar);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommandPath + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    capability.setVirtualCores(amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "735d8b27f78ea8be839008650a3e88db37dc507d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7. Support CPU resource for DistributedShell. (Junping Du via llu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1531222 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/10/13 1:18 AM",
      "commitName": "735d8b27f78ea8be839008650a3e88db37dc507d",
      "commitAuthor": "Luke Lu",
      "commitDateOld": "04/10/13 11:08 PM",
      "commitNameOld": "be3edccf0acf55e710b0ec8ab8ce8418da74c615",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 6.09,
      "commitsBetweenForRepo": 46,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,276 +1,289 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n+    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n+    LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n+    \n+    if (amVCores \u003e maxVCores) {\n+      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n+          + \"Using max value.\" + \", specified\u003d\" + amVCores \n+          + \", max\u003d\" + maxVCores);\n+      amVCores \u003d maxVCores;\n+    }\n+    \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n       .append(File.pathSeparatorChar).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(File.pathSeparatorChar);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n+    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n-    // For now, only memory is supported so we set memory requirements\n+    // For now, both memory and vcores are supported, so we set memory and \n+    // vcores requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n+    capability.setVirtualCores(amVCores);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // Setup security tokens\n     if (UserGroupInformation.isSecurityEnabled()) {\n       Credentials credentials \u003d new Credentials();\n       String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n       if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n         throw new IOException(\n           \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n       }\n \n       // For now, only getting tokens for the default file-system.\n       final Token\u003c?\u003e tokens[] \u003d\n           fs.addDelegationTokens(tokenRenewer, credentials);\n       if (tokens !\u003d null) {\n         for (Token\u003c?\u003e token : tokens) {\n           LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n         }\n       }\n       DataOutputBuffer dob \u003d new DataOutputBuffer();\n       credentials.writeTokenStorageToStream(dob);\n       ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n       amContainer.setTokens(fsTokens);\n     }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    int maxVCores \u003d appResponse.getMaximumResourceCapability().getVirtualCores();\n    LOG.info(\"Max virtual cores capabililty of resources in this cluster \" + maxVCores);\n    \n    if (amVCores \u003e maxVCores) {\n      LOG.info(\"AM virtual cores specified above max threshold of cluster. \" \n          + \"Using max value.\" + \", specified\u003d\" + amVCores \n          + \", max\u003d\" + maxVCores);\n      amVCores \u003d maxVCores;\n    }\n    \n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n      .append(File.pathSeparatorChar).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(File.pathSeparatorChar);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, both memory and vcores are supported, so we set memory and \n    // vcores requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    capability.setVirtualCores(amVCores);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "42c3cd3d137ba1de1c0573c0bb655fa380ed9412": {
      "type": "Ybodychange",
      "commitMessage": "YARN-49. Improve distributed shell application to work on a secure cluster. Contributed by Vinod Kumar Vavilapalli.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1526330 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/09/13 4:39 PM",
      "commitName": "42c3cd3d137ba1de1c0573c0bb655fa380ed9412",
      "commitAuthor": "Hitesh Shah",
      "commitDateOld": "08/07/13 3:30 PM",
      "commitNameOld": "5e4f6ad1d9aa6df96af837600674af4467c1e99c",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 79.05,
      "commitsBetweenForRepo": 457,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,256 +1,276 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n         NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n       .append(File.pathSeparatorChar).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(File.pathSeparatorChar);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, only memory is supported so we set memory requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n-    // The following are not required for launching an application master \n-    // amContainer.setContainerId(containerId);\t\t\n+    // Setup security tokens\n+    if (UserGroupInformation.isSecurityEnabled()) {\n+      Credentials credentials \u003d new Credentials();\n+      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n+      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n+        throw new IOException(\n+          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n+      }\n+\n+      // For now, only getting tokens for the default file-system.\n+      final Token\u003c?\u003e tokens[] \u003d\n+          fs.addDelegationTokens(tokenRenewer, credentials);\n+      if (tokens !\u003d null) {\n+        for (Token\u003c?\u003e token : tokens) {\n+          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n+        }\n+      }\n+      DataOutputBuffer dob \u003d new DataOutputBuffer();\n+      credentials.writeTokenStorageToStream(dob);\n+      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n+      amContainer.setTokens(fsTokens);\n+    }\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n      .append(File.pathSeparatorChar).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(File.pathSeparatorChar);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // Setup security tokens\n    if (UserGroupInformation.isSecurityEnabled()) {\n      Credentials credentials \u003d new Credentials();\n      String tokenRenewer \u003d conf.get(YarnConfiguration.RM_PRINCIPAL);\n      if (tokenRenewer \u003d\u003d null || tokenRenewer.length() \u003d\u003d 0) {\n        throw new IOException(\n          \"Can\u0027t get Master Kerberos principal for the RM to use as renewer\");\n      }\n\n      // For now, only getting tokens for the default file-system.\n      final Token\u003c?\u003e tokens[] \u003d\n          fs.addDelegationTokens(tokenRenewer, credentials);\n      if (tokens !\u003d null) {\n        for (Token\u003c?\u003e token : tokens) {\n          LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\n        }\n      }\n      DataOutputBuffer dob \u003d new DataOutputBuffer();\n      credentials.writeTokenStorageToStream(dob);\n      ByteBuffer fsTokens \u003d ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n      amContainer.setTokens(fsTokens);\n    }\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "5e4f6ad1d9aa6df96af837600674af4467c1e99c": {
      "type": "Ybodychange",
      "commitMessage": "YARN-791. Changed RM APIs and web-services related to nodes to ensure that both are consistent with each other. Contributed by Sandy Ryza.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1500994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/07/13 3:30 PM",
      "commitName": "5e4f6ad1d9aa6df96af837600674af4467c1e99c",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "19/06/13 12:06 AM",
      "commitNameOld": "d3198dddc8c66139cbb57b3c3c061a3d0d2c6a5d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 19.64,
      "commitsBetweenForRepo": 76,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,255 +1,256 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n-    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports();\n+    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n+        NodeState.RUNNING);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id\n     YarnClientApplication app \u003d yarnClient.createApplication();\n     GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     // set the application name\n     ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n     ApplicationId appId \u003d appContext.getApplicationId();\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n       .append(File.pathSeparatorChar).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(File.pathSeparatorChar);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, only memory is supported so we set memory requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // The following are not required for launching an application master \n     // amContainer.setContainerId(containerId);\t\t\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports(\n        NodeState.RUNNING);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n      .append(File.pathSeparatorChar).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(File.pathSeparatorChar);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "d3198dddc8c66139cbb57b3c3c061a3d0d2c6a5d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-553. Replaced YarnClient.getNewApplication with YarnClient.createApplication which provides a directly usable ApplicationSubmissionContext to simplify the api. Contributed by Karthik Kambatla.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1494476 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/06/13 12:06 AM",
      "commitName": "d3198dddc8c66139cbb57b3c3c061a3d0d2c6a5d",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "17/06/13 9:02 PM",
      "commitNameOld": "7ef54faad4bee4346da082a3f8cc5d6ea405d74a",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 1.13,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,260 +1,255 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     yarnClient.start();\n \n     YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports();\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n-    // Get a new application id \n-    GetNewApplicationResponse newApp \u003d yarnClient.getNewApplication();\n-    ApplicationId appId \u003d newApp.getApplicationId();\n-\n+    // Get a new application id\n+    YarnClientApplication app \u003d yarnClient.createApplication();\n+    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n-    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n+    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n-    // Create launch context for app master\n-    LOG.info(\"Setting up application submission context for ASM\");\n-    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n-\n-    // set the application id \n-    appContext.setApplicationId(appId);\n     // set the application name\n+    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n+    ApplicationId appId \u003d appContext.getApplicationId();\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n       .append(File.pathSeparatorChar).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(File.pathSeparatorChar);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, only memory is supported so we set memory requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // The following are not required for launching an application master \n     // amContainer.setContainerId(containerId);\t\t\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports();\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id\n    YarnClientApplication app \u003d yarnClient.createApplication();\n    GetNewApplicationResponse appResponse \u003d app.getNewApplicationResponse();\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d appResponse.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // set the application name\n    ApplicationSubmissionContext appContext \u003d app.getApplicationSubmissionContext();\n    ApplicationId appId \u003d appContext.getApplicationId();\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n      .append(File.pathSeparatorChar).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(File.pathSeparatorChar);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "ff70f912f781e35e3538d00c892d18b17aefa105": {
      "type": "Ybodychange",
      "commitMessage": "YARN-824. Added static factory methods to hadoop-yarn-client interfaces. Contributed by Jian He.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1493631 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/06/13 8:19 PM",
      "commitName": "ff70f912f781e35e3538d00c892d18b17aefa105",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "16/06/13 7:33 PM",
      "commitNameOld": "6b75a5c3b50877fc03574932ad54e4b4298f80d1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.03,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,260 +1,260 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n-    start();\n+    yarnClient.start();\n \n-    YarnClusterMetrics clusterMetrics \u003d super.getYarnClusterMetrics();\n+    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n-    List\u003cNodeReport\u003e clusterNodeReports \u003d super.getNodeReports();\n+    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports();\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n-    QueueInfo queueInfo \u003d super.getQueueInfo(this.amQueue);\t\t\n+    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n-    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d super.getQueueAclsInfo();\t\t\t\t\n+    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id \n-    GetNewApplicationResponse newApp \u003d super.getNewApplication();\n+    GetNewApplicationResponse newApp \u003d yarnClient.getNewApplication();\n     ApplicationId appId \u003d newApp.getApplicationId();\n \n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask cannot exceed the max. \n     if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     // Create launch context for app master\n     LOG.info(\"Setting up application submission context for ASM\");\n     ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n \n     // set the application id \n     appContext.setApplicationId(appId);\n     // set the application name\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n       .append(File.pathSeparatorChar).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(File.pathSeparatorChar);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, only memory is supported so we set memory requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // The following are not required for launching an application master \n     // amContainer.setContainerId(containerId);\t\t\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n-    super.submitApplication(appContext);\n+    yarnClient.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    yarnClient.start();\n\n    YarnClusterMetrics clusterMetrics \u003d yarnClient.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d yarnClient.getNodeReports();\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d yarnClient.getQueueInfo(this.amQueue);\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d yarnClient.getQueueAclsInfo();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id \n    GetNewApplicationResponse newApp \u003d yarnClient.getNewApplication();\n    ApplicationId appId \u003d newApp.getApplicationId();\n\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // Create launch context for app master\n    LOG.info(\"Setting up application submission context for ASM\");\n    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n\n    // set the application id \n    appContext.setApplicationId(appId);\n    // set the application name\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n      .append(File.pathSeparatorChar).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(File.pathSeparatorChar);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    yarnClient.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "6b75a5c3b50877fc03574932ad54e4b4298f80d1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-831. Removed minimum resource from GetNewApplicationResponse as a follow-up to YARN-787. Contributed Jian He.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1493626 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/06/13 7:33 PM",
      "commitName": "6b75a5c3b50877fc03574932ad54e4b4298f80d1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "16/06/13 7:27 PM",
      "commitNameOld": "77e134d13fb87cd098f2e9c23212affe0a7be1be",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,270 +1,260 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     start();\n \n     YarnClusterMetrics clusterMetrics \u003d super.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d super.getNodeReports();\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d super.getQueueInfo(this.amQueue);\t\t\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d super.getQueueAclsInfo();\t\t\t\t\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id \n     GetNewApplicationResponse newApp \u003d super.getNewApplication();\n     ApplicationId appId \u003d newApp.getApplicationId();\n \n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n-    int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n     int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n-    LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n-    // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n-    // a multiple of the min value and cannot exceed the max. \n-    // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n-    if (amMemory \u003c minMem) {\n-      LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n-          + \", specified\u003d\" + amMemory\n-          + \", min\u003d\" + minMem);\n-      amMemory \u003d minMem; \n-    } \n-    else if (amMemory \u003e maxMem) {\n+    // A resource ask cannot exceed the max. \n+    if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     // Create launch context for app master\n     LOG.info(\"Setting up application submission context for ASM\");\n     ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n \n     // set the application id \n     appContext.setApplicationId(appId);\n     // set the application name\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n       .append(File.pathSeparatorChar).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(File.pathSeparatorChar);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, only memory is supported so we set memory requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // The following are not required for launching an application master \n     // amContainer.setContainerId(containerId);\t\t\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     super.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    start();\n\n    YarnClusterMetrics clusterMetrics \u003d super.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d super.getNodeReports();\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d super.getQueueInfo(this.amQueue);\t\t\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d super.getQueueAclsInfo();\t\t\t\t\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id \n    GetNewApplicationResponse newApp \u003d super.getNewApplication();\n    ApplicationId appId \u003d newApp.getApplicationId();\n\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask cannot exceed the max. \n    if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // Create launch context for app master\n    LOG.info(\"Setting up application submission context for ASM\");\n    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n\n    // set the application id \n    appContext.setApplicationId(appId);\n    // set the application name\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n      .append(File.pathSeparatorChar).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(File.pathSeparatorChar);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    super.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "af8514eef297574240652672d048748100c97733": {
      "type": "Ybodychange",
      "commitMessage": "YARN-686. Flatten NodeReport. (sandyr via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1490827 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/06/13 1:59 PM",
      "commitName": "af8514eef297574240652672d048748100c97733",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "03/06/13 9:05 PM",
      "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 3.7,
      "commitsBetweenForRepo": 29,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,271 +1,270 @@\n   public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     start();\n \n     YarnClusterMetrics clusterMetrics \u003d super.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d super.getNodeReports();\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n-          + \", nodeNumContainers\" + node.getNumContainers()\n-          + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n+          + \", nodeNumContainers\" + node.getNumContainers());\n     }\n \n     QueueInfo queueInfo \u003d super.getQueueInfo(this.amQueue);\t\t\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d super.getQueueAclsInfo();\t\t\t\t\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id \n     GetNewApplicationResponse newApp \u003d super.getNewApplication();\n     ApplicationId appId \u003d newApp.getApplicationId();\n \n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n     int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n     // a multiple of the min value and cannot exceed the max. \n     // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n     if (amMemory \u003c minMem) {\n       LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n           + \", specified\u003d\" + amMemory\n           + \", min\u003d\" + minMem);\n       amMemory \u003d minMem; \n     } \n     else if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     // Create launch context for app master\n     LOG.info(\"Setting up application submission context for ASM\");\n     ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n \n     // set the application id \n     appContext.setApplicationId(appId);\n     // set the application name\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n       .append(File.pathSeparatorChar).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(File.pathSeparatorChar);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, only memory is supported so we set memory requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // The following are not required for launching an application master \n     // amContainer.setContainerId(containerId);\t\t\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     super.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    start();\n\n    YarnClusterMetrics clusterMetrics \u003d super.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d super.getNodeReports();\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers());\n    }\n\n    QueueInfo queueInfo \u003d super.getQueueInfo(this.amQueue);\t\t\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d super.getQueueAclsInfo();\t\t\t\t\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id \n    GetNewApplicationResponse newApp \u003d super.getNewApplication();\n    ApplicationId appId \u003d newApp.getApplicationId();\n\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n    // a multiple of the min value and cannot exceed the max. \n    // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n    if (amMemory \u003c minMem) {\n      LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n          + \", specified\u003d\" + amMemory\n          + \", min\u003d\" + minMem);\n      amMemory \u003d minMem; \n    } \n    else if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // Create launch context for app master\n    LOG.info(\"Setting up application submission context for ASM\");\n    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n\n    // set the application id \n    appContext.setApplicationId(appId);\n    // set the application name\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n      .append(File.pathSeparatorChar).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(File.pathSeparatorChar);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    super.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "a83fb61ac07c0468cbc7a38526e92683883dd932": {
      "type": "Yexceptionschange",
      "commitMessage": "YARN-635. Renamed YarnRemoteException to YarnException. Contributed by Siddharth Seth.\nMAPREDUCE-5301. Updated MR code to work with YARN-635 changes of renaming YarnRemoteException to YarnException. Contributed by Siddharth Seth\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1489283 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/06/13 9:05 PM",
      "commitName": "a83fb61ac07c0468cbc7a38526e92683883dd932",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "08/05/13 3:53 PM",
      "commitNameOld": "0727ecaf50481fa7a529398bc2a12ce18c9a6b43",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 26.22,
      "commitsBetweenForRepo": 152,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,271 +1,271 @@\n-  public boolean run() throws IOException, YarnRemoteException {\n+  public boolean run() throws IOException, YarnException {\n \n     LOG.info(\"Running Client\");\n     start();\n \n     YarnClusterMetrics clusterMetrics \u003d super.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d super.getNodeReports();\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers()\n           + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n     }\n \n     QueueInfo queueInfo \u003d super.getQueueInfo(this.amQueue);\t\t\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d super.getQueueAclsInfo();\t\t\t\t\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id \n     GetNewApplicationResponse newApp \u003d super.getNewApplication();\n     ApplicationId appId \u003d newApp.getApplicationId();\n \n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n     int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n     // a multiple of the min value and cannot exceed the max. \n     // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n     if (amMemory \u003c minMem) {\n       LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n           + \", specified\u003d\" + amMemory\n           + \", min\u003d\" + minMem);\n       amMemory \u003d minMem; \n     } \n     else if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     // Create launch context for app master\n     LOG.info(\"Setting up application submission context for ASM\");\n     ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n \n     // set the application id \n     appContext.setApplicationId(appId);\n     // set the application name\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n       .append(File.pathSeparatorChar).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(File.pathSeparatorChar);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, only memory is supported so we set memory requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // The following are not required for launching an application master \n     // amContainer.setContainerId(containerId);\t\t\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     super.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnException {\n\n    LOG.info(\"Running Client\");\n    start();\n\n    YarnClusterMetrics clusterMetrics \u003d super.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d super.getNodeReports();\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers()\n          + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n    }\n\n    QueueInfo queueInfo \u003d super.getQueueInfo(this.amQueue);\t\t\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d super.getQueueAclsInfo();\t\t\t\t\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id \n    GetNewApplicationResponse newApp \u003d super.getNewApplication();\n    ApplicationId appId \u003d newApp.getApplicationId();\n\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n    // a multiple of the min value and cannot exceed the max. \n    // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n    if (amMemory \u003c minMem) {\n      LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n          + \", specified\u003d\" + amMemory\n          + \", min\u003d\" + minMem);\n      amMemory \u003d minMem; \n    } \n    else if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // Create launch context for app master\n    LOG.info(\"Setting up application submission context for ASM\");\n    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n\n    // set the application id \n    appContext.setApplicationId(appId);\n    // set the application name\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n      .append(File.pathSeparatorChar).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(File.pathSeparatorChar);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    super.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {
        "oldValue": "[IOException, YarnRemoteException]",
        "newValue": "[IOException, YarnException]"
      }
    },
    "92b7165a71656468f17ce8b760ce11e648932f0e": {
      "type": "Yexceptionschange",
      "commitMessage": "YARN-629. Make YarnRemoteException not be rooted at IOException. Contributed by Xuan Gong.\nMAPREDUCE-5204. Handling YarnRemoteException separately from IOException in MR app after YARN-629. Contributed by Xuan Gong.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1479680 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/05/13 12:04 PM",
      "commitName": "92b7165a71656468f17ce8b760ce11e648932f0e",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "11/04/13 12:28 PM",
      "commitNameOld": "e4c55e17fea55e2fcbef182bb2b0c4b22686f38c",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 24.98,
      "commitsBetweenForRepo": 133,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,271 +1,271 @@\n-  public boolean run() throws IOException {\n+  public boolean run() throws IOException, YarnRemoteException {\n \n     LOG.info(\"Running Client\");\n     start();\n \n     YarnClusterMetrics clusterMetrics \u003d super.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d super.getNodeReports();\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers()\n           + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n     }\n \n     QueueInfo queueInfo \u003d super.getQueueInfo(this.amQueue);\t\t\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d super.getQueueAclsInfo();\t\t\t\t\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id \n     GetNewApplicationResponse newApp \u003d super.getNewApplication();\n     ApplicationId appId \u003d newApp.getApplicationId();\n \n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n     int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n     // a multiple of the min value and cannot exceed the max. \n     // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n     if (amMemory \u003c minMem) {\n       LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n           + \", specified\u003d\" + amMemory\n           + \", min\u003d\" + minMem);\n       amMemory \u003d minMem; \n     } \n     else if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     // Create launch context for app master\n     LOG.info(\"Setting up application submission context for ASM\");\n     ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n \n     // set the application id \n     appContext.setApplicationId(appId);\n     // set the application name\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n       .append(File.pathSeparatorChar).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(File.pathSeparatorChar);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, only memory is supported so we set memory requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // The following are not required for launching an application master \n     // amContainer.setContainerId(containerId);\t\t\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n \n     super.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException, YarnRemoteException {\n\n    LOG.info(\"Running Client\");\n    start();\n\n    YarnClusterMetrics clusterMetrics \u003d super.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d super.getNodeReports();\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers()\n          + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n    }\n\n    QueueInfo queueInfo \u003d super.getQueueInfo(this.amQueue);\t\t\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d super.getQueueAclsInfo();\t\t\t\t\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id \n    GetNewApplicationResponse newApp \u003d super.getNewApplication();\n    ApplicationId appId \u003d newApp.getApplicationId();\n\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n    // a multiple of the min value and cannot exceed the max. \n    // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n    if (amMemory \u003c minMem) {\n      LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n          + \", specified\u003d\" + amMemory\n          + \", min\u003d\" + minMem);\n      amMemory \u003d minMem; \n    } \n    else if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // Create launch context for app master\n    LOG.info(\"Setting up application submission context for ASM\");\n    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n\n    // set the application id \n    appContext.setApplicationId(appId);\n    // set the application name\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n      .append(File.pathSeparatorChar).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(File.pathSeparatorChar);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    super.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {
        "oldValue": "[IOException]",
        "newValue": "[IOException, YarnRemoteException]"
      }
    },
    "e4c55e17fea55e2fcbef182bb2b0c4b22686f38c": {
      "type": "Ybodychange",
      "commitMessage": "YARN-486. Changed NM\u0027s startContainer API to accept Container record given by RM as a direct parameter instead of as part of the ContainerLaunchContext record. Contributed by Xuan Gong.\nMAPREDUCE-5139. Update MR AM to use the modified startContainer API after YARN-486. Contributed by Xuan Gong.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1467063 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/04/13 12:28 PM",
      "commitName": "e4c55e17fea55e2fcbef182bb2b0c4b22686f38c",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "21/03/13 1:48 PM",
      "commitNameOld": "d6b33ee981693169be688eb076998f1d0e4aa84d",
      "commitAuthorOld": "Hitesh Shah",
      "daysBetweenCommits": 20.94,
      "commitsBetweenForRepo": 121,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,270 +1,271 @@\n   public boolean run() throws IOException {\n \n     LOG.info(\"Running Client\");\n     start();\n \n     YarnClusterMetrics clusterMetrics \u003d super.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d super.getNodeReports();\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers()\n           + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n     }\n \n     QueueInfo queueInfo \u003d super.getQueueInfo(this.amQueue);\t\t\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d super.getQueueAclsInfo();\t\t\t\t\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id \n     GetNewApplicationResponse newApp \u003d super.getNewApplication();\n     ApplicationId appId \u003d newApp.getApplicationId();\n \n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n     int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n     // a multiple of the min value and cannot exceed the max. \n     // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n     if (amMemory \u003c minMem) {\n       LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n           + \", specified\u003d\" + amMemory\n           + \", min\u003d\" + minMem);\n       amMemory \u003d minMem; \n     } \n     else if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     // Create launch context for app master\n     LOG.info(\"Setting up application submission context for ASM\");\n     ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n \n     // set the application id \n     appContext.setApplicationId(appId);\n     // set the application name\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n       .append(File.pathSeparatorChar).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(File.pathSeparatorChar);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, only memory is supported so we set memory requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n-    amContainer.setResource(capability);\n+    appContext.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // The following are not required for launching an application master \n     // amContainer.setContainerId(containerId);\t\t\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n+\n     super.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException {\n\n    LOG.info(\"Running Client\");\n    start();\n\n    YarnClusterMetrics clusterMetrics \u003d super.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d super.getNodeReports();\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers()\n          + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n    }\n\n    QueueInfo queueInfo \u003d super.getQueueInfo(this.amQueue);\t\t\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d super.getQueueAclsInfo();\t\t\t\t\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id \n    GetNewApplicationResponse newApp \u003d super.getNewApplication();\n    ApplicationId appId \u003d newApp.getApplicationId();\n\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n    // a multiple of the min value and cannot exceed the max. \n    // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n    if (amMemory \u003c minMem) {\n      LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n          + \", specified\u003d\" + amMemory\n          + \", min\u003d\" + minMem);\n      amMemory \u003d minMem; \n    } \n    else if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // Create launch context for app master\n    LOG.info(\"Setting up application submission context for ASM\");\n    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n\n    // set the application id \n    appContext.setApplicationId(appId);\n    // set the application name\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n      .append(File.pathSeparatorChar).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(File.pathSeparatorChar);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    appContext.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n\n    super.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "d6b33ee981693169be688eb076998f1d0e4aa84d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-490. TestDistributedShell fails on Windows. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1459520 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/03/13 1:48 PM",
      "commitName": "d6b33ee981693169be688eb076998f1d0e4aa84d",
      "commitAuthor": "Hitesh Shah",
      "commitDateOld": "22/01/13 12:49 PM",
      "commitNameOld": "f5551bf8091c11586d402cdd4a0b09aa0498b673",
      "commitAuthorOld": "Hitesh Shah",
      "daysBetweenCommits": 58.0,
      "commitsBetweenForRepo": 249,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,269 +1,270 @@\n   public boolean run() throws IOException {\n \n     LOG.info(\"Running Client\");\n     start();\n \n     YarnClusterMetrics clusterMetrics \u003d super.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d super.getNodeReports();\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers()\n           + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n     }\n \n     QueueInfo queueInfo \u003d super.getQueueInfo(this.amQueue);\t\t\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d super.getQueueAclsInfo();\t\t\t\t\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id \n     GetNewApplicationResponse newApp \u003d super.getNewApplication();\n     ApplicationId appId \u003d newApp.getApplicationId();\n \n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n     int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n     // a multiple of the min value and cannot exceed the max. \n     // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n     if (amMemory \u003c minMem) {\n       LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n           + \", specified\u003d\" + amMemory\n           + \", min\u003d\" + minMem);\n       amMemory \u003d minMem; \n     } \n     else if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     // Create launch context for app master\n     LOG.info(\"Setting up application submission context for ASM\");\n     ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n \n     // set the application id \n     appContext.setApplicationId(appId);\n     // set the application name\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n-    StringBuilder classPathEnv \u003d new StringBuilder(\"${CLASSPATH}:./*\");\n+    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n+      .append(File.pathSeparatorChar).append(\"./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n-      classPathEnv.append(\u0027:\u0027);\n+      classPathEnv.append(File.pathSeparatorChar);\n       classPathEnv.append(c.trim());\n     }\n-    classPathEnv.append(\":./log4j.properties\");\n+    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(System.getProperty(\"java.class.path\"));\n     }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n-    vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n+    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, only memory is supported so we set memory requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     amContainer.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // The following are not required for launching an application master \n     // amContainer.setContainerId(containerId);\t\t\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n     super.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException {\n\n    LOG.info(\"Running Client\");\n    start();\n\n    YarnClusterMetrics clusterMetrics \u003d super.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d super.getNodeReports();\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers()\n          + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n    }\n\n    QueueInfo queueInfo \u003d super.getQueueInfo(this.amQueue);\t\t\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d super.getQueueAclsInfo();\t\t\t\t\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id \n    GetNewApplicationResponse newApp \u003d super.getNewApplication();\n    ApplicationId appId \u003d newApp.getApplicationId();\n\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n    // a multiple of the min value and cannot exceed the max. \n    // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n    if (amMemory \u003c minMem) {\n      LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n          + \", specified\u003d\" + amMemory\n          + \", min\u003d\" + minMem);\n      amMemory \u003d minMem; \n    } \n    else if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // Create launch context for app master\n    LOG.info(\"Setting up application submission context for ASM\");\n    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n\n    // set the application id \n    appContext.setApplicationId(appId);\n    // set the application name\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(Environment.CLASSPATH.$())\n      .append(File.pathSeparatorChar).append(\"./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(File.pathSeparatorChar);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(File.pathSeparatorChar).append(\"./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(Environment.JAVA_HOME.$() + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    amContainer.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n    super.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "e464607b7d156f20bb9ca19a2dfbd73edeaec722": {
      "type": "Ybodychange",
      "commitMessage": "YARN-129. Simplify classpath construction for mini YARN tests.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1411235 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/11/12 7:12 AM",
      "commitName": "e464607b7d156f20bb9ca19a2dfbd73edeaec722",
      "commitAuthor": "Thomas White",
      "commitDateOld": "09/10/12 12:40 PM",
      "commitNameOld": "bca57d471f4cc67bd5b73589cb941e868e0ca840",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 40.81,
      "commitsBetweenForRepo": 237,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,268 +1,269 @@\n   public boolean run() throws IOException {\n \n     LOG.info(\"Running Client\");\n     start();\n \n     YarnClusterMetrics clusterMetrics \u003d super.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n     List\u003cNodeReport\u003e clusterNodeReports \u003d super.getNodeReports();\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers()\n           + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n     }\n \n     QueueInfo queueInfo \u003d super.getQueueInfo(this.amQueue);\t\t\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d super.getQueueAclsInfo();\t\t\t\t\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id \n     GetNewApplicationResponse newApp \u003d super.getNewApplication();\n     ApplicationId appId \u003d newApp.getApplicationId();\n \n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n     int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n     // a multiple of the min value and cannot exceed the max. \n     // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n     if (amMemory \u003c minMem) {\n       LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n           + \", specified\u003d\" + amMemory\n           + \", min\u003d\" + minMem);\n       amMemory \u003d minMem; \n     } \n     else if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     // Create launch context for app master\n     LOG.info(\"Setting up application submission context for ASM\");\n     ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n \n     // set the application id \n     appContext.setApplicationId(appId);\n     // set the application name\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(\"${CLASSPATH}:./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(\":./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n-    String testRuntimeClassPath \u003d Client.getTestRuntimeClasspath();\n-    classPathEnv.append(\u0027:\u0027);\n-    classPathEnv.append(testRuntimeClassPath);\n+    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n+      classPathEnv.append(\u0027:\u0027);\n+      classPathEnv.append(System.getProperty(\"java.class.path\"));\n+    }\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, only memory is supported so we set memory requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     amContainer.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // The following are not required for launching an application master \n     // amContainer.setContainerId(containerId);\t\t\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n     super.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException {\n\n    LOG.info(\"Running Client\");\n    start();\n\n    YarnClusterMetrics clusterMetrics \u003d super.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d super.getNodeReports();\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers()\n          + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n    }\n\n    QueueInfo queueInfo \u003d super.getQueueInfo(this.amQueue);\t\t\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d super.getQueueAclsInfo();\t\t\t\t\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id \n    GetNewApplicationResponse newApp \u003d super.getNewApplication();\n    ApplicationId appId \u003d newApp.getApplicationId();\n\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n    // a multiple of the min value and cannot exceed the max. \n    // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n    if (amMemory \u003c minMem) {\n      LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n          + \", specified\u003d\" + amMemory\n          + \", min\u003d\" + minMem);\n      amMemory \u003d minMem; \n    } \n    else if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // Create launch context for app master\n    LOG.info(\"Setting up application submission context for ASM\");\n    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n\n    // set the application id \n    appContext.setApplicationId(appId);\n    // set the application name\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(\"${CLASSPATH}:./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(\":./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(System.getProperty(\"java.class.path\"));\n    }\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    amContainer.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n    super.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "10e704c50ba1fa601329d0fee099993e8c3725a6": {
      "type": "Ybodychange",
      "commitMessage": "YARN-29. Add a yarn-client module. (Contributed by Vinod Kumar Vavilapalli)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1377781 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/08/12 11:27 AM",
      "commitName": "10e704c50ba1fa601329d0fee099993e8c3725a6",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "07/08/12 10:22 PM",
      "commitNameOld": "e1fdf62123625e4ba399af02f8aad500637d29d1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 19.55,
      "commitsBetweenForRepo": 117,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,282 +1,268 @@\n   public boolean run() throws IOException {\n-    LOG.info(\"Starting Client\");\n \n-    // Connect to ResourceManager \t\n-    connectToASM();\n-    assert(applicationsManager !\u003d null);\t\t\n+    LOG.info(\"Running Client\");\n+    start();\n \n-    // Use ClientRMProtocol handle to general cluster information \n-    GetClusterMetricsRequest clusterMetricsReq \u003d Records.newRecord(GetClusterMetricsRequest.class);\n-    GetClusterMetricsResponse clusterMetricsResp \u003d applicationsManager.getClusterMetrics(clusterMetricsReq);\n+    YarnClusterMetrics clusterMetrics \u003d super.getYarnClusterMetrics();\n     LOG.info(\"Got Cluster metric info from ASM\" \n-        + \", numNodeManagers\u003d\" + clusterMetricsResp.getClusterMetrics().getNumNodeManagers());\n+        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n \n-    GetClusterNodesRequest clusterNodesReq \u003d Records.newRecord(GetClusterNodesRequest.class);\n-    GetClusterNodesResponse clusterNodesResp \u003d applicationsManager.getClusterNodes(clusterNodesReq);\n+    List\u003cNodeReport\u003e clusterNodeReports \u003d super.getNodeReports();\n     LOG.info(\"Got Cluster node info from ASM\");\n-    for (NodeReport node : clusterNodesResp.getNodeReports()) {\n+    for (NodeReport node : clusterNodeReports) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers()\n           + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n     }\n \n-    GetQueueInfoRequest queueInfoReq \u003d Records.newRecord(GetQueueInfoRequest.class);\n-    queueInfoReq.setQueueName(this.amQueue);\n-    GetQueueInfoResponse queueInfoResp \u003d applicationsManager.getQueueInfo(queueInfoReq);\t\t\n-    QueueInfo queueInfo \u003d queueInfoResp.getQueueInfo();\n+    QueueInfo queueInfo \u003d super.getQueueInfo(this.amQueue);\t\t\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n-    GetQueueUserAclsInfoRequest queueUserAclsReq \u003d Records.newRecord(GetQueueUserAclsInfoRequest.class);\n-    GetQueueUserAclsInfoResponse queueUserAclsResp \u003d applicationsManager.getQueueUserAcls(queueUserAclsReq);\t\t\t\t\n-    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d queueUserAclsResp.getUserAclsInfoList();\n+    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d super.getQueueAclsInfo();\t\t\t\t\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id \n-    GetNewApplicationResponse newApp \u003d getApplication();\n+    GetNewApplicationResponse newApp \u003d super.getNewApplication();\n     ApplicationId appId \u003d newApp.getApplicationId();\n \n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n     int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n     // a multiple of the min value and cannot exceed the max. \n     // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n     if (amMemory \u003c minMem) {\n       LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n           + \", specified\u003d\" + amMemory\n           + \", min\u003d\" + minMem);\n       amMemory \u003d minMem; \n     } \n     else if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     // Create launch context for app master\n     LOG.info(\"Setting up application submission context for ASM\");\n     ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n \n     // set the application id \n     appContext.setApplicationId(appId);\n     // set the application name\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(\"${CLASSPATH}:./*\");\n     for (String c : conf.getStrings(\n         YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n         YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(\":./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     String testRuntimeClassPath \u003d Client.getTestRuntimeClasspath();\n     classPathEnv.append(\u0027:\u0027);\n     classPathEnv.append(testRuntimeClassPath);\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, only memory is supported so we set memory requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     amContainer.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // The following are not required for launching an application master \n     // amContainer.setContainerId(containerId);\t\t\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n-    // Create the request to send to the applications manager \n-    SubmitApplicationRequest appRequest \u003d Records.newRecord(SubmitApplicationRequest.class);\n-    appRequest.setApplicationSubmissionContext(appContext);\n-\n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n-    applicationsManager.submitApplication(appRequest);\n+    super.submitApplication(appContext);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException {\n\n    LOG.info(\"Running Client\");\n    start();\n\n    YarnClusterMetrics clusterMetrics \u003d super.getYarnClusterMetrics();\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetrics.getNumNodeManagers());\n\n    List\u003cNodeReport\u003e clusterNodeReports \u003d super.getNodeReports();\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodeReports) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers()\n          + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n    }\n\n    QueueInfo queueInfo \u003d super.getQueueInfo(this.amQueue);\t\t\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d super.getQueueAclsInfo();\t\t\t\t\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id \n    GetNewApplicationResponse newApp \u003d super.getNewApplication();\n    ApplicationId appId \u003d newApp.getApplicationId();\n\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n    // a multiple of the min value and cannot exceed the max. \n    // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n    if (amMemory \u003c minMem) {\n      LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n          + \", specified\u003d\" + amMemory\n          + \", min\u003d\" + minMem);\n      amMemory \u003d minMem; \n    } \n    else if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // Create launch context for app master\n    LOG.info(\"Setting up application submission context for ASM\");\n    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n\n    // set the application id \n    appContext.setApplicationId(appId);\n    // set the application name\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(\"${CLASSPATH}:./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(\":./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    String testRuntimeClassPath \u003d Client.getTestRuntimeClasspath();\n    classPathEnv.append(\u0027:\u0027);\n    classPathEnv.append(testRuntimeClassPath);\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    amContainer.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n    super.submitApplication(appContext);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "e1fdf62123625e4ba399af02f8aad500637d29d1": {
      "type": "Yfilerename",
      "commitMessage": "YARN-1. Promote YARN to be a sub-project of Apache Hadoop.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370666 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/12 10:22 PM",
      "commitName": "e1fdf62123625e4ba399af02f8aad500637d29d1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "07/08/12 7:53 PM",
      "commitNameOld": "34554d1e11ee1d5b564d7d9ed3e6d55931d72749",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public boolean run() throws IOException {\n    LOG.info(\"Starting Client\");\n\n    // Connect to ResourceManager \t\n    connectToASM();\n    assert(applicationsManager !\u003d null);\t\t\n\n    // Use ClientRMProtocol handle to general cluster information \n    GetClusterMetricsRequest clusterMetricsReq \u003d Records.newRecord(GetClusterMetricsRequest.class);\n    GetClusterMetricsResponse clusterMetricsResp \u003d applicationsManager.getClusterMetrics(clusterMetricsReq);\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetricsResp.getClusterMetrics().getNumNodeManagers());\n\n    GetClusterNodesRequest clusterNodesReq \u003d Records.newRecord(GetClusterNodesRequest.class);\n    GetClusterNodesResponse clusterNodesResp \u003d applicationsManager.getClusterNodes(clusterNodesReq);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodesResp.getNodeReports()) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers()\n          + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n    }\n\n    GetQueueInfoRequest queueInfoReq \u003d Records.newRecord(GetQueueInfoRequest.class);\n    queueInfoReq.setQueueName(this.amQueue);\n    GetQueueInfoResponse queueInfoResp \u003d applicationsManager.getQueueInfo(queueInfoReq);\t\t\n    QueueInfo queueInfo \u003d queueInfoResp.getQueueInfo();\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    GetQueueUserAclsInfoRequest queueUserAclsReq \u003d Records.newRecord(GetQueueUserAclsInfoRequest.class);\n    GetQueueUserAclsInfoResponse queueUserAclsResp \u003d applicationsManager.getQueueUserAcls(queueUserAclsReq);\t\t\t\t\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d queueUserAclsResp.getUserAclsInfoList();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id \n    GetNewApplicationResponse newApp \u003d getApplication();\n    ApplicationId appId \u003d newApp.getApplicationId();\n\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n    // a multiple of the min value and cannot exceed the max. \n    // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n    if (amMemory \u003c minMem) {\n      LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n          + \", specified\u003d\" + amMemory\n          + \", min\u003d\" + minMem);\n      amMemory \u003d minMem; \n    } \n    else if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // Create launch context for app master\n    LOG.info(\"Setting up application submission context for ASM\");\n    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n\n    // set the application id \n    appContext.setApplicationId(appId);\n    // set the application name\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(\"${CLASSPATH}:./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(\":./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    String testRuntimeClassPath \u003d Client.getTestRuntimeClasspath();\n    classPathEnv.append(\u0027:\u0027);\n    classPathEnv.append(testRuntimeClassPath);\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    amContainer.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Create the request to send to the applications manager \n    SubmitApplicationRequest appRequest \u003d Records.newRecord(SubmitApplicationRequest.class);\n    appRequest.setApplicationSubmissionContext(appContext);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n    applicationsManager.submitApplication(appRequest);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java"
      }
    },
    "2e00d28f1413fcb5afbcbda836dfb9ea6cf3a5a1": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4422. YARN_APPLICATION_CLASSPATH needs a documented default value in YarnConfiguration. (ahmed via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1362722 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/07/12 4:31 PM",
      "commitName": "2e00d28f1413fcb5afbcbda836dfb9ea6cf3a5a1",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "25/06/12 8:58 AM",
      "commitNameOld": "db31b6c0e4aa1f6cd2d655a48195fdfb76bc5329",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 22.31,
      "commitsBetweenForRepo": 155,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,281 +1,282 @@\n   public boolean run() throws IOException {\n     LOG.info(\"Starting Client\");\n \n     // Connect to ResourceManager \t\n     connectToASM();\n     assert(applicationsManager !\u003d null);\t\t\n \n     // Use ClientRMProtocol handle to general cluster information \n     GetClusterMetricsRequest clusterMetricsReq \u003d Records.newRecord(GetClusterMetricsRequest.class);\n     GetClusterMetricsResponse clusterMetricsResp \u003d applicationsManager.getClusterMetrics(clusterMetricsReq);\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetricsResp.getClusterMetrics().getNumNodeManagers());\n \n     GetClusterNodesRequest clusterNodesReq \u003d Records.newRecord(GetClusterNodesRequest.class);\n     GetClusterNodesResponse clusterNodesResp \u003d applicationsManager.getClusterNodes(clusterNodesReq);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodesResp.getNodeReports()) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers()\n           + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n     }\n \n     GetQueueInfoRequest queueInfoReq \u003d Records.newRecord(GetQueueInfoRequest.class);\n     queueInfoReq.setQueueName(this.amQueue);\n     GetQueueInfoResponse queueInfoResp \u003d applicationsManager.getQueueInfo(queueInfoReq);\t\t\n     QueueInfo queueInfo \u003d queueInfoResp.getQueueInfo();\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     GetQueueUserAclsInfoRequest queueUserAclsReq \u003d Records.newRecord(GetQueueUserAclsInfoRequest.class);\n     GetQueueUserAclsInfoResponse queueUserAclsResp \u003d applicationsManager.getQueueUserAcls(queueUserAclsReq);\t\t\t\t\n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d queueUserAclsResp.getUserAclsInfoList();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id \n     GetNewApplicationResponse newApp \u003d getApplication();\n     ApplicationId appId \u003d newApp.getApplicationId();\n \n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n     int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n     // a multiple of the min value and cannot exceed the max. \n     // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n     if (amMemory \u003c minMem) {\n       LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n           + \", specified\u003d\" + amMemory\n           + \", min\u003d\" + minMem);\n       amMemory \u003d minMem; \n     } \n     else if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     // Create launch context for app master\n     LOG.info(\"Setting up application submission context for ASM\");\n     ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n \n     // set the application id \n     appContext.setApplicationId(appId);\n     // set the application name\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(\"${CLASSPATH}:./*\");\n-    for (String c : conf.get(YarnConfiguration.YARN_APPLICATION_CLASSPATH)\n-        .split(\",\")) {\n+    for (String c : conf.getStrings(\n+        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n+        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(\":./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     String testRuntimeClassPath \u003d Client.getTestRuntimeClasspath();\n     classPathEnv.append(\u0027:\u0027);\n     classPathEnv.append(testRuntimeClassPath);\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, only memory is supported so we set memory requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     amContainer.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // The following are not required for launching an application master \n     // amContainer.setContainerId(containerId);\t\t\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Create the request to send to the applications manager \n     SubmitApplicationRequest appRequest \u003d Records.newRecord(SubmitApplicationRequest.class);\n     appRequest.setApplicationSubmissionContext(appContext);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n     applicationsManager.submitApplication(appRequest);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException {\n    LOG.info(\"Starting Client\");\n\n    // Connect to ResourceManager \t\n    connectToASM();\n    assert(applicationsManager !\u003d null);\t\t\n\n    // Use ClientRMProtocol handle to general cluster information \n    GetClusterMetricsRequest clusterMetricsReq \u003d Records.newRecord(GetClusterMetricsRequest.class);\n    GetClusterMetricsResponse clusterMetricsResp \u003d applicationsManager.getClusterMetrics(clusterMetricsReq);\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetricsResp.getClusterMetrics().getNumNodeManagers());\n\n    GetClusterNodesRequest clusterNodesReq \u003d Records.newRecord(GetClusterNodesRequest.class);\n    GetClusterNodesResponse clusterNodesResp \u003d applicationsManager.getClusterNodes(clusterNodesReq);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodesResp.getNodeReports()) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers()\n          + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n    }\n\n    GetQueueInfoRequest queueInfoReq \u003d Records.newRecord(GetQueueInfoRequest.class);\n    queueInfoReq.setQueueName(this.amQueue);\n    GetQueueInfoResponse queueInfoResp \u003d applicationsManager.getQueueInfo(queueInfoReq);\t\t\n    QueueInfo queueInfo \u003d queueInfoResp.getQueueInfo();\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    GetQueueUserAclsInfoRequest queueUserAclsReq \u003d Records.newRecord(GetQueueUserAclsInfoRequest.class);\n    GetQueueUserAclsInfoResponse queueUserAclsResp \u003d applicationsManager.getQueueUserAcls(queueUserAclsReq);\t\t\t\t\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d queueUserAclsResp.getUserAclsInfoList();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id \n    GetNewApplicationResponse newApp \u003d getApplication();\n    ApplicationId appId \u003d newApp.getApplicationId();\n\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n    // a multiple of the min value and cannot exceed the max. \n    // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n    if (amMemory \u003c minMem) {\n      LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n          + \", specified\u003d\" + amMemory\n          + \", min\u003d\" + minMem);\n      amMemory \u003d minMem; \n    } \n    else if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // Create launch context for app master\n    LOG.info(\"Setting up application submission context for ASM\");\n    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n\n    // set the application id \n    appContext.setApplicationId(appId);\n    // set the application name\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(\"${CLASSPATH}:./*\");\n    for (String c : conf.getStrings(\n        YarnConfiguration.YARN_APPLICATION_CLASSPATH,\n        YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(\":./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    String testRuntimeClassPath \u003d Client.getTestRuntimeClasspath();\n    classPathEnv.append(\u0027:\u0027);\n    classPathEnv.append(testRuntimeClassPath);\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    amContainer.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Create the request to send to the applications manager \n    SubmitApplicationRequest appRequest \u003d Records.newRecord(SubmitApplicationRequest.class);\n    appRequest.setApplicationSubmissionContext(appContext);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n    applicationsManager.submitApplication(appRequest);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "db31b6c0e4aa1f6cd2d655a48195fdfb76bc5329": {
      "type": "Ybodychange",
      "commitMessage": " MAPREDUCE-4336. Distributed Shell fails when used with the CapacityScheduler (ahmed via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1353625 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/06/12 8:58 AM",
      "commitName": "db31b6c0e4aa1f6cd2d655a48195fdfb76bc5329",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "19/06/12 3:00 PM",
      "commitNameOld": "daa28cc6ce23ef5c8db8b9f896f342cb770dd092",
      "commitAuthorOld": "Siddharth Seth",
      "daysBetweenCommits": 5.75,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,280 +1,281 @@\n   public boolean run() throws IOException {\n     LOG.info(\"Starting Client\");\n \n     // Connect to ResourceManager \t\n     connectToASM();\n     assert(applicationsManager !\u003d null);\t\t\n \n     // Use ClientRMProtocol handle to general cluster information \n     GetClusterMetricsRequest clusterMetricsReq \u003d Records.newRecord(GetClusterMetricsRequest.class);\n     GetClusterMetricsResponse clusterMetricsResp \u003d applicationsManager.getClusterMetrics(clusterMetricsReq);\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetricsResp.getClusterMetrics().getNumNodeManagers());\n \n     GetClusterNodesRequest clusterNodesReq \u003d Records.newRecord(GetClusterNodesRequest.class);\n     GetClusterNodesResponse clusterNodesResp \u003d applicationsManager.getClusterNodes(clusterNodesReq);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodesResp.getNodeReports()) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers()\n           + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n     }\n \n     GetQueueInfoRequest queueInfoReq \u003d Records.newRecord(GetQueueInfoRequest.class);\n+    queueInfoReq.setQueueName(this.amQueue);\n     GetQueueInfoResponse queueInfoResp \u003d applicationsManager.getQueueInfo(queueInfoReq);\t\t\n     QueueInfo queueInfo \u003d queueInfoResp.getQueueInfo();\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     GetQueueUserAclsInfoRequest queueUserAclsReq \u003d Records.newRecord(GetQueueUserAclsInfoRequest.class);\n     GetQueueUserAclsInfoResponse queueUserAclsResp \u003d applicationsManager.getQueueUserAcls(queueUserAclsReq);\t\t\t\t\n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d queueUserAclsResp.getUserAclsInfoList();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id \n     GetNewApplicationResponse newApp \u003d getApplication();\n     ApplicationId appId \u003d newApp.getApplicationId();\n \n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n     int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n     // a multiple of the min value and cannot exceed the max. \n     // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n     if (amMemory \u003c minMem) {\n       LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n           + \", specified\u003d\" + amMemory\n           + \", min\u003d\" + minMem);\n       amMemory \u003d minMem; \n     } \n     else if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     // Create launch context for app master\n     LOG.info(\"Setting up application submission context for ASM\");\n     ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n \n     // set the application id \n     appContext.setApplicationId(appId);\n     // set the application name\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(\"${CLASSPATH}:./*\");\n     for (String c : conf.get(YarnConfiguration.YARN_APPLICATION_CLASSPATH)\n         .split(\",\")) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(\":./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     String testRuntimeClassPath \u003d Client.getTestRuntimeClasspath();\n     classPathEnv.append(\u0027:\u0027);\n     classPathEnv.append(testRuntimeClassPath);\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // Set up resource type requirements\n     // For now, only memory is supported so we set memory requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     amContainer.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // The following are not required for launching an application master \n     // amContainer.setContainerId(containerId);\t\t\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n \n     // Create the request to send to the applications manager \n     SubmitApplicationRequest appRequest \u003d Records.newRecord(SubmitApplicationRequest.class);\n     appRequest.setApplicationSubmissionContext(appContext);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n     applicationsManager.submitApplication(appRequest);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException {\n    LOG.info(\"Starting Client\");\n\n    // Connect to ResourceManager \t\n    connectToASM();\n    assert(applicationsManager !\u003d null);\t\t\n\n    // Use ClientRMProtocol handle to general cluster information \n    GetClusterMetricsRequest clusterMetricsReq \u003d Records.newRecord(GetClusterMetricsRequest.class);\n    GetClusterMetricsResponse clusterMetricsResp \u003d applicationsManager.getClusterMetrics(clusterMetricsReq);\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetricsResp.getClusterMetrics().getNumNodeManagers());\n\n    GetClusterNodesRequest clusterNodesReq \u003d Records.newRecord(GetClusterNodesRequest.class);\n    GetClusterNodesResponse clusterNodesResp \u003d applicationsManager.getClusterNodes(clusterNodesReq);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodesResp.getNodeReports()) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers()\n          + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n    }\n\n    GetQueueInfoRequest queueInfoReq \u003d Records.newRecord(GetQueueInfoRequest.class);\n    queueInfoReq.setQueueName(this.amQueue);\n    GetQueueInfoResponse queueInfoResp \u003d applicationsManager.getQueueInfo(queueInfoReq);\t\t\n    QueueInfo queueInfo \u003d queueInfoResp.getQueueInfo();\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    GetQueueUserAclsInfoRequest queueUserAclsReq \u003d Records.newRecord(GetQueueUserAclsInfoRequest.class);\n    GetQueueUserAclsInfoResponse queueUserAclsResp \u003d applicationsManager.getQueueUserAcls(queueUserAclsReq);\t\t\t\t\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d queueUserAclsResp.getUserAclsInfoList();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id \n    GetNewApplicationResponse newApp \u003d getApplication();\n    ApplicationId appId \u003d newApp.getApplicationId();\n\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n    // a multiple of the min value and cannot exceed the max. \n    // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n    if (amMemory \u003c minMem) {\n      LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n          + \", specified\u003d\" + amMemory\n          + \", min\u003d\" + minMem);\n      amMemory \u003d minMem; \n    } \n    else if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // Create launch context for app master\n    LOG.info(\"Setting up application submission context for ASM\");\n    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n\n    // set the application id \n    appContext.setApplicationId(appId);\n    // set the application name\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(\"${CLASSPATH}:./*\");\n    for (String c : conf.get(YarnConfiguration.YARN_APPLICATION_CLASSPATH)\n        .split(\",\")) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(\":./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    String testRuntimeClassPath \u003d Client.getTestRuntimeClasspath();\n    classPathEnv.append(\u0027:\u0027);\n    classPathEnv.append(testRuntimeClassPath);\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    amContainer.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Create the request to send to the applications manager \n    SubmitApplicationRequest appRequest \u003d Records.newRecord(SubmitApplicationRequest.class);\n    appRequest.setApplicationSubmissionContext(appContext);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n    applicationsManager.submitApplication(appRequest);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "daa28cc6ce23ef5c8db8b9f896f342cb770dd092": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4306. Fix distributed shell to work with users other than the one running the daemons. (Contributed by Ahmed Radwan)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1351876 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/06/12 3:00 PM",
      "commitName": "daa28cc6ce23ef5c8db8b9f896f342cb770dd092",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "19/04/12 1:33 PM",
      "commitNameOld": "df654cca49c12ab3fa8ec1e626da1bb562bbb6c1",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 61.06,
      "commitsBetweenForRepo": 319,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,287 +1,280 @@\n   public boolean run() throws IOException {\n     LOG.info(\"Starting Client\");\n \n     // Connect to ResourceManager \t\n     connectToASM();\n     assert(applicationsManager !\u003d null);\t\t\n \n     // Use ClientRMProtocol handle to general cluster information \n     GetClusterMetricsRequest clusterMetricsReq \u003d Records.newRecord(GetClusterMetricsRequest.class);\n     GetClusterMetricsResponse clusterMetricsResp \u003d applicationsManager.getClusterMetrics(clusterMetricsReq);\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetricsResp.getClusterMetrics().getNumNodeManagers());\n \n     GetClusterNodesRequest clusterNodesReq \u003d Records.newRecord(GetClusterNodesRequest.class);\n     GetClusterNodesResponse clusterNodesResp \u003d applicationsManager.getClusterNodes(clusterNodesReq);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodesResp.getNodeReports()) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers()\n           + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n     }\n \n     GetQueueInfoRequest queueInfoReq \u003d Records.newRecord(GetQueueInfoRequest.class);\n     GetQueueInfoResponse queueInfoResp \u003d applicationsManager.getQueueInfo(queueInfoReq);\t\t\n     QueueInfo queueInfo \u003d queueInfoResp.getQueueInfo();\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     GetQueueUserAclsInfoRequest queueUserAclsReq \u003d Records.newRecord(GetQueueUserAclsInfoRequest.class);\n     GetQueueUserAclsInfoResponse queueUserAclsResp \u003d applicationsManager.getQueueUserAcls(queueUserAclsReq);\t\t\t\t\n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d queueUserAclsResp.getUserAclsInfoList();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id \n     GetNewApplicationResponse newApp \u003d getApplication();\n     ApplicationId appId \u003d newApp.getApplicationId();\n \n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n     int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n     // a multiple of the min value and cannot exceed the max. \n     // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n     if (amMemory \u003c minMem) {\n       LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n           + \", specified\u003d\" + amMemory\n           + \", min\u003d\" + minMem);\n       amMemory \u003d minMem; \n     } \n     else if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     // Create launch context for app master\n     LOG.info(\"Setting up application submission context for ASM\");\n     ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n \n     // set the application id \n     appContext.setApplicationId(appId);\n     // set the application name\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     StringBuilder classPathEnv \u003d new StringBuilder(\"${CLASSPATH}:./*\");\n     for (String c : conf.get(YarnConfiguration.YARN_APPLICATION_CLASSPATH)\n         .split(\",\")) {\n       classPathEnv.append(\u0027:\u0027);\n       classPathEnv.append(c.trim());\n     }\n     classPathEnv.append(\":./log4j.properties\");\n \n     // add the runtime classpath needed for tests to work\n     String testRuntimeClassPath \u003d Client.getTestRuntimeClasspath();\n     classPathEnv.append(\u0027:\u0027);\n     classPathEnv.append(testRuntimeClassPath);\n \n     env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n-    // For launching an AM Container, setting user here is not needed\n-    // Set user in ApplicationSubmissionContext\n-    // amContainer.setUser(amUser);\n-\n     // Set up resource type requirements\n     // For now, only memory is supported so we set memory requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     amContainer.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // The following are not required for launching an application master \n     // amContainer.setContainerId(containerId);\t\t\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n-    // Set the user submitting this application \n-    // TODO can it be empty? \n-    appContext.setUser(amUser);\n \n     // Create the request to send to the applications manager \n     SubmitApplicationRequest appRequest \u003d Records.newRecord(SubmitApplicationRequest.class);\n     appRequest.setApplicationSubmissionContext(appContext);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n     applicationsManager.submitApplication(appRequest);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException {\n    LOG.info(\"Starting Client\");\n\n    // Connect to ResourceManager \t\n    connectToASM();\n    assert(applicationsManager !\u003d null);\t\t\n\n    // Use ClientRMProtocol handle to general cluster information \n    GetClusterMetricsRequest clusterMetricsReq \u003d Records.newRecord(GetClusterMetricsRequest.class);\n    GetClusterMetricsResponse clusterMetricsResp \u003d applicationsManager.getClusterMetrics(clusterMetricsReq);\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetricsResp.getClusterMetrics().getNumNodeManagers());\n\n    GetClusterNodesRequest clusterNodesReq \u003d Records.newRecord(GetClusterNodesRequest.class);\n    GetClusterNodesResponse clusterNodesResp \u003d applicationsManager.getClusterNodes(clusterNodesReq);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodesResp.getNodeReports()) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers()\n          + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n    }\n\n    GetQueueInfoRequest queueInfoReq \u003d Records.newRecord(GetQueueInfoRequest.class);\n    GetQueueInfoResponse queueInfoResp \u003d applicationsManager.getQueueInfo(queueInfoReq);\t\t\n    QueueInfo queueInfo \u003d queueInfoResp.getQueueInfo();\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    GetQueueUserAclsInfoRequest queueUserAclsReq \u003d Records.newRecord(GetQueueUserAclsInfoRequest.class);\n    GetQueueUserAclsInfoResponse queueUserAclsResp \u003d applicationsManager.getQueueUserAcls(queueUserAclsReq);\t\t\t\t\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d queueUserAclsResp.getUserAclsInfoList();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id \n    GetNewApplicationResponse newApp \u003d getApplication();\n    ApplicationId appId \u003d newApp.getApplicationId();\n\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n    // a multiple of the min value and cannot exceed the max. \n    // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n    if (amMemory \u003c minMem) {\n      LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n          + \", specified\u003d\" + amMemory\n          + \", min\u003d\" + minMem);\n      amMemory \u003d minMem; \n    } \n    else if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // Create launch context for app master\n    LOG.info(\"Setting up application submission context for ASM\");\n    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n\n    // set the application id \n    appContext.setApplicationId(appId);\n    // set the application name\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(\"${CLASSPATH}:./*\");\n    for (String c : conf.get(YarnConfiguration.YARN_APPLICATION_CLASSPATH)\n        .split(\",\")) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(\":./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    String testRuntimeClassPath \u003d Client.getTestRuntimeClasspath();\n    classPathEnv.append(\u0027:\u0027);\n    classPathEnv.append(testRuntimeClassPath);\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    amContainer.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n\n    // Create the request to send to the applications manager \n    SubmitApplicationRequest appRequest \u003d Records.newRecord(SubmitApplicationRequest.class);\n    appRequest.setApplicationSubmissionContext(appContext);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n    applicationsManager.submitApplication(appRequest);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "b28f134e9cc61c49b404eaacf8a321bb12b78969": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3869. Fix classpath for DistributedShell application. (Contributed by Devaraj K)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1311523 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/04/12 5:01 PM",
      "commitName": "b28f134e9cc61c49b404eaacf8a321bb12b78969",
      "commitAuthor": "Siddharth Seth",
      "commitDateOld": "06/02/12 5:53 PM",
      "commitNameOld": "aaace5e84e9fadd817c984353e299745ff2fc334",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 62.92,
      "commitsBetweenForRepo": 473,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,289 +1,287 @@\n   public boolean run() throws IOException {\n     LOG.info(\"Starting Client\");\n \n     // Connect to ResourceManager \t\n     connectToASM();\n     assert(applicationsManager !\u003d null);\t\t\n \n     // Use ClientRMProtocol handle to general cluster information \n     GetClusterMetricsRequest clusterMetricsReq \u003d Records.newRecord(GetClusterMetricsRequest.class);\n     GetClusterMetricsResponse clusterMetricsResp \u003d applicationsManager.getClusterMetrics(clusterMetricsReq);\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetricsResp.getClusterMetrics().getNumNodeManagers());\n \n     GetClusterNodesRequest clusterNodesReq \u003d Records.newRecord(GetClusterNodesRequest.class);\n     GetClusterNodesResponse clusterNodesResp \u003d applicationsManager.getClusterNodes(clusterNodesReq);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodesResp.getNodeReports()) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers()\n           + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n     }\n \n     GetQueueInfoRequest queueInfoReq \u003d Records.newRecord(GetQueueInfoRequest.class);\n     GetQueueInfoResponse queueInfoResp \u003d applicationsManager.getQueueInfo(queueInfoReq);\t\t\n     QueueInfo queueInfo \u003d queueInfoResp.getQueueInfo();\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     GetQueueUserAclsInfoRequest queueUserAclsReq \u003d Records.newRecord(GetQueueUserAclsInfoRequest.class);\n     GetQueueUserAclsInfoResponse queueUserAclsResp \u003d applicationsManager.getQueueUserAcls(queueUserAclsReq);\t\t\t\t\n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d queueUserAclsResp.getUserAclsInfoList();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id \n     GetNewApplicationResponse newApp \u003d getApplication();\n     ApplicationId appId \u003d newApp.getApplicationId();\n \n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n     int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n     // a multiple of the min value and cannot exceed the max. \n     // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n     if (amMemory \u003c minMem) {\n       LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n           + \", specified\u003d\" + amMemory\n           + \", min\u003d\" + minMem);\n       amMemory \u003d minMem; \n     } \n     else if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     // Create launch context for app master\n     LOG.info(\"Setting up application submission context for ASM\");\n     ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n \n     // set the application id \n     appContext.setApplicationId(appId);\n     // set the application name\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n-    String classPathEnv \u003d \"${CLASSPATH}\"\n-        + \":./*\"\n-        + \":$HADOOP_CONF_DIR\"\n-        + \":$HADOOP_COMMON_HOME/share/hadoop/common/*\"\n-        + \":$HADOOP_COMMON_HOME/share/hadoop/common/lib/*\"\n-        + \":$HADOOP_HDFS_HOME/share/hadoop/hdfs/*\"\n-        + \":$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*\"\n-        + \":$YARN_HOME/modules/*\"\n-        + \":$YARN_HOME/lib/*\"\n-        + \":./log4j.properties:\";\n+    StringBuilder classPathEnv \u003d new StringBuilder(\"${CLASSPATH}:./*\");\n+    for (String c : conf.get(YarnConfiguration.YARN_APPLICATION_CLASSPATH)\n+        .split(\",\")) {\n+      classPathEnv.append(\u0027:\u0027);\n+      classPathEnv.append(c.trim());\n+    }\n+    classPathEnv.append(\":./log4j.properties\");\n \n-    // add the runtime classpath needed for tests to work \n+    // add the runtime classpath needed for tests to work\n     String testRuntimeClassPath \u003d Client.getTestRuntimeClasspath();\n-    classPathEnv +\u003d \":\" + testRuntimeClassPath; \n+    classPathEnv.append(\u0027:\u0027);\n+    classPathEnv.append(testRuntimeClassPath);\n \n-    env.put(\"CLASSPATH\", classPathEnv);\n+    env.put(\"CLASSPATH\", classPathEnv.toString());\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n     // Set Xmx based on am memory size\n     vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // For launching an AM Container, setting user here is not needed\n     // Set user in ApplicationSubmissionContext\n     // amContainer.setUser(amUser);\n \n     // Set up resource type requirements\n     // For now, only memory is supported so we set memory requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     amContainer.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // The following are not required for launching an application master \n     // amContainer.setContainerId(containerId);\t\t\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n     // Set the user submitting this application \n     // TODO can it be empty? \n     appContext.setUser(amUser);\n \n     // Create the request to send to the applications manager \n     SubmitApplicationRequest appRequest \u003d Records.newRecord(SubmitApplicationRequest.class);\n     appRequest.setApplicationSubmissionContext(appContext);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n     applicationsManager.submitApplication(appRequest);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException {\n    LOG.info(\"Starting Client\");\n\n    // Connect to ResourceManager \t\n    connectToASM();\n    assert(applicationsManager !\u003d null);\t\t\n\n    // Use ClientRMProtocol handle to general cluster information \n    GetClusterMetricsRequest clusterMetricsReq \u003d Records.newRecord(GetClusterMetricsRequest.class);\n    GetClusterMetricsResponse clusterMetricsResp \u003d applicationsManager.getClusterMetrics(clusterMetricsReq);\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetricsResp.getClusterMetrics().getNumNodeManagers());\n\n    GetClusterNodesRequest clusterNodesReq \u003d Records.newRecord(GetClusterNodesRequest.class);\n    GetClusterNodesResponse clusterNodesResp \u003d applicationsManager.getClusterNodes(clusterNodesReq);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodesResp.getNodeReports()) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers()\n          + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n    }\n\n    GetQueueInfoRequest queueInfoReq \u003d Records.newRecord(GetQueueInfoRequest.class);\n    GetQueueInfoResponse queueInfoResp \u003d applicationsManager.getQueueInfo(queueInfoReq);\t\t\n    QueueInfo queueInfo \u003d queueInfoResp.getQueueInfo();\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    GetQueueUserAclsInfoRequest queueUserAclsReq \u003d Records.newRecord(GetQueueUserAclsInfoRequest.class);\n    GetQueueUserAclsInfoResponse queueUserAclsResp \u003d applicationsManager.getQueueUserAcls(queueUserAclsReq);\t\t\t\t\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d queueUserAclsResp.getUserAclsInfoList();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id \n    GetNewApplicationResponse newApp \u003d getApplication();\n    ApplicationId appId \u003d newApp.getApplicationId();\n\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n    // a multiple of the min value and cannot exceed the max. \n    // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n    if (amMemory \u003c minMem) {\n      LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n          + \", specified\u003d\" + amMemory\n          + \", min\u003d\" + minMem);\n      amMemory \u003d minMem; \n    } \n    else if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // Create launch context for app master\n    LOG.info(\"Setting up application submission context for ASM\");\n    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n\n    // set the application id \n    appContext.setApplicationId(appId);\n    // set the application name\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    StringBuilder classPathEnv \u003d new StringBuilder(\"${CLASSPATH}:./*\");\n    for (String c : conf.get(YarnConfiguration.YARN_APPLICATION_CLASSPATH)\n        .split(\",\")) {\n      classPathEnv.append(\u0027:\u0027);\n      classPathEnv.append(c.trim());\n    }\n    classPathEnv.append(\":./log4j.properties\");\n\n    // add the runtime classpath needed for tests to work\n    String testRuntimeClassPath \u003d Client.getTestRuntimeClasspath();\n    classPathEnv.append(\u0027:\u0027);\n    classPathEnv.append(testRuntimeClassPath);\n\n    env.put(\"CLASSPATH\", classPathEnv.toString());\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // For launching an AM Container, setting user here is not needed\n    // Set user in ApplicationSubmissionContext\n    // amContainer.setUser(amUser);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    amContainer.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n    // Set the user submitting this application \n    // TODO can it be empty? \n    appContext.setUser(amUser);\n\n    // Create the request to send to the applications manager \n    SubmitApplicationRequest appRequest \u003d Records.newRecord(SubmitApplicationRequest.class);\n    appRequest.setApplicationSubmissionContext(appContext);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n    applicationsManager.submitApplication(appRequest);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "aaace5e84e9fadd817c984353e299745ff2fc334": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3709. TestDistributedShell is failing. (Hitesh Shah via mahadev)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1241325 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/02/12 5:53 PM",
      "commitName": "aaace5e84e9fadd817c984353e299745ff2fc334",
      "commitAuthor": "Mahadev Konar",
      "commitDateOld": "31/10/11 9:47 PM",
      "commitNameOld": "8e04fa8b8414b66966499347453adbace256559b",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 97.88,
      "commitsBetweenForRepo": 524,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,287 +1,289 @@\n   public boolean run() throws IOException {\n     LOG.info(\"Starting Client\");\n \n     // Connect to ResourceManager \t\n     connectToASM();\n     assert(applicationsManager !\u003d null);\t\t\n \n     // Use ClientRMProtocol handle to general cluster information \n     GetClusterMetricsRequest clusterMetricsReq \u003d Records.newRecord(GetClusterMetricsRequest.class);\n     GetClusterMetricsResponse clusterMetricsResp \u003d applicationsManager.getClusterMetrics(clusterMetricsReq);\n     LOG.info(\"Got Cluster metric info from ASM\" \n         + \", numNodeManagers\u003d\" + clusterMetricsResp.getClusterMetrics().getNumNodeManagers());\n \n     GetClusterNodesRequest clusterNodesReq \u003d Records.newRecord(GetClusterNodesRequest.class);\n     GetClusterNodesResponse clusterNodesResp \u003d applicationsManager.getClusterNodes(clusterNodesReq);\n     LOG.info(\"Got Cluster node info from ASM\");\n     for (NodeReport node : clusterNodesResp.getNodeReports()) {\n       LOG.info(\"Got node report from ASM for\"\n           + \", nodeId\u003d\" + node.getNodeId() \n           + \", nodeAddress\" + node.getHttpAddress()\n           + \", nodeRackName\" + node.getRackName()\n           + \", nodeNumContainers\" + node.getNumContainers()\n           + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n     }\n \n     GetQueueInfoRequest queueInfoReq \u003d Records.newRecord(GetQueueInfoRequest.class);\n     GetQueueInfoResponse queueInfoResp \u003d applicationsManager.getQueueInfo(queueInfoReq);\t\t\n     QueueInfo queueInfo \u003d queueInfoResp.getQueueInfo();\n     LOG.info(\"Queue info\"\n         + \", queueName\u003d\" + queueInfo.getQueueName()\n         + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n         + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n         + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n         + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n \n     GetQueueUserAclsInfoRequest queueUserAclsReq \u003d Records.newRecord(GetQueueUserAclsInfoRequest.class);\n     GetQueueUserAclsInfoResponse queueUserAclsResp \u003d applicationsManager.getQueueUserAcls(queueUserAclsReq);\t\t\t\t\n     List\u003cQueueUserACLInfo\u003e listAclInfo \u003d queueUserAclsResp.getUserAclsInfoList();\n     for (QueueUserACLInfo aclInfo : listAclInfo) {\n       for (QueueACL userAcl : aclInfo.getUserAcls()) {\n         LOG.info(\"User ACL Info for Queue\"\n             + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n             + \", userAcl\u003d\" + userAcl.name());\n       }\n     }\t\t\n \n     // Get a new application id \n     GetNewApplicationResponse newApp \u003d getApplication();\n     ApplicationId appId \u003d newApp.getApplicationId();\n \n     // TODO get min/max resource capabilities from RM and change memory ask if needed\n     // If we do not have min/max, we may not be able to correctly request \n     // the required resources from the RM for the app master\n     // Memory ask has to be a multiple of min and less than max. \n     // Dump out information about cluster capability as seen by the resource manager\n     int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n     int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n     LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n     LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n \n     // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n     // a multiple of the min value and cannot exceed the max. \n     // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n     if (amMemory \u003c minMem) {\n       LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n           + \", specified\u003d\" + amMemory\n           + \", min\u003d\" + minMem);\n       amMemory \u003d minMem; \n     } \n     else if (amMemory \u003e maxMem) {\n       LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n           + \", specified\u003d\" + amMemory\n           + \", max\u003d\" + maxMem);\n       amMemory \u003d maxMem;\n     }\t\t\t\t\n \n     // Create launch context for app master\n     LOG.info(\"Setting up application submission context for ASM\");\n     ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n \n     // set the application id \n     appContext.setApplicationId(appId);\n     // set the application name\n     appContext.setApplicationName(appName);\n \n     // Set up the container launch context for the application master\n     ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n \n     // set local resources for the application master\n     // local files or archives as needed\n     // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n \n     LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n     // Copy the application master jar to the filesystem \n     // Create a local resource to point to the destination jar path \n     FileSystem fs \u003d FileSystem.get(conf);\n     Path src \u003d new Path(appMasterJar);\n     String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n     Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n     fs.copyFromLocalFile(false, true, src, dst);\n     FileStatus destStatus \u003d fs.getFileStatus(dst);\n     LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n \n     // Set the type of resource - file or archive\n     // archives are untarred at destination\n     // we don\u0027t need the jar file to be untarred for now\n     amJarRsrc.setType(LocalResourceType.FILE);\n     // Set visibility of the resource \n     // Setting to most private option\n     amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n     // Set the resource to be copied over\n     amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n     // Set timestamp and length of file so that the framework \n     // can do basic sanity checks for the local resource \n     // after it has been copied over to ensure it is the same \n     // resource the client intended to use with the application\n     amJarRsrc.setTimestamp(destStatus.getModificationTime());\n     amJarRsrc.setSize(destStatus.getLen());\n     localResources.put(\"AppMaster.jar\",  amJarRsrc);\n \n     // Set the log4j properties if needed \n     if (!log4jPropFile.isEmpty()) {\n       Path log4jSrc \u003d new Path(log4jPropFile);\n       Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n       fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n       FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n       LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n       log4jRsrc.setType(LocalResourceType.FILE);\n       log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n       log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n       log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n       log4jRsrc.setSize(log4jFileStatus.getLen());\n       localResources.put(\"log4j.properties\", log4jRsrc);\n     }\t\t\t\n \n     // The shell script has to be made available on the final container(s)\n     // where it will be executed. \n     // To do this, we need to first copy into the filesystem that is visible \n     // to the yarn framework. \n     // We do not need to set this as a local resource for the application \n     // master as the application master does not need it. \t\t\n     String hdfsShellScriptLocation \u003d \"\"; \n     long hdfsShellScriptLen \u003d 0;\n     long hdfsShellScriptTimestamp \u003d 0;\n     if (!shellScriptPath.isEmpty()) {\n       Path shellSrc \u003d new Path(shellScriptPath);\n       String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n       Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n       fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n       hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n       FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n       hdfsShellScriptLen \u003d shellFileStatus.getLen();\n       hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n     }\n \n     // Set local resource info into app master container launch context\n     amContainer.setLocalResources(localResources);\n \n     // Set the necessary security tokens as needed\n     //amContainer.setContainerTokens(containerToken);\n \n     // Set the env variables to be setup in the env where the application master will be run\n     LOG.info(\"Set the environment for the application master\");\n     Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n \n     // put location of shell script into env\n     // using the env info, the application master will create the correct local resource for the \n     // eventual containers that will be launched to execute the shell scripts\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n     env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n \n     // Add AppMaster.jar location to classpath \t\t\n     // At some point we should not be required to add \n     // the hadoop specific classpaths to the env. \n     // It should be provided out of the box. \n     // For now setting all required classpaths including\n     // the classpath to \".\" for the application jar\n     String classPathEnv \u003d \"${CLASSPATH}\"\n         + \":./*\"\n         + \":$HADOOP_CONF_DIR\"\n         + \":$HADOOP_COMMON_HOME/share/hadoop/common/*\"\n         + \":$HADOOP_COMMON_HOME/share/hadoop/common/lib/*\"\n         + \":$HADOOP_HDFS_HOME/share/hadoop/hdfs/*\"\n         + \":$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*\"\n         + \":$YARN_HOME/modules/*\"\n         + \":$YARN_HOME/lib/*\"\n         + \":./log4j.properties:\";\n \n     // add the runtime classpath needed for tests to work \n     String testRuntimeClassPath \u003d Client.getTestRuntimeClasspath();\n     classPathEnv +\u003d \":\" + testRuntimeClassPath; \n \n     env.put(\"CLASSPATH\", classPathEnv);\n \n     amContainer.setEnvironment(env);\n \n     // Set the necessary command to execute the application master \n     Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n \n     // Set java executable command \n     LOG.info(\"Setting up app master command\");\n     vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n+    // Set Xmx based on am memory size\n+    vargs.add(\"-Xmx\" + amMemory + \"m\");\n     // Set class name \n     vargs.add(appMasterMainClass);\n     // Set params for Application Master\n     vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n     vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n     vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n     if (!shellCommand.isEmpty()) {\n       vargs.add(\"--shell_command \" + shellCommand + \"\");\n     }\n     if (!shellArgs.isEmpty()) {\n       vargs.add(\"--shell_args \" + shellArgs + \"\");\n     }\n     for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n       vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n     }\t\t\t\n     if (debugFlag) {\n       vargs.add(\"--debug\");\n     }\n \n     vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n     vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n \n     // Get final commmand\n     StringBuilder command \u003d new StringBuilder();\n     for (CharSequence str : vargs) {\n       command.append(str).append(\" \");\n     }\n \n     LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n     List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n     commands.add(command.toString());\t\t\n     amContainer.setCommands(commands);\n \n     // For launching an AM Container, setting user here is not needed\n     // Set user in ApplicationSubmissionContext\n     // amContainer.setUser(amUser);\n \n     // Set up resource type requirements\n     // For now, only memory is supported so we set memory requirements\n     Resource capability \u003d Records.newRecord(Resource.class);\n     capability.setMemory(amMemory);\n     amContainer.setResource(capability);\n \n     // Service data is a binary blob that can be passed to the application\n     // Not needed in this scenario\n     // amContainer.setServiceData(serviceData);\n \n     // The following are not required for launching an application master \n     // amContainer.setContainerId(containerId);\t\t\n \n     appContext.setAMContainerSpec(amContainer);\n \n     // Set the priority for the application master\n     Priority pri \u003d Records.newRecord(Priority.class);\n     // TODO - what is the range for priority? how to decide? \n     pri.setPriority(amPriority);\n     appContext.setPriority(pri);\n \n     // Set the queue to which this application is to be submitted in the RM\n     appContext.setQueue(amQueue);\n     // Set the user submitting this application \n     // TODO can it be empty? \n     appContext.setUser(amUser);\n \n     // Create the request to send to the applications manager \n     SubmitApplicationRequest appRequest \u003d Records.newRecord(SubmitApplicationRequest.class);\n     appRequest.setApplicationSubmissionContext(appContext);\n \n     // Submit the application to the applications manager\n     // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n     // Ignore the response as either a valid response object is returned on success \n     // or an exception thrown to denote some form of a failure\n     LOG.info(\"Submitting application to ASM\");\n     applicationsManager.submitApplication(appRequest);\n \n     // TODO\n     // Try submitting the same request again\n     // app submission failure?\n \n     // Monitor the application\n     return monitorApplication(appId);\n \n   }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException {\n    LOG.info(\"Starting Client\");\n\n    // Connect to ResourceManager \t\n    connectToASM();\n    assert(applicationsManager !\u003d null);\t\t\n\n    // Use ClientRMProtocol handle to general cluster information \n    GetClusterMetricsRequest clusterMetricsReq \u003d Records.newRecord(GetClusterMetricsRequest.class);\n    GetClusterMetricsResponse clusterMetricsResp \u003d applicationsManager.getClusterMetrics(clusterMetricsReq);\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetricsResp.getClusterMetrics().getNumNodeManagers());\n\n    GetClusterNodesRequest clusterNodesReq \u003d Records.newRecord(GetClusterNodesRequest.class);\n    GetClusterNodesResponse clusterNodesResp \u003d applicationsManager.getClusterNodes(clusterNodesReq);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodesResp.getNodeReports()) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers()\n          + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n    }\n\n    GetQueueInfoRequest queueInfoReq \u003d Records.newRecord(GetQueueInfoRequest.class);\n    GetQueueInfoResponse queueInfoResp \u003d applicationsManager.getQueueInfo(queueInfoReq);\t\t\n    QueueInfo queueInfo \u003d queueInfoResp.getQueueInfo();\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    GetQueueUserAclsInfoRequest queueUserAclsReq \u003d Records.newRecord(GetQueueUserAclsInfoRequest.class);\n    GetQueueUserAclsInfoResponse queueUserAclsResp \u003d applicationsManager.getQueueUserAcls(queueUserAclsReq);\t\t\t\t\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d queueUserAclsResp.getUserAclsInfoList();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id \n    GetNewApplicationResponse newApp \u003d getApplication();\n    ApplicationId appId \u003d newApp.getApplicationId();\n\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n    // a multiple of the min value and cannot exceed the max. \n    // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n    if (amMemory \u003c minMem) {\n      LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n          + \", specified\u003d\" + amMemory\n          + \", min\u003d\" + minMem);\n      amMemory \u003d minMem; \n    } \n    else if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // Create launch context for app master\n    LOG.info(\"Setting up application submission context for ASM\");\n    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n\n    // set the application id \n    appContext.setApplicationId(appId);\n    // set the application name\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    String classPathEnv \u003d \"${CLASSPATH}\"\n        + \":./*\"\n        + \":$HADOOP_CONF_DIR\"\n        + \":$HADOOP_COMMON_HOME/share/hadoop/common/*\"\n        + \":$HADOOP_COMMON_HOME/share/hadoop/common/lib/*\"\n        + \":$HADOOP_HDFS_HOME/share/hadoop/hdfs/*\"\n        + \":$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*\"\n        + \":$YARN_HOME/modules/*\"\n        + \":$YARN_HOME/lib/*\"\n        + \":./log4j.properties:\";\n\n    // add the runtime classpath needed for tests to work \n    String testRuntimeClassPath \u003d Client.getTestRuntimeClasspath();\n    classPathEnv +\u003d \":\" + testRuntimeClassPath; \n\n    env.put(\"CLASSPATH\", classPathEnv);\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n    // Set Xmx based on am memory size\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // For launching an AM Container, setting user here is not needed\n    // Set user in ApplicationSubmissionContext\n    // amContainer.setUser(amUser);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    amContainer.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n    // Set the user submitting this application \n    // TODO can it be empty? \n    appContext.setUser(amUser);\n\n    // Create the request to send to the applications manager \n    SubmitApplicationRequest appRequest \u003d Records.newRecord(SubmitApplicationRequest.class);\n    appRequest.setApplicationSubmissionContext(appContext);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n    applicationsManager.submitApplication(appRequest);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java",
      "extendedDetails": {}
    },
    "fad230a49d0d4cdbb2062b10c3dea6c755737db5": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-2719. Add a simple, DistributedShell, application to illustrate alternate frameworks on YARN. Contributed by Hitesh Shah.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1177864 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/09/11 3:25 PM",
      "commitName": "fad230a49d0d4cdbb2062b10c3dea6c755737db5",
      "commitAuthor": "Arun Murthy",
      "diff": "@@ -0,0 +1,287 @@\n+  public boolean run() throws IOException {\n+    LOG.info(\"Starting Client\");\n+\n+    // Connect to ResourceManager \t\n+    connectToASM();\n+    assert(applicationsManager !\u003d null);\t\t\n+\n+    // Use ClientRMProtocol handle to general cluster information \n+    GetClusterMetricsRequest clusterMetricsReq \u003d Records.newRecord(GetClusterMetricsRequest.class);\n+    GetClusterMetricsResponse clusterMetricsResp \u003d applicationsManager.getClusterMetrics(clusterMetricsReq);\n+    LOG.info(\"Got Cluster metric info from ASM\" \n+        + \", numNodeManagers\u003d\" + clusterMetricsResp.getClusterMetrics().getNumNodeManagers());\n+\n+    GetClusterNodesRequest clusterNodesReq \u003d Records.newRecord(GetClusterNodesRequest.class);\n+    GetClusterNodesResponse clusterNodesResp \u003d applicationsManager.getClusterNodes(clusterNodesReq);\n+    LOG.info(\"Got Cluster node info from ASM\");\n+    for (NodeReport node : clusterNodesResp.getNodeReports()) {\n+      LOG.info(\"Got node report from ASM for\"\n+          + \", nodeId\u003d\" + node.getNodeId() \n+          + \", nodeAddress\" + node.getHttpAddress()\n+          + \", nodeRackName\" + node.getRackName()\n+          + \", nodeNumContainers\" + node.getNumContainers()\n+          + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n+    }\n+\n+    GetQueueInfoRequest queueInfoReq \u003d Records.newRecord(GetQueueInfoRequest.class);\n+    GetQueueInfoResponse queueInfoResp \u003d applicationsManager.getQueueInfo(queueInfoReq);\t\t\n+    QueueInfo queueInfo \u003d queueInfoResp.getQueueInfo();\n+    LOG.info(\"Queue info\"\n+        + \", queueName\u003d\" + queueInfo.getQueueName()\n+        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n+        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n+        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n+        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n+\n+    GetQueueUserAclsInfoRequest queueUserAclsReq \u003d Records.newRecord(GetQueueUserAclsInfoRequest.class);\n+    GetQueueUserAclsInfoResponse queueUserAclsResp \u003d applicationsManager.getQueueUserAcls(queueUserAclsReq);\t\t\t\t\n+    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d queueUserAclsResp.getUserAclsInfoList();\n+    for (QueueUserACLInfo aclInfo : listAclInfo) {\n+      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n+        LOG.info(\"User ACL Info for Queue\"\n+            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n+            + \", userAcl\u003d\" + userAcl.name());\n+      }\n+    }\t\t\n+\n+    // Get a new application id \n+    GetNewApplicationResponse newApp \u003d getApplication();\n+    ApplicationId appId \u003d newApp.getApplicationId();\n+\n+    // TODO get min/max resource capabilities from RM and change memory ask if needed\n+    // If we do not have min/max, we may not be able to correctly request \n+    // the required resources from the RM for the app master\n+    // Memory ask has to be a multiple of min and less than max. \n+    // Dump out information about cluster capability as seen by the resource manager\n+    int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n+    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n+    LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n+    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n+\n+    // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n+    // a multiple of the min value and cannot exceed the max. \n+    // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n+    if (amMemory \u003c minMem) {\n+      LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n+          + \", specified\u003d\" + amMemory\n+          + \", min\u003d\" + minMem);\n+      amMemory \u003d minMem; \n+    } \n+    else if (amMemory \u003e maxMem) {\n+      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n+          + \", specified\u003d\" + amMemory\n+          + \", max\u003d\" + maxMem);\n+      amMemory \u003d maxMem;\n+    }\t\t\t\t\n+\n+    // Create launch context for app master\n+    LOG.info(\"Setting up application submission context for ASM\");\n+    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n+\n+    // set the application id \n+    appContext.setApplicationId(appId);\n+    // set the application name\n+    appContext.setApplicationName(appName);\n+\n+    // Set up the container launch context for the application master\n+    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n+\n+    // set local resources for the application master\n+    // local files or archives as needed\n+    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n+    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n+\n+    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n+    // Copy the application master jar to the filesystem \n+    // Create a local resource to point to the destination jar path \n+    FileSystem fs \u003d FileSystem.get(conf);\n+    Path src \u003d new Path(appMasterJar);\n+    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n+    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n+    fs.copyFromLocalFile(false, true, src, dst);\n+    FileStatus destStatus \u003d fs.getFileStatus(dst);\n+    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n+\n+    // Set the type of resource - file or archive\n+    // archives are untarred at destination\n+    // we don\u0027t need the jar file to be untarred for now\n+    amJarRsrc.setType(LocalResourceType.FILE);\n+    // Set visibility of the resource \n+    // Setting to most private option\n+    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n+    // Set the resource to be copied over\n+    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n+    // Set timestamp and length of file so that the framework \n+    // can do basic sanity checks for the local resource \n+    // after it has been copied over to ensure it is the same \n+    // resource the client intended to use with the application\n+    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n+    amJarRsrc.setSize(destStatus.getLen());\n+    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n+\n+    // Set the log4j properties if needed \n+    if (!log4jPropFile.isEmpty()) {\n+      Path log4jSrc \u003d new Path(log4jPropFile);\n+      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n+      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n+      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n+      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n+      log4jRsrc.setType(LocalResourceType.FILE);\n+      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n+      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n+      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n+      log4jRsrc.setSize(log4jFileStatus.getLen());\n+      localResources.put(\"log4j.properties\", log4jRsrc);\n+    }\t\t\t\n+\n+    // The shell script has to be made available on the final container(s)\n+    // where it will be executed. \n+    // To do this, we need to first copy into the filesystem that is visible \n+    // to the yarn framework. \n+    // We do not need to set this as a local resource for the application \n+    // master as the application master does not need it. \t\t\n+    String hdfsShellScriptLocation \u003d \"\"; \n+    long hdfsShellScriptLen \u003d 0;\n+    long hdfsShellScriptTimestamp \u003d 0;\n+    if (!shellScriptPath.isEmpty()) {\n+      Path shellSrc \u003d new Path(shellScriptPath);\n+      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n+      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n+      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n+      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n+      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n+      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n+      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n+    }\n+\n+    // Set local resource info into app master container launch context\n+    amContainer.setLocalResources(localResources);\n+\n+    // Set the necessary security tokens as needed\n+    //amContainer.setContainerTokens(containerToken);\n+\n+    // Set the env variables to be setup in the env where the application master will be run\n+    LOG.info(\"Set the environment for the application master\");\n+    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n+\n+    // put location of shell script into env\n+    // using the env info, the application master will create the correct local resource for the \n+    // eventual containers that will be launched to execute the shell scripts\n+    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n+    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n+    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n+\n+    // Add AppMaster.jar location to classpath \t\t\n+    // At some point we should not be required to add \n+    // the hadoop specific classpaths to the env. \n+    // It should be provided out of the box. \n+    // For now setting all required classpaths including\n+    // the classpath to \".\" for the application jar\n+    String classPathEnv \u003d \"${CLASSPATH}\"\n+        + \":./*\"\n+        + \":$HADOOP_CONF_DIR\"\n+        + \":$HADOOP_COMMON_HOME/share/hadoop/common/*\"\n+        + \":$HADOOP_COMMON_HOME/share/hadoop/common/lib/*\"\n+        + \":$HADOOP_HDFS_HOME/share/hadoop/hdfs/*\"\n+        + \":$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*\"\n+        + \":$YARN_HOME/modules/*\"\n+        + \":$YARN_HOME/lib/*\"\n+        + \":./log4j.properties:\";\n+\n+    // add the runtime classpath needed for tests to work \n+    String testRuntimeClassPath \u003d Client.getTestRuntimeClasspath();\n+    classPathEnv +\u003d \":\" + testRuntimeClassPath; \n+\n+    env.put(\"CLASSPATH\", classPathEnv);\n+\n+    amContainer.setEnvironment(env);\n+\n+    // Set the necessary command to execute the application master \n+    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n+\n+    // Set java executable command \n+    LOG.info(\"Setting up app master command\");\n+    vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n+    // Set class name \n+    vargs.add(appMasterMainClass);\n+    // Set params for Application Master\n+    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n+    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n+    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n+    if (!shellCommand.isEmpty()) {\n+      vargs.add(\"--shell_command \" + shellCommand + \"\");\n+    }\n+    if (!shellArgs.isEmpty()) {\n+      vargs.add(\"--shell_args \" + shellArgs + \"\");\n+    }\n+    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n+      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n+    }\t\t\t\n+    if (debugFlag) {\n+      vargs.add(\"--debug\");\n+    }\n+\n+    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n+    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n+\n+    // Get final commmand\n+    StringBuilder command \u003d new StringBuilder();\n+    for (CharSequence str : vargs) {\n+      command.append(str).append(\" \");\n+    }\n+\n+    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n+    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n+    commands.add(command.toString());\t\t\n+    amContainer.setCommands(commands);\n+\n+    // For launching an AM Container, setting user here is not needed\n+    // Set user in ApplicationSubmissionContext\n+    // amContainer.setUser(amUser);\n+\n+    // Set up resource type requirements\n+    // For now, only memory is supported so we set memory requirements\n+    Resource capability \u003d Records.newRecord(Resource.class);\n+    capability.setMemory(amMemory);\n+    amContainer.setResource(capability);\n+\n+    // Service data is a binary blob that can be passed to the application\n+    // Not needed in this scenario\n+    // amContainer.setServiceData(serviceData);\n+\n+    // The following are not required for launching an application master \n+    // amContainer.setContainerId(containerId);\t\t\n+\n+    appContext.setAMContainerSpec(amContainer);\n+\n+    // Set the priority for the application master\n+    Priority pri \u003d Records.newRecord(Priority.class);\n+    // TODO - what is the range for priority? how to decide? \n+    pri.setPriority(amPriority);\n+    appContext.setPriority(pri);\n+\n+    // Set the queue to which this application is to be submitted in the RM\n+    appContext.setQueue(amQueue);\n+    // Set the user submitting this application \n+    // TODO can it be empty? \n+    appContext.setUser(amUser);\n+\n+    // Create the request to send to the applications manager \n+    SubmitApplicationRequest appRequest \u003d Records.newRecord(SubmitApplicationRequest.class);\n+    appRequest.setApplicationSubmissionContext(appContext);\n+\n+    // Submit the application to the applications manager\n+    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n+    // Ignore the response as either a valid response object is returned on success \n+    // or an exception thrown to denote some form of a failure\n+    LOG.info(\"Submitting application to ASM\");\n+    applicationsManager.submitApplication(appRequest);\n+\n+    // TODO\n+    // Try submitting the same request again\n+    // app submission failure?\n+\n+    // Monitor the application\n+    return monitorApplication(appId);\n+\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean run() throws IOException {\n    LOG.info(\"Starting Client\");\n\n    // Connect to ResourceManager \t\n    connectToASM();\n    assert(applicationsManager !\u003d null);\t\t\n\n    // Use ClientRMProtocol handle to general cluster information \n    GetClusterMetricsRequest clusterMetricsReq \u003d Records.newRecord(GetClusterMetricsRequest.class);\n    GetClusterMetricsResponse clusterMetricsResp \u003d applicationsManager.getClusterMetrics(clusterMetricsReq);\n    LOG.info(\"Got Cluster metric info from ASM\" \n        + \", numNodeManagers\u003d\" + clusterMetricsResp.getClusterMetrics().getNumNodeManagers());\n\n    GetClusterNodesRequest clusterNodesReq \u003d Records.newRecord(GetClusterNodesRequest.class);\n    GetClusterNodesResponse clusterNodesResp \u003d applicationsManager.getClusterNodes(clusterNodesReq);\n    LOG.info(\"Got Cluster node info from ASM\");\n    for (NodeReport node : clusterNodesResp.getNodeReports()) {\n      LOG.info(\"Got node report from ASM for\"\n          + \", nodeId\u003d\" + node.getNodeId() \n          + \", nodeAddress\" + node.getHttpAddress()\n          + \", nodeRackName\" + node.getRackName()\n          + \", nodeNumContainers\" + node.getNumContainers()\n          + \", nodeHealthStatus\" + node.getNodeHealthStatus());\n    }\n\n    GetQueueInfoRequest queueInfoReq \u003d Records.newRecord(GetQueueInfoRequest.class);\n    GetQueueInfoResponse queueInfoResp \u003d applicationsManager.getQueueInfo(queueInfoReq);\t\t\n    QueueInfo queueInfo \u003d queueInfoResp.getQueueInfo();\n    LOG.info(\"Queue info\"\n        + \", queueName\u003d\" + queueInfo.getQueueName()\n        + \", queueCurrentCapacity\u003d\" + queueInfo.getCurrentCapacity()\n        + \", queueMaxCapacity\u003d\" + queueInfo.getMaximumCapacity()\n        + \", queueApplicationCount\u003d\" + queueInfo.getApplications().size()\n        + \", queueChildQueueCount\u003d\" + queueInfo.getChildQueues().size());\t\t\n\n    GetQueueUserAclsInfoRequest queueUserAclsReq \u003d Records.newRecord(GetQueueUserAclsInfoRequest.class);\n    GetQueueUserAclsInfoResponse queueUserAclsResp \u003d applicationsManager.getQueueUserAcls(queueUserAclsReq);\t\t\t\t\n    List\u003cQueueUserACLInfo\u003e listAclInfo \u003d queueUserAclsResp.getUserAclsInfoList();\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\n      for (QueueACL userAcl : aclInfo.getUserAcls()) {\n        LOG.info(\"User ACL Info for Queue\"\n            + \", queueName\u003d\" + aclInfo.getQueueName()\t\t\t\n            + \", userAcl\u003d\" + userAcl.name());\n      }\n    }\t\t\n\n    // Get a new application id \n    GetNewApplicationResponse newApp \u003d getApplication();\n    ApplicationId appId \u003d newApp.getApplicationId();\n\n    // TODO get min/max resource capabilities from RM and change memory ask if needed\n    // If we do not have min/max, we may not be able to correctly request \n    // the required resources from the RM for the app master\n    // Memory ask has to be a multiple of min and less than max. \n    // Dump out information about cluster capability as seen by the resource manager\n    int minMem \u003d newApp.getMinimumResourceCapability().getMemory();\n    int maxMem \u003d newApp.getMaximumResourceCapability().getMemory();\n    LOG.info(\"Min mem capabililty of resources in this cluster \" + minMem);\n    LOG.info(\"Max mem capabililty of resources in this cluster \" + maxMem);\n\n    // A resource ask has to be atleast the minimum of the capability of the cluster, the value has to be \n    // a multiple of the min value and cannot exceed the max. \n    // If it is not an exact multiple of min, the RM will allocate to the nearest multiple of min\n    if (amMemory \u003c minMem) {\n      LOG.info(\"AM memory specified below min threshold of cluster. Using min value.\"\n          + \", specified\u003d\" + amMemory\n          + \", min\u003d\" + minMem);\n      amMemory \u003d minMem; \n    } \n    else if (amMemory \u003e maxMem) {\n      LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\"\n          + \", specified\u003d\" + amMemory\n          + \", max\u003d\" + maxMem);\n      amMemory \u003d maxMem;\n    }\t\t\t\t\n\n    // Create launch context for app master\n    LOG.info(\"Setting up application submission context for ASM\");\n    ApplicationSubmissionContext appContext \u003d Records.newRecord(ApplicationSubmissionContext.class);\n\n    // set the application id \n    appContext.setApplicationId(appId);\n    // set the application name\n    appContext.setApplicationName(appName);\n\n    // Set up the container launch context for the application master\n    ContainerLaunchContext amContainer \u003d Records.newRecord(ContainerLaunchContext.class);\n\n    // set local resources for the application master\n    // local files or archives as needed\n    // In this scenario, the jar file for the application master is part of the local resources\t\t\t\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003cString, LocalResource\u003e();\n\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\n    // Copy the application master jar to the filesystem \n    // Create a local resource to point to the destination jar path \n    FileSystem fs \u003d FileSystem.get(conf);\n    Path src \u003d new Path(appMasterJar);\n    String pathSuffix \u003d appName + \"/\" + appId.getId() + \"/AppMaster.jar\";\t    \n    Path dst \u003d new Path(fs.getHomeDirectory(), pathSuffix);\n    fs.copyFromLocalFile(false, true, src, dst);\n    FileStatus destStatus \u003d fs.getFileStatus(dst);\n    LocalResource amJarRsrc \u003d Records.newRecord(LocalResource.class);\n\n    // Set the type of resource - file or archive\n    // archives are untarred at destination\n    // we don\u0027t need the jar file to be untarred for now\n    amJarRsrc.setType(LocalResourceType.FILE);\n    // Set visibility of the resource \n    // Setting to most private option\n    amJarRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n    // Set the resource to be copied over\n    amJarRsrc.setResource(ConverterUtils.getYarnUrlFromPath(dst)); \n    // Set timestamp and length of file so that the framework \n    // can do basic sanity checks for the local resource \n    // after it has been copied over to ensure it is the same \n    // resource the client intended to use with the application\n    amJarRsrc.setTimestamp(destStatus.getModificationTime());\n    amJarRsrc.setSize(destStatus.getLen());\n    localResources.put(\"AppMaster.jar\",  amJarRsrc);\n\n    // Set the log4j properties if needed \n    if (!log4jPropFile.isEmpty()) {\n      Path log4jSrc \u003d new Path(log4jPropFile);\n      Path log4jDst \u003d new Path(fs.getHomeDirectory(), \"log4j.props\");\n      fs.copyFromLocalFile(false, true, log4jSrc, log4jDst);\n      FileStatus log4jFileStatus \u003d fs.getFileStatus(log4jDst);\n      LocalResource log4jRsrc \u003d Records.newRecord(LocalResource.class);\n      log4jRsrc.setType(LocalResourceType.FILE);\n      log4jRsrc.setVisibility(LocalResourceVisibility.APPLICATION);\t   \n      log4jRsrc.setResource(ConverterUtils.getYarnUrlFromURI(log4jDst.toUri()));\n      log4jRsrc.setTimestamp(log4jFileStatus.getModificationTime());\n      log4jRsrc.setSize(log4jFileStatus.getLen());\n      localResources.put(\"log4j.properties\", log4jRsrc);\n    }\t\t\t\n\n    // The shell script has to be made available on the final container(s)\n    // where it will be executed. \n    // To do this, we need to first copy into the filesystem that is visible \n    // to the yarn framework. \n    // We do not need to set this as a local resource for the application \n    // master as the application master does not need it. \t\t\n    String hdfsShellScriptLocation \u003d \"\"; \n    long hdfsShellScriptLen \u003d 0;\n    long hdfsShellScriptTimestamp \u003d 0;\n    if (!shellScriptPath.isEmpty()) {\n      Path shellSrc \u003d new Path(shellScriptPath);\n      String shellPathSuffix \u003d appName + \"/\" + appId.getId() + \"/ExecShellScript.sh\";\n      Path shellDst \u003d new Path(fs.getHomeDirectory(), shellPathSuffix);\n      fs.copyFromLocalFile(false, true, shellSrc, shellDst);\n      hdfsShellScriptLocation \u003d shellDst.toUri().toString(); \n      FileStatus shellFileStatus \u003d fs.getFileStatus(shellDst);\n      hdfsShellScriptLen \u003d shellFileStatus.getLen();\n      hdfsShellScriptTimestamp \u003d shellFileStatus.getModificationTime();\n    }\n\n    // Set local resource info into app master container launch context\n    amContainer.setLocalResources(localResources);\n\n    // Set the necessary security tokens as needed\n    //amContainer.setContainerTokens(containerToken);\n\n    // Set the env variables to be setup in the env where the application master will be run\n    LOG.info(\"Set the environment for the application master\");\n    Map\u003cString, String\u003e env \u003d new HashMap\u003cString, String\u003e();\n\n    // put location of shell script into env\n    // using the env info, the application master will create the correct local resource for the \n    // eventual containers that will be launched to execute the shell scripts\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\n\n    // Add AppMaster.jar location to classpath \t\t\n    // At some point we should not be required to add \n    // the hadoop specific classpaths to the env. \n    // It should be provided out of the box. \n    // For now setting all required classpaths including\n    // the classpath to \".\" for the application jar\n    String classPathEnv \u003d \"${CLASSPATH}\"\n        + \":./*\"\n        + \":$HADOOP_CONF_DIR\"\n        + \":$HADOOP_COMMON_HOME/share/hadoop/common/*\"\n        + \":$HADOOP_COMMON_HOME/share/hadoop/common/lib/*\"\n        + \":$HADOOP_HDFS_HOME/share/hadoop/hdfs/*\"\n        + \":$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*\"\n        + \":$YARN_HOME/modules/*\"\n        + \":$YARN_HOME/lib/*\"\n        + \":./log4j.properties:\";\n\n    // add the runtime classpath needed for tests to work \n    String testRuntimeClassPath \u003d Client.getTestRuntimeClasspath();\n    classPathEnv +\u003d \":\" + testRuntimeClassPath; \n\n    env.put(\"CLASSPATH\", classPathEnv);\n\n    amContainer.setEnvironment(env);\n\n    // Set the necessary command to execute the application master \n    Vector\u003cCharSequence\u003e vargs \u003d new Vector\u003cCharSequence\u003e(30);\n\n    // Set java executable command \n    LOG.info(\"Setting up app master command\");\n    vargs.add(\"${JAVA_HOME}\" + \"/bin/java\");\n    // Set class name \n    vargs.add(appMasterMainClass);\n    // Set params for Application Master\n    vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\n    if (!shellCommand.isEmpty()) {\n      vargs.add(\"--shell_command \" + shellCommand + \"\");\n    }\n    if (!shellArgs.isEmpty()) {\n      vargs.add(\"--shell_args \" + shellArgs + \"\");\n    }\n    for (Map.Entry\u003cString, String\u003e entry : shellEnv.entrySet()) {\n      vargs.add(\"--shell_env \" + entry.getKey() + \"\u003d\" + entry.getValue());\n    }\t\t\t\n    if (debugFlag) {\n      vargs.add(\"--debug\");\n    }\n\n    vargs.add(\"1\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\n    vargs.add(\"2\u003e\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\n\n    // Get final commmand\n    StringBuilder command \u003d new StringBuilder();\n    for (CharSequence str : vargs) {\n      command.append(str).append(\" \");\n    }\n\n    LOG.info(\"Completed setting up app master command \" + command.toString());\t   \n    List\u003cString\u003e commands \u003d new ArrayList\u003cString\u003e();\n    commands.add(command.toString());\t\t\n    amContainer.setCommands(commands);\n\n    // For launching an AM Container, setting user here is not needed\n    // Set user in ApplicationSubmissionContext\n    // amContainer.setUser(amUser);\n\n    // Set up resource type requirements\n    // For now, only memory is supported so we set memory requirements\n    Resource capability \u003d Records.newRecord(Resource.class);\n    capability.setMemory(amMemory);\n    amContainer.setResource(capability);\n\n    // Service data is a binary blob that can be passed to the application\n    // Not needed in this scenario\n    // amContainer.setServiceData(serviceData);\n\n    // The following are not required for launching an application master \n    // amContainer.setContainerId(containerId);\t\t\n\n    appContext.setAMContainerSpec(amContainer);\n\n    // Set the priority for the application master\n    Priority pri \u003d Records.newRecord(Priority.class);\n    // TODO - what is the range for priority? how to decide? \n    pri.setPriority(amPriority);\n    appContext.setPriority(pri);\n\n    // Set the queue to which this application is to be submitted in the RM\n    appContext.setQueue(amQueue);\n    // Set the user submitting this application \n    // TODO can it be empty? \n    appContext.setUser(amUser);\n\n    // Create the request to send to the applications manager \n    SubmitApplicationRequest appRequest \u003d Records.newRecord(SubmitApplicationRequest.class);\n    appRequest.setApplicationSubmissionContext(appContext);\n\n    // Submit the application to the applications manager\n    // SubmitApplicationResponse submitResp \u003d applicationsManager.submitApplication(appRequest);\n    // Ignore the response as either a valid response object is returned on success \n    // or an exception thrown to denote some form of a failure\n    LOG.info(\"Submitting application to ASM\");\n    applicationsManager.submitApplication(appRequest);\n\n    // TODO\n    // Try submitting the same request again\n    // app submission failure?\n\n    // Monitor the application\n    return monitorApplication(appId);\n\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell/src/main/java/org/apache/hadoop/yarn/applications/distributedshell/Client.java"
    }
  }
}