{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JournalNode.java",
  "functionName": "stop",
  "functionId": "stop___rc-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java",
  "functionStartLine": 272,
  "functionEndLine": 305,
  "numCommitsSeen": 32,
  "timeTaken": 2556,
  "changeHistory": [
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
    "13d4bcfe3535a2df79c2a56e7578716d15497ff4",
    "a4bd54f9d776f39080b41913afa455f8c0f6e46d",
    "892ade689f9bcce76daae8f66fc00a49bee8548e",
    "587f68b160411dd90d3215dab6a30126a0bd78a6",
    "74d4573a23db5586c6e47ff2277aa7c35237da34"
  ],
  "changeHistoryShort": {
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568": "Ybodychange",
    "13d4bcfe3535a2df79c2a56e7578716d15497ff4": "Ybodychange",
    "a4bd54f9d776f39080b41913afa455f8c0f6e46d": "Ybodychange",
    "892ade689f9bcce76daae8f66fc00a49bee8548e": "Ybodychange",
    "587f68b160411dd90d3215dab6a30126a0bd78a6": "Ybodychange",
    "74d4573a23db5586c6e47ff2277aa7c35237da34": "Yintroduced"
  },
  "changeHistoryDetails": {
    "eca1a4bfe952fc184fe90dde50bac9b0e5293568": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13695. Move logging to slf4j in HDFS package. Contributed by Ian Pickering.\n",
      "commitDate": "06/09/18 2:48 PM",
      "commitName": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthor": "Giovanni Matteo Fumarola",
      "commitDateOld": "17/04/18 2:19 PM",
      "commitNameOld": "c9b33514b8d11db44b5f95b4df43789ed45c47a7",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 142.02,
      "commitsBetweenForRepo": 1537,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n   public void stop(int rc) {\n     this.resultCode \u003d rc;\n \n     for (JournalNodeSyncer jSyncer : journalSyncersById.values()) {\n       jSyncer.stopSync();\n     }\n \n     if (rpcServer !\u003d null) { \n       rpcServer.stop();\n     }\n \n     if (httpServer !\u003d null) {\n       try {\n         httpServer.stop();\n       } catch (IOException ioe) {\n         LOG.warn(\"Unable to stop HTTP server for \" + this, ioe);\n       }\n     }\n     \n     for (Journal j : journalsById.values()) {\n-      IOUtils.cleanup(LOG, j);\n+      IOUtils.cleanupWithLogger(LOG, j);\n     }\n \n     DefaultMetricsSystem.shutdown();\n \n     if (journalNodeInfoBeanName !\u003d null) {\n       MBeans.unregister(journalNodeInfoBeanName);\n       journalNodeInfoBeanName \u003d null;\n     }\n     if (tracer !\u003d null) {\n       tracer.close();\n       tracer \u003d null;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void stop(int rc) {\n    this.resultCode \u003d rc;\n\n    for (JournalNodeSyncer jSyncer : journalSyncersById.values()) {\n      jSyncer.stopSync();\n    }\n\n    if (rpcServer !\u003d null) { \n      rpcServer.stop();\n    }\n\n    if (httpServer !\u003d null) {\n      try {\n        httpServer.stop();\n      } catch (IOException ioe) {\n        LOG.warn(\"Unable to stop HTTP server for \" + this, ioe);\n      }\n    }\n    \n    for (Journal j : journalsById.values()) {\n      IOUtils.cleanupWithLogger(LOG, j);\n    }\n\n    DefaultMetricsSystem.shutdown();\n\n    if (journalNodeInfoBeanName !\u003d null) {\n      MBeans.unregister(journalNodeInfoBeanName);\n      journalNodeInfoBeanName \u003d null;\n    }\n    if (tracer !\u003d null) {\n      tracer.close();\n      tracer \u003d null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java",
      "extendedDetails": {}
    },
    "13d4bcfe3535a2df79c2a56e7578716d15497ff4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4025. QJM: Sychronize past log segments to JNs that missed them. Contributed by Hanisha Koneru.\n",
      "commitDate": "22/02/17 4:33 PM",
      "commitName": "13d4bcfe3535a2df79c2a56e7578716d15497ff4",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "27/10/16 4:09 PM",
      "commitNameOld": "5877f20f9c3f6f0afa505715e9a2ee312475af17",
      "commitAuthorOld": "Robert Kanter",
      "daysBetweenCommits": 118.06,
      "commitsBetweenForRepo": 673,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,34 @@\n   public void stop(int rc) {\n     this.resultCode \u003d rc;\n-    \n+\n+    for (JournalNodeSyncer jSyncer : journalSyncersById.values()) {\n+      jSyncer.stopSync();\n+    }\n+\n     if (rpcServer !\u003d null) { \n       rpcServer.stop();\n     }\n \n     if (httpServer !\u003d null) {\n       try {\n         httpServer.stop();\n       } catch (IOException ioe) {\n         LOG.warn(\"Unable to stop HTTP server for \" + this, ioe);\n       }\n     }\n     \n     for (Journal j : journalsById.values()) {\n       IOUtils.cleanup(LOG, j);\n     }\n \n     DefaultMetricsSystem.shutdown();\n \n     if (journalNodeInfoBeanName !\u003d null) {\n       MBeans.unregister(journalNodeInfoBeanName);\n       journalNodeInfoBeanName \u003d null;\n     }\n     if (tracer !\u003d null) {\n       tracer.close();\n       tracer \u003d null;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void stop(int rc) {\n    this.resultCode \u003d rc;\n\n    for (JournalNodeSyncer jSyncer : journalSyncersById.values()) {\n      jSyncer.stopSync();\n    }\n\n    if (rpcServer !\u003d null) { \n      rpcServer.stop();\n    }\n\n    if (httpServer !\u003d null) {\n      try {\n        httpServer.stop();\n      } catch (IOException ioe) {\n        LOG.warn(\"Unable to stop HTTP server for \" + this, ioe);\n      }\n    }\n    \n    for (Journal j : journalsById.values()) {\n      IOUtils.cleanup(LOG, j);\n    }\n\n    DefaultMetricsSystem.shutdown();\n\n    if (journalNodeInfoBeanName !\u003d null) {\n      MBeans.unregister(journalNodeInfoBeanName);\n      journalNodeInfoBeanName \u003d null;\n    }\n    if (tracer !\u003d null) {\n      tracer.close();\n      tracer \u003d null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java",
      "extendedDetails": {}
    },
    "a4bd54f9d776f39080b41913afa455f8c0f6e46d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7897. Shutdown metrics when stopping JournalNode. Contributed by zhouyingchao.\n",
      "commitDate": "22/11/15 7:12 PM",
      "commitName": "a4bd54f9d776f39080b41913afa455f8c0f6e46d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/09/15 7:42 AM",
      "commitNameOld": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 55.52,
      "commitsBetweenForRepo": 430,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,30 @@\n   public void stop(int rc) {\n     this.resultCode \u003d rc;\n     \n     if (rpcServer !\u003d null) { \n       rpcServer.stop();\n     }\n \n     if (httpServer !\u003d null) {\n       try {\n         httpServer.stop();\n       } catch (IOException ioe) {\n         LOG.warn(\"Unable to stop HTTP server for \" + this, ioe);\n       }\n     }\n     \n     for (Journal j : journalsById.values()) {\n       IOUtils.cleanup(LOG, j);\n     }\n \n+    DefaultMetricsSystem.shutdown();\n+\n     if (journalNodeInfoBeanName !\u003d null) {\n       MBeans.unregister(journalNodeInfoBeanName);\n       journalNodeInfoBeanName \u003d null;\n     }\n     if (tracer !\u003d null) {\n       tracer.close();\n       tracer \u003d null;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void stop(int rc) {\n    this.resultCode \u003d rc;\n    \n    if (rpcServer !\u003d null) { \n      rpcServer.stop();\n    }\n\n    if (httpServer !\u003d null) {\n      try {\n        httpServer.stop();\n      } catch (IOException ioe) {\n        LOG.warn(\"Unable to stop HTTP server for \" + this, ioe);\n      }\n    }\n    \n    for (Journal j : journalsById.values()) {\n      IOUtils.cleanup(LOG, j);\n    }\n\n    DefaultMetricsSystem.shutdown();\n\n    if (journalNodeInfoBeanName !\u003d null) {\n      MBeans.unregister(journalNodeInfoBeanName);\n      journalNodeInfoBeanName \u003d null;\n    }\n    if (tracer !\u003d null) {\n      tracer.close();\n      tracer \u003d null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java",
      "extendedDetails": {}
    },
    "892ade689f9bcce76daae8f66fc00a49bee8548e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9080. Update htrace version to 4.0.1 (cmccabe)\n",
      "commitDate": "28/09/15 7:42 AM",
      "commitName": "892ade689f9bcce76daae8f66fc00a49bee8548e",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "11/12/14 12:36 PM",
      "commitNameOld": "b9f6d0c956f0278c8b9b83e05b523a442a730ebb",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 290.75,
      "commitsBetweenForRepo": 2194,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,28 @@\n   public void stop(int rc) {\n     this.resultCode \u003d rc;\n     \n     if (rpcServer !\u003d null) { \n       rpcServer.stop();\n     }\n \n     if (httpServer !\u003d null) {\n       try {\n         httpServer.stop();\n       } catch (IOException ioe) {\n         LOG.warn(\"Unable to stop HTTP server for \" + this, ioe);\n       }\n     }\n     \n     for (Journal j : journalsById.values()) {\n       IOUtils.cleanup(LOG, j);\n     }\n \n     if (journalNodeInfoBeanName !\u003d null) {\n       MBeans.unregister(journalNodeInfoBeanName);\n       journalNodeInfoBeanName \u003d null;\n     }\n+    if (tracer !\u003d null) {\n+      tracer.close();\n+      tracer \u003d null;\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void stop(int rc) {\n    this.resultCode \u003d rc;\n    \n    if (rpcServer !\u003d null) { \n      rpcServer.stop();\n    }\n\n    if (httpServer !\u003d null) {\n      try {\n        httpServer.stop();\n      } catch (IOException ioe) {\n        LOG.warn(\"Unable to stop HTTP server for \" + this, ioe);\n      }\n    }\n    \n    for (Journal j : journalsById.values()) {\n      IOUtils.cleanup(LOG, j);\n    }\n\n    if (journalNodeInfoBeanName !\u003d null) {\n      MBeans.unregister(journalNodeInfoBeanName);\n      journalNodeInfoBeanName \u003d null;\n    }\n    if (tracer !\u003d null) {\n      tracer.close();\n      tracer \u003d null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java",
      "extendedDetails": {}
    },
    "587f68b160411dd90d3215dab6a30126a0bd78a6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-1386. TestJMXGet fails in jdk7 (jeagles)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1543612 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/11/13 2:44 PM",
      "commitName": "587f68b160411dd90d3215dab6a30126a0bd78a6",
      "commitAuthor": "Jonathan Turner Eagles",
      "commitDateOld": "15/08/13 11:22 AM",
      "commitNameOld": "02b19e0738d9df1e4d38280c5575e1d3ba49f8cb",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 96.18,
      "commitsBetweenForRepo": 601,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,24 @@\n   public void stop(int rc) {\n     this.resultCode \u003d rc;\n     \n     if (rpcServer !\u003d null) { \n       rpcServer.stop();\n     }\n \n     if (httpServer !\u003d null) {\n       try {\n         httpServer.stop();\n       } catch (IOException ioe) {\n         LOG.warn(\"Unable to stop HTTP server for \" + this, ioe);\n       }\n     }\n     \n     for (Journal j : journalsById.values()) {\n       IOUtils.cleanup(LOG, j);\n     }\n+\n+    if (journalNodeInfoBeanName !\u003d null) {\n+      MBeans.unregister(journalNodeInfoBeanName);\n+      journalNodeInfoBeanName \u003d null;\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void stop(int rc) {\n    this.resultCode \u003d rc;\n    \n    if (rpcServer !\u003d null) { \n      rpcServer.stop();\n    }\n\n    if (httpServer !\u003d null) {\n      try {\n        httpServer.stop();\n      } catch (IOException ioe) {\n        LOG.warn(\"Unable to stop HTTP server for \" + this, ioe);\n      }\n    }\n    \n    for (Journal j : journalsById.values()) {\n      IOUtils.cleanup(LOG, j);\n    }\n\n    if (journalNodeInfoBeanName !\u003d null) {\n      MBeans.unregister(journalNodeInfoBeanName);\n      journalNodeInfoBeanName \u003d null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java",
      "extendedDetails": {}
    },
    "74d4573a23db5586c6e47ff2277aa7c35237da34": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1363596 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/07/12 5:25 PM",
      "commitName": "74d4573a23db5586c6e47ff2277aa7c35237da34",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,19 @@\n+  public void stop(int rc) {\n+    this.resultCode \u003d rc;\n+    \n+    if (rpcServer !\u003d null) { \n+      rpcServer.stop();\n+    }\n+\n+    if (httpServer !\u003d null) {\n+      try {\n+        httpServer.stop();\n+      } catch (IOException ioe) {\n+        LOG.warn(\"Unable to stop HTTP server for \" + this, ioe);\n+      }\n+    }\n+    \n+    for (Journal j : journalsById.values()) {\n+      IOUtils.cleanup(LOG, j);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void stop(int rc) {\n    this.resultCode \u003d rc;\n    \n    if (rpcServer !\u003d null) { \n      rpcServer.stop();\n    }\n\n    if (httpServer !\u003d null) {\n      try {\n        httpServer.stop();\n      } catch (IOException ioe) {\n        LOG.warn(\"Unable to stop HTTP server for \" + this, ioe);\n      }\n    }\n    \n    for (Journal j : journalsById.values()) {\n      IOUtils.cleanup(LOG, j);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/server/JournalNode.java"
    }
  }
}