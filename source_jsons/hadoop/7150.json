{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockStorageMovementAttemptedItems.java",
  "functionName": "matchesReportedBlock",
  "functionId": "matchesReportedBlock___reportedDn-DatanodeInfo__type-StorageType__reportedBlock-Block",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementAttemptedItems.java",
  "functionStartLine": 154,
  "functionEndLine": 182,
  "numCommitsSeen": 7,
  "timeTaken": 2762,
  "changeHistory": [
    "66e8f9b31529226309c924226a53dead3e6fcf11",
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d"
  ],
  "changeHistoryShort": {
    "66e8f9b31529226309c924226a53dead3e6fcf11": "Ybodychange",
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": "Yintroduced"
  },
  "changeHistoryDetails": {
    "66e8f9b31529226309c924226a53dead3e6fcf11": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13381 : [SPS]: Use DFSUtilClient#makePathFromFileId() to prepare satisfier file path. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "66e8f9b31529226309c924226a53dead3e6fcf11",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,29 @@\n   private void matchesReportedBlock(DatanodeInfo reportedDn, StorageType type,\n       Block reportedBlock) {\n     Set\u003cStorageTypeNodePair\u003e blkLocs \u003d scheduledBlkLocs.get(reportedBlock);\n     if (blkLocs \u003d\u003d null) {\n       return; // unknown block, simply skip.\n     }\n \n     for (StorageTypeNodePair dn : blkLocs) {\n       boolean foundDn \u003d dn.getDatanodeInfo().compareTo(reportedDn) \u003d\u003d 0 ? true\n           : false;\n       boolean foundType \u003d dn.getStorageType().equals(type);\n       if (foundDn \u0026\u0026 foundType) {\n         blkLocs.remove(dn);\n-        // listener if it is plugged-in\n-        if (blkMovementListener !\u003d null) {\n-          blkMovementListener\n-              .notifyMovementTriedBlocks(new Block[] {reportedBlock});\n-        }\n+        Block[] mFinishedBlocks \u003d new Block[1];\n+        mFinishedBlocks[0] \u003d reportedBlock;\n+        context.notifyMovementTriedBlocks(mFinishedBlocks);\n         // All the block locations has reported.\n         if (blkLocs.size() \u003c\u003d 0) {\n           movementFinishedBlocks.add(reportedBlock);\n           scheduledBlkLocs.remove(reportedBlock); // clean-up reported block\n         }\n         return; // found\n       }\n     }\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"Reported block:{} not found in attempted blocks. Datanode:{}\"\n           + \", StorageType:{}\", reportedBlock, reportedDn, type);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void matchesReportedBlock(DatanodeInfo reportedDn, StorageType type,\n      Block reportedBlock) {\n    Set\u003cStorageTypeNodePair\u003e blkLocs \u003d scheduledBlkLocs.get(reportedBlock);\n    if (blkLocs \u003d\u003d null) {\n      return; // unknown block, simply skip.\n    }\n\n    for (StorageTypeNodePair dn : blkLocs) {\n      boolean foundDn \u003d dn.getDatanodeInfo().compareTo(reportedDn) \u003d\u003d 0 ? true\n          : false;\n      boolean foundType \u003d dn.getStorageType().equals(type);\n      if (foundDn \u0026\u0026 foundType) {\n        blkLocs.remove(dn);\n        Block[] mFinishedBlocks \u003d new Block[1];\n        mFinishedBlocks[0] \u003d reportedBlock;\n        context.notifyMovementTriedBlocks(mFinishedBlocks);\n        // All the block locations has reported.\n        if (blkLocs.size() \u003c\u003d 0) {\n          movementFinishedBlocks.add(reportedBlock);\n          scheduledBlkLocs.remove(reportedBlock); // clean-up reported block\n        }\n        return; // found\n      }\n    }\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Reported block:{} not found in attempted blocks. Datanode:{}\"\n          + \", StorageType:{}\", reportedBlock, reportedDn, type);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementAttemptedItems.java",
      "extendedDetails": {}
    },
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "diff": "@@ -0,0 +1,31 @@\n+  private void matchesReportedBlock(DatanodeInfo reportedDn, StorageType type,\n+      Block reportedBlock) {\n+    Set\u003cStorageTypeNodePair\u003e blkLocs \u003d scheduledBlkLocs.get(reportedBlock);\n+    if (blkLocs \u003d\u003d null) {\n+      return; // unknown block, simply skip.\n+    }\n+\n+    for (StorageTypeNodePair dn : blkLocs) {\n+      boolean foundDn \u003d dn.getDatanodeInfo().compareTo(reportedDn) \u003d\u003d 0 ? true\n+          : false;\n+      boolean foundType \u003d dn.getStorageType().equals(type);\n+      if (foundDn \u0026\u0026 foundType) {\n+        blkLocs.remove(dn);\n+        // listener if it is plugged-in\n+        if (blkMovementListener !\u003d null) {\n+          blkMovementListener\n+              .notifyMovementTriedBlocks(new Block[] {reportedBlock});\n+        }\n+        // All the block locations has reported.\n+        if (blkLocs.size() \u003c\u003d 0) {\n+          movementFinishedBlocks.add(reportedBlock);\n+          scheduledBlkLocs.remove(reportedBlock); // clean-up reported block\n+        }\n+        return; // found\n+      }\n+    }\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Reported block:{} not found in attempted blocks. Datanode:{}\"\n+          + \", StorageType:{}\", reportedBlock, reportedDn, type);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void matchesReportedBlock(DatanodeInfo reportedDn, StorageType type,\n      Block reportedBlock) {\n    Set\u003cStorageTypeNodePair\u003e blkLocs \u003d scheduledBlkLocs.get(reportedBlock);\n    if (blkLocs \u003d\u003d null) {\n      return; // unknown block, simply skip.\n    }\n\n    for (StorageTypeNodePair dn : blkLocs) {\n      boolean foundDn \u003d dn.getDatanodeInfo().compareTo(reportedDn) \u003d\u003d 0 ? true\n          : false;\n      boolean foundType \u003d dn.getStorageType().equals(type);\n      if (foundDn \u0026\u0026 foundType) {\n        blkLocs.remove(dn);\n        // listener if it is plugged-in\n        if (blkMovementListener !\u003d null) {\n          blkMovementListener\n              .notifyMovementTriedBlocks(new Block[] {reportedBlock});\n        }\n        // All the block locations has reported.\n        if (blkLocs.size() \u003c\u003d 0) {\n          movementFinishedBlocks.add(reportedBlock);\n          scheduledBlkLocs.remove(reportedBlock); // clean-up reported block\n        }\n        return; // found\n      }\n    }\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"Reported block:{} not found in attempted blocks. Datanode:{}\"\n          + \", StorageType:{}\", reportedBlock, reportedDn, type);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementAttemptedItems.java"
    }
  }
}