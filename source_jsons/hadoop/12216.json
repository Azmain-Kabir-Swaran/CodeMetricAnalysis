{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataNode.java",
  "functionName": "checkReadAccess",
  "functionId": "checkReadAccess___block-ExtendedBlock(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
  "functionStartLine": 3019,
  "functionEndLine": 3043,
  "numCommitsSeen": 358,
  "timeTaken": 2309,
  "changeHistory": [
    "dfcb331ba3516264398121c9f23af3a79c0509cc"
  ],
  "changeHistoryShort": {
    "dfcb331ba3516264398121c9f23af3a79c0509cc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "dfcb331ba3516264398121c9f23af3a79c0509cc": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13076: [SPS]: Addendum. Resolve conflicts after rebasing branch to trunk. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "dfcb331ba3516264398121c9f23af3a79c0509cc",
      "commitAuthor": "Rakesh Radhakrishnan",
      "diff": "@@ -0,0 +1,25 @@\n+  private void checkReadAccess(final ExtendedBlock block) throws IOException {\n+    // Make sure this node has registered for the block pool.\n+    try {\n+      getDNRegistrationForBP(block.getBlockPoolId());\n+    } catch (IOException e) {\n+      // if it has not registered with the NN, throw an exception back.\n+      throw new org.apache.hadoop.ipc.RetriableException(\n+          \"Datanode not registered. Try again later.\");\n+    }\n+\n+    if (isBlockTokenEnabled) {\n+      Set\u003cTokenIdentifier\u003e tokenIds \u003d UserGroupInformation.getCurrentUser()\n+          .getTokenIdentifiers();\n+      if (tokenIds.size() !\u003d 1) {\n+        throw new IOException(\"Can\u0027t continue since none or more than one \"\n+            + \"BlockTokenIdentifier is found.\");\n+      }\n+      for (TokenIdentifier tokenId : tokenIds) {\n+        BlockTokenIdentifier id \u003d (BlockTokenIdentifier) tokenId;\n+        LOG.debug(\"Got: {}\", id);\n+        blockPoolTokenSecretManager.checkAccess(id, null, block,\n+            BlockTokenIdentifier.AccessMode.READ, null, null);\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void checkReadAccess(final ExtendedBlock block) throws IOException {\n    // Make sure this node has registered for the block pool.\n    try {\n      getDNRegistrationForBP(block.getBlockPoolId());\n    } catch (IOException e) {\n      // if it has not registered with the NN, throw an exception back.\n      throw new org.apache.hadoop.ipc.RetriableException(\n          \"Datanode not registered. Try again later.\");\n    }\n\n    if (isBlockTokenEnabled) {\n      Set\u003cTokenIdentifier\u003e tokenIds \u003d UserGroupInformation.getCurrentUser()\n          .getTokenIdentifiers();\n      if (tokenIds.size() !\u003d 1) {\n        throw new IOException(\"Can\u0027t continue since none or more than one \"\n            + \"BlockTokenIdentifier is found.\");\n      }\n      for (TokenIdentifier tokenId : tokenIds) {\n        BlockTokenIdentifier id \u003d (BlockTokenIdentifier) tokenId;\n        LOG.debug(\"Got: {}\", id);\n        blockPoolTokenSecretManager.checkAccess(id, null, block,\n            BlockTokenIdentifier.AccessMode.READ, null, null);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java"
    }
  }
}