{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Token.java",
  "functionName": "decodeIdentifier",
  "functionId": "decodeIdentifier",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/Token.java",
  "functionStartLine": 164,
  "functionEndLine": 175,
  "numCommitsSeen": 29,
  "timeTaken": 980,
  "changeHistory": [
    "aea890f7d215d97feec873228158daefa2e63217"
  ],
  "changeHistoryShort": {
    "aea890f7d215d97feec873228158daefa2e63217": "Yintroduced"
  },
  "changeHistoryDetails": {
    "aea890f7d215d97feec873228158daefa2e63217": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-4148. MapReduce should not have a compile-time dependency on HDFS.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1337199 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/05/12 8:00 AM",
      "commitName": "aea890f7d215d97feec873228158daefa2e63217",
      "commitAuthor": "Thomas White",
      "diff": "@@ -0,0 +1,12 @@\n+  public T decodeIdentifier() throws IOException {\n+    Class\u003c? extends TokenIdentifier\u003e cls \u003d getClassForIdentifier(getKind());\n+    if (cls \u003d\u003d null) {\n+      return null;\n+    }\n+    TokenIdentifier tokenIdentifier \u003d ReflectionUtils.newInstance(cls, null);\n+    ByteArrayInputStream buf \u003d new ByteArrayInputStream(identifier);\n+    DataInputStream in \u003d new DataInputStream(buf);  \n+    tokenIdentifier.readFields(in);\n+    in.close();\n+    return (T) tokenIdentifier;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public T decodeIdentifier() throws IOException {\n    Class\u003c? extends TokenIdentifier\u003e cls \u003d getClassForIdentifier(getKind());\n    if (cls \u003d\u003d null) {\n      return null;\n    }\n    TokenIdentifier tokenIdentifier \u003d ReflectionUtils.newInstance(cls, null);\n    ByteArrayInputStream buf \u003d new ByteArrayInputStream(identifier);\n    DataInputStream in \u003d new DataInputStream(buf);  \n    tokenIdentifier.readFields(in);\n    in.close();\n    return (T) tokenIdentifier;\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/Token.java"
    }
  }
}