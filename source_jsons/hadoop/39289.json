{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CapacityScheduler.java",
  "functionName": "updateLabelsOnNode",
  "functionId": "updateLabelsOnNode___nodeId-NodeId__newLabels-Set__String__",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java",
  "functionStartLine": 1376,
  "functionEndLine": 1418,
  "numCommitsSeen": 239,
  "timeTaken": 8690,
  "changeHistory": [
    "7d2d8d25ba0cb10a3c6192d4123f27ede5ef2ba6",
    "31f8da22d0b8d2dcce5fbc8e45d832f40acf056f",
    "bb62e0592566b2fcae7136b30972aad2d3ac55b0",
    "20d389ce61eaacb5ddfb329015f50e96ad894f8d",
    "a44ce3f14fd940601f984fbf7980aa6fdc8f23b7",
    "150f5ae0343e872ee8bef39c57008c1389f0ba9e",
    "3fe57285635e8058c34aa40a103845b49ca7d6ff",
    "adf260a728df427eb729abe8fb9ad7248991ea54",
    "805a9ed85eb34c8125cfb7d26d07cdfac12b3579",
    "29a582ada0fe195989eca25e5a995895e178f4ea",
    "bf669b6d9f8ba165e30b8823218d625a49958925",
    "fdf042dfffa4d2474e3cac86cfb8fe9ee4648beb"
  ],
  "changeHistoryShort": {
    "7d2d8d25ba0cb10a3c6192d4123f27ede5ef2ba6": "Ybodychange",
    "31f8da22d0b8d2dcce5fbc8e45d832f40acf056f": "Ymultichange(Ymodifierchange,Ybodychange)",
    "bb62e0592566b2fcae7136b30972aad2d3ac55b0": "Ybodychange",
    "20d389ce61eaacb5ddfb329015f50e96ad894f8d": "Ybodychange",
    "a44ce3f14fd940601f984fbf7980aa6fdc8f23b7": "Ybodychange",
    "150f5ae0343e872ee8bef39c57008c1389f0ba9e": "Ybodychange",
    "3fe57285635e8058c34aa40a103845b49ca7d6ff": "Ybodychange",
    "adf260a728df427eb729abe8fb9ad7248991ea54": "Ybodychange",
    "805a9ed85eb34c8125cfb7d26d07cdfac12b3579": "Ybodychange",
    "29a582ada0fe195989eca25e5a995895e178f4ea": "Ybodychange",
    "bf669b6d9f8ba165e30b8823218d625a49958925": "Ybodychange",
    "fdf042dfffa4d2474e3cac86cfb8fe9ee4648beb": "Yintroduced"
  },
  "changeHistoryDetails": {
    "7d2d8d25ba0cb10a3c6192d4123f27ede5ef2ba6": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5788. Apps not activiated and AM limit resource in UI and REST not updated after -replaceLabelsOnNode (Bibin A Chundatt via Varun Saxena)\n",
      "commitDate": "01/11/16 3:02 AM",
      "commitName": "7d2d8d25ba0cb10a3c6192d4123f27ede5ef2ba6",
      "commitAuthor": "Varun Saxena",
      "commitDateOld": "20/10/16 9:17 PM",
      "commitNameOld": "754cb4e30fac1c5fe8d44626968c0ddbfe459335",
      "commitAuthorOld": "Karthik Kambatla",
      "daysBetweenCommits": 11.24,
      "commitsBetweenForRepo": 118,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,43 @@\n   private void updateLabelsOnNode(NodeId nodeId,\n       Set\u003cString\u003e newLabels) {\n-    try {\n-      writeLock.lock();\n-      FiCaSchedulerNode node \u003d nodeTracker.getNode(nodeId);\n-      if (null \u003d\u003d node) {\n-        return;\n-      }\n-\n-      // Get new partition, we have only one partition per node\n-      String newPartition;\n-      if (newLabels.isEmpty()) {\n-        newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n-      } else{\n-        newPartition \u003d newLabels.iterator().next();\n-      }\n-\n-      // old partition as well\n-      String oldPartition \u003d node.getPartition();\n-\n-      // Update resources of these containers\n-      for (RMContainer rmContainer : node.getCopiedListOfRunningContainers()) {\n-        FiCaSchedulerApp application \u003d getApplicationAttempt(\n-            rmContainer.getApplicationAttemptId());\n-        if (null !\u003d application) {\n-          application.nodePartitionUpdated(rmContainer, oldPartition,\n-              newPartition);\n-        } else{\n-          LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n-              + \" a node, but we cannot find SchedulerApplicationAttempt \"\n-              + \"for it. Node\u003d\" + node.getNodeID() + \" applicationAttemptId\u003d\"\n-              + rmContainer.getApplicationAttemptId());\n-          continue;\n-        }\n-      }\n-\n-      // Unreserve container on this node\n-      RMContainer reservedContainer \u003d node.getReservedContainer();\n-      if (null !\u003d reservedContainer) {\n-        killReservedContainer(reservedContainer);\n-      }\n-\n-      // Update node labels after we\u0027ve done this\n-      node.updateLabels(newLabels);\n-    } finally {\n-      writeLock.unlock();\n+    FiCaSchedulerNode node \u003d nodeTracker.getNode(nodeId);\n+    if (null \u003d\u003d node) {\n+      return;\n     }\n+\n+    // Get new partition, we have only one partition per node\n+    String newPartition;\n+    if (newLabels.isEmpty()) {\n+      newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n+    } else{\n+      newPartition \u003d newLabels.iterator().next();\n+    }\n+\n+    // old partition as well\n+    String oldPartition \u003d node.getPartition();\n+\n+    // Update resources of these containers\n+    for (RMContainer rmContainer : node.getCopiedListOfRunningContainers()) {\n+      FiCaSchedulerApp application \u003d getApplicationAttempt(\n+          rmContainer.getApplicationAttemptId());\n+      if (null !\u003d application) {\n+        application.nodePartitionUpdated(rmContainer, oldPartition,\n+            newPartition);\n+      } else{\n+        LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n+            + \" a node, but we cannot find SchedulerApplicationAttempt \"\n+            + \"for it. Node\u003d\" + node.getNodeID() + \" applicationAttemptId\u003d\"\n+            + rmContainer.getApplicationAttemptId());\n+        continue;\n+      }\n+    }\n+\n+    // Unreserve container on this node\n+    RMContainer reservedContainer \u003d node.getReservedContainer();\n+    if (null !\u003d reservedContainer) {\n+      killReservedContainer(reservedContainer);\n+    }\n+\n+    // Update node labels after we\u0027ve done this\n+    node.updateLabels(newLabels);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void updateLabelsOnNode(NodeId nodeId,\n      Set\u003cString\u003e newLabels) {\n    FiCaSchedulerNode node \u003d nodeTracker.getNode(nodeId);\n    if (null \u003d\u003d node) {\n      return;\n    }\n\n    // Get new partition, we have only one partition per node\n    String newPartition;\n    if (newLabels.isEmpty()) {\n      newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n    } else{\n      newPartition \u003d newLabels.iterator().next();\n    }\n\n    // old partition as well\n    String oldPartition \u003d node.getPartition();\n\n    // Update resources of these containers\n    for (RMContainer rmContainer : node.getCopiedListOfRunningContainers()) {\n      FiCaSchedulerApp application \u003d getApplicationAttempt(\n          rmContainer.getApplicationAttemptId());\n      if (null !\u003d application) {\n        application.nodePartitionUpdated(rmContainer, oldPartition,\n            newPartition);\n      } else{\n        LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n            + \" a node, but we cannot find SchedulerApplicationAttempt \"\n            + \"for it. Node\u003d\" + node.getNodeID() + \" applicationAttemptId\u003d\"\n            + rmContainer.getApplicationAttemptId());\n        continue;\n      }\n    }\n\n    // Unreserve container on this node\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (null !\u003d reservedContainer) {\n      killReservedContainer(reservedContainer);\n    }\n\n    // Update node labels after we\u0027ve done this\n    node.updateLabels(newLabels);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java",
      "extendedDetails": {}
    },
    "31f8da22d0b8d2dcce5fbc8e45d832f40acf056f": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "YARN-3139. Improve locks in AbstractYarnScheduler/CapacityScheduler/FairScheduler. Contributed by Wangda Tan\n",
      "commitDate": "04/10/16 5:23 PM",
      "commitName": "31f8da22d0b8d2dcce5fbc8e45d832f40acf056f",
      "commitAuthor": "Jian He",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-3139. Improve locks in AbstractYarnScheduler/CapacityScheduler/FairScheduler. Contributed by Wangda Tan\n",
          "commitDate": "04/10/16 5:23 PM",
          "commitName": "31f8da22d0b8d2dcce5fbc8e45d832f40acf056f",
          "commitAuthor": "Jian He",
          "commitDateOld": "30/08/16 3:52 PM",
          "commitNameOld": "d6d9cff21b7b6141ed88359652cf22e8973c0661",
          "commitAuthorOld": "Arun Suresh",
          "daysBetweenCommits": 35.06,
          "commitsBetweenForRepo": 195,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,43 +1,48 @@\n-  private synchronized void updateLabelsOnNode(NodeId nodeId,\n+  private void updateLabelsOnNode(NodeId nodeId,\n       Set\u003cString\u003e newLabels) {\n-    FiCaSchedulerNode node \u003d nodeTracker.getNode(nodeId);\n-    if (null \u003d\u003d node) {\n-      return;\n-    }\n-    \n-    // Get new partition, we have only one partition per node\n-    String newPartition;\n-    if (newLabels.isEmpty()) {\n-      newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n-    } else {\n-      newPartition \u003d newLabels.iterator().next();\n-    }\n-\n-    // old partition as well\n-    String oldPartition \u003d node.getPartition();\n-\n-    // Update resources of these containers\n-    for (RMContainer rmContainer : node.getCopiedListOfRunningContainers()) {\n-      FiCaSchedulerApp application \u003d\n-          getApplicationAttempt(rmContainer.getApplicationAttemptId());\n-      if (null !\u003d application) {\n-        application.nodePartitionUpdated(rmContainer, oldPartition,\n-            newPartition);\n-      } else {\n-        LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n-            + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n-            + node.getNodeID() + \" applicationAttemptId\u003d\"\n-            + rmContainer.getApplicationAttemptId());\n-        continue;\n+    try {\n+      writeLock.lock();\n+      FiCaSchedulerNode node \u003d nodeTracker.getNode(nodeId);\n+      if (null \u003d\u003d node) {\n+        return;\n       }\n+\n+      // Get new partition, we have only one partition per node\n+      String newPartition;\n+      if (newLabels.isEmpty()) {\n+        newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n+      } else{\n+        newPartition \u003d newLabels.iterator().next();\n+      }\n+\n+      // old partition as well\n+      String oldPartition \u003d node.getPartition();\n+\n+      // Update resources of these containers\n+      for (RMContainer rmContainer : node.getCopiedListOfRunningContainers()) {\n+        FiCaSchedulerApp application \u003d getApplicationAttempt(\n+            rmContainer.getApplicationAttemptId());\n+        if (null !\u003d application) {\n+          application.nodePartitionUpdated(rmContainer, oldPartition,\n+              newPartition);\n+        } else{\n+          LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n+              + \" a node, but we cannot find SchedulerApplicationAttempt \"\n+              + \"for it. Node\u003d\" + node.getNodeID() + \" applicationAttemptId\u003d\"\n+              + rmContainer.getApplicationAttemptId());\n+          continue;\n+        }\n+      }\n+\n+      // Unreserve container on this node\n+      RMContainer reservedContainer \u003d node.getReservedContainer();\n+      if (null !\u003d reservedContainer) {\n+        killReservedContainer(reservedContainer);\n+      }\n+\n+      // Update node labels after we\u0027ve done this\n+      node.updateLabels(newLabels);\n+    } finally {\n+      writeLock.unlock();\n     }\n-    \n-    // Unreserve container on this node\n-    RMContainer reservedContainer \u003d node.getReservedContainer();\n-    if (null !\u003d reservedContainer) {\n-      killReservedContainer(reservedContainer);\n-    }\n-    \n-    // Update node labels after we\u0027ve done this\n-    node.updateLabels(newLabels);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void updateLabelsOnNode(NodeId nodeId,\n      Set\u003cString\u003e newLabels) {\n    try {\n      writeLock.lock();\n      FiCaSchedulerNode node \u003d nodeTracker.getNode(nodeId);\n      if (null \u003d\u003d node) {\n        return;\n      }\n\n      // Get new partition, we have only one partition per node\n      String newPartition;\n      if (newLabels.isEmpty()) {\n        newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n      } else{\n        newPartition \u003d newLabels.iterator().next();\n      }\n\n      // old partition as well\n      String oldPartition \u003d node.getPartition();\n\n      // Update resources of these containers\n      for (RMContainer rmContainer : node.getCopiedListOfRunningContainers()) {\n        FiCaSchedulerApp application \u003d getApplicationAttempt(\n            rmContainer.getApplicationAttemptId());\n        if (null !\u003d application) {\n          application.nodePartitionUpdated(rmContainer, oldPartition,\n              newPartition);\n        } else{\n          LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n              + \" a node, but we cannot find SchedulerApplicationAttempt \"\n              + \"for it. Node\u003d\" + node.getNodeID() + \" applicationAttemptId\u003d\"\n              + rmContainer.getApplicationAttemptId());\n          continue;\n        }\n      }\n\n      // Unreserve container on this node\n      RMContainer reservedContainer \u003d node.getReservedContainer();\n      if (null !\u003d reservedContainer) {\n        killReservedContainer(reservedContainer);\n      }\n\n      // Update node labels after we\u0027ve done this\n      node.updateLabels(newLabels);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java",
          "extendedDetails": {
            "oldValue": "[private, synchronized]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-3139. Improve locks in AbstractYarnScheduler/CapacityScheduler/FairScheduler. Contributed by Wangda Tan\n",
          "commitDate": "04/10/16 5:23 PM",
          "commitName": "31f8da22d0b8d2dcce5fbc8e45d832f40acf056f",
          "commitAuthor": "Jian He",
          "commitDateOld": "30/08/16 3:52 PM",
          "commitNameOld": "d6d9cff21b7b6141ed88359652cf22e8973c0661",
          "commitAuthorOld": "Arun Suresh",
          "daysBetweenCommits": 35.06,
          "commitsBetweenForRepo": 195,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,43 +1,48 @@\n-  private synchronized void updateLabelsOnNode(NodeId nodeId,\n+  private void updateLabelsOnNode(NodeId nodeId,\n       Set\u003cString\u003e newLabels) {\n-    FiCaSchedulerNode node \u003d nodeTracker.getNode(nodeId);\n-    if (null \u003d\u003d node) {\n-      return;\n-    }\n-    \n-    // Get new partition, we have only one partition per node\n-    String newPartition;\n-    if (newLabels.isEmpty()) {\n-      newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n-    } else {\n-      newPartition \u003d newLabels.iterator().next();\n-    }\n-\n-    // old partition as well\n-    String oldPartition \u003d node.getPartition();\n-\n-    // Update resources of these containers\n-    for (RMContainer rmContainer : node.getCopiedListOfRunningContainers()) {\n-      FiCaSchedulerApp application \u003d\n-          getApplicationAttempt(rmContainer.getApplicationAttemptId());\n-      if (null !\u003d application) {\n-        application.nodePartitionUpdated(rmContainer, oldPartition,\n-            newPartition);\n-      } else {\n-        LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n-            + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n-            + node.getNodeID() + \" applicationAttemptId\u003d\"\n-            + rmContainer.getApplicationAttemptId());\n-        continue;\n+    try {\n+      writeLock.lock();\n+      FiCaSchedulerNode node \u003d nodeTracker.getNode(nodeId);\n+      if (null \u003d\u003d node) {\n+        return;\n       }\n+\n+      // Get new partition, we have only one partition per node\n+      String newPartition;\n+      if (newLabels.isEmpty()) {\n+        newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n+      } else{\n+        newPartition \u003d newLabels.iterator().next();\n+      }\n+\n+      // old partition as well\n+      String oldPartition \u003d node.getPartition();\n+\n+      // Update resources of these containers\n+      for (RMContainer rmContainer : node.getCopiedListOfRunningContainers()) {\n+        FiCaSchedulerApp application \u003d getApplicationAttempt(\n+            rmContainer.getApplicationAttemptId());\n+        if (null !\u003d application) {\n+          application.nodePartitionUpdated(rmContainer, oldPartition,\n+              newPartition);\n+        } else{\n+          LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n+              + \" a node, but we cannot find SchedulerApplicationAttempt \"\n+              + \"for it. Node\u003d\" + node.getNodeID() + \" applicationAttemptId\u003d\"\n+              + rmContainer.getApplicationAttemptId());\n+          continue;\n+        }\n+      }\n+\n+      // Unreserve container on this node\n+      RMContainer reservedContainer \u003d node.getReservedContainer();\n+      if (null !\u003d reservedContainer) {\n+        killReservedContainer(reservedContainer);\n+      }\n+\n+      // Update node labels after we\u0027ve done this\n+      node.updateLabels(newLabels);\n+    } finally {\n+      writeLock.unlock();\n     }\n-    \n-    // Unreserve container on this node\n-    RMContainer reservedContainer \u003d node.getReservedContainer();\n-    if (null !\u003d reservedContainer) {\n-      killReservedContainer(reservedContainer);\n-    }\n-    \n-    // Update node labels after we\u0027ve done this\n-    node.updateLabels(newLabels);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void updateLabelsOnNode(NodeId nodeId,\n      Set\u003cString\u003e newLabels) {\n    try {\n      writeLock.lock();\n      FiCaSchedulerNode node \u003d nodeTracker.getNode(nodeId);\n      if (null \u003d\u003d node) {\n        return;\n      }\n\n      // Get new partition, we have only one partition per node\n      String newPartition;\n      if (newLabels.isEmpty()) {\n        newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n      } else{\n        newPartition \u003d newLabels.iterator().next();\n      }\n\n      // old partition as well\n      String oldPartition \u003d node.getPartition();\n\n      // Update resources of these containers\n      for (RMContainer rmContainer : node.getCopiedListOfRunningContainers()) {\n        FiCaSchedulerApp application \u003d getApplicationAttempt(\n            rmContainer.getApplicationAttemptId());\n        if (null !\u003d application) {\n          application.nodePartitionUpdated(rmContainer, oldPartition,\n              newPartition);\n        } else{\n          LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n              + \" a node, but we cannot find SchedulerApplicationAttempt \"\n              + \"for it. Node\u003d\" + node.getNodeID() + \" applicationAttemptId\u003d\"\n              + rmContainer.getApplicationAttemptId());\n          continue;\n        }\n      }\n\n      // Unreserve container on this node\n      RMContainer reservedContainer \u003d node.getReservedContainer();\n      if (null !\u003d reservedContainer) {\n        killReservedContainer(reservedContainer);\n      }\n\n      // Update node labels after we\u0027ve done this\n      node.updateLabels(newLabels);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java",
          "extendedDetails": {}
        }
      ]
    },
    "bb62e0592566b2fcae7136b30972aad2d3ac55b0": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4390. Do surgical preemption based on reserved container in CapacityScheduler. Contributed by Wangda Tan\n",
      "commitDate": "05/05/16 12:56 PM",
      "commitName": "bb62e0592566b2fcae7136b30972aad2d3ac55b0",
      "commitAuthor": "Jian He",
      "commitDateOld": "08/04/16 3:33 PM",
      "commitNameOld": "ec06957941367930c855b5e05e6a84ba676fd46a",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 26.89,
      "commitsBetweenForRepo": 160,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,43 @@\n   private synchronized void updateLabelsOnNode(NodeId nodeId,\n       Set\u003cString\u003e newLabels) {\n     FiCaSchedulerNode node \u003d nodeTracker.getNode(nodeId);\n     if (null \u003d\u003d node) {\n       return;\n     }\n     \n     // Get new partition, we have only one partition per node\n     String newPartition;\n     if (newLabels.isEmpty()) {\n       newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n     } else {\n       newPartition \u003d newLabels.iterator().next();\n     }\n \n     // old partition as well\n     String oldPartition \u003d node.getPartition();\n \n     // Update resources of these containers\n-    for (RMContainer rmContainer : node.getRunningContainers()) {\n+    for (RMContainer rmContainer : node.getCopiedListOfRunningContainers()) {\n       FiCaSchedulerApp application \u003d\n           getApplicationAttempt(rmContainer.getApplicationAttemptId());\n       if (null !\u003d application) {\n         application.nodePartitionUpdated(rmContainer, oldPartition,\n             newPartition);\n       } else {\n         LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n             + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n             + node.getNodeID() + \" applicationAttemptId\u003d\"\n             + rmContainer.getApplicationAttemptId());\n         continue;\n       }\n     }\n     \n     // Unreserve container on this node\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (null !\u003d reservedContainer) {\n       killReservedContainer(reservedContainer);\n     }\n     \n     // Update node labels after we\u0027ve done this\n     node.updateLabels(newLabels);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void updateLabelsOnNode(NodeId nodeId,\n      Set\u003cString\u003e newLabels) {\n    FiCaSchedulerNode node \u003d nodeTracker.getNode(nodeId);\n    if (null \u003d\u003d node) {\n      return;\n    }\n    \n    // Get new partition, we have only one partition per node\n    String newPartition;\n    if (newLabels.isEmpty()) {\n      newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n    } else {\n      newPartition \u003d newLabels.iterator().next();\n    }\n\n    // old partition as well\n    String oldPartition \u003d node.getPartition();\n\n    // Update resources of these containers\n    for (RMContainer rmContainer : node.getCopiedListOfRunningContainers()) {\n      FiCaSchedulerApp application \u003d\n          getApplicationAttempt(rmContainer.getApplicationAttemptId());\n      if (null !\u003d application) {\n        application.nodePartitionUpdated(rmContainer, oldPartition,\n            newPartition);\n      } else {\n        LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n            + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n            + node.getNodeID() + \" applicationAttemptId\u003d\"\n            + rmContainer.getApplicationAttemptId());\n        continue;\n      }\n    }\n    \n    // Unreserve container on this node\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (null !\u003d reservedContainer) {\n      killReservedContainer(reservedContainer);\n    }\n    \n    // Update node labels after we\u0027ve done this\n    node.updateLabels(newLabels);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java",
      "extendedDetails": {}
    },
    "20d389ce61eaacb5ddfb329015f50e96ad894f8d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4719. Add a helper library to maintain node state and allows common queries. (kasha)\n",
      "commitDate": "14/03/16 2:19 PM",
      "commitName": "20d389ce61eaacb5ddfb329015f50e96ad894f8d",
      "commitAuthor": "Karthik Kambatla",
      "commitDateOld": "01/03/16 1:14 PM",
      "commitNameOld": "5c465df90414d43250d09084748ab2d41af44eea",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 13.0,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,43 @@\n   private synchronized void updateLabelsOnNode(NodeId nodeId,\n       Set\u003cString\u003e newLabels) {\n-    FiCaSchedulerNode node \u003d nodes.get(nodeId);\n+    FiCaSchedulerNode node \u003d nodeTracker.getNode(nodeId);\n     if (null \u003d\u003d node) {\n       return;\n     }\n     \n     // Get new partition, we have only one partition per node\n     String newPartition;\n     if (newLabels.isEmpty()) {\n       newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n     } else {\n       newPartition \u003d newLabels.iterator().next();\n     }\n \n     // old partition as well\n     String oldPartition \u003d node.getPartition();\n \n     // Update resources of these containers\n     for (RMContainer rmContainer : node.getRunningContainers()) {\n       FiCaSchedulerApp application \u003d\n           getApplicationAttempt(rmContainer.getApplicationAttemptId());\n       if (null !\u003d application) {\n         application.nodePartitionUpdated(rmContainer, oldPartition,\n             newPartition);\n       } else {\n         LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n             + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n             + node.getNodeID() + \" applicationAttemptId\u003d\"\n             + rmContainer.getApplicationAttemptId());\n         continue;\n       }\n     }\n     \n     // Unreserve container on this node\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (null !\u003d reservedContainer) {\n       killReservedContainer(reservedContainer);\n     }\n     \n     // Update node labels after we\u0027ve done this\n     node.updateLabels(newLabels);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void updateLabelsOnNode(NodeId nodeId,\n      Set\u003cString\u003e newLabels) {\n    FiCaSchedulerNode node \u003d nodeTracker.getNode(nodeId);\n    if (null \u003d\u003d node) {\n      return;\n    }\n    \n    // Get new partition, we have only one partition per node\n    String newPartition;\n    if (newLabels.isEmpty()) {\n      newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n    } else {\n      newPartition \u003d newLabels.iterator().next();\n    }\n\n    // old partition as well\n    String oldPartition \u003d node.getPartition();\n\n    // Update resources of these containers\n    for (RMContainer rmContainer : node.getRunningContainers()) {\n      FiCaSchedulerApp application \u003d\n          getApplicationAttempt(rmContainer.getApplicationAttemptId());\n      if (null !\u003d application) {\n        application.nodePartitionUpdated(rmContainer, oldPartition,\n            newPartition);\n      } else {\n        LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n            + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n            + node.getNodeID() + \" applicationAttemptId\u003d\"\n            + rmContainer.getApplicationAttemptId());\n        continue;\n      }\n    }\n    \n    // Unreserve container on this node\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (null !\u003d reservedContainer) {\n      killReservedContainer(reservedContainer);\n    }\n    \n    // Update node labels after we\u0027ve done this\n    node.updateLabels(newLabels);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java",
      "extendedDetails": {}
    },
    "a44ce3f14fd940601f984fbf7980aa6fdc8f23b7": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4502. Fix two AM containers get allocated when AM restart. (Vinod Kumar Vavilapalli via wangda)\n",
      "commitDate": "18/01/16 5:30 PM",
      "commitName": "a44ce3f14fd940601f984fbf7980aa6fdc8f23b7",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "18/01/16 5:27 PM",
      "commitNameOld": "150f5ae0343e872ee8bef39c57008c1389f0ba9e",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,43 @@\n   private synchronized void updateLabelsOnNode(NodeId nodeId,\n       Set\u003cString\u003e newLabels) {\n     FiCaSchedulerNode node \u003d nodes.get(nodeId);\n     if (null \u003d\u003d node) {\n       return;\n     }\n     \n     // Get new partition, we have only one partition per node\n     String newPartition;\n     if (newLabels.isEmpty()) {\n       newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n     } else {\n       newPartition \u003d newLabels.iterator().next();\n     }\n \n     // old partition as well\n     String oldPartition \u003d node.getPartition();\n \n     // Update resources of these containers\n     for (RMContainer rmContainer : node.getRunningContainers()) {\n       FiCaSchedulerApp application \u003d\n           getApplicationAttempt(rmContainer.getApplicationAttemptId());\n       if (null !\u003d application) {\n         application.nodePartitionUpdated(rmContainer, oldPartition,\n             newPartition);\n       } else {\n         LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n             + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n             + node.getNodeID() + \" applicationAttemptId\u003d\"\n             + rmContainer.getApplicationAttemptId());\n         continue;\n       }\n     }\n     \n     // Unreserve container on this node\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (null !\u003d reservedContainer) {\n-      dropContainerReservation(reservedContainer);\n+      killReservedContainer(reservedContainer);\n     }\n     \n     // Update node labels after we\u0027ve done this\n     node.updateLabels(newLabels);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void updateLabelsOnNode(NodeId nodeId,\n      Set\u003cString\u003e newLabels) {\n    FiCaSchedulerNode node \u003d nodes.get(nodeId);\n    if (null \u003d\u003d node) {\n      return;\n    }\n    \n    // Get new partition, we have only one partition per node\n    String newPartition;\n    if (newLabels.isEmpty()) {\n      newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n    } else {\n      newPartition \u003d newLabels.iterator().next();\n    }\n\n    // old partition as well\n    String oldPartition \u003d node.getPartition();\n\n    // Update resources of these containers\n    for (RMContainer rmContainer : node.getRunningContainers()) {\n      FiCaSchedulerApp application \u003d\n          getApplicationAttempt(rmContainer.getApplicationAttemptId());\n      if (null !\u003d application) {\n        application.nodePartitionUpdated(rmContainer, oldPartition,\n            newPartition);\n      } else {\n        LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n            + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n            + node.getNodeID() + \" applicationAttemptId\u003d\"\n            + rmContainer.getApplicationAttemptId());\n        continue;\n      }\n    }\n    \n    // Unreserve container on this node\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (null !\u003d reservedContainer) {\n      killReservedContainer(reservedContainer);\n    }\n    \n    // Update node labels after we\u0027ve done this\n    node.updateLabels(newLabels);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java",
      "extendedDetails": {}
    },
    "150f5ae0343e872ee8bef39c57008c1389f0ba9e": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"YARN-4502. Fix two AM containers get allocated when AM restart. (Vinod Kumar Vavilapalli via wangda)\"\n\nThis reverts commit 3fe57285635e8058c34aa40a103845b49ca7d6ff.\n\nConflicts:\n\thadoop-yarn-project/CHANGES.txt\n",
      "commitDate": "18/01/16 5:27 PM",
      "commitName": "150f5ae0343e872ee8bef39c57008c1389f0ba9e",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "18/01/16 1:06 AM",
      "commitNameOld": "3fe57285635e8058c34aa40a103845b49ca7d6ff",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 0.68,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,43 @@\n   private synchronized void updateLabelsOnNode(NodeId nodeId,\n       Set\u003cString\u003e newLabels) {\n     FiCaSchedulerNode node \u003d nodes.get(nodeId);\n     if (null \u003d\u003d node) {\n       return;\n     }\n     \n     // Get new partition, we have only one partition per node\n     String newPartition;\n     if (newLabels.isEmpty()) {\n       newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n     } else {\n       newPartition \u003d newLabels.iterator().next();\n     }\n \n     // old partition as well\n     String oldPartition \u003d node.getPartition();\n \n     // Update resources of these containers\n     for (RMContainer rmContainer : node.getRunningContainers()) {\n       FiCaSchedulerApp application \u003d\n           getApplicationAttempt(rmContainer.getApplicationAttemptId());\n       if (null !\u003d application) {\n         application.nodePartitionUpdated(rmContainer, oldPartition,\n             newPartition);\n       } else {\n         LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n             + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n             + node.getNodeID() + \" applicationAttemptId\u003d\"\n             + rmContainer.getApplicationAttemptId());\n         continue;\n       }\n     }\n     \n     // Unreserve container on this node\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (null !\u003d reservedContainer) {\n-      killReservedContainer(reservedContainer);\n+      dropContainerReservation(reservedContainer);\n     }\n     \n     // Update node labels after we\u0027ve done this\n     node.updateLabels(newLabels);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void updateLabelsOnNode(NodeId nodeId,\n      Set\u003cString\u003e newLabels) {\n    FiCaSchedulerNode node \u003d nodes.get(nodeId);\n    if (null \u003d\u003d node) {\n      return;\n    }\n    \n    // Get new partition, we have only one partition per node\n    String newPartition;\n    if (newLabels.isEmpty()) {\n      newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n    } else {\n      newPartition \u003d newLabels.iterator().next();\n    }\n\n    // old partition as well\n    String oldPartition \u003d node.getPartition();\n\n    // Update resources of these containers\n    for (RMContainer rmContainer : node.getRunningContainers()) {\n      FiCaSchedulerApp application \u003d\n          getApplicationAttempt(rmContainer.getApplicationAttemptId());\n      if (null !\u003d application) {\n        application.nodePartitionUpdated(rmContainer, oldPartition,\n            newPartition);\n      } else {\n        LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n            + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n            + node.getNodeID() + \" applicationAttemptId\u003d\"\n            + rmContainer.getApplicationAttemptId());\n        continue;\n      }\n    }\n    \n    // Unreserve container on this node\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (null !\u003d reservedContainer) {\n      dropContainerReservation(reservedContainer);\n    }\n    \n    // Update node labels after we\u0027ve done this\n    node.updateLabels(newLabels);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java",
      "extendedDetails": {}
    },
    "3fe57285635e8058c34aa40a103845b49ca7d6ff": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4502. Fix two AM containers get allocated when AM restart. (Vinod Kumar Vavilapalli via wangda)\n\n(cherry picked from commit 805a9ed85eb34c8125cfb7d26d07cdfac12b3579)\n",
      "commitDate": "18/01/16 1:06 AM",
      "commitName": "3fe57285635e8058c34aa40a103845b49ca7d6ff",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "18/01/16 12:50 AM",
      "commitNameOld": "adf260a728df427eb729abe8fb9ad7248991ea54",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,43 @@\n   private synchronized void updateLabelsOnNode(NodeId nodeId,\n       Set\u003cString\u003e newLabels) {\n     FiCaSchedulerNode node \u003d nodes.get(nodeId);\n     if (null \u003d\u003d node) {\n       return;\n     }\n     \n     // Get new partition, we have only one partition per node\n     String newPartition;\n     if (newLabels.isEmpty()) {\n       newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n     } else {\n       newPartition \u003d newLabels.iterator().next();\n     }\n \n     // old partition as well\n     String oldPartition \u003d node.getPartition();\n \n     // Update resources of these containers\n     for (RMContainer rmContainer : node.getRunningContainers()) {\n       FiCaSchedulerApp application \u003d\n           getApplicationAttempt(rmContainer.getApplicationAttemptId());\n       if (null !\u003d application) {\n         application.nodePartitionUpdated(rmContainer, oldPartition,\n             newPartition);\n       } else {\n         LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n             + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n             + node.getNodeID() + \" applicationAttemptId\u003d\"\n             + rmContainer.getApplicationAttemptId());\n         continue;\n       }\n     }\n     \n     // Unreserve container on this node\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (null !\u003d reservedContainer) {\n-      dropContainerReservation(reservedContainer);\n+      killReservedContainer(reservedContainer);\n     }\n     \n     // Update node labels after we\u0027ve done this\n     node.updateLabels(newLabels);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void updateLabelsOnNode(NodeId nodeId,\n      Set\u003cString\u003e newLabels) {\n    FiCaSchedulerNode node \u003d nodes.get(nodeId);\n    if (null \u003d\u003d node) {\n      return;\n    }\n    \n    // Get new partition, we have only one partition per node\n    String newPartition;\n    if (newLabels.isEmpty()) {\n      newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n    } else {\n      newPartition \u003d newLabels.iterator().next();\n    }\n\n    // old partition as well\n    String oldPartition \u003d node.getPartition();\n\n    // Update resources of these containers\n    for (RMContainer rmContainer : node.getRunningContainers()) {\n      FiCaSchedulerApp application \u003d\n          getApplicationAttempt(rmContainer.getApplicationAttemptId());\n      if (null !\u003d application) {\n        application.nodePartitionUpdated(rmContainer, oldPartition,\n            newPartition);\n      } else {\n        LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n            + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n            + node.getNodeID() + \" applicationAttemptId\u003d\"\n            + rmContainer.getApplicationAttemptId());\n        continue;\n      }\n    }\n    \n    // Unreserve container on this node\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (null !\u003d reservedContainer) {\n      killReservedContainer(reservedContainer);\n    }\n    \n    // Update node labels after we\u0027ve done this\n    node.updateLabels(newLabels);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java",
      "extendedDetails": {}
    },
    "adf260a728df427eb729abe8fb9ad7248991ea54": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"YARN-4502. Fix two AM containers get allocated when AM restart. (Vinod Kumar Vavilapalli via wangda)\"\n\nThis reverts commit 805a9ed85eb34c8125cfb7d26d07cdfac12b3579.\n",
      "commitDate": "18/01/16 12:50 AM",
      "commitName": "adf260a728df427eb729abe8fb9ad7248991ea54",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "17/01/16 7:04 PM",
      "commitNameOld": "805a9ed85eb34c8125cfb7d26d07cdfac12b3579",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 0.24,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,43 @@\n   private synchronized void updateLabelsOnNode(NodeId nodeId,\n       Set\u003cString\u003e newLabels) {\n     FiCaSchedulerNode node \u003d nodes.get(nodeId);\n     if (null \u003d\u003d node) {\n       return;\n     }\n     \n     // Get new partition, we have only one partition per node\n     String newPartition;\n     if (newLabels.isEmpty()) {\n       newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n     } else {\n       newPartition \u003d newLabels.iterator().next();\n     }\n \n     // old partition as well\n     String oldPartition \u003d node.getPartition();\n \n     // Update resources of these containers\n     for (RMContainer rmContainer : node.getRunningContainers()) {\n       FiCaSchedulerApp application \u003d\n           getApplicationAttempt(rmContainer.getApplicationAttemptId());\n       if (null !\u003d application) {\n         application.nodePartitionUpdated(rmContainer, oldPartition,\n             newPartition);\n       } else {\n         LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n             + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n             + node.getNodeID() + \" applicationAttemptId\u003d\"\n             + rmContainer.getApplicationAttemptId());\n         continue;\n       }\n     }\n     \n     // Unreserve container on this node\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (null !\u003d reservedContainer) {\n-      killReservedContainer(reservedContainer);\n+      dropContainerReservation(reservedContainer);\n     }\n     \n     // Update node labels after we\u0027ve done this\n     node.updateLabels(newLabels);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void updateLabelsOnNode(NodeId nodeId,\n      Set\u003cString\u003e newLabels) {\n    FiCaSchedulerNode node \u003d nodes.get(nodeId);\n    if (null \u003d\u003d node) {\n      return;\n    }\n    \n    // Get new partition, we have only one partition per node\n    String newPartition;\n    if (newLabels.isEmpty()) {\n      newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n    } else {\n      newPartition \u003d newLabels.iterator().next();\n    }\n\n    // old partition as well\n    String oldPartition \u003d node.getPartition();\n\n    // Update resources of these containers\n    for (RMContainer rmContainer : node.getRunningContainers()) {\n      FiCaSchedulerApp application \u003d\n          getApplicationAttempt(rmContainer.getApplicationAttemptId());\n      if (null !\u003d application) {\n        application.nodePartitionUpdated(rmContainer, oldPartition,\n            newPartition);\n      } else {\n        LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n            + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n            + node.getNodeID() + \" applicationAttemptId\u003d\"\n            + rmContainer.getApplicationAttemptId());\n        continue;\n      }\n    }\n    \n    // Unreserve container on this node\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (null !\u003d reservedContainer) {\n      dropContainerReservation(reservedContainer);\n    }\n    \n    // Update node labels after we\u0027ve done this\n    node.updateLabels(newLabels);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java",
      "extendedDetails": {}
    },
    "805a9ed85eb34c8125cfb7d26d07cdfac12b3579": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4502. Fix two AM containers get allocated when AM restart. (Vinod Kumar Vavilapalli via wangda)\n",
      "commitDate": "17/01/16 7:04 PM",
      "commitName": "805a9ed85eb34c8125cfb7d26d07cdfac12b3579",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "12/01/16 9:18 PM",
      "commitNameOld": "c0537bcd2c2dcdb4812fcab7badf42e4f55a54d9",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 4.91,
      "commitsBetweenForRepo": 35,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,43 @@\n   private synchronized void updateLabelsOnNode(NodeId nodeId,\n       Set\u003cString\u003e newLabels) {\n     FiCaSchedulerNode node \u003d nodes.get(nodeId);\n     if (null \u003d\u003d node) {\n       return;\n     }\n     \n     // Get new partition, we have only one partition per node\n     String newPartition;\n     if (newLabels.isEmpty()) {\n       newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n     } else {\n       newPartition \u003d newLabels.iterator().next();\n     }\n \n     // old partition as well\n     String oldPartition \u003d node.getPartition();\n \n     // Update resources of these containers\n     for (RMContainer rmContainer : node.getRunningContainers()) {\n       FiCaSchedulerApp application \u003d\n           getApplicationAttempt(rmContainer.getApplicationAttemptId());\n       if (null !\u003d application) {\n         application.nodePartitionUpdated(rmContainer, oldPartition,\n             newPartition);\n       } else {\n         LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n             + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n             + node.getNodeID() + \" applicationAttemptId\u003d\"\n             + rmContainer.getApplicationAttemptId());\n         continue;\n       }\n     }\n     \n     // Unreserve container on this node\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (null !\u003d reservedContainer) {\n-      dropContainerReservation(reservedContainer);\n+      killReservedContainer(reservedContainer);\n     }\n     \n     // Update node labels after we\u0027ve done this\n     node.updateLabels(newLabels);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void updateLabelsOnNode(NodeId nodeId,\n      Set\u003cString\u003e newLabels) {\n    FiCaSchedulerNode node \u003d nodes.get(nodeId);\n    if (null \u003d\u003d node) {\n      return;\n    }\n    \n    // Get new partition, we have only one partition per node\n    String newPartition;\n    if (newLabels.isEmpty()) {\n      newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n    } else {\n      newPartition \u003d newLabels.iterator().next();\n    }\n\n    // old partition as well\n    String oldPartition \u003d node.getPartition();\n\n    // Update resources of these containers\n    for (RMContainer rmContainer : node.getRunningContainers()) {\n      FiCaSchedulerApp application \u003d\n          getApplicationAttempt(rmContainer.getApplicationAttemptId());\n      if (null !\u003d application) {\n        application.nodePartitionUpdated(rmContainer, oldPartition,\n            newPartition);\n      } else {\n        LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n            + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n            + node.getNodeID() + \" applicationAttemptId\u003d\"\n            + rmContainer.getApplicationAttemptId());\n        continue;\n      }\n    }\n    \n    // Unreserve container on this node\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (null !\u003d reservedContainer) {\n      killReservedContainer(reservedContainer);\n    }\n    \n    // Update node labels after we\u0027ve done this\n    node.updateLabels(newLabels);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java",
      "extendedDetails": {}
    },
    "29a582ada0fe195989eca25e5a995895e178f4ea": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4215. RMNodeLabels Manager Need to verify and replace node labels for the only modified Node Label Mappings in the request. (Naganarasimha G R via wangda)\n",
      "commitDate": "06/10/15 11:56 AM",
      "commitName": "29a582ada0fe195989eca25e5a995895e178f4ea",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "23/09/15 11:43 PM",
      "commitNameOld": "a9aafad12b1d2f67e55e09a6fa261d61789c9d7e",
      "commitAuthorOld": "Rohith Sharma K S",
      "daysBetweenCommits": 12.51,
      "commitsBetweenForRepo": 81,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,43 @@\n   private synchronized void updateLabelsOnNode(NodeId nodeId,\n       Set\u003cString\u003e newLabels) {\n     FiCaSchedulerNode node \u003d nodes.get(nodeId);\n     if (null \u003d\u003d node) {\n       return;\n     }\n     \n-    // labels is same, we don\u0027t need do update\n-    if (node.getLabels().size() \u003d\u003d newLabels.size()\n-        \u0026\u0026 node.getLabels().containsAll(newLabels)) {\n-      return;\n-    }\n-    \n     // Get new partition, we have only one partition per node\n     String newPartition;\n     if (newLabels.isEmpty()) {\n       newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n     } else {\n       newPartition \u003d newLabels.iterator().next();\n     }\n \n     // old partition as well\n     String oldPartition \u003d node.getPartition();\n \n     // Update resources of these containers\n     for (RMContainer rmContainer : node.getRunningContainers()) {\n       FiCaSchedulerApp application \u003d\n           getApplicationAttempt(rmContainer.getApplicationAttemptId());\n       if (null !\u003d application) {\n         application.nodePartitionUpdated(rmContainer, oldPartition,\n             newPartition);\n       } else {\n         LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n             + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n             + node.getNodeID() + \" applicationAttemptId\u003d\"\n             + rmContainer.getApplicationAttemptId());\n         continue;\n       }\n     }\n     \n     // Unreserve container on this node\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (null !\u003d reservedContainer) {\n       dropContainerReservation(reservedContainer);\n     }\n     \n     // Update node labels after we\u0027ve done this\n     node.updateLabels(newLabels);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void updateLabelsOnNode(NodeId nodeId,\n      Set\u003cString\u003e newLabels) {\n    FiCaSchedulerNode node \u003d nodes.get(nodeId);\n    if (null \u003d\u003d node) {\n      return;\n    }\n    \n    // Get new partition, we have only one partition per node\n    String newPartition;\n    if (newLabels.isEmpty()) {\n      newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n    } else {\n      newPartition \u003d newLabels.iterator().next();\n    }\n\n    // old partition as well\n    String oldPartition \u003d node.getPartition();\n\n    // Update resources of these containers\n    for (RMContainer rmContainer : node.getRunningContainers()) {\n      FiCaSchedulerApp application \u003d\n          getApplicationAttempt(rmContainer.getApplicationAttemptId());\n      if (null !\u003d application) {\n        application.nodePartitionUpdated(rmContainer, oldPartition,\n            newPartition);\n      } else {\n        LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n            + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n            + node.getNodeID() + \" applicationAttemptId\u003d\"\n            + rmContainer.getApplicationAttemptId());\n        continue;\n      }\n    }\n    \n    // Unreserve container on this node\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (null !\u003d reservedContainer) {\n      dropContainerReservation(reservedContainer);\n    }\n    \n    // Update node labels after we\u0027ve done this\n    node.updateLabels(newLabels);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java",
      "extendedDetails": {}
    },
    "bf669b6d9f8ba165e30b8823218d625a49958925": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4082. Container shouldn\u0027t be killed when node\u0027s label updated. Contributed by Wangda Tan.\n",
      "commitDate": "01/09/15 1:49 AM",
      "commitName": "bf669b6d9f8ba165e30b8823218d625a49958925",
      "commitAuthor": "Varun Vasudev",
      "commitDateOld": "27/08/15 1:25 PM",
      "commitNameOld": "a9c8ea71aa427ff5f25caec98be15bc880e578a7",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 4.52,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,49 @@\n   private synchronized void updateLabelsOnNode(NodeId nodeId,\n       Set\u003cString\u003e newLabels) {\n     FiCaSchedulerNode node \u003d nodes.get(nodeId);\n     if (null \u003d\u003d node) {\n       return;\n     }\n     \n     // labels is same, we don\u0027t need do update\n     if (node.getLabels().size() \u003d\u003d newLabels.size()\n         \u0026\u0026 node.getLabels().containsAll(newLabels)) {\n       return;\n     }\n     \n-    // Kill running containers since label is changed\n+    // Get new partition, we have only one partition per node\n+    String newPartition;\n+    if (newLabels.isEmpty()) {\n+      newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n+    } else {\n+      newPartition \u003d newLabels.iterator().next();\n+    }\n+\n+    // old partition as well\n+    String oldPartition \u003d node.getPartition();\n+\n+    // Update resources of these containers\n     for (RMContainer rmContainer : node.getRunningContainers()) {\n-      ContainerId containerId \u003d rmContainer.getContainerId();\n-      completedContainer(rmContainer, \n-          ContainerStatus.newInstance(containerId,\n-              ContainerState.COMPLETE, \n-              String.format(\n-                  \"Container\u003d%s killed since labels on the node\u003d%s changed\",\n-                  containerId.toString(), nodeId.toString()),\n-              ContainerExitStatus.KILLED_BY_RESOURCEMANAGER),\n-          RMContainerEventType.KILL);\n+      FiCaSchedulerApp application \u003d\n+          getApplicationAttempt(rmContainer.getApplicationAttemptId());\n+      if (null !\u003d application) {\n+        application.nodePartitionUpdated(rmContainer, oldPartition,\n+            newPartition);\n+      } else {\n+        LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n+            + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n+            + node.getNodeID() + \" applicationAttemptId\u003d\"\n+            + rmContainer.getApplicationAttemptId());\n+        continue;\n+      }\n     }\n     \n     // Unreserve container on this node\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (null !\u003d reservedContainer) {\n       dropContainerReservation(reservedContainer);\n     }\n     \n     // Update node labels after we\u0027ve done this\n     node.updateLabels(newLabels);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void updateLabelsOnNode(NodeId nodeId,\n      Set\u003cString\u003e newLabels) {\n    FiCaSchedulerNode node \u003d nodes.get(nodeId);\n    if (null \u003d\u003d node) {\n      return;\n    }\n    \n    // labels is same, we don\u0027t need do update\n    if (node.getLabels().size() \u003d\u003d newLabels.size()\n        \u0026\u0026 node.getLabels().containsAll(newLabels)) {\n      return;\n    }\n    \n    // Get new partition, we have only one partition per node\n    String newPartition;\n    if (newLabels.isEmpty()) {\n      newPartition \u003d RMNodeLabelsManager.NO_LABEL;\n    } else {\n      newPartition \u003d newLabels.iterator().next();\n    }\n\n    // old partition as well\n    String oldPartition \u003d node.getPartition();\n\n    // Update resources of these containers\n    for (RMContainer rmContainer : node.getRunningContainers()) {\n      FiCaSchedulerApp application \u003d\n          getApplicationAttempt(rmContainer.getApplicationAttemptId());\n      if (null !\u003d application) {\n        application.nodePartitionUpdated(rmContainer, oldPartition,\n            newPartition);\n      } else {\n        LOG.warn(\"There\u0027s something wrong, some RMContainers running on\"\n            + \" a node, but we cannot find SchedulerApplicationAttempt for it. Node\u003d\"\n            + node.getNodeID() + \" applicationAttemptId\u003d\"\n            + rmContainer.getApplicationAttemptId());\n        continue;\n      }\n    }\n    \n    // Unreserve container on this node\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (null !\u003d reservedContainer) {\n      dropContainerReservation(reservedContainer);\n    }\n    \n    // Update node labels after we\u0027ve done this\n    node.updateLabels(newLabels);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java",
      "extendedDetails": {}
    },
    "fdf042dfffa4d2474e3cac86cfb8fe9ee4648beb": {
      "type": "Yintroduced",
      "commitMessage": "YARN-2920. Changed CapacityScheduler to kill containers on nodes where node labels are changed. Contributed by  Wangda Tan\n",
      "commitDate": "22/12/14 4:51 PM",
      "commitName": "fdf042dfffa4d2474e3cac86cfb8fe9ee4648beb",
      "commitAuthor": "Jian He",
      "diff": "@@ -0,0 +1,35 @@\n+  private synchronized void updateLabelsOnNode(NodeId nodeId,\n+      Set\u003cString\u003e newLabels) {\n+    FiCaSchedulerNode node \u003d nodes.get(nodeId);\n+    if (null \u003d\u003d node) {\n+      return;\n+    }\n+    \n+    // labels is same, we don\u0027t need do update\n+    if (node.getLabels().size() \u003d\u003d newLabels.size()\n+        \u0026\u0026 node.getLabels().containsAll(newLabels)) {\n+      return;\n+    }\n+    \n+    // Kill running containers since label is changed\n+    for (RMContainer rmContainer : node.getRunningContainers()) {\n+      ContainerId containerId \u003d rmContainer.getContainerId();\n+      completedContainer(rmContainer, \n+          ContainerStatus.newInstance(containerId,\n+              ContainerState.COMPLETE, \n+              String.format(\n+                  \"Container\u003d%s killed since labels on the node\u003d%s changed\",\n+                  containerId.toString(), nodeId.toString()),\n+              ContainerExitStatus.KILLED_BY_RESOURCEMANAGER),\n+          RMContainerEventType.KILL);\n+    }\n+    \n+    // Unreserve container on this node\n+    RMContainer reservedContainer \u003d node.getReservedContainer();\n+    if (null !\u003d reservedContainer) {\n+      dropContainerReservation(reservedContainer);\n+    }\n+    \n+    // Update node labels after we\u0027ve done this\n+    node.updateLabels(newLabels);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void updateLabelsOnNode(NodeId nodeId,\n      Set\u003cString\u003e newLabels) {\n    FiCaSchedulerNode node \u003d nodes.get(nodeId);\n    if (null \u003d\u003d node) {\n      return;\n    }\n    \n    // labels is same, we don\u0027t need do update\n    if (node.getLabels().size() \u003d\u003d newLabels.size()\n        \u0026\u0026 node.getLabels().containsAll(newLabels)) {\n      return;\n    }\n    \n    // Kill running containers since label is changed\n    for (RMContainer rmContainer : node.getRunningContainers()) {\n      ContainerId containerId \u003d rmContainer.getContainerId();\n      completedContainer(rmContainer, \n          ContainerStatus.newInstance(containerId,\n              ContainerState.COMPLETE, \n              String.format(\n                  \"Container\u003d%s killed since labels on the node\u003d%s changed\",\n                  containerId.toString(), nodeId.toString()),\n              ContainerExitStatus.KILLED_BY_RESOURCEMANAGER),\n          RMContainerEventType.KILL);\n    }\n    \n    // Unreserve container on this node\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (null !\u003d reservedContainer) {\n      dropContainerReservation(reservedContainer);\n    }\n    \n    // Update node labels after we\u0027ve done this\n    node.updateLabels(newLabels);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler.java"
    }
  }
}