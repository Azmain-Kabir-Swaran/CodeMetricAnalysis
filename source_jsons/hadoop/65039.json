{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "StagingCommitter.java",
  "functionName": "listPendingUploads",
  "functionId": "listPendingUploads___context-JobContext__suppressExceptions-boolean",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/staging/StagingCommitter.java",
  "functionStartLine": 496,
  "functionEndLine": 517,
  "numCommitsSeen": 9,
  "timeTaken": 2468,
  "changeHistory": [
    "6574f27fa348542411bff888b184cd7ce34e5d9e",
    "5a0babf76550f63dad4c17173c4da2bf335c6532",
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c"
  ],
  "changeHistoryShort": {
    "6574f27fa348542411bff888b184cd7ce34e5d9e": "Ymultichange(Yreturntypechange,Ybodychange)",
    "5a0babf76550f63dad4c17173c4da2bf335c6532": "Ybodychange",
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6574f27fa348542411bff888b184cd7ce34e5d9e": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HADOOP-16570. S3A committers encounter scale issues.\n\nContributed by Steve Loughran.\n\nThis addresses two scale issues which has surfaced in large scale benchmarks\nof the S3A Committers.\n\n* Thread pools are not cleaned up.\n  This now happens, with tests.\n\n* OOM on job commit for jobs with many thousands of tasks,\n  each generating tens of (very large) files.\n\nInstead of loading all pending commits into memory as a single list, the list\nof files to load is the sole list which is passed around; .pendingset files are\nloaded and processed in isolation -and reloaded if necessary for any\nabort/rollback operation.\n\nThe parallel commit/abort/revert operations now work at the .pendingset level,\nrather than that of individual pending commit files. The existing parallelized\nTasks API is still used to commit those files, but with a null thread pool, so\nas to serialize the operations.\n\nChange-Id: I5c8240cd31800eaa83d112358770ca0eb2bca797\n",
      "commitDate": "04/10/19 10:54 AM",
      "commitName": "6574f27fa348542411bff888b184cd7ce34e5d9e",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HADOOP-16570. S3A committers encounter scale issues.\n\nContributed by Steve Loughran.\n\nThis addresses two scale issues which has surfaced in large scale benchmarks\nof the S3A Committers.\n\n* Thread pools are not cleaned up.\n  This now happens, with tests.\n\n* OOM on job commit for jobs with many thousands of tasks,\n  each generating tens of (very large) files.\n\nInstead of loading all pending commits into memory as a single list, the list\nof files to load is the sole list which is passed around; .pendingset files are\nloaded and processed in isolation -and reloaded if necessary for any\nabort/rollback operation.\n\nThe parallel commit/abort/revert operations now work at the .pendingset level,\nrather than that of individual pending commit files. The existing parallelized\nTasks API is still used to commit those files, but with a null thread pool, so\nas to serialize the operations.\n\nChange-Id: I5c8240cd31800eaa83d112358770ca0eb2bca797\n",
          "commitDate": "04/10/19 10:54 AM",
          "commitName": "6574f27fa348542411bff888b184cd7ce34e5d9e",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "04/10/19 6:12 AM",
          "commitNameOld": "f44abc3e11676579bdea94fce045d081ae38e6c3",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 0.2,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,22 @@\n-  protected List\u003cSinglePendingCommit\u003e listPendingUploads(\n+  protected ActiveCommit listPendingUploads(\n       JobContext context, boolean suppressExceptions) throws IOException {\n-    try {\n-      Path wrappedJobAttemptPath \u003d wrappedCommitter.getJobAttemptPath(context);\n+    try (DurationInfo ignored \u003d new DurationInfo(LOG,\n+        \"Listing pending uploads\")) {\n+      Path wrappedJobAttemptPath \u003d getJobAttemptPath(context);\n       final FileSystem attemptFS \u003d wrappedJobAttemptPath.getFileSystem(\n           context.getConfiguration());\n-      return loadPendingsetFiles(context, suppressExceptions, attemptFS,\n+      return ActiveCommit.fromStatusList(attemptFS,\n           listAndFilter(attemptFS,\n               wrappedJobAttemptPath, false,\n               HIDDEN_FILE_FILTER));\n     } catch (FileNotFoundException e) {\n       // this can mean the job was aborted early on, so don\u0027t confuse people\n       // with long stack traces that aren\u0027t the underlying problem.\n       maybeIgnore(suppressExceptions, \"Pending upload directory not found\", e);\n     } catch (IOException e) {\n       // unable to work with endpoint, if suppressing errors decide our actions\n       maybeIgnore(suppressExceptions, \"Listing pending uploads\", e);\n     }\n     // reached iff an IOE was caught and swallowed\n-    return new ArrayList\u003c\u003e(0);\n+    return ActiveCommit.empty();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected ActiveCommit listPendingUploads(\n      JobContext context, boolean suppressExceptions) throws IOException {\n    try (DurationInfo ignored \u003d new DurationInfo(LOG,\n        \"Listing pending uploads\")) {\n      Path wrappedJobAttemptPath \u003d getJobAttemptPath(context);\n      final FileSystem attemptFS \u003d wrappedJobAttemptPath.getFileSystem(\n          context.getConfiguration());\n      return ActiveCommit.fromStatusList(attemptFS,\n          listAndFilter(attemptFS,\n              wrappedJobAttemptPath, false,\n              HIDDEN_FILE_FILTER));\n    } catch (FileNotFoundException e) {\n      // this can mean the job was aborted early on, so don\u0027t confuse people\n      // with long stack traces that aren\u0027t the underlying problem.\n      maybeIgnore(suppressExceptions, \"Pending upload directory not found\", e);\n    } catch (IOException e) {\n      // unable to work with endpoint, if suppressing errors decide our actions\n      maybeIgnore(suppressExceptions, \"Listing pending uploads\", e);\n    }\n    // reached iff an IOE was caught and swallowed\n    return ActiveCommit.empty();\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/staging/StagingCommitter.java",
          "extendedDetails": {
            "oldValue": "List\u003cSinglePendingCommit\u003e",
            "newValue": "ActiveCommit"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-16570. S3A committers encounter scale issues.\n\nContributed by Steve Loughran.\n\nThis addresses two scale issues which has surfaced in large scale benchmarks\nof the S3A Committers.\n\n* Thread pools are not cleaned up.\n  This now happens, with tests.\n\n* OOM on job commit for jobs with many thousands of tasks,\n  each generating tens of (very large) files.\n\nInstead of loading all pending commits into memory as a single list, the list\nof files to load is the sole list which is passed around; .pendingset files are\nloaded and processed in isolation -and reloaded if necessary for any\nabort/rollback operation.\n\nThe parallel commit/abort/revert operations now work at the .pendingset level,\nrather than that of individual pending commit files. The existing parallelized\nTasks API is still used to commit those files, but with a null thread pool, so\nas to serialize the operations.\n\nChange-Id: I5c8240cd31800eaa83d112358770ca0eb2bca797\n",
          "commitDate": "04/10/19 10:54 AM",
          "commitName": "6574f27fa348542411bff888b184cd7ce34e5d9e",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "04/10/19 6:12 AM",
          "commitNameOld": "f44abc3e11676579bdea94fce045d081ae38e6c3",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 0.2,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,22 @@\n-  protected List\u003cSinglePendingCommit\u003e listPendingUploads(\n+  protected ActiveCommit listPendingUploads(\n       JobContext context, boolean suppressExceptions) throws IOException {\n-    try {\n-      Path wrappedJobAttemptPath \u003d wrappedCommitter.getJobAttemptPath(context);\n+    try (DurationInfo ignored \u003d new DurationInfo(LOG,\n+        \"Listing pending uploads\")) {\n+      Path wrappedJobAttemptPath \u003d getJobAttemptPath(context);\n       final FileSystem attemptFS \u003d wrappedJobAttemptPath.getFileSystem(\n           context.getConfiguration());\n-      return loadPendingsetFiles(context, suppressExceptions, attemptFS,\n+      return ActiveCommit.fromStatusList(attemptFS,\n           listAndFilter(attemptFS,\n               wrappedJobAttemptPath, false,\n               HIDDEN_FILE_FILTER));\n     } catch (FileNotFoundException e) {\n       // this can mean the job was aborted early on, so don\u0027t confuse people\n       // with long stack traces that aren\u0027t the underlying problem.\n       maybeIgnore(suppressExceptions, \"Pending upload directory not found\", e);\n     } catch (IOException e) {\n       // unable to work with endpoint, if suppressing errors decide our actions\n       maybeIgnore(suppressExceptions, \"Listing pending uploads\", e);\n     }\n     // reached iff an IOE was caught and swallowed\n-    return new ArrayList\u003c\u003e(0);\n+    return ActiveCommit.empty();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected ActiveCommit listPendingUploads(\n      JobContext context, boolean suppressExceptions) throws IOException {\n    try (DurationInfo ignored \u003d new DurationInfo(LOG,\n        \"Listing pending uploads\")) {\n      Path wrappedJobAttemptPath \u003d getJobAttemptPath(context);\n      final FileSystem attemptFS \u003d wrappedJobAttemptPath.getFileSystem(\n          context.getConfiguration());\n      return ActiveCommit.fromStatusList(attemptFS,\n          listAndFilter(attemptFS,\n              wrappedJobAttemptPath, false,\n              HIDDEN_FILE_FILTER));\n    } catch (FileNotFoundException e) {\n      // this can mean the job was aborted early on, so don\u0027t confuse people\n      // with long stack traces that aren\u0027t the underlying problem.\n      maybeIgnore(suppressExceptions, \"Pending upload directory not found\", e);\n    } catch (IOException e) {\n      // unable to work with endpoint, if suppressing errors decide our actions\n      maybeIgnore(suppressExceptions, \"Listing pending uploads\", e);\n    }\n    // reached iff an IOE was caught and swallowed\n    return ActiveCommit.empty();\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/staging/StagingCommitter.java",
          "extendedDetails": {}
        }
      ]
    },
    "5a0babf76550f63dad4c17173c4da2bf335c6532": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15107. Stabilize/tune S3A committers; review correctness \u0026 docs.\nContributed by Steve Loughran.\n",
      "commitDate": "30/08/18 6:49 AM",
      "commitName": "5a0babf76550f63dad4c17173c4da2bf335c6532",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "27/11/17 8:31 AM",
      "commitNameOld": "3cd75845da1aced3d88e0ce68c68e8d95f48fb79",
      "commitAuthorOld": "Rohith Sharma K S",
      "daysBetweenCommits": 275.89,
      "commitsBetweenForRepo": 2513,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,21 @@\n   protected List\u003cSinglePendingCommit\u003e listPendingUploads(\n       JobContext context, boolean suppressExceptions) throws IOException {\n     try {\n       Path wrappedJobAttemptPath \u003d wrappedCommitter.getJobAttemptPath(context);\n       final FileSystem attemptFS \u003d wrappedJobAttemptPath.getFileSystem(\n           context.getConfiguration());\n       return loadPendingsetFiles(context, suppressExceptions, attemptFS,\n           listAndFilter(attemptFS,\n               wrappedJobAttemptPath, false,\n               HIDDEN_FILE_FILTER));\n+    } catch (FileNotFoundException e) {\n+      // this can mean the job was aborted early on, so don\u0027t confuse people\n+      // with long stack traces that aren\u0027t the underlying problem.\n+      maybeIgnore(suppressExceptions, \"Pending upload directory not found\", e);\n     } catch (IOException e) {\n       // unable to work with endpoint, if suppressing errors decide our actions\n       maybeIgnore(suppressExceptions, \"Listing pending uploads\", e);\n     }\n     // reached iff an IOE was caught and swallowed\n     return new ArrayList\u003c\u003e(0);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected List\u003cSinglePendingCommit\u003e listPendingUploads(\n      JobContext context, boolean suppressExceptions) throws IOException {\n    try {\n      Path wrappedJobAttemptPath \u003d wrappedCommitter.getJobAttemptPath(context);\n      final FileSystem attemptFS \u003d wrappedJobAttemptPath.getFileSystem(\n          context.getConfiguration());\n      return loadPendingsetFiles(context, suppressExceptions, attemptFS,\n          listAndFilter(attemptFS,\n              wrappedJobAttemptPath, false,\n              HIDDEN_FILE_FILTER));\n    } catch (FileNotFoundException e) {\n      // this can mean the job was aborted early on, so don\u0027t confuse people\n      // with long stack traces that aren\u0027t the underlying problem.\n      maybeIgnore(suppressExceptions, \"Pending upload directory not found\", e);\n    } catch (IOException e) {\n      // unable to work with endpoint, if suppressing errors decide our actions\n      maybeIgnore(suppressExceptions, \"Listing pending uploads\", e);\n    }\n    // reached iff an IOE was caught and swallowed\n    return new ArrayList\u003c\u003e(0);\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/staging/StagingCommitter.java",
      "extendedDetails": {}
    },
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13786 Add S3A committer for zero-rename commits to S3 endpoints.\nContributed by Steve Loughran and Ryan Blue.\n",
      "commitDate": "22/11/17 7:28 AM",
      "commitName": "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,17 @@\n+  protected List\u003cSinglePendingCommit\u003e listPendingUploads(\n+      JobContext context, boolean suppressExceptions) throws IOException {\n+    try {\n+      Path wrappedJobAttemptPath \u003d wrappedCommitter.getJobAttemptPath(context);\n+      final FileSystem attemptFS \u003d wrappedJobAttemptPath.getFileSystem(\n+          context.getConfiguration());\n+      return loadPendingsetFiles(context, suppressExceptions, attemptFS,\n+          listAndFilter(attemptFS,\n+              wrappedJobAttemptPath, false,\n+              HIDDEN_FILE_FILTER));\n+    } catch (IOException e) {\n+      // unable to work with endpoint, if suppressing errors decide our actions\n+      maybeIgnore(suppressExceptions, \"Listing pending uploads\", e);\n+    }\n+    // reached iff an IOE was caught and swallowed\n+    return new ArrayList\u003c\u003e(0);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected List\u003cSinglePendingCommit\u003e listPendingUploads(\n      JobContext context, boolean suppressExceptions) throws IOException {\n    try {\n      Path wrappedJobAttemptPath \u003d wrappedCommitter.getJobAttemptPath(context);\n      final FileSystem attemptFS \u003d wrappedJobAttemptPath.getFileSystem(\n          context.getConfiguration());\n      return loadPendingsetFiles(context, suppressExceptions, attemptFS,\n          listAndFilter(attemptFS,\n              wrappedJobAttemptPath, false,\n              HIDDEN_FILE_FILTER));\n    } catch (IOException e) {\n      // unable to work with endpoint, if suppressing errors decide our actions\n      maybeIgnore(suppressExceptions, \"Listing pending uploads\", e);\n    }\n    // reached iff an IOE was caught and swallowed\n    return new ArrayList\u003c\u003e(0);\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/staging/StagingCommitter.java"
    }
  }
}