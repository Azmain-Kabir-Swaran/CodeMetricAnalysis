{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSNamesystem.java",
  "functionName": "truncate",
  "functionId": "truncate___src-String__newLength-long__clientName-String__clientMachine-String__mtime-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
  "functionStartLine": 2255,
  "functionEndLine": 2295,
  "numCommitsSeen": 873,
  "timeTaken": 26182,
  "changeHistory": [
    "1824aee9da4056de0fb638906b2172e486bbebe7",
    "4b95c242eca540455a4d5d0899aaf73b6064b5ea",
    "84a1321f6aa0af6895564a7c47f8f264656f0294",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893",
    "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
    "71de367c5e80ea76d1e8d21f0216cd6b879dcee5",
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2"
  ],
  "changeHistoryShort": {
    "1824aee9da4056de0fb638906b2172e486bbebe7": "Ybodychange",
    "4b95c242eca540455a4d5d0899aaf73b6064b5ea": "Ybodychange",
    "84a1321f6aa0af6895564a7c47f8f264656f0294": "Ybodychange",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": "Ybodychange",
    "d3797f9f3cf502b7bfee3b64c641807b276c6faf": "Ybodychange",
    "71de367c5e80ea76d1e8d21f0216cd6b879dcee5": "Ybodychange",
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2": "Yintroduced"
  },
  "changeHistoryDetails": {
    "1824aee9da4056de0fb638906b2172e486bbebe7": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-15217 Add more information to longest write/read lock held log\n\n",
      "commitDate": "18/04/20 1:52 PM",
      "commitName": "1824aee9da4056de0fb638906b2172e486bbebe7",
      "commitAuthor": "Toshihiro Suzuki",
      "commitDateOld": "25/03/20 10:28 AM",
      "commitNameOld": "a700803a18fb957d2799001a2ce1dcb70f75c080",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 24.14,
      "commitsBetweenForRepo": 78,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,41 @@\n   boolean truncate(String src, long newLength, String clientName,\n       String clientMachine, long mtime) throws IOException,\n       UnresolvedLinkException {\n \n     final String operationName \u003d \"truncate\";\n     requireEffectiveLayoutVersionForFeature(Feature.TRUNCATE);\n-    final FSDirTruncateOp.TruncateResult r;\n+    FSDirTruncateOp.TruncateResult r \u003d null;\n     try {\n       NameNode.stateChangeLog.debug(\n           \"DIR* NameSystem.truncate: src\u003d{} newLength\u003d{}\", src, newLength);\n       if (newLength \u003c 0) {\n         throw new HadoopIllegalArgumentException(\n             \"Cannot truncate to a negative file size: \" + newLength + \".\");\n       }\n       checkOperation(OperationCategory.WRITE);\n       final FSPermissionChecker pc \u003d getPermissionChecker();\n       FSPermissionChecker.setOperationType(operationName);\n       writeLock();\n       BlocksMapUpdateInfo toRemoveBlocks \u003d new BlocksMapUpdateInfo();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         checkNameNodeSafeMode(\"Cannot truncate for \" + src);\n         r \u003d FSDirTruncateOp.truncate(this, src, newLength, clientName,\n             clientMachine, mtime, toRemoveBlocks, pc);\n       } finally {\n-        writeUnlock(operationName);\n+        FileStatus status \u003d r !\u003d null ? r.getFileStatus() : null;\n+        writeUnlock(operationName,\n+            getLockReportInfoSupplier(src, null, status));\n       }\n       getEditLog().logSync();\n       if (!toRemoveBlocks.getToDeleteList().isEmpty()) {\n         removeBlocks(toRemoveBlocks);\n         toRemoveBlocks.clear();\n       }\n       logAuditEvent(true, operationName, src, null, r.getFileStatus());\n     } catch (AccessControlException e) {\n       logAuditEvent(false, operationName, src);\n       throw e;\n     }\n     return r.getResult();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean truncate(String src, long newLength, String clientName,\n      String clientMachine, long mtime) throws IOException,\n      UnresolvedLinkException {\n\n    final String operationName \u003d \"truncate\";\n    requireEffectiveLayoutVersionForFeature(Feature.TRUNCATE);\n    FSDirTruncateOp.TruncateResult r \u003d null;\n    try {\n      NameNode.stateChangeLog.debug(\n          \"DIR* NameSystem.truncate: src\u003d{} newLength\u003d{}\", src, newLength);\n      if (newLength \u003c 0) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a negative file size: \" + newLength + \".\");\n      }\n      checkOperation(OperationCategory.WRITE);\n      final FSPermissionChecker pc \u003d getPermissionChecker();\n      FSPermissionChecker.setOperationType(operationName);\n      writeLock();\n      BlocksMapUpdateInfo toRemoveBlocks \u003d new BlocksMapUpdateInfo();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        checkNameNodeSafeMode(\"Cannot truncate for \" + src);\n        r \u003d FSDirTruncateOp.truncate(this, src, newLength, clientName,\n            clientMachine, mtime, toRemoveBlocks, pc);\n      } finally {\n        FileStatus status \u003d r !\u003d null ? r.getFileStatus() : null;\n        writeUnlock(operationName,\n            getLockReportInfoSupplier(src, null, status));\n      }\n      getEditLog().logSync();\n      if (!toRemoveBlocks.getToDeleteList().isEmpty()) {\n        removeBlocks(toRemoveBlocks);\n        toRemoveBlocks.clear();\n      }\n      logAuditEvent(true, operationName, src, null, r.getFileStatus());\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, src);\n      throw e;\n    }\n    return r.getResult();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "4b95c242eca540455a4d5d0899aaf73b6064b5ea": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14743. Enhance INodeAttributeProvider/ AccessControlEnforcer Interface in HDFS to support Authorization of mkdir, rm, rmdir, copy, move etc... (#1829)\n\nReviewed-by: Xiaoyu Yao \u003cxyao@apache.org\u003e",
      "commitDate": "13/03/20 11:29 AM",
      "commitName": "4b95c242eca540455a4d5d0899aaf73b6064b5ea",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "27/02/20 8:49 AM",
      "commitNameOld": "cd2c6b1aac470991b9b90339ce2721ba179e7c48",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 15.07,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,39 @@\n   boolean truncate(String src, long newLength, String clientName,\n       String clientMachine, long mtime) throws IOException,\n       UnresolvedLinkException {\n \n     final String operationName \u003d \"truncate\";\n     requireEffectiveLayoutVersionForFeature(Feature.TRUNCATE);\n     final FSDirTruncateOp.TruncateResult r;\n     try {\n       NameNode.stateChangeLog.debug(\n           \"DIR* NameSystem.truncate: src\u003d{} newLength\u003d{}\", src, newLength);\n       if (newLength \u003c 0) {\n         throw new HadoopIllegalArgumentException(\n             \"Cannot truncate to a negative file size: \" + newLength + \".\");\n       }\n       checkOperation(OperationCategory.WRITE);\n       final FSPermissionChecker pc \u003d getPermissionChecker();\n+      FSPermissionChecker.setOperationType(operationName);\n       writeLock();\n       BlocksMapUpdateInfo toRemoveBlocks \u003d new BlocksMapUpdateInfo();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         checkNameNodeSafeMode(\"Cannot truncate for \" + src);\n         r \u003d FSDirTruncateOp.truncate(this, src, newLength, clientName,\n             clientMachine, mtime, toRemoveBlocks, pc);\n       } finally {\n         writeUnlock(operationName);\n       }\n       getEditLog().logSync();\n       if (!toRemoveBlocks.getToDeleteList().isEmpty()) {\n         removeBlocks(toRemoveBlocks);\n         toRemoveBlocks.clear();\n       }\n       logAuditEvent(true, operationName, src, null, r.getFileStatus());\n     } catch (AccessControlException e) {\n       logAuditEvent(false, operationName, src);\n       throw e;\n     }\n     return r.getResult();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean truncate(String src, long newLength, String clientName,\n      String clientMachine, long mtime) throws IOException,\n      UnresolvedLinkException {\n\n    final String operationName \u003d \"truncate\";\n    requireEffectiveLayoutVersionForFeature(Feature.TRUNCATE);\n    final FSDirTruncateOp.TruncateResult r;\n    try {\n      NameNode.stateChangeLog.debug(\n          \"DIR* NameSystem.truncate: src\u003d{} newLength\u003d{}\", src, newLength);\n      if (newLength \u003c 0) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a negative file size: \" + newLength + \".\");\n      }\n      checkOperation(OperationCategory.WRITE);\n      final FSPermissionChecker pc \u003d getPermissionChecker();\n      FSPermissionChecker.setOperationType(operationName);\n      writeLock();\n      BlocksMapUpdateInfo toRemoveBlocks \u003d new BlocksMapUpdateInfo();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        checkNameNodeSafeMode(\"Cannot truncate for \" + src);\n        r \u003d FSDirTruncateOp.truncate(this, src, newLength, clientName,\n            clientMachine, mtime, toRemoveBlocks, pc);\n      } finally {\n        writeUnlock(operationName);\n      }\n      getEditLog().logSync();\n      if (!toRemoveBlocks.getToDeleteList().isEmpty()) {\n        removeBlocks(toRemoveBlocks);\n        toRemoveBlocks.clear();\n      }\n      logAuditEvent(true, operationName, src, null, r.getFileStatus());\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, src);\n      throw e;\n    }\n    return r.getResult();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "84a1321f6aa0af6895564a7c47f8f264656f0294": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13136. Avoid taking FSN lock while doing group member lookup for FSD permission check. Contributed by Xiaoyu Yao.\n",
      "commitDate": "22/02/18 11:32 AM",
      "commitName": "84a1321f6aa0af6895564a7c47f8f264656f0294",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "15/02/18 1:32 PM",
      "commitNameOld": "47473952e56b0380147d42f4110ad03c2276c961",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 6.92,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,38 @@\n   boolean truncate(String src, long newLength, String clientName,\n       String clientMachine, long mtime) throws IOException,\n       UnresolvedLinkException {\n \n     final String operationName \u003d \"truncate\";\n     requireEffectiveLayoutVersionForFeature(Feature.TRUNCATE);\n     final FSDirTruncateOp.TruncateResult r;\n     try {\n       NameNode.stateChangeLog.debug(\n           \"DIR* NameSystem.truncate: src\u003d{} newLength\u003d{}\", src, newLength);\n       if (newLength \u003c 0) {\n         throw new HadoopIllegalArgumentException(\n             \"Cannot truncate to a negative file size: \" + newLength + \".\");\n       }\n-      final FSPermissionChecker pc \u003d getPermissionChecker();\n       checkOperation(OperationCategory.WRITE);\n+      final FSPermissionChecker pc \u003d getPermissionChecker();\n       writeLock();\n       BlocksMapUpdateInfo toRemoveBlocks \u003d new BlocksMapUpdateInfo();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         checkNameNodeSafeMode(\"Cannot truncate for \" + src);\n         r \u003d FSDirTruncateOp.truncate(this, src, newLength, clientName,\n             clientMachine, mtime, toRemoveBlocks, pc);\n       } finally {\n         writeUnlock(operationName);\n       }\n       getEditLog().logSync();\n       if (!toRemoveBlocks.getToDeleteList().isEmpty()) {\n         removeBlocks(toRemoveBlocks);\n         toRemoveBlocks.clear();\n       }\n       logAuditEvent(true, operationName, src, null, r.getFileStatus());\n     } catch (AccessControlException e) {\n       logAuditEvent(false, operationName, src);\n       throw e;\n     }\n     return r.getResult();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean truncate(String src, long newLength, String clientName,\n      String clientMachine, long mtime) throws IOException,\n      UnresolvedLinkException {\n\n    final String operationName \u003d \"truncate\";\n    requireEffectiveLayoutVersionForFeature(Feature.TRUNCATE);\n    final FSDirTruncateOp.TruncateResult r;\n    try {\n      NameNode.stateChangeLog.debug(\n          \"DIR* NameSystem.truncate: src\u003d{} newLength\u003d{}\", src, newLength);\n      if (newLength \u003c 0) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a negative file size: \" + newLength + \".\");\n      }\n      checkOperation(OperationCategory.WRITE);\n      final FSPermissionChecker pc \u003d getPermissionChecker();\n      writeLock();\n      BlocksMapUpdateInfo toRemoveBlocks \u003d new BlocksMapUpdateInfo();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        checkNameNodeSafeMode(\"Cannot truncate for \" + src);\n        r \u003d FSDirTruncateOp.truncate(this, src, newLength, clientName,\n            clientMachine, mtime, toRemoveBlocks, pc);\n      } finally {\n        writeUnlock(operationName);\n      }\n      getEditLog().logSync();\n      if (!toRemoveBlocks.getToDeleteList().isEmpty()) {\n        removeBlocks(toRemoveBlocks);\n        toRemoveBlocks.clear();\n      }\n      logAuditEvent(true, operationName, src, null, r.getFileStatus());\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, src);\n      throw e;\n    }\n    return r.getResult();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10872. Add MutableRate metrics for FSNamesystemLock operations. Contributed by Erik Krogen.\n",
      "commitDate": "14/11/16 11:05 AM",
      "commitName": "ff0b99eafeda035ebe0dc82cfe689808047a8893",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "08/11/16 6:17 PM",
      "commitNameOld": "ed0bebabaaf27cd730f7f8eb002d92c9c7db327d",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 5.7,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,38 @@\n   boolean truncate(String src, long newLength, String clientName,\n       String clientMachine, long mtime) throws IOException,\n       UnresolvedLinkException {\n \n+    final String operationName \u003d \"truncate\";\n     requireEffectiveLayoutVersionForFeature(Feature.TRUNCATE);\n     final FSDirTruncateOp.TruncateResult r;\n     try {\n       NameNode.stateChangeLog.debug(\n           \"DIR* NameSystem.truncate: src\u003d{} newLength\u003d{}\", src, newLength);\n       if (newLength \u003c 0) {\n         throw new HadoopIllegalArgumentException(\n             \"Cannot truncate to a negative file size: \" + newLength + \".\");\n       }\n       final FSPermissionChecker pc \u003d getPermissionChecker();\n       checkOperation(OperationCategory.WRITE);\n       writeLock();\n       BlocksMapUpdateInfo toRemoveBlocks \u003d new BlocksMapUpdateInfo();\n       try {\n         checkOperation(OperationCategory.WRITE);\n         checkNameNodeSafeMode(\"Cannot truncate for \" + src);\n         r \u003d FSDirTruncateOp.truncate(this, src, newLength, clientName,\n             clientMachine, mtime, toRemoveBlocks, pc);\n       } finally {\n-        writeUnlock();\n+        writeUnlock(operationName);\n       }\n       getEditLog().logSync();\n       if (!toRemoveBlocks.getToDeleteList().isEmpty()) {\n         removeBlocks(toRemoveBlocks);\n         toRemoveBlocks.clear();\n       }\n-      logAuditEvent(true, \"truncate\", src, null, r.getFileStatus());\n+      logAuditEvent(true, operationName, src, null, r.getFileStatus());\n     } catch (AccessControlException e) {\n-      logAuditEvent(false, \"truncate\", src);\n+      logAuditEvent(false, operationName, src);\n       throw e;\n     }\n     return r.getResult();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean truncate(String src, long newLength, String clientName,\n      String clientMachine, long mtime) throws IOException,\n      UnresolvedLinkException {\n\n    final String operationName \u003d \"truncate\";\n    requireEffectiveLayoutVersionForFeature(Feature.TRUNCATE);\n    final FSDirTruncateOp.TruncateResult r;\n    try {\n      NameNode.stateChangeLog.debug(\n          \"DIR* NameSystem.truncate: src\u003d{} newLength\u003d{}\", src, newLength);\n      if (newLength \u003c 0) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a negative file size: \" + newLength + \".\");\n      }\n      final FSPermissionChecker pc \u003d getPermissionChecker();\n      checkOperation(OperationCategory.WRITE);\n      writeLock();\n      BlocksMapUpdateInfo toRemoveBlocks \u003d new BlocksMapUpdateInfo();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        checkNameNodeSafeMode(\"Cannot truncate for \" + src);\n        r \u003d FSDirTruncateOp.truncate(this, src, newLength, clientName,\n            clientMachine, mtime, toRemoveBlocks, pc);\n      } finally {\n        writeUnlock(operationName);\n      }\n      getEditLog().logSync();\n      if (!toRemoveBlocks.getToDeleteList().isEmpty()) {\n        removeBlocks(toRemoveBlocks);\n        toRemoveBlocks.clear();\n      }\n      logAuditEvent(true, operationName, src, null, r.getFileStatus());\n    } catch (AccessControlException e) {\n      logAuditEvent(false, operationName, src);\n      throw e;\n    }\n    return r.getResult();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "d3797f9f3cf502b7bfee3b64c641807b276c6faf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
      "commitDate": "29/06/15 4:45 PM",
      "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "26/06/15 11:30 AM",
      "commitNameOld": "60b858bfa65e0feb665e1a84784a3d45e9091c66",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 3.22,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,37 @@\n-  boolean truncate(String src, long newLength,\n-                   String clientName, String clientMachine,\n-                   long mtime)\n-      throws IOException, UnresolvedLinkException {\n+  boolean truncate(String src, long newLength, String clientName,\n+      String clientMachine, long mtime) throws IOException,\n+      UnresolvedLinkException {\n+\n     requireEffectiveLayoutVersionForFeature(Feature.TRUNCATE);\n-    boolean ret;\n+    final FSDirTruncateOp.TruncateResult r;\n     try {\n-      ret \u003d truncateInt(src, newLength, clientName, clientMachine, mtime);\n+      NameNode.stateChangeLog.debug(\n+          \"DIR* NameSystem.truncate: src\u003d{} newLength\u003d{}\", src, newLength);\n+      if (newLength \u003c 0) {\n+        throw new HadoopIllegalArgumentException(\n+            \"Cannot truncate to a negative file size: \" + newLength + \".\");\n+      }\n+      final FSPermissionChecker pc \u003d getPermissionChecker();\n+      checkOperation(OperationCategory.WRITE);\n+      writeLock();\n+      BlocksMapUpdateInfo toRemoveBlocks \u003d new BlocksMapUpdateInfo();\n+      try {\n+        checkOperation(OperationCategory.WRITE);\n+        checkNameNodeSafeMode(\"Cannot truncate for \" + src);\n+        r \u003d FSDirTruncateOp.truncate(this, src, newLength, clientName,\n+            clientMachine, mtime, toRemoveBlocks, pc);\n+      } finally {\n+        writeUnlock();\n+      }\n+      getEditLog().logSync();\n+      if (!toRemoveBlocks.getToDeleteList().isEmpty()) {\n+        removeBlocks(toRemoveBlocks);\n+        toRemoveBlocks.clear();\n+      }\n+      logAuditEvent(true, \"truncate\", src, null, r.getFileStatus());\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"truncate\", src);\n       throw e;\n     }\n-    return ret;\n+    return r.getResult();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean truncate(String src, long newLength, String clientName,\n      String clientMachine, long mtime) throws IOException,\n      UnresolvedLinkException {\n\n    requireEffectiveLayoutVersionForFeature(Feature.TRUNCATE);\n    final FSDirTruncateOp.TruncateResult r;\n    try {\n      NameNode.stateChangeLog.debug(\n          \"DIR* NameSystem.truncate: src\u003d{} newLength\u003d{}\", src, newLength);\n      if (newLength \u003c 0) {\n        throw new HadoopIllegalArgumentException(\n            \"Cannot truncate to a negative file size: \" + newLength + \".\");\n      }\n      final FSPermissionChecker pc \u003d getPermissionChecker();\n      checkOperation(OperationCategory.WRITE);\n      writeLock();\n      BlocksMapUpdateInfo toRemoveBlocks \u003d new BlocksMapUpdateInfo();\n      try {\n        checkOperation(OperationCategory.WRITE);\n        checkNameNodeSafeMode(\"Cannot truncate for \" + src);\n        r \u003d FSDirTruncateOp.truncate(this, src, newLength, clientName,\n            clientMachine, mtime, toRemoveBlocks, pc);\n      } finally {\n        writeUnlock();\n      }\n      getEditLog().logSync();\n      if (!toRemoveBlocks.getToDeleteList().isEmpty()) {\n        removeBlocks(toRemoveBlocks);\n        toRemoveBlocks.clear();\n      }\n      logAuditEvent(true, \"truncate\", src, null, r.getFileStatus());\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"truncate\", src);\n      throw e;\n    }\n    return r.getResult();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "71de367c5e80ea76d1e8d21f0216cd6b879dcee5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8432. Introduce a minimum compatible layout version to allow downgrade in more rolling upgrade use cases. Contributed by Chris Nauroth.\n",
      "commitDate": "06/06/15 9:43 AM",
      "commitName": "71de367c5e80ea76d1e8d21f0216cd6b879dcee5",
      "commitAuthor": "cnauroth",
      "commitDateOld": "05/06/15 3:09 PM",
      "commitNameOld": "3841d09765bab332c9ae4803c5981799585b1f41",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 0.77,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,14 @@\n   boolean truncate(String src, long newLength,\n                    String clientName, String clientMachine,\n                    long mtime)\n       throws IOException, UnresolvedLinkException {\n+    requireEffectiveLayoutVersionForFeature(Feature.TRUNCATE);\n     boolean ret;\n     try {\n       ret \u003d truncateInt(src, newLength, clientName, clientMachine, mtime);\n     } catch (AccessControlException e) {\n       logAuditEvent(false, \"truncate\", src);\n       throw e;\n     }\n     return ret;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  boolean truncate(String src, long newLength,\n                   String clientName, String clientMachine,\n                   long mtime)\n      throws IOException, UnresolvedLinkException {\n    requireEffectiveLayoutVersionForFeature(Feature.TRUNCATE);\n    boolean ret;\n    try {\n      ret \u003d truncateInt(src, newLength, clientName, clientMachine, mtime);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"truncate\", src);\n      throw e;\n    }\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3107. Introduce truncate. Contributed by Plamen Jeliazkov.",
      "commitDate": "12/01/15 10:50 PM",
      "commitName": "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
      "commitAuthor": "Plamen Jeliazkov",
      "diff": "@@ -0,0 +1,13 @@\n+  boolean truncate(String src, long newLength,\n+                   String clientName, String clientMachine,\n+                   long mtime)\n+      throws IOException, UnresolvedLinkException {\n+    boolean ret;\n+    try {\n+      ret \u003d truncateInt(src, newLength, clientName, clientMachine, mtime);\n+    } catch (AccessControlException e) {\n+      logAuditEvent(false, \"truncate\", src);\n+      throw e;\n+    }\n+    return ret;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  boolean truncate(String src, long newLength,\n                   String clientName, String clientMachine,\n                   long mtime)\n      throws IOException, UnresolvedLinkException {\n    boolean ret;\n    try {\n      ret \u003d truncateInt(src, newLength, clientName, clientMachine, mtime);\n    } catch (AccessControlException e) {\n      logAuditEvent(false, \"truncate\", src);\n      throw e;\n    }\n    return ret;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}