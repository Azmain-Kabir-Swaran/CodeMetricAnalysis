{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockMovementAttemptFinished.java",
  "functionName": "toString",
  "functionId": "toString",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/sps/BlockMovementAttemptFinished.java",
  "functionStartLine": 93,
  "functionEndLine": 99,
  "numCommitsSeen": 16,
  "timeTaken": 3163,
  "changeHistory": [
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
    "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
    "24add8c2f89b63640672c016f03ebfa07d585a0d"
  ],
  "changeHistoryShort": {
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": "Ybodychange",
    "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10": "Ymovefromfile",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": "Ybodychange",
    "24add8c2f89b63640672c016f03ebfa07d585a0d": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,7 @@\n   public String toString() {\n     return new StringBuilder().append(\"Block movement attempt finished(\\n  \")\n         .append(\" block : \").append(block).append(\" src node: \").append(src)\n-        .append(\" target node: \").append(target).append(\" movement status: \")\n+        .append(\" target node: \").append(target).append(\" target type: \")\n+        .append(targetType).append(\" movement status: \")\n         .append(status).append(\")\").toString();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String toString() {\n    return new StringBuilder().append(\"Block movement attempt finished(\\n  \")\n        .append(\" block : \").append(block).append(\" src node: \").append(src)\n        .append(\" target node: \").append(target).append(\" target type: \")\n        .append(targetType).append(\" movement status: \")\n        .append(status).append(\")\").toString();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/sps/BlockMovementAttemptFinished.java",
      "extendedDetails": {}
    },
    "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-13033: [SPS]: Implement a mechanism to do file block movements for external SPS. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "3159b39cf8ef704835325263154fb1a1cecc109d",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,6 @@\n-    public String toString() {\n-      return new StringBuilder().append(\"Block movement attempt finished(\\n  \")\n-          .append(\" block : \")\n-          .append(block).append(\" src node: \").append(src)\n-          .append(\" target node: \").append(target)\n-          .append(\" movement status: \").append(status).append(\")\").toString();\n-    }\n\\ No newline at end of file\n+  public String toString() {\n+    return new StringBuilder().append(\"Block movement attempt finished(\\n  \")\n+        .append(\" block : \").append(block).append(\" src node: \").append(src)\n+        .append(\" target node: \").append(target).append(\" movement status: \")\n+        .append(status).append(\")\").toString();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public String toString() {\n    return new StringBuilder().append(\"Block movement attempt finished(\\n  \")\n        .append(\" block : \").append(block).append(\" src node: \").append(src)\n        .append(\" target node: \").append(target).append(\" movement status: \")\n        .append(status).append(\")\").toString();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/sps/BlockMovementAttemptFinished.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/StoragePolicySatisfyWorker.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/common/sps/BlockMovementAttemptFinished.java",
        "oldMethodName": "toString",
        "newMethodName": "toString"
      }
    },
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "3b601f2c0e16b84e35ebe5ecdcd06d3277eabb74",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,6 +1,7 @@\n     public String toString() {\n-      return new StringBuilder().append(\"Block movement result(\\n  \")\n-          .append(\"track id: \").append(trackId).append(\" block id: \")\n-          .append(blockId).append(\" target node: \").append(target)\n+      return new StringBuilder().append(\"Block movement attempt finished(\\n  \")\n+          .append(\" block : \")\n+          .append(block).append(\" src node: \").append(src)\n+          .append(\" target node: \").append(target)\n           .append(\" movement status: \").append(status).append(\")\").toString();\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public String toString() {\n      return new StringBuilder().append(\"Block movement attempt finished(\\n  \")\n          .append(\" block : \")\n          .append(block).append(\" src node: \").append(src)\n          .append(\" target node: \").append(target)\n          .append(\" movement status: \").append(status).append(\")\").toString();\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/StoragePolicySatisfyWorker.java",
      "extendedDetails": {}
    },
    "24add8c2f89b63640672c016f03ebfa07d585a0d": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-10884: [SPS]: Add block movement tracker to track the completion of block movement future tasks at DN. Contributed by Rakesh R\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "24add8c2f89b63640672c016f03ebfa07d585a0d",
      "commitAuthor": "Uma Maheswara Rao G",
      "diff": "@@ -0,0 +1,6 @@\n+    public String toString() {\n+      return new StringBuilder().append(\"Block movement result(\\n  \")\n+          .append(\"track id: \").append(trackId).append(\" block id: \")\n+          .append(blockId).append(\" target node: \").append(target)\n+          .append(\" movement status: \").append(status).append(\")\").toString();\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public String toString() {\n      return new StringBuilder().append(\"Block movement result(\\n  \")\n          .append(\"track id: \").append(trackId).append(\" block id: \")\n          .append(blockId).append(\" target node: \").append(target)\n          .append(\" movement status: \").append(status).append(\")\").toString();\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/StoragePolicySatisfyWorker.java"
    }
  }
}