{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CacheReplicationMonitor.java",
  "functionName": "rescanCacheDirectives",
  "functionId": "rescanCacheDirectives",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
  "functionStartLine": 322,
  "functionEndLine": 362,
  "numCommitsSeen": 33,
  "timeTaken": 3872,
  "changeHistory": [
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
    "93e23a99157c30b51752fc49748c3c210745a187",
    "bab90b2222abb41d0e3382a92c2f9a8dc568f0e0",
    "70cff9e2f0c8f78c1dc54a064182971bb2106795",
    "8deb7a60575ad33b78a5167673276275ba7bece5",
    "b9ae3087c0f83bfeeea47ded8e19932b46fd2350",
    "991c453ca3ac141a3f286f74af8401f83c38b230",
    "55e5b0653c34a5f4146ce5a97a5b4a88a976d88a",
    "9da451cac57f3cd64c2c047675e5b60ca88ecf83",
    "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
    "916ab9286b6006571649d21c74d9ae70273a3ddc",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a"
  ],
  "changeHistoryShort": {
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04": "Ybodychange",
    "93e23a99157c30b51752fc49748c3c210745a187": "Ybodychange",
    "bab90b2222abb41d0e3382a92c2f9a8dc568f0e0": "Ybodychange",
    "70cff9e2f0c8f78c1dc54a064182971bb2106795": "Ybodychange",
    "8deb7a60575ad33b78a5167673276275ba7bece5": "Ybodychange",
    "b9ae3087c0f83bfeeea47ded8e19932b46fd2350": "Ybodychange",
    "991c453ca3ac141a3f286f74af8401f83c38b230": "Ybodychange",
    "55e5b0653c34a5f4146ce5a97a5b4a88a976d88a": "Ybodychange",
    "9da451cac57f3cd64c2c047675e5b60ca88ecf83": "Ybodychange",
    "f91a45a96c21db9e5d40097c7d3f5d005ae10dde": "Ymultichange(Yrename,Ybodychange)",
    "916ab9286b6006571649d21c74d9ae70273a3ddc": "Ybodychange",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10997. Reduce number of path resolving methods. Contributed by Daryn Sharp.\n",
      "commitDate": "24/10/16 3:14 PM",
      "commitName": "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "17/10/16 5:45 PM",
      "commitNameOld": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
      "commitAuthorOld": "Ming Ma",
      "daysBetweenCommits": 6.9,
      "commitsBetweenForRepo": 44,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,42 +1,41 @@\n   private void rescanCacheDirectives() {\n     FSDirectory fsDir \u003d namesystem.getFSDirectory();\n     final long now \u003d new Date().getTime();\n     for (CacheDirective directive : cacheManager.getCacheDirectives()) {\n       scannedDirectives++;\n       // Skip processing this entry if it has expired\n       if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n         LOG.debug(\"Directive {}: the directive expired at {} (now \u003d {})\",\n              directive.getId(), directive.getExpiryTime(), now);\n         continue;\n       }\n       String path \u003d directive.getPath();\n       INode node;\n       try {\n-        node \u003d fsDir.getINode(path);\n-      } catch (UnresolvedLinkException e) {\n-        // We don\u0027t cache through symlinks\n-        LOG.debug(\"Directive {}: got UnresolvedLinkException while resolving \"\n-                + \"path {}\", directive.getId(), path\n-        );\n+        node \u003d fsDir.getINode(path, DirOp.READ);\n+      } catch (IOException e) {\n+        // We don\u0027t cache through symlinks or invalid paths\n+        LOG.debug(\"Directive {}: Failed to resolve path {} ({})\",\n+            directive.getId(), path, e.getMessage());\n         continue;\n       }\n       if (node \u003d\u003d null)  {\n         LOG.debug(\"Directive {}: No inode found at {}\", directive.getId(),\n             path);\n       } else if (node.isDirectory()) {\n         INodeDirectory dir \u003d node.asDirectory();\n         ReadOnlyList\u003cINode\u003e children \u003d dir\n             .getChildrenList(Snapshot.CURRENT_STATE_ID);\n         for (INode child : children) {\n           if (child.isFile()) {\n             rescanFile(directive, child.asFile());\n           }\n         }\n       } else if (node.isFile()) {\n         rescanFile(directive, node.asFile());\n       } else {\n         LOG.debug(\"Directive {}: ignoring non-directive, non-file inode {} \",\n             directive.getId(), node);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCacheDirectives() {\n    FSDirectory fsDir \u003d namesystem.getFSDirectory();\n    final long now \u003d new Date().getTime();\n    for (CacheDirective directive : cacheManager.getCacheDirectives()) {\n      scannedDirectives++;\n      // Skip processing this entry if it has expired\n      if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n        LOG.debug(\"Directive {}: the directive expired at {} (now \u003d {})\",\n             directive.getId(), directive.getExpiryTime(), now);\n        continue;\n      }\n      String path \u003d directive.getPath();\n      INode node;\n      try {\n        node \u003d fsDir.getINode(path, DirOp.READ);\n      } catch (IOException e) {\n        // We don\u0027t cache through symlinks or invalid paths\n        LOG.debug(\"Directive {}: Failed to resolve path {} ({})\",\n            directive.getId(), path, e.getMessage());\n        continue;\n      }\n      if (node \u003d\u003d null)  {\n        LOG.debug(\"Directive {}: No inode found at {}\", directive.getId(),\n            path);\n      } else if (node.isDirectory()) {\n        INodeDirectory dir \u003d node.asDirectory();\n        ReadOnlyList\u003cINode\u003e children \u003d dir\n            .getChildrenList(Snapshot.CURRENT_STATE_ID);\n        for (INode child : children) {\n          if (child.isFile()) {\n            rescanFile(directive, child.asFile());\n          }\n        }\n      } else if (node.isFile()) {\n        rescanFile(directive, node.asFile());\n      } else {\n        LOG.debug(\"Directive {}: ignoring non-directive, non-file inode {} \",\n            directive.getId(), node);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "93e23a99157c30b51752fc49748c3c210745a187": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6613. Improve logging in caching classes. (wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1607697 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/07/14 10:13 AM",
      "commitName": "93e23a99157c30b51752fc49748c3c210745a187",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "10/03/14 11:24 PM",
      "commitNameOld": "bab90b2222abb41d0e3382a92c2f9a8dc568f0e0",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 114.45,
      "commitsBetweenForRepo": 724,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,42 @@\n   private void rescanCacheDirectives() {\n     FSDirectory fsDir \u003d namesystem.getFSDirectory();\n     final long now \u003d new Date().getTime();\n     for (CacheDirective directive : cacheManager.getCacheDirectives()) {\n       scannedDirectives++;\n       // Skip processing this entry if it has expired\n       if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"Directive \" + directive.getId() + \": the directive \" +\n-              \"expired at \" + directive.getExpiryTime() + \" (now \u003d \" +\n-              now + \")\");\n-        }\n+        LOG.debug(\"Directive {}: the directive expired at {} (now \u003d {})\",\n+             directive.getId(), directive.getExpiryTime(), now);\n         continue;\n       }\n       String path \u003d directive.getPath();\n       INode node;\n       try {\n         node \u003d fsDir.getINode(path);\n       } catch (UnresolvedLinkException e) {\n         // We don\u0027t cache through symlinks\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"Directive \" + directive.getId() +\n-              \": got UnresolvedLinkException while resolving path \" + path);\n-        }\n+        LOG.debug(\"Directive {}: got UnresolvedLinkException while resolving \"\n+                + \"path {}\", directive.getId(), path\n+        );\n         continue;\n       }\n       if (node \u003d\u003d null)  {\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"Directive \" + directive.getId() +\n-              \": No inode found at \" + path);\n-        }\n+        LOG.debug(\"Directive {}: No inode found at {}\", directive.getId(),\n+            path);\n       } else if (node.isDirectory()) {\n         INodeDirectory dir \u003d node.asDirectory();\n         ReadOnlyList\u003cINode\u003e children \u003d dir\n             .getChildrenList(Snapshot.CURRENT_STATE_ID);\n         for (INode child : children) {\n           if (child.isFile()) {\n             rescanFile(directive, child.asFile());\n           }\n         }\n       } else if (node.isFile()) {\n         rescanFile(directive, node.asFile());\n       } else {\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"Directive \" + directive.getId() + \n-              \": ignoring non-directive, non-file inode \" + node);\n-        }\n+        LOG.debug(\"Directive {}: ignoring non-directive, non-file inode {} \",\n+            directive.getId(), node);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCacheDirectives() {\n    FSDirectory fsDir \u003d namesystem.getFSDirectory();\n    final long now \u003d new Date().getTime();\n    for (CacheDirective directive : cacheManager.getCacheDirectives()) {\n      scannedDirectives++;\n      // Skip processing this entry if it has expired\n      if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n        LOG.debug(\"Directive {}: the directive expired at {} (now \u003d {})\",\n             directive.getId(), directive.getExpiryTime(), now);\n        continue;\n      }\n      String path \u003d directive.getPath();\n      INode node;\n      try {\n        node \u003d fsDir.getINode(path);\n      } catch (UnresolvedLinkException e) {\n        // We don\u0027t cache through symlinks\n        LOG.debug(\"Directive {}: got UnresolvedLinkException while resolving \"\n                + \"path {}\", directive.getId(), path\n        );\n        continue;\n      }\n      if (node \u003d\u003d null)  {\n        LOG.debug(\"Directive {}: No inode found at {}\", directive.getId(),\n            path);\n      } else if (node.isDirectory()) {\n        INodeDirectory dir \u003d node.asDirectory();\n        ReadOnlyList\u003cINode\u003e children \u003d dir\n            .getChildrenList(Snapshot.CURRENT_STATE_ID);\n        for (INode child : children) {\n          if (child.isFile()) {\n            rescanFile(directive, child.asFile());\n          }\n        }\n      } else if (node.isFile()) {\n        rescanFile(directive, node.asFile());\n      } else {\n        LOG.debug(\"Directive {}: ignoring non-directive, non-file inode {} \",\n            directive.getId(), node);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "bab90b2222abb41d0e3382a92c2f9a8dc568f0e0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6085. Improve CacheReplicationMonitor log messages a bit (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1576194 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/03/14 11:24 PM",
      "commitName": "bab90b2222abb41d0e3382a92c2f9a8dc568f0e0",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "07/01/14 12:52 PM",
      "commitNameOld": "70cff9e2f0c8f78c1dc54a064182971bb2106795",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 62.4,
      "commitsBetweenForRepo": 529,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,50 @@\n   private void rescanCacheDirectives() {\n     FSDirectory fsDir \u003d namesystem.getFSDirectory();\n     final long now \u003d new Date().getTime();\n     for (CacheDirective directive : cacheManager.getCacheDirectives()) {\n+      scannedDirectives++;\n       // Skip processing this entry if it has expired\n-      if (LOG.isTraceEnabled()) {\n-        LOG.trace(\"Directive expiry is at \" + directive.getExpiryTime());\n-      }\n       if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n         if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"Skipping directive id \" + directive.getId()\n-              + \" because it has expired (\" + directive.getExpiryTime() + \"\u003c\u003d\"\n-              + now + \")\");\n+          LOG.debug(\"Directive \" + directive.getId() + \": the directive \" +\n+              \"expired at \" + directive.getExpiryTime() + \" (now \u003d \" +\n+              now + \")\");\n         }\n         continue;\n       }\n-      scannedDirectives++;\n       String path \u003d directive.getPath();\n       INode node;\n       try {\n         node \u003d fsDir.getINode(path);\n       } catch (UnresolvedLinkException e) {\n         // We don\u0027t cache through symlinks\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Directive \" + directive.getId() +\n+              \": got UnresolvedLinkException while resolving path \" + path);\n+        }\n         continue;\n       }\n       if (node \u003d\u003d null)  {\n         if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"No inode found at \" + path);\n+          LOG.debug(\"Directive \" + directive.getId() +\n+              \": No inode found at \" + path);\n         }\n       } else if (node.isDirectory()) {\n         INodeDirectory dir \u003d node.asDirectory();\n         ReadOnlyList\u003cINode\u003e children \u003d dir\n             .getChildrenList(Snapshot.CURRENT_STATE_ID);\n         for (INode child : children) {\n           if (child.isFile()) {\n             rescanFile(directive, child.asFile());\n           }\n         }\n       } else if (node.isFile()) {\n         rescanFile(directive, node.asFile());\n       } else {\n         if (LOG.isDebugEnabled()) {\n-          LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n-                    \" found at \" + path);\n+          LOG.debug(\"Directive \" + directive.getId() + \n+              \": ignoring non-directive, non-file inode \" + node);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCacheDirectives() {\n    FSDirectory fsDir \u003d namesystem.getFSDirectory();\n    final long now \u003d new Date().getTime();\n    for (CacheDirective directive : cacheManager.getCacheDirectives()) {\n      scannedDirectives++;\n      // Skip processing this entry if it has expired\n      if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Directive \" + directive.getId() + \": the directive \" +\n              \"expired at \" + directive.getExpiryTime() + \" (now \u003d \" +\n              now + \")\");\n        }\n        continue;\n      }\n      String path \u003d directive.getPath();\n      INode node;\n      try {\n        node \u003d fsDir.getINode(path);\n      } catch (UnresolvedLinkException e) {\n        // We don\u0027t cache through symlinks\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Directive \" + directive.getId() +\n              \": got UnresolvedLinkException while resolving path \" + path);\n        }\n        continue;\n      }\n      if (node \u003d\u003d null)  {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Directive \" + directive.getId() +\n              \": No inode found at \" + path);\n        }\n      } else if (node.isDirectory()) {\n        INodeDirectory dir \u003d node.asDirectory();\n        ReadOnlyList\u003cINode\u003e children \u003d dir\n            .getChildrenList(Snapshot.CURRENT_STATE_ID);\n        for (INode child : children) {\n          if (child.isFile()) {\n            rescanFile(directive, child.asFile());\n          }\n        }\n      } else if (node.isFile()) {\n        rescanFile(directive, node.asFile());\n      } else {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Directive \" + directive.getId() + \n              \": ignoring non-directive, non-file inode \" + node);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "70cff9e2f0c8f78c1dc54a064182971bb2106795": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5715. Use Snapshot ID to indicate the corresponding Snapshot for a FileDiff/DirectoryDiff. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1556353 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/01/14 12:52 PM",
      "commitName": "70cff9e2f0c8f78c1dc54a064182971bb2106795",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "06/01/14 11:45 AM",
      "commitNameOld": "8deb7a60575ad33b78a5167673276275ba7bece5",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 1.05,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,48 @@\n   private void rescanCacheDirectives() {\n     FSDirectory fsDir \u003d namesystem.getFSDirectory();\n     final long now \u003d new Date().getTime();\n     for (CacheDirective directive : cacheManager.getCacheDirectives()) {\n       // Skip processing this entry if it has expired\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"Directive expiry is at \" + directive.getExpiryTime());\n       }\n       if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Skipping directive id \" + directive.getId()\n               + \" because it has expired (\" + directive.getExpiryTime() + \"\u003c\u003d\"\n               + now + \")\");\n         }\n         continue;\n       }\n       scannedDirectives++;\n       String path \u003d directive.getPath();\n       INode node;\n       try {\n         node \u003d fsDir.getINode(path);\n       } catch (UnresolvedLinkException e) {\n         // We don\u0027t cache through symlinks\n         continue;\n       }\n       if (node \u003d\u003d null)  {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"No inode found at \" + path);\n         }\n       } else if (node.isDirectory()) {\n         INodeDirectory dir \u003d node.asDirectory();\n-        ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n+        ReadOnlyList\u003cINode\u003e children \u003d dir\n+            .getChildrenList(Snapshot.CURRENT_STATE_ID);\n         for (INode child : children) {\n           if (child.isFile()) {\n             rescanFile(directive, child.asFile());\n           }\n         }\n       } else if (node.isFile()) {\n         rescanFile(directive, node.asFile());\n       } else {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                     \" found at \" + path);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCacheDirectives() {\n    FSDirectory fsDir \u003d namesystem.getFSDirectory();\n    final long now \u003d new Date().getTime();\n    for (CacheDirective directive : cacheManager.getCacheDirectives()) {\n      // Skip processing this entry if it has expired\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"Directive expiry is at \" + directive.getExpiryTime());\n      }\n      if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Skipping directive id \" + directive.getId()\n              + \" because it has expired (\" + directive.getExpiryTime() + \"\u003c\u003d\"\n              + now + \")\");\n        }\n        continue;\n      }\n      scannedDirectives++;\n      String path \u003d directive.getPath();\n      INode node;\n      try {\n        node \u003d fsDir.getINode(path);\n      } catch (UnresolvedLinkException e) {\n        // We don\u0027t cache through symlinks\n        continue;\n      }\n      if (node \u003d\u003d null)  {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"No inode found at \" + path);\n        }\n      } else if (node.isDirectory()) {\n        INodeDirectory dir \u003d node.asDirectory();\n        ReadOnlyList\u003cINode\u003e children \u003d dir\n            .getChildrenList(Snapshot.CURRENT_STATE_ID);\n        for (INode child : children) {\n          if (child.isFile()) {\n            rescanFile(directive, child.asFile());\n          }\n        }\n      } else if (node.isFile()) {\n        rescanFile(directive, node.asFile());\n      } else {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                    \" found at \" + path);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "8deb7a60575ad33b78a5167673276275ba7bece5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5589. Namenode loops caching and uncaching when data should be uncached. (awang via cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1555996 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/01/14 11:45 AM",
      "commitName": "8deb7a60575ad33b78a5167673276275ba7bece5",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "02/01/14 6:45 PM",
      "commitNameOld": "d85c017d0488930d806f267141057fc73e68c728",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 3.71,
      "commitsBetweenForRepo": 11,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,47 @@\n   private void rescanCacheDirectives() {\n     FSDirectory fsDir \u003d namesystem.getFSDirectory();\n     final long now \u003d new Date().getTime();\n     for (CacheDirective directive : cacheManager.getCacheDirectives()) {\n-      // Reset the directive\u0027s statistics\n-      directive.resetStatistics();\n       // Skip processing this entry if it has expired\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"Directive expiry is at \" + directive.getExpiryTime());\n       }\n       if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Skipping directive id \" + directive.getId()\n               + \" because it has expired (\" + directive.getExpiryTime() + \"\u003c\u003d\"\n               + now + \")\");\n         }\n         continue;\n       }\n       scannedDirectives++;\n       String path \u003d directive.getPath();\n       INode node;\n       try {\n         node \u003d fsDir.getINode(path);\n       } catch (UnresolvedLinkException e) {\n         // We don\u0027t cache through symlinks\n         continue;\n       }\n       if (node \u003d\u003d null)  {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"No inode found at \" + path);\n         }\n       } else if (node.isDirectory()) {\n         INodeDirectory dir \u003d node.asDirectory();\n         ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n         for (INode child : children) {\n           if (child.isFile()) {\n             rescanFile(directive, child.asFile());\n           }\n         }\n       } else if (node.isFile()) {\n         rescanFile(directive, node.asFile());\n       } else {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                     \" found at \" + path);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCacheDirectives() {\n    FSDirectory fsDir \u003d namesystem.getFSDirectory();\n    final long now \u003d new Date().getTime();\n    for (CacheDirective directive : cacheManager.getCacheDirectives()) {\n      // Skip processing this entry if it has expired\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"Directive expiry is at \" + directive.getExpiryTime());\n      }\n      if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Skipping directive id \" + directive.getId()\n              + \" because it has expired (\" + directive.getExpiryTime() + \"\u003c\u003d\"\n              + now + \")\");\n        }\n        continue;\n      }\n      scannedDirectives++;\n      String path \u003d directive.getPath();\n      INode node;\n      try {\n        node \u003d fsDir.getINode(path);\n      } catch (UnresolvedLinkException e) {\n        // We don\u0027t cache through symlinks\n        continue;\n      }\n      if (node \u003d\u003d null)  {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"No inode found at \" + path);\n        }\n      } else if (node.isDirectory()) {\n        INodeDirectory dir \u003d node.asDirectory();\n        ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n        for (INode child : children) {\n          if (child.isFile()) {\n            rescanFile(directive, child.asFile());\n          }\n        }\n      } else if (node.isFile()) {\n        rescanFile(directive, node.asFile());\n      } else {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                    \" found at \" + path);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "b9ae3087c0f83bfeeea47ded8e19932b46fd2350": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5636. Enforce a max TTL per cache pool (awang via cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1552841 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/12/13 3:27 PM",
      "commitName": "b9ae3087c0f83bfeeea47ded8e19932b46fd2350",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "17/12/13 10:47 AM",
      "commitNameOld": "991c453ca3ac141a3f286f74af8401f83c38b230",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 3.19,
      "commitsBetweenForRepo": 31,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,49 @@\n   private void rescanCacheDirectives() {\n     FSDirectory fsDir \u003d namesystem.getFSDirectory();\n     final long now \u003d new Date().getTime();\n     for (CacheDirective directive : cacheManager.getCacheDirectives()) {\n       // Reset the directive\u0027s statistics\n       directive.resetStatistics();\n       // Skip processing this entry if it has expired\n       if (LOG.isTraceEnabled()) {\n         LOG.trace(\"Directive expiry is at \" + directive.getExpiryTime());\n       }\n       if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Skipping directive id \" + directive.getId()\n-              + \" because it has expired (\" + directive.getExpiryTime() + \"\u003e\u003d\"\n+              + \" because it has expired (\" + directive.getExpiryTime() + \"\u003c\u003d\"\n               + now + \")\");\n         }\n         continue;\n       }\n       scannedDirectives++;\n       String path \u003d directive.getPath();\n       INode node;\n       try {\n         node \u003d fsDir.getINode(path);\n       } catch (UnresolvedLinkException e) {\n         // We don\u0027t cache through symlinks\n         continue;\n       }\n       if (node \u003d\u003d null)  {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"No inode found at \" + path);\n         }\n       } else if (node.isDirectory()) {\n         INodeDirectory dir \u003d node.asDirectory();\n         ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n         for (INode child : children) {\n           if (child.isFile()) {\n             rescanFile(directive, child.asFile());\n           }\n         }\n       } else if (node.isFile()) {\n         rescanFile(directive, node.asFile());\n       } else {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                     \" found at \" + path);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCacheDirectives() {\n    FSDirectory fsDir \u003d namesystem.getFSDirectory();\n    final long now \u003d new Date().getTime();\n    for (CacheDirective directive : cacheManager.getCacheDirectives()) {\n      // Reset the directive\u0027s statistics\n      directive.resetStatistics();\n      // Skip processing this entry if it has expired\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"Directive expiry is at \" + directive.getExpiryTime());\n      }\n      if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Skipping directive id \" + directive.getId()\n              + \" because it has expired (\" + directive.getExpiryTime() + \"\u003c\u003d\"\n              + now + \")\");\n        }\n        continue;\n      }\n      scannedDirectives++;\n      String path \u003d directive.getPath();\n      INode node;\n      try {\n        node \u003d fsDir.getINode(path);\n      } catch (UnresolvedLinkException e) {\n        // We don\u0027t cache through symlinks\n        continue;\n      }\n      if (node \u003d\u003d null)  {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"No inode found at \" + path);\n        }\n      } else if (node.isDirectory()) {\n        INodeDirectory dir \u003d node.asDirectory();\n        ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n        for (INode child : children) {\n          if (child.isFile()) {\n            rescanFile(directive, child.asFile());\n          }\n        }\n      } else if (node.isFile()) {\n        rescanFile(directive, node.asFile());\n      } else {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                    \" found at \" + path);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "991c453ca3ac141a3f286f74af8401f83c38b230": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5431. Support cachepool-based limit management in path-based caching. (awang via cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1551651 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/12/13 10:47 AM",
      "commitName": "991c453ca3ac141a3f286f74af8401f83c38b230",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "05/12/13 1:09 PM",
      "commitNameOld": "55e5b0653c34a5f4146ce5a97a5b4a88a976d88a",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 11.9,
      "commitsBetweenForRepo": 67,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,49 @@\n   private void rescanCacheDirectives() {\n     FSDirectory fsDir \u003d namesystem.getFSDirectory();\n     final long now \u003d new Date().getTime();\n     for (CacheDirective directive : cacheManager.getCacheDirectives()) {\n       // Reset the directive\u0027s statistics\n       directive.resetStatistics();\n       // Skip processing this entry if it has expired\n-      LOG.info(\"Directive expiry is at \" + directive.getExpiryTime());\n+      if (LOG.isTraceEnabled()) {\n+        LOG.trace(\"Directive expiry is at \" + directive.getExpiryTime());\n+      }\n       if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Skipping directive id \" + directive.getId()\n               + \" because it has expired (\" + directive.getExpiryTime() + \"\u003e\u003d\"\n-              + now);\n+              + now + \")\");\n         }\n         continue;\n       }\n       scannedDirectives++;\n       String path \u003d directive.getPath();\n       INode node;\n       try {\n         node \u003d fsDir.getINode(path);\n       } catch (UnresolvedLinkException e) {\n         // We don\u0027t cache through symlinks\n         continue;\n       }\n       if (node \u003d\u003d null)  {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"No inode found at \" + path);\n         }\n       } else if (node.isDirectory()) {\n         INodeDirectory dir \u003d node.asDirectory();\n         ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n         for (INode child : children) {\n           if (child.isFile()) {\n             rescanFile(directive, child.asFile());\n           }\n         }\n       } else if (node.isFile()) {\n         rescanFile(directive, node.asFile());\n       } else {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                     \" found at \" + path);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCacheDirectives() {\n    FSDirectory fsDir \u003d namesystem.getFSDirectory();\n    final long now \u003d new Date().getTime();\n    for (CacheDirective directive : cacheManager.getCacheDirectives()) {\n      // Reset the directive\u0027s statistics\n      directive.resetStatistics();\n      // Skip processing this entry if it has expired\n      if (LOG.isTraceEnabled()) {\n        LOG.trace(\"Directive expiry is at \" + directive.getExpiryTime());\n      }\n      if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Skipping directive id \" + directive.getId()\n              + \" because it has expired (\" + directive.getExpiryTime() + \"\u003e\u003d\"\n              + now + \")\");\n        }\n        continue;\n      }\n      scannedDirectives++;\n      String path \u003d directive.getPath();\n      INode node;\n      try {\n        node \u003d fsDir.getINode(path);\n      } catch (UnresolvedLinkException e) {\n        // We don\u0027t cache through symlinks\n        continue;\n      }\n      if (node \u003d\u003d null)  {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"No inode found at \" + path);\n        }\n      } else if (node.isDirectory()) {\n        INodeDirectory dir \u003d node.asDirectory();\n        ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n        for (INode child : children) {\n          if (child.isFile()) {\n            rescanFile(directive, child.asFile());\n          }\n        }\n      } else if (node.isFile()) {\n        rescanFile(directive, node.asFile());\n      } else {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                    \" found at \" + path);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "55e5b0653c34a5f4146ce5a97a5b4a88a976d88a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5630. Hook up cache directive and pool usage statistics. (wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1548309 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/12/13 1:09 PM",
      "commitName": "55e5b0653c34a5f4146ce5a97a5b4a88a976d88a",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "27/11/13 11:20 PM",
      "commitNameOld": "9da451cac57f3cd64c2c047675e5b60ca88ecf83",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 7.58,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,47 @@\n   private void rescanCacheDirectives() {\n     FSDirectory fsDir \u003d namesystem.getFSDirectory();\n     final long now \u003d new Date().getTime();\n-    for (CacheDirective directive : cacheManager.getEntriesById().values()) {\n-      // Reset the directive\n-      directive.clearBytesNeeded();\n-      directive.clearBytesCached();\n-      directive.clearFilesAffected();\n+    for (CacheDirective directive : cacheManager.getCacheDirectives()) {\n+      // Reset the directive\u0027s statistics\n+      directive.resetStatistics();\n       // Skip processing this entry if it has expired\n       LOG.info(\"Directive expiry is at \" + directive.getExpiryTime());\n       if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Skipping directive id \" + directive.getId()\n               + \" because it has expired (\" + directive.getExpiryTime() + \"\u003e\u003d\"\n               + now);\n         }\n         continue;\n       }\n       scannedDirectives++;\n       String path \u003d directive.getPath();\n       INode node;\n       try {\n         node \u003d fsDir.getINode(path);\n       } catch (UnresolvedLinkException e) {\n         // We don\u0027t cache through symlinks\n         continue;\n       }\n       if (node \u003d\u003d null)  {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"No inode found at \" + path);\n         }\n       } else if (node.isDirectory()) {\n         INodeDirectory dir \u003d node.asDirectory();\n         ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n         for (INode child : children) {\n           if (child.isFile()) {\n             rescanFile(directive, child.asFile());\n           }\n         }\n       } else if (node.isFile()) {\n         rescanFile(directive, node.asFile());\n       } else {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                     \" found at \" + path);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCacheDirectives() {\n    FSDirectory fsDir \u003d namesystem.getFSDirectory();\n    final long now \u003d new Date().getTime();\n    for (CacheDirective directive : cacheManager.getCacheDirectives()) {\n      // Reset the directive\u0027s statistics\n      directive.resetStatistics();\n      // Skip processing this entry if it has expired\n      LOG.info(\"Directive expiry is at \" + directive.getExpiryTime());\n      if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Skipping directive id \" + directive.getId()\n              + \" because it has expired (\" + directive.getExpiryTime() + \"\u003e\u003d\"\n              + now);\n        }\n        continue;\n      }\n      scannedDirectives++;\n      String path \u003d directive.getPath();\n      INode node;\n      try {\n        node \u003d fsDir.getINode(path);\n      } catch (UnresolvedLinkException e) {\n        // We don\u0027t cache through symlinks\n        continue;\n      }\n      if (node \u003d\u003d null)  {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"No inode found at \" + path);\n        }\n      } else if (node.isDirectory()) {\n        INodeDirectory dir \u003d node.asDirectory();\n        ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n        for (INode child : children) {\n          if (child.isFile()) {\n            rescanFile(directive, child.asFile());\n          }\n        }\n      } else if (node.isFile()) {\n        rescanFile(directive, node.asFile());\n      } else {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                    \" found at \" + path);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "9da451cac57f3cd64c2c047675e5b60ca88ecf83": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5430. Support TTL on CacheDirectives. Contributed by Andrew Wang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1546301 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/11/13 11:20 PM",
      "commitName": "9da451cac57f3cd64c2c047675e5b60ca88ecf83",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "27/11/13 9:55 AM",
      "commitNameOld": "13edb391d06c479720202eb5ac81f1c71fe64748",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 0.56,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,49 @@\n   private void rescanCacheDirectives() {\n     FSDirectory fsDir \u003d namesystem.getFSDirectory();\n-    for (CacheDirective pce : cacheManager.getEntriesById().values()) {\n+    final long now \u003d new Date().getTime();\n+    for (CacheDirective directive : cacheManager.getEntriesById().values()) {\n+      // Reset the directive\n+      directive.clearBytesNeeded();\n+      directive.clearBytesCached();\n+      directive.clearFilesAffected();\n+      // Skip processing this entry if it has expired\n+      LOG.info(\"Directive expiry is at \" + directive.getExpiryTime());\n+      if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Skipping directive id \" + directive.getId()\n+              + \" because it has expired (\" + directive.getExpiryTime() + \"\u003e\u003d\"\n+              + now);\n+        }\n+        continue;\n+      }\n       scannedDirectives++;\n-      pce.clearBytesNeeded();\n-      pce.clearBytesCached();\n-      pce.clearFilesAffected();\n-      String path \u003d pce.getPath();\n+      String path \u003d directive.getPath();\n       INode node;\n       try {\n         node \u003d fsDir.getINode(path);\n       } catch (UnresolvedLinkException e) {\n         // We don\u0027t cache through symlinks\n         continue;\n       }\n       if (node \u003d\u003d null)  {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"No inode found at \" + path);\n         }\n       } else if (node.isDirectory()) {\n         INodeDirectory dir \u003d node.asDirectory();\n         ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n         for (INode child : children) {\n           if (child.isFile()) {\n-            rescanFile(pce, child.asFile());\n+            rescanFile(directive, child.asFile());\n           }\n         }\n       } else if (node.isFile()) {\n-        rescanFile(pce, node.asFile());\n+        rescanFile(directive, node.asFile());\n       } else {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                     \" found at \" + path);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanCacheDirectives() {\n    FSDirectory fsDir \u003d namesystem.getFSDirectory();\n    final long now \u003d new Date().getTime();\n    for (CacheDirective directive : cacheManager.getEntriesById().values()) {\n      // Reset the directive\n      directive.clearBytesNeeded();\n      directive.clearBytesCached();\n      directive.clearFilesAffected();\n      // Skip processing this entry if it has expired\n      LOG.info(\"Directive expiry is at \" + directive.getExpiryTime());\n      if (directive.getExpiryTime() \u003e 0 \u0026\u0026 directive.getExpiryTime() \u003c\u003d now) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Skipping directive id \" + directive.getId()\n              + \" because it has expired (\" + directive.getExpiryTime() + \"\u003e\u003d\"\n              + now);\n        }\n        continue;\n      }\n      scannedDirectives++;\n      String path \u003d directive.getPath();\n      INode node;\n      try {\n        node \u003d fsDir.getINode(path);\n      } catch (UnresolvedLinkException e) {\n        // We don\u0027t cache through symlinks\n        continue;\n      }\n      if (node \u003d\u003d null)  {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"No inode found at \" + path);\n        }\n      } else if (node.isDirectory()) {\n        INodeDirectory dir \u003d node.asDirectory();\n        ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n        for (INode child : children) {\n          if (child.isFile()) {\n            rescanFile(directive, child.asFile());\n          }\n        }\n      } else if (node.isFile()) {\n        rescanFile(directive, node.asFile());\n      } else {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                    \" found at \" + path);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "f91a45a96c21db9e5d40097c7d3f5d005ae10dde": {
      "type": "Ymultichange(Yrename,Ybodychange)",
      "commitMessage": "HDFS-5473. Consistent naming of user-visible caching classes and methods (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544252 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/11/13 9:12 AM",
      "commitName": "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
      "commitAuthor": "Colin McCabe",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-5473. Consistent naming of user-visible caching classes and methods (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544252 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/11/13 9:12 AM",
          "commitName": "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "20/11/13 1:31 PM",
          "commitNameOld": "916ab9286b6006571649d21c74d9ae70273a3ddc",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 0.82,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,37 +1,37 @@\n-  private void rescanPathBasedCacheEntries() {\n+  private void rescanCacheDirectives() {\n     FSDirectory fsDir \u003d namesystem.getFSDirectory();\n-    for (PathBasedCacheEntry pce : cacheManager.getEntriesById().values()) {\n+    for (CacheDirective pce : cacheManager.getEntriesById().values()) {\n       scannedDirectives++;\n       pce.clearBytesNeeded();\n       pce.clearBytesCached();\n       pce.clearFilesAffected();\n       String path \u003d pce.getPath();\n       INode node;\n       try {\n         node \u003d fsDir.getINode(path);\n       } catch (UnresolvedLinkException e) {\n         // We don\u0027t cache through symlinks\n         continue;\n       }\n       if (node \u003d\u003d null)  {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"No inode found at \" + path);\n         }\n       } else if (node.isDirectory()) {\n         INodeDirectory dir \u003d node.asDirectory();\n         ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n         for (INode child : children) {\n           if (child.isFile()) {\n             rescanFile(pce, child.asFile());\n           }\n         }\n       } else if (node.isFile()) {\n         rescanFile(pce, node.asFile());\n       } else {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                     \" found at \" + path);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void rescanCacheDirectives() {\n    FSDirectory fsDir \u003d namesystem.getFSDirectory();\n    for (CacheDirective pce : cacheManager.getEntriesById().values()) {\n      scannedDirectives++;\n      pce.clearBytesNeeded();\n      pce.clearBytesCached();\n      pce.clearFilesAffected();\n      String path \u003d pce.getPath();\n      INode node;\n      try {\n        node \u003d fsDir.getINode(path);\n      } catch (UnresolvedLinkException e) {\n        // We don\u0027t cache through symlinks\n        continue;\n      }\n      if (node \u003d\u003d null)  {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"No inode found at \" + path);\n        }\n      } else if (node.isDirectory()) {\n        INodeDirectory dir \u003d node.asDirectory();\n        ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n        for (INode child : children) {\n          if (child.isFile()) {\n            rescanFile(pce, child.asFile());\n          }\n        }\n      } else if (node.isFile()) {\n        rescanFile(pce, node.asFile());\n      } else {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                    \" found at \" + path);\n        }\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
          "extendedDetails": {
            "oldValue": "rescanPathBasedCacheEntries",
            "newValue": "rescanCacheDirectives"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-5473. Consistent naming of user-visible caching classes and methods (cmccabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1544252 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/11/13 9:12 AM",
          "commitName": "f91a45a96c21db9e5d40097c7d3f5d005ae10dde",
          "commitAuthor": "Colin McCabe",
          "commitDateOld": "20/11/13 1:31 PM",
          "commitNameOld": "916ab9286b6006571649d21c74d9ae70273a3ddc",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 0.82,
          "commitsBetweenForRepo": 10,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,37 +1,37 @@\n-  private void rescanPathBasedCacheEntries() {\n+  private void rescanCacheDirectives() {\n     FSDirectory fsDir \u003d namesystem.getFSDirectory();\n-    for (PathBasedCacheEntry pce : cacheManager.getEntriesById().values()) {\n+    for (CacheDirective pce : cacheManager.getEntriesById().values()) {\n       scannedDirectives++;\n       pce.clearBytesNeeded();\n       pce.clearBytesCached();\n       pce.clearFilesAffected();\n       String path \u003d pce.getPath();\n       INode node;\n       try {\n         node \u003d fsDir.getINode(path);\n       } catch (UnresolvedLinkException e) {\n         // We don\u0027t cache through symlinks\n         continue;\n       }\n       if (node \u003d\u003d null)  {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"No inode found at \" + path);\n         }\n       } else if (node.isDirectory()) {\n         INodeDirectory dir \u003d node.asDirectory();\n         ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n         for (INode child : children) {\n           if (child.isFile()) {\n             rescanFile(pce, child.asFile());\n           }\n         }\n       } else if (node.isFile()) {\n         rescanFile(pce, node.asFile());\n       } else {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                     \" found at \" + path);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void rescanCacheDirectives() {\n    FSDirectory fsDir \u003d namesystem.getFSDirectory();\n    for (CacheDirective pce : cacheManager.getEntriesById().values()) {\n      scannedDirectives++;\n      pce.clearBytesNeeded();\n      pce.clearBytesCached();\n      pce.clearFilesAffected();\n      String path \u003d pce.getPath();\n      INode node;\n      try {\n        node \u003d fsDir.getINode(path);\n      } catch (UnresolvedLinkException e) {\n        // We don\u0027t cache through symlinks\n        continue;\n      }\n      if (node \u003d\u003d null)  {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"No inode found at \" + path);\n        }\n      } else if (node.isDirectory()) {\n        INodeDirectory dir \u003d node.asDirectory();\n        ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n        for (INode child : children) {\n          if (child.isFile()) {\n            rescanFile(pce, child.asFile());\n          }\n        }\n      } else if (node.isFile()) {\n        rescanFile(pce, node.asFile());\n      } else {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                    \" found at \" + path);\n        }\n      }\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
          "extendedDetails": {}
        }
      ]
    },
    "916ab9286b6006571649d21c74d9ae70273a3ddc": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5451. Add byte and file statistics to PathBasedCacheEntry. Contributed by Colin Patrick McCabe.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1543958 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/11/13 1:31 PM",
      "commitName": "916ab9286b6006571649d21c74d9ae70273a3ddc",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "13/11/13 10:18 AM",
      "commitNameOld": "3c591aa442d342bdd4a0c4abe9a43c64d8ef3e65",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 7.13,
      "commitsBetweenForRepo": 62,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,37 @@\n   private void rescanPathBasedCacheEntries() {\n     FSDirectory fsDir \u003d namesystem.getFSDirectory();\n     for (PathBasedCacheEntry pce : cacheManager.getEntriesById().values()) {\n       scannedDirectives++;\n+      pce.clearBytesNeeded();\n+      pce.clearBytesCached();\n+      pce.clearFilesAffected();\n       String path \u003d pce.getPath();\n       INode node;\n       try {\n         node \u003d fsDir.getINode(path);\n       } catch (UnresolvedLinkException e) {\n         // We don\u0027t cache through symlinks\n         continue;\n       }\n       if (node \u003d\u003d null)  {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"No inode found at \" + path);\n         }\n       } else if (node.isDirectory()) {\n         INodeDirectory dir \u003d node.asDirectory();\n         ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n         for (INode child : children) {\n           if (child.isFile()) {\n             rescanFile(pce, child.asFile());\n           }\n         }\n       } else if (node.isFile()) {\n         rescanFile(pce, node.asFile());\n       } else {\n         if (LOG.isDebugEnabled()) {\n           LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                     \" found at \" + path);\n         }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanPathBasedCacheEntries() {\n    FSDirectory fsDir \u003d namesystem.getFSDirectory();\n    for (PathBasedCacheEntry pce : cacheManager.getEntriesById().values()) {\n      scannedDirectives++;\n      pce.clearBytesNeeded();\n      pce.clearBytesCached();\n      pce.clearFilesAffected();\n      String path \u003d pce.getPath();\n      INode node;\n      try {\n        node \u003d fsDir.getINode(path);\n      } catch (UnresolvedLinkException e) {\n        // We don\u0027t cache through symlinks\n        continue;\n      }\n      if (node \u003d\u003d null)  {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"No inode found at \" + path);\n        }\n      } else if (node.isDirectory()) {\n        INodeDirectory dir \u003d node.asDirectory();\n        ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n        for (INode child : children) {\n          if (child.isFile()) {\n            rescanFile(pce, child.asFile());\n          }\n        }\n      } else if (node.isFile()) {\n        rescanFile(pce, node.asFile());\n      } else {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                    \" found at \" + path);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java",
      "extendedDetails": {}
    },
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 3:15 PM",
      "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthor": "Colin McCabe",
      "diff": "@@ -0,0 +1,34 @@\n+  private void rescanPathBasedCacheEntries() {\n+    FSDirectory fsDir \u003d namesystem.getFSDirectory();\n+    for (PathBasedCacheEntry pce : cacheManager.getEntriesById().values()) {\n+      scannedDirectives++;\n+      String path \u003d pce.getPath();\n+      INode node;\n+      try {\n+        node \u003d fsDir.getINode(path);\n+      } catch (UnresolvedLinkException e) {\n+        // We don\u0027t cache through symlinks\n+        continue;\n+      }\n+      if (node \u003d\u003d null)  {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"No inode found at \" + path);\n+        }\n+      } else if (node.isDirectory()) {\n+        INodeDirectory dir \u003d node.asDirectory();\n+        ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n+        for (INode child : children) {\n+          if (child.isFile()) {\n+            rescanFile(pce, child.asFile());\n+          }\n+        }\n+      } else if (node.isFile()) {\n+        rescanFile(pce, node.asFile());\n+      } else {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n+                    \" found at \" + path);\n+        }\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void rescanPathBasedCacheEntries() {\n    FSDirectory fsDir \u003d namesystem.getFSDirectory();\n    for (PathBasedCacheEntry pce : cacheManager.getEntriesById().values()) {\n      scannedDirectives++;\n      String path \u003d pce.getPath();\n      INode node;\n      try {\n        node \u003d fsDir.getINode(path);\n      } catch (UnresolvedLinkException e) {\n        // We don\u0027t cache through symlinks\n        continue;\n      }\n      if (node \u003d\u003d null)  {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"No inode found at \" + path);\n        }\n      } else if (node.isDirectory()) {\n        INodeDirectory dir \u003d node.asDirectory();\n        ReadOnlyList\u003cINode\u003e children \u003d dir.getChildrenList(null);\n        for (INode child : children) {\n          if (child.isFile()) {\n            rescanFile(pce, child.asFile());\n          }\n        }\n      } else if (node.isFile()) {\n        rescanFile(pce, node.asFile());\n      } else {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Ignoring non-directory, non-file inode \" + node +\n                    \" found at \" + path);\n        }\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/CacheReplicationMonitor.java"
    }
  }
}