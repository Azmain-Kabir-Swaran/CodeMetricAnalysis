{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3ARetryPolicy.java",
  "functionName": "getConfiguration",
  "functionId": "getConfiguration",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ARetryPolicy.java",
  "functionStartLine": 265,
  "functionEndLine": 267,
  "numCommitsSeen": 10,
  "timeTaken": 1470,
  "changeHistory": [
    "9221704f857e33a5f9e00c19d3705e46e94f427b"
  ],
  "changeHistoryShort": {
    "9221704f857e33a5f9e00c19d3705e46e94f427b": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9221704f857e33a5f9e00c19d3705e46e94f427b": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-16490. Avoid/handle cached 404s during S3A file creation.\n\nContributed by Steve Loughran.\n\nThis patch avoids issuing any HEAD path request when creating a file with overwrite\u003dtrue,\nso 404s will not end up in the S3 load balancers unless someone calls getFileStatus/exists/isFile\nin their own code.\n\nThe Hadoop FsShell CommandWithDestination class is modified to not register uncreated files\nfor deleteOnExit(), because that calls exists() and so can place the 404 in the cache, even\nafter S3A is patched to not do it itself.\n\nBecause S3Guard knows when a file should be present, it adds a special FileNotFound retry policy\nindependently configurable from other retry policies; it is also exponential, but with\ndifferent parameters. This is because every HEAD request will refresh any 404 cached in\nthe S3 Load Balancers. It\u0027s not enough to retry: we have to have a suitable gap between\nattempts to (hopefully) ensure any cached entry wil be gone.\n\nThe options and values are:\n\nfs.s3a.s3guard.consistency.retry.interval: 2s\nfs.s3a.s3guard.consistency.retry.limit: 7\n\nThe S3A copy() method used during rename() raises a RemoteFileChangedException which is not caught\nso not downgraded to false. Thus: when a rename is unrecoverable, this fact is propagated.\n\nCopy operations without S3Guard lack the confidence that the file exists, so don\u0027t retry the same way:\nit will fail fast with a different error message. However, because create(path, overwrite\u003dfalse) no\nlonger does HEAD path, we can at least be confident that S3A itself is not creating those cached\n404 markers.\n\nChange-Id: Ia7807faad8b9a8546836cb19f816cccf17cca26d\n",
      "commitDate": "11/09/19 8:46 AM",
      "commitName": "9221704f857e33a5f9e00c19d3705e46e94f427b",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,3 @@\n+  protected Configuration getConfiguration() {\n+    return configuration;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected Configuration getConfiguration() {\n    return configuration;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ARetryPolicy.java"
    }
  }
}