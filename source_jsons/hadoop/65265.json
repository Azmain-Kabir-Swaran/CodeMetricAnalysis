{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3ABlockOutputStream.java",
  "functionName": "createBlockIfNeeded",
  "functionId": "createBlockIfNeeded",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
  "functionStartLine": 183,
  "functionEndLine": 194,
  "numCommitsSeen": 10,
  "timeTaken": 1169,
  "changeHistory": [
    "dab00da19f25619ccc71c7f803a235b21766bf1e",
    "6c348c56918973fd988b110e79231324a8befe12"
  ],
  "changeHistoryShort": {
    "dab00da19f25619ccc71c7f803a235b21766bf1e": "Ybodychange",
    "6c348c56918973fd988b110e79231324a8befe12": "Yintroduced"
  },
  "changeHistoryDetails": {
    "dab00da19f25619ccc71c7f803a235b21766bf1e": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14028. S3A BlockOutputStreams doesn\u0027t delete temporary files in multipart uploads or handle part upload failures.\nContributed by Steve Loughran.\n\n(cherry picked from commit 29fe5af017b945d8750c074ca39031b5b777eddd)\n",
      "commitDate": "25/02/17 7:35 AM",
      "commitName": "dab00da19f25619ccc71c7f803a235b21766bf1e",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "11/02/17 1:59 PM",
      "commitNameOld": "839b690ed5edc2ac4984640d58c005bb63cd8a07",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 13.73,
      "commitsBetweenForRepo": 86,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   private synchronized S3ADataBlocks.DataBlock createBlockIfNeeded()\n       throws IOException {\n     if (activeBlock \u003d\u003d null) {\n       blockCount++;\n       if (blockCount\u003e\u003d Constants.MAX_MULTIPART_COUNT) {\n-        LOG.error(\"Number of partitions in stream exceeds limit for S3: \" +\n+        LOG.error(\"Number of partitions in stream exceeds limit for S3: \"\n              + Constants.MAX_MULTIPART_COUNT +  \" write may fail.\");\n       }\n-      activeBlock \u003d blockFactory.create(this.blockSize);\n+      activeBlock \u003d blockFactory.create(blockCount, this.blockSize, statistics);\n     }\n     return activeBlock;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized S3ADataBlocks.DataBlock createBlockIfNeeded()\n      throws IOException {\n    if (activeBlock \u003d\u003d null) {\n      blockCount++;\n      if (blockCount\u003e\u003d Constants.MAX_MULTIPART_COUNT) {\n        LOG.error(\"Number of partitions in stream exceeds limit for S3: \"\n             + Constants.MAX_MULTIPART_COUNT +  \" write may fail.\");\n      }\n      activeBlock \u003d blockFactory.create(blockCount, this.blockSize, statistics);\n    }\n    return activeBlock;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
      "extendedDetails": {}
    },
    "6c348c56918973fd988b110e79231324a8befe12": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-13560. S3ABlockOutputStream to support huge (many GB) file writes. Contributed by Steve Loughran\n",
      "commitDate": "18/10/16 1:16 PM",
      "commitName": "6c348c56918973fd988b110e79231324a8befe12",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,12 @@\n+  private synchronized S3ADataBlocks.DataBlock createBlockIfNeeded()\n+      throws IOException {\n+    if (activeBlock \u003d\u003d null) {\n+      blockCount++;\n+      if (blockCount\u003e\u003d Constants.MAX_MULTIPART_COUNT) {\n+        LOG.error(\"Number of partitions in stream exceeds limit for S3: \" +\n+             + Constants.MAX_MULTIPART_COUNT +  \" write may fail.\");\n+      }\n+      activeBlock \u003d blockFactory.create(this.blockSize);\n+    }\n+    return activeBlock;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized S3ADataBlocks.DataBlock createBlockIfNeeded()\n      throws IOException {\n    if (activeBlock \u003d\u003d null) {\n      blockCount++;\n      if (blockCount\u003e\u003d Constants.MAX_MULTIPART_COUNT) {\n        LOG.error(\"Number of partitions in stream exceeds limit for S3: \" +\n             + Constants.MAX_MULTIPART_COUNT +  \" write may fail.\");\n      }\n      activeBlock \u003d blockFactory.create(this.blockSize);\n    }\n    return activeBlock;\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java"
    }
  }
}