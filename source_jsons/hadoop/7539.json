{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NameNode.java",
  "functionName": "startCommonServices",
  "functionId": "startCommonServices___conf-Configuration",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
  "functionStartLine": 861,
  "functionEndLine": 894,
  "numCommitsSeen": 210,
  "timeTaken": 5512,
  "changeHistory": [
    "8fc0d04517912766a3102f3e611f7d0fabd2f815",
    "859bd159ae554174200334b5eb1d7e8dbef958ad",
    "b4564103e4709caa1135f6ccc2864d90e54f2ac9",
    "dc17bda4b677e30c02c2a9a053895a43e41f7a12",
    "da8e962e39bd41b73b53966826c82e741b08010b",
    "a8e4bb81b2e7c5c79273ef3ceb1af86ae8e4cd68"
  ],
  "changeHistoryShort": {
    "8fc0d04517912766a3102f3e611f7d0fabd2f815": "Ybodychange",
    "859bd159ae554174200334b5eb1d7e8dbef958ad": "Ybodychange",
    "b4564103e4709caa1135f6ccc2864d90e54f2ac9": "Ybodychange",
    "dc17bda4b677e30c02c2a9a053895a43e41f7a12": "Ybodychange",
    "da8e962e39bd41b73b53966826c82e741b08010b": "Ybodychange",
    "a8e4bb81b2e7c5c79273ef3ceb1af86ae8e4cd68": "Ybodychange"
  },
  "changeHistoryDetails": {
    "8fc0d04517912766a3102f3e611f7d0fabd2f815": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14001. [PROVIDED Storage] bootstrapStandby should manage the InMemoryAliasMap. Contributed by Virajith Jalaparti.\n",
      "commitDate": "07/12/18 6:30 PM",
      "commitName": "8fc0d04517912766a3102f3e611f7d0fabd2f815",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "30/10/18 10:43 PM",
      "commitNameOld": "fac9f91b2944cee641049fffcafa6b65e0cf68f2",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 37.87,
      "commitsBetweenForRepo": 257,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,34 @@\n   private void startCommonServices(Configuration conf) throws IOException {\n     namesystem.startCommonServices(conf, haContext);\n     registerNNSMXBean();\n     if (NamenodeRole.NAMENODE !\u003d role) {\n       startHttpServer(conf);\n       httpServer.setNameNodeAddress(getNameNodeAddress());\n       httpServer.setFSImage(getFSImage());\n+      if (levelDBAliasMapServer !\u003d null) {\n+        httpServer.setAliasMap(levelDBAliasMapServer.getAliasMap());\n+      }\n     }\n     rpcServer.start();\n     try {\n       plugins \u003d conf.getInstances(DFS_NAMENODE_PLUGINS_KEY,\n           ServicePlugin.class);\n     } catch (RuntimeException e) {\n       String pluginsValue \u003d conf.get(DFS_NAMENODE_PLUGINS_KEY);\n       LOG.error(\"Unable to load NameNode plugins. Specified list of plugins: \" +\n           pluginsValue, e);\n       throw e;\n     }\n     for (ServicePlugin p: plugins) {\n       try {\n         p.start(this);\n       } catch (Throwable t) {\n         LOG.warn(\"ServicePlugin \" + p + \" could not be started\", t);\n       }\n     }\n     LOG.info(getRole() + \" RPC up at: \" + getNameNodeAddress());\n     if (rpcServer.getServiceRpcAddress() !\u003d null) {\n       LOG.info(getRole() + \" service RPC up at: \"\n           + rpcServer.getServiceRpcAddress());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startCommonServices(Configuration conf) throws IOException {\n    namesystem.startCommonServices(conf, haContext);\n    registerNNSMXBean();\n    if (NamenodeRole.NAMENODE !\u003d role) {\n      startHttpServer(conf);\n      httpServer.setNameNodeAddress(getNameNodeAddress());\n      httpServer.setFSImage(getFSImage());\n      if (levelDBAliasMapServer !\u003d null) {\n        httpServer.setAliasMap(levelDBAliasMapServer.getAliasMap());\n      }\n    }\n    rpcServer.start();\n    try {\n      plugins \u003d conf.getInstances(DFS_NAMENODE_PLUGINS_KEY,\n          ServicePlugin.class);\n    } catch (RuntimeException e) {\n      String pluginsValue \u003d conf.get(DFS_NAMENODE_PLUGINS_KEY);\n      LOG.error(\"Unable to load NameNode plugins. Specified list of plugins: \" +\n          pluginsValue, e);\n      throw e;\n    }\n    for (ServicePlugin p: plugins) {\n      try {\n        p.start(this);\n      } catch (Throwable t) {\n        LOG.warn(\"ServicePlugin \" + p + \" could not be started\", t);\n      }\n    }\n    LOG.info(getRole() + \" RPC up at: \" + getNameNodeAddress());\n    if (rpcServer.getServiceRpcAddress() !\u003d null) {\n      LOG.info(getRole() + \" service RPC up at: \"\n          + rpcServer.getServiceRpcAddress());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "859bd159ae554174200334b5eb1d7e8dbef958ad": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11333. Print a user friendly error message when plugins are not found. Contributed by Wei-Chiu Chuang.\n",
      "commitDate": "15/02/17 2:50 AM",
      "commitName": "859bd159ae554174200334b5eb1d7e8dbef958ad",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "14/02/17 11:53 PM",
      "commitNameOld": "8acb376c9c5f7f52a097be221ed18877a403bece",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 0.12,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,31 @@\n   private void startCommonServices(Configuration conf) throws IOException {\n     namesystem.startCommonServices(conf, haContext);\n     registerNNSMXBean();\n     if (NamenodeRole.NAMENODE !\u003d role) {\n       startHttpServer(conf);\n       httpServer.setNameNodeAddress(getNameNodeAddress());\n       httpServer.setFSImage(getFSImage());\n     }\n     rpcServer.start();\n-    plugins \u003d conf.getInstances(DFS_NAMENODE_PLUGINS_KEY,\n-        ServicePlugin.class);\n+    try {\n+      plugins \u003d conf.getInstances(DFS_NAMENODE_PLUGINS_KEY,\n+          ServicePlugin.class);\n+    } catch (RuntimeException e) {\n+      String pluginsValue \u003d conf.get(DFS_NAMENODE_PLUGINS_KEY);\n+      LOG.error(\"Unable to load NameNode plugins. Specified list of plugins: \" +\n+          pluginsValue, e);\n+      throw e;\n+    }\n     for (ServicePlugin p: plugins) {\n       try {\n         p.start(this);\n       } catch (Throwable t) {\n         LOG.warn(\"ServicePlugin \" + p + \" could not be started\", t);\n       }\n     }\n     LOG.info(getRole() + \" RPC up at: \" + getNameNodeAddress());\n     if (rpcServer.getServiceRpcAddress() !\u003d null) {\n       LOG.info(getRole() + \" service RPC up at: \"\n           + rpcServer.getServiceRpcAddress());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startCommonServices(Configuration conf) throws IOException {\n    namesystem.startCommonServices(conf, haContext);\n    registerNNSMXBean();\n    if (NamenodeRole.NAMENODE !\u003d role) {\n      startHttpServer(conf);\n      httpServer.setNameNodeAddress(getNameNodeAddress());\n      httpServer.setFSImage(getFSImage());\n    }\n    rpcServer.start();\n    try {\n      plugins \u003d conf.getInstances(DFS_NAMENODE_PLUGINS_KEY,\n          ServicePlugin.class);\n    } catch (RuntimeException e) {\n      String pluginsValue \u003d conf.get(DFS_NAMENODE_PLUGINS_KEY);\n      LOG.error(\"Unable to load NameNode plugins. Specified list of plugins: \" +\n          pluginsValue, e);\n      throw e;\n    }\n    for (ServicePlugin p: plugins) {\n      try {\n        p.start(this);\n      } catch (Throwable t) {\n        LOG.warn(\"ServicePlugin \" + p + \" could not be started\", t);\n      }\n    }\n    LOG.info(getRole() + \" RPC up at: \" + getNameNodeAddress());\n    if (rpcServer.getServiceRpcAddress() !\u003d null) {\n      LOG.info(getRole() + \" service RPC up at: \"\n          + rpcServer.getServiceRpcAddress());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "b4564103e4709caa1135f6ccc2864d90e54f2ac9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10752. Several log refactoring/improvement suggestion in HDFS. Contributed by Hanisha Koneru.\n",
      "commitDate": "19/10/16 5:20 PM",
      "commitName": "b4564103e4709caa1135f6ccc2864d90e54f2ac9",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "12/10/16 1:11 PM",
      "commitNameOld": "85cd06f6636f295ad1f3bf2a90063f4714c9cca7",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 7.17,
      "commitsBetweenForRepo": 51,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,24 @@\n   private void startCommonServices(Configuration conf) throws IOException {\n     namesystem.startCommonServices(conf, haContext);\n     registerNNSMXBean();\n     if (NamenodeRole.NAMENODE !\u003d role) {\n       startHttpServer(conf);\n       httpServer.setNameNodeAddress(getNameNodeAddress());\n       httpServer.setFSImage(getFSImage());\n     }\n     rpcServer.start();\n     plugins \u003d conf.getInstances(DFS_NAMENODE_PLUGINS_KEY,\n         ServicePlugin.class);\n     for (ServicePlugin p: plugins) {\n       try {\n         p.start(this);\n       } catch (Throwable t) {\n         LOG.warn(\"ServicePlugin \" + p + \" could not be started\", t);\n       }\n     }\n-    LOG.info(getRole() + \" RPC up at: \" + rpcServer.getRpcAddress());\n+    LOG.info(getRole() + \" RPC up at: \" + getNameNodeAddress());\n     if (rpcServer.getServiceRpcAddress() !\u003d null) {\n       LOG.info(getRole() + \" service RPC up at: \"\n           + rpcServer.getServiceRpcAddress());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startCommonServices(Configuration conf) throws IOException {\n    namesystem.startCommonServices(conf, haContext);\n    registerNNSMXBean();\n    if (NamenodeRole.NAMENODE !\u003d role) {\n      startHttpServer(conf);\n      httpServer.setNameNodeAddress(getNameNodeAddress());\n      httpServer.setFSImage(getFSImage());\n    }\n    rpcServer.start();\n    plugins \u003d conf.getInstances(DFS_NAMENODE_PLUGINS_KEY,\n        ServicePlugin.class);\n    for (ServicePlugin p: plugins) {\n      try {\n        p.start(this);\n      } catch (Throwable t) {\n        LOG.warn(\"ServicePlugin \" + p + \" could not be started\", t);\n      }\n    }\n    LOG.info(getRole() + \" RPC up at: \" + getNameNodeAddress());\n    if (rpcServer.getServiceRpcAddress() !\u003d null) {\n      LOG.info(getRole() + \" service RPC up at: \"\n          + rpcServer.getServiceRpcAddress());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "dc17bda4b677e30c02c2a9a053895a43e41f7a12": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5004. Add additional JMX bean for NameNode status data. Contributed by Trevor Lorimer.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1507530 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "26/07/13 4:59 PM",
      "commitName": "dc17bda4b677e30c02c2a9a053895a43e41f7a12",
      "commitAuthor": "Konstantin Boudnik",
      "commitDateOld": "20/07/13 9:22 AM",
      "commitNameOld": "313dd0250543177752ebbad7f7f6a6bcf3a8ab42",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 6.32,
      "commitsBetweenForRepo": 44,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,24 @@\n   private void startCommonServices(Configuration conf) throws IOException {\n     namesystem.startCommonServices(conf, haContext);\n+    registerNNSMXBean();\n     if (NamenodeRole.NAMENODE !\u003d role) {\n       startHttpServer(conf);\n       httpServer.setNameNodeAddress(getNameNodeAddress());\n       httpServer.setFSImage(getFSImage());\n     }\n     rpcServer.start();\n     plugins \u003d conf.getInstances(DFS_NAMENODE_PLUGINS_KEY,\n         ServicePlugin.class);\n     for (ServicePlugin p: plugins) {\n       try {\n         p.start(this);\n       } catch (Throwable t) {\n         LOG.warn(\"ServicePlugin \" + p + \" could not be started\", t);\n       }\n     }\n     LOG.info(getRole() + \" RPC up at: \" + rpcServer.getRpcAddress());\n     if (rpcServer.getServiceRpcAddress() !\u003d null) {\n       LOG.info(getRole() + \" service RPC up at: \"\n           + rpcServer.getServiceRpcAddress());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startCommonServices(Configuration conf) throws IOException {\n    namesystem.startCommonServices(conf, haContext);\n    registerNNSMXBean();\n    if (NamenodeRole.NAMENODE !\u003d role) {\n      startHttpServer(conf);\n      httpServer.setNameNodeAddress(getNameNodeAddress());\n      httpServer.setFSImage(getFSImage());\n    }\n    rpcServer.start();\n    plugins \u003d conf.getInstances(DFS_NAMENODE_PLUGINS_KEY,\n        ServicePlugin.class);\n    for (ServicePlugin p: plugins) {\n      try {\n        p.start(this);\n      } catch (Throwable t) {\n        LOG.warn(\"ServicePlugin \" + p + \" could not be started\", t);\n      }\n    }\n    LOG.info(getRole() + \" RPC up at: \" + rpcServer.getRpcAddress());\n    if (rpcServer.getServiceRpcAddress() !\u003d null) {\n      LOG.info(getRole() + \" service RPC up at: \"\n          + rpcServer.getServiceRpcAddress());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "da8e962e39bd41b73b53966826c82e741b08010b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4372. Track NameNode startup progress. Contributed by Chris Nauroth.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1502120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/07/13 10:35 PM",
      "commitName": "da8e962e39bd41b73b53966826c82e741b08010b",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "22/04/13 6:18 PM",
      "commitNameOld": "fd24c6e83357d4d3c937e112328a1eb378327eb0",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 79.18,
      "commitsBetweenForRepo": 494,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,23 @@\n   private void startCommonServices(Configuration conf) throws IOException {\n     namesystem.startCommonServices(conf, haContext);\n-    startHttpServer(conf);\n+    if (NamenodeRole.NAMENODE !\u003d role) {\n+      startHttpServer(conf);\n+      httpServer.setNameNodeAddress(getNameNodeAddress());\n+      httpServer.setFSImage(getFSImage());\n+    }\n     rpcServer.start();\n     plugins \u003d conf.getInstances(DFS_NAMENODE_PLUGINS_KEY,\n         ServicePlugin.class);\n     for (ServicePlugin p: plugins) {\n       try {\n         p.start(this);\n       } catch (Throwable t) {\n         LOG.warn(\"ServicePlugin \" + p + \" could not be started\", t);\n       }\n     }\n     LOG.info(getRole() + \" RPC up at: \" + rpcServer.getRpcAddress());\n     if (rpcServer.getServiceRpcAddress() !\u003d null) {\n       LOG.info(getRole() + \" service RPC up at: \"\n           + rpcServer.getServiceRpcAddress());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startCommonServices(Configuration conf) throws IOException {\n    namesystem.startCommonServices(conf, haContext);\n    if (NamenodeRole.NAMENODE !\u003d role) {\n      startHttpServer(conf);\n      httpServer.setNameNodeAddress(getNameNodeAddress());\n      httpServer.setFSImage(getFSImage());\n    }\n    rpcServer.start();\n    plugins \u003d conf.getInstances(DFS_NAMENODE_PLUGINS_KEY,\n        ServicePlugin.class);\n    for (ServicePlugin p: plugins) {\n      try {\n        p.start(this);\n      } catch (Throwable t) {\n        LOG.warn(\"ServicePlugin \" + p + \" could not be started\", t);\n      }\n    }\n    LOG.info(getRole() + \" RPC up at: \" + rpcServer.getRpcAddress());\n    if (rpcServer.getServiceRpcAddress() !\u003d null) {\n      LOG.info(getRole() + \" service RPC up at: \"\n          + rpcServer.getServiceRpcAddress());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "a8e4bb81b2e7c5c79273ef3ceb1af86ae8e4cd68": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3939. NN RPC address cleanup. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1387278 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/09/12 10:42 AM",
      "commitName": "a8e4bb81b2e7c5c79273ef3ceb1af86ae8e4cd68",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "01/09/12 12:22 PM",
      "commitNameOld": "54e612bfb9f877e58f7f153c43cb4147876826d3",
      "commitAuthorOld": "Harsh J",
      "daysBetweenCommits": 16.93,
      "commitsBetweenForRepo": 84,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n   private void startCommonServices(Configuration conf) throws IOException {\n     namesystem.startCommonServices(conf, haContext);\n     startHttpServer(conf);\n     rpcServer.start();\n     plugins \u003d conf.getInstances(DFS_NAMENODE_PLUGINS_KEY,\n         ServicePlugin.class);\n     for (ServicePlugin p: plugins) {\n       try {\n         p.start(this);\n       } catch (Throwable t) {\n         LOG.warn(\"ServicePlugin \" + p + \" could not be started\", t);\n       }\n     }\n-    LOG.info(getRole() + \" up at: \" + rpcServer.getRpcAddress());\n+    LOG.info(getRole() + \" RPC up at: \" + rpcServer.getRpcAddress());\n     if (rpcServer.getServiceRpcAddress() !\u003d null) {\n-      LOG.info(getRole() + \" service server is up at: \"\n+      LOG.info(getRole() + \" service RPC up at: \"\n           + rpcServer.getServiceRpcAddress());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startCommonServices(Configuration conf) throws IOException {\n    namesystem.startCommonServices(conf, haContext);\n    startHttpServer(conf);\n    rpcServer.start();\n    plugins \u003d conf.getInstances(DFS_NAMENODE_PLUGINS_KEY,\n        ServicePlugin.class);\n    for (ServicePlugin p: plugins) {\n      try {\n        p.start(this);\n      } catch (Throwable t) {\n        LOG.warn(\"ServicePlugin \" + p + \" could not be started\", t);\n      }\n    }\n    LOG.info(getRole() + \" RPC up at: \" + rpcServer.getRpcAddress());\n    if (rpcServer.getServiceRpcAddress() !\u003d null) {\n      LOG.info(getRole() + \" service RPC up at: \"\n          + rpcServer.getServiceRpcAddress());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    }
  }
}