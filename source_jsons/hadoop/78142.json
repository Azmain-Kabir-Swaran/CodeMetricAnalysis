{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Command.java",
  "functionName": "displayError",
  "functionId": "displayError___e-Exception",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Command.java",
  "functionStartLine": 454,
  "functionEndLine": 473,
  "numCommitsSeen": 29,
  "timeTaken": 1671,
  "changeHistory": [
    "9221704f857e33a5f9e00c19d3705e46e94f427b",
    "3c373405e0bfc9ac3cca1f1bc02dbcd63e756056",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
    "a65753ddac34a114c51cb0010ee39a9af48b4f9e"
  ],
  "changeHistoryShort": {
    "9221704f857e33a5f9e00c19d3705e46e94f427b": "Ybodychange",
    "3c373405e0bfc9ac3cca1f1bc02dbcd63e756056": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yfilerename",
    "a65753ddac34a114c51cb0010ee39a9af48b4f9e": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9221704f857e33a5f9e00c19d3705e46e94f427b": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16490. Avoid/handle cached 404s during S3A file creation.\n\nContributed by Steve Loughran.\n\nThis patch avoids issuing any HEAD path request when creating a file with overwrite\u003dtrue,\nso 404s will not end up in the S3 load balancers unless someone calls getFileStatus/exists/isFile\nin their own code.\n\nThe Hadoop FsShell CommandWithDestination class is modified to not register uncreated files\nfor deleteOnExit(), because that calls exists() and so can place the 404 in the cache, even\nafter S3A is patched to not do it itself.\n\nBecause S3Guard knows when a file should be present, it adds a special FileNotFound retry policy\nindependently configurable from other retry policies; it is also exponential, but with\ndifferent parameters. This is because every HEAD request will refresh any 404 cached in\nthe S3 Load Balancers. It\u0027s not enough to retry: we have to have a suitable gap between\nattempts to (hopefully) ensure any cached entry wil be gone.\n\nThe options and values are:\n\nfs.s3a.s3guard.consistency.retry.interval: 2s\nfs.s3a.s3guard.consistency.retry.limit: 7\n\nThe S3A copy() method used during rename() raises a RemoteFileChangedException which is not caught\nso not downgraded to false. Thus: when a rename is unrecoverable, this fact is propagated.\n\nCopy operations without S3Guard lack the confidence that the file exists, so don\u0027t retry the same way:\nit will fail fast with a different error message. However, because create(path, overwrite\u003dfalse) no\nlonger does HEAD path, we can at least be confident that S3A itself is not creating those cached\n404 markers.\n\nChange-Id: Ia7807faad8b9a8546836cb19f816cccf17cca26d\n",
      "commitDate": "11/09/19 8:46 AM",
      "commitName": "9221704f857e33a5f9e00c19d3705e46e94f427b",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "10/10/18 9:51 PM",
      "commitNameOld": "7b57f2f71fbaa5af4897309597cca70a95b04edd",
      "commitAuthorOld": "Takanobu Asanuma",
      "daysBetweenCommits": 335.45,
      "commitsBetweenForRepo": 2557,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n   public void displayError(Exception e) {\n     // build up a list of exceptions that occurred\n     exceptions.add(e);\n     // use runtime so it rips up through the stack and exits out \n     if (e instanceof InterruptedIOException) {\n       throw new CommandInterruptException();\n     }\n-    \n+    LOG.debug(\"{} failure\", getName(), e);\n     String errorMessage \u003d e.getLocalizedMessage();\n     if (errorMessage \u003d\u003d null) {\n       // this is an unexpected condition, so dump the whole exception since\n       // it\u0027s probably a nasty internal error where the backtrace would be\n       // useful\n       errorMessage \u003d StringUtils.stringifyException(e);\n       LOG.debug(errorMessage);\n     } else {\n       errorMessage \u003d errorMessage.split(\"\\n\", 2)[0];\n     }\n     displayError(errorMessage);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void displayError(Exception e) {\n    // build up a list of exceptions that occurred\n    exceptions.add(e);\n    // use runtime so it rips up through the stack and exits out \n    if (e instanceof InterruptedIOException) {\n      throw new CommandInterruptException();\n    }\n    LOG.debug(\"{} failure\", getName(), e);\n    String errorMessage \u003d e.getLocalizedMessage();\n    if (errorMessage \u003d\u003d null) {\n      // this is an unexpected condition, so dump the whole exception since\n      // it\u0027s probably a nasty internal error where the backtrace would be\n      // useful\n      errorMessage \u003d StringUtils.stringifyException(e);\n      LOG.debug(errorMessage);\n    } else {\n      errorMessage \u003d errorMessage.split(\"\\n\", 2)[0];\n    }\n    displayError(errorMessage);\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Command.java",
      "extendedDetails": {}
    },
    "3c373405e0bfc9ac3cca1f1bc02dbcd63e756056": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-8146.  FsShell commands cannot be interrupted. Contributed by Daryn Shar\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1298976 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/03/12 10:48 AM",
      "commitName": "3c373405e0bfc9ac3cca1f1bc02dbcd63e756056",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "31/10/11 6:50 PM",
      "commitNameOld": "8f9661da4823bfbb243e430252ec1bb5780ecbfc",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 129.71,
      "commitsBetweenForRepo": 892,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,20 @@\n   public void displayError(Exception e) {\n     // build up a list of exceptions that occurred\n     exceptions.add(e);\n+    // use runtime so it rips up through the stack and exits out \n+    if (e instanceof InterruptedIOException) {\n+      throw new CommandInterruptException();\n+    }\n     \n     String errorMessage \u003d e.getLocalizedMessage();\n     if (errorMessage \u003d\u003d null) {\n       // this is an unexpected condition, so dump the whole exception since\n       // it\u0027s probably a nasty internal error where the backtrace would be\n       // useful\n       errorMessage \u003d StringUtils.stringifyException(e);\n       LOG.debug(errorMessage);\n     } else {\n       errorMessage \u003d errorMessage.split(\"\\n\", 2)[0];\n     }\n     displayError(errorMessage);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void displayError(Exception e) {\n    // build up a list of exceptions that occurred\n    exceptions.add(e);\n    // use runtime so it rips up through the stack and exits out \n    if (e instanceof InterruptedIOException) {\n      throw new CommandInterruptException();\n    }\n    \n    String errorMessage \u003d e.getLocalizedMessage();\n    if (errorMessage \u003d\u003d null) {\n      // this is an unexpected condition, so dump the whole exception since\n      // it\u0027s probably a nasty internal error where the backtrace would be\n      // useful\n      errorMessage \u003d StringUtils.stringifyException(e);\n      LOG.debug(errorMessage);\n    } else {\n      errorMessage \u003d errorMessage.split(\"\\n\", 2)[0];\n    }\n    displayError(errorMessage);\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Command.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void displayError(Exception e) {\n    // build up a list of exceptions that occurred\n    exceptions.add(e);\n    \n    String errorMessage \u003d e.getLocalizedMessage();\n    if (errorMessage \u003d\u003d null) {\n      // this is an unexpected condition, so dump the whole exception since\n      // it\u0027s probably a nasty internal error where the backtrace would be\n      // useful\n      errorMessage \u003d StringUtils.stringifyException(e);\n      LOG.debug(errorMessage);\n    } else {\n      errorMessage \u003d errorMessage.split(\"\\n\", 2)[0];\n    }\n    displayError(errorMessage);\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Command.java",
      "extendedDetails": {
        "oldPath": "hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Command.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Command.java"
      }
    },
    "0f6dfeeacbab65a31a33927a4eb84871d371fe52": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-6671. Use maven for hadoop common builds. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1153184 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "02/08/11 9:37 AM",
      "commitName": "0f6dfeeacbab65a31a33927a4eb84871d371fe52",
      "commitAuthor": "Thomas White",
      "commitDateOld": "01/08/11 3:53 PM",
      "commitNameOld": "9bac807cedbcff34e1a144fb475eff267e5ed86d",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void displayError(Exception e) {\n    // build up a list of exceptions that occurred\n    exceptions.add(e);\n    \n    String errorMessage \u003d e.getLocalizedMessage();\n    if (errorMessage \u003d\u003d null) {\n      // this is an unexpected condition, so dump the whole exception since\n      // it\u0027s probably a nasty internal error where the backtrace would be\n      // useful\n      errorMessage \u003d StringUtils.stringifyException(e);\n      LOG.debug(errorMessage);\n    } else {\n      errorMessage \u003d errorMessage.split(\"\\n\", 2)[0];\n    }\n    displayError(errorMessage);\n  }",
      "path": "hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Command.java",
      "extendedDetails": {
        "oldPath": "common/src/java/org/apache/hadoop/fs/shell/Command.java",
        "newPath": "hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Command.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "11/06/11 9:13 PM",
      "commitNameOld": "a285fb5effe9ba3be4ec5f942afaf5ddd1186151",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.74,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void displayError(Exception e) {\n    // build up a list of exceptions that occurred\n    exceptions.add(e);\n    \n    String errorMessage \u003d e.getLocalizedMessage();\n    if (errorMessage \u003d\u003d null) {\n      // this is an unexpected condition, so dump the whole exception since\n      // it\u0027s probably a nasty internal error where the backtrace would be\n      // useful\n      errorMessage \u003d StringUtils.stringifyException(e);\n      LOG.debug(errorMessage);\n    } else {\n      errorMessage \u003d errorMessage.split(\"\\n\", 2)[0];\n    }\n    displayError(errorMessage);\n  }",
      "path": "common/src/java/org/apache/hadoop/fs/shell/Command.java",
      "extendedDetails": {
        "oldPath": "src/java/org/apache/hadoop/fs/shell/Command.java",
        "newPath": "common/src/java/org/apache/hadoop/fs/shell/Command.java"
      }
    },
    "a65753ddac34a114c51cb0010ee39a9af48b4f9e": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7202. Improve shell Command base class.  Contributed by Daryn Sharp\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1090039 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/04/11 2:59 PM",
      "commitName": "a65753ddac34a114c51cb0010ee39a9af48b4f9e",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,16 @@\n+  public void displayError(Exception e) {\n+    // build up a list of exceptions that occurred\n+    exceptions.add(e);\n+    \n+    String errorMessage \u003d e.getLocalizedMessage();\n+    if (errorMessage \u003d\u003d null) {\n+      // this is an unexpected condition, so dump the whole exception since\n+      // it\u0027s probably a nasty internal error where the backtrace would be\n+      // useful\n+      errorMessage \u003d StringUtils.stringifyException(e);\n+      LOG.debug(errorMessage);\n+    } else {\n+      errorMessage \u003d errorMessage.split(\"\\n\", 2)[0];\n+    }\n+    displayError(errorMessage);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void displayError(Exception e) {\n    // build up a list of exceptions that occurred\n    exceptions.add(e);\n    \n    String errorMessage \u003d e.getLocalizedMessage();\n    if (errorMessage \u003d\u003d null) {\n      // this is an unexpected condition, so dump the whole exception since\n      // it\u0027s probably a nasty internal error where the backtrace would be\n      // useful\n      errorMessage \u003d StringUtils.stringifyException(e);\n      LOG.debug(errorMessage);\n    } else {\n      errorMessage \u003d errorMessage.split(\"\\n\", 2)[0];\n    }\n    displayError(errorMessage);\n  }",
      "path": "src/java/org/apache/hadoop/fs/shell/Command.java"
    }
  }
}