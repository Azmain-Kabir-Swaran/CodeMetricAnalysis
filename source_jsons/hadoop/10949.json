{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DirectoryScanner.java",
  "functionName": "scan",
  "functionId": "scan",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
  "functionStartLine": 459,
  "functionEndLine": 558,
  "numCommitsSeen": 60,
  "timeTaken": 9185,
  "changeHistory": [
    "ecd461f940efcd8c75f4833cf09bc7a52cc0b559",
    "1dc0adfac0ee4821c67366728c70be9b59477b0f",
    "6df606f1b4edabd15ae2896c5df0fe675bcf0138",
    "b668eb91556b8c85c2b4925808ccb1f769031c20",
    "9e03ee527988ff85af7f2c224c5570b69d09279a",
    "96b12662ea76e3ded4ef13944fc8df206cfb4613",
    "86c9862bec0248d671e657aa56094a2919b8ac14",
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c",
    "7a3c381b39887a02e944fa98287afd0eb4db3560",
    "6dae6d12ec5abb716e1501cd4e18b10ae7809b94",
    "9f22fb8c9a10952225e15c7b67b5f77fa44b155d",
    "b9d561c548c26d0db4994e6c13c7ebf43705d794",
    "bf3271bd2b3b347a94e00f145e55aa08baa69437",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "ecd461f940efcd8c75f4833cf09bc7a52cc0b559": "Ybodychange",
    "1dc0adfac0ee4821c67366728c70be9b59477b0f": "Ybodychange",
    "6df606f1b4edabd15ae2896c5df0fe675bcf0138": "Ybodychange",
    "b668eb91556b8c85c2b4925808ccb1f769031c20": "Ybodychange",
    "9e03ee527988ff85af7f2c224c5570b69d09279a": "Ybodychange",
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": "Ybodychange",
    "86c9862bec0248d671e657aa56094a2919b8ac14": "Ybodychange",
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c": "Ybodychange",
    "7a3c381b39887a02e944fa98287afd0eb4db3560": "Ymodifierchange",
    "6dae6d12ec5abb716e1501cd4e18b10ae7809b94": "Ybodychange",
    "9f22fb8c9a10952225e15c7b67b5f77fa44b155d": "Ybodychange",
    "b9d561c548c26d0db4994e6c13c7ebf43705d794": "Ybodychange",
    "bf3271bd2b3b347a94e00f145e55aa08baa69437": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "ecd461f940efcd8c75f4833cf09bc7a52cc0b559": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14751. Synchronize on diffs in DirectoryScanner. Contributed by Lisheng Sun.\n",
      "commitDate": "06/12/19 3:10 PM",
      "commitName": "ecd461f940efcd8c75f4833cf09bc7a52cc0b559",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "06/12/19 3:10 PM",
      "commitNameOld": "313b76f8e92643e3412a98dc73f83437729f3984",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,98 +1,100 @@\n   private void scan() {\n     BlockPoolReport blockPoolReport \u003d new BlockPoolReport();\n \n     clear();\n \n     Collection\u003cScanInfoVolumeReport\u003e volumeReports \u003d getVolumeReports();\n     for (ScanInfoVolumeReport volumeReport : volumeReports) {\n       for (String blockPoolId : volumeReport.getBlockPoolIds()) {\n         List\u003cScanInfo\u003e scanInfos \u003d volumeReport.getScanInfo(blockPoolId);\n         blockPoolReport.addAll(blockPoolId, scanInfos);\n       }\n     }\n \n     // Pre-sort the reports outside of the lock\n     blockPoolReport.sortBlocks();\n \n     // Hold FSDataset lock to prevent further changes to the block map\n     try (AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n       for (final String bpid : blockPoolReport.getBlockPoolIds()) {\n         List\u003cScanInfo\u003e blockpoolReport \u003d blockPoolReport.getScanInfo(bpid);\n \n         Stats statsRecord \u003d new Stats(bpid);\n         stats.put(bpid, statsRecord);\n         Collection\u003cScanInfo\u003e diffRecord \u003d new ArrayList\u003c\u003e();\n \n         statsRecord.totalBlocks \u003d blockpoolReport.size();\n         final List\u003cReplicaInfo\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n         Collections.sort(bl); // Sort based on blockId\n \n         int d \u003d 0; // index for blockpoolReport\n         int m \u003d 0; // index for memReprot\n         while (m \u003c bl.size() \u0026\u0026 d \u003c blockpoolReport.size()) {\n           ReplicaInfo memBlock \u003d bl.get(m);\n           ScanInfo info \u003d blockpoolReport.get(d);\n           if (info.getBlockId() \u003c memBlock.getBlockId()) {\n             if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n               // Block is missing in memory\n               statsRecord.missingMemoryBlocks++;\n               addDifference(diffRecord, statsRecord, info);\n             }\n             d++;\n             continue;\n           }\n           if (info.getBlockId() \u003e memBlock.getBlockId()) {\n             // Block is missing on the disk\n             addDifference(diffRecord, statsRecord, memBlock.getBlockId(),\n                 info.getVolume());\n             m++;\n             continue;\n           }\n           // Block file and/or metadata file exists on the disk\n           // Block exists in memory\n           if (info.getVolume().getStorageType() !\u003d StorageType.PROVIDED\n               \u0026\u0026 info.getBlockFile() \u003d\u003d null) {\n             // Block metadata file exits and block file is missing\n             addDifference(diffRecord, statsRecord, info);\n           } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n               || info.getBlockLength() !\u003d memBlock.getNumBytes()) {\n             // Block metadata file is missing or has wrong generation stamp,\n             // or block file length is different than expected\n             statsRecord.mismatchBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           } else if (memBlock.compareWith(info) !\u003d 0) {\n             // volumeMap record and on-disk files do not match.\n             statsRecord.duplicateBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           }\n           d++;\n \n           if (d \u003c blockpoolReport.size()) {\n             // There may be multiple on-disk records for the same block, do not\n             // increment the memory record pointer if so.\n             ScanInfo nextInfo \u003d blockpoolReport.get(d);\n             if (nextInfo.getBlockId() !\u003d info.getBlockId()) {\n               ++m;\n             }\n           } else {\n             ++m;\n           }\n         }\n         while (m \u003c bl.size()) {\n           ReplicaInfo current \u003d bl.get(m++);\n           addDifference(diffRecord, statsRecord, current.getBlockId(),\n               current.getVolume());\n         }\n         while (d \u003c blockpoolReport.size()) {\n           if (!dataset.isDeletingBlock(bpid,\n               blockpoolReport.get(d).getBlockId())) {\n             statsRecord.missingMemoryBlocks++;\n             addDifference(diffRecord, statsRecord, blockpoolReport.get(d));\n           }\n           d++;\n         }\n-        diffs.addAll(bpid, diffRecord);\n+        synchronized (diffs) {\n+          diffs.addAll(bpid, diffRecord);\n+        }\n         LOG.info(\"Scan Results: {}\", statsRecord);\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void scan() {\n    BlockPoolReport blockPoolReport \u003d new BlockPoolReport();\n\n    clear();\n\n    Collection\u003cScanInfoVolumeReport\u003e volumeReports \u003d getVolumeReports();\n    for (ScanInfoVolumeReport volumeReport : volumeReports) {\n      for (String blockPoolId : volumeReport.getBlockPoolIds()) {\n        List\u003cScanInfo\u003e scanInfos \u003d volumeReport.getScanInfo(blockPoolId);\n        blockPoolReport.addAll(blockPoolId, scanInfos);\n      }\n    }\n\n    // Pre-sort the reports outside of the lock\n    blockPoolReport.sortBlocks();\n\n    // Hold FSDataset lock to prevent further changes to the block map\n    try (AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n      for (final String bpid : blockPoolReport.getBlockPoolIds()) {\n        List\u003cScanInfo\u003e blockpoolReport \u003d blockPoolReport.getScanInfo(bpid);\n\n        Stats statsRecord \u003d new Stats(bpid);\n        stats.put(bpid, statsRecord);\n        Collection\u003cScanInfo\u003e diffRecord \u003d new ArrayList\u003c\u003e();\n\n        statsRecord.totalBlocks \u003d blockpoolReport.size();\n        final List\u003cReplicaInfo\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n        Collections.sort(bl); // Sort based on blockId\n\n        int d \u003d 0; // index for blockpoolReport\n        int m \u003d 0; // index for memReprot\n        while (m \u003c bl.size() \u0026\u0026 d \u003c blockpoolReport.size()) {\n          ReplicaInfo memBlock \u003d bl.get(m);\n          ScanInfo info \u003d blockpoolReport.get(d);\n          if (info.getBlockId() \u003c memBlock.getBlockId()) {\n            if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n              // Block is missing in memory\n              statsRecord.missingMemoryBlocks++;\n              addDifference(diffRecord, statsRecord, info);\n            }\n            d++;\n            continue;\n          }\n          if (info.getBlockId() \u003e memBlock.getBlockId()) {\n            // Block is missing on the disk\n            addDifference(diffRecord, statsRecord, memBlock.getBlockId(),\n                info.getVolume());\n            m++;\n            continue;\n          }\n          // Block file and/or metadata file exists on the disk\n          // Block exists in memory\n          if (info.getVolume().getStorageType() !\u003d StorageType.PROVIDED\n              \u0026\u0026 info.getBlockFile() \u003d\u003d null) {\n            // Block metadata file exits and block file is missing\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n              || info.getBlockLength() !\u003d memBlock.getNumBytes()) {\n            // Block metadata file is missing or has wrong generation stamp,\n            // or block file length is different than expected\n            statsRecord.mismatchBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          } else if (memBlock.compareWith(info) !\u003d 0) {\n            // volumeMap record and on-disk files do not match.\n            statsRecord.duplicateBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          }\n          d++;\n\n          if (d \u003c blockpoolReport.size()) {\n            // There may be multiple on-disk records for the same block, do not\n            // increment the memory record pointer if so.\n            ScanInfo nextInfo \u003d blockpoolReport.get(d);\n            if (nextInfo.getBlockId() !\u003d info.getBlockId()) {\n              ++m;\n            }\n          } else {\n            ++m;\n          }\n        }\n        while (m \u003c bl.size()) {\n          ReplicaInfo current \u003d bl.get(m++);\n          addDifference(diffRecord, statsRecord, current.getBlockId(),\n              current.getVolume());\n        }\n        while (d \u003c blockpoolReport.size()) {\n          if (!dataset.isDeletingBlock(bpid,\n              blockpoolReport.get(d).getBlockId())) {\n            statsRecord.missingMemoryBlocks++;\n            addDifference(diffRecord, statsRecord, blockpoolReport.get(d));\n          }\n          d++;\n        }\n        synchronized (diffs) {\n          diffs.addAll(bpid, diffRecord);\n        }\n        LOG.info(\"Scan Results: {}\", statsRecord);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "1dc0adfac0ee4821c67366728c70be9b59477b0f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13947. Review of DirectoryScanner Class. Contributed by BELUGA BEHR.\n",
      "commitDate": "03/10/18 11:19 AM",
      "commitName": "1dc0adfac0ee4821c67366728c70be9b59477b0f",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "06/09/18 2:48 PM",
      "commitNameOld": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 26.86,
      "commitsBetweenForRepo": 283,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,98 @@\n   private void scan() {\n+    BlockPoolReport blockPoolReport \u003d new BlockPoolReport();\n+\n     clear();\n-    Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n+\n+    Collection\u003cScanInfoVolumeReport\u003e volumeReports \u003d getVolumeReports();\n+    for (ScanInfoVolumeReport volumeReport : volumeReports) {\n+      for (String blockPoolId : volumeReport.getBlockPoolIds()) {\n+        List\u003cScanInfo\u003e scanInfos \u003d volumeReport.getScanInfo(blockPoolId);\n+        blockPoolReport.addAll(blockPoolId, scanInfos);\n+      }\n+    }\n+\n+    // Pre-sort the reports outside of the lock\n+    blockPoolReport.sortBlocks();\n \n     // Hold FSDataset lock to prevent further changes to the block map\n-    try(AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n-      for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n-        String bpid \u003d entry.getKey();\n-        ScanInfo[] blockpoolReport \u003d entry.getValue();\n-        \n+    try (AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n+      for (final String bpid : blockPoolReport.getBlockPoolIds()) {\n+        List\u003cScanInfo\u003e blockpoolReport \u003d blockPoolReport.getScanInfo(bpid);\n+\n         Stats statsRecord \u003d new Stats(bpid);\n         stats.put(bpid, statsRecord);\n-        LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n-        diffs.put(bpid, diffRecord);\n-        \n-        statsRecord.totalBlocks \u003d blockpoolReport.length;\n+        Collection\u003cScanInfo\u003e diffRecord \u003d new ArrayList\u003c\u003e();\n+\n+        statsRecord.totalBlocks \u003d blockpoolReport.size();\n         final List\u003cReplicaInfo\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n         Collections.sort(bl); // Sort based on blockId\n-  \n+\n         int d \u003d 0; // index for blockpoolReport\n         int m \u003d 0; // index for memReprot\n-        while (m \u003c bl.size() \u0026\u0026 d \u003c blockpoolReport.length) {\n+        while (m \u003c bl.size() \u0026\u0026 d \u003c blockpoolReport.size()) {\n           ReplicaInfo memBlock \u003d bl.get(m);\n-          ScanInfo info \u003d blockpoolReport[d];\n+          ScanInfo info \u003d blockpoolReport.get(d);\n           if (info.getBlockId() \u003c memBlock.getBlockId()) {\n             if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n               // Block is missing in memory\n               statsRecord.missingMemoryBlocks++;\n               addDifference(diffRecord, statsRecord, info);\n             }\n             d++;\n             continue;\n           }\n           if (info.getBlockId() \u003e memBlock.getBlockId()) {\n             // Block is missing on the disk\n-            addDifference(diffRecord, statsRecord,\n-                          memBlock.getBlockId(), info.getVolume());\n+            addDifference(diffRecord, statsRecord, memBlock.getBlockId(),\n+                info.getVolume());\n             m++;\n             continue;\n           }\n           // Block file and/or metadata file exists on the disk\n           // Block exists in memory\n-          if (info.getVolume().getStorageType() !\u003d StorageType.PROVIDED \u0026\u0026\n-              info.getBlockFile() \u003d\u003d null) {\n+          if (info.getVolume().getStorageType() !\u003d StorageType.PROVIDED\n+              \u0026\u0026 info.getBlockFile() \u003d\u003d null) {\n             // Block metadata file exits and block file is missing\n             addDifference(diffRecord, statsRecord, info);\n           } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n               || info.getBlockLength() !\u003d memBlock.getNumBytes()) {\n             // Block metadata file is missing or has wrong generation stamp,\n             // or block file length is different than expected\n             statsRecord.mismatchBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           } else if (memBlock.compareWith(info) !\u003d 0) {\n-            // volumeMap record and on-disk files don\u0027t match.\n+            // volumeMap record and on-disk files do not match.\n             statsRecord.duplicateBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           }\n           d++;\n \n-          if (d \u003c blockpoolReport.length) {\n-            // There may be multiple on-disk records for the same block, don\u0027t increment\n-            // the memory record pointer if so.\n-            ScanInfo nextInfo \u003d blockpoolReport[d];\n+          if (d \u003c blockpoolReport.size()) {\n+            // There may be multiple on-disk records for the same block, do not\n+            // increment the memory record pointer if so.\n+            ScanInfo nextInfo \u003d blockpoolReport.get(d);\n             if (nextInfo.getBlockId() !\u003d info.getBlockId()) {\n               ++m;\n             }\n           } else {\n             ++m;\n           }\n         }\n         while (m \u003c bl.size()) {\n           ReplicaInfo current \u003d bl.get(m++);\n-          addDifference(diffRecord, statsRecord,\n-                        current.getBlockId(), current.getVolume());\n+          addDifference(diffRecord, statsRecord, current.getBlockId(),\n+              current.getVolume());\n         }\n-        while (d \u003c blockpoolReport.length) {\n-          if (!dataset.isDeletingBlock(bpid, blockpoolReport[d].getBlockId())) {\n+        while (d \u003c blockpoolReport.size()) {\n+          if (!dataset.isDeletingBlock(bpid,\n+              blockpoolReport.get(d).getBlockId())) {\n             statsRecord.missingMemoryBlocks++;\n-            addDifference(diffRecord, statsRecord, blockpoolReport[d]);\n+            addDifference(diffRecord, statsRecord, blockpoolReport.get(d));\n           }\n           d++;\n         }\n-        LOG.info(statsRecord.toString());\n-      } //end for\n-    } //end synchronized\n+        diffs.addAll(bpid, diffRecord);\n+        LOG.info(\"Scan Results: {}\", statsRecord);\n+      }\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void scan() {\n    BlockPoolReport blockPoolReport \u003d new BlockPoolReport();\n\n    clear();\n\n    Collection\u003cScanInfoVolumeReport\u003e volumeReports \u003d getVolumeReports();\n    for (ScanInfoVolumeReport volumeReport : volumeReports) {\n      for (String blockPoolId : volumeReport.getBlockPoolIds()) {\n        List\u003cScanInfo\u003e scanInfos \u003d volumeReport.getScanInfo(blockPoolId);\n        blockPoolReport.addAll(blockPoolId, scanInfos);\n      }\n    }\n\n    // Pre-sort the reports outside of the lock\n    blockPoolReport.sortBlocks();\n\n    // Hold FSDataset lock to prevent further changes to the block map\n    try (AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n      for (final String bpid : blockPoolReport.getBlockPoolIds()) {\n        List\u003cScanInfo\u003e blockpoolReport \u003d blockPoolReport.getScanInfo(bpid);\n\n        Stats statsRecord \u003d new Stats(bpid);\n        stats.put(bpid, statsRecord);\n        Collection\u003cScanInfo\u003e diffRecord \u003d new ArrayList\u003c\u003e();\n\n        statsRecord.totalBlocks \u003d blockpoolReport.size();\n        final List\u003cReplicaInfo\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n        Collections.sort(bl); // Sort based on blockId\n\n        int d \u003d 0; // index for blockpoolReport\n        int m \u003d 0; // index for memReprot\n        while (m \u003c bl.size() \u0026\u0026 d \u003c blockpoolReport.size()) {\n          ReplicaInfo memBlock \u003d bl.get(m);\n          ScanInfo info \u003d blockpoolReport.get(d);\n          if (info.getBlockId() \u003c memBlock.getBlockId()) {\n            if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n              // Block is missing in memory\n              statsRecord.missingMemoryBlocks++;\n              addDifference(diffRecord, statsRecord, info);\n            }\n            d++;\n            continue;\n          }\n          if (info.getBlockId() \u003e memBlock.getBlockId()) {\n            // Block is missing on the disk\n            addDifference(diffRecord, statsRecord, memBlock.getBlockId(),\n                info.getVolume());\n            m++;\n            continue;\n          }\n          // Block file and/or metadata file exists on the disk\n          // Block exists in memory\n          if (info.getVolume().getStorageType() !\u003d StorageType.PROVIDED\n              \u0026\u0026 info.getBlockFile() \u003d\u003d null) {\n            // Block metadata file exits and block file is missing\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n              || info.getBlockLength() !\u003d memBlock.getNumBytes()) {\n            // Block metadata file is missing or has wrong generation stamp,\n            // or block file length is different than expected\n            statsRecord.mismatchBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          } else if (memBlock.compareWith(info) !\u003d 0) {\n            // volumeMap record and on-disk files do not match.\n            statsRecord.duplicateBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          }\n          d++;\n\n          if (d \u003c blockpoolReport.size()) {\n            // There may be multiple on-disk records for the same block, do not\n            // increment the memory record pointer if so.\n            ScanInfo nextInfo \u003d blockpoolReport.get(d);\n            if (nextInfo.getBlockId() !\u003d info.getBlockId()) {\n              ++m;\n            }\n          } else {\n            ++m;\n          }\n        }\n        while (m \u003c bl.size()) {\n          ReplicaInfo current \u003d bl.get(m++);\n          addDifference(diffRecord, statsRecord, current.getBlockId(),\n              current.getVolume());\n        }\n        while (d \u003c blockpoolReport.size()) {\n          if (!dataset.isDeletingBlock(bpid,\n              blockpoolReport.get(d).getBlockId())) {\n            statsRecord.missingMemoryBlocks++;\n            addDifference(diffRecord, statsRecord, blockpoolReport.get(d));\n          }\n          d++;\n        }\n        diffs.addAll(bpid, diffRecord);\n        LOG.info(\"Scan Results: {}\", statsRecord);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "6df606f1b4edabd15ae2896c5df0fe675bcf0138": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13829. Remove redundant condition judgement in DirectoryScanner#scan. Contributed by liaoyuxiangqin.\n",
      "commitDate": "16/08/18 3:44 AM",
      "commitName": "6df606f1b4edabd15ae2896c5df0fe675bcf0138",
      "commitAuthor": "Yiqun Lin",
      "commitDateOld": "18/06/18 10:17 AM",
      "commitNameOld": "fba9d7cd746cd7b659d2fd9d2bfa23266be9009b",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 58.73,
      "commitsBetweenForRepo": 424,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,86 @@\n   private void scan() {\n     clear();\n     Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n \n     // Hold FSDataset lock to prevent further changes to the block map\n     try(AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n       for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n         String bpid \u003d entry.getKey();\n         ScanInfo[] blockpoolReport \u003d entry.getValue();\n         \n         Stats statsRecord \u003d new Stats(bpid);\n         stats.put(bpid, statsRecord);\n         LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n         diffs.put(bpid, diffRecord);\n         \n         statsRecord.totalBlocks \u003d blockpoolReport.length;\n         final List\u003cReplicaInfo\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n         Collections.sort(bl); // Sort based on blockId\n   \n         int d \u003d 0; // index for blockpoolReport\n         int m \u003d 0; // index for memReprot\n         while (m \u003c bl.size() \u0026\u0026 d \u003c blockpoolReport.length) {\n           ReplicaInfo memBlock \u003d bl.get(m);\n           ScanInfo info \u003d blockpoolReport[d];\n           if (info.getBlockId() \u003c memBlock.getBlockId()) {\n             if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n               // Block is missing in memory\n               statsRecord.missingMemoryBlocks++;\n               addDifference(diffRecord, statsRecord, info);\n             }\n             d++;\n             continue;\n           }\n           if (info.getBlockId() \u003e memBlock.getBlockId()) {\n             // Block is missing on the disk\n             addDifference(diffRecord, statsRecord,\n                           memBlock.getBlockId(), info.getVolume());\n             m++;\n             continue;\n           }\n           // Block file and/or metadata file exists on the disk\n           // Block exists in memory\n           if (info.getVolume().getStorageType() !\u003d StorageType.PROVIDED \u0026\u0026\n               info.getBlockFile() \u003d\u003d null) {\n             // Block metadata file exits and block file is missing\n             addDifference(diffRecord, statsRecord, info);\n           } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n               || info.getBlockLength() !\u003d memBlock.getNumBytes()) {\n             // Block metadata file is missing or has wrong generation stamp,\n             // or block file length is different than expected\n             statsRecord.mismatchBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           } else if (memBlock.compareWith(info) !\u003d 0) {\n             // volumeMap record and on-disk files don\u0027t match.\n             statsRecord.duplicateBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           }\n           d++;\n \n           if (d \u003c blockpoolReport.length) {\n             // There may be multiple on-disk records for the same block, don\u0027t increment\n             // the memory record pointer if so.\n-            ScanInfo nextInfo \u003d blockpoolReport[Math.min(d, blockpoolReport.length - 1)];\n+            ScanInfo nextInfo \u003d blockpoolReport[d];\n             if (nextInfo.getBlockId() !\u003d info.getBlockId()) {\n               ++m;\n             }\n           } else {\n             ++m;\n           }\n         }\n         while (m \u003c bl.size()) {\n           ReplicaInfo current \u003d bl.get(m++);\n           addDifference(diffRecord, statsRecord,\n                         current.getBlockId(), current.getVolume());\n         }\n         while (d \u003c blockpoolReport.length) {\n           if (!dataset.isDeletingBlock(bpid, blockpoolReport[d].getBlockId())) {\n             statsRecord.missingMemoryBlocks++;\n             addDifference(diffRecord, statsRecord, blockpoolReport[d]);\n           }\n           d++;\n         }\n         LOG.info(statsRecord.toString());\n       } //end for\n     } //end synchronized\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void scan() {\n    clear();\n    Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n\n    // Hold FSDataset lock to prevent further changes to the block map\n    try(AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n      for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n        String bpid \u003d entry.getKey();\n        ScanInfo[] blockpoolReport \u003d entry.getValue();\n        \n        Stats statsRecord \u003d new Stats(bpid);\n        stats.put(bpid, statsRecord);\n        LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n        diffs.put(bpid, diffRecord);\n        \n        statsRecord.totalBlocks \u003d blockpoolReport.length;\n        final List\u003cReplicaInfo\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n        Collections.sort(bl); // Sort based on blockId\n  \n        int d \u003d 0; // index for blockpoolReport\n        int m \u003d 0; // index for memReprot\n        while (m \u003c bl.size() \u0026\u0026 d \u003c blockpoolReport.length) {\n          ReplicaInfo memBlock \u003d bl.get(m);\n          ScanInfo info \u003d blockpoolReport[d];\n          if (info.getBlockId() \u003c memBlock.getBlockId()) {\n            if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n              // Block is missing in memory\n              statsRecord.missingMemoryBlocks++;\n              addDifference(diffRecord, statsRecord, info);\n            }\n            d++;\n            continue;\n          }\n          if (info.getBlockId() \u003e memBlock.getBlockId()) {\n            // Block is missing on the disk\n            addDifference(diffRecord, statsRecord,\n                          memBlock.getBlockId(), info.getVolume());\n            m++;\n            continue;\n          }\n          // Block file and/or metadata file exists on the disk\n          // Block exists in memory\n          if (info.getVolume().getStorageType() !\u003d StorageType.PROVIDED \u0026\u0026\n              info.getBlockFile() \u003d\u003d null) {\n            // Block metadata file exits and block file is missing\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n              || info.getBlockLength() !\u003d memBlock.getNumBytes()) {\n            // Block metadata file is missing or has wrong generation stamp,\n            // or block file length is different than expected\n            statsRecord.mismatchBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          } else if (memBlock.compareWith(info) !\u003d 0) {\n            // volumeMap record and on-disk files don\u0027t match.\n            statsRecord.duplicateBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          }\n          d++;\n\n          if (d \u003c blockpoolReport.length) {\n            // There may be multiple on-disk records for the same block, don\u0027t increment\n            // the memory record pointer if so.\n            ScanInfo nextInfo \u003d blockpoolReport[d];\n            if (nextInfo.getBlockId() !\u003d info.getBlockId()) {\n              ++m;\n            }\n          } else {\n            ++m;\n          }\n        }\n        while (m \u003c bl.size()) {\n          ReplicaInfo current \u003d bl.get(m++);\n          addDifference(diffRecord, statsRecord,\n                        current.getBlockId(), current.getVolume());\n        }\n        while (d \u003c blockpoolReport.length) {\n          if (!dataset.isDeletingBlock(bpid, blockpoolReport[d].getBlockId())) {\n            statsRecord.missingMemoryBlocks++;\n            addDifference(diffRecord, statsRecord, blockpoolReport[d]);\n          }\n          d++;\n        }\n        LOG.info(statsRecord.toString());\n      } //end for\n    } //end synchronized\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "b668eb91556b8c85c2b4925808ccb1f769031c20": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10675. Datanode support to read from external stores.\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "b668eb91556b8c85c2b4925808ccb1f769031c20",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "25/08/17 10:41 AM",
      "commitNameOld": "4b2c442d4e34f4708fa2ca442208427ca10798c1",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 112.34,
      "commitsBetweenForRepo": 958,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,85 +1,86 @@\n   private void scan() {\n     clear();\n     Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n \n     // Hold FSDataset lock to prevent further changes to the block map\n     try(AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n       for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n         String bpid \u003d entry.getKey();\n         ScanInfo[] blockpoolReport \u003d entry.getValue();\n         \n         Stats statsRecord \u003d new Stats(bpid);\n         stats.put(bpid, statsRecord);\n         LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n         diffs.put(bpid, diffRecord);\n         \n         statsRecord.totalBlocks \u003d blockpoolReport.length;\n         final List\u003cReplicaInfo\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n         Collections.sort(bl); // Sort based on blockId\n   \n         int d \u003d 0; // index for blockpoolReport\n         int m \u003d 0; // index for memReprot\n         while (m \u003c bl.size() \u0026\u0026 d \u003c blockpoolReport.length) {\n           ReplicaInfo memBlock \u003d bl.get(m);\n           ScanInfo info \u003d blockpoolReport[d];\n           if (info.getBlockId() \u003c memBlock.getBlockId()) {\n             if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n               // Block is missing in memory\n               statsRecord.missingMemoryBlocks++;\n               addDifference(diffRecord, statsRecord, info);\n             }\n             d++;\n             continue;\n           }\n           if (info.getBlockId() \u003e memBlock.getBlockId()) {\n             // Block is missing on the disk\n             addDifference(diffRecord, statsRecord,\n                           memBlock.getBlockId(), info.getVolume());\n             m++;\n             continue;\n           }\n           // Block file and/or metadata file exists on the disk\n           // Block exists in memory\n-          if (info.getBlockFile() \u003d\u003d null) {\n+          if (info.getVolume().getStorageType() !\u003d StorageType.PROVIDED \u0026\u0026\n+              info.getBlockFile() \u003d\u003d null) {\n             // Block metadata file exits and block file is missing\n             addDifference(diffRecord, statsRecord, info);\n           } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n-              || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n+              || info.getBlockLength() !\u003d memBlock.getNumBytes()) {\n             // Block metadata file is missing or has wrong generation stamp,\n             // or block file length is different than expected\n             statsRecord.mismatchBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           } else if (memBlock.compareWith(info) !\u003d 0) {\n             // volumeMap record and on-disk files don\u0027t match.\n             statsRecord.duplicateBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           }\n           d++;\n \n           if (d \u003c blockpoolReport.length) {\n             // There may be multiple on-disk records for the same block, don\u0027t increment\n             // the memory record pointer if so.\n             ScanInfo nextInfo \u003d blockpoolReport[Math.min(d, blockpoolReport.length - 1)];\n             if (nextInfo.getBlockId() !\u003d info.getBlockId()) {\n               ++m;\n             }\n           } else {\n             ++m;\n           }\n         }\n         while (m \u003c bl.size()) {\n           ReplicaInfo current \u003d bl.get(m++);\n           addDifference(diffRecord, statsRecord,\n                         current.getBlockId(), current.getVolume());\n         }\n         while (d \u003c blockpoolReport.length) {\n           if (!dataset.isDeletingBlock(bpid, blockpoolReport[d].getBlockId())) {\n             statsRecord.missingMemoryBlocks++;\n             addDifference(diffRecord, statsRecord, blockpoolReport[d]);\n           }\n           d++;\n         }\n         LOG.info(statsRecord.toString());\n       } //end for\n     } //end synchronized\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void scan() {\n    clear();\n    Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n\n    // Hold FSDataset lock to prevent further changes to the block map\n    try(AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n      for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n        String bpid \u003d entry.getKey();\n        ScanInfo[] blockpoolReport \u003d entry.getValue();\n        \n        Stats statsRecord \u003d new Stats(bpid);\n        stats.put(bpid, statsRecord);\n        LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n        diffs.put(bpid, diffRecord);\n        \n        statsRecord.totalBlocks \u003d blockpoolReport.length;\n        final List\u003cReplicaInfo\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n        Collections.sort(bl); // Sort based on blockId\n  \n        int d \u003d 0; // index for blockpoolReport\n        int m \u003d 0; // index for memReprot\n        while (m \u003c bl.size() \u0026\u0026 d \u003c blockpoolReport.length) {\n          ReplicaInfo memBlock \u003d bl.get(m);\n          ScanInfo info \u003d blockpoolReport[d];\n          if (info.getBlockId() \u003c memBlock.getBlockId()) {\n            if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n              // Block is missing in memory\n              statsRecord.missingMemoryBlocks++;\n              addDifference(diffRecord, statsRecord, info);\n            }\n            d++;\n            continue;\n          }\n          if (info.getBlockId() \u003e memBlock.getBlockId()) {\n            // Block is missing on the disk\n            addDifference(diffRecord, statsRecord,\n                          memBlock.getBlockId(), info.getVolume());\n            m++;\n            continue;\n          }\n          // Block file and/or metadata file exists on the disk\n          // Block exists in memory\n          if (info.getVolume().getStorageType() !\u003d StorageType.PROVIDED \u0026\u0026\n              info.getBlockFile() \u003d\u003d null) {\n            // Block metadata file exits and block file is missing\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n              || info.getBlockLength() !\u003d memBlock.getNumBytes()) {\n            // Block metadata file is missing or has wrong generation stamp,\n            // or block file length is different than expected\n            statsRecord.mismatchBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          } else if (memBlock.compareWith(info) !\u003d 0) {\n            // volumeMap record and on-disk files don\u0027t match.\n            statsRecord.duplicateBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          }\n          d++;\n\n          if (d \u003c blockpoolReport.length) {\n            // There may be multiple on-disk records for the same block, don\u0027t increment\n            // the memory record pointer if so.\n            ScanInfo nextInfo \u003d blockpoolReport[Math.min(d, blockpoolReport.length - 1)];\n            if (nextInfo.getBlockId() !\u003d info.getBlockId()) {\n              ++m;\n            }\n          } else {\n            ++m;\n          }\n        }\n        while (m \u003c bl.size()) {\n          ReplicaInfo current \u003d bl.get(m++);\n          addDifference(diffRecord, statsRecord,\n                        current.getBlockId(), current.getVolume());\n        }\n        while (d \u003c blockpoolReport.length) {\n          if (!dataset.isDeletingBlock(bpid, blockpoolReport[d].getBlockId())) {\n            statsRecord.missingMemoryBlocks++;\n            addDifference(diffRecord, statsRecord, blockpoolReport[d]);\n          }\n          d++;\n        }\n        LOG.info(statsRecord.toString());\n      } //end for\n    } //end synchronized\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "9e03ee527988ff85af7f2c224c5570b69d09279a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11047. Remove deep copies of FinalizedReplica to alleviate heap consumption on DataNode. Contributed by Xiaobing Zhou\n",
      "commitDate": "27/10/16 4:00 PM",
      "commitName": "9e03ee527988ff85af7f2c224c5570b69d09279a",
      "commitAuthor": "Mingliang Liu",
      "commitDateOld": "10/10/16 3:30 PM",
      "commitNameOld": "96b12662ea76e3ded4ef13944fc8df206cfb4613",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 17.02,
      "commitsBetweenForRepo": 162,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,85 @@\n   private void scan() {\n     clear();\n     Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n \n     // Hold FSDataset lock to prevent further changes to the block map\n     try(AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n       for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n         String bpid \u003d entry.getKey();\n         ScanInfo[] blockpoolReport \u003d entry.getValue();\n         \n         Stats statsRecord \u003d new Stats(bpid);\n         stats.put(bpid, statsRecord);\n         LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n         diffs.put(bpid, diffRecord);\n         \n         statsRecord.totalBlocks \u003d blockpoolReport.length;\n-        List\u003cReplicaInfo\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n-        ReplicaInfo[] memReport \u003d bl.toArray(new ReplicaInfo[bl.size()]);\n-        Arrays.sort(memReport); // Sort based on blockId\n+        final List\u003cReplicaInfo\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n+        Collections.sort(bl); // Sort based on blockId\n   \n         int d \u003d 0; // index for blockpoolReport\n         int m \u003d 0; // index for memReprot\n-        while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n-          ReplicaInfo memBlock \u003d memReport[m];\n+        while (m \u003c bl.size() \u0026\u0026 d \u003c blockpoolReport.length) {\n+          ReplicaInfo memBlock \u003d bl.get(m);\n           ScanInfo info \u003d blockpoolReport[d];\n           if (info.getBlockId() \u003c memBlock.getBlockId()) {\n             if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n               // Block is missing in memory\n               statsRecord.missingMemoryBlocks++;\n               addDifference(diffRecord, statsRecord, info);\n             }\n             d++;\n             continue;\n           }\n           if (info.getBlockId() \u003e memBlock.getBlockId()) {\n             // Block is missing on the disk\n             addDifference(diffRecord, statsRecord,\n                           memBlock.getBlockId(), info.getVolume());\n             m++;\n             continue;\n           }\n           // Block file and/or metadata file exists on the disk\n           // Block exists in memory\n           if (info.getBlockFile() \u003d\u003d null) {\n             // Block metadata file exits and block file is missing\n             addDifference(diffRecord, statsRecord, info);\n           } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n               || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n             // Block metadata file is missing or has wrong generation stamp,\n             // or block file length is different than expected\n             statsRecord.mismatchBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           } else if (memBlock.compareWith(info) !\u003d 0) {\n             // volumeMap record and on-disk files don\u0027t match.\n             statsRecord.duplicateBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           }\n           d++;\n \n           if (d \u003c blockpoolReport.length) {\n             // There may be multiple on-disk records for the same block, don\u0027t increment\n             // the memory record pointer if so.\n             ScanInfo nextInfo \u003d blockpoolReport[Math.min(d, blockpoolReport.length - 1)];\n             if (nextInfo.getBlockId() !\u003d info.getBlockId()) {\n               ++m;\n             }\n           } else {\n             ++m;\n           }\n         }\n-        while (m \u003c memReport.length) {\n-          ReplicaInfo current \u003d memReport[m++];\n+        while (m \u003c bl.size()) {\n+          ReplicaInfo current \u003d bl.get(m++);\n           addDifference(diffRecord, statsRecord,\n                         current.getBlockId(), current.getVolume());\n         }\n         while (d \u003c blockpoolReport.length) {\n           if (!dataset.isDeletingBlock(bpid, blockpoolReport[d].getBlockId())) {\n             statsRecord.missingMemoryBlocks++;\n             addDifference(diffRecord, statsRecord, blockpoolReport[d]);\n           }\n           d++;\n         }\n         LOG.info(statsRecord.toString());\n       } //end for\n     } //end synchronized\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void scan() {\n    clear();\n    Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n\n    // Hold FSDataset lock to prevent further changes to the block map\n    try(AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n      for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n        String bpid \u003d entry.getKey();\n        ScanInfo[] blockpoolReport \u003d entry.getValue();\n        \n        Stats statsRecord \u003d new Stats(bpid);\n        stats.put(bpid, statsRecord);\n        LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n        diffs.put(bpid, diffRecord);\n        \n        statsRecord.totalBlocks \u003d blockpoolReport.length;\n        final List\u003cReplicaInfo\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n        Collections.sort(bl); // Sort based on blockId\n  \n        int d \u003d 0; // index for blockpoolReport\n        int m \u003d 0; // index for memReprot\n        while (m \u003c bl.size() \u0026\u0026 d \u003c blockpoolReport.length) {\n          ReplicaInfo memBlock \u003d bl.get(m);\n          ScanInfo info \u003d blockpoolReport[d];\n          if (info.getBlockId() \u003c memBlock.getBlockId()) {\n            if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n              // Block is missing in memory\n              statsRecord.missingMemoryBlocks++;\n              addDifference(diffRecord, statsRecord, info);\n            }\n            d++;\n            continue;\n          }\n          if (info.getBlockId() \u003e memBlock.getBlockId()) {\n            // Block is missing on the disk\n            addDifference(diffRecord, statsRecord,\n                          memBlock.getBlockId(), info.getVolume());\n            m++;\n            continue;\n          }\n          // Block file and/or metadata file exists on the disk\n          // Block exists in memory\n          if (info.getBlockFile() \u003d\u003d null) {\n            // Block metadata file exits and block file is missing\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n              || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n            // Block metadata file is missing or has wrong generation stamp,\n            // or block file length is different than expected\n            statsRecord.mismatchBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          } else if (memBlock.compareWith(info) !\u003d 0) {\n            // volumeMap record and on-disk files don\u0027t match.\n            statsRecord.duplicateBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          }\n          d++;\n\n          if (d \u003c blockpoolReport.length) {\n            // There may be multiple on-disk records for the same block, don\u0027t increment\n            // the memory record pointer if so.\n            ScanInfo nextInfo \u003d blockpoolReport[Math.min(d, blockpoolReport.length - 1)];\n            if (nextInfo.getBlockId() !\u003d info.getBlockId()) {\n              ++m;\n            }\n          } else {\n            ++m;\n          }\n        }\n        while (m \u003c bl.size()) {\n          ReplicaInfo current \u003d bl.get(m++);\n          addDifference(diffRecord, statsRecord,\n                        current.getBlockId(), current.getVolume());\n        }\n        while (d \u003c blockpoolReport.length) {\n          if (!dataset.isDeletingBlock(bpid, blockpoolReport[d].getBlockId())) {\n            statsRecord.missingMemoryBlocks++;\n            addDifference(diffRecord, statsRecord, blockpoolReport[d]);\n          }\n          d++;\n        }\n        LOG.info(statsRecord.toString());\n      } //end for\n    } //end synchronized\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "96b12662ea76e3ded4ef13944fc8df206cfb4613": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10637. Modifications to remove the assumption that FsVolumes are backed by java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "10/10/16 3:30 PM",
      "commitName": "96b12662ea76e3ded4ef13944fc8df206cfb4613",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "13/09/16 12:54 PM",
      "commitNameOld": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 27.11,
      "commitsBetweenForRepo": 180,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,86 @@\n   private void scan() {\n     clear();\n     Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n \n     // Hold FSDataset lock to prevent further changes to the block map\n     try(AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n       for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n         String bpid \u003d entry.getKey();\n         ScanInfo[] blockpoolReport \u003d entry.getValue();\n         \n         Stats statsRecord \u003d new Stats(bpid);\n         stats.put(bpid, statsRecord);\n         LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n         diffs.put(bpid, diffRecord);\n         \n         statsRecord.totalBlocks \u003d blockpoolReport.length;\n         List\u003cReplicaInfo\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n         ReplicaInfo[] memReport \u003d bl.toArray(new ReplicaInfo[bl.size()]);\n         Arrays.sort(memReport); // Sort based on blockId\n   \n         int d \u003d 0; // index for blockpoolReport\n         int m \u003d 0; // index for memReprot\n         while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n           ReplicaInfo memBlock \u003d memReport[m];\n           ScanInfo info \u003d blockpoolReport[d];\n           if (info.getBlockId() \u003c memBlock.getBlockId()) {\n             if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n               // Block is missing in memory\n               statsRecord.missingMemoryBlocks++;\n               addDifference(diffRecord, statsRecord, info);\n             }\n             d++;\n             continue;\n           }\n           if (info.getBlockId() \u003e memBlock.getBlockId()) {\n             // Block is missing on the disk\n             addDifference(diffRecord, statsRecord,\n                           memBlock.getBlockId(), info.getVolume());\n             m++;\n             continue;\n           }\n           // Block file and/or metadata file exists on the disk\n           // Block exists in memory\n           if (info.getBlockFile() \u003d\u003d null) {\n             // Block metadata file exits and block file is missing\n             addDifference(diffRecord, statsRecord, info);\n           } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n               || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n             // Block metadata file is missing or has wrong generation stamp,\n             // or block file length is different than expected\n             statsRecord.mismatchBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           } else if (memBlock.compareWith(info) !\u003d 0) {\n             // volumeMap record and on-disk files don\u0027t match.\n             statsRecord.duplicateBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           }\n           d++;\n \n           if (d \u003c blockpoolReport.length) {\n             // There may be multiple on-disk records for the same block, don\u0027t increment\n             // the memory record pointer if so.\n             ScanInfo nextInfo \u003d blockpoolReport[Math.min(d, blockpoolReport.length - 1)];\n-            if (nextInfo.getBlockId() !\u003d info.blockId) {\n+            if (nextInfo.getBlockId() !\u003d info.getBlockId()) {\n               ++m;\n             }\n           } else {\n             ++m;\n           }\n         }\n         while (m \u003c memReport.length) {\n           ReplicaInfo current \u003d memReport[m++];\n           addDifference(diffRecord, statsRecord,\n                         current.getBlockId(), current.getVolume());\n         }\n         while (d \u003c blockpoolReport.length) {\n           if (!dataset.isDeletingBlock(bpid, blockpoolReport[d].getBlockId())) {\n             statsRecord.missingMemoryBlocks++;\n             addDifference(diffRecord, statsRecord, blockpoolReport[d]);\n           }\n           d++;\n         }\n         LOG.info(statsRecord.toString());\n       } //end for\n     } //end synchronized\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void scan() {\n    clear();\n    Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n\n    // Hold FSDataset lock to prevent further changes to the block map\n    try(AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n      for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n        String bpid \u003d entry.getKey();\n        ScanInfo[] blockpoolReport \u003d entry.getValue();\n        \n        Stats statsRecord \u003d new Stats(bpid);\n        stats.put(bpid, statsRecord);\n        LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n        diffs.put(bpid, diffRecord);\n        \n        statsRecord.totalBlocks \u003d blockpoolReport.length;\n        List\u003cReplicaInfo\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n        ReplicaInfo[] memReport \u003d bl.toArray(new ReplicaInfo[bl.size()]);\n        Arrays.sort(memReport); // Sort based on blockId\n  \n        int d \u003d 0; // index for blockpoolReport\n        int m \u003d 0; // index for memReprot\n        while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n          ReplicaInfo memBlock \u003d memReport[m];\n          ScanInfo info \u003d blockpoolReport[d];\n          if (info.getBlockId() \u003c memBlock.getBlockId()) {\n            if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n              // Block is missing in memory\n              statsRecord.missingMemoryBlocks++;\n              addDifference(diffRecord, statsRecord, info);\n            }\n            d++;\n            continue;\n          }\n          if (info.getBlockId() \u003e memBlock.getBlockId()) {\n            // Block is missing on the disk\n            addDifference(diffRecord, statsRecord,\n                          memBlock.getBlockId(), info.getVolume());\n            m++;\n            continue;\n          }\n          // Block file and/or metadata file exists on the disk\n          // Block exists in memory\n          if (info.getBlockFile() \u003d\u003d null) {\n            // Block metadata file exits and block file is missing\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n              || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n            // Block metadata file is missing or has wrong generation stamp,\n            // or block file length is different than expected\n            statsRecord.mismatchBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          } else if (memBlock.compareWith(info) !\u003d 0) {\n            // volumeMap record and on-disk files don\u0027t match.\n            statsRecord.duplicateBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          }\n          d++;\n\n          if (d \u003c blockpoolReport.length) {\n            // There may be multiple on-disk records for the same block, don\u0027t increment\n            // the memory record pointer if so.\n            ScanInfo nextInfo \u003d blockpoolReport[Math.min(d, blockpoolReport.length - 1)];\n            if (nextInfo.getBlockId() !\u003d info.getBlockId()) {\n              ++m;\n            }\n          } else {\n            ++m;\n          }\n        }\n        while (m \u003c memReport.length) {\n          ReplicaInfo current \u003d memReport[m++];\n          addDifference(diffRecord, statsRecord,\n                        current.getBlockId(), current.getVolume());\n        }\n        while (d \u003c blockpoolReport.length) {\n          if (!dataset.isDeletingBlock(bpid, blockpoolReport[d].getBlockId())) {\n            statsRecord.missingMemoryBlocks++;\n            addDifference(diffRecord, statsRecord, blockpoolReport[d]);\n          }\n          d++;\n        }\n        LOG.info(statsRecord.toString());\n      } //end for\n    } //end synchronized\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "86c9862bec0248d671e657aa56094a2919b8ac14": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10636. Modify ReplicaInfo to remove the assumption that replica metadata and data are stored in java.io.File. (Virajith Jalaparti via lei)\n",
      "commitDate": "13/09/16 12:54 PM",
      "commitName": "86c9862bec0248d671e657aa56094a2919b8ac14",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "06/09/16 10:38 AM",
      "commitNameOld": "d37dc5d1b8e022a7085118a2e7066623483c293f",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 7.09,
      "commitsBetweenForRepo": 42,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,86 @@\n   private void scan() {\n     clear();\n     Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n \n     // Hold FSDataset lock to prevent further changes to the block map\n     try(AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n       for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n         String bpid \u003d entry.getKey();\n         ScanInfo[] blockpoolReport \u003d entry.getValue();\n         \n         Stats statsRecord \u003d new Stats(bpid);\n         stats.put(bpid, statsRecord);\n         LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n         diffs.put(bpid, diffRecord);\n         \n         statsRecord.totalBlocks \u003d blockpoolReport.length;\n-        List\u003cFinalizedReplica\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n-        FinalizedReplica[] memReport \u003d bl.toArray(new FinalizedReplica[bl.size()]);\n+        List\u003cReplicaInfo\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n+        ReplicaInfo[] memReport \u003d bl.toArray(new ReplicaInfo[bl.size()]);\n         Arrays.sort(memReport); // Sort based on blockId\n   \n         int d \u003d 0; // index for blockpoolReport\n         int m \u003d 0; // index for memReprot\n         while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n-          FinalizedReplica memBlock \u003d memReport[m];\n+          ReplicaInfo memBlock \u003d memReport[m];\n           ScanInfo info \u003d blockpoolReport[d];\n           if (info.getBlockId() \u003c memBlock.getBlockId()) {\n             if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n               // Block is missing in memory\n               statsRecord.missingMemoryBlocks++;\n               addDifference(diffRecord, statsRecord, info);\n             }\n             d++;\n             continue;\n           }\n           if (info.getBlockId() \u003e memBlock.getBlockId()) {\n             // Block is missing on the disk\n             addDifference(diffRecord, statsRecord,\n                           memBlock.getBlockId(), info.getVolume());\n             m++;\n             continue;\n           }\n           // Block file and/or metadata file exists on the disk\n           // Block exists in memory\n           if (info.getBlockFile() \u003d\u003d null) {\n             // Block metadata file exits and block file is missing\n             addDifference(diffRecord, statsRecord, info);\n           } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n               || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n             // Block metadata file is missing or has wrong generation stamp,\n             // or block file length is different than expected\n             statsRecord.mismatchBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n-          } else if (info.getBlockFile().compareTo(memBlock.getBlockFile()) !\u003d 0) {\n+          } else if (memBlock.compareWith(info) !\u003d 0) {\n             // volumeMap record and on-disk files don\u0027t match.\n             statsRecord.duplicateBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           }\n           d++;\n \n           if (d \u003c blockpoolReport.length) {\n             // There may be multiple on-disk records for the same block, don\u0027t increment\n             // the memory record pointer if so.\n             ScanInfo nextInfo \u003d blockpoolReport[Math.min(d, blockpoolReport.length - 1)];\n             if (nextInfo.getBlockId() !\u003d info.blockId) {\n               ++m;\n             }\n           } else {\n             ++m;\n           }\n         }\n         while (m \u003c memReport.length) {\n-          FinalizedReplica current \u003d memReport[m++];\n+          ReplicaInfo current \u003d memReport[m++];\n           addDifference(diffRecord, statsRecord,\n                         current.getBlockId(), current.getVolume());\n         }\n         while (d \u003c blockpoolReport.length) {\n           if (!dataset.isDeletingBlock(bpid, blockpoolReport[d].getBlockId())) {\n             statsRecord.missingMemoryBlocks++;\n             addDifference(diffRecord, statsRecord, blockpoolReport[d]);\n           }\n           d++;\n         }\n         LOG.info(statsRecord.toString());\n       } //end for\n     } //end synchronized\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void scan() {\n    clear();\n    Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n\n    // Hold FSDataset lock to prevent further changes to the block map\n    try(AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n      for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n        String bpid \u003d entry.getKey();\n        ScanInfo[] blockpoolReport \u003d entry.getValue();\n        \n        Stats statsRecord \u003d new Stats(bpid);\n        stats.put(bpid, statsRecord);\n        LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n        diffs.put(bpid, diffRecord);\n        \n        statsRecord.totalBlocks \u003d blockpoolReport.length;\n        List\u003cReplicaInfo\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n        ReplicaInfo[] memReport \u003d bl.toArray(new ReplicaInfo[bl.size()]);\n        Arrays.sort(memReport); // Sort based on blockId\n  \n        int d \u003d 0; // index for blockpoolReport\n        int m \u003d 0; // index for memReprot\n        while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n          ReplicaInfo memBlock \u003d memReport[m];\n          ScanInfo info \u003d blockpoolReport[d];\n          if (info.getBlockId() \u003c memBlock.getBlockId()) {\n            if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n              // Block is missing in memory\n              statsRecord.missingMemoryBlocks++;\n              addDifference(diffRecord, statsRecord, info);\n            }\n            d++;\n            continue;\n          }\n          if (info.getBlockId() \u003e memBlock.getBlockId()) {\n            // Block is missing on the disk\n            addDifference(diffRecord, statsRecord,\n                          memBlock.getBlockId(), info.getVolume());\n            m++;\n            continue;\n          }\n          // Block file and/or metadata file exists on the disk\n          // Block exists in memory\n          if (info.getBlockFile() \u003d\u003d null) {\n            // Block metadata file exits and block file is missing\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n              || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n            // Block metadata file is missing or has wrong generation stamp,\n            // or block file length is different than expected\n            statsRecord.mismatchBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          } else if (memBlock.compareWith(info) !\u003d 0) {\n            // volumeMap record and on-disk files don\u0027t match.\n            statsRecord.duplicateBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          }\n          d++;\n\n          if (d \u003c blockpoolReport.length) {\n            // There may be multiple on-disk records for the same block, don\u0027t increment\n            // the memory record pointer if so.\n            ScanInfo nextInfo \u003d blockpoolReport[Math.min(d, blockpoolReport.length - 1)];\n            if (nextInfo.getBlockId() !\u003d info.blockId) {\n              ++m;\n            }\n          } else {\n            ++m;\n          }\n        }\n        while (m \u003c memReport.length) {\n          ReplicaInfo current \u003d memReport[m++];\n          addDifference(diffRecord, statsRecord,\n                        current.getBlockId(), current.getVolume());\n        }\n        while (d \u003c blockpoolReport.length) {\n          if (!dataset.isDeletingBlock(bpid, blockpoolReport[d].getBlockId())) {\n            statsRecord.missingMemoryBlocks++;\n            addDifference(diffRecord, statsRecord, blockpoolReport[d]);\n          }\n          d++;\n        }\n        LOG.info(statsRecord.toString());\n      } //end for\n    } //end synchronized\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10682. Replace FsDatasetImpl object lock with a separate lock object. (Chen Liang)\n",
      "commitDate": "08/08/16 12:02 PM",
      "commitName": "8c0638471f8f1dd47667b2d6727d4d2d54e4b48c",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "14/04/16 5:58 AM",
      "commitNameOld": "0d1c1152f1ce2706f92109bfbdff0d62e98e6797",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 116.25,
      "commitsBetweenForRepo": 888,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,86 @@\n   private void scan() {\n     clear();\n     Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n \n     // Hold FSDataset lock to prevent further changes to the block map\n-    synchronized(dataset) {\n+    try(AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n       for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n         String bpid \u003d entry.getKey();\n         ScanInfo[] blockpoolReport \u003d entry.getValue();\n         \n         Stats statsRecord \u003d new Stats(bpid);\n         stats.put(bpid, statsRecord);\n         LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n         diffs.put(bpid, diffRecord);\n         \n         statsRecord.totalBlocks \u003d blockpoolReport.length;\n         List\u003cFinalizedReplica\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n         FinalizedReplica[] memReport \u003d bl.toArray(new FinalizedReplica[bl.size()]);\n         Arrays.sort(memReport); // Sort based on blockId\n   \n         int d \u003d 0; // index for blockpoolReport\n         int m \u003d 0; // index for memReprot\n         while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n           FinalizedReplica memBlock \u003d memReport[m];\n           ScanInfo info \u003d blockpoolReport[d];\n           if (info.getBlockId() \u003c memBlock.getBlockId()) {\n             if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n               // Block is missing in memory\n               statsRecord.missingMemoryBlocks++;\n               addDifference(diffRecord, statsRecord, info);\n             }\n             d++;\n             continue;\n           }\n           if (info.getBlockId() \u003e memBlock.getBlockId()) {\n             // Block is missing on the disk\n             addDifference(diffRecord, statsRecord,\n                           memBlock.getBlockId(), info.getVolume());\n             m++;\n             continue;\n           }\n           // Block file and/or metadata file exists on the disk\n           // Block exists in memory\n           if (info.getBlockFile() \u003d\u003d null) {\n             // Block metadata file exits and block file is missing\n             addDifference(diffRecord, statsRecord, info);\n           } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n               || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n             // Block metadata file is missing or has wrong generation stamp,\n             // or block file length is different than expected\n             statsRecord.mismatchBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           } else if (info.getBlockFile().compareTo(memBlock.getBlockFile()) !\u003d 0) {\n             // volumeMap record and on-disk files don\u0027t match.\n             statsRecord.duplicateBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           }\n           d++;\n \n           if (d \u003c blockpoolReport.length) {\n             // There may be multiple on-disk records for the same block, don\u0027t increment\n             // the memory record pointer if so.\n             ScanInfo nextInfo \u003d blockpoolReport[Math.min(d, blockpoolReport.length - 1)];\n             if (nextInfo.getBlockId() !\u003d info.blockId) {\n               ++m;\n             }\n           } else {\n             ++m;\n           }\n         }\n         while (m \u003c memReport.length) {\n           FinalizedReplica current \u003d memReport[m++];\n           addDifference(diffRecord, statsRecord,\n                         current.getBlockId(), current.getVolume());\n         }\n         while (d \u003c blockpoolReport.length) {\n           if (!dataset.isDeletingBlock(bpid, blockpoolReport[d].getBlockId())) {\n             statsRecord.missingMemoryBlocks++;\n             addDifference(diffRecord, statsRecord, blockpoolReport[d]);\n           }\n           d++;\n         }\n         LOG.info(statsRecord.toString());\n       } //end for\n     } //end synchronized\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void scan() {\n    clear();\n    Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n\n    // Hold FSDataset lock to prevent further changes to the block map\n    try(AutoCloseableLock lock \u003d dataset.acquireDatasetLock()) {\n      for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n        String bpid \u003d entry.getKey();\n        ScanInfo[] blockpoolReport \u003d entry.getValue();\n        \n        Stats statsRecord \u003d new Stats(bpid);\n        stats.put(bpid, statsRecord);\n        LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n        diffs.put(bpid, diffRecord);\n        \n        statsRecord.totalBlocks \u003d blockpoolReport.length;\n        List\u003cFinalizedReplica\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n        FinalizedReplica[] memReport \u003d bl.toArray(new FinalizedReplica[bl.size()]);\n        Arrays.sort(memReport); // Sort based on blockId\n  \n        int d \u003d 0; // index for blockpoolReport\n        int m \u003d 0; // index for memReprot\n        while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n          FinalizedReplica memBlock \u003d memReport[m];\n          ScanInfo info \u003d blockpoolReport[d];\n          if (info.getBlockId() \u003c memBlock.getBlockId()) {\n            if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n              // Block is missing in memory\n              statsRecord.missingMemoryBlocks++;\n              addDifference(diffRecord, statsRecord, info);\n            }\n            d++;\n            continue;\n          }\n          if (info.getBlockId() \u003e memBlock.getBlockId()) {\n            // Block is missing on the disk\n            addDifference(diffRecord, statsRecord,\n                          memBlock.getBlockId(), info.getVolume());\n            m++;\n            continue;\n          }\n          // Block file and/or metadata file exists on the disk\n          // Block exists in memory\n          if (info.getBlockFile() \u003d\u003d null) {\n            // Block metadata file exits and block file is missing\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n              || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n            // Block metadata file is missing or has wrong generation stamp,\n            // or block file length is different than expected\n            statsRecord.mismatchBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getBlockFile().compareTo(memBlock.getBlockFile()) !\u003d 0) {\n            // volumeMap record and on-disk files don\u0027t match.\n            statsRecord.duplicateBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          }\n          d++;\n\n          if (d \u003c blockpoolReport.length) {\n            // There may be multiple on-disk records for the same block, don\u0027t increment\n            // the memory record pointer if so.\n            ScanInfo nextInfo \u003d blockpoolReport[Math.min(d, blockpoolReport.length - 1)];\n            if (nextInfo.getBlockId() !\u003d info.blockId) {\n              ++m;\n            }\n          } else {\n            ++m;\n          }\n        }\n        while (m \u003c memReport.length) {\n          FinalizedReplica current \u003d memReport[m++];\n          addDifference(diffRecord, statsRecord,\n                        current.getBlockId(), current.getVolume());\n        }\n        while (d \u003c blockpoolReport.length) {\n          if (!dataset.isDeletingBlock(bpid, blockpoolReport[d].getBlockId())) {\n            statsRecord.missingMemoryBlocks++;\n            addDifference(diffRecord, statsRecord, blockpoolReport[d]);\n          }\n          d++;\n        }\n        LOG.info(statsRecord.toString());\n      } //end for\n    } //end synchronized\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "7a3c381b39887a02e944fa98287afd0eb4db3560": {
      "type": "Ymodifierchange",
      "commitMessage": "HDFS-8873. Allow the directoryScanner to be rate-limited (Daniel Templeton via Colin P. McCabe)\n",
      "commitDate": "26/09/15 4:09 AM",
      "commitName": "7a3c381b39887a02e944fa98287afd0eb4db3560",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "19/05/15 10:50 AM",
      "commitNameOld": "470c87dbc6c24dd3b370f1ad9e7ab1f6dabd2080",
      "commitAuthorOld": "Colin Patrick Mccabe",
      "daysBetweenCommits": 129.72,
      "commitsBetweenForRepo": 819,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,86 +1,86 @@\n-  void scan() {\n+  private void scan() {\n     clear();\n     Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n \n     // Hold FSDataset lock to prevent further changes to the block map\n     synchronized(dataset) {\n       for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n         String bpid \u003d entry.getKey();\n         ScanInfo[] blockpoolReport \u003d entry.getValue();\n         \n         Stats statsRecord \u003d new Stats(bpid);\n         stats.put(bpid, statsRecord);\n         LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n         diffs.put(bpid, diffRecord);\n         \n         statsRecord.totalBlocks \u003d blockpoolReport.length;\n         List\u003cFinalizedReplica\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n         FinalizedReplica[] memReport \u003d bl.toArray(new FinalizedReplica[bl.size()]);\n         Arrays.sort(memReport); // Sort based on blockId\n   \n         int d \u003d 0; // index for blockpoolReport\n         int m \u003d 0; // index for memReprot\n         while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n           FinalizedReplica memBlock \u003d memReport[m];\n           ScanInfo info \u003d blockpoolReport[d];\n           if (info.getBlockId() \u003c memBlock.getBlockId()) {\n             if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n               // Block is missing in memory\n               statsRecord.missingMemoryBlocks++;\n               addDifference(diffRecord, statsRecord, info);\n             }\n             d++;\n             continue;\n           }\n           if (info.getBlockId() \u003e memBlock.getBlockId()) {\n             // Block is missing on the disk\n             addDifference(diffRecord, statsRecord,\n                           memBlock.getBlockId(), info.getVolume());\n             m++;\n             continue;\n           }\n           // Block file and/or metadata file exists on the disk\n           // Block exists in memory\n           if (info.getBlockFile() \u003d\u003d null) {\n             // Block metadata file exits and block file is missing\n             addDifference(diffRecord, statsRecord, info);\n           } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n               || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n             // Block metadata file is missing or has wrong generation stamp,\n             // or block file length is different than expected\n             statsRecord.mismatchBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           } else if (info.getBlockFile().compareTo(memBlock.getBlockFile()) !\u003d 0) {\n             // volumeMap record and on-disk files don\u0027t match.\n             statsRecord.duplicateBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           }\n           d++;\n \n           if (d \u003c blockpoolReport.length) {\n             // There may be multiple on-disk records for the same block, don\u0027t increment\n             // the memory record pointer if so.\n             ScanInfo nextInfo \u003d blockpoolReport[Math.min(d, blockpoolReport.length - 1)];\n             if (nextInfo.getBlockId() !\u003d info.blockId) {\n               ++m;\n             }\n           } else {\n             ++m;\n           }\n         }\n         while (m \u003c memReport.length) {\n           FinalizedReplica current \u003d memReport[m++];\n           addDifference(diffRecord, statsRecord,\n                         current.getBlockId(), current.getVolume());\n         }\n         while (d \u003c blockpoolReport.length) {\n           if (!dataset.isDeletingBlock(bpid, blockpoolReport[d].getBlockId())) {\n             statsRecord.missingMemoryBlocks++;\n             addDifference(diffRecord, statsRecord, blockpoolReport[d]);\n           }\n           d++;\n         }\n         LOG.info(statsRecord.toString());\n       } //end for\n     } //end synchronized\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void scan() {\n    clear();\n    Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n\n    // Hold FSDataset lock to prevent further changes to the block map\n    synchronized(dataset) {\n      for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n        String bpid \u003d entry.getKey();\n        ScanInfo[] blockpoolReport \u003d entry.getValue();\n        \n        Stats statsRecord \u003d new Stats(bpid);\n        stats.put(bpid, statsRecord);\n        LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n        diffs.put(bpid, diffRecord);\n        \n        statsRecord.totalBlocks \u003d blockpoolReport.length;\n        List\u003cFinalizedReplica\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n        FinalizedReplica[] memReport \u003d bl.toArray(new FinalizedReplica[bl.size()]);\n        Arrays.sort(memReport); // Sort based on blockId\n  \n        int d \u003d 0; // index for blockpoolReport\n        int m \u003d 0; // index for memReprot\n        while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n          FinalizedReplica memBlock \u003d memReport[m];\n          ScanInfo info \u003d blockpoolReport[d];\n          if (info.getBlockId() \u003c memBlock.getBlockId()) {\n            if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n              // Block is missing in memory\n              statsRecord.missingMemoryBlocks++;\n              addDifference(diffRecord, statsRecord, info);\n            }\n            d++;\n            continue;\n          }\n          if (info.getBlockId() \u003e memBlock.getBlockId()) {\n            // Block is missing on the disk\n            addDifference(diffRecord, statsRecord,\n                          memBlock.getBlockId(), info.getVolume());\n            m++;\n            continue;\n          }\n          // Block file and/or metadata file exists on the disk\n          // Block exists in memory\n          if (info.getBlockFile() \u003d\u003d null) {\n            // Block metadata file exits and block file is missing\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n              || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n            // Block metadata file is missing or has wrong generation stamp,\n            // or block file length is different than expected\n            statsRecord.mismatchBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getBlockFile().compareTo(memBlock.getBlockFile()) !\u003d 0) {\n            // volumeMap record and on-disk files don\u0027t match.\n            statsRecord.duplicateBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          }\n          d++;\n\n          if (d \u003c blockpoolReport.length) {\n            // There may be multiple on-disk records for the same block, don\u0027t increment\n            // the memory record pointer if so.\n            ScanInfo nextInfo \u003d blockpoolReport[Math.min(d, blockpoolReport.length - 1)];\n            if (nextInfo.getBlockId() !\u003d info.blockId) {\n              ++m;\n            }\n          } else {\n            ++m;\n          }\n        }\n        while (m \u003c memReport.length) {\n          FinalizedReplica current \u003d memReport[m++];\n          addDifference(diffRecord, statsRecord,\n                        current.getBlockId(), current.getVolume());\n        }\n        while (d \u003c blockpoolReport.length) {\n          if (!dataset.isDeletingBlock(bpid, blockpoolReport[d].getBlockId())) {\n            statsRecord.missingMemoryBlocks++;\n            addDifference(diffRecord, statsRecord, blockpoolReport[d]);\n          }\n          d++;\n        }\n        LOG.info(statsRecord.toString());\n      } //end for\n    } //end synchronized\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[private]"
      }
    },
    "6dae6d12ec5abb716e1501cd4e18b10ae7809b94": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6833.  DirectoryScanner should not register a deleting block with memory of DataNode.  Contributed by Shinichi Yamashita\n",
      "commitDate": "12/03/15 11:25 AM",
      "commitName": "6dae6d12ec5abb716e1501cd4e18b10ae7809b94",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "04/03/15 5:51 PM",
      "commitNameOld": "430b5371883e22abb65f37c3e3d4afc3f421fc89",
      "commitAuthorOld": "Dongming Liang",
      "daysBetweenCommits": 7.69,
      "commitsBetweenForRepo": 47,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,82 +1,86 @@\n   void scan() {\n     clear();\n     Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n \n     // Hold FSDataset lock to prevent further changes to the block map\n     synchronized(dataset) {\n       for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n         String bpid \u003d entry.getKey();\n         ScanInfo[] blockpoolReport \u003d entry.getValue();\n         \n         Stats statsRecord \u003d new Stats(bpid);\n         stats.put(bpid, statsRecord);\n         LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n         diffs.put(bpid, diffRecord);\n         \n         statsRecord.totalBlocks \u003d blockpoolReport.length;\n         List\u003cFinalizedReplica\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n         FinalizedReplica[] memReport \u003d bl.toArray(new FinalizedReplica[bl.size()]);\n         Arrays.sort(memReport); // Sort based on blockId\n   \n         int d \u003d 0; // index for blockpoolReport\n         int m \u003d 0; // index for memReprot\n         while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n-          FinalizedReplica memBlock \u003d memReport[Math.min(m, memReport.length - 1)];\n-          ScanInfo info \u003d blockpoolReport[Math.min(\n-              d, blockpoolReport.length - 1)];\n+          FinalizedReplica memBlock \u003d memReport[m];\n+          ScanInfo info \u003d blockpoolReport[d];\n           if (info.getBlockId() \u003c memBlock.getBlockId()) {\n-            // Block is missing in memory\n-            statsRecord.missingMemoryBlocks++;\n-            addDifference(diffRecord, statsRecord, info);\n+            if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n+              // Block is missing in memory\n+              statsRecord.missingMemoryBlocks++;\n+              addDifference(diffRecord, statsRecord, info);\n+            }\n             d++;\n             continue;\n           }\n           if (info.getBlockId() \u003e memBlock.getBlockId()) {\n             // Block is missing on the disk\n             addDifference(diffRecord, statsRecord,\n                           memBlock.getBlockId(), info.getVolume());\n             m++;\n             continue;\n           }\n           // Block file and/or metadata file exists on the disk\n           // Block exists in memory\n           if (info.getBlockFile() \u003d\u003d null) {\n             // Block metadata file exits and block file is missing\n             addDifference(diffRecord, statsRecord, info);\n           } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n               || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n             // Block metadata file is missing or has wrong generation stamp,\n             // or block file length is different than expected\n             statsRecord.mismatchBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           } else if (info.getBlockFile().compareTo(memBlock.getBlockFile()) !\u003d 0) {\n             // volumeMap record and on-disk files don\u0027t match.\n             statsRecord.duplicateBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           }\n           d++;\n \n           if (d \u003c blockpoolReport.length) {\n             // There may be multiple on-disk records for the same block, don\u0027t increment\n             // the memory record pointer if so.\n             ScanInfo nextInfo \u003d blockpoolReport[Math.min(d, blockpoolReport.length - 1)];\n             if (nextInfo.getBlockId() !\u003d info.blockId) {\n               ++m;\n             }\n           } else {\n             ++m;\n           }\n         }\n         while (m \u003c memReport.length) {\n           FinalizedReplica current \u003d memReport[m++];\n           addDifference(diffRecord, statsRecord,\n                         current.getBlockId(), current.getVolume());\n         }\n         while (d \u003c blockpoolReport.length) {\n-          statsRecord.missingMemoryBlocks++;\n-          addDifference(diffRecord, statsRecord, blockpoolReport[d++]);\n+          if (!dataset.isDeletingBlock(bpid, blockpoolReport[d].getBlockId())) {\n+            statsRecord.missingMemoryBlocks++;\n+            addDifference(diffRecord, statsRecord, blockpoolReport[d]);\n+          }\n+          d++;\n         }\n         LOG.info(statsRecord.toString());\n       } //end for\n     } //end synchronized\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void scan() {\n    clear();\n    Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n\n    // Hold FSDataset lock to prevent further changes to the block map\n    synchronized(dataset) {\n      for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n        String bpid \u003d entry.getKey();\n        ScanInfo[] blockpoolReport \u003d entry.getValue();\n        \n        Stats statsRecord \u003d new Stats(bpid);\n        stats.put(bpid, statsRecord);\n        LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n        diffs.put(bpid, diffRecord);\n        \n        statsRecord.totalBlocks \u003d blockpoolReport.length;\n        List\u003cFinalizedReplica\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n        FinalizedReplica[] memReport \u003d bl.toArray(new FinalizedReplica[bl.size()]);\n        Arrays.sort(memReport); // Sort based on blockId\n  \n        int d \u003d 0; // index for blockpoolReport\n        int m \u003d 0; // index for memReprot\n        while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n          FinalizedReplica memBlock \u003d memReport[m];\n          ScanInfo info \u003d blockpoolReport[d];\n          if (info.getBlockId() \u003c memBlock.getBlockId()) {\n            if (!dataset.isDeletingBlock(bpid, info.getBlockId())) {\n              // Block is missing in memory\n              statsRecord.missingMemoryBlocks++;\n              addDifference(diffRecord, statsRecord, info);\n            }\n            d++;\n            continue;\n          }\n          if (info.getBlockId() \u003e memBlock.getBlockId()) {\n            // Block is missing on the disk\n            addDifference(diffRecord, statsRecord,\n                          memBlock.getBlockId(), info.getVolume());\n            m++;\n            continue;\n          }\n          // Block file and/or metadata file exists on the disk\n          // Block exists in memory\n          if (info.getBlockFile() \u003d\u003d null) {\n            // Block metadata file exits and block file is missing\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n              || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n            // Block metadata file is missing or has wrong generation stamp,\n            // or block file length is different than expected\n            statsRecord.mismatchBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getBlockFile().compareTo(memBlock.getBlockFile()) !\u003d 0) {\n            // volumeMap record and on-disk files don\u0027t match.\n            statsRecord.duplicateBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          }\n          d++;\n\n          if (d \u003c blockpoolReport.length) {\n            // There may be multiple on-disk records for the same block, don\u0027t increment\n            // the memory record pointer if so.\n            ScanInfo nextInfo \u003d blockpoolReport[Math.min(d, blockpoolReport.length - 1)];\n            if (nextInfo.getBlockId() !\u003d info.blockId) {\n              ++m;\n            }\n          } else {\n            ++m;\n          }\n        }\n        while (m \u003c memReport.length) {\n          FinalizedReplica current \u003d memReport[m++];\n          addDifference(diffRecord, statsRecord,\n                        current.getBlockId(), current.getVolume());\n        }\n        while (d \u003c blockpoolReport.length) {\n          if (!dataset.isDeletingBlock(bpid, blockpoolReport[d].getBlockId())) {\n            statsRecord.missingMemoryBlocks++;\n            addDifference(diffRecord, statsRecord, blockpoolReport[d]);\n          }\n          d++;\n        }\n        LOG.info(statsRecord.toString());\n      } //end for\n    } //end synchronized\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "9f22fb8c9a10952225e15c7b67b5f77fa44b155d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6978. Directory scanner should correctly reconcile blocks on RAM disk. (Arpit Agarwal)\n",
      "commitDate": "12/09/14 10:13 PM",
      "commitName": "9f22fb8c9a10952225e15c7b67b5f77fa44b155d",
      "commitAuthor": "arp",
      "commitDateOld": "27/08/14 9:47 PM",
      "commitNameOld": "a317bd7b02c37bd57743bfad59593ec12f53f4ed",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 16.02,
      "commitsBetweenForRepo": 158,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,82 @@\n   void scan() {\n     clear();\n     Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n \n     // Hold FSDataset lock to prevent further changes to the block map\n     synchronized(dataset) {\n       for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n         String bpid \u003d entry.getKey();\n         ScanInfo[] blockpoolReport \u003d entry.getValue();\n         \n         Stats statsRecord \u003d new Stats(bpid);\n         stats.put(bpid, statsRecord);\n         LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n         diffs.put(bpid, diffRecord);\n         \n         statsRecord.totalBlocks \u003d blockpoolReport.length;\n         List\u003cFinalizedReplica\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n         FinalizedReplica[] memReport \u003d bl.toArray(new FinalizedReplica[bl.size()]);\n         Arrays.sort(memReport); // Sort based on blockId\n   \n         int d \u003d 0; // index for blockpoolReport\n         int m \u003d 0; // index for memReprot\n         while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n-          Block memBlock \u003d memReport[Math.min(m, memReport.length - 1)];\n+          FinalizedReplica memBlock \u003d memReport[Math.min(m, memReport.length - 1)];\n           ScanInfo info \u003d blockpoolReport[Math.min(\n               d, blockpoolReport.length - 1)];\n           if (info.getBlockId() \u003c memBlock.getBlockId()) {\n             // Block is missing in memory\n             statsRecord.missingMemoryBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n             d++;\n             continue;\n           }\n           if (info.getBlockId() \u003e memBlock.getBlockId()) {\n             // Block is missing on the disk\n             addDifference(diffRecord, statsRecord,\n                           memBlock.getBlockId(), info.getVolume());\n             m++;\n             continue;\n           }\n           // Block file and/or metadata file exists on the disk\n           // Block exists in memory\n           if (info.getBlockFile() \u003d\u003d null) {\n             // Block metadata file exits and block file is missing\n             addDifference(diffRecord, statsRecord, info);\n           } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n               || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n             // Block metadata file is missing or has wrong generation stamp,\n             // or block file length is different than expected\n             statsRecord.mismatchBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n+          } else if (info.getBlockFile().compareTo(memBlock.getBlockFile()) !\u003d 0) {\n+            // volumeMap record and on-disk files don\u0027t match.\n+            statsRecord.duplicateBlocks++;\n+            addDifference(diffRecord, statsRecord, info);\n           }\n           d++;\n-          m++;\n+\n+          if (d \u003c blockpoolReport.length) {\n+            // There may be multiple on-disk records for the same block, don\u0027t increment\n+            // the memory record pointer if so.\n+            ScanInfo nextInfo \u003d blockpoolReport[Math.min(d, blockpoolReport.length - 1)];\n+            if (nextInfo.getBlockId() !\u003d info.blockId) {\n+              ++m;\n+            }\n+          } else {\n+            ++m;\n+          }\n         }\n         while (m \u003c memReport.length) {\n           FinalizedReplica current \u003d memReport[m++];\n           addDifference(diffRecord, statsRecord,\n                         current.getBlockId(), current.getVolume());\n         }\n         while (d \u003c blockpoolReport.length) {\n           statsRecord.missingMemoryBlocks++;\n           addDifference(diffRecord, statsRecord, blockpoolReport[d++]);\n         }\n         LOG.info(statsRecord.toString());\n       } //end for\n     } //end synchronized\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void scan() {\n    clear();\n    Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n\n    // Hold FSDataset lock to prevent further changes to the block map\n    synchronized(dataset) {\n      for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n        String bpid \u003d entry.getKey();\n        ScanInfo[] blockpoolReport \u003d entry.getValue();\n        \n        Stats statsRecord \u003d new Stats(bpid);\n        stats.put(bpid, statsRecord);\n        LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n        diffs.put(bpid, diffRecord);\n        \n        statsRecord.totalBlocks \u003d blockpoolReport.length;\n        List\u003cFinalizedReplica\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n        FinalizedReplica[] memReport \u003d bl.toArray(new FinalizedReplica[bl.size()]);\n        Arrays.sort(memReport); // Sort based on blockId\n  \n        int d \u003d 0; // index for blockpoolReport\n        int m \u003d 0; // index for memReprot\n        while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n          FinalizedReplica memBlock \u003d memReport[Math.min(m, memReport.length - 1)];\n          ScanInfo info \u003d blockpoolReport[Math.min(\n              d, blockpoolReport.length - 1)];\n          if (info.getBlockId() \u003c memBlock.getBlockId()) {\n            // Block is missing in memory\n            statsRecord.missingMemoryBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n            d++;\n            continue;\n          }\n          if (info.getBlockId() \u003e memBlock.getBlockId()) {\n            // Block is missing on the disk\n            addDifference(diffRecord, statsRecord,\n                          memBlock.getBlockId(), info.getVolume());\n            m++;\n            continue;\n          }\n          // Block file and/or metadata file exists on the disk\n          // Block exists in memory\n          if (info.getBlockFile() \u003d\u003d null) {\n            // Block metadata file exits and block file is missing\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n              || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n            // Block metadata file is missing or has wrong generation stamp,\n            // or block file length is different than expected\n            statsRecord.mismatchBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getBlockFile().compareTo(memBlock.getBlockFile()) !\u003d 0) {\n            // volumeMap record and on-disk files don\u0027t match.\n            statsRecord.duplicateBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          }\n          d++;\n\n          if (d \u003c blockpoolReport.length) {\n            // There may be multiple on-disk records for the same block, don\u0027t increment\n            // the memory record pointer if so.\n            ScanInfo nextInfo \u003d blockpoolReport[Math.min(d, blockpoolReport.length - 1)];\n            if (nextInfo.getBlockId() !\u003d info.blockId) {\n              ++m;\n            }\n          } else {\n            ++m;\n          }\n        }\n        while (m \u003c memReport.length) {\n          FinalizedReplica current \u003d memReport[m++];\n          addDifference(diffRecord, statsRecord,\n                        current.getBlockId(), current.getVolume());\n        }\n        while (d \u003c blockpoolReport.length) {\n          statsRecord.missingMemoryBlocks++;\n          addDifference(diffRecord, statsRecord, blockpoolReport[d++]);\n        }\n        LOG.info(statsRecord.toString());\n      } //end for\n    } //end synchronized\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "b9d561c548c26d0db4994e6c13c7ebf43705d794": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5214. Fix NPEs in BlockManager and DirectoryScanner.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1536179 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/10/13 11:29 AM",
      "commitName": "b9d561c548c26d0db4994e6c13c7ebf43705d794",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "23/10/13 2:29 PM",
      "commitNameOld": "bf3271bd2b3b347a94e00f145e55aa08baa69437",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 3.87,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,68 @@\n   void scan() {\n     clear();\n     Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n \n     // Hold FSDataset lock to prevent further changes to the block map\n     synchronized(dataset) {\n       for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n         String bpid \u003d entry.getKey();\n         ScanInfo[] blockpoolReport \u003d entry.getValue();\n         \n         Stats statsRecord \u003d new Stats(bpid);\n         stats.put(bpid, statsRecord);\n         LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n         diffs.put(bpid, diffRecord);\n         \n         statsRecord.totalBlocks \u003d blockpoolReport.length;\n-        List\u003cBlock\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n-        Block[] memReport \u003d bl.toArray(new Block[bl.size()]);\n+        List\u003cFinalizedReplica\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n+        FinalizedReplica[] memReport \u003d bl.toArray(new FinalizedReplica[bl.size()]);\n         Arrays.sort(memReport); // Sort based on blockId\n   \n         int d \u003d 0; // index for blockpoolReport\n         int m \u003d 0; // index for memReprot\n         while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n           Block memBlock \u003d memReport[Math.min(m, memReport.length - 1)];\n           ScanInfo info \u003d blockpoolReport[Math.min(\n               d, blockpoolReport.length - 1)];\n           if (info.getBlockId() \u003c memBlock.getBlockId()) {\n             // Block is missing in memory\n             statsRecord.missingMemoryBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n             d++;\n             continue;\n           }\n           if (info.getBlockId() \u003e memBlock.getBlockId()) {\n             // Block is missing on the disk\n-            addDifference(diffRecord, statsRecord, memBlock.getBlockId());\n+            addDifference(diffRecord, statsRecord,\n+                          memBlock.getBlockId(), info.getVolume());\n             m++;\n             continue;\n           }\n           // Block file and/or metadata file exists on the disk\n           // Block exists in memory\n           if (info.getBlockFile() \u003d\u003d null) {\n             // Block metadata file exits and block file is missing\n             addDifference(diffRecord, statsRecord, info);\n           } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n               || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n             // Block metadata file is missing or has wrong generation stamp,\n             // or block file length is different than expected\n             statsRecord.mismatchBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           }\n           d++;\n           m++;\n         }\n         while (m \u003c memReport.length) {\n-          addDifference(diffRecord, statsRecord, memReport[m++].getBlockId());\n+          FinalizedReplica current \u003d memReport[m++];\n+          addDifference(diffRecord, statsRecord,\n+                        current.getBlockId(), current.getVolume());\n         }\n         while (d \u003c blockpoolReport.length) {\n           statsRecord.missingMemoryBlocks++;\n           addDifference(diffRecord, statsRecord, blockpoolReport[d++]);\n         }\n         LOG.info(statsRecord.toString());\n       } //end for\n     } //end synchronized\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void scan() {\n    clear();\n    Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n\n    // Hold FSDataset lock to prevent further changes to the block map\n    synchronized(dataset) {\n      for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n        String bpid \u003d entry.getKey();\n        ScanInfo[] blockpoolReport \u003d entry.getValue();\n        \n        Stats statsRecord \u003d new Stats(bpid);\n        stats.put(bpid, statsRecord);\n        LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n        diffs.put(bpid, diffRecord);\n        \n        statsRecord.totalBlocks \u003d blockpoolReport.length;\n        List\u003cFinalizedReplica\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n        FinalizedReplica[] memReport \u003d bl.toArray(new FinalizedReplica[bl.size()]);\n        Arrays.sort(memReport); // Sort based on blockId\n  \n        int d \u003d 0; // index for blockpoolReport\n        int m \u003d 0; // index for memReprot\n        while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n          Block memBlock \u003d memReport[Math.min(m, memReport.length - 1)];\n          ScanInfo info \u003d blockpoolReport[Math.min(\n              d, blockpoolReport.length - 1)];\n          if (info.getBlockId() \u003c memBlock.getBlockId()) {\n            // Block is missing in memory\n            statsRecord.missingMemoryBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n            d++;\n            continue;\n          }\n          if (info.getBlockId() \u003e memBlock.getBlockId()) {\n            // Block is missing on the disk\n            addDifference(diffRecord, statsRecord,\n                          memBlock.getBlockId(), info.getVolume());\n            m++;\n            continue;\n          }\n          // Block file and/or metadata file exists on the disk\n          // Block exists in memory\n          if (info.getBlockFile() \u003d\u003d null) {\n            // Block metadata file exits and block file is missing\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n              || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n            // Block metadata file is missing or has wrong generation stamp,\n            // or block file length is different than expected\n            statsRecord.mismatchBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          }\n          d++;\n          m++;\n        }\n        while (m \u003c memReport.length) {\n          FinalizedReplica current \u003d memReport[m++];\n          addDifference(diffRecord, statsRecord,\n                        current.getBlockId(), current.getVolume());\n        }\n        while (d \u003c blockpoolReport.length) {\n          statsRecord.missingMemoryBlocks++;\n          addDifference(diffRecord, statsRecord, blockpoolReport[d++]);\n        }\n        LOG.info(statsRecord.toString());\n      } //end for\n    } //end synchronized\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "bf3271bd2b3b347a94e00f145e55aa08baa69437": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5341. Reduce fsdataset lock duration during directory scanning. Contributed by Qus-Jiawei.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1535188 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/10/13 2:29 PM",
      "commitName": "bf3271bd2b3b347a94e00f145e55aa08baa69437",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "18/06/13 5:34 PM",
      "commitNameOld": "57006e1c8c9df24ca26338b7e3dca745e301218f",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 126.87,
      "commitsBetweenForRepo": 743,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,65 @@\n   void scan() {\n     clear();\n     Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n \n     // Hold FSDataset lock to prevent further changes to the block map\n     synchronized(dataset) {\n       for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n         String bpid \u003d entry.getKey();\n         ScanInfo[] blockpoolReport \u003d entry.getValue();\n         \n         Stats statsRecord \u003d new Stats(bpid);\n         stats.put(bpid, statsRecord);\n         LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n         diffs.put(bpid, diffRecord);\n         \n         statsRecord.totalBlocks \u003d blockpoolReport.length;\n         List\u003cBlock\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n         Block[] memReport \u003d bl.toArray(new Block[bl.size()]);\n         Arrays.sort(memReport); // Sort based on blockId\n   \n         int d \u003d 0; // index for blockpoolReport\n         int m \u003d 0; // index for memReprot\n         while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n           Block memBlock \u003d memReport[Math.min(m, memReport.length - 1)];\n           ScanInfo info \u003d blockpoolReport[Math.min(\n               d, blockpoolReport.length - 1)];\n           if (info.getBlockId() \u003c memBlock.getBlockId()) {\n             // Block is missing in memory\n             statsRecord.missingMemoryBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n             d++;\n             continue;\n           }\n           if (info.getBlockId() \u003e memBlock.getBlockId()) {\n             // Block is missing on the disk\n             addDifference(diffRecord, statsRecord, memBlock.getBlockId());\n             m++;\n             continue;\n           }\n           // Block file and/or metadata file exists on the disk\n           // Block exists in memory\n           if (info.getBlockFile() \u003d\u003d null) {\n             // Block metadata file exits and block file is missing\n             addDifference(diffRecord, statsRecord, info);\n           } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n-              || info.getBlockFile().length() !\u003d memBlock.getNumBytes()) {\n+              || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n             // Block metadata file is missing or has wrong generation stamp,\n             // or block file length is different than expected\n             statsRecord.mismatchBlocks++;\n             addDifference(diffRecord, statsRecord, info);\n           }\n           d++;\n           m++;\n         }\n         while (m \u003c memReport.length) {\n           addDifference(diffRecord, statsRecord, memReport[m++].getBlockId());\n         }\n         while (d \u003c blockpoolReport.length) {\n           statsRecord.missingMemoryBlocks++;\n           addDifference(diffRecord, statsRecord, blockpoolReport[d++]);\n         }\n         LOG.info(statsRecord.toString());\n       } //end for\n     } //end synchronized\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void scan() {\n    clear();\n    Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n\n    // Hold FSDataset lock to prevent further changes to the block map\n    synchronized(dataset) {\n      for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n        String bpid \u003d entry.getKey();\n        ScanInfo[] blockpoolReport \u003d entry.getValue();\n        \n        Stats statsRecord \u003d new Stats(bpid);\n        stats.put(bpid, statsRecord);\n        LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n        diffs.put(bpid, diffRecord);\n        \n        statsRecord.totalBlocks \u003d blockpoolReport.length;\n        List\u003cBlock\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n        Block[] memReport \u003d bl.toArray(new Block[bl.size()]);\n        Arrays.sort(memReport); // Sort based on blockId\n  \n        int d \u003d 0; // index for blockpoolReport\n        int m \u003d 0; // index for memReprot\n        while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n          Block memBlock \u003d memReport[Math.min(m, memReport.length - 1)];\n          ScanInfo info \u003d blockpoolReport[Math.min(\n              d, blockpoolReport.length - 1)];\n          if (info.getBlockId() \u003c memBlock.getBlockId()) {\n            // Block is missing in memory\n            statsRecord.missingMemoryBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n            d++;\n            continue;\n          }\n          if (info.getBlockId() \u003e memBlock.getBlockId()) {\n            // Block is missing on the disk\n            addDifference(diffRecord, statsRecord, memBlock.getBlockId());\n            m++;\n            continue;\n          }\n          // Block file and/or metadata file exists on the disk\n          // Block exists in memory\n          if (info.getBlockFile() \u003d\u003d null) {\n            // Block metadata file exits and block file is missing\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n              || info.getBlockFileLength() !\u003d memBlock.getNumBytes()) {\n            // Block metadata file is missing or has wrong generation stamp,\n            // or block file length is different than expected\n            statsRecord.mismatchBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          }\n          d++;\n          m++;\n        }\n        while (m \u003c memReport.length) {\n          addDifference(diffRecord, statsRecord, memReport[m++].getBlockId());\n        }\n        while (d \u003c blockpoolReport.length) {\n          statsRecord.missingMemoryBlocks++;\n          addDifference(diffRecord, statsRecord, blockpoolReport[d++]);\n        }\n        LOG.info(statsRecord.toString());\n      } //end for\n    } //end synchronized\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  void scan() {\n    clear();\n    Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n\n    // Hold FSDataset lock to prevent further changes to the block map\n    synchronized(dataset) {\n      for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n        String bpid \u003d entry.getKey();\n        ScanInfo[] blockpoolReport \u003d entry.getValue();\n        \n        Stats statsRecord \u003d new Stats(bpid);\n        stats.put(bpid, statsRecord);\n        LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n        diffs.put(bpid, diffRecord);\n        \n        statsRecord.totalBlocks \u003d blockpoolReport.length;\n        List\u003cBlock\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n        Block[] memReport \u003d bl.toArray(new Block[bl.size()]);\n        Arrays.sort(memReport); // Sort based on blockId\n  \n        int d \u003d 0; // index for blockpoolReport\n        int m \u003d 0; // index for memReprot\n        while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n          Block memBlock \u003d memReport[Math.min(m, memReport.length - 1)];\n          ScanInfo info \u003d blockpoolReport[Math.min(\n              d, blockpoolReport.length - 1)];\n          if (info.getBlockId() \u003c memBlock.getBlockId()) {\n            // Block is missing in memory\n            statsRecord.missingMemoryBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n            d++;\n            continue;\n          }\n          if (info.getBlockId() \u003e memBlock.getBlockId()) {\n            // Block is missing on the disk\n            addDifference(diffRecord, statsRecord, memBlock.getBlockId());\n            m++;\n            continue;\n          }\n          // Block file and/or metadata file exists on the disk\n          // Block exists in memory\n          if (info.getBlockFile() \u003d\u003d null) {\n            // Block metadata file exits and block file is missing\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n              || info.getBlockFile().length() !\u003d memBlock.getNumBytes()) {\n            // Block metadata file is missing or has wrong generation stamp,\n            // or block file length is different than expected\n            statsRecord.mismatchBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          }\n          d++;\n          m++;\n        }\n        while (m \u003c memReport.length) {\n          addDifference(diffRecord, statsRecord, memReport[m++].getBlockId());\n        }\n        while (d \u003c blockpoolReport.length) {\n          statsRecord.missingMemoryBlocks++;\n          addDifference(diffRecord, statsRecord, blockpoolReport[d++]);\n        }\n        LOG.info(statsRecord.toString());\n      } //end for\n    } //end synchronized\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  void scan() {\n    clear();\n    Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n\n    // Hold FSDataset lock to prevent further changes to the block map\n    synchronized(dataset) {\n      for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n        String bpid \u003d entry.getKey();\n        ScanInfo[] blockpoolReport \u003d entry.getValue();\n        \n        Stats statsRecord \u003d new Stats(bpid);\n        stats.put(bpid, statsRecord);\n        LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n        diffs.put(bpid, diffRecord);\n        \n        statsRecord.totalBlocks \u003d blockpoolReport.length;\n        List\u003cBlock\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n        Block[] memReport \u003d bl.toArray(new Block[bl.size()]);\n        Arrays.sort(memReport); // Sort based on blockId\n  \n        int d \u003d 0; // index for blockpoolReport\n        int m \u003d 0; // index for memReprot\n        while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n          Block memBlock \u003d memReport[Math.min(m, memReport.length - 1)];\n          ScanInfo info \u003d blockpoolReport[Math.min(\n              d, blockpoolReport.length - 1)];\n          if (info.getBlockId() \u003c memBlock.getBlockId()) {\n            // Block is missing in memory\n            statsRecord.missingMemoryBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n            d++;\n            continue;\n          }\n          if (info.getBlockId() \u003e memBlock.getBlockId()) {\n            // Block is missing on the disk\n            addDifference(diffRecord, statsRecord, memBlock.getBlockId());\n            m++;\n            continue;\n          }\n          // Block file and/or metadata file exists on the disk\n          // Block exists in memory\n          if (info.getBlockFile() \u003d\u003d null) {\n            // Block metadata file exits and block file is missing\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n              || info.getBlockFile().length() !\u003d memBlock.getNumBytes()) {\n            // Block metadata file is missing or has wrong generation stamp,\n            // or block file length is different than expected\n            statsRecord.mismatchBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          }\n          d++;\n          m++;\n        }\n        while (m \u003c memReport.length) {\n          addDifference(diffRecord, statsRecord, memReport[m++].getBlockId());\n        }\n        while (d \u003c blockpoolReport.length) {\n          statsRecord.missingMemoryBlocks++;\n          addDifference(diffRecord, statsRecord, blockpoolReport[d++]);\n        }\n        LOG.info(statsRecord.toString());\n      } //end for\n    } //end synchronized\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,65 @@\n+  void scan() {\n+    clear();\n+    Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n+\n+    // Hold FSDataset lock to prevent further changes to the block map\n+    synchronized(dataset) {\n+      for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n+        String bpid \u003d entry.getKey();\n+        ScanInfo[] blockpoolReport \u003d entry.getValue();\n+        \n+        Stats statsRecord \u003d new Stats(bpid);\n+        stats.put(bpid, statsRecord);\n+        LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n+        diffs.put(bpid, diffRecord);\n+        \n+        statsRecord.totalBlocks \u003d blockpoolReport.length;\n+        List\u003cBlock\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n+        Block[] memReport \u003d bl.toArray(new Block[bl.size()]);\n+        Arrays.sort(memReport); // Sort based on blockId\n+  \n+        int d \u003d 0; // index for blockpoolReport\n+        int m \u003d 0; // index for memReprot\n+        while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n+          Block memBlock \u003d memReport[Math.min(m, memReport.length - 1)];\n+          ScanInfo info \u003d blockpoolReport[Math.min(\n+              d, blockpoolReport.length - 1)];\n+          if (info.getBlockId() \u003c memBlock.getBlockId()) {\n+            // Block is missing in memory\n+            statsRecord.missingMemoryBlocks++;\n+            addDifference(diffRecord, statsRecord, info);\n+            d++;\n+            continue;\n+          }\n+          if (info.getBlockId() \u003e memBlock.getBlockId()) {\n+            // Block is missing on the disk\n+            addDifference(diffRecord, statsRecord, memBlock.getBlockId());\n+            m++;\n+            continue;\n+          }\n+          // Block file and/or metadata file exists on the disk\n+          // Block exists in memory\n+          if (info.getBlockFile() \u003d\u003d null) {\n+            // Block metadata file exits and block file is missing\n+            addDifference(diffRecord, statsRecord, info);\n+          } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n+              || info.getBlockFile().length() !\u003d memBlock.getNumBytes()) {\n+            // Block metadata file is missing or has wrong generation stamp,\n+            // or block file length is different than expected\n+            statsRecord.mismatchBlocks++;\n+            addDifference(diffRecord, statsRecord, info);\n+          }\n+          d++;\n+          m++;\n+        }\n+        while (m \u003c memReport.length) {\n+          addDifference(diffRecord, statsRecord, memReport[m++].getBlockId());\n+        }\n+        while (d \u003c blockpoolReport.length) {\n+          statsRecord.missingMemoryBlocks++;\n+          addDifference(diffRecord, statsRecord, blockpoolReport[d++]);\n+        }\n+        LOG.info(statsRecord.toString());\n+      } //end for\n+    } //end synchronized\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void scan() {\n    clear();\n    Map\u003cString, ScanInfo[]\u003e diskReport \u003d getDiskReport();\n\n    // Hold FSDataset lock to prevent further changes to the block map\n    synchronized(dataset) {\n      for (Entry\u003cString, ScanInfo[]\u003e entry : diskReport.entrySet()) {\n        String bpid \u003d entry.getKey();\n        ScanInfo[] blockpoolReport \u003d entry.getValue();\n        \n        Stats statsRecord \u003d new Stats(bpid);\n        stats.put(bpid, statsRecord);\n        LinkedList\u003cScanInfo\u003e diffRecord \u003d new LinkedList\u003cScanInfo\u003e();\n        diffs.put(bpid, diffRecord);\n        \n        statsRecord.totalBlocks \u003d blockpoolReport.length;\n        List\u003cBlock\u003e bl \u003d dataset.getFinalizedBlocks(bpid);\n        Block[] memReport \u003d bl.toArray(new Block[bl.size()]);\n        Arrays.sort(memReport); // Sort based on blockId\n  \n        int d \u003d 0; // index for blockpoolReport\n        int m \u003d 0; // index for memReprot\n        while (m \u003c memReport.length \u0026\u0026 d \u003c blockpoolReport.length) {\n          Block memBlock \u003d memReport[Math.min(m, memReport.length - 1)];\n          ScanInfo info \u003d blockpoolReport[Math.min(\n              d, blockpoolReport.length - 1)];\n          if (info.getBlockId() \u003c memBlock.getBlockId()) {\n            // Block is missing in memory\n            statsRecord.missingMemoryBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n            d++;\n            continue;\n          }\n          if (info.getBlockId() \u003e memBlock.getBlockId()) {\n            // Block is missing on the disk\n            addDifference(diffRecord, statsRecord, memBlock.getBlockId());\n            m++;\n            continue;\n          }\n          // Block file and/or metadata file exists on the disk\n          // Block exists in memory\n          if (info.getBlockFile() \u003d\u003d null) {\n            // Block metadata file exits and block file is missing\n            addDifference(diffRecord, statsRecord, info);\n          } else if (info.getGenStamp() !\u003d memBlock.getGenerationStamp()\n              || info.getBlockFile().length() !\u003d memBlock.getNumBytes()) {\n            // Block metadata file is missing or has wrong generation stamp,\n            // or block file length is different than expected\n            statsRecord.mismatchBlocks++;\n            addDifference(diffRecord, statsRecord, info);\n          }\n          d++;\n          m++;\n        }\n        while (m \u003c memReport.length) {\n          addDifference(diffRecord, statsRecord, memReport[m++].getBlockId());\n        }\n        while (d \u003c blockpoolReport.length) {\n          statsRecord.missingMemoryBlocks++;\n          addDifference(diffRecord, statsRecord, blockpoolReport[d++]);\n        }\n        LOG.info(statsRecord.toString());\n      } //end for\n    } //end synchronized\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.java"
    }
  }
}