{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockStorageMovementAttemptedItems.java",
  "functionName": "add",
  "functionId": "add___startPathId-long__fileId-long__monotonicNow-long__assignedBlocks-Map__Block,Set__StorageTypeNodePair______retryCount-int",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementAttemptedItems.java",
  "functionStartLine": 122,
  "functionEndLine": 132,
  "numCommitsSeen": 64,
  "timeTaken": 10670,
  "changeHistory": [
    "66e8f9b31529226309c924226a53dead3e6fcf11",
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
    "8467ec24fb74f30371d5a13e893fc56309ee9372",
    "78420719eb1f138c6f10558befb7bc8ebcc28a54",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
    "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
    "b7bed9f00a25bcad6f9c3543f5a1fb0a1f23b0e9",
    "047526b4c27909f78313e1ed6216de85c6137f14"
  ],
  "changeHistoryShort": {
    "66e8f9b31529226309c924226a53dead3e6fcf11": "Ymultichange(Yparameterchange,Ybodychange)",
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": "Ymultichange(Yparameterchange,Ybodychange)",
    "8467ec24fb74f30371d5a13e893fc56309ee9372": "Yparameterchange",
    "78420719eb1f138c6f10558befb7bc8ebcc28a54": "Yfilerename",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": "Ymultichange(Yparameterchange,Ybodychange)",
    "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923": "Ybodychange",
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064": "Ymultichange(Yparameterchange,Ybodychange)",
    "b7bed9f00a25bcad6f9c3543f5a1fb0a1f23b0e9": "Ymultichange(Yparameterchange,Ybodychange)",
    "047526b4c27909f78313e1ed6216de85c6137f14": "Yintroduced"
  },
  "changeHistoryDetails": {
    "66e8f9b31529226309c924226a53dead3e6fcf11": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-13381 : [SPS]: Use DFSUtilClient#makePathFromFileId() to prepare satisfier file path. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "66e8f9b31529226309c924226a53dead3e6fcf11",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13381 : [SPS]: Use DFSUtilClient#makePathFromFileId() to prepare satisfier file path. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "66e8f9b31529226309c924226a53dead3e6fcf11",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,11 @@\n-  public void add(T startPath, T file, long monotonicNow,\n+  public void add(long startPathId, long fileId, long monotonicNow,\n       Map\u003cBlock, Set\u003cStorageTypeNodePair\u003e\u003e assignedBlocks, int retryCount) {\n-    AttemptedItemInfo\u003cT\u003e itemInfo \u003d new AttemptedItemInfo\u003cT\u003e(startPath, file,\n+    AttemptedItemInfo itemInfo \u003d new AttemptedItemInfo(startPathId, fileId,\n         monotonicNow, assignedBlocks.keySet(), retryCount);\n     synchronized (storageMovementAttemptedItems) {\n       storageMovementAttemptedItems.add(itemInfo);\n     }\n     synchronized (scheduledBlkLocs) {\n       scheduledBlkLocs.putAll(assignedBlocks);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void add(long startPathId, long fileId, long monotonicNow,\n      Map\u003cBlock, Set\u003cStorageTypeNodePair\u003e\u003e assignedBlocks, int retryCount) {\n    AttemptedItemInfo itemInfo \u003d new AttemptedItemInfo(startPathId, fileId,\n        monotonicNow, assignedBlocks.keySet(), retryCount);\n    synchronized (storageMovementAttemptedItems) {\n      storageMovementAttemptedItems.add(itemInfo);\n    }\n    synchronized (scheduledBlkLocs) {\n      scheduledBlkLocs.putAll(assignedBlocks);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementAttemptedItems.java",
          "extendedDetails": {
            "oldValue": "[startPath-T, file-T, monotonicNow-long, assignedBlocks-Map\u003cBlock,Set\u003cStorageTypeNodePair\u003e\u003e, retryCount-int]",
            "newValue": "[startPathId-long, fileId-long, monotonicNow-long, assignedBlocks-Map\u003cBlock,Set\u003cStorageTypeNodePair\u003e\u003e, retryCount-int]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13381 : [SPS]: Use DFSUtilClient#makePathFromFileId() to prepare satisfier file path. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "66e8f9b31529226309c924226a53dead3e6fcf11",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,11 @@\n-  public void add(T startPath, T file, long monotonicNow,\n+  public void add(long startPathId, long fileId, long monotonicNow,\n       Map\u003cBlock, Set\u003cStorageTypeNodePair\u003e\u003e assignedBlocks, int retryCount) {\n-    AttemptedItemInfo\u003cT\u003e itemInfo \u003d new AttemptedItemInfo\u003cT\u003e(startPath, file,\n+    AttemptedItemInfo itemInfo \u003d new AttemptedItemInfo(startPathId, fileId,\n         monotonicNow, assignedBlocks.keySet(), retryCount);\n     synchronized (storageMovementAttemptedItems) {\n       storageMovementAttemptedItems.add(itemInfo);\n     }\n     synchronized (scheduledBlkLocs) {\n       scheduledBlkLocs.putAll(assignedBlocks);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void add(long startPathId, long fileId, long monotonicNow,\n      Map\u003cBlock, Set\u003cStorageTypeNodePair\u003e\u003e assignedBlocks, int retryCount) {\n    AttemptedItemInfo itemInfo \u003d new AttemptedItemInfo(startPathId, fileId,\n        monotonicNow, assignedBlocks.keySet(), retryCount);\n    synchronized (storageMovementAttemptedItems) {\n      storageMovementAttemptedItems.add(itemInfo);\n    }\n    synchronized (scheduledBlkLocs) {\n      scheduledBlkLocs.putAll(assignedBlocks);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementAttemptedItems.java",
          "extendedDetails": {}
        }
      ]
    },
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,11 @@\n-  public void add(AttemptedItemInfo\u003cT\u003e itemInfo) {\n+  public void add(T startPath, T file, long monotonicNow,\n+      Map\u003cBlock, Set\u003cStorageTypeNodePair\u003e\u003e assignedBlocks, int retryCount) {\n+    AttemptedItemInfo\u003cT\u003e itemInfo \u003d new AttemptedItemInfo\u003cT\u003e(startPath, file,\n+        monotonicNow, assignedBlocks.keySet(), retryCount);\n     synchronized (storageMovementAttemptedItems) {\n       storageMovementAttemptedItems.add(itemInfo);\n     }\n+    synchronized (scheduledBlkLocs) {\n+      scheduledBlkLocs.putAll(assignedBlocks);\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void add(T startPath, T file, long monotonicNow,\n      Map\u003cBlock, Set\u003cStorageTypeNodePair\u003e\u003e assignedBlocks, int retryCount) {\n    AttemptedItemInfo\u003cT\u003e itemInfo \u003d new AttemptedItemInfo\u003cT\u003e(startPath, file,\n        monotonicNow, assignedBlocks.keySet(), retryCount);\n    synchronized (storageMovementAttemptedItems) {\n      storageMovementAttemptedItems.add(itemInfo);\n    }\n    synchronized (scheduledBlkLocs) {\n      scheduledBlkLocs.putAll(assignedBlocks);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementAttemptedItems.java",
          "extendedDetails": {
            "oldValue": "[itemInfo-AttemptedItemInfo\u003cT\u003e]",
            "newValue": "[startPath-T, file-T, monotonicNow-long, assignedBlocks-Map\u003cBlock,Set\u003cStorageTypeNodePair\u003e\u003e, retryCount-int]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "8467ec24fb74f30371d5a13e893fc56309ee9372",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,11 @@\n-  public void add(AttemptedItemInfo\u003cT\u003e itemInfo) {\n+  public void add(T startPath, T file, long monotonicNow,\n+      Map\u003cBlock, Set\u003cStorageTypeNodePair\u003e\u003e assignedBlocks, int retryCount) {\n+    AttemptedItemInfo\u003cT\u003e itemInfo \u003d new AttemptedItemInfo\u003cT\u003e(startPath, file,\n+        monotonicNow, assignedBlocks.keySet(), retryCount);\n     synchronized (storageMovementAttemptedItems) {\n       storageMovementAttemptedItems.add(itemInfo);\n     }\n+    synchronized (scheduledBlkLocs) {\n+      scheduledBlkLocs.putAll(assignedBlocks);\n+    }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void add(T startPath, T file, long monotonicNow,\n      Map\u003cBlock, Set\u003cStorageTypeNodePair\u003e\u003e assignedBlocks, int retryCount) {\n    AttemptedItemInfo\u003cT\u003e itemInfo \u003d new AttemptedItemInfo\u003cT\u003e(startPath, file,\n        monotonicNow, assignedBlocks.keySet(), retryCount);\n    synchronized (storageMovementAttemptedItems) {\n      storageMovementAttemptedItems.add(itemInfo);\n    }\n    synchronized (scheduledBlkLocs) {\n      scheduledBlkLocs.putAll(assignedBlocks);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementAttemptedItems.java",
          "extendedDetails": {}
        }
      ]
    },
    "8467ec24fb74f30371d5a13e893fc56309ee9372": {
      "type": "Yparameterchange",
      "commitMessage": "HDFS-13110: [SPS]: Reduce the number of APIs in NamenodeProtocol used by external satisfier. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "8467ec24fb74f30371d5a13e893fc56309ee9372",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,5 @@\n-  public void add(AttemptedItemInfo itemInfo) {\n+  public void add(AttemptedItemInfo\u003cT\u003e itemInfo) {\n     synchronized (storageMovementAttemptedItems) {\n       storageMovementAttemptedItems.add(itemInfo);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void add(AttemptedItemInfo\u003cT\u003e itemInfo) {\n    synchronized (storageMovementAttemptedItems) {\n      storageMovementAttemptedItems.add(itemInfo);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementAttemptedItems.java",
      "extendedDetails": {
        "oldValue": "[itemInfo-AttemptedItemInfo]",
        "newValue": "[itemInfo-AttemptedItemInfo\u003cT\u003e]"
      }
    },
    "78420719eb1f138c6f10558befb7bc8ebcc28a54": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-12955: [SPS]: Move SPS classes to a separate package. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "78420719eb1f138c6f10558befb7bc8ebcc28a54",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "c561cb316e365ef674784cd6cf0b12c0fbc271a3",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void add(AttemptedItemInfo itemInfo) {\n    synchronized (storageMovementAttemptedItems) {\n      storageMovementAttemptedItems.add(itemInfo);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementAttemptedItems.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementAttemptedItems.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/sps/BlockStorageMovementAttemptedItems.java"
      }
    },
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,5 @@\n-  public void add(ItemInfo itemInfo, boolean allBlockLocsAttemptedToSatisfy) {\n+  public void add(AttemptedItemInfo itemInfo) {\n     synchronized (storageMovementAttemptedItems) {\n-      AttemptedItemInfo attemptedItemInfo \u003d new AttemptedItemInfo(\n-          itemInfo.getStartId(), itemInfo.getTrackId(), monotonicNow(),\n-          allBlockLocsAttemptedToSatisfy);\n-      storageMovementAttemptedItems.put(itemInfo.getTrackId(),\n-          attemptedItemInfo);\n+      storageMovementAttemptedItems.add(itemInfo);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void add(AttemptedItemInfo itemInfo) {\n    synchronized (storageMovementAttemptedItems) {\n      storageMovementAttemptedItems.add(itemInfo);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementAttemptedItems.java",
          "extendedDetails": {
            "oldValue": "[itemInfo-ItemInfo, allBlockLocsAttemptedToSatisfy-boolean]",
            "newValue": "[itemInfo-AttemptedItemInfo]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,9 +1,5 @@\n-  public void add(ItemInfo itemInfo, boolean allBlockLocsAttemptedToSatisfy) {\n+  public void add(AttemptedItemInfo itemInfo) {\n     synchronized (storageMovementAttemptedItems) {\n-      AttemptedItemInfo attemptedItemInfo \u003d new AttemptedItemInfo(\n-          itemInfo.getStartId(), itemInfo.getTrackId(), monotonicNow(),\n-          allBlockLocsAttemptedToSatisfy);\n-      storageMovementAttemptedItems.put(itemInfo.getTrackId(),\n-          attemptedItemInfo);\n+      storageMovementAttemptedItems.add(itemInfo);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void add(AttemptedItemInfo itemInfo) {\n    synchronized (storageMovementAttemptedItems) {\n      storageMovementAttemptedItems.add(itemInfo);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementAttemptedItems.java",
          "extendedDetails": {}
        }
      ]
    },
    "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12291: [SPS]: Provide a mechanism to recursively iterate and satisfy storage policy of all the files under the given dir. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "bfd3f8bd8a9ae2186ec3e4addc71f912ec7b8923",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,9 @@\n   public void add(ItemInfo itemInfo, boolean allBlockLocsAttemptedToSatisfy) {\n     synchronized (storageMovementAttemptedItems) {\n       AttemptedItemInfo attemptedItemInfo \u003d new AttemptedItemInfo(\n-          itemInfo.getRootId(), itemInfo.getTrackId(), monotonicNow(),\n+          itemInfo.getStartId(), itemInfo.getTrackId(), monotonicNow(),\n           allBlockLocsAttemptedToSatisfy);\n       storageMovementAttemptedItems.put(itemInfo.getTrackId(),\n           attemptedItemInfo);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void add(ItemInfo itemInfo, boolean allBlockLocsAttemptedToSatisfy) {\n    synchronized (storageMovementAttemptedItems) {\n      AttemptedItemInfo attemptedItemInfo \u003d new AttemptedItemInfo(\n          itemInfo.getStartId(), itemInfo.getTrackId(), monotonicNow(),\n          allBlockLocsAttemptedToSatisfy);\n      storageMovementAttemptedItems.put(itemInfo.getTrackId(),\n          attemptedItemInfo);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementAttemptedItems.java",
      "extendedDetails": {}
    },
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-12225: [SPS]: Optimize extended attributes for tracking SPS movements. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-12225: [SPS]: Optimize extended attributes for tracking SPS movements. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "0e820f16af309cc8476edba448dd548686431133",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,9 @@\n-  public void add(Long blockCollectionID,\n-      boolean allBlockLocsAttemptedToSatisfy) {\n+  public void add(ItemInfo itemInfo, boolean allBlockLocsAttemptedToSatisfy) {\n     synchronized (storageMovementAttemptedItems) {\n-      ItemInfo itemInfo \u003d new ItemInfo(monotonicNow(),\n+      AttemptedItemInfo attemptedItemInfo \u003d new AttemptedItemInfo(\n+          itemInfo.getRootId(), itemInfo.getTrackId(), monotonicNow(),\n           allBlockLocsAttemptedToSatisfy);\n-      storageMovementAttemptedItems.put(blockCollectionID, itemInfo);\n+      storageMovementAttemptedItems.put(itemInfo.getTrackId(),\n+          attemptedItemInfo);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void add(ItemInfo itemInfo, boolean allBlockLocsAttemptedToSatisfy) {\n    synchronized (storageMovementAttemptedItems) {\n      AttemptedItemInfo attemptedItemInfo \u003d new AttemptedItemInfo(\n          itemInfo.getRootId(), itemInfo.getTrackId(), monotonicNow(),\n          allBlockLocsAttemptedToSatisfy);\n      storageMovementAttemptedItems.put(itemInfo.getTrackId(),\n          attemptedItemInfo);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementAttemptedItems.java",
          "extendedDetails": {
            "oldValue": "[blockCollectionID-Long, allBlockLocsAttemptedToSatisfy-boolean]",
            "newValue": "[itemInfo-ItemInfo, allBlockLocsAttemptedToSatisfy-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-12225: [SPS]: Optimize extended attributes for tracking SPS movements. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "0e820f16af309cc8476edba448dd548686431133",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,8 +1,9 @@\n-  public void add(Long blockCollectionID,\n-      boolean allBlockLocsAttemptedToSatisfy) {\n+  public void add(ItemInfo itemInfo, boolean allBlockLocsAttemptedToSatisfy) {\n     synchronized (storageMovementAttemptedItems) {\n-      ItemInfo itemInfo \u003d new ItemInfo(monotonicNow(),\n+      AttemptedItemInfo attemptedItemInfo \u003d new AttemptedItemInfo(\n+          itemInfo.getRootId(), itemInfo.getTrackId(), monotonicNow(),\n           allBlockLocsAttemptedToSatisfy);\n-      storageMovementAttemptedItems.put(blockCollectionID, itemInfo);\n+      storageMovementAttemptedItems.put(itemInfo.getTrackId(),\n+          attemptedItemInfo);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void add(ItemInfo itemInfo, boolean allBlockLocsAttemptedToSatisfy) {\n    synchronized (storageMovementAttemptedItems) {\n      AttemptedItemInfo attemptedItemInfo \u003d new AttemptedItemInfo(\n          itemInfo.getRootId(), itemInfo.getTrackId(), monotonicNow(),\n          allBlockLocsAttemptedToSatisfy);\n      storageMovementAttemptedItems.put(itemInfo.getTrackId(),\n          attemptedItemInfo);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementAttemptedItems.java",
          "extendedDetails": {}
        }
      ]
    },
    "b7bed9f00a25bcad6f9c3543f5a1fb0a1f23b0e9": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-11248: [SPS]: Handle partial block location movements. Contributed by Rakesh R\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "b7bed9f00a25bcad6f9c3543f5a1fb0a1f23b0e9",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-11248: [SPS]: Handle partial block location movements. Contributed by Rakesh R\n",
          "commitDate": "12/08/18 3:05 AM",
          "commitName": "b7bed9f00a25bcad6f9c3543f5a1fb0a1f23b0e9",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "5179d99b7e1faeac1ce041967480115913d9f795",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,8 @@\n-  public void add(Long blockCollectionID) {\n+  public void add(Long blockCollectionID,\n+      boolean allBlockLocsAttemptedToSatisfy) {\n     synchronized (storageMovementAttemptedItems) {\n-      storageMovementAttemptedItems.put(blockCollectionID, monotonicNow());\n+      ItemInfo itemInfo \u003d new ItemInfo(monotonicNow(),\n+          allBlockLocsAttemptedToSatisfy);\n+      storageMovementAttemptedItems.put(blockCollectionID, itemInfo);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void add(Long blockCollectionID,\n      boolean allBlockLocsAttemptedToSatisfy) {\n    synchronized (storageMovementAttemptedItems) {\n      ItemInfo itemInfo \u003d new ItemInfo(monotonicNow(),\n          allBlockLocsAttemptedToSatisfy);\n      storageMovementAttemptedItems.put(blockCollectionID, itemInfo);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementAttemptedItems.java",
          "extendedDetails": {
            "oldValue": "[blockCollectionID-Long]",
            "newValue": "[blockCollectionID-Long, allBlockLocsAttemptedToSatisfy-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-11248: [SPS]: Handle partial block location movements. Contributed by Rakesh R\n",
          "commitDate": "12/08/18 3:05 AM",
          "commitName": "b7bed9f00a25bcad6f9c3543f5a1fb0a1f23b0e9",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "5179d99b7e1faeac1ce041967480115913d9f795",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,5 +1,8 @@\n-  public void add(Long blockCollectionID) {\n+  public void add(Long blockCollectionID,\n+      boolean allBlockLocsAttemptedToSatisfy) {\n     synchronized (storageMovementAttemptedItems) {\n-      storageMovementAttemptedItems.put(blockCollectionID, monotonicNow());\n+      ItemInfo itemInfo \u003d new ItemInfo(monotonicNow(),\n+          allBlockLocsAttemptedToSatisfy);\n+      storageMovementAttemptedItems.put(blockCollectionID, itemInfo);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void add(Long blockCollectionID,\n      boolean allBlockLocsAttemptedToSatisfy) {\n    synchronized (storageMovementAttemptedItems) {\n      ItemInfo itemInfo \u003d new ItemInfo(monotonicNow(),\n          allBlockLocsAttemptedToSatisfy);\n      storageMovementAttemptedItems.put(blockCollectionID, itemInfo);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementAttemptedItems.java",
          "extendedDetails": {}
        }
      ]
    },
    "047526b4c27909f78313e1ed6216de85c6137f14": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11029. [SPS]:Provide retry mechanism for the blocks which were failed while moving its storage at DNs. Contributed by Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "047526b4c27909f78313e1ed6216de85c6137f14",
      "commitAuthor": "Rakesh Radhakrishnan",
      "diff": "@@ -0,0 +1,5 @@\n+  public void add(Long blockCollectionID) {\n+    synchronized (storageMovementAttemptedItems) {\n+      storageMovementAttemptedItems.put(blockCollectionID, monotonicNow());\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void add(Long blockCollectionID) {\n    synchronized (storageMovementAttemptedItems) {\n      storageMovementAttemptedItems.put(blockCollectionID, monotonicNow());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/BlockStorageMovementAttemptedItems.java"
    }
  }
}