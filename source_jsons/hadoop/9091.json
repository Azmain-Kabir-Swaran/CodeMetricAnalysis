{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSNamesystem.java",
  "functionName": "handleHeartbeat",
  "functionId": "handleHeartbeat___nodeReg-DatanodeRegistration__reports-StorageReport[]__cacheCapacity-long__cacheUsed-long__xceiverCount-int__xmitsInProgress-int__failedVolumes-int__volumeFailureSummary-VolumeFailureSummary__requestFullBlockReportLease-boolean__slowPeers-SlowPeerReports(annotations-@Nonnull)__slowDisks-SlowDiskReports(annotations-@Nonnull)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
  "functionStartLine": 4301,
  "functionEndLine": 4333,
  "numCommitsSeen": 4736,
  "timeTaken": 26912,
  "changeHistory": [
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
    "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
    "5179d99b7e1faeac1ce041967480115913d9f795",
    "cd5262aba00aa51b905aaac95e201d4d48f2480d",
    "0f2d1ddc2c41c8db800c58cabb150e71804fe23a",
    "e7c8da614c37e36fb8081234f4c639d6054f6082",
    "b57368b6f893cb27d77fc9425e116f1312f4790f",
    "e0fa49234fd37aca88e1caa95bac77bca192bae4",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893",
    "8602692338d6f493647205e0241e4116211fab75"
  ],
  "changeHistoryShort": {
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": "Ymultichange(Yparameterchange,Ybodychange)",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": "Ybodychange",
    "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10": "Ybodychange",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": "Ymultichange(Yparameterchange,Ybodychange)",
    "5179d99b7e1faeac1ce041967480115913d9f795": "Ybodychange",
    "cd5262aba00aa51b905aaac95e201d4d48f2480d": "Ybodychange",
    "0f2d1ddc2c41c8db800c58cabb150e71804fe23a": "Ymultichange(Yparameterchange,Ybodychange)",
    "e7c8da614c37e36fb8081234f4c639d6054f6082": "Ymultichange(Yparameterchange,Ybodychange)",
    "b57368b6f893cb27d77fc9425e116f1312f4790f": "Ymultichange(Yparameterchange,Ybodychange)",
    "e0fa49234fd37aca88e1caa95bac77bca192bae4": "Ybodychange",
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": "Ybodychange",
    "8602692338d6f493647205e0241e4116211fab75": "Ybodychange"
  },
  "changeHistoryDetails": {
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,46 +1,33 @@\n   HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xceiverCount, int xmitsInProgress, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n       @Nonnull SlowPeerReports slowPeers,\n-      @Nonnull SlowDiskReports slowDisks,\n-      BlocksStorageMoveAttemptFinished blksMovementsFinished)\n+      @Nonnull SlowDiskReports slowDisks)\n           throws IOException {\n     readLock();\n     try {\n       //get datanode commands\n       final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n           - xmitsInProgress;\n       DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n           nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n           xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n           slowPeers, slowDisks);\n       long blockReportLeaseId \u003d 0;\n       if (requestFullBlockReportLease) {\n         blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n       }\n \n-      // Handle blocks movement results sent by the coordinator datanode.\n-      SPSService sps \u003d blockManager.getSPSManager().getInternalSPSService();\n-      if (!sps.isRunning()) {\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\n-              \"Storage policy satisfier is not running. So, ignoring storage\"\n-                  + \"  movement attempt finished block info sent by DN\");\n-        }\n-      } else {\n-        sps.notifyStorageMovementAttemptFinishedBlks(blksMovementsFinished);\n-      }\n-\n       //create ha status\n       final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n           haContext.getState().getServiceState(),\n           getFSImage().getCorrectLastAppliedOrWrittenTxId());\n \n       return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n           blockReportLeaseId);\n     } finally {\n       readUnlock(\"handleHeartbeat\");\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xceiverCount, int xmitsInProgress, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks)\n          throws IOException {\n    readLock();\n    try {\n      //get datanode commands\n      final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n          - xmitsInProgress;\n      DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n          slowPeers, slowDisks);\n      long blockReportLeaseId \u003d 0;\n      if (requestFullBlockReportLease) {\n        blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n      }\n\n      //create ha status\n      final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n          haContext.getState().getServiceState(),\n          getFSImage().getCorrectLastAppliedOrWrittenTxId());\n\n      return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n          blockReportLeaseId);\n    } finally {\n      readUnlock(\"handleHeartbeat\");\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[nodeReg-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xceiverCount-int, xmitsInProgress-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull), slowDisks-SlowDiskReports(annotations-@Nonnull), blksMovementsFinished-BlocksStorageMoveAttemptFinished]",
            "newValue": "[nodeReg-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xceiverCount-int, xmitsInProgress-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull), slowDisks-SlowDiskReports(annotations-@Nonnull)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 3,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,46 +1,33 @@\n   HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xceiverCount, int xmitsInProgress, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n       @Nonnull SlowPeerReports slowPeers,\n-      @Nonnull SlowDiskReports slowDisks,\n-      BlocksStorageMoveAttemptFinished blksMovementsFinished)\n+      @Nonnull SlowDiskReports slowDisks)\n           throws IOException {\n     readLock();\n     try {\n       //get datanode commands\n       final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n           - xmitsInProgress;\n       DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n           nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n           xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n           slowPeers, slowDisks);\n       long blockReportLeaseId \u003d 0;\n       if (requestFullBlockReportLease) {\n         blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n       }\n \n-      // Handle blocks movement results sent by the coordinator datanode.\n-      SPSService sps \u003d blockManager.getSPSManager().getInternalSPSService();\n-      if (!sps.isRunning()) {\n-        if (LOG.isDebugEnabled()) {\n-          LOG.debug(\n-              \"Storage policy satisfier is not running. So, ignoring storage\"\n-                  + \"  movement attempt finished block info sent by DN\");\n-        }\n-      } else {\n-        sps.notifyStorageMovementAttemptFinishedBlks(blksMovementsFinished);\n-      }\n-\n       //create ha status\n       final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n           haContext.getState().getServiceState(),\n           getFSImage().getCorrectLastAppliedOrWrittenTxId());\n \n       return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n           blockReportLeaseId);\n     } finally {\n       readUnlock(\"handleHeartbeat\");\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xceiverCount, int xmitsInProgress, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks)\n          throws IOException {\n    readLock();\n    try {\n      //get datanode commands\n      final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n          - xmitsInProgress;\n      DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n          slowPeers, slowDisks);\n      long blockReportLeaseId \u003d 0;\n      if (requestFullBlockReportLease) {\n        blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n      }\n\n      //create ha status\n      final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n          haContext.getState().getServiceState(),\n          getFSImage().getCorrectLastAppliedOrWrittenTxId());\n\n      return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n          blockReportLeaseId);\n    } finally {\n      readUnlock(\"handleHeartbeat\");\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13097: [SPS]: Fix the branch review comments(Part1). Contributed by Surendra Singh.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "d3de4fb2a084cbadab8ef91f11aa7732d3b0f308",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,46 @@\n   HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xceiverCount, int xmitsInProgress, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks,\n       BlocksStorageMoveAttemptFinished blksMovementsFinished)\n           throws IOException {\n     readLock();\n     try {\n       //get datanode commands\n       final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n           - xmitsInProgress;\n       DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n           nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n           xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n           slowPeers, slowDisks);\n       long blockReportLeaseId \u003d 0;\n       if (requestFullBlockReportLease) {\n         blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n       }\n \n       // Handle blocks movement results sent by the coordinator datanode.\n-      StoragePolicySatisfier sps \u003d blockManager.getStoragePolicySatisfier();\n-      if (sps !\u003d null) {\n-        if (!sps.isRunning()) {\n-          if (LOG.isDebugEnabled()) {\n-            LOG.debug(\n-                \"Storage policy satisfier is not running. So, ignoring storage\"\n-                    + \"  movement attempt finished block info sent by DN\");\n-          }\n-        } else {\n-          sps.notifyStorageMovementAttemptFinishedBlks(blksMovementsFinished);\n+      SPSService sps \u003d blockManager.getSPSManager().getInternalSPSService();\n+      if (!sps.isRunning()) {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.debug(\n+              \"Storage policy satisfier is not running. So, ignoring storage\"\n+                  + \"  movement attempt finished block info sent by DN\");\n         }\n+      } else {\n+        sps.notifyStorageMovementAttemptFinishedBlks(blksMovementsFinished);\n       }\n \n       //create ha status\n       final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n           haContext.getState().getServiceState(),\n           getFSImage().getCorrectLastAppliedOrWrittenTxId());\n \n       return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n           blockReportLeaseId);\n     } finally {\n       readUnlock(\"handleHeartbeat\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xceiverCount, int xmitsInProgress, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks,\n      BlocksStorageMoveAttemptFinished blksMovementsFinished)\n          throws IOException {\n    readLock();\n    try {\n      //get datanode commands\n      final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n          - xmitsInProgress;\n      DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n          slowPeers, slowDisks);\n      long blockReportLeaseId \u003d 0;\n      if (requestFullBlockReportLease) {\n        blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n      }\n\n      // Handle blocks movement results sent by the coordinator datanode.\n      SPSService sps \u003d blockManager.getSPSManager().getInternalSPSService();\n      if (!sps.isRunning()) {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\n              \"Storage policy satisfier is not running. So, ignoring storage\"\n                  + \"  movement attempt finished block info sent by DN\");\n        }\n      } else {\n        sps.notifyStorageMovementAttemptFinishedBlks(blksMovementsFinished);\n      }\n\n      //create ha status\n      final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n          haContext.getState().getServiceState(),\n          getFSImage().getCorrectLastAppliedOrWrittenTxId());\n\n      return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n          blockReportLeaseId);\n    } finally {\n      readUnlock(\"handleHeartbeat\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13033: [SPS]: Implement a mechanism to do file block movements for external SPS. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "b0cb8d9bb44c963ae686d2b5c1b70bc76b955e10",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,48 @@\n   HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xceiverCount, int xmitsInProgress, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks,\n       BlocksStorageMoveAttemptFinished blksMovementsFinished)\n           throws IOException {\n     readLock();\n     try {\n       //get datanode commands\n       final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n           - xmitsInProgress;\n       DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n           nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n           xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n           slowPeers, slowDisks);\n       long blockReportLeaseId \u003d 0;\n       if (requestFullBlockReportLease) {\n         blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n       }\n \n       // Handle blocks movement results sent by the coordinator datanode.\n       StoragePolicySatisfier sps \u003d blockManager.getStoragePolicySatisfier();\n       if (sps !\u003d null) {\n         if (!sps.isRunning()) {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\n                 \"Storage policy satisfier is not running. So, ignoring storage\"\n                     + \"  movement attempt finished block info sent by DN\");\n           }\n         } else {\n-          sps.handleStorageMovementAttemptFinishedBlks(blksMovementsFinished);\n+          sps.notifyStorageMovementAttemptFinishedBlks(blksMovementsFinished);\n         }\n       }\n \n       //create ha status\n       final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n           haContext.getState().getServiceState(),\n           getFSImage().getCorrectLastAppliedOrWrittenTxId());\n \n       return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n           blockReportLeaseId);\n     } finally {\n       readUnlock(\"handleHeartbeat\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xceiverCount, int xmitsInProgress, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks,\n      BlocksStorageMoveAttemptFinished blksMovementsFinished)\n          throws IOException {\n    readLock();\n    try {\n      //get datanode commands\n      final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n          - xmitsInProgress;\n      DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n          slowPeers, slowDisks);\n      long blockReportLeaseId \u003d 0;\n      if (requestFullBlockReportLease) {\n        blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n      }\n\n      // Handle blocks movement results sent by the coordinator datanode.\n      StoragePolicySatisfier sps \u003d blockManager.getStoragePolicySatisfier();\n      if (sps !\u003d null) {\n        if (!sps.isRunning()) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\n                \"Storage policy satisfier is not running. So, ignoring storage\"\n                    + \"  movement attempt finished block info sent by DN\");\n          }\n        } else {\n          sps.notifyStorageMovementAttemptFinishedBlks(blksMovementsFinished);\n        }\n      }\n\n      //create ha status\n      final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n          haContext.getState().getServiceState(),\n          getFSImage().getCorrectLastAppliedOrWrittenTxId());\n\n      return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n          blockReportLeaseId);\n    } finally {\n      readUnlock(\"handleHeartbeat\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,47 +1,48 @@\n   HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xceiverCount, int xmitsInProgress, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks,\n-      BlocksStorageMovementResult[] blksMovementResults) throws IOException {\n+      BlocksStorageMoveAttemptFinished blksMovementsFinished)\n+          throws IOException {\n     readLock();\n     try {\n       //get datanode commands\n       final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n           - xmitsInProgress;\n       DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n           nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n           xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n           slowPeers, slowDisks);\n       long blockReportLeaseId \u003d 0;\n       if (requestFullBlockReportLease) {\n         blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n       }\n \n       // Handle blocks movement results sent by the coordinator datanode.\n       StoragePolicySatisfier sps \u003d blockManager.getStoragePolicySatisfier();\n       if (sps !\u003d null) {\n         if (!sps.isRunning()) {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\n-                \"Storage policy satisfier is not running. So, ignoring block \"\n-                    + \"storage movement results sent by co-ordinator datanode\");\n+                \"Storage policy satisfier is not running. So, ignoring storage\"\n+                    + \"  movement attempt finished block info sent by DN\");\n           }\n         } else {\n-          sps.handleBlocksStorageMovementResults(blksMovementResults);\n+          sps.handleStorageMovementAttemptFinishedBlks(blksMovementsFinished);\n         }\n       }\n \n       //create ha status\n       final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n           haContext.getState().getServiceState(),\n           getFSImage().getCorrectLastAppliedOrWrittenTxId());\n \n       return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n           blockReportLeaseId);\n     } finally {\n       readUnlock(\"handleHeartbeat\");\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xceiverCount, int xmitsInProgress, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks,\n      BlocksStorageMoveAttemptFinished blksMovementsFinished)\n          throws IOException {\n    readLock();\n    try {\n      //get datanode commands\n      final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n          - xmitsInProgress;\n      DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n          slowPeers, slowDisks);\n      long blockReportLeaseId \u003d 0;\n      if (requestFullBlockReportLease) {\n        blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n      }\n\n      // Handle blocks movement results sent by the coordinator datanode.\n      StoragePolicySatisfier sps \u003d blockManager.getStoragePolicySatisfier();\n      if (sps !\u003d null) {\n        if (!sps.isRunning()) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\n                \"Storage policy satisfier is not running. So, ignoring storage\"\n                    + \"  movement attempt finished block info sent by DN\");\n          }\n        } else {\n          sps.handleStorageMovementAttemptFinishedBlks(blksMovementsFinished);\n        }\n      }\n\n      //create ha status\n      final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n          haContext.getState().getServiceState(),\n          getFSImage().getCorrectLastAppliedOrWrittenTxId());\n\n      return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n          blockReportLeaseId);\n    } finally {\n      readUnlock(\"handleHeartbeat\");\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[nodeReg-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xceiverCount-int, xmitsInProgress-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull), slowDisks-SlowDiskReports(annotations-@Nonnull), blksMovementResults-BlocksStorageMovementResult[]]",
            "newValue": "[nodeReg-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xceiverCount-int, xmitsInProgress-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull), slowDisks-SlowDiskReports(annotations-@Nonnull), blksMovementsFinished-BlocksStorageMoveAttemptFinished]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:06 AM",
          "commitNameOld": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
          "commitAuthorOld": "Uma Maheswara Rao G",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 2,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,47 +1,48 @@\n   HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xceiverCount, int xmitsInProgress, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks,\n-      BlocksStorageMovementResult[] blksMovementResults) throws IOException {\n+      BlocksStorageMoveAttemptFinished blksMovementsFinished)\n+          throws IOException {\n     readLock();\n     try {\n       //get datanode commands\n       final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n           - xmitsInProgress;\n       DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n           nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n           xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n           slowPeers, slowDisks);\n       long blockReportLeaseId \u003d 0;\n       if (requestFullBlockReportLease) {\n         blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n       }\n \n       // Handle blocks movement results sent by the coordinator datanode.\n       StoragePolicySatisfier sps \u003d blockManager.getStoragePolicySatisfier();\n       if (sps !\u003d null) {\n         if (!sps.isRunning()) {\n           if (LOG.isDebugEnabled()) {\n             LOG.debug(\n-                \"Storage policy satisfier is not running. So, ignoring block \"\n-                    + \"storage movement results sent by co-ordinator datanode\");\n+                \"Storage policy satisfier is not running. So, ignoring storage\"\n+                    + \"  movement attempt finished block info sent by DN\");\n           }\n         } else {\n-          sps.handleBlocksStorageMovementResults(blksMovementResults);\n+          sps.handleStorageMovementAttemptFinishedBlks(blksMovementsFinished);\n         }\n       }\n \n       //create ha status\n       final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n           haContext.getState().getServiceState(),\n           getFSImage().getCorrectLastAppliedOrWrittenTxId());\n \n       return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n           blockReportLeaseId);\n     } finally {\n       readUnlock(\"handleHeartbeat\");\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xceiverCount, int xmitsInProgress, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks,\n      BlocksStorageMoveAttemptFinished blksMovementsFinished)\n          throws IOException {\n    readLock();\n    try {\n      //get datanode commands\n      final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n          - xmitsInProgress;\n      DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n          slowPeers, slowDisks);\n      long blockReportLeaseId \u003d 0;\n      if (requestFullBlockReportLease) {\n        blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n      }\n\n      // Handle blocks movement results sent by the coordinator datanode.\n      StoragePolicySatisfier sps \u003d blockManager.getStoragePolicySatisfier();\n      if (sps !\u003d null) {\n        if (!sps.isRunning()) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\n                \"Storage policy satisfier is not running. So, ignoring storage\"\n                    + \"  movement attempt finished block info sent by DN\");\n          }\n        } else {\n          sps.handleStorageMovementAttemptFinishedBlks(blksMovementsFinished);\n        }\n      }\n\n      //create ha status\n      final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n          haContext.getState().getServiceState(),\n          getFSImage().getCorrectLastAppliedOrWrittenTxId());\n\n      return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n          blockReportLeaseId);\n    } finally {\n      readUnlock(\"handleHeartbeat\");\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "5179d99b7e1faeac1ce041967480115913d9f795": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11123. [SPS] Make storage policy satisfier daemon work on/off dynamically. Contributed by Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "5179d99b7e1faeac1ce041967480115913d9f795",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "cd5262aba00aa51b905aaac95e201d4d48f2480d",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,47 @@\n   HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xceiverCount, int xmitsInProgress, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks,\n       BlocksStorageMovementResult[] blksMovementResults) throws IOException {\n     readLock();\n     try {\n       //get datanode commands\n       final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n           - xmitsInProgress;\n       DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n           nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n           xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n           slowPeers, slowDisks);\n       long blockReportLeaseId \u003d 0;\n       if (requestFullBlockReportLease) {\n         blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n       }\n \n-      // TODO: Handle blocks movement results send by the coordinator datanode.\n-      // This has to be revisited as part of HDFS-11029.\n-      if (blockManager.getStoragePolicySatisfier() !\u003d null) {\n-        blockManager.getStoragePolicySatisfier()\n-            .handleBlocksStorageMovementResults(blksMovementResults);\n+      // Handle blocks movement results sent by the coordinator datanode.\n+      StoragePolicySatisfier sps \u003d blockManager.getStoragePolicySatisfier();\n+      if (sps !\u003d null) {\n+        if (!sps.isRunning()) {\n+          if (LOG.isDebugEnabled()) {\n+            LOG.debug(\n+                \"Storage policy satisfier is not running. So, ignoring block \"\n+                    + \"storage movement results sent by co-ordinator datanode\");\n+          }\n+        } else {\n+          sps.handleBlocksStorageMovementResults(blksMovementResults);\n+        }\n       }\n \n       //create ha status\n       final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n           haContext.getState().getServiceState(),\n           getFSImage().getCorrectLastAppliedOrWrittenTxId());\n \n       return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n           blockReportLeaseId);\n     } finally {\n       readUnlock(\"handleHeartbeat\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xceiverCount, int xmitsInProgress, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks,\n      BlocksStorageMovementResult[] blksMovementResults) throws IOException {\n    readLock();\n    try {\n      //get datanode commands\n      final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n          - xmitsInProgress;\n      DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n          slowPeers, slowDisks);\n      long blockReportLeaseId \u003d 0;\n      if (requestFullBlockReportLease) {\n        blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n      }\n\n      // Handle blocks movement results sent by the coordinator datanode.\n      StoragePolicySatisfier sps \u003d blockManager.getStoragePolicySatisfier();\n      if (sps !\u003d null) {\n        if (!sps.isRunning()) {\n          if (LOG.isDebugEnabled()) {\n            LOG.debug(\n                \"Storage policy satisfier is not running. So, ignoring block \"\n                    + \"storage movement results sent by co-ordinator datanode\");\n          }\n        } else {\n          sps.handleBlocksStorageMovementResults(blksMovementResults);\n        }\n      }\n\n      //create ha status\n      final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n          haContext.getState().getServiceState(),\n          getFSImage().getCorrectLastAppliedOrWrittenTxId());\n\n      return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n          blockReportLeaseId);\n    } finally {\n      readUnlock(\"handleHeartbeat\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "cd5262aba00aa51b905aaac95e201d4d48f2480d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10885. [SPS]: Mover tool should not be allowed to run when Storage Policy Satisfier is on. Contributed by Wei Zhou\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "cd5262aba00aa51b905aaac95e201d4d48f2480d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "b67ae6d9d741e79ccf2bd6f08a37fce070e6ad77",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,40 @@\n   HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xceiverCount, int xmitsInProgress, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n       @Nonnull SlowPeerReports slowPeers,\n       @Nonnull SlowDiskReports slowDisks,\n       BlocksStorageMovementResult[] blksMovementResults) throws IOException {\n     readLock();\n     try {\n       //get datanode commands\n       final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n           - xmitsInProgress;\n       DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n           nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n           xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n           slowPeers, slowDisks);\n       long blockReportLeaseId \u003d 0;\n       if (requestFullBlockReportLease) {\n         blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n       }\n \n       // TODO: Handle blocks movement results send by the coordinator datanode.\n       // This has to be revisited as part of HDFS-11029.\n-      blockManager.getStoragePolicySatisfier()\n-          .handleBlocksStorageMovementResults(blksMovementResults);\n+      if (blockManager.getStoragePolicySatisfier() !\u003d null) {\n+        blockManager.getStoragePolicySatisfier()\n+            .handleBlocksStorageMovementResults(blksMovementResults);\n+      }\n \n       //create ha status\n       final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n           haContext.getState().getServiceState(),\n           getFSImage().getCorrectLastAppliedOrWrittenTxId());\n \n       return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n           blockReportLeaseId);\n     } finally {\n       readUnlock(\"handleHeartbeat\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xceiverCount, int xmitsInProgress, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks,\n      BlocksStorageMovementResult[] blksMovementResults) throws IOException {\n    readLock();\n    try {\n      //get datanode commands\n      final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n          - xmitsInProgress;\n      DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n          slowPeers, slowDisks);\n      long blockReportLeaseId \u003d 0;\n      if (requestFullBlockReportLease) {\n        blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n      }\n\n      // TODO: Handle blocks movement results send by the coordinator datanode.\n      // This has to be revisited as part of HDFS-11029.\n      if (blockManager.getStoragePolicySatisfier() !\u003d null) {\n        blockManager.getStoragePolicySatisfier()\n            .handleBlocksStorageMovementResults(blksMovementResults);\n      }\n\n      //create ha status\n      final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n          haContext.getState().getServiceState(),\n          getFSImage().getCorrectLastAppliedOrWrittenTxId());\n\n      return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n          blockReportLeaseId);\n    } finally {\n      readUnlock(\"handleHeartbeat\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "0f2d1ddc2c41c8db800c58cabb150e71804fe23a": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-10954. [SPS]: Provide mechanism to send blocks movement result back to NN from coordinator DN. Contributed by Rakesh R\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "0f2d1ddc2c41c8db800c58cabb150e71804fe23a",
      "commitAuthor": "Rakesh Radhakrishnan",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-10954. [SPS]: Provide mechanism to send blocks movement result back to NN from coordinator DN. Contributed by Rakesh R\n",
          "commitDate": "12/08/18 3:05 AM",
          "commitName": "0f2d1ddc2c41c8db800c58cabb150e71804fe23a",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "08/08/18 10:40 AM",
          "commitNameOld": "9499df7b81b55b488a32fd59798a543dafef4ef8",
          "commitAuthorOld": "Xiao Chen",
          "daysBetweenCommits": 3.68,
          "commitsBetweenForRepo": 27,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,31 +1,38 @@\n   HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xceiverCount, int xmitsInProgress, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n       @Nonnull SlowPeerReports slowPeers,\n-      @Nonnull SlowDiskReports slowDisks) throws IOException {\n+      @Nonnull SlowDiskReports slowDisks,\n+      BlocksStorageMovementResult[] blksMovementResults) throws IOException {\n     readLock();\n     try {\n       //get datanode commands\n       final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n           - xmitsInProgress;\n       DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n           nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n           xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n           slowPeers, slowDisks);\n       long blockReportLeaseId \u003d 0;\n       if (requestFullBlockReportLease) {\n         blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n       }\n+\n+      // TODO: Handle blocks movement results send by the coordinator datanode.\n+      // This has to be revisited as part of HDFS-11029.\n+      blockManager.getStoragePolicySatisfier()\n+          .handleBlocksStorageMovementResults(blksMovementResults);\n+\n       //create ha status\n       final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n           haContext.getState().getServiceState(),\n           getFSImage().getCorrectLastAppliedOrWrittenTxId());\n \n       return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n           blockReportLeaseId);\n     } finally {\n       readUnlock(\"handleHeartbeat\");\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xceiverCount, int xmitsInProgress, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks,\n      BlocksStorageMovementResult[] blksMovementResults) throws IOException {\n    readLock();\n    try {\n      //get datanode commands\n      final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n          - xmitsInProgress;\n      DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n          slowPeers, slowDisks);\n      long blockReportLeaseId \u003d 0;\n      if (requestFullBlockReportLease) {\n        blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n      }\n\n      // TODO: Handle blocks movement results send by the coordinator datanode.\n      // This has to be revisited as part of HDFS-11029.\n      blockManager.getStoragePolicySatisfier()\n          .handleBlocksStorageMovementResults(blksMovementResults);\n\n      //create ha status\n      final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n          haContext.getState().getServiceState(),\n          getFSImage().getCorrectLastAppliedOrWrittenTxId());\n\n      return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n          blockReportLeaseId);\n    } finally {\n      readUnlock(\"handleHeartbeat\");\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[nodeReg-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xceiverCount-int, xmitsInProgress-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull), slowDisks-SlowDiskReports(annotations-@Nonnull)]",
            "newValue": "[nodeReg-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xceiverCount-int, xmitsInProgress-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull), slowDisks-SlowDiskReports(annotations-@Nonnull), blksMovementResults-BlocksStorageMovementResult[]]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10954. [SPS]: Provide mechanism to send blocks movement result back to NN from coordinator DN. Contributed by Rakesh R\n",
          "commitDate": "12/08/18 3:05 AM",
          "commitName": "0f2d1ddc2c41c8db800c58cabb150e71804fe23a",
          "commitAuthor": "Rakesh Radhakrishnan",
          "commitDateOld": "08/08/18 10:40 AM",
          "commitNameOld": "9499df7b81b55b488a32fd59798a543dafef4ef8",
          "commitAuthorOld": "Xiao Chen",
          "daysBetweenCommits": 3.68,
          "commitsBetweenForRepo": 27,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,31 +1,38 @@\n   HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xceiverCount, int xmitsInProgress, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n       @Nonnull SlowPeerReports slowPeers,\n-      @Nonnull SlowDiskReports slowDisks) throws IOException {\n+      @Nonnull SlowDiskReports slowDisks,\n+      BlocksStorageMovementResult[] blksMovementResults) throws IOException {\n     readLock();\n     try {\n       //get datanode commands\n       final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n           - xmitsInProgress;\n       DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n           nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n           xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n           slowPeers, slowDisks);\n       long blockReportLeaseId \u003d 0;\n       if (requestFullBlockReportLease) {\n         blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n       }\n+\n+      // TODO: Handle blocks movement results send by the coordinator datanode.\n+      // This has to be revisited as part of HDFS-11029.\n+      blockManager.getStoragePolicySatisfier()\n+          .handleBlocksStorageMovementResults(blksMovementResults);\n+\n       //create ha status\n       final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n           haContext.getState().getServiceState(),\n           getFSImage().getCorrectLastAppliedOrWrittenTxId());\n \n       return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n           blockReportLeaseId);\n     } finally {\n       readUnlock(\"handleHeartbeat\");\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xceiverCount, int xmitsInProgress, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks,\n      BlocksStorageMovementResult[] blksMovementResults) throws IOException {\n    readLock();\n    try {\n      //get datanode commands\n      final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n          - xmitsInProgress;\n      DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n          slowPeers, slowDisks);\n      long blockReportLeaseId \u003d 0;\n      if (requestFullBlockReportLease) {\n        blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n      }\n\n      // TODO: Handle blocks movement results send by the coordinator datanode.\n      // This has to be revisited as part of HDFS-11029.\n      blockManager.getStoragePolicySatisfier()\n          .handleBlocksStorageMovementResults(blksMovementResults);\n\n      //create ha status\n      final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n          haContext.getState().getServiceState(),\n          getFSImage().getCorrectLastAppliedOrWrittenTxId());\n\n      return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n          blockReportLeaseId);\n    } finally {\n      readUnlock(\"handleHeartbeat\");\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "e7c8da614c37e36fb8081234f4c639d6054f6082": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-11545. Propagate DataNode\u0027s slow disks info to the NameNode via Heartbeats. Contributed by Hanisha Koneru.\n",
      "commitDate": "20/03/17 9:54 PM",
      "commitName": "e7c8da614c37e36fb8081234f4c639d6054f6082",
      "commitAuthor": "Arpit Agarwal",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-11545. Propagate DataNode\u0027s slow disks info to the NameNode via Heartbeats. Contributed by Hanisha Koneru.\n",
          "commitDate": "20/03/17 9:54 PM",
          "commitName": "e7c8da614c37e36fb8081234f4c639d6054f6082",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "16/03/17 8:54 AM",
          "commitNameOld": "ba62b50ebacd33b55eafc9db55a2fe5b4c80207a",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 4.54,
          "commitsBetweenForRepo": 18,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,30 +1,31 @@\n   HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xceiverCount, int xmitsInProgress, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n-      @Nonnull SlowPeerReports slowPeers) throws IOException {\n+      @Nonnull SlowPeerReports slowPeers,\n+      @Nonnull SlowDiskReports slowDisks) throws IOException {\n     readLock();\n     try {\n       //get datanode commands\n       final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n           - xmitsInProgress;\n       DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n           nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n           xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n-          slowPeers);\n+          slowPeers, slowDisks);\n       long blockReportLeaseId \u003d 0;\n       if (requestFullBlockReportLease) {\n         blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n       }\n       //create ha status\n       final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n           haContext.getState().getServiceState(),\n           getFSImage().getCorrectLastAppliedOrWrittenTxId());\n \n       return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n           blockReportLeaseId);\n     } finally {\n       readUnlock(\"handleHeartbeat\");\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xceiverCount, int xmitsInProgress, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks) throws IOException {\n    readLock();\n    try {\n      //get datanode commands\n      final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n          - xmitsInProgress;\n      DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n          slowPeers, slowDisks);\n      long blockReportLeaseId \u003d 0;\n      if (requestFullBlockReportLease) {\n        blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n      }\n      //create ha status\n      final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n          haContext.getState().getServiceState(),\n          getFSImage().getCorrectLastAppliedOrWrittenTxId());\n\n      return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n          blockReportLeaseId);\n    } finally {\n      readUnlock(\"handleHeartbeat\");\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[nodeReg-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xceiverCount-int, xmitsInProgress-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull)]",
            "newValue": "[nodeReg-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xceiverCount-int, xmitsInProgress-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull), slowDisks-SlowDiskReports(annotations-@Nonnull)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-11545. Propagate DataNode\u0027s slow disks info to the NameNode via Heartbeats. Contributed by Hanisha Koneru.\n",
          "commitDate": "20/03/17 9:54 PM",
          "commitName": "e7c8da614c37e36fb8081234f4c639d6054f6082",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "16/03/17 8:54 AM",
          "commitNameOld": "ba62b50ebacd33b55eafc9db55a2fe5b4c80207a",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 4.54,
          "commitsBetweenForRepo": 18,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,30 +1,31 @@\n   HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xceiverCount, int xmitsInProgress, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease,\n-      @Nonnull SlowPeerReports slowPeers) throws IOException {\n+      @Nonnull SlowPeerReports slowPeers,\n+      @Nonnull SlowDiskReports slowDisks) throws IOException {\n     readLock();\n     try {\n       //get datanode commands\n       final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n           - xmitsInProgress;\n       DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n           nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n           xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n-          slowPeers);\n+          slowPeers, slowDisks);\n       long blockReportLeaseId \u003d 0;\n       if (requestFullBlockReportLease) {\n         blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n       }\n       //create ha status\n       final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n           haContext.getState().getServiceState(),\n           getFSImage().getCorrectLastAppliedOrWrittenTxId());\n \n       return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n           blockReportLeaseId);\n     } finally {\n       readUnlock(\"handleHeartbeat\");\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xceiverCount, int xmitsInProgress, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers,\n      @Nonnull SlowDiskReports slowDisks) throws IOException {\n    readLock();\n    try {\n      //get datanode commands\n      final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n          - xmitsInProgress;\n      DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n          slowPeers, slowDisks);\n      long blockReportLeaseId \u003d 0;\n      if (requestFullBlockReportLease) {\n        blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n      }\n      //create ha status\n      final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n          haContext.getState().getServiceState(),\n          getFSImage().getCorrectLastAppliedOrWrittenTxId());\n\n      return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n          blockReportLeaseId);\n    } finally {\n      readUnlock(\"handleHeartbeat\");\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "b57368b6f893cb27d77fc9425e116f1312f4790f": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-11194. Maintain aggregated peer performance metrics on NameNode.\n",
      "commitDate": "24/01/17 4:58 PM",
      "commitName": "b57368b6f893cb27d77fc9425e116f1312f4790f",
      "commitAuthor": "Arpit Agarwal",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-11194. Maintain aggregated peer performance metrics on NameNode.\n",
          "commitDate": "24/01/17 4:58 PM",
          "commitName": "b57368b6f893cb27d77fc9425e116f1312f4790f",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "18/01/17 1:31 PM",
          "commitNameOld": "a2a5d7b5bca715835d92816e7b267b59f7270708",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 6.14,
          "commitsBetweenForRepo": 36,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,30 @@\n   HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xceiverCount, int xmitsInProgress, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n-      boolean requestFullBlockReportLease) throws IOException {\n+      boolean requestFullBlockReportLease,\n+      @Nonnull SlowPeerReports slowPeers) throws IOException {\n     readLock();\n     try {\n       //get datanode commands\n       final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n           - xmitsInProgress;\n       DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n           nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n-          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary);\n+          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n+          slowPeers);\n       long blockReportLeaseId \u003d 0;\n       if (requestFullBlockReportLease) {\n         blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n       }\n       //create ha status\n       final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n           haContext.getState().getServiceState(),\n           getFSImage().getCorrectLastAppliedOrWrittenTxId());\n \n       return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n           blockReportLeaseId);\n     } finally {\n       readUnlock(\"handleHeartbeat\");\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xceiverCount, int xmitsInProgress, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers) throws IOException {\n    readLock();\n    try {\n      //get datanode commands\n      final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n          - xmitsInProgress;\n      DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n          slowPeers);\n      long blockReportLeaseId \u003d 0;\n      if (requestFullBlockReportLease) {\n        blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n      }\n      //create ha status\n      final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n          haContext.getState().getServiceState(),\n          getFSImage().getCorrectLastAppliedOrWrittenTxId());\n\n      return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n          blockReportLeaseId);\n    } finally {\n      readUnlock(\"handleHeartbeat\");\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {
            "oldValue": "[nodeReg-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xceiverCount-int, xmitsInProgress-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean]",
            "newValue": "[nodeReg-DatanodeRegistration, reports-StorageReport[], cacheCapacity-long, cacheUsed-long, xceiverCount-int, xmitsInProgress-int, failedVolumes-int, volumeFailureSummary-VolumeFailureSummary, requestFullBlockReportLease-boolean, slowPeers-SlowPeerReports(annotations-@Nonnull)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-11194. Maintain aggregated peer performance metrics on NameNode.\n",
          "commitDate": "24/01/17 4:58 PM",
          "commitName": "b57368b6f893cb27d77fc9425e116f1312f4790f",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "18/01/17 1:31 PM",
          "commitNameOld": "a2a5d7b5bca715835d92816e7b267b59f7270708",
          "commitAuthorOld": "Andrew Wang",
          "daysBetweenCommits": 6.14,
          "commitsBetweenForRepo": 36,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,30 @@\n   HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xceiverCount, int xmitsInProgress, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n-      boolean requestFullBlockReportLease) throws IOException {\n+      boolean requestFullBlockReportLease,\n+      @Nonnull SlowPeerReports slowPeers) throws IOException {\n     readLock();\n     try {\n       //get datanode commands\n       final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n           - xmitsInProgress;\n       DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n           nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n-          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary);\n+          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n+          slowPeers);\n       long blockReportLeaseId \u003d 0;\n       if (requestFullBlockReportLease) {\n         blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n       }\n       //create ha status\n       final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n           haContext.getState().getServiceState(),\n           getFSImage().getCorrectLastAppliedOrWrittenTxId());\n \n       return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n           blockReportLeaseId);\n     } finally {\n       readUnlock(\"handleHeartbeat\");\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xceiverCount, int xmitsInProgress, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease,\n      @Nonnull SlowPeerReports slowPeers) throws IOException {\n    readLock();\n    try {\n      //get datanode commands\n      final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n          - xmitsInProgress;\n      DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary,\n          slowPeers);\n      long blockReportLeaseId \u003d 0;\n      if (requestFullBlockReportLease) {\n        blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n      }\n      //create ha status\n      final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n          haContext.getState().getServiceState(),\n          getFSImage().getCorrectLastAppliedOrWrittenTxId());\n\n      return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n          blockReportLeaseId);\n    } finally {\n      readUnlock(\"handleHeartbeat\");\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "e0fa49234fd37aca88e1caa95bac77bca192bae4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11180. Intermittent deadlock in NameNode when failover happens.\n",
      "commitDate": "01/12/16 6:08 AM",
      "commitName": "e0fa49234fd37aca88e1caa95bac77bca192bae4",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "28/11/16 6:08 PM",
      "commitNameOld": "47ca9e26fba4a639e43bee5bfc001ffc4b42330d",
      "commitAuthorOld": "Robert Kanter",
      "daysBetweenCommits": 2.5,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n   HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xceiverCount, int xmitsInProgress, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease) throws IOException {\n     readLock();\n     try {\n       //get datanode commands\n       final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n           - xmitsInProgress;\n       DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n           nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n           xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary);\n       long blockReportLeaseId \u003d 0;\n       if (requestFullBlockReportLease) {\n         blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n       }\n       //create ha status\n       final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n           haContext.getState().getServiceState(),\n-          getFSImage().getLastAppliedOrWrittenTxId());\n+          getFSImage().getCorrectLastAppliedOrWrittenTxId());\n \n       return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n           blockReportLeaseId);\n     } finally {\n       readUnlock(\"handleHeartbeat\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xceiverCount, int xmitsInProgress, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease) throws IOException {\n    readLock();\n    try {\n      //get datanode commands\n      final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n          - xmitsInProgress;\n      DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary);\n      long blockReportLeaseId \u003d 0;\n      if (requestFullBlockReportLease) {\n        blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n      }\n      //create ha status\n      final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n          haContext.getState().getServiceState(),\n          getFSImage().getCorrectLastAppliedOrWrittenTxId());\n\n      return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n          blockReportLeaseId);\n    } finally {\n      readUnlock(\"handleHeartbeat\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "ff0b99eafeda035ebe0dc82cfe689808047a8893": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10872. Add MutableRate metrics for FSNamesystemLock operations. Contributed by Erik Krogen.\n",
      "commitDate": "14/11/16 11:05 AM",
      "commitName": "ff0b99eafeda035ebe0dc82cfe689808047a8893",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "08/11/16 6:17 PM",
      "commitNameOld": "ed0bebabaaf27cd730f7f8eb002d92c9c7db327d",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 5.7,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n   HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xceiverCount, int xmitsInProgress, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease) throws IOException {\n     readLock();\n     try {\n       //get datanode commands\n       final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n           - xmitsInProgress;\n       DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n           nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n           xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary);\n       long blockReportLeaseId \u003d 0;\n       if (requestFullBlockReportLease) {\n         blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n       }\n       //create ha status\n       final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n           haContext.getState().getServiceState(),\n           getFSImage().getLastAppliedOrWrittenTxId());\n \n       return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n           blockReportLeaseId);\n     } finally {\n-      readUnlock();\n+      readUnlock(\"handleHeartbeat\");\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xceiverCount, int xmitsInProgress, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease) throws IOException {\n    readLock();\n    try {\n      //get datanode commands\n      final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n          - xmitsInProgress;\n      DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary);\n      long blockReportLeaseId \u003d 0;\n      if (requestFullBlockReportLease) {\n        blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n      }\n      //create ha status\n      final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n          haContext.getState().getServiceState(),\n          getFSImage().getLastAppliedOrWrittenTxId());\n\n      return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n          blockReportLeaseId);\n    } finally {\n      readUnlock(\"handleHeartbeat\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "8602692338d6f493647205e0241e4116211fab75": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9371. Code cleanup for DatanodeManager. Contributed by Jing Zhao.\n",
      "commitDate": "15/12/15 10:47 AM",
      "commitName": "8602692338d6f493647205e0241e4116211fab75",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "11/12/15 5:57 PM",
      "commitNameOld": "796a676d18bd7cd3ed4113d002e0e69cf261d6d1",
      "commitAuthorOld": "Uma Mahesh",
      "daysBetweenCommits": 3.7,
      "commitsBetweenForRepo": 19,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n   HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n       StorageReport[] reports, long cacheCapacity, long cacheUsed,\n       int xceiverCount, int xmitsInProgress, int failedVolumes,\n       VolumeFailureSummary volumeFailureSummary,\n       boolean requestFullBlockReportLease) throws IOException {\n     readLock();\n     try {\n       //get datanode commands\n       final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n           - xmitsInProgress;\n       DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n-          nodeReg, reports, blockPoolId, cacheCapacity, cacheUsed,\n+          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n           xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary);\n       long blockReportLeaseId \u003d 0;\n       if (requestFullBlockReportLease) {\n         blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n       }\n       //create ha status\n       final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n           haContext.getState().getServiceState(),\n           getFSImage().getLastAppliedOrWrittenTxId());\n \n       return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n           blockReportLeaseId);\n     } finally {\n       readUnlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  HeartbeatResponse handleHeartbeat(DatanodeRegistration nodeReg,\n      StorageReport[] reports, long cacheCapacity, long cacheUsed,\n      int xceiverCount, int xmitsInProgress, int failedVolumes,\n      VolumeFailureSummary volumeFailureSummary,\n      boolean requestFullBlockReportLease) throws IOException {\n    readLock();\n    try {\n      //get datanode commands\n      final int maxTransfer \u003d blockManager.getMaxReplicationStreams()\n          - xmitsInProgress;\n      DatanodeCommand[] cmds \u003d blockManager.getDatanodeManager().handleHeartbeat(\n          nodeReg, reports, getBlockPoolId(), cacheCapacity, cacheUsed,\n          xceiverCount, maxTransfer, failedVolumes, volumeFailureSummary);\n      long blockReportLeaseId \u003d 0;\n      if (requestFullBlockReportLease) {\n        blockReportLeaseId \u003d  blockManager.requestBlockReportLeaseId(nodeReg);\n      }\n      //create ha status\n      final NNHAStatusHeartbeat haState \u003d new NNHAStatusHeartbeat(\n          haContext.getState().getServiceState(),\n          getFSImage().getLastAppliedOrWrittenTxId());\n\n      return new HeartbeatResponse(cmds, haState, rollingUpgradeInfo,\n          blockReportLeaseId);\n    } finally {\n      readUnlock();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    }
  }
}