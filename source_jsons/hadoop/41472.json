{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FairScheduler.java",
  "functionName": "nodeUpdate",
  "functionId": "nodeUpdate___nm-RMNode",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
  "functionStartLine": 1004,
  "functionEndLine": 1018,
  "numCommitsSeen": 243,
  "timeTaken": 11901,
  "changeHistory": [
    "ea2c6c8c9a55813a19b3dbd0d29747d6a7739030",
    "4cc9479dae2bfb7d14d29b55d103eea9fa35a586",
    "f69a107aeccc68ca1085a7be8093d36b2f45eaa1",
    "ab1faa4ba80702fb04e28ffb23a4b3bb6e64ee16",
    "e0f2379312c48e26b0cb2c1e1e803ef71d1839cf",
    "754cb4e30fac1c5fe8d44626968c0ddbfe459335",
    "31f8da22d0b8d2dcce5fbc8e45d832f40acf056f",
    "20d389ce61eaacb5ddfb329015f50e96ad894f8d",
    "f9692770a58af0ab082eb7f15da9cbdcd177605b",
    "9ed17f181d96b8719a0ef54a129081948781d57e",
    "a44ce3f14fd940601f984fbf7980aa6fdc8f23b7",
    "150f5ae0343e872ee8bef39c57008c1389f0ba9e",
    "3fe57285635e8058c34aa40a103845b49ca7d6ff",
    "adf260a728df427eb729abe8fb9ad7248991ea54",
    "805a9ed85eb34c8125cfb7d26d07cdfac12b3579",
    "52948bb20bd1446164df1d3920c46c96dad750ae",
    "5c14bc426b4be381383018ebc2236be83eef15cd",
    "14864e9c7c879c15b5fa2d1776614ec83152918f",
    "82f3454f5ac1f1c457e668e2cee12b4dcc800ee1",
    "6990355e577ad19371cb656c250fb665ed14062f",
    "ae05623a75803d4e12a902ac4a24187540f56699",
    "51ccb87031eda6a2b75be098a88f1d89ea82c610",
    "e0562e3d07f29afbf283857293db0699dcb232c9",
    "d10428cab26c4c75328ecca118744041f2848251",
    "a43c344eee888f2a2488c8c9dca7e25a2cce10bf",
    "df55edd5dec9c944a6c38f08d6f1f0fdb901c880",
    "e74d1f0435c2bcdfae2c26f6c340a5a487d20aa3",
    "7ea82ca558c2e2fbb50277ee6ac7debdf9e94b69",
    "0768f96a833c16bf6136253d9ed846c72c4565bc",
    "ee007d3f38e6f437a79ca47f2ebd44966860746e",
    "ae6f1123f57c09a9cf5eed3e8c4659481417dc21",
    "d9050e12081c0e56e1185e330badcca00e5d4b21",
    "933a6d2c1ec8d3b373674e3e74eb472863fc464d",
    "e1fdf62123625e4ba399af02f8aad500637d29d1",
    "7f2b1eadc1b0807ec1302a0c3488bf6e7a59bc76",
    "1ef64e64c05ae5318cd4cb47d03a0494d742fb7c"
  ],
  "changeHistoryShort": {
    "ea2c6c8c9a55813a19b3dbd0d29747d6a7739030": "Ybodychange",
    "4cc9479dae2bfb7d14d29b55d103eea9fa35a586": "Ybodychange",
    "f69a107aeccc68ca1085a7be8093d36b2f45eaa1": "Ymodifierchange",
    "ab1faa4ba80702fb04e28ffb23a4b3bb6e64ee16": "Ymodifierchange",
    "e0f2379312c48e26b0cb2c1e1e803ef71d1839cf": "Ymodifierchange",
    "754cb4e30fac1c5fe8d44626968c0ddbfe459335": "Ymultichange(Ymodifierchange,Ybodychange)",
    "31f8da22d0b8d2dcce5fbc8e45d832f40acf056f": "Ymultichange(Ymodifierchange,Ybodychange)",
    "20d389ce61eaacb5ddfb329015f50e96ad894f8d": "Ybodychange",
    "f9692770a58af0ab082eb7f15da9cbdcd177605b": "Ybodychange",
    "9ed17f181d96b8719a0ef54a129081948781d57e": "Ybodychange",
    "a44ce3f14fd940601f984fbf7980aa6fdc8f23b7": "Ybodychange",
    "150f5ae0343e872ee8bef39c57008c1389f0ba9e": "Ybodychange",
    "3fe57285635e8058c34aa40a103845b49ca7d6ff": "Ybodychange",
    "adf260a728df427eb729abe8fb9ad7248991ea54": "Ybodychange",
    "805a9ed85eb34c8125cfb7d26d07cdfac12b3579": "Ybodychange",
    "52948bb20bd1446164df1d3920c46c96dad750ae": "Ybodychange",
    "5c14bc426b4be381383018ebc2236be83eef15cd": "Ybodychange",
    "14864e9c7c879c15b5fa2d1776614ec83152918f": "Ybodychange",
    "82f3454f5ac1f1c457e668e2cee12b4dcc800ee1": "Ybodychange",
    "6990355e577ad19371cb656c250fb665ed14062f": "Ybodychange",
    "ae05623a75803d4e12a902ac4a24187540f56699": "Ybodychange",
    "51ccb87031eda6a2b75be098a88f1d89ea82c610": "Ybodychange",
    "e0562e3d07f29afbf283857293db0699dcb232c9": "Ybodychange",
    "d10428cab26c4c75328ecca118744041f2848251": "Ybodychange",
    "a43c344eee888f2a2488c8c9dca7e25a2cce10bf": "Ybodychange",
    "df55edd5dec9c944a6c38f08d6f1f0fdb901c880": "Ybodychange",
    "e74d1f0435c2bcdfae2c26f6c340a5a487d20aa3": "Ybodychange",
    "7ea82ca558c2e2fbb50277ee6ac7debdf9e94b69": "Ymultichange(Yparameterchange,Ybodychange)",
    "0768f96a833c16bf6136253d9ed846c72c4565bc": "Ybodychange",
    "ee007d3f38e6f437a79ca47f2ebd44966860746e": "Ybodychange",
    "ae6f1123f57c09a9cf5eed3e8c4659481417dc21": "Ybodychange",
    "d9050e12081c0e56e1185e330badcca00e5d4b21": "Ybodychange",
    "933a6d2c1ec8d3b373674e3e74eb472863fc464d": "Ybodychange",
    "e1fdf62123625e4ba399af02f8aad500637d29d1": "Yfilerename",
    "7f2b1eadc1b0807ec1302a0c3488bf6e7a59bc76": "Ybodychange",
    "1ef64e64c05ae5318cd4cb47d03a0494d742fb7c": "Yintroduced"
  },
  "changeHistoryDetails": {
    "ea2c6c8c9a55813a19b3dbd0d29747d6a7739030": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7133. Clean up lock-try order in fair scheduler. (Szilard Nemeth via Haibo Chen)\n",
      "commitDate": "24/07/18 12:46 PM",
      "commitName": "ea2c6c8c9a55813a19b3dbd0d29747d6a7739030",
      "commitAuthor": "Haibo Chen",
      "commitDateOld": "11/06/18 11:12 AM",
      "commitNameOld": "c190ac2be88e574b3322cdc73a7c0af0cef708b2",
      "commitAuthorOld": "Haibo Chen",
      "daysBetweenCommits": 43.07,
      "commitsBetweenForRepo": 266,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,15 @@\n   protected void nodeUpdate(RMNode nm) {\n+    writeLock.lock();\n     try {\n-      writeLock.lock();\n       long start \u003d getClock().getTime();\n       super.nodeUpdate(nm);\n \n       FSSchedulerNode fsNode \u003d getFSSchedulerNode(nm.getNodeID());\n       attemptScheduling(fsNode);\n \n       long duration \u003d getClock().getTime() - start;\n       fsOpDurations.addNodeUpdateDuration(duration);\n     } finally {\n       writeLock.unlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void nodeUpdate(RMNode nm) {\n    writeLock.lock();\n    try {\n      long start \u003d getClock().getTime();\n      super.nodeUpdate(nm);\n\n      FSSchedulerNode fsNode \u003d getFSSchedulerNode(nm.getNodeID());\n      attemptScheduling(fsNode);\n\n      long duration \u003d getClock().getTime() - start;\n      fsOpDurations.addNodeUpdateDuration(duration);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "4cc9479dae2bfb7d14d29b55d103eea9fa35a586": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7524. Remove unused FairSchedulerEventLog. (Contributed by Wilfred Spiegelenburg)\n",
      "commitDate": "22/11/17 2:18 PM",
      "commitName": "4cc9479dae2bfb7d14d29b55d103eea9fa35a586",
      "commitAuthor": "Yufei Gu",
      "commitDateOld": "15/11/17 10:03 AM",
      "commitNameOld": "b246c547490dd94271806ca4caf1e5f199f0fb09",
      "commitAuthorOld": "Daniel Templeton",
      "daysBetweenCommits": 7.18,
      "commitsBetweenForRepo": 33,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,15 @@\n   protected void nodeUpdate(RMNode nm) {\n     try {\n       writeLock.lock();\n       long start \u003d getClock().getTime();\n-      eventLog.log(\"HEARTBEAT\", nm.getHostName());\n       super.nodeUpdate(nm);\n \n       FSSchedulerNode fsNode \u003d getFSSchedulerNode(nm.getNodeID());\n       attemptScheduling(fsNode);\n \n       long duration \u003d getClock().getTime() - start;\n       fsOpDurations.addNodeUpdateDuration(duration);\n     } finally {\n       writeLock.unlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void nodeUpdate(RMNode nm) {\n    try {\n      writeLock.lock();\n      long start \u003d getClock().getTime();\n      super.nodeUpdate(nm);\n\n      FSSchedulerNode fsNode \u003d getFSSchedulerNode(nm.getNodeID());\n      attemptScheduling(fsNode);\n\n      long duration \u003d getClock().getTime() - start;\n      fsOpDurations.addNodeUpdateDuration(duration);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "f69a107aeccc68ca1085a7be8093d36b2f45eaa1": {
      "type": "Ymodifierchange",
      "commitMessage": "YARN-6025. Fix synchronization issues of AbstractYarnScheduler#nodeUpdate and its implementations. (Naganarasimha G R via wangda)\n\n(cherry picked from commit e0f2379312c48e26b0cb2c1e1e803ef71d1839cf)\n",
      "commitDate": "03/01/17 2:53 PM",
      "commitName": "f69a107aeccc68ca1085a7be8093d36b2f45eaa1",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "03/01/17 2:53 PM",
      "commitNameOld": "ab1faa4ba80702fb04e28ffb23a4b3bb6e64ee16",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n-  protected synchronized void nodeUpdate(RMNode nm) {\n+  protected void nodeUpdate(RMNode nm) {\n     try {\n       writeLock.lock();\n       long start \u003d getClock().getTime();\n       eventLog.log(\"HEARTBEAT\", nm.getHostName());\n       super.nodeUpdate(nm);\n \n       FSSchedulerNode fsNode \u003d getFSSchedulerNode(nm.getNodeID());\n       attemptScheduling(fsNode);\n \n       long duration \u003d getClock().getTime() - start;\n       fsOpDurations.addNodeUpdateDuration(duration);\n     } finally {\n       writeLock.unlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void nodeUpdate(RMNode nm) {\n    try {\n      writeLock.lock();\n      long start \u003d getClock().getTime();\n      eventLog.log(\"HEARTBEAT\", nm.getHostName());\n      super.nodeUpdate(nm);\n\n      FSSchedulerNode fsNode \u003d getFSSchedulerNode(nm.getNodeID());\n      attemptScheduling(fsNode);\n\n      long duration \u003d getClock().getTime() - start;\n      fsOpDurations.addNodeUpdateDuration(duration);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {
        "oldValue": "[protected, synchronized]",
        "newValue": "[protected]"
      }
    },
    "ab1faa4ba80702fb04e28ffb23a4b3bb6e64ee16": {
      "type": "Ymodifierchange",
      "commitMessage": "Revert \"Fix synchronization issues of AbstractYarnScheduler#nodeUpdate and its implementations. (Naganarasimha G R via wangda)\" to add correct JIRA number\n\nThis reverts commit e0f2379312c48e26b0cb2c1e1e803ef71d1839cf.\n",
      "commitDate": "03/01/17 2:53 PM",
      "commitName": "ab1faa4ba80702fb04e28ffb23a4b3bb6e64ee16",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "03/01/17 2:46 PM",
      "commitNameOld": "e0f2379312c48e26b0cb2c1e1e803ef71d1839cf",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n-  protected void nodeUpdate(RMNode nm) {\n+  protected synchronized void nodeUpdate(RMNode nm) {\n     try {\n       writeLock.lock();\n       long start \u003d getClock().getTime();\n       eventLog.log(\"HEARTBEAT\", nm.getHostName());\n       super.nodeUpdate(nm);\n \n       FSSchedulerNode fsNode \u003d getFSSchedulerNode(nm.getNodeID());\n       attemptScheduling(fsNode);\n \n       long duration \u003d getClock().getTime() - start;\n       fsOpDurations.addNodeUpdateDuration(duration);\n     } finally {\n       writeLock.unlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected synchronized void nodeUpdate(RMNode nm) {\n    try {\n      writeLock.lock();\n      long start \u003d getClock().getTime();\n      eventLog.log(\"HEARTBEAT\", nm.getHostName());\n      super.nodeUpdate(nm);\n\n      FSSchedulerNode fsNode \u003d getFSSchedulerNode(nm.getNodeID());\n      attemptScheduling(fsNode);\n\n      long duration \u003d getClock().getTime() - start;\n      fsOpDurations.addNodeUpdateDuration(duration);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {
        "oldValue": "[protected]",
        "newValue": "[protected, synchronized]"
      }
    },
    "e0f2379312c48e26b0cb2c1e1e803ef71d1839cf": {
      "type": "Ymodifierchange",
      "commitMessage": "Fix synchronization issues of AbstractYarnScheduler#nodeUpdate and its implementations. (Naganarasimha G R via wangda)\n",
      "commitDate": "03/01/17 2:46 PM",
      "commitName": "e0f2379312c48e26b0cb2c1e1e803ef71d1839cf",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "07/12/16 11:12 AM",
      "commitNameOld": "9f5d2c4fff6d31acc8b422b52462ef4927c4eea1",
      "commitAuthorOld": "Daniel Templeton",
      "daysBetweenCommits": 27.15,
      "commitsBetweenForRepo": 116,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n-  protected synchronized void nodeUpdate(RMNode nm) {\n+  protected void nodeUpdate(RMNode nm) {\n     try {\n       writeLock.lock();\n       long start \u003d getClock().getTime();\n       eventLog.log(\"HEARTBEAT\", nm.getHostName());\n       super.nodeUpdate(nm);\n \n       FSSchedulerNode fsNode \u003d getFSSchedulerNode(nm.getNodeID());\n       attemptScheduling(fsNode);\n \n       long duration \u003d getClock().getTime() - start;\n       fsOpDurations.addNodeUpdateDuration(duration);\n     } finally {\n       writeLock.unlock();\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected void nodeUpdate(RMNode nm) {\n    try {\n      writeLock.lock();\n      long start \u003d getClock().getTime();\n      eventLog.log(\"HEARTBEAT\", nm.getHostName());\n      super.nodeUpdate(nm);\n\n      FSSchedulerNode fsNode \u003d getFSSchedulerNode(nm.getNodeID());\n      attemptScheduling(fsNode);\n\n      long duration \u003d getClock().getTime() - start;\n      fsOpDurations.addNodeUpdateDuration(duration);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {
        "oldValue": "[protected, synchronized]",
        "newValue": "[protected]"
      }
    },
    "754cb4e30fac1c5fe8d44626968c0ddbfe459335": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "YARN-5047. Refactor nodeUpdate across schedulers. (Ray Chiang via kasha)\n",
      "commitDate": "20/10/16 9:17 PM",
      "commitName": "754cb4e30fac1c5fe8d44626968c0ddbfe459335",
      "commitAuthor": "Karthik Kambatla",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-5047. Refactor nodeUpdate across schedulers. (Ray Chiang via kasha)\n",
          "commitDate": "20/10/16 9:17 PM",
          "commitName": "754cb4e30fac1c5fe8d44626968c0ddbfe459335",
          "commitAuthor": "Karthik Kambatla",
          "commitDateOld": "20/10/16 8:57 PM",
          "commitNameOld": "a064865abf7dceee46d3c42eca67a04a25af9d4e",
          "commitAuthorOld": "Karthik Kambatla",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,64 +1,16 @@\n-  private void nodeUpdate(RMNode nm) {\n+  protected synchronized void nodeUpdate(RMNode nm) {\n     try {\n       writeLock.lock();\n       long start \u003d getClock().getTime();\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\n-            \"nodeUpdate: \" + nm + \" cluster capacity: \" + getClusterResource());\n-      }\n       eventLog.log(\"HEARTBEAT\", nm.getHostName());\n-      FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n+      super.nodeUpdate(nm);\n \n-      List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n-      List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d\n-          new ArrayList\u003cContainerStatus\u003e();\n-      List\u003cContainerStatus\u003e completedContainers \u003d\n-          new ArrayList\u003cContainerStatus\u003e();\n-      for (UpdatedContainerInfo containerInfo : containerInfoList) {\n-        newlyLaunchedContainers.addAll(\n-            containerInfo.getNewlyLaunchedContainers());\n-        completedContainers.addAll(containerInfo.getCompletedContainers());\n-      }\n-      // Processing the newly launched containers\n-      for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n-        containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n-      }\n-\n-      // Process completed containers\n-      for (ContainerStatus completedContainer : completedContainers) {\n-        ContainerId containerId \u003d completedContainer.getContainerId();\n-        LOG.debug(\"Container FINISHED: \" + containerId);\n-        super.completedContainer(getRMContainer(containerId),\n-            completedContainer, RMContainerEventType.FINISHED);\n-      }\n-\n-      // If the node is decommissioning, send an update to have the total\n-      // resource equal to the used resource, so no available resource to\n-      // schedule.\n-      if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n-        this.rmContext.getDispatcher().getEventHandler().handle(\n-            new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n-                .newInstance(\n-                    getSchedulerNode(nm.getNodeID()).getAllocatedResource(),\n-                    0)));\n-      }\n-\n-      if (continuousSchedulingEnabled) {\n-        if (!completedContainers.isEmpty()) {\n-          attemptScheduling(node);\n-        }\n-      } else{\n-        attemptScheduling(node);\n-      }\n-\n-      // Updating node resource utilization\n-      node.setAggregatedContainersUtilization(\n-          nm.getAggregatedContainersUtilization());\n-      node.setNodeUtilization(nm.getNodeUtilization());\n+      FSSchedulerNode fsNode \u003d getFSSchedulerNode(nm.getNodeID());\n+      attemptScheduling(fsNode);\n \n       long duration \u003d getClock().getTime() - start;\n       fsOpDurations.addNodeUpdateDuration(duration);\n     } finally {\n       writeLock.unlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected synchronized void nodeUpdate(RMNode nm) {\n    try {\n      writeLock.lock();\n      long start \u003d getClock().getTime();\n      eventLog.log(\"HEARTBEAT\", nm.getHostName());\n      super.nodeUpdate(nm);\n\n      FSSchedulerNode fsNode \u003d getFSSchedulerNode(nm.getNodeID());\n      attemptScheduling(fsNode);\n\n      long duration \u003d getClock().getTime() - start;\n      fsOpDurations.addNodeUpdateDuration(duration);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[protected, synchronized]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-5047. Refactor nodeUpdate across schedulers. (Ray Chiang via kasha)\n",
          "commitDate": "20/10/16 9:17 PM",
          "commitName": "754cb4e30fac1c5fe8d44626968c0ddbfe459335",
          "commitAuthor": "Karthik Kambatla",
          "commitDateOld": "20/10/16 8:57 PM",
          "commitNameOld": "a064865abf7dceee46d3c42eca67a04a25af9d4e",
          "commitAuthorOld": "Karthik Kambatla",
          "daysBetweenCommits": 0.01,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,64 +1,16 @@\n-  private void nodeUpdate(RMNode nm) {\n+  protected synchronized void nodeUpdate(RMNode nm) {\n     try {\n       writeLock.lock();\n       long start \u003d getClock().getTime();\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\n-            \"nodeUpdate: \" + nm + \" cluster capacity: \" + getClusterResource());\n-      }\n       eventLog.log(\"HEARTBEAT\", nm.getHostName());\n-      FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n+      super.nodeUpdate(nm);\n \n-      List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n-      List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d\n-          new ArrayList\u003cContainerStatus\u003e();\n-      List\u003cContainerStatus\u003e completedContainers \u003d\n-          new ArrayList\u003cContainerStatus\u003e();\n-      for (UpdatedContainerInfo containerInfo : containerInfoList) {\n-        newlyLaunchedContainers.addAll(\n-            containerInfo.getNewlyLaunchedContainers());\n-        completedContainers.addAll(containerInfo.getCompletedContainers());\n-      }\n-      // Processing the newly launched containers\n-      for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n-        containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n-      }\n-\n-      // Process completed containers\n-      for (ContainerStatus completedContainer : completedContainers) {\n-        ContainerId containerId \u003d completedContainer.getContainerId();\n-        LOG.debug(\"Container FINISHED: \" + containerId);\n-        super.completedContainer(getRMContainer(containerId),\n-            completedContainer, RMContainerEventType.FINISHED);\n-      }\n-\n-      // If the node is decommissioning, send an update to have the total\n-      // resource equal to the used resource, so no available resource to\n-      // schedule.\n-      if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n-        this.rmContext.getDispatcher().getEventHandler().handle(\n-            new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n-                .newInstance(\n-                    getSchedulerNode(nm.getNodeID()).getAllocatedResource(),\n-                    0)));\n-      }\n-\n-      if (continuousSchedulingEnabled) {\n-        if (!completedContainers.isEmpty()) {\n-          attemptScheduling(node);\n-        }\n-      } else{\n-        attemptScheduling(node);\n-      }\n-\n-      // Updating node resource utilization\n-      node.setAggregatedContainersUtilization(\n-          nm.getAggregatedContainersUtilization());\n-      node.setNodeUtilization(nm.getNodeUtilization());\n+      FSSchedulerNode fsNode \u003d getFSSchedulerNode(nm.getNodeID());\n+      attemptScheduling(fsNode);\n \n       long duration \u003d getClock().getTime() - start;\n       fsOpDurations.addNodeUpdateDuration(duration);\n     } finally {\n       writeLock.unlock();\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected synchronized void nodeUpdate(RMNode nm) {\n    try {\n      writeLock.lock();\n      long start \u003d getClock().getTime();\n      eventLog.log(\"HEARTBEAT\", nm.getHostName());\n      super.nodeUpdate(nm);\n\n      FSSchedulerNode fsNode \u003d getFSSchedulerNode(nm.getNodeID());\n      attemptScheduling(fsNode);\n\n      long duration \u003d getClock().getTime() - start;\n      fsOpDurations.addNodeUpdateDuration(duration);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
          "extendedDetails": {}
        }
      ]
    },
    "31f8da22d0b8d2dcce5fbc8e45d832f40acf056f": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "YARN-3139. Improve locks in AbstractYarnScheduler/CapacityScheduler/FairScheduler. Contributed by Wangda Tan\n",
      "commitDate": "04/10/16 5:23 PM",
      "commitName": "31f8da22d0b8d2dcce5fbc8e45d832f40acf056f",
      "commitAuthor": "Jian He",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "YARN-3139. Improve locks in AbstractYarnScheduler/CapacityScheduler/FairScheduler. Contributed by Wangda Tan\n",
          "commitDate": "04/10/16 5:23 PM",
          "commitName": "31f8da22d0b8d2dcce5fbc8e45d832f40acf056f",
          "commitAuthor": "Jian He",
          "commitDateOld": "03/10/16 6:03 AM",
          "commitNameOld": "0da54e8848764c71a31473516d23ada582013f8c",
          "commitAuthorOld": "Karthik Kambatla",
          "daysBetweenCommits": 1.47,
          "commitsBetweenForRepo": 14,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,58 +1,64 @@\n-  private synchronized void nodeUpdate(RMNode nm) {\n-    long start \u003d getClock().getTime();\n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"nodeUpdate: \" + nm +\n-          \" cluster capacity: \" + getClusterResource());\n-    }\n-    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n-    FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n-    \n-    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n-    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n-    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n-    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n-      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n-      completedContainers.addAll(containerInfo.getCompletedContainers());\n-    } \n-    // Processing the newly launched containers\n-    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n-      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n-    }\n+  private void nodeUpdate(RMNode nm) {\n+    try {\n+      writeLock.lock();\n+      long start \u003d getClock().getTime();\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\n+            \"nodeUpdate: \" + nm + \" cluster capacity: \" + getClusterResource());\n+      }\n+      eventLog.log(\"HEARTBEAT\", nm.getHostName());\n+      FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n \n-    // Process completed containers\n-    for (ContainerStatus completedContainer : completedContainers) {\n-      ContainerId containerId \u003d completedContainer.getContainerId();\n-      LOG.debug(\"Container FINISHED: \" + containerId);\n-      super.completedContainer(getRMContainer(containerId),\n-          completedContainer, RMContainerEventType.FINISHED);\n-    }\n+      List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n+      List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d\n+          new ArrayList\u003cContainerStatus\u003e();\n+      List\u003cContainerStatus\u003e completedContainers \u003d\n+          new ArrayList\u003cContainerStatus\u003e();\n+      for (UpdatedContainerInfo containerInfo : containerInfoList) {\n+        newlyLaunchedContainers.addAll(\n+            containerInfo.getNewlyLaunchedContainers());\n+        completedContainers.addAll(containerInfo.getCompletedContainers());\n+      }\n+      // Processing the newly launched containers\n+      for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n+        containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n+      }\n \n-    // If the node is decommissioning, send an update to have the total\n-    // resource equal to the used resource, so no available resource to\n-    // schedule.\n-    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n-      this.rmContext\n-          .getDispatcher()\n-          .getEventHandler()\n-          .handle(\n-              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n-                  .newInstance(getSchedulerNode(nm.getNodeID())\n-                      .getAllocatedResource(), 0)));\n-    }\n+      // Process completed containers\n+      for (ContainerStatus completedContainer : completedContainers) {\n+        ContainerId containerId \u003d completedContainer.getContainerId();\n+        LOG.debug(\"Container FINISHED: \" + containerId);\n+        super.completedContainer(getRMContainer(containerId),\n+            completedContainer, RMContainerEventType.FINISHED);\n+      }\n \n-    if (continuousSchedulingEnabled) {\n-      if (!completedContainers.isEmpty()) {\n+      // If the node is decommissioning, send an update to have the total\n+      // resource equal to the used resource, so no available resource to\n+      // schedule.\n+      if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n+        this.rmContext.getDispatcher().getEventHandler().handle(\n+            new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n+                .newInstance(\n+                    getSchedulerNode(nm.getNodeID()).getAllocatedResource(),\n+                    0)));\n+      }\n+\n+      if (continuousSchedulingEnabled) {\n+        if (!completedContainers.isEmpty()) {\n+          attemptScheduling(node);\n+        }\n+      } else{\n         attemptScheduling(node);\n       }\n-    } else {\n-      attemptScheduling(node);\n+\n+      // Updating node resource utilization\n+      node.setAggregatedContainersUtilization(\n+          nm.getAggregatedContainersUtilization());\n+      node.setNodeUtilization(nm.getNodeUtilization());\n+\n+      long duration \u003d getClock().getTime() - start;\n+      fsOpDurations.addNodeUpdateDuration(duration);\n+    } finally {\n+      writeLock.unlock();\n     }\n-\n-    // Updating node resource utilization\n-    node.setAggregatedContainersUtilization(\n-        nm.getAggregatedContainersUtilization());\n-    node.setNodeUtilization(nm.getNodeUtilization());\n-\n-    long duration \u003d getClock().getTime() - start;\n-    fsOpDurations.addNodeUpdateDuration(duration);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void nodeUpdate(RMNode nm) {\n    try {\n      writeLock.lock();\n      long start \u003d getClock().getTime();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n            \"nodeUpdate: \" + nm + \" cluster capacity: \" + getClusterResource());\n      }\n      eventLog.log(\"HEARTBEAT\", nm.getHostName());\n      FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n\n      List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n      List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d\n          new ArrayList\u003cContainerStatus\u003e();\n      List\u003cContainerStatus\u003e completedContainers \u003d\n          new ArrayList\u003cContainerStatus\u003e();\n      for (UpdatedContainerInfo containerInfo : containerInfoList) {\n        newlyLaunchedContainers.addAll(\n            containerInfo.getNewlyLaunchedContainers());\n        completedContainers.addAll(containerInfo.getCompletedContainers());\n      }\n      // Processing the newly launched containers\n      for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n        containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n      }\n\n      // Process completed containers\n      for (ContainerStatus completedContainer : completedContainers) {\n        ContainerId containerId \u003d completedContainer.getContainerId();\n        LOG.debug(\"Container FINISHED: \" + containerId);\n        super.completedContainer(getRMContainer(containerId),\n            completedContainer, RMContainerEventType.FINISHED);\n      }\n\n      // If the node is decommissioning, send an update to have the total\n      // resource equal to the used resource, so no available resource to\n      // schedule.\n      if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n        this.rmContext.getDispatcher().getEventHandler().handle(\n            new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                .newInstance(\n                    getSchedulerNode(nm.getNodeID()).getAllocatedResource(),\n                    0)));\n      }\n\n      if (continuousSchedulingEnabled) {\n        if (!completedContainers.isEmpty()) {\n          attemptScheduling(node);\n        }\n      } else{\n        attemptScheduling(node);\n      }\n\n      // Updating node resource utilization\n      node.setAggregatedContainersUtilization(\n          nm.getAggregatedContainersUtilization());\n      node.setNodeUtilization(nm.getNodeUtilization());\n\n      long duration \u003d getClock().getTime() - start;\n      fsOpDurations.addNodeUpdateDuration(duration);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
          "extendedDetails": {
            "oldValue": "[private, synchronized]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-3139. Improve locks in AbstractYarnScheduler/CapacityScheduler/FairScheduler. Contributed by Wangda Tan\n",
          "commitDate": "04/10/16 5:23 PM",
          "commitName": "31f8da22d0b8d2dcce5fbc8e45d832f40acf056f",
          "commitAuthor": "Jian He",
          "commitDateOld": "03/10/16 6:03 AM",
          "commitNameOld": "0da54e8848764c71a31473516d23ada582013f8c",
          "commitAuthorOld": "Karthik Kambatla",
          "daysBetweenCommits": 1.47,
          "commitsBetweenForRepo": 14,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,58 +1,64 @@\n-  private synchronized void nodeUpdate(RMNode nm) {\n-    long start \u003d getClock().getTime();\n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"nodeUpdate: \" + nm +\n-          \" cluster capacity: \" + getClusterResource());\n-    }\n-    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n-    FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n-    \n-    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n-    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n-    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n-    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n-      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n-      completedContainers.addAll(containerInfo.getCompletedContainers());\n-    } \n-    // Processing the newly launched containers\n-    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n-      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n-    }\n+  private void nodeUpdate(RMNode nm) {\n+    try {\n+      writeLock.lock();\n+      long start \u003d getClock().getTime();\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\n+            \"nodeUpdate: \" + nm + \" cluster capacity: \" + getClusterResource());\n+      }\n+      eventLog.log(\"HEARTBEAT\", nm.getHostName());\n+      FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n \n-    // Process completed containers\n-    for (ContainerStatus completedContainer : completedContainers) {\n-      ContainerId containerId \u003d completedContainer.getContainerId();\n-      LOG.debug(\"Container FINISHED: \" + containerId);\n-      super.completedContainer(getRMContainer(containerId),\n-          completedContainer, RMContainerEventType.FINISHED);\n-    }\n+      List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n+      List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d\n+          new ArrayList\u003cContainerStatus\u003e();\n+      List\u003cContainerStatus\u003e completedContainers \u003d\n+          new ArrayList\u003cContainerStatus\u003e();\n+      for (UpdatedContainerInfo containerInfo : containerInfoList) {\n+        newlyLaunchedContainers.addAll(\n+            containerInfo.getNewlyLaunchedContainers());\n+        completedContainers.addAll(containerInfo.getCompletedContainers());\n+      }\n+      // Processing the newly launched containers\n+      for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n+        containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n+      }\n \n-    // If the node is decommissioning, send an update to have the total\n-    // resource equal to the used resource, so no available resource to\n-    // schedule.\n-    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n-      this.rmContext\n-          .getDispatcher()\n-          .getEventHandler()\n-          .handle(\n-              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n-                  .newInstance(getSchedulerNode(nm.getNodeID())\n-                      .getAllocatedResource(), 0)));\n-    }\n+      // Process completed containers\n+      for (ContainerStatus completedContainer : completedContainers) {\n+        ContainerId containerId \u003d completedContainer.getContainerId();\n+        LOG.debug(\"Container FINISHED: \" + containerId);\n+        super.completedContainer(getRMContainer(containerId),\n+            completedContainer, RMContainerEventType.FINISHED);\n+      }\n \n-    if (continuousSchedulingEnabled) {\n-      if (!completedContainers.isEmpty()) {\n+      // If the node is decommissioning, send an update to have the total\n+      // resource equal to the used resource, so no available resource to\n+      // schedule.\n+      if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n+        this.rmContext.getDispatcher().getEventHandler().handle(\n+            new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n+                .newInstance(\n+                    getSchedulerNode(nm.getNodeID()).getAllocatedResource(),\n+                    0)));\n+      }\n+\n+      if (continuousSchedulingEnabled) {\n+        if (!completedContainers.isEmpty()) {\n+          attemptScheduling(node);\n+        }\n+      } else{\n         attemptScheduling(node);\n       }\n-    } else {\n-      attemptScheduling(node);\n+\n+      // Updating node resource utilization\n+      node.setAggregatedContainersUtilization(\n+          nm.getAggregatedContainersUtilization());\n+      node.setNodeUtilization(nm.getNodeUtilization());\n+\n+      long duration \u003d getClock().getTime() - start;\n+      fsOpDurations.addNodeUpdateDuration(duration);\n+    } finally {\n+      writeLock.unlock();\n     }\n-\n-    // Updating node resource utilization\n-    node.setAggregatedContainersUtilization(\n-        nm.getAggregatedContainersUtilization());\n-    node.setNodeUtilization(nm.getNodeUtilization());\n-\n-    long duration \u003d getClock().getTime() - start;\n-    fsOpDurations.addNodeUpdateDuration(duration);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void nodeUpdate(RMNode nm) {\n    try {\n      writeLock.lock();\n      long start \u003d getClock().getTime();\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\n            \"nodeUpdate: \" + nm + \" cluster capacity: \" + getClusterResource());\n      }\n      eventLog.log(\"HEARTBEAT\", nm.getHostName());\n      FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n\n      List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n      List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d\n          new ArrayList\u003cContainerStatus\u003e();\n      List\u003cContainerStatus\u003e completedContainers \u003d\n          new ArrayList\u003cContainerStatus\u003e();\n      for (UpdatedContainerInfo containerInfo : containerInfoList) {\n        newlyLaunchedContainers.addAll(\n            containerInfo.getNewlyLaunchedContainers());\n        completedContainers.addAll(containerInfo.getCompletedContainers());\n      }\n      // Processing the newly launched containers\n      for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n        containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n      }\n\n      // Process completed containers\n      for (ContainerStatus completedContainer : completedContainers) {\n        ContainerId containerId \u003d completedContainer.getContainerId();\n        LOG.debug(\"Container FINISHED: \" + containerId);\n        super.completedContainer(getRMContainer(containerId),\n            completedContainer, RMContainerEventType.FINISHED);\n      }\n\n      // If the node is decommissioning, send an update to have the total\n      // resource equal to the used resource, so no available resource to\n      // schedule.\n      if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n        this.rmContext.getDispatcher().getEventHandler().handle(\n            new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                .newInstance(\n                    getSchedulerNode(nm.getNodeID()).getAllocatedResource(),\n                    0)));\n      }\n\n      if (continuousSchedulingEnabled) {\n        if (!completedContainers.isEmpty()) {\n          attemptScheduling(node);\n        }\n      } else{\n        attemptScheduling(node);\n      }\n\n      // Updating node resource utilization\n      node.setAggregatedContainersUtilization(\n          nm.getAggregatedContainersUtilization());\n      node.setNodeUtilization(nm.getNodeUtilization());\n\n      long duration \u003d getClock().getTime() - start;\n      fsOpDurations.addNodeUpdateDuration(duration);\n    } finally {\n      writeLock.unlock();\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
          "extendedDetails": {}
        }
      ]
    },
    "20d389ce61eaacb5ddfb329015f50e96ad894f8d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4719. Add a helper library to maintain node state and allows common queries. (kasha)\n",
      "commitDate": "14/03/16 2:19 PM",
      "commitName": "20d389ce61eaacb5ddfb329015f50e96ad894f8d",
      "commitAuthor": "Karthik Kambatla",
      "commitDateOld": "06/03/16 7:46 PM",
      "commitNameOld": "e1ccc9622b2f1fbefea1862fa74d1fb56d8eb264",
      "commitAuthorOld": "Zhihai Xu",
      "daysBetweenCommits": 7.73,
      "commitsBetweenForRepo": 44,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,57 +1,58 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     long start \u003d getClock().getTime();\n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n+      LOG.debug(\"nodeUpdate: \" + nm +\n+          \" cluster capacity: \" + getClusterResource());\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n     \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       super.completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     // If the node is decommissioning, send an update to have the total\n     // resource equal to the used resource, so no available resource to\n     // schedule.\n     if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n       this.rmContext\n           .getDispatcher()\n           .getEventHandler()\n           .handle(\n               new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                   .newInstance(getSchedulerNode(nm.getNodeID())\n                       .getAllocatedResource(), 0)));\n     }\n \n     if (continuousSchedulingEnabled) {\n       if (!completedContainers.isEmpty()) {\n         attemptScheduling(node);\n       }\n     } else {\n       attemptScheduling(node);\n     }\n \n     // Updating node resource utilization\n     node.setAggregatedContainersUtilization(\n         nm.getAggregatedContainersUtilization());\n     node.setNodeUtilization(nm.getNodeUtilization());\n \n     long duration \u003d getClock().getTime() - start;\n     fsOpDurations.addNodeUpdateDuration(duration);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    long start \u003d getClock().getTime();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm +\n          \" cluster capacity: \" + getClusterResource());\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n    \n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      super.completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // If the node is decommissioning, send an update to have the total\n    // resource equal to the used resource, so no available resource to\n    // schedule.\n    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n      this.rmContext\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                  .newInstance(getSchedulerNode(nm.getNodeID())\n                      .getAllocatedResource(), 0)));\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n\n    // Updating node resource utilization\n    node.setAggregatedContainersUtilization(\n        nm.getAggregatedContainersUtilization());\n    node.setNodeUtilization(nm.getNodeUtilization());\n\n    long duration \u003d getClock().getTime() - start;\n    fsOpDurations.addNodeUpdateDuration(duration);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "f9692770a58af0ab082eb7f15da9cbdcd177605b": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4718. Rename variables in SchedulerNode to reduce ambiguity post YARN-1011. (Inigo Goiri via kasha)\n",
      "commitDate": "28/02/16 9:35 AM",
      "commitName": "f9692770a58af0ab082eb7f15da9cbdcd177605b",
      "commitAuthor": "Karthik Kambatla",
      "commitDateOld": "23/02/16 3:30 AM",
      "commitNameOld": "9ed17f181d96b8719a0ef54a129081948781d57e",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 5.25,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,57 +1,57 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     long start \u003d getClock().getTime();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n     \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       super.completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     // If the node is decommissioning, send an update to have the total\n     // resource equal to the used resource, so no available resource to\n     // schedule.\n     if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n       this.rmContext\n           .getDispatcher()\n           .getEventHandler()\n           .handle(\n               new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                   .newInstance(getSchedulerNode(nm.getNodeID())\n-                      .getUsedResource(), 0)));\n+                      .getAllocatedResource(), 0)));\n     }\n \n     if (continuousSchedulingEnabled) {\n       if (!completedContainers.isEmpty()) {\n         attemptScheduling(node);\n       }\n     } else {\n       attemptScheduling(node);\n     }\n \n     // Updating node resource utilization\n     node.setAggregatedContainersUtilization(\n         nm.getAggregatedContainersUtilization());\n     node.setNodeUtilization(nm.getNodeUtilization());\n \n     long duration \u003d getClock().getTime() - start;\n     fsOpDurations.addNodeUpdateDuration(duration);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    long start \u003d getClock().getTime();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n    \n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      super.completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // If the node is decommissioning, send an update to have the total\n    // resource equal to the used resource, so no available resource to\n    // schedule.\n    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n      this.rmContext\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                  .newInstance(getSchedulerNode(nm.getNodeID())\n                      .getAllocatedResource(), 0)));\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n\n    // Updating node resource utilization\n    node.setAggregatedContainersUtilization(\n        nm.getAggregatedContainersUtilization());\n    node.setNodeUtilization(nm.getNodeUtilization());\n\n    long duration \u003d getClock().getTime() - start;\n    fsOpDurations.addNodeUpdateDuration(duration);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "9ed17f181d96b8719a0ef54a129081948781d57e": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3223. Resource update during NM graceful decommission. Contributed by Brook Zhou.\n",
      "commitDate": "23/02/16 3:30 AM",
      "commitName": "9ed17f181d96b8719a0ef54a129081948781d57e",
      "commitAuthor": "Junping Du",
      "commitDateOld": "21/01/16 8:40 AM",
      "commitNameOld": "4992398aeeb213ce59e068b0226e22e49ce559eb",
      "commitAuthorOld": "Karthik Kambatla",
      "daysBetweenCommits": 32.78,
      "commitsBetweenForRepo": 234,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,57 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     long start \u003d getClock().getTime();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n     \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       super.completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n+    // If the node is decommissioning, send an update to have the total\n+    // resource equal to the used resource, so no available resource to\n+    // schedule.\n+    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n+      this.rmContext\n+          .getDispatcher()\n+          .getEventHandler()\n+          .handle(\n+              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n+                  .newInstance(getSchedulerNode(nm.getNodeID())\n+                      .getUsedResource(), 0)));\n+    }\n+\n     if (continuousSchedulingEnabled) {\n       if (!completedContainers.isEmpty()) {\n         attemptScheduling(node);\n       }\n     } else {\n       attemptScheduling(node);\n     }\n \n     // Updating node resource utilization\n     node.setAggregatedContainersUtilization(\n         nm.getAggregatedContainersUtilization());\n     node.setNodeUtilization(nm.getNodeUtilization());\n \n     long duration \u003d getClock().getTime() - start;\n     fsOpDurations.addNodeUpdateDuration(duration);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    long start \u003d getClock().getTime();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n    \n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      super.completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // If the node is decommissioning, send an update to have the total\n    // resource equal to the used resource, so no available resource to\n    // schedule.\n    if (nm.getState() \u003d\u003d NodeState.DECOMMISSIONING) {\n      this.rmContext\n          .getDispatcher()\n          .getEventHandler()\n          .handle(\n              new RMNodeResourceUpdateEvent(nm.getNodeID(), ResourceOption\n                  .newInstance(getSchedulerNode(nm.getNodeID())\n                      .getUsedResource(), 0)));\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n\n    // Updating node resource utilization\n    node.setAggregatedContainersUtilization(\n        nm.getAggregatedContainersUtilization());\n    node.setNodeUtilization(nm.getNodeUtilization());\n\n    long duration \u003d getClock().getTime() - start;\n    fsOpDurations.addNodeUpdateDuration(duration);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "a44ce3f14fd940601f984fbf7980aa6fdc8f23b7": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4502. Fix two AM containers get allocated when AM restart. (Vinod Kumar Vavilapalli via wangda)\n",
      "commitDate": "18/01/16 5:30 PM",
      "commitName": "a44ce3f14fd940601f984fbf7980aa6fdc8f23b7",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "18/01/16 5:27 PM",
      "commitNameOld": "150f5ae0343e872ee8bef39c57008c1389f0ba9e",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     long start \u003d getClock().getTime();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n     \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n-      completedContainer(getRMContainer(containerId),\n+      super.completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     if (continuousSchedulingEnabled) {\n       if (!completedContainers.isEmpty()) {\n         attemptScheduling(node);\n       }\n     } else {\n       attemptScheduling(node);\n     }\n \n     // Updating node resource utilization\n     node.setAggregatedContainersUtilization(\n         nm.getAggregatedContainersUtilization());\n     node.setNodeUtilization(nm.getNodeUtilization());\n \n     long duration \u003d getClock().getTime() - start;\n     fsOpDurations.addNodeUpdateDuration(duration);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    long start \u003d getClock().getTime();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n    \n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      super.completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n\n    // Updating node resource utilization\n    node.setAggregatedContainersUtilization(\n        nm.getAggregatedContainersUtilization());\n    node.setNodeUtilization(nm.getNodeUtilization());\n\n    long duration \u003d getClock().getTime() - start;\n    fsOpDurations.addNodeUpdateDuration(duration);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "150f5ae0343e872ee8bef39c57008c1389f0ba9e": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"YARN-4502. Fix two AM containers get allocated when AM restart. (Vinod Kumar Vavilapalli via wangda)\"\n\nThis reverts commit 3fe57285635e8058c34aa40a103845b49ca7d6ff.\n\nConflicts:\n\thadoop-yarn-project/CHANGES.txt\n",
      "commitDate": "18/01/16 5:27 PM",
      "commitName": "150f5ae0343e872ee8bef39c57008c1389f0ba9e",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "18/01/16 1:58 AM",
      "commitNameOld": "d40859fab1ad977636457a6cc96b6a4f9b903afc",
      "commitAuthorOld": "Karthik Kambatla",
      "daysBetweenCommits": 0.65,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     long start \u003d getClock().getTime();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n     \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n-      super.completedContainer(getRMContainer(containerId),\n+      completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     if (continuousSchedulingEnabled) {\n       if (!completedContainers.isEmpty()) {\n         attemptScheduling(node);\n       }\n     } else {\n       attemptScheduling(node);\n     }\n \n     // Updating node resource utilization\n     node.setAggregatedContainersUtilization(\n         nm.getAggregatedContainersUtilization());\n     node.setNodeUtilization(nm.getNodeUtilization());\n \n     long duration \u003d getClock().getTime() - start;\n     fsOpDurations.addNodeUpdateDuration(duration);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    long start \u003d getClock().getTime();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n    \n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n\n    // Updating node resource utilization\n    node.setAggregatedContainersUtilization(\n        nm.getAggregatedContainersUtilization());\n    node.setNodeUtilization(nm.getNodeUtilization());\n\n    long duration \u003d getClock().getTime() - start;\n    fsOpDurations.addNodeUpdateDuration(duration);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "3fe57285635e8058c34aa40a103845b49ca7d6ff": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4502. Fix two AM containers get allocated when AM restart. (Vinod Kumar Vavilapalli via wangda)\n\n(cherry picked from commit 805a9ed85eb34c8125cfb7d26d07cdfac12b3579)\n",
      "commitDate": "18/01/16 1:06 AM",
      "commitName": "3fe57285635e8058c34aa40a103845b49ca7d6ff",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "18/01/16 12:50 AM",
      "commitNameOld": "adf260a728df427eb729abe8fb9ad7248991ea54",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     long start \u003d getClock().getTime();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n     \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n-      completedContainer(getRMContainer(containerId),\n+      super.completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     if (continuousSchedulingEnabled) {\n       if (!completedContainers.isEmpty()) {\n         attemptScheduling(node);\n       }\n     } else {\n       attemptScheduling(node);\n     }\n \n     // Updating node resource utilization\n     node.setAggregatedContainersUtilization(\n         nm.getAggregatedContainersUtilization());\n     node.setNodeUtilization(nm.getNodeUtilization());\n \n     long duration \u003d getClock().getTime() - start;\n     fsOpDurations.addNodeUpdateDuration(duration);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    long start \u003d getClock().getTime();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n    \n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      super.completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n\n    // Updating node resource utilization\n    node.setAggregatedContainersUtilization(\n        nm.getAggregatedContainersUtilization());\n    node.setNodeUtilization(nm.getNodeUtilization());\n\n    long duration \u003d getClock().getTime() - start;\n    fsOpDurations.addNodeUpdateDuration(duration);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "adf260a728df427eb729abe8fb9ad7248991ea54": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"YARN-4502. Fix two AM containers get allocated when AM restart. (Vinod Kumar Vavilapalli via wangda)\"\n\nThis reverts commit 805a9ed85eb34c8125cfb7d26d07cdfac12b3579.\n",
      "commitDate": "18/01/16 12:50 AM",
      "commitName": "adf260a728df427eb729abe8fb9ad7248991ea54",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "17/01/16 7:04 PM",
      "commitNameOld": "805a9ed85eb34c8125cfb7d26d07cdfac12b3579",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 0.24,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     long start \u003d getClock().getTime();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n     \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n-      super.completedContainer(getRMContainer(containerId),\n+      completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     if (continuousSchedulingEnabled) {\n       if (!completedContainers.isEmpty()) {\n         attemptScheduling(node);\n       }\n     } else {\n       attemptScheduling(node);\n     }\n \n     // Updating node resource utilization\n     node.setAggregatedContainersUtilization(\n         nm.getAggregatedContainersUtilization());\n     node.setNodeUtilization(nm.getNodeUtilization());\n \n     long duration \u003d getClock().getTime() - start;\n     fsOpDurations.addNodeUpdateDuration(duration);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    long start \u003d getClock().getTime();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n    \n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n\n    // Updating node resource utilization\n    node.setAggregatedContainersUtilization(\n        nm.getAggregatedContainersUtilization());\n    node.setNodeUtilization(nm.getNodeUtilization());\n\n    long duration \u003d getClock().getTime() - start;\n    fsOpDurations.addNodeUpdateDuration(duration);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "805a9ed85eb34c8125cfb7d26d07cdfac12b3579": {
      "type": "Ybodychange",
      "commitMessage": "YARN-4502. Fix two AM containers get allocated when AM restart. (Vinod Kumar Vavilapalli via wangda)\n",
      "commitDate": "17/01/16 7:04 PM",
      "commitName": "805a9ed85eb34c8125cfb7d26d07cdfac12b3579",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "14/12/15 10:52 AM",
      "commitNameOld": "6cb0af3c39a5d49cb2f7911ee21363a9542ca2d7",
      "commitAuthorOld": "Wangda Tan",
      "daysBetweenCommits": 34.34,
      "commitsBetweenForRepo": 200,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,44 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     long start \u003d getClock().getTime();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n     \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n-      completedContainer(getRMContainer(containerId),\n+      super.completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     if (continuousSchedulingEnabled) {\n       if (!completedContainers.isEmpty()) {\n         attemptScheduling(node);\n       }\n     } else {\n       attemptScheduling(node);\n     }\n \n     // Updating node resource utilization\n     node.setAggregatedContainersUtilization(\n         nm.getAggregatedContainersUtilization());\n     node.setNodeUtilization(nm.getNodeUtilization());\n \n     long duration \u003d getClock().getTime() - start;\n     fsOpDurations.addNodeUpdateDuration(duration);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    long start \u003d getClock().getTime();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n    \n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      super.completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n\n    // Updating node resource utilization\n    node.setAggregatedContainersUtilization(\n        nm.getAggregatedContainersUtilization());\n    node.setNodeUtilization(nm.getNodeUtilization());\n\n    long duration \u003d getClock().getTime() - start;\n    fsOpDurations.addNodeUpdateDuration(duration);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "52948bb20bd1446164df1d3920c46c96dad750ae": {
      "type": "Ybodychange",
      "commitMessage": "YARN-3980. Plumb resource-utilization info in node heartbeat through to the scheduler. (Inigo Goiri via kasha)\n",
      "commitDate": "24/11/15 12:17 AM",
      "commitName": "52948bb20bd1446164df1d3920c46c96dad750ae",
      "commitAuthor": "Karthik Kambatla",
      "commitDateOld": "24/10/15 10:53 PM",
      "commitNameOld": "ab8eb8770c8b8bff41dacb1a399d75906abb1ac4",
      "commitAuthorOld": "Arun Suresh",
      "daysBetweenCommits": 30.1,
      "commitsBetweenForRepo": 237,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,39 +1,44 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     long start \u003d getClock().getTime();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n     \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     if (continuousSchedulingEnabled) {\n       if (!completedContainers.isEmpty()) {\n         attemptScheduling(node);\n       }\n     } else {\n       attemptScheduling(node);\n     }\n \n+    // Updating node resource utilization\n+    node.setAggregatedContainersUtilization(\n+        nm.getAggregatedContainersUtilization());\n+    node.setNodeUtilization(nm.getNodeUtilization());\n+\n     long duration \u003d getClock().getTime() - start;\n     fsOpDurations.addNodeUpdateDuration(duration);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    long start \u003d getClock().getTime();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n    \n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n\n    // Updating node resource utilization\n    node.setAggregatedContainersUtilization(\n        nm.getAggregatedContainersUtilization());\n    node.setNodeUtilization(nm.getNodeUtilization());\n\n    long duration \u003d getClock().getTime() - start;\n    fsOpDurations.addNodeUpdateDuration(duration);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "5c14bc426b4be381383018ebc2236be83eef15cd": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1506. Changed RMNode/SchedulerNode to update resource with event notification. Contributed by Junping Du\n",
      "commitDate": "29/08/14 11:05 PM",
      "commitName": "5c14bc426b4be381383018ebc2236be83eef15cd",
      "commitAuthor": "Jian He",
      "commitDateOld": "22/08/14 8:44 AM",
      "commitNameOld": "0097b15e2150f95745f64179a0ef4644e96128f5",
      "commitAuthorOld": "Karthik Kambatla",
      "daysBetweenCommits": 7.6,
      "commitsBetweenForRepo": 52,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,42 +1,39 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     long start \u003d getClock().getTime();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n-\n-    // Update resource if any change\n-    SchedulerUtils.updateResourceIfChanged(node, nm, clusterResource, LOG);\n     \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     if (continuousSchedulingEnabled) {\n       if (!completedContainers.isEmpty()) {\n         attemptScheduling(node);\n       }\n     } else {\n       attemptScheduling(node);\n     }\n \n     long duration \u003d getClock().getTime() - start;\n     fsOpDurations.addNodeUpdateDuration(duration);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    long start \u003d getClock().getTime();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n    \n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n\n    long duration \u003d getClock().getTime() - start;\n    fsOpDurations.addNodeUpdateDuration(duration);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "14864e9c7c879c15b5fa2d1776614ec83152918f": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2352. FairScheduler: Collect metrics on duration of critical methods that affect performance. (kasha)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1616769 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/08/14 7:17 AM",
      "commitName": "14864e9c7c879c15b5fa2d1776614ec83152918f",
      "commitAuthor": "Karthik Kambatla",
      "commitDateOld": "29/07/14 10:41 AM",
      "commitNameOld": "c0b49ff10728bb70bb60e6cb5973976f0466d247",
      "commitAuthorOld": "Karthik Kambatla",
      "daysBetweenCommits": 9.86,
      "commitsBetweenForRepo": 74,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,42 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n+    long start \u003d getClock().getTime();\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n \n     // Update resource if any change\n     SchedulerUtils.updateResourceIfChanged(node, nm, clusterResource, LOG);\n     \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     if (continuousSchedulingEnabled) {\n       if (!completedContainers.isEmpty()) {\n         attemptScheduling(node);\n       }\n     } else {\n       attemptScheduling(node);\n     }\n+\n+    long duration \u003d getClock().getTime() - start;\n+    fsOpDurations.addNodeUpdateDuration(duration);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    long start \u003d getClock().getTime();\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n\n    // Update resource if any change\n    SchedulerUtils.updateResourceIfChanged(node, nm, clusterResource, LOG);\n    \n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n\n    long duration \u003d getClock().getTime() - start;\n    fsOpDurations.addNodeUpdateDuration(duration);\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "82f3454f5ac1f1c457e668e2cee12b4dcc800ee1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2017. Merged some of the common scheduler code. Contributed by Jian He.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1596753 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/05/14 10:32 PM",
      "commitName": "82f3454f5ac1f1c457e668e2cee12b4dcc800ee1",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "31/03/14 4:40 PM",
      "commitNameOld": "7bd62b8da03642612fae8349e967b9c0aa290843",
      "commitAuthorOld": "Sanford Ryza",
      "daysBetweenCommits": 51.24,
      "commitsBetweenForRepo": 299,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,38 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n+      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n-    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n+    FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n \n     // Update resource if any change\n-    SchedulerUtils.updateResourceIfChanged(node, nm, clusterCapacity, LOG);\n+    SchedulerUtils.updateResourceIfChanged(node, nm, clusterResource, LOG);\n     \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     if (continuousSchedulingEnabled) {\n       if (!completedContainers.isEmpty()) {\n         attemptScheduling(node);\n       }\n     } else {\n       attemptScheduling(node);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterResource);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d getFSSchedulerNode(nm.getNodeID());\n\n    // Update resource if any change\n    SchedulerUtils.updateResourceIfChanged(node, nm, clusterResource, LOG);\n    \n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "6990355e577ad19371cb656c250fb665ed14062f": {
      "type": "Ybodychange",
      "commitMessage": "YARN-311. RM/scheduler support for dynamic resource configuration. (Junping Du via llu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1539134 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/11/13 1:23 PM",
      "commitName": "6990355e577ad19371cb656c250fb665ed14062f",
      "commitAuthor": "Luke Lu",
      "commitDateOld": "31/10/13 7:54 PM",
      "commitNameOld": "da317f2ea5af8c12dd8ce04173239d5f9ace5d96",
      "commitAuthorOld": "Sanford Ryza",
      "daysBetweenCommits": 4.77,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,35 +1,38 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n \n+    // Update resource if any change\n+    SchedulerUtils.updateResourceIfChanged(node, nm, clusterCapacity, LOG);\n+    \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     if (continuousSchedulingEnabled) {\n       if (!completedContainers.isEmpty()) {\n         attemptScheduling(node);\n       }\n     } else {\n       attemptScheduling(node);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    // Update resource if any change\n    SchedulerUtils.updateResourceIfChanged(node, nm, clusterCapacity, LOG);\n    \n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "ae05623a75803d4e12a902ac4a24187540f56699": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1010. FairScheduler: decouple container scheduling from nodemanager heartbeats. (Wei Yan via Sandy Ryza)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1528192 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/10/13 12:54 PM",
      "commitName": "ae05623a75803d4e12a902ac4a24187540f56699",
      "commitAuthor": "Sanford Ryza",
      "commitDateOld": "29/09/13 1:21 AM",
      "commitNameOld": "1c5b49eeafc2253d4fa92456e6ccf0f35290c889",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 2.48,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,35 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n-    // Assign new containers...\n-    // 1. Check for reserved applications\n-    // 2. Schedule if there are no reservations\n-\n-    AppSchedulable reservedAppSchedulable \u003d node.getReservedAppSchedulable();\n-    if (reservedAppSchedulable !\u003d null) {\n-      Priority reservedPriority \u003d node.getReservedContainer().getReservedPriority();\n-      if (reservedAppSchedulable !\u003d null \u0026\u0026\n-          !reservedAppSchedulable.hasContainerForNode(reservedPriority, node)) {\n-        // Don\u0027t hold the reservation if app can no longer use it\n-        LOG.info(\"Releasing reservation that cannot be satisfied for application \"\n-            + reservedAppSchedulable.getApp().getApplicationAttemptId()\n-            + \" on node \" + nm);\n-        reservedAppSchedulable.unreserve(reservedPriority, node);\n-        reservedAppSchedulable \u003d null;\n-      } else {\n-        // Reservation exists; try to fulfill the reservation\n-        LOG.info(\"Trying to fulfill reservation for application \"\n-            + reservedAppSchedulable.getApp().getApplicationAttemptId()\n-            + \" on node: \" + nm);\n-\n-        node.getReservedAppSchedulable().assignReservedContainer(node);\n+    if (continuousSchedulingEnabled) {\n+      if (!completedContainers.isEmpty()) {\n+        attemptScheduling(node);\n       }\n+    } else {\n+      attemptScheduling(node);\n     }\n-    if (reservedAppSchedulable \u003d\u003d null) {\n-      // No reservation, schedule at queue which is farthest below fair share\n-      int assignedContainers \u003d 0;\n-      while (node.getReservedContainer() \u003d\u003d null) {\n-        boolean assignedContainer \u003d false;\n-        if (Resources.greaterThan(RESOURCE_CALCULATOR, clusterCapacity,\n-              queueMgr.getRootQueue().assignContainer(node),\n-              Resources.none())) {\n-          assignedContainers++;\n-          assignedContainer \u003d true;\n-        }\n-        if (!assignedContainer) { break; }\n-        if (!assignMultiple) { break; }\n-        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n-      }\n-    }\n-    updateRootQueueMetrics();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    if (continuousSchedulingEnabled) {\n      if (!completedContainers.isEmpty()) {\n        attemptScheduling(node);\n      }\n    } else {\n      attemptScheduling(node);\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "51ccb87031eda6a2b75be098a88f1d89ea82c610": {
      "type": "Ybodychange",
      "commitMessage": "YARN-655. Fair scheduler metrics should subtract allocated memory from available memory. (sandyr via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1480809 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/05/13 3:15 PM",
      "commitName": "51ccb87031eda6a2b75be098a88f1d89ea82c610",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "09/05/13 2:52 PM",
      "commitNameOld": "e0562e3d07f29afbf283857293db0699dcb232c9",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,69 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     // Assign new containers...\n     // 1. Check for reserved applications\n     // 2. Schedule if there are no reservations\n \n     AppSchedulable reservedAppSchedulable \u003d node.getReservedAppSchedulable();\n     if (reservedAppSchedulable !\u003d null) {\n       Priority reservedPriority \u003d node.getReservedContainer().getReservedPriority();\n       if (reservedAppSchedulable !\u003d null \u0026\u0026\n           !reservedAppSchedulable.hasContainerForNode(reservedPriority, node)) {\n         // Don\u0027t hold the reservation if app can no longer use it\n         LOG.info(\"Releasing reservation that cannot be satisfied for application \"\n             + reservedAppSchedulable.getApp().getApplicationAttemptId()\n             + \" on node \" + nm);\n         reservedAppSchedulable.unreserve(reservedPriority, node);\n         reservedAppSchedulable \u003d null;\n       } else {\n         // Reservation exists; try to fulfill the reservation\n         LOG.info(\"Trying to fulfill reservation for application \"\n             + reservedAppSchedulable.getApp().getApplicationAttemptId()\n             + \" on node: \" + nm);\n \n         node.getReservedAppSchedulable().assignReservedContainer(node);\n       }\n     }\n     if (reservedAppSchedulable \u003d\u003d null) {\n       // No reservation, schedule at queue which is farthest below fair share\n       int assignedContainers \u003d 0;\n       while (node.getReservedContainer() \u003d\u003d null) {\n         boolean assignedContainer \u003d false;\n         if (Resources.greaterThan(RESOURCE_CALCULATOR, clusterCapacity,\n               queueMgr.getRootQueue().assignContainer(node),\n               Resources.none())) {\n           assignedContainers++;\n           assignedContainer \u003d true;\n         }\n         if (!assignedContainer) { break; }\n         if (!assignMultiple) { break; }\n         if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n       }\n     }\n+    updateRootQueueMetrics();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    AppSchedulable reservedAppSchedulable \u003d node.getReservedAppSchedulable();\n    if (reservedAppSchedulable !\u003d null) {\n      Priority reservedPriority \u003d node.getReservedContainer().getReservedPriority();\n      if (reservedAppSchedulable !\u003d null \u0026\u0026\n          !reservedAppSchedulable.hasContainerForNode(reservedPriority, node)) {\n        // Don\u0027t hold the reservation if app can no longer use it\n        LOG.info(\"Releasing reservation that cannot be satisfied for application \"\n            + reservedAppSchedulable.getApp().getApplicationAttemptId()\n            + \" on node \" + nm);\n        reservedAppSchedulable.unreserve(reservedPriority, node);\n        reservedAppSchedulable \u003d null;\n      } else {\n        // Reservation exists; try to fulfill the reservation\n        LOG.info(\"Trying to fulfill reservation for application \"\n            + reservedAppSchedulable.getApp().getApplicationAttemptId()\n            + \" on node: \" + nm);\n\n        node.getReservedAppSchedulable().assignReservedContainer(node);\n      }\n    }\n    if (reservedAppSchedulable \u003d\u003d null) {\n      // No reservation, schedule at queue which is farthest below fair share\n      int assignedContainers \u003d 0;\n      while (node.getReservedContainer() \u003d\u003d null) {\n        boolean assignedContainer \u003d false;\n        if (Resources.greaterThan(RESOURCE_CALCULATOR, clusterCapacity,\n              queueMgr.getRootQueue().assignContainer(node),\n              Resources.none())) {\n          assignedContainers++;\n          assignedContainer \u003d true;\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n      }\n    }\n    updateRootQueueMetrics();\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "e0562e3d07f29afbf283857293db0699dcb232c9": {
      "type": "Ybodychange",
      "commitMessage": "YARN-637. FS: maxAssign is not honored. (kkambatl via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1480802 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/05/13 2:52 PM",
      "commitName": "e0562e3d07f29afbf283857293db0699dcb232c9",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "09/05/13 2:21 PM",
      "commitNameOld": "505fe2653941e4f36f61edd0fc2f8e750ceb5d8f",
      "commitAuthorOld": "Christopher Douglas",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,68 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     // Assign new containers...\n     // 1. Check for reserved applications\n     // 2. Schedule if there are no reservations\n \n     AppSchedulable reservedAppSchedulable \u003d node.getReservedAppSchedulable();\n     if (reservedAppSchedulable !\u003d null) {\n       Priority reservedPriority \u003d node.getReservedContainer().getReservedPriority();\n       if (reservedAppSchedulable !\u003d null \u0026\u0026\n           !reservedAppSchedulable.hasContainerForNode(reservedPriority, node)) {\n         // Don\u0027t hold the reservation if app can no longer use it\n         LOG.info(\"Releasing reservation that cannot be satisfied for application \"\n             + reservedAppSchedulable.getApp().getApplicationAttemptId()\n             + \" on node \" + nm);\n         reservedAppSchedulable.unreserve(reservedPriority, node);\n         reservedAppSchedulable \u003d null;\n       } else {\n         // Reservation exists; try to fulfill the reservation\n         LOG.info(\"Trying to fulfill reservation for application \"\n             + reservedAppSchedulable.getApp().getApplicationAttemptId()\n             + \" on node: \" + nm);\n \n         node.getReservedAppSchedulable().assignReservedContainer(node);\n       }\n     }\n     if (reservedAppSchedulable \u003d\u003d null) {\n       // No reservation, schedule at queue which is farthest below fair share\n       int assignedContainers \u003d 0;\n       while (node.getReservedContainer() \u003d\u003d null) {\n         boolean assignedContainer \u003d false;\n         if (Resources.greaterThan(RESOURCE_CALCULATOR, clusterCapacity,\n               queueMgr.getRootQueue().assignContainer(node),\n               Resources.none())) {\n+          assignedContainers++;\n           assignedContainer \u003d true;\n         }\n         if (!assignedContainer) { break; }\n         if (!assignMultiple) { break; }\n         if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    AppSchedulable reservedAppSchedulable \u003d node.getReservedAppSchedulable();\n    if (reservedAppSchedulable !\u003d null) {\n      Priority reservedPriority \u003d node.getReservedContainer().getReservedPriority();\n      if (reservedAppSchedulable !\u003d null \u0026\u0026\n          !reservedAppSchedulable.hasContainerForNode(reservedPriority, node)) {\n        // Don\u0027t hold the reservation if app can no longer use it\n        LOG.info(\"Releasing reservation that cannot be satisfied for application \"\n            + reservedAppSchedulable.getApp().getApplicationAttemptId()\n            + \" on node \" + nm);\n        reservedAppSchedulable.unreserve(reservedPriority, node);\n        reservedAppSchedulable \u003d null;\n      } else {\n        // Reservation exists; try to fulfill the reservation\n        LOG.info(\"Trying to fulfill reservation for application \"\n            + reservedAppSchedulable.getApp().getApplicationAttemptId()\n            + \" on node: \" + nm);\n\n        node.getReservedAppSchedulable().assignReservedContainer(node);\n      }\n    }\n    if (reservedAppSchedulable \u003d\u003d null) {\n      // No reservation, schedule at queue which is farthest below fair share\n      int assignedContainers \u003d 0;\n      while (node.getReservedContainer() \u003d\u003d null) {\n        boolean assignedContainer \u003d false;\n        if (Resources.greaterThan(RESOURCE_CALCULATOR, clusterCapacity,\n              queueMgr.getRootQueue().assignContainer(node),\n              Resources.none())) {\n          assignedContainers++;\n          assignedContainer \u003d true;\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "d10428cab26c4c75328ecca118744041f2848251": {
      "type": "Ybodychange",
      "commitMessage": "YARN-289. Fair scheduler allows reservations that won\u0027t fit on node. Contributed by Sandy Ryza.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1475681 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/04/13 2:15 AM",
      "commitName": "d10428cab26c4c75328ecca118744041f2848251",
      "commitAuthor": "Thomas White",
      "commitDateOld": "25/04/13 1:33 AM",
      "commitNameOld": "a43c344eee888f2a2488c8c9dca7e25a2cce10bf",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.03,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,56 +1,67 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     // Assign new containers...\n     // 1. Check for reserved applications\n     // 2. Schedule if there are no reservations\n \n     AppSchedulable reservedAppSchedulable \u003d node.getReservedAppSchedulable();\n     if (reservedAppSchedulable !\u003d null) {\n-      // Reservation exists; try to fulfill the reservation\n-      LOG.info(\"Trying to fulfill reservation for application \"\n-          + reservedAppSchedulable.getApp().getApplicationAttemptId()\n-          + \" on node: \" + nm);\n+      Priority reservedPriority \u003d node.getReservedContainer().getReservedPriority();\n+      if (reservedAppSchedulable !\u003d null \u0026\u0026\n+          !reservedAppSchedulable.hasContainerForNode(reservedPriority, node)) {\n+        // Don\u0027t hold the reservation if app can no longer use it\n+        LOG.info(\"Releasing reservation that cannot be satisfied for application \"\n+            + reservedAppSchedulable.getApp().getApplicationAttemptId()\n+            + \" on node \" + nm);\n+        reservedAppSchedulable.unreserve(reservedPriority, node);\n+        reservedAppSchedulable \u003d null;\n+      } else {\n+        // Reservation exists; try to fulfill the reservation\n+        LOG.info(\"Trying to fulfill reservation for application \"\n+            + reservedAppSchedulable.getApp().getApplicationAttemptId()\n+            + \" on node: \" + nm);\n \n-      node.getReservedAppSchedulable().assignReservedContainer(node);\n+        node.getReservedAppSchedulable().assignReservedContainer(node);\n+      }\n     }\n-    else {\n+    if (reservedAppSchedulable \u003d\u003d null) {\n       // No reservation, schedule at queue which is farthest below fair share\n       int assignedContainers \u003d 0;\n       while (node.getReservedContainer() \u003d\u003d null) {\n         boolean assignedContainer \u003d false;\n         if (Resources.greaterThan(RESOURCE_CALCULATOR, clusterCapacity,\n               queueMgr.getRootQueue().assignContainer(node),\n               Resources.none())) {\n           assignedContainer \u003d true;\n         }\n         if (!assignedContainer) { break; }\n         if (!assignMultiple) { break; }\n         if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    AppSchedulable reservedAppSchedulable \u003d node.getReservedAppSchedulable();\n    if (reservedAppSchedulable !\u003d null) {\n      Priority reservedPriority \u003d node.getReservedContainer().getReservedPriority();\n      if (reservedAppSchedulable !\u003d null \u0026\u0026\n          !reservedAppSchedulable.hasContainerForNode(reservedPriority, node)) {\n        // Don\u0027t hold the reservation if app can no longer use it\n        LOG.info(\"Releasing reservation that cannot be satisfied for application \"\n            + reservedAppSchedulable.getApp().getApplicationAttemptId()\n            + \" on node \" + nm);\n        reservedAppSchedulable.unreserve(reservedPriority, node);\n        reservedAppSchedulable \u003d null;\n      } else {\n        // Reservation exists; try to fulfill the reservation\n        LOG.info(\"Trying to fulfill reservation for application \"\n            + reservedAppSchedulable.getApp().getApplicationAttemptId()\n            + \" on node: \" + nm);\n\n        node.getReservedAppSchedulable().assignReservedContainer(node);\n      }\n    }\n    if (reservedAppSchedulable \u003d\u003d null) {\n      // No reservation, schedule at queue which is farthest below fair share\n      int assignedContainers \u003d 0;\n      while (node.getReservedContainer() \u003d\u003d null) {\n        boolean assignedContainer \u003d false;\n        if (Resources.greaterThan(RESOURCE_CALCULATOR, clusterCapacity,\n              queueMgr.getRootQueue().assignContainer(node),\n              Resources.none())) {\n          assignedContainer \u003d true;\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "a43c344eee888f2a2488c8c9dca7e25a2cce10bf": {
      "type": "Ybodychange",
      "commitMessage": "YARN-595. Refactor fair scheduler to use common Resources. Contributed by Sandy Ryza.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1475670 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/04/13 1:33 AM",
      "commitName": "a43c344eee888f2a2488c8c9dca7e25a2cce10bf",
      "commitAuthor": "Thomas White",
      "commitDateOld": "18/04/13 11:11 AM",
      "commitNameOld": "df55edd5dec9c944a6c38f08d6f1f0fdb901c880",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 6.6,
      "commitsBetweenForRepo": 37,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,56 +1,56 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     // Assign new containers...\n     // 1. Check for reserved applications\n     // 2. Schedule if there are no reservations\n \n     AppSchedulable reservedAppSchedulable \u003d node.getReservedAppSchedulable();\n     if (reservedAppSchedulable !\u003d null) {\n       // Reservation exists; try to fulfill the reservation\n       LOG.info(\"Trying to fulfill reservation for application \"\n           + reservedAppSchedulable.getApp().getApplicationAttemptId()\n           + \" on node: \" + nm);\n \n       node.getReservedAppSchedulable().assignReservedContainer(node);\n     }\n     else {\n       // No reservation, schedule at queue which is farthest below fair share\n       int assignedContainers \u003d 0;\n       while (node.getReservedContainer() \u003d\u003d null) {\n         boolean assignedContainer \u003d false;\n-        if (Resources.greaterThan(\n-            queueMgr.getRootQueue().assignContainer(node),\n-            Resources.none())) {\n+        if (Resources.greaterThan(RESOURCE_CALCULATOR, clusterCapacity,\n+              queueMgr.getRootQueue().assignContainer(node),\n+              Resources.none())) {\n           assignedContainer \u003d true;\n         }\n         if (!assignedContainer) { break; }\n         if (!assignMultiple) { break; }\n         if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    AppSchedulable reservedAppSchedulable \u003d node.getReservedAppSchedulable();\n    if (reservedAppSchedulable !\u003d null) {\n      // Reservation exists; try to fulfill the reservation\n      LOG.info(\"Trying to fulfill reservation for application \"\n          + reservedAppSchedulable.getApp().getApplicationAttemptId()\n          + \" on node: \" + nm);\n\n      node.getReservedAppSchedulable().assignReservedContainer(node);\n    }\n    else {\n      // No reservation, schedule at queue which is farthest below fair share\n      int assignedContainers \u003d 0;\n      while (node.getReservedContainer() \u003d\u003d null) {\n        boolean assignedContainer \u003d false;\n        if (Resources.greaterThan(RESOURCE_CALCULATOR, clusterCapacity,\n              queueMgr.getRootQueue().assignContainer(node),\n              Resources.none())) {\n          assignedContainer \u003d true;\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "df55edd5dec9c944a6c38f08d6f1f0fdb901c880": {
      "type": "Ybodychange",
      "commitMessage": "YARN-482. FS: Extend SchedulingMode to intermediate queues. (kkambatl via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1469506 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/04/13 11:11 AM",
      "commitName": "df55edd5dec9c944a6c38f08d6f1f0fdb901c880",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "05/04/13 10:45 AM",
      "commitNameOld": "bc6777dd5bdcbaef09897b506bc6511ae456033d",
      "commitAuthorOld": "Bikas Saha",
      "daysBetweenCommits": 13.02,
      "commitsBetweenForRepo": 63,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,71 +1,56 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     // Assign new containers...\n     // 1. Check for reserved applications\n     // 2. Schedule if there are no reservations\n \n-    // If we have have an application that has reserved a resource on this node\n-    // already, we try to complete the reservation.\n-    RMContainer reservedContainer \u003d node.getReservedContainer();\n-    if (reservedContainer !\u003d null) {\n-      FSSchedulerApp reservedApplication \u003d\n-          applications.get(reservedContainer.getApplicationAttemptId());\n+    AppSchedulable reservedAppSchedulable \u003d node.getReservedAppSchedulable();\n+    if (reservedAppSchedulable !\u003d null) {\n+      // Reservation exists; try to fulfill the reservation\n+      LOG.info(\"Trying to fulfill reservation for application \"\n+          + reservedAppSchedulable.getApp().getApplicationAttemptId()\n+          + \" on node: \" + nm);\n \n-      // Try to fulfill the reservation\n-      LOG.info(\"Trying to fulfill reservation for application \" +\n-          reservedApplication.getApplicationId() + \" on node: \" + nm);\n-\n-      FSLeafQueue queue \u003d queueMgr.getLeafQueue(reservedApplication.getQueueName());\n-      queue.assignContainer(node, true);\n+      node.getReservedAppSchedulable().assignReservedContainer(node);\n     }\n-\n-    // Otherwise, schedule at queue which is furthest below fair share\n     else {\n+      // No reservation, schedule at queue which is farthest below fair share\n       int assignedContainers \u003d 0;\n       while (node.getReservedContainer() \u003d\u003d null) {\n-        // At most one task is scheduled each iteration of this loop\n-        List\u003cFSLeafQueue\u003e scheds \u003d new ArrayList\u003cFSLeafQueue\u003e(\n-            queueMgr.getLeafQueues());\n-        Collections.sort(scheds, SchedulingMode.getDefault().getComparator());\n         boolean assignedContainer \u003d false;\n-        for (FSLeafQueue sched : scheds) {\n-          Resource assigned \u003d sched.assignContainer(node, false);\n-          if (Resources.greaterThan(assigned, Resources.none()) ||\n-              node.getReservedContainer() !\u003d null) {\n-            eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n-            assignedContainers++;\n-            assignedContainer \u003d true;\n-            break;\n-          }\n+        if (Resources.greaterThan(\n+            queueMgr.getRootQueue().assignContainer(node),\n+            Resources.none())) {\n+          assignedContainer \u003d true;\n         }\n         if (!assignedContainer) { break; }\n         if (!assignMultiple) { break; }\n         if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    AppSchedulable reservedAppSchedulable \u003d node.getReservedAppSchedulable();\n    if (reservedAppSchedulable !\u003d null) {\n      // Reservation exists; try to fulfill the reservation\n      LOG.info(\"Trying to fulfill reservation for application \"\n          + reservedAppSchedulable.getApp().getApplicationAttemptId()\n          + \" on node: \" + nm);\n\n      node.getReservedAppSchedulable().assignReservedContainer(node);\n    }\n    else {\n      // No reservation, schedule at queue which is farthest below fair share\n      int assignedContainers \u003d 0;\n      while (node.getReservedContainer() \u003d\u003d null) {\n        boolean assignedContainer \u003d false;\n        if (Resources.greaterThan(\n            queueMgr.getRootQueue().assignContainer(node),\n            Resources.none())) {\n          assignedContainer \u003d true;\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "e74d1f0435c2bcdfae2c26f6c340a5a487d20aa3": {
      "type": "Ybodychange",
      "commitMessage": "YARN-469. Make scheduling mode in FS pluggable. (kkambatl via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1460961 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/03/13 8:25 PM",
      "commitName": "e74d1f0435c2bcdfae2c26f6c340a5a487d20aa3",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "28/02/13 5:28 PM",
      "commitNameOld": "5d6eca08bd778fd971b29d3553d32cfc0dbe8d4e",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 25.08,
      "commitsBetweenForRepo": 137,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,71 +1,71 @@\n   private synchronized void nodeUpdate(RMNode nm) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n \n     List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n     List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n     for(UpdatedContainerInfo containerInfo : containerInfoList) {\n       newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n       completedContainers.addAll(containerInfo.getCompletedContainers());\n     } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     // Assign new containers...\n     // 1. Check for reserved applications\n     // 2. Schedule if there are no reservations\n \n     // If we have have an application that has reserved a resource on this node\n     // already, we try to complete the reservation.\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (reservedContainer !\u003d null) {\n       FSSchedulerApp reservedApplication \u003d\n           applications.get(reservedContainer.getApplicationAttemptId());\n \n       // Try to fulfill the reservation\n       LOG.info(\"Trying to fulfill reservation for application \" +\n           reservedApplication.getApplicationId() + \" on node: \" + nm);\n \n       FSLeafQueue queue \u003d queueMgr.getLeafQueue(reservedApplication.getQueueName());\n       queue.assignContainer(node, true);\n     }\n \n     // Otherwise, schedule at queue which is furthest below fair share\n     else {\n       int assignedContainers \u003d 0;\n       while (node.getReservedContainer() \u003d\u003d null) {\n         // At most one task is scheduled each iteration of this loop\n         List\u003cFSLeafQueue\u003e scheds \u003d new ArrayList\u003cFSLeafQueue\u003e(\n             queueMgr.getLeafQueues());\n-        Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n+        Collections.sort(scheds, SchedulingMode.getDefault().getComparator());\n         boolean assignedContainer \u003d false;\n         for (FSLeafQueue sched : scheds) {\n           Resource assigned \u003d sched.assignContainer(node, false);\n           if (Resources.greaterThan(assigned, Resources.none()) ||\n               node.getReservedContainer() !\u003d null) {\n             eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n             assignedContainers++;\n             assignedContainer \u003d true;\n             break;\n           }\n         }\n         if (!assignedContainer) { break; }\n         if (!assignMultiple) { break; }\n         if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    // If we have have an application that has reserved a resource on this node\n    // already, we try to complete the reservation.\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (reservedContainer !\u003d null) {\n      FSSchedulerApp reservedApplication \u003d\n          applications.get(reservedContainer.getApplicationAttemptId());\n\n      // Try to fulfill the reservation\n      LOG.info(\"Trying to fulfill reservation for application \" +\n          reservedApplication.getApplicationId() + \" on node: \" + nm);\n\n      FSLeafQueue queue \u003d queueMgr.getLeafQueue(reservedApplication.getQueueName());\n      queue.assignContainer(node, true);\n    }\n\n    // Otherwise, schedule at queue which is furthest below fair share\n    else {\n      int assignedContainers \u003d 0;\n      while (node.getReservedContainer() \u003d\u003d null) {\n        // At most one task is scheduled each iteration of this loop\n        List\u003cFSLeafQueue\u003e scheds \u003d new ArrayList\u003cFSLeafQueue\u003e(\n            queueMgr.getLeafQueues());\n        Collections.sort(scheds, SchedulingMode.getDefault().getComparator());\n        boolean assignedContainer \u003d false;\n        for (FSLeafQueue sched : scheds) {\n          Resource assigned \u003d sched.assignContainer(node, false);\n          if (Resources.greaterThan(assigned, Resources.none()) ||\n              node.getReservedContainer() !\u003d null) {\n            eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n            assignedContainers++;\n            assignedContainer \u003d true;\n            break;\n          }\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "7ea82ca558c2e2fbb50277ee6ac7debdf9e94b69": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-365. Change NM heartbeat handling to not generate a scheduler event on each heartbeat. (Contributed by Xuan Gong)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1450007 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/02/13 7:32 PM",
      "commitName": "7ea82ca558c2e2fbb50277ee6ac7debdf9e94b69",
      "commitAuthor": "Siddharth Seth",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-365. Change NM heartbeat handling to not generate a scheduler event on each heartbeat. (Contributed by Xuan Gong)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1450007 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "25/02/13 7:32 PM",
          "commitName": "7ea82ca558c2e2fbb50277ee6ac7debdf9e94b69",
          "commitAuthor": "Siddharth Seth",
          "commitDateOld": "23/01/13 2:53 AM",
          "commitNameOld": "345bcee0664392323b4297c0797897a96fef8958",
          "commitAuthorOld": "Thomas White",
          "daysBetweenCommits": 33.69,
          "commitsBetweenForRepo": 120,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,66 +1,71 @@\n-  private synchronized void nodeUpdate(RMNode nm,\n-      List\u003cContainerStatus\u003e newlyLaunchedContainers,\n-      List\u003cContainerStatus\u003e completedContainers) {\n+  private synchronized void nodeUpdate(RMNode nm) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n \n+    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n+    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n+    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n+    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n+      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n+      completedContainers.addAll(containerInfo.getCompletedContainers());\n+    } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     // Assign new containers...\n     // 1. Check for reserved applications\n     // 2. Schedule if there are no reservations\n \n     // If we have have an application that has reserved a resource on this node\n     // already, we try to complete the reservation.\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (reservedContainer !\u003d null) {\n       FSSchedulerApp reservedApplication \u003d\n           applications.get(reservedContainer.getApplicationAttemptId());\n \n       // Try to fulfill the reservation\n       LOG.info(\"Trying to fulfill reservation for application \" +\n           reservedApplication.getApplicationId() + \" on node: \" + nm);\n \n       FSLeafQueue queue \u003d queueMgr.getLeafQueue(reservedApplication.getQueueName());\n       queue.assignContainer(node, true);\n     }\n \n     // Otherwise, schedule at queue which is furthest below fair share\n     else {\n       int assignedContainers \u003d 0;\n       while (node.getReservedContainer() \u003d\u003d null) {\n         // At most one task is scheduled each iteration of this loop\n         List\u003cFSLeafQueue\u003e scheds \u003d new ArrayList\u003cFSLeafQueue\u003e(\n             queueMgr.getLeafQueues());\n         Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n         boolean assignedContainer \u003d false;\n         for (FSLeafQueue sched : scheds) {\n           Resource assigned \u003d sched.assignContainer(node, false);\n           if (Resources.greaterThan(assigned, Resources.none()) ||\n               node.getReservedContainer() !\u003d null) {\n             eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n             assignedContainers++;\n             assignedContainer \u003d true;\n             break;\n           }\n         }\n         if (!assignedContainer) { break; }\n         if (!assignMultiple) { break; }\n         if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    // If we have have an application that has reserved a resource on this node\n    // already, we try to complete the reservation.\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (reservedContainer !\u003d null) {\n      FSSchedulerApp reservedApplication \u003d\n          applications.get(reservedContainer.getApplicationAttemptId());\n\n      // Try to fulfill the reservation\n      LOG.info(\"Trying to fulfill reservation for application \" +\n          reservedApplication.getApplicationId() + \" on node: \" + nm);\n\n      FSLeafQueue queue \u003d queueMgr.getLeafQueue(reservedApplication.getQueueName());\n      queue.assignContainer(node, true);\n    }\n\n    // Otherwise, schedule at queue which is furthest below fair share\n    else {\n      int assignedContainers \u003d 0;\n      while (node.getReservedContainer() \u003d\u003d null) {\n        // At most one task is scheduled each iteration of this loop\n        List\u003cFSLeafQueue\u003e scheds \u003d new ArrayList\u003cFSLeafQueue\u003e(\n            queueMgr.getLeafQueues());\n        Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n        boolean assignedContainer \u003d false;\n        for (FSLeafQueue sched : scheds) {\n          Resource assigned \u003d sched.assignContainer(node, false);\n          if (Resources.greaterThan(assigned, Resources.none()) ||\n              node.getReservedContainer() !\u003d null) {\n            eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n            assignedContainers++;\n            assignedContainer \u003d true;\n            break;\n          }\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n      }\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
          "extendedDetails": {
            "oldValue": "[nm-RMNode, newlyLaunchedContainers-List\u003cContainerStatus\u003e, completedContainers-List\u003cContainerStatus\u003e]",
            "newValue": "[nm-RMNode]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-365. Change NM heartbeat handling to not generate a scheduler event on each heartbeat. (Contributed by Xuan Gong)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1450007 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "25/02/13 7:32 PM",
          "commitName": "7ea82ca558c2e2fbb50277ee6ac7debdf9e94b69",
          "commitAuthor": "Siddharth Seth",
          "commitDateOld": "23/01/13 2:53 AM",
          "commitNameOld": "345bcee0664392323b4297c0797897a96fef8958",
          "commitAuthorOld": "Thomas White",
          "daysBetweenCommits": 33.69,
          "commitsBetweenForRepo": 120,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,66 +1,71 @@\n-  private synchronized void nodeUpdate(RMNode nm,\n-      List\u003cContainerStatus\u003e newlyLaunchedContainers,\n-      List\u003cContainerStatus\u003e completedContainers) {\n+  private synchronized void nodeUpdate(RMNode nm) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n \n+    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n+    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n+    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n+    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n+      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n+      completedContainers.addAll(containerInfo.getCompletedContainers());\n+    } \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     // Assign new containers...\n     // 1. Check for reserved applications\n     // 2. Schedule if there are no reservations\n \n     // If we have have an application that has reserved a resource on this node\n     // already, we try to complete the reservation.\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (reservedContainer !\u003d null) {\n       FSSchedulerApp reservedApplication \u003d\n           applications.get(reservedContainer.getApplicationAttemptId());\n \n       // Try to fulfill the reservation\n       LOG.info(\"Trying to fulfill reservation for application \" +\n           reservedApplication.getApplicationId() + \" on node: \" + nm);\n \n       FSLeafQueue queue \u003d queueMgr.getLeafQueue(reservedApplication.getQueueName());\n       queue.assignContainer(node, true);\n     }\n \n     // Otherwise, schedule at queue which is furthest below fair share\n     else {\n       int assignedContainers \u003d 0;\n       while (node.getReservedContainer() \u003d\u003d null) {\n         // At most one task is scheduled each iteration of this loop\n         List\u003cFSLeafQueue\u003e scheds \u003d new ArrayList\u003cFSLeafQueue\u003e(\n             queueMgr.getLeafQueues());\n         Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n         boolean assignedContainer \u003d false;\n         for (FSLeafQueue sched : scheds) {\n           Resource assigned \u003d sched.assignContainer(node, false);\n           if (Resources.greaterThan(assigned, Resources.none()) ||\n               node.getReservedContainer() !\u003d null) {\n             eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n             assignedContainers++;\n             assignedContainer \u003d true;\n             break;\n           }\n         }\n         if (!assignedContainer) { break; }\n         if (!assignMultiple) { break; }\n         if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n       }\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private synchronized void nodeUpdate(RMNode nm) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    List\u003cUpdatedContainerInfo\u003e containerInfoList \u003d nm.pullContainerUpdates();\n    List\u003cContainerStatus\u003e newlyLaunchedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    List\u003cContainerStatus\u003e completedContainers \u003d new ArrayList\u003cContainerStatus\u003e();\n    for(UpdatedContainerInfo containerInfo : containerInfoList) {\n      newlyLaunchedContainers.addAll(containerInfo.getNewlyLaunchedContainers());\n      completedContainers.addAll(containerInfo.getCompletedContainers());\n    } \n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    // If we have have an application that has reserved a resource on this node\n    // already, we try to complete the reservation.\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (reservedContainer !\u003d null) {\n      FSSchedulerApp reservedApplication \u003d\n          applications.get(reservedContainer.getApplicationAttemptId());\n\n      // Try to fulfill the reservation\n      LOG.info(\"Trying to fulfill reservation for application \" +\n          reservedApplication.getApplicationId() + \" on node: \" + nm);\n\n      FSLeafQueue queue \u003d queueMgr.getLeafQueue(reservedApplication.getQueueName());\n      queue.assignContainer(node, true);\n    }\n\n    // Otherwise, schedule at queue which is furthest below fair share\n    else {\n      int assignedContainers \u003d 0;\n      while (node.getReservedContainer() \u003d\u003d null) {\n        // At most one task is scheduled each iteration of this loop\n        List\u003cFSLeafQueue\u003e scheds \u003d new ArrayList\u003cFSLeafQueue\u003e(\n            queueMgr.getLeafQueues());\n        Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n        boolean assignedContainer \u003d false;\n        for (FSLeafQueue sched : scheds) {\n          Resource assigned \u003d sched.assignContainer(node, false);\n          if (Resources.greaterThan(assigned, Resources.none()) ||\n              node.getReservedContainer() !\u003d null) {\n            eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n            assignedContainers++;\n            assignedContainer \u003d true;\n            break;\n          }\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n      }\n    }\n  }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
          "extendedDetails": {}
        }
      ]
    },
    "0768f96a833c16bf6136253d9ed846c72c4565bc": {
      "type": "Ybodychange",
      "commitMessage": "YARN-300. After YARN-271, fair scheduler can infinite loop and not schedule any application. Contributed by Sandy Ryza.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1428387 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/01/13 7:07 AM",
      "commitName": "0768f96a833c16bf6136253d9ed846c72c4565bc",
      "commitAuthor": "Thomas White",
      "commitDateOld": "03/01/13 6:32 AM",
      "commitNameOld": "19a291a0d65b64e50571c3519414b9d54acbe28a",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.02,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,66 @@\n   private synchronized void nodeUpdate(RMNode nm,\n       List\u003cContainerStatus\u003e newlyLaunchedContainers,\n       List\u003cContainerStatus\u003e completedContainers) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     // Assign new containers...\n     // 1. Check for reserved applications\n     // 2. Schedule if there are no reservations\n \n     // If we have have an application that has reserved a resource on this node\n     // already, we try to complete the reservation.\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (reservedContainer !\u003d null) {\n       FSSchedulerApp reservedApplication \u003d\n           applications.get(reservedContainer.getApplicationAttemptId());\n \n       // Try to fulfill the reservation\n       LOG.info(\"Trying to fulfill reservation for application \" +\n           reservedApplication.getApplicationId() + \" on node: \" + nm);\n \n       FSLeafQueue queue \u003d queueMgr.getLeafQueue(reservedApplication.getQueueName());\n       queue.assignContainer(node, true);\n     }\n \n     // Otherwise, schedule at queue which is furthest below fair share\n     else {\n       int assignedContainers \u003d 0;\n-      while (true) {\n+      while (node.getReservedContainer() \u003d\u003d null) {\n         // At most one task is scheduled each iteration of this loop\n         List\u003cFSLeafQueue\u003e scheds \u003d new ArrayList\u003cFSLeafQueue\u003e(\n             queueMgr.getLeafQueues());\n         Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n         boolean assignedContainer \u003d false;\n         for (FSLeafQueue sched : scheds) {\n           Resource assigned \u003d sched.assignContainer(node, false);\n           if (Resources.greaterThan(assigned, Resources.none()) ||\n               node.getReservedContainer() !\u003d null) {\n             eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n             assignedContainers++;\n             assignedContainer \u003d true;\n             break;\n           }\n         }\n         if (!assignedContainer) { break; }\n         if (!assignMultiple) { break; }\n         if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm,\n      List\u003cContainerStatus\u003e newlyLaunchedContainers,\n      List\u003cContainerStatus\u003e completedContainers) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    // If we have have an application that has reserved a resource on this node\n    // already, we try to complete the reservation.\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (reservedContainer !\u003d null) {\n      FSSchedulerApp reservedApplication \u003d\n          applications.get(reservedContainer.getApplicationAttemptId());\n\n      // Try to fulfill the reservation\n      LOG.info(\"Trying to fulfill reservation for application \" +\n          reservedApplication.getApplicationId() + \" on node: \" + nm);\n\n      FSLeafQueue queue \u003d queueMgr.getLeafQueue(reservedApplication.getQueueName());\n      queue.assignContainer(node, true);\n    }\n\n    // Otherwise, schedule at queue which is furthest below fair share\n    else {\n      int assignedContainers \u003d 0;\n      while (node.getReservedContainer() \u003d\u003d null) {\n        // At most one task is scheduled each iteration of this loop\n        List\u003cFSLeafQueue\u003e scheds \u003d new ArrayList\u003cFSLeafQueue\u003e(\n            queueMgr.getLeafQueues());\n        Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n        boolean assignedContainer \u003d false;\n        for (FSLeafQueue sched : scheds) {\n          Resource assigned \u003d sched.assignContainer(node, false);\n          if (Resources.greaterThan(assigned, Resources.none()) ||\n              node.getReservedContainer() !\u003d null) {\n            eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n            assignedContainers++;\n            assignedContainer \u003d true;\n            break;\n          }\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "ee007d3f38e6f437a79ca47f2ebd44966860746e": {
      "type": "Ybodychange",
      "commitMessage": "YARN-271. Fair scheduler hits IllegalStateException trying to reserve different apps on same node. Contributed by Sandy Ryza.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1424945 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/12/12 7:10 AM",
      "commitName": "ee007d3f38e6f437a79ca47f2ebd44966860746e",
      "commitAuthor": "Thomas White",
      "commitDateOld": "30/11/12 4:03 AM",
      "commitNameOld": "ae6f1123f57c09a9cf5eed3e8c4659481417dc21",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 21.13,
      "commitsBetweenForRepo": 83,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,66 @@\n   private synchronized void nodeUpdate(RMNode nm,\n       List\u003cContainerStatus\u003e newlyLaunchedContainers,\n       List\u003cContainerStatus\u003e completedContainers) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     // Assign new containers...\n     // 1. Check for reserved applications\n     // 2. Schedule if there are no reservations\n \n     // If we have have an application that has reserved a resource on this node\n     // already, we try to complete the reservation.\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (reservedContainer !\u003d null) {\n       FSSchedulerApp reservedApplication \u003d\n           applications.get(reservedContainer.getApplicationAttemptId());\n \n       // Try to fulfill the reservation\n       LOG.info(\"Trying to fulfill reservation for application \" +\n           reservedApplication.getApplicationId() + \" on node: \" + nm);\n \n       FSLeafQueue queue \u003d queueMgr.getLeafQueue(reservedApplication.getQueueName());\n       queue.assignContainer(node, true);\n     }\n \n     // Otherwise, schedule at queue which is furthest below fair share\n     else {\n       int assignedContainers \u003d 0;\n       while (true) {\n         // At most one task is scheduled each iteration of this loop\n         List\u003cFSLeafQueue\u003e scheds \u003d new ArrayList\u003cFSLeafQueue\u003e(\n             queueMgr.getLeafQueues());\n         Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n         boolean assignedContainer \u003d false;\n         for (FSLeafQueue sched : scheds) {\n           Resource assigned \u003d sched.assignContainer(node, false);\n-          if (Resources.greaterThan(assigned, Resources.none())) {\n+          if (Resources.greaterThan(assigned, Resources.none()) ||\n+              node.getReservedContainer() !\u003d null) {\n             eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n             assignedContainers++;\n             assignedContainer \u003d true;\n             break;\n           }\n         }\n         if (!assignedContainer) { break; }\n         if (!assignMultiple) { break; }\n         if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm,\n      List\u003cContainerStatus\u003e newlyLaunchedContainers,\n      List\u003cContainerStatus\u003e completedContainers) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    // If we have have an application that has reserved a resource on this node\n    // already, we try to complete the reservation.\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (reservedContainer !\u003d null) {\n      FSSchedulerApp reservedApplication \u003d\n          applications.get(reservedContainer.getApplicationAttemptId());\n\n      // Try to fulfill the reservation\n      LOG.info(\"Trying to fulfill reservation for application \" +\n          reservedApplication.getApplicationId() + \" on node: \" + nm);\n\n      FSLeafQueue queue \u003d queueMgr.getLeafQueue(reservedApplication.getQueueName());\n      queue.assignContainer(node, true);\n    }\n\n    // Otherwise, schedule at queue which is furthest below fair share\n    else {\n      int assignedContainers \u003d 0;\n      while (true) {\n        // At most one task is scheduled each iteration of this loop\n        List\u003cFSLeafQueue\u003e scheds \u003d new ArrayList\u003cFSLeafQueue\u003e(\n            queueMgr.getLeafQueues());\n        Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n        boolean assignedContainer \u003d false;\n        for (FSLeafQueue sched : scheds) {\n          Resource assigned \u003d sched.assignContainer(node, false);\n          if (Resources.greaterThan(assigned, Resources.none()) ||\n              node.getReservedContainer() !\u003d null) {\n            eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n            assignedContainers++;\n            assignedContainer \u003d true;\n            break;\n          }\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "ae6f1123f57c09a9cf5eed3e8c4659481417dc21": {
      "type": "Ybodychange",
      "commitMessage": "YARN-187. Add hierarchical queues to the fair scheduler. Contributed by Sandy Ryza.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1415592 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/11/12 4:03 AM",
      "commitName": "ae6f1123f57c09a9cf5eed3e8c4659481417dc21",
      "commitAuthor": "Thomas White",
      "commitDateOld": "28/11/12 5:56 PM",
      "commitNameOld": "1943fdbec613715f3cdc3ca60cbd273115f28299",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 1.42,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,65 @@\n   private synchronized void nodeUpdate(RMNode nm,\n       List\u003cContainerStatus\u003e newlyLaunchedContainers,\n       List\u003cContainerStatus\u003e completedContainers) {\n     if (LOG.isDebugEnabled()) {\n       LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n     }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     // Assign new containers...\n     // 1. Check for reserved applications\n     // 2. Schedule if there are no reservations\n \n     // If we have have an application that has reserved a resource on this node\n     // already, we try to complete the reservation.\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (reservedContainer !\u003d null) {\n       FSSchedulerApp reservedApplication \u003d\n           applications.get(reservedContainer.getApplicationAttemptId());\n \n       // Try to fulfill the reservation\n       LOG.info(\"Trying to fulfill reservation for application \" +\n           reservedApplication.getApplicationId() + \" on node: \" + nm);\n \n-      FSQueue queue \u003d queueMgr.getQueue(reservedApplication.getQueueName());\n-      queue.getQueueSchedulable().assignContainer(node, true);\n+      FSLeafQueue queue \u003d queueMgr.getLeafQueue(reservedApplication.getQueueName());\n+      queue.assignContainer(node, true);\n     }\n \n-\n     // Otherwise, schedule at queue which is furthest below fair share\n     else {\n       int assignedContainers \u003d 0;\n       while (true) {\n         // At most one task is scheduled each iteration of this loop\n-        List\u003cFSQueueSchedulable\u003e scheds \u003d getQueueSchedulables();\n+        List\u003cFSLeafQueue\u003e scheds \u003d new ArrayList\u003cFSLeafQueue\u003e(\n+            queueMgr.getLeafQueues());\n         Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n         boolean assignedContainer \u003d false;\n-        for (FSQueueSchedulable sched : scheds) {\n+        for (FSLeafQueue sched : scheds) {\n           Resource assigned \u003d sched.assignContainer(node, false);\n           if (Resources.greaterThan(assigned, Resources.none())) {\n             eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n             assignedContainers++;\n             assignedContainer \u003d true;\n             break;\n           }\n         }\n         if (!assignedContainer) { break; }\n         if (!assignMultiple) { break; }\n         if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm,\n      List\u003cContainerStatus\u003e newlyLaunchedContainers,\n      List\u003cContainerStatus\u003e completedContainers) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    // If we have have an application that has reserved a resource on this node\n    // already, we try to complete the reservation.\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (reservedContainer !\u003d null) {\n      FSSchedulerApp reservedApplication \u003d\n          applications.get(reservedContainer.getApplicationAttemptId());\n\n      // Try to fulfill the reservation\n      LOG.info(\"Trying to fulfill reservation for application \" +\n          reservedApplication.getApplicationId() + \" on node: \" + nm);\n\n      FSLeafQueue queue \u003d queueMgr.getLeafQueue(reservedApplication.getQueueName());\n      queue.assignContainer(node, true);\n    }\n\n    // Otherwise, schedule at queue which is furthest below fair share\n    else {\n      int assignedContainers \u003d 0;\n      while (true) {\n        // At most one task is scheduled each iteration of this loop\n        List\u003cFSLeafQueue\u003e scheds \u003d new ArrayList\u003cFSLeafQueue\u003e(\n            queueMgr.getLeafQueues());\n        Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n        boolean assignedContainer \u003d false;\n        for (FSLeafQueue sched : scheds) {\n          Resource assigned \u003d sched.assignContainer(node, false);\n          if (Resources.greaterThan(assigned, Resources.none())) {\n            eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n            assignedContainers++;\n            assignedContainer \u003d true;\n            break;\n          }\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "d9050e12081c0e56e1185e330badcca00e5d4b21": {
      "type": "Ybodychange",
      "commitMessage": "YARN-224. Fair scheduler logs too many nodeUpdate INFO messages. Contributed by Sandy Ryza.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1414647 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/11/12 4:27 AM",
      "commitName": "d9050e12081c0e56e1185e330badcca00e5d4b21",
      "commitAuthor": "Thomas White",
      "commitDateOld": "17/11/12 9:00 PM",
      "commitNameOld": "576f96f0ac79a2afe49948056498f2c06fe317c3",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 10.31,
      "commitsBetweenForRepo": 25,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,63 +1,65 @@\n   private synchronized void nodeUpdate(RMNode nm,\n       List\u003cContainerStatus\u003e newlyLaunchedContainers,\n       List\u003cContainerStatus\u003e completedContainers) {\n-    LOG.info(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n+    }\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     // Assign new containers...\n     // 1. Check for reserved applications\n     // 2. Schedule if there are no reservations\n \n     // If we have have an application that has reserved a resource on this node\n     // already, we try to complete the reservation.\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (reservedContainer !\u003d null) {\n       FSSchedulerApp reservedApplication \u003d\n           applications.get(reservedContainer.getApplicationAttemptId());\n \n       // Try to fulfill the reservation\n       LOG.info(\"Trying to fulfill reservation for application \" +\n           reservedApplication.getApplicationId() + \" on node: \" + nm);\n \n       FSQueue queue \u003d queueMgr.getQueue(reservedApplication.getQueueName());\n       queue.getQueueSchedulable().assignContainer(node, true);\n     }\n \n \n     // Otherwise, schedule at queue which is furthest below fair share\n     else {\n       int assignedContainers \u003d 0;\n       while (true) {\n         // At most one task is scheduled each iteration of this loop\n         List\u003cFSQueueSchedulable\u003e scheds \u003d getQueueSchedulables();\n         Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n         boolean assignedContainer \u003d false;\n         for (FSQueueSchedulable sched : scheds) {\n           Resource assigned \u003d sched.assignContainer(node, false);\n           if (Resources.greaterThan(assigned, Resources.none())) {\n             eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n             assignedContainers++;\n             assignedContainer \u003d true;\n             break;\n           }\n         }\n         if (!assignedContainer) { break; }\n         if (!assignMultiple) { break; }\n         if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm,\n      List\u003cContainerStatus\u003e newlyLaunchedContainers,\n      List\u003cContainerStatus\u003e completedContainers) {\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    }\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    // If we have have an application that has reserved a resource on this node\n    // already, we try to complete the reservation.\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (reservedContainer !\u003d null) {\n      FSSchedulerApp reservedApplication \u003d\n          applications.get(reservedContainer.getApplicationAttemptId());\n\n      // Try to fulfill the reservation\n      LOG.info(\"Trying to fulfill reservation for application \" +\n          reservedApplication.getApplicationId() + \" on node: \" + nm);\n\n      FSQueue queue \u003d queueMgr.getQueue(reservedApplication.getQueueName());\n      queue.getQueueSchedulable().assignContainer(node, true);\n    }\n\n\n    // Otherwise, schedule at queue which is furthest below fair share\n    else {\n      int assignedContainers \u003d 0;\n      while (true) {\n        // At most one task is scheduled each iteration of this loop\n        List\u003cFSQueueSchedulable\u003e scheds \u003d getQueueSchedulables();\n        Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n        boolean assignedContainer \u003d false;\n        for (FSQueueSchedulable sched : scheds) {\n          Resource assigned \u003d sched.assignContainer(node, false);\n          if (Resources.greaterThan(assigned, Resources.none())) {\n            eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n            assignedContainers++;\n            assignedContainer \u003d true;\n            break;\n          }\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "933a6d2c1ec8d3b373674e3e74eb472863fc464d": {
      "type": "Ybodychange",
      "commitMessage": "YARN-183. Clean up fair scheduler code. Contributed by Sandy Ryza.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1407433 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/11/12 4:38 AM",
      "commitName": "933a6d2c1ec8d3b373674e3e74eb472863fc464d",
      "commitAuthor": "Thomas White",
      "commitDateOld": "26/10/12 1:55 PM",
      "commitNameOld": "b54e794fb059fa68b115c2ca5e58f11a0d7f3985",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 13.65,
      "commitsBetweenForRepo": 70,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,63 +1,63 @@\n   private synchronized void nodeUpdate(RMNode nm,\n       List\u003cContainerStatus\u003e newlyLaunchedContainers,\n       List\u003cContainerStatus\u003e completedContainers) {\n     LOG.info(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n     FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     // Assign new containers...\n     // 1. Check for reserved applications\n     // 2. Schedule if there are no reservations\n \n     // If we have have an application that has reserved a resource on this node\n     // already, we try to complete the reservation.\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (reservedContainer !\u003d null) {\n       FSSchedulerApp reservedApplication \u003d\n           applications.get(reservedContainer.getApplicationAttemptId());\n \n       // Try to fulfill the reservation\n       LOG.info(\"Trying to fulfill reservation for application \" +\n           reservedApplication.getApplicationId() + \" on node: \" + nm);\n \n       FSQueue queue \u003d queueMgr.getQueue(reservedApplication.getQueueName());\n       queue.getQueueSchedulable().assignContainer(node, true);\n     }\n \n \n     // Otherwise, schedule at queue which is furthest below fair share\n     else {\n       int assignedContainers \u003d 0;\n       while (true) {\n         // At most one task is scheduled each iteration of this loop\n-        List\u003cFSQueueSchedulable\u003e scheds \u003d this.getQueueSchedulables();\n+        List\u003cFSQueueSchedulable\u003e scheds \u003d getQueueSchedulables();\n         Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n         boolean assignedContainer \u003d false;\n         for (FSQueueSchedulable sched : scheds) {\n           Resource assigned \u003d sched.assignContainer(node, false);\n           if (Resources.greaterThan(assigned, Resources.none())) {\n             eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n             assignedContainers++;\n             assignedContainer \u003d true;\n             break;\n           }\n         }\n         if (!assignedContainer) { break; }\n         if (!assignMultiple) { break; }\n         if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm,\n      List\u003cContainerStatus\u003e newlyLaunchedContainers,\n      List\u003cContainerStatus\u003e completedContainers) {\n    LOG.info(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    // If we have have an application that has reserved a resource on this node\n    // already, we try to complete the reservation.\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (reservedContainer !\u003d null) {\n      FSSchedulerApp reservedApplication \u003d\n          applications.get(reservedContainer.getApplicationAttemptId());\n\n      // Try to fulfill the reservation\n      LOG.info(\"Trying to fulfill reservation for application \" +\n          reservedApplication.getApplicationId() + \" on node: \" + nm);\n\n      FSQueue queue \u003d queueMgr.getQueue(reservedApplication.getQueueName());\n      queue.getQueueSchedulable().assignContainer(node, true);\n    }\n\n\n    // Otherwise, schedule at queue which is furthest below fair share\n    else {\n      int assignedContainers \u003d 0;\n      while (true) {\n        // At most one task is scheduled each iteration of this loop\n        List\u003cFSQueueSchedulable\u003e scheds \u003d getQueueSchedulables();\n        Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n        boolean assignedContainer \u003d false;\n        for (FSQueueSchedulable sched : scheds) {\n          Resource assigned \u003d sched.assignContainer(node, false);\n          if (Resources.greaterThan(assigned, Resources.none())) {\n            eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n            assignedContainers++;\n            assignedContainer \u003d true;\n            break;\n          }\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "e1fdf62123625e4ba399af02f8aad500637d29d1": {
      "type": "Yfilerename",
      "commitMessage": "YARN-1. Promote YARN to be a sub-project of Apache Hadoop.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370666 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/12 10:22 PM",
      "commitName": "e1fdf62123625e4ba399af02f8aad500637d29d1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "07/08/12 7:53 PM",
      "commitNameOld": "34554d1e11ee1d5b564d7d9ed3e6d55931d72749",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm,\n      List\u003cContainerStatus\u003e newlyLaunchedContainers,\n      List\u003cContainerStatus\u003e completedContainers) {\n    LOG.info(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    // If we have have an application that has reserved a resource on this node\n    // already, we try to complete the reservation.\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (reservedContainer !\u003d null) {\n      FSSchedulerApp reservedApplication \u003d\n          applications.get(reservedContainer.getApplicationAttemptId());\n\n      // Try to fulfill the reservation\n      LOG.info(\"Trying to fulfill reservation for application \" +\n          reservedApplication.getApplicationId() + \" on node: \" + nm);\n\n      FSQueue queue \u003d queueMgr.getQueue(reservedApplication.getQueueName());\n      queue.getQueueSchedulable().assignContainer(node, true);\n    }\n\n\n    // Otherwise, schedule at queue which is furthest below fair share\n    else {\n      int assignedContainers \u003d 0;\n      while (true) {\n        // At most one task is scheduled each iteration of this loop\n        List\u003cFSQueueSchedulable\u003e scheds \u003d this.getQueueSchedulables();\n        Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n        boolean assignedContainer \u003d false;\n        for (FSQueueSchedulable sched : scheds) {\n          Resource assigned \u003d sched.assignContainer(node, false);\n          if (Resources.greaterThan(assigned, Resources.none())) {\n            eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n            assignedContainers++;\n            assignedContainer \u003d true;\n            break;\n          }\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n      }\n    }\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java"
      }
    },
    "7f2b1eadc1b0807ec1302a0c3488bf6e7a59bc76": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4440. Changed SchedulerApp and SchedulerNode to be a minimal interface to allow schedulers to maintain their own.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1362332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/07/12 6:43 PM",
      "commitName": "7f2b1eadc1b0807ec1302a0c3488bf6e7a59bc76",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "12/07/12 5:43 PM",
      "commitNameOld": "1ef64e64c05ae5318cd4cb47d03a0494d742fb7c",
      "commitAuthorOld": "Alejandro Abdelnur",
      "daysBetweenCommits": 4.04,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,63 +1,63 @@\n   private synchronized void nodeUpdate(RMNode nm,\n       List\u003cContainerStatus\u003e newlyLaunchedContainers,\n       List\u003cContainerStatus\u003e completedContainers) {\n     LOG.info(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n     eventLog.log(\"HEARTBEAT\", nm.getHostName());\n-    SchedulerNode node \u003d nodes.get(nm.getNodeID());\n+    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n \n     // Processing the newly launched containers\n     for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n       containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n     }\n \n     // Process completed containers\n     for (ContainerStatus completedContainer : completedContainers) {\n       ContainerId containerId \u003d completedContainer.getContainerId();\n       LOG.debug(\"Container FINISHED: \" + containerId);\n       completedContainer(getRMContainer(containerId),\n           completedContainer, RMContainerEventType.FINISHED);\n     }\n \n     // Assign new containers...\n     // 1. Check for reserved applications\n     // 2. Schedule if there are no reservations\n \n     // If we have have an application that has reserved a resource on this node\n     // already, we try to complete the reservation.\n     RMContainer reservedContainer \u003d node.getReservedContainer();\n     if (reservedContainer !\u003d null) {\n-      SchedulerApp reservedApplication \u003d\n+      FSSchedulerApp reservedApplication \u003d\n           applications.get(reservedContainer.getApplicationAttemptId());\n \n       // Try to fulfill the reservation\n       LOG.info(\"Trying to fulfill reservation for application \" +\n           reservedApplication.getApplicationId() + \" on node: \" + nm);\n \n       FSQueue queue \u003d queueMgr.getQueue(reservedApplication.getQueueName());\n       queue.getQueueSchedulable().assignContainer(node, true);\n     }\n \n \n     // Otherwise, schedule at queue which is furthest below fair share\n     else {\n       int assignedContainers \u003d 0;\n       while (true) {\n         // At most one task is scheduled each iteration of this loop\n         List\u003cFSQueueSchedulable\u003e scheds \u003d this.getQueueSchedulables();\n         Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n         boolean assignedContainer \u003d false;\n         for (FSQueueSchedulable sched : scheds) {\n           Resource assigned \u003d sched.assignContainer(node, false);\n           if (Resources.greaterThan(assigned, Resources.none())) {\n             eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n             assignedContainers++;\n             assignedContainer \u003d true;\n             break;\n           }\n         }\n         if (!assignedContainer) { break; }\n         if (!assignMultiple) { break; }\n         if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n       }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm,\n      List\u003cContainerStatus\u003e newlyLaunchedContainers,\n      List\u003cContainerStatus\u003e completedContainers) {\n    LOG.info(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    FSSchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    // If we have have an application that has reserved a resource on this node\n    // already, we try to complete the reservation.\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (reservedContainer !\u003d null) {\n      FSSchedulerApp reservedApplication \u003d\n          applications.get(reservedContainer.getApplicationAttemptId());\n\n      // Try to fulfill the reservation\n      LOG.info(\"Trying to fulfill reservation for application \" +\n          reservedApplication.getApplicationId() + \" on node: \" + nm);\n\n      FSQueue queue \u003d queueMgr.getQueue(reservedApplication.getQueueName());\n      queue.getQueueSchedulable().assignContainer(node, true);\n    }\n\n\n    // Otherwise, schedule at queue which is furthest below fair share\n    else {\n      int assignedContainers \u003d 0;\n      while (true) {\n        // At most one task is scheduled each iteration of this loop\n        List\u003cFSQueueSchedulable\u003e scheds \u003d this.getQueueSchedulables();\n        Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n        boolean assignedContainer \u003d false;\n        for (FSQueueSchedulable sched : scheds) {\n          Resource assigned \u003d sched.assignContainer(node, false);\n          if (Resources.greaterThan(assigned, Resources.none())) {\n            eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n            assignedContainers++;\n            assignedContainer \u003d true;\n            break;\n          }\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java",
      "extendedDetails": {}
    },
    "1ef64e64c05ae5318cd4cb47d03a0494d742fb7c": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-3451. Port Fair Scheduler to MR2 (pwendell via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1361020 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/07/12 5:43 PM",
      "commitName": "1ef64e64c05ae5318cd4cb47d03a0494d742fb7c",
      "commitAuthor": "Alejandro Abdelnur",
      "diff": "@@ -0,0 +1,63 @@\n+  private synchronized void nodeUpdate(RMNode nm,\n+      List\u003cContainerStatus\u003e newlyLaunchedContainers,\n+      List\u003cContainerStatus\u003e completedContainers) {\n+    LOG.info(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n+    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n+    SchedulerNode node \u003d nodes.get(nm.getNodeID());\n+\n+    // Processing the newly launched containers\n+    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n+      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n+    }\n+\n+    // Process completed containers\n+    for (ContainerStatus completedContainer : completedContainers) {\n+      ContainerId containerId \u003d completedContainer.getContainerId();\n+      LOG.debug(\"Container FINISHED: \" + containerId);\n+      completedContainer(getRMContainer(containerId),\n+          completedContainer, RMContainerEventType.FINISHED);\n+    }\n+\n+    // Assign new containers...\n+    // 1. Check for reserved applications\n+    // 2. Schedule if there are no reservations\n+\n+    // If we have have an application that has reserved a resource on this node\n+    // already, we try to complete the reservation.\n+    RMContainer reservedContainer \u003d node.getReservedContainer();\n+    if (reservedContainer !\u003d null) {\n+      SchedulerApp reservedApplication \u003d\n+          applications.get(reservedContainer.getApplicationAttemptId());\n+\n+      // Try to fulfill the reservation\n+      LOG.info(\"Trying to fulfill reservation for application \" +\n+          reservedApplication.getApplicationId() + \" on node: \" + nm);\n+\n+      FSQueue queue \u003d queueMgr.getQueue(reservedApplication.getQueueName());\n+      queue.getQueueSchedulable().assignContainer(node, true);\n+    }\n+\n+\n+    // Otherwise, schedule at queue which is furthest below fair share\n+    else {\n+      int assignedContainers \u003d 0;\n+      while (true) {\n+        // At most one task is scheduled each iteration of this loop\n+        List\u003cFSQueueSchedulable\u003e scheds \u003d this.getQueueSchedulables();\n+        Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n+        boolean assignedContainer \u003d false;\n+        for (FSQueueSchedulable sched : scheds) {\n+          Resource assigned \u003d sched.assignContainer(node, false);\n+          if (Resources.greaterThan(assigned, Resources.none())) {\n+            eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n+            assignedContainers++;\n+            assignedContainer \u003d true;\n+            break;\n+          }\n+        }\n+        if (!assignedContainer) { break; }\n+        if (!assignMultiple) { break; }\n+        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private synchronized void nodeUpdate(RMNode nm,\n      List\u003cContainerStatus\u003e newlyLaunchedContainers,\n      List\u003cContainerStatus\u003e completedContainers) {\n    LOG.info(\"nodeUpdate: \" + nm + \" cluster capacity: \" + clusterCapacity);\n    eventLog.log(\"HEARTBEAT\", nm.getHostName());\n    SchedulerNode node \u003d nodes.get(nm.getNodeID());\n\n    // Processing the newly launched containers\n    for (ContainerStatus launchedContainer : newlyLaunchedContainers) {\n      containerLaunchedOnNode(launchedContainer.getContainerId(), node);\n    }\n\n    // Process completed containers\n    for (ContainerStatus completedContainer : completedContainers) {\n      ContainerId containerId \u003d completedContainer.getContainerId();\n      LOG.debug(\"Container FINISHED: \" + containerId);\n      completedContainer(getRMContainer(containerId),\n          completedContainer, RMContainerEventType.FINISHED);\n    }\n\n    // Assign new containers...\n    // 1. Check for reserved applications\n    // 2. Schedule if there are no reservations\n\n    // If we have have an application that has reserved a resource on this node\n    // already, we try to complete the reservation.\n    RMContainer reservedContainer \u003d node.getReservedContainer();\n    if (reservedContainer !\u003d null) {\n      SchedulerApp reservedApplication \u003d\n          applications.get(reservedContainer.getApplicationAttemptId());\n\n      // Try to fulfill the reservation\n      LOG.info(\"Trying to fulfill reservation for application \" +\n          reservedApplication.getApplicationId() + \" on node: \" + nm);\n\n      FSQueue queue \u003d queueMgr.getQueue(reservedApplication.getQueueName());\n      queue.getQueueSchedulable().assignContainer(node, true);\n    }\n\n\n    // Otherwise, schedule at queue which is furthest below fair share\n    else {\n      int assignedContainers \u003d 0;\n      while (true) {\n        // At most one task is scheduled each iteration of this loop\n        List\u003cFSQueueSchedulable\u003e scheds \u003d this.getQueueSchedulables();\n        Collections.sort(scheds, new SchedulingAlgorithms.FairShareComparator());\n        boolean assignedContainer \u003d false;\n        for (FSQueueSchedulable sched : scheds) {\n          Resource assigned \u003d sched.assignContainer(node, false);\n          if (Resources.greaterThan(assigned, Resources.none())) {\n            eventLog.log(\"ASSIGN\", nm.getHostName(), assigned);\n            assignedContainers++;\n            assignedContainer \u003d true;\n            break;\n          }\n        }\n        if (!assignedContainer) { break; }\n        if (!assignMultiple) { break; }\n        if ((assignedContainers \u003e\u003d maxAssign) \u0026\u0026 (maxAssign \u003e 0)) { break; }\n      }\n    }\n  }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair/FairScheduler.java"
    }
  }
}