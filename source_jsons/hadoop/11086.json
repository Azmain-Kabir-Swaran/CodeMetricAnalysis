{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DiskBalancer.java",
  "functionName": "createWorkPlan",
  "functionId": "createWorkPlan___volumePair-VolumePair(modifiers-final)__step-Step",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java",
  "functionStartLine": 554,
  "functionEndLine": 579,
  "numCommitsSeen": 60,
  "timeTaken": 2685,
  "changeHistory": [
    "03f519a757ce83d76e7fc9f6aadf271e38bb9f6d",
    "050677077beaf42255b3936952b8e816a9201203",
    "2b1b2faf76a7ff148650a7836935a85439f60c49"
  ],
  "changeHistoryShort": {
    "03f519a757ce83d76e7fc9f6aadf271e38bb9f6d": "Ymultichange(Yparameterchange,Ybodychange)",
    "050677077beaf42255b3936952b8e816a9201203": "Ymultichange(Yparameterchange,Ybodychange)",
    "2b1b2faf76a7ff148650a7836935a85439f60c49": "Yintroduced"
  },
  "changeHistoryDetails": {
    "03f519a757ce83d76e7fc9f6aadf271e38bb9f6d": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-9850. DiskBalancer: Explore removing references to FsVolumeSpi. Contributed by Manoj Govindassamy.\n",
      "commitDate": "27/09/16 9:35 PM",
      "commitName": "03f519a757ce83d76e7fc9f6aadf271e38bb9f6d",
      "commitAuthor": "Anu Engineer",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9850. DiskBalancer: Explore removing references to FsVolumeSpi. Contributed by Manoj Govindassamy.\n",
          "commitDate": "27/09/16 9:35 PM",
          "commitName": "03f519a757ce83d76e7fc9f6aadf271e38bb9f6d",
          "commitAuthor": "Anu Engineer",
          "commitDateOld": "09/09/16 3:00 PM",
          "commitNameOld": "bee9f57f5ca9f037ade932c6fd01b0dad47a1296",
          "commitAuthorOld": "Anu Engineer",
          "daysBetweenCommits": 18.27,
          "commitsBetweenForRepo": 96,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,26 @@\n-  private void createWorkPlan(FsVolumeSpi source, FsVolumeSpi dest,\n-                              Step step) throws DiskBalancerException {\n-\n-    if (source.getStorageID().equals(dest.getStorageID())) {\n-      LOG.info(\"Disk Balancer - source \u0026 destination volumes are same.\");\n-      throw new DiskBalancerException(\"source and destination volumes are \" +\n-          \"same.\", DiskBalancerException.Result.INVALID_MOVE);\n+  private void createWorkPlan(final VolumePair volumePair, Step step)\n+      throws DiskBalancerException {\n+    if (volumePair.getSourceVolUuid().equals(volumePair.getDestVolUuid())) {\n+      final String errMsg \u003d \"Disk Balancer - Source and destination volumes \" +\n+          \"are same: \" + volumePair.getSourceVolUuid();\n+      LOG.warn(errMsg);\n+      throw new DiskBalancerException(errMsg,\n+          DiskBalancerException.Result.INVALID_MOVE);\n     }\n-    VolumePair pair \u003d new VolumePair(source, dest);\n     long bytesToMove \u003d step.getBytesToMove();\n     // In case we have a plan with more than\n-    // one line of same \u003csource, dest\u003e\n+    // one line of same VolumePair\n     // we compress that into one work order.\n-    if (workMap.containsKey(pair)) {\n-      bytesToMove +\u003d workMap.get(pair).getBytesToCopy();\n+    if (workMap.containsKey(volumePair)) {\n+      bytesToMove +\u003d workMap.get(volumePair).getBytesToCopy();\n     }\n \n     DiskBalancerWorkItem work \u003d new DiskBalancerWorkItem(bytesToMove, 0);\n \n     // all these values can be zero, if so we will use\n     // values from configuration.\n     work.setBandwidth(step.getBandwidth());\n     work.setTolerancePercent(step.getTolerancePercent());\n     work.setMaxDiskErrors(step.getMaxDiskErrors());\n-    workMap.put(pair, work);\n+    workMap.put(volumePair, work);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void createWorkPlan(final VolumePair volumePair, Step step)\n      throws DiskBalancerException {\n    if (volumePair.getSourceVolUuid().equals(volumePair.getDestVolUuid())) {\n      final String errMsg \u003d \"Disk Balancer - Source and destination volumes \" +\n          \"are same: \" + volumePair.getSourceVolUuid();\n      LOG.warn(errMsg);\n      throw new DiskBalancerException(errMsg,\n          DiskBalancerException.Result.INVALID_MOVE);\n    }\n    long bytesToMove \u003d step.getBytesToMove();\n    // In case we have a plan with more than\n    // one line of same VolumePair\n    // we compress that into one work order.\n    if (workMap.containsKey(volumePair)) {\n      bytesToMove +\u003d workMap.get(volumePair).getBytesToCopy();\n    }\n\n    DiskBalancerWorkItem work \u003d new DiskBalancerWorkItem(bytesToMove, 0);\n\n    // all these values can be zero, if so we will use\n    // values from configuration.\n    work.setBandwidth(step.getBandwidth());\n    work.setTolerancePercent(step.getTolerancePercent());\n    work.setMaxDiskErrors(step.getMaxDiskErrors());\n    workMap.put(volumePair, work);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java",
          "extendedDetails": {
            "oldValue": "[source-FsVolumeSpi, dest-FsVolumeSpi, step-Step]",
            "newValue": "[volumePair-VolumePair(modifiers-final), step-Step]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9850. DiskBalancer: Explore removing references to FsVolumeSpi. Contributed by Manoj Govindassamy.\n",
          "commitDate": "27/09/16 9:35 PM",
          "commitName": "03f519a757ce83d76e7fc9f6aadf271e38bb9f6d",
          "commitAuthor": "Anu Engineer",
          "commitDateOld": "09/09/16 3:00 PM",
          "commitNameOld": "bee9f57f5ca9f037ade932c6fd01b0dad47a1296",
          "commitAuthorOld": "Anu Engineer",
          "daysBetweenCommits": 18.27,
          "commitsBetweenForRepo": 96,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,26 @@\n-  private void createWorkPlan(FsVolumeSpi source, FsVolumeSpi dest,\n-                              Step step) throws DiskBalancerException {\n-\n-    if (source.getStorageID().equals(dest.getStorageID())) {\n-      LOG.info(\"Disk Balancer - source \u0026 destination volumes are same.\");\n-      throw new DiskBalancerException(\"source and destination volumes are \" +\n-          \"same.\", DiskBalancerException.Result.INVALID_MOVE);\n+  private void createWorkPlan(final VolumePair volumePair, Step step)\n+      throws DiskBalancerException {\n+    if (volumePair.getSourceVolUuid().equals(volumePair.getDestVolUuid())) {\n+      final String errMsg \u003d \"Disk Balancer - Source and destination volumes \" +\n+          \"are same: \" + volumePair.getSourceVolUuid();\n+      LOG.warn(errMsg);\n+      throw new DiskBalancerException(errMsg,\n+          DiskBalancerException.Result.INVALID_MOVE);\n     }\n-    VolumePair pair \u003d new VolumePair(source, dest);\n     long bytesToMove \u003d step.getBytesToMove();\n     // In case we have a plan with more than\n-    // one line of same \u003csource, dest\u003e\n+    // one line of same VolumePair\n     // we compress that into one work order.\n-    if (workMap.containsKey(pair)) {\n-      bytesToMove +\u003d workMap.get(pair).getBytesToCopy();\n+    if (workMap.containsKey(volumePair)) {\n+      bytesToMove +\u003d workMap.get(volumePair).getBytesToCopy();\n     }\n \n     DiskBalancerWorkItem work \u003d new DiskBalancerWorkItem(bytesToMove, 0);\n \n     // all these values can be zero, if so we will use\n     // values from configuration.\n     work.setBandwidth(step.getBandwidth());\n     work.setTolerancePercent(step.getTolerancePercent());\n     work.setMaxDiskErrors(step.getMaxDiskErrors());\n-    workMap.put(pair, work);\n+    workMap.put(volumePair, work);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void createWorkPlan(final VolumePair volumePair, Step step)\n      throws DiskBalancerException {\n    if (volumePair.getSourceVolUuid().equals(volumePair.getDestVolUuid())) {\n      final String errMsg \u003d \"Disk Balancer - Source and destination volumes \" +\n          \"are same: \" + volumePair.getSourceVolUuid();\n      LOG.warn(errMsg);\n      throw new DiskBalancerException(errMsg,\n          DiskBalancerException.Result.INVALID_MOVE);\n    }\n    long bytesToMove \u003d step.getBytesToMove();\n    // In case we have a plan with more than\n    // one line of same VolumePair\n    // we compress that into one work order.\n    if (workMap.containsKey(volumePair)) {\n      bytesToMove +\u003d workMap.get(volumePair).getBytesToCopy();\n    }\n\n    DiskBalancerWorkItem work \u003d new DiskBalancerWorkItem(bytesToMove, 0);\n\n    // all these values can be zero, if so we will use\n    // values from configuration.\n    work.setBandwidth(step.getBandwidth());\n    work.setTolerancePercent(step.getTolerancePercent());\n    work.setMaxDiskErrors(step.getMaxDiskErrors());\n    workMap.put(volumePair, work);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java",
          "extendedDetails": {}
        }
      ]
    },
    "050677077beaf42255b3936952b8e816a9201203": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-9720. DiskBalancer : Add configuration parameters. Contributed by Anu Engineer.\n",
      "commitDate": "23/06/16 6:18 PM",
      "commitName": "050677077beaf42255b3936952b8e816a9201203",
      "commitAuthor": "Anu Engineer",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9720. DiskBalancer : Add configuration parameters. Contributed by Anu Engineer.\n",
          "commitDate": "23/06/16 6:18 PM",
          "commitName": "050677077beaf42255b3936952b8e816a9201203",
          "commitAuthor": "Anu Engineer",
          "commitDateOld": "23/06/16 6:18 PM",
          "commitNameOld": "6c606bf5c8c1ace381ce73679c2be96d5475ba34",
          "commitAuthorOld": "Anu Engineer",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,26 @@\n   private void createWorkPlan(FsVolumeSpi source, FsVolumeSpi dest,\n-                              long bytesToMove) throws DiskBalancerException {\n+                              Step step) throws DiskBalancerException {\n \n     if(source.getStorageID().equals(dest.getStorageID())) {\n-      throw new DiskBalancerException(\"Same source and destination\",\n-          DiskBalancerException.Result.INVALID_MOVE);\n+      LOG.info(\"Disk Balancer - source \u0026 destination volumes are same.\");\n+      throw new DiskBalancerException(\"source and destination volumes are \" +\n+          \"same.\", DiskBalancerException.Result.INVALID_MOVE);\n     }\n     VolumePair pair \u003d new VolumePair(source, dest);\n-\n+    long bytesToMove \u003d step.getBytesToMove();\n     // In case we have a plan with more than\n     // one line of same \u003csource, dest\u003e\n     // we compress that into one work order.\n     if (workMap.containsKey(pair)) {\n       bytesToMove +\u003d workMap.get(pair).getBytesToCopy();\n     }\n \n     DiskBalancerWorkItem work \u003d new DiskBalancerWorkItem(bytesToMove, 0);\n+\n+    // all these values can be zero, if so we will use\n+    // values from configuration.\n+    work.setBandwidth(step.getBandwidth());\n+    work.setTolerancePercent(step.getTolerancePercent());\n+    work.setMaxDiskErrors(step.getMaxDiskErrors());\n     workMap.put(pair, work);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void createWorkPlan(FsVolumeSpi source, FsVolumeSpi dest,\n                              Step step) throws DiskBalancerException {\n\n    if(source.getStorageID().equals(dest.getStorageID())) {\n      LOG.info(\"Disk Balancer - source \u0026 destination volumes are same.\");\n      throw new DiskBalancerException(\"source and destination volumes are \" +\n          \"same.\", DiskBalancerException.Result.INVALID_MOVE);\n    }\n    VolumePair pair \u003d new VolumePair(source, dest);\n    long bytesToMove \u003d step.getBytesToMove();\n    // In case we have a plan with more than\n    // one line of same \u003csource, dest\u003e\n    // we compress that into one work order.\n    if (workMap.containsKey(pair)) {\n      bytesToMove +\u003d workMap.get(pair).getBytesToCopy();\n    }\n\n    DiskBalancerWorkItem work \u003d new DiskBalancerWorkItem(bytesToMove, 0);\n\n    // all these values can be zero, if so we will use\n    // values from configuration.\n    work.setBandwidth(step.getBandwidth());\n    work.setTolerancePercent(step.getTolerancePercent());\n    work.setMaxDiskErrors(step.getMaxDiskErrors());\n    workMap.put(pair, work);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java",
          "extendedDetails": {
            "oldValue": "[source-FsVolumeSpi, dest-FsVolumeSpi, bytesToMove-long]",
            "newValue": "[source-FsVolumeSpi, dest-FsVolumeSpi, step-Step]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9720. DiskBalancer : Add configuration parameters. Contributed by Anu Engineer.\n",
          "commitDate": "23/06/16 6:18 PM",
          "commitName": "050677077beaf42255b3936952b8e816a9201203",
          "commitAuthor": "Anu Engineer",
          "commitDateOld": "23/06/16 6:18 PM",
          "commitNameOld": "6c606bf5c8c1ace381ce73679c2be96d5475ba34",
          "commitAuthorOld": "Anu Engineer",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,26 @@\n   private void createWorkPlan(FsVolumeSpi source, FsVolumeSpi dest,\n-                              long bytesToMove) throws DiskBalancerException {\n+                              Step step) throws DiskBalancerException {\n \n     if(source.getStorageID().equals(dest.getStorageID())) {\n-      throw new DiskBalancerException(\"Same source and destination\",\n-          DiskBalancerException.Result.INVALID_MOVE);\n+      LOG.info(\"Disk Balancer - source \u0026 destination volumes are same.\");\n+      throw new DiskBalancerException(\"source and destination volumes are \" +\n+          \"same.\", DiskBalancerException.Result.INVALID_MOVE);\n     }\n     VolumePair pair \u003d new VolumePair(source, dest);\n-\n+    long bytesToMove \u003d step.getBytesToMove();\n     // In case we have a plan with more than\n     // one line of same \u003csource, dest\u003e\n     // we compress that into one work order.\n     if (workMap.containsKey(pair)) {\n       bytesToMove +\u003d workMap.get(pair).getBytesToCopy();\n     }\n \n     DiskBalancerWorkItem work \u003d new DiskBalancerWorkItem(bytesToMove, 0);\n+\n+    // all these values can be zero, if so we will use\n+    // values from configuration.\n+    work.setBandwidth(step.getBandwidth());\n+    work.setTolerancePercent(step.getTolerancePercent());\n+    work.setMaxDiskErrors(step.getMaxDiskErrors());\n     workMap.put(pair, work);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void createWorkPlan(FsVolumeSpi source, FsVolumeSpi dest,\n                              Step step) throws DiskBalancerException {\n\n    if(source.getStorageID().equals(dest.getStorageID())) {\n      LOG.info(\"Disk Balancer - source \u0026 destination volumes are same.\");\n      throw new DiskBalancerException(\"source and destination volumes are \" +\n          \"same.\", DiskBalancerException.Result.INVALID_MOVE);\n    }\n    VolumePair pair \u003d new VolumePair(source, dest);\n    long bytesToMove \u003d step.getBytesToMove();\n    // In case we have a plan with more than\n    // one line of same \u003csource, dest\u003e\n    // we compress that into one work order.\n    if (workMap.containsKey(pair)) {\n      bytesToMove +\u003d workMap.get(pair).getBytesToCopy();\n    }\n\n    DiskBalancerWorkItem work \u003d new DiskBalancerWorkItem(bytesToMove, 0);\n\n    // all these values can be zero, if so we will use\n    // values from configuration.\n    work.setBandwidth(step.getBandwidth());\n    work.setTolerancePercent(step.getTolerancePercent());\n    work.setMaxDiskErrors(step.getMaxDiskErrors());\n    workMap.put(pair, work);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java",
          "extendedDetails": {}
        }
      ]
    },
    "2b1b2faf76a7ff148650a7836935a85439f60c49": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9671. DiskBalancer: SubmitPlan implementation. (Contributed by Anu Engineer)\n",
      "commitDate": "23/06/16 6:18 PM",
      "commitName": "2b1b2faf76a7ff148650a7836935a85439f60c49",
      "commitAuthor": "Arpit Agarwal",
      "diff": "@@ -0,0 +1,19 @@\n+  private void createWorkPlan(FsVolumeSpi source, FsVolumeSpi dest,\n+                              long bytesToMove) throws DiskBalancerException {\n+\n+    if(source.getStorageID().equals(dest.getStorageID())) {\n+      throw new DiskBalancerException(\"Same source and destination\",\n+          DiskBalancerException.Result.INVALID_MOVE);\n+    }\n+    VolumePair pair \u003d new VolumePair(source, dest);\n+\n+    // In case we have a plan with more than\n+    // one line of same \u003csource, dest\u003e\n+    // we compress that into one work order.\n+    if (workMap.containsKey(pair)) {\n+      bytesToMove +\u003d workMap.get(pair).getBytesToCopy();\n+    }\n+\n+    DiskBalancerWorkItem work \u003d new DiskBalancerWorkItem(bytesToMove, 0);\n+    workMap.put(pair, work);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void createWorkPlan(FsVolumeSpi source, FsVolumeSpi dest,\n                              long bytesToMove) throws DiskBalancerException {\n\n    if(source.getStorageID().equals(dest.getStorageID())) {\n      throw new DiskBalancerException(\"Same source and destination\",\n          DiskBalancerException.Result.INVALID_MOVE);\n    }\n    VolumePair pair \u003d new VolumePair(source, dest);\n\n    // In case we have a plan with more than\n    // one line of same \u003csource, dest\u003e\n    // we compress that into one work order.\n    if (workMap.containsKey(pair)) {\n      bytesToMove +\u003d workMap.get(pair).getBytesToCopy();\n    }\n\n    DiskBalancerWorkItem work \u003d new DiskBalancerWorkItem(bytesToMove, 0);\n    workMap.put(pair, work);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.java"
    }
  }
}