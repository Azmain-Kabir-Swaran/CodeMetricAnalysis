{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HarFileSystem.java",
  "functionName": "parseMetaData",
  "functionId": "parseMetaData",
  "sourceFilePath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/HarFileSystem.java",
  "functionStartLine": 1171,
  "functionEndLine": 1235,
  "numCommitsSeen": 36,
  "timeTaken": 5652,
  "changeHistory": [
    "ccaf036662e22da14583942054898c99fa51dae5",
    "bbd6a3277678a60d472e76a207f25a916220946c",
    "4e9c652c5200d5bf296a5a776d12b6ca4b2d5fab",
    "0b565a967d7abb1bdab9827f1209118bf17e4471",
    "4c13b6f34e277ae6badaa105abcb8e5515a54f06",
    "0201be46c298e94176ec6297e9d9cdba3afc2bbd",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "ccaf036662e22da14583942054898c99fa51dae5": "Ybodychange",
    "bbd6a3277678a60d472e76a207f25a916220946c": "Ybodychange",
    "4e9c652c5200d5bf296a5a776d12b6ca4b2d5fab": "Ybodychange",
    "0b565a967d7abb1bdab9827f1209118bf17e4471": "Ybodychange",
    "4c13b6f34e277ae6badaa105abcb8e5515a54f06": "Ybodychange",
    "0201be46c298e94176ec6297e9d9cdba3afc2bbd": "Yfilerename",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "ccaf036662e22da14583942054898c99fa51dae5": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-14539. Move commons logging APIs over to slf4j in hadoop-common. Contributed by Wenxin He.\n",
      "commitDate": "17/07/17 9:32 PM",
      "commitName": "ccaf036662e22da14583942054898c99fa51dae5",
      "commitAuthor": "Akira Ajisaka",
      "commitDateOld": "19/06/17 3:09 AM",
      "commitNameOld": "7ade5124b8b6c52a084ec187c531017eee0f1884",
      "commitAuthorOld": "Akira Ajisaka",
      "daysBetweenCommits": 28.77,
      "commitsBetweenForRepo": 144,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,65 @@\n     private void parseMetaData() throws IOException {\n       Text line \u003d new Text();\n       long read;\n       FSDataInputStream in \u003d null;\n       LineReader lin \u003d null;\n \n       try {\n         in \u003d fs.open(masterIndexPath);\n         FileStatus masterStat \u003d fs.getFileStatus(masterIndexPath);\n         masterIndexTimestamp \u003d masterStat.getModificationTime();\n         lin \u003d new LineReader(in, getConf());\n         read \u003d lin.readLine(line);\n \n         // the first line contains the version of the index file\n         String versionLine \u003d line.toString();\n         String[] arr \u003d versionLine.split(\" \");\n         version \u003d Integer.parseInt(arr[0]);\n         // make it always backwards-compatible\n         if (this.version \u003e HarFileSystem.VERSION) {\n           throw new IOException(\"Invalid version \" + \n               this.version + \" expected \" + HarFileSystem.VERSION);\n         }\n \n         // each line contains a hashcode range and the index file name\n         String[] readStr;\n         while(read \u003c masterStat.getLen()) {\n           int b \u003d lin.readLine(line);\n           read +\u003d b;\n           readStr \u003d line.toString().split(\" \");\n           stores.add(new Store(Long.parseLong(readStr[2]), \n               Long.parseLong(readStr[3])));\n           line.clear();\n         }\n       } catch (IOException ioe) {\n         LOG.warn(\"Encountered exception \", ioe);\n         throw ioe;\n       } finally {\n-        IOUtils.cleanup(LOG, lin, in);\n+        IOUtils.cleanupWithLogger(LOG, lin, in);\n       }\n \n       FSDataInputStream aIn \u003d fs.open(archiveIndexPath);\n       try {\n         FileStatus archiveStat \u003d fs.getFileStatus(archiveIndexPath);\n         archiveIndexTimestamp \u003d archiveStat.getModificationTime();\n         LineReader aLin;\n \n         // now start reading the real index file\n         for (Store s: stores) {\n           read \u003d 0;\n           aIn.seek(s.begin);\n           aLin \u003d new LineReader(aIn, getConf());\n           while (read + s.begin \u003c s.end) {\n             int tmp \u003d aLin.readLine(line);\n             read +\u003d tmp;\n             String lineFeed \u003d line.toString();\n             String[] parsed \u003d lineFeed.split(\" \");\n             parsed[0] \u003d decodeFileName(parsed[0]);\n             archive.put(new Path(parsed[0]), new HarStatus(lineFeed));\n             line.clear();\n           }\n         }\n       } finally {\n-        IOUtils.cleanup(LOG, aIn);\n+        IOUtils.cleanupWithLogger(LOG, aIn);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void parseMetaData() throws IOException {\n      Text line \u003d new Text();\n      long read;\n      FSDataInputStream in \u003d null;\n      LineReader lin \u003d null;\n\n      try {\n        in \u003d fs.open(masterIndexPath);\n        FileStatus masterStat \u003d fs.getFileStatus(masterIndexPath);\n        masterIndexTimestamp \u003d masterStat.getModificationTime();\n        lin \u003d new LineReader(in, getConf());\n        read \u003d lin.readLine(line);\n\n        // the first line contains the version of the index file\n        String versionLine \u003d line.toString();\n        String[] arr \u003d versionLine.split(\" \");\n        version \u003d Integer.parseInt(arr[0]);\n        // make it always backwards-compatible\n        if (this.version \u003e HarFileSystem.VERSION) {\n          throw new IOException(\"Invalid version \" + \n              this.version + \" expected \" + HarFileSystem.VERSION);\n        }\n\n        // each line contains a hashcode range and the index file name\n        String[] readStr;\n        while(read \u003c masterStat.getLen()) {\n          int b \u003d lin.readLine(line);\n          read +\u003d b;\n          readStr \u003d line.toString().split(\" \");\n          stores.add(new Store(Long.parseLong(readStr[2]), \n              Long.parseLong(readStr[3])));\n          line.clear();\n        }\n      } catch (IOException ioe) {\n        LOG.warn(\"Encountered exception \", ioe);\n        throw ioe;\n      } finally {\n        IOUtils.cleanupWithLogger(LOG, lin, in);\n      }\n\n      FSDataInputStream aIn \u003d fs.open(archiveIndexPath);\n      try {\n        FileStatus archiveStat \u003d fs.getFileStatus(archiveIndexPath);\n        archiveIndexTimestamp \u003d archiveStat.getModificationTime();\n        LineReader aLin;\n\n        // now start reading the real index file\n        for (Store s: stores) {\n          read \u003d 0;\n          aIn.seek(s.begin);\n          aLin \u003d new LineReader(aIn, getConf());\n          while (read + s.begin \u003c s.end) {\n            int tmp \u003d aLin.readLine(line);\n            read +\u003d tmp;\n            String lineFeed \u003d line.toString();\n            String[] parsed \u003d lineFeed.split(\" \");\n            parsed[0] \u003d decodeFileName(parsed[0]);\n            archive.put(new Path(parsed[0]), new HarStatus(lineFeed));\n            line.clear();\n          }\n        }\n      } finally {\n        IOUtils.cleanupWithLogger(LOG, aIn);\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/HarFileSystem.java",
      "extendedDetails": {}
    },
    "bbd6a3277678a60d472e76a207f25a916220946c": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10482. Fix various findbugs warnings in hadoop-common. Contributed by Haohui Mai.\n",
      "commitDate": "10/12/14 12:44 PM",
      "commitName": "bbd6a3277678a60d472e76a207f25a916220946c",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "22/05/14 11:17 AM",
      "commitNameOld": "3671a5e16fbddbe5a0516289ce98e1305e02291c",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 202.1,
      "commitsBetweenForRepo": 1742,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,68 +1,65 @@\n     private void parseMetaData() throws IOException {\n       Text line \u003d new Text();\n       long read;\n       FSDataInputStream in \u003d null;\n       LineReader lin \u003d null;\n \n       try {\n         in \u003d fs.open(masterIndexPath);\n         FileStatus masterStat \u003d fs.getFileStatus(masterIndexPath);\n         masterIndexTimestamp \u003d masterStat.getModificationTime();\n         lin \u003d new LineReader(in, getConf());\n         read \u003d lin.readLine(line);\n \n         // the first line contains the version of the index file\n         String versionLine \u003d line.toString();\n         String[] arr \u003d versionLine.split(\" \");\n         version \u003d Integer.parseInt(arr[0]);\n         // make it always backwards-compatible\n         if (this.version \u003e HarFileSystem.VERSION) {\n           throw new IOException(\"Invalid version \" + \n               this.version + \" expected \" + HarFileSystem.VERSION);\n         }\n \n         // each line contains a hashcode range and the index file name\n         String[] readStr;\n         while(read \u003c masterStat.getLen()) {\n           int b \u003d lin.readLine(line);\n           read +\u003d b;\n           readStr \u003d line.toString().split(\" \");\n-          int startHash \u003d Integer.parseInt(readStr[0]);\n-          int endHash  \u003d Integer.parseInt(readStr[1]);\n           stores.add(new Store(Long.parseLong(readStr[2]), \n-              Long.parseLong(readStr[3]), startHash,\n-              endHash));\n+              Long.parseLong(readStr[3])));\n           line.clear();\n         }\n       } catch (IOException ioe) {\n         LOG.warn(\"Encountered exception \", ioe);\n         throw ioe;\n       } finally {\n         IOUtils.cleanup(LOG, lin, in);\n       }\n \n       FSDataInputStream aIn \u003d fs.open(archiveIndexPath);\n       try {\n         FileStatus archiveStat \u003d fs.getFileStatus(archiveIndexPath);\n         archiveIndexTimestamp \u003d archiveStat.getModificationTime();\n         LineReader aLin;\n \n         // now start reading the real index file\n         for (Store s: stores) {\n           read \u003d 0;\n           aIn.seek(s.begin);\n           aLin \u003d new LineReader(aIn, getConf());\n           while (read + s.begin \u003c s.end) {\n             int tmp \u003d aLin.readLine(line);\n             read +\u003d tmp;\n             String lineFeed \u003d line.toString();\n             String[] parsed \u003d lineFeed.split(\" \");\n             parsed[0] \u003d decodeFileName(parsed[0]);\n             archive.put(new Path(parsed[0]), new HarStatus(lineFeed));\n             line.clear();\n           }\n         }\n       } finally {\n         IOUtils.cleanup(LOG, aIn);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void parseMetaData() throws IOException {\n      Text line \u003d new Text();\n      long read;\n      FSDataInputStream in \u003d null;\n      LineReader lin \u003d null;\n\n      try {\n        in \u003d fs.open(masterIndexPath);\n        FileStatus masterStat \u003d fs.getFileStatus(masterIndexPath);\n        masterIndexTimestamp \u003d masterStat.getModificationTime();\n        lin \u003d new LineReader(in, getConf());\n        read \u003d lin.readLine(line);\n\n        // the first line contains the version of the index file\n        String versionLine \u003d line.toString();\n        String[] arr \u003d versionLine.split(\" \");\n        version \u003d Integer.parseInt(arr[0]);\n        // make it always backwards-compatible\n        if (this.version \u003e HarFileSystem.VERSION) {\n          throw new IOException(\"Invalid version \" + \n              this.version + \" expected \" + HarFileSystem.VERSION);\n        }\n\n        // each line contains a hashcode range and the index file name\n        String[] readStr;\n        while(read \u003c masterStat.getLen()) {\n          int b \u003d lin.readLine(line);\n          read +\u003d b;\n          readStr \u003d line.toString().split(\" \");\n          stores.add(new Store(Long.parseLong(readStr[2]), \n              Long.parseLong(readStr[3])));\n          line.clear();\n        }\n      } catch (IOException ioe) {\n        LOG.warn(\"Encountered exception \", ioe);\n        throw ioe;\n      } finally {\n        IOUtils.cleanup(LOG, lin, in);\n      }\n\n      FSDataInputStream aIn \u003d fs.open(archiveIndexPath);\n      try {\n        FileStatus archiveStat \u003d fs.getFileStatus(archiveIndexPath);\n        archiveIndexTimestamp \u003d archiveStat.getModificationTime();\n        LineReader aLin;\n\n        // now start reading the real index file\n        for (Store s: stores) {\n          read \u003d 0;\n          aIn.seek(s.begin);\n          aLin \u003d new LineReader(aIn, getConf());\n          while (read + s.begin \u003c s.end) {\n            int tmp \u003d aLin.readLine(line);\n            read +\u003d tmp;\n            String lineFeed \u003d line.toString();\n            String[] parsed \u003d lineFeed.split(\" \");\n            parsed[0] \u003d decodeFileName(parsed[0]);\n            archive.put(new Path(parsed[0]), new HarStatus(lineFeed));\n            line.clear();\n          }\n        }\n      } finally {\n        IOUtils.cleanup(LOG, aIn);\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/HarFileSystem.java",
      "extendedDetails": {}
    },
    "4e9c652c5200d5bf296a5a776d12b6ca4b2d5fab": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10003. HarFileSystem.listLocatedStatus() fails. Contributed by Jason Dere and suresh.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1528256 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/10/13 3:57 PM",
      "commitName": "4e9c652c5200d5bf296a5a776d12b6ca4b2d5fab",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "24/09/13 10:17 PM",
      "commitNameOld": "43bb7c8d529364af325be7fee7442997d807b11a",
      "commitAuthorOld": "Ivan Mitic",
      "daysBetweenCommits": 6.74,
      "commitsBetweenForRepo": 50,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,68 @@\n     private void parseMetaData() throws IOException {\n-      Text line;\n+      Text line \u003d new Text();\n       long read;\n       FSDataInputStream in \u003d null;\n       LineReader lin \u003d null;\n \n       try {\n         in \u003d fs.open(masterIndexPath);\n         FileStatus masterStat \u003d fs.getFileStatus(masterIndexPath);\n         masterIndexTimestamp \u003d masterStat.getModificationTime();\n         lin \u003d new LineReader(in, getConf());\n-        line \u003d new Text();\n         read \u003d lin.readLine(line);\n \n         // the first line contains the version of the index file\n         String versionLine \u003d line.toString();\n         String[] arr \u003d versionLine.split(\" \");\n         version \u003d Integer.parseInt(arr[0]);\n         // make it always backwards-compatible\n         if (this.version \u003e HarFileSystem.VERSION) {\n           throw new IOException(\"Invalid version \" + \n               this.version + \" expected \" + HarFileSystem.VERSION);\n         }\n \n         // each line contains a hashcode range and the index file name\n-        String[] readStr \u003d null;\n+        String[] readStr;\n         while(read \u003c masterStat.getLen()) {\n           int b \u003d lin.readLine(line);\n           read +\u003d b;\n           readStr \u003d line.toString().split(\" \");\n           int startHash \u003d Integer.parseInt(readStr[0]);\n           int endHash  \u003d Integer.parseInt(readStr[1]);\n           stores.add(new Store(Long.parseLong(readStr[2]), \n               Long.parseLong(readStr[3]), startHash,\n               endHash));\n           line.clear();\n         }\n+      } catch (IOException ioe) {\n+        LOG.warn(\"Encountered exception \", ioe);\n+        throw ioe;\n       } finally {\n         IOUtils.cleanup(LOG, lin, in);\n       }\n \n       FSDataInputStream aIn \u003d fs.open(archiveIndexPath);\n       try {\n         FileStatus archiveStat \u003d fs.getFileStatus(archiveIndexPath);\n         archiveIndexTimestamp \u003d archiveStat.getModificationTime();\n         LineReader aLin;\n \n         // now start reading the real index file\n         for (Store s: stores) {\n           read \u003d 0;\n           aIn.seek(s.begin);\n           aLin \u003d new LineReader(aIn, getConf());\n           while (read + s.begin \u003c s.end) {\n             int tmp \u003d aLin.readLine(line);\n             read +\u003d tmp;\n             String lineFeed \u003d line.toString();\n             String[] parsed \u003d lineFeed.split(\" \");\n             parsed[0] \u003d decodeFileName(parsed[0]);\n             archive.put(new Path(parsed[0]), new HarStatus(lineFeed));\n             line.clear();\n           }\n         }\n       } finally {\n         IOUtils.cleanup(LOG, aIn);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void parseMetaData() throws IOException {\n      Text line \u003d new Text();\n      long read;\n      FSDataInputStream in \u003d null;\n      LineReader lin \u003d null;\n\n      try {\n        in \u003d fs.open(masterIndexPath);\n        FileStatus masterStat \u003d fs.getFileStatus(masterIndexPath);\n        masterIndexTimestamp \u003d masterStat.getModificationTime();\n        lin \u003d new LineReader(in, getConf());\n        read \u003d lin.readLine(line);\n\n        // the first line contains the version of the index file\n        String versionLine \u003d line.toString();\n        String[] arr \u003d versionLine.split(\" \");\n        version \u003d Integer.parseInt(arr[0]);\n        // make it always backwards-compatible\n        if (this.version \u003e HarFileSystem.VERSION) {\n          throw new IOException(\"Invalid version \" + \n              this.version + \" expected \" + HarFileSystem.VERSION);\n        }\n\n        // each line contains a hashcode range and the index file name\n        String[] readStr;\n        while(read \u003c masterStat.getLen()) {\n          int b \u003d lin.readLine(line);\n          read +\u003d b;\n          readStr \u003d line.toString().split(\" \");\n          int startHash \u003d Integer.parseInt(readStr[0]);\n          int endHash  \u003d Integer.parseInt(readStr[1]);\n          stores.add(new Store(Long.parseLong(readStr[2]), \n              Long.parseLong(readStr[3]), startHash,\n              endHash));\n          line.clear();\n        }\n      } catch (IOException ioe) {\n        LOG.warn(\"Encountered exception \", ioe);\n        throw ioe;\n      } finally {\n        IOUtils.cleanup(LOG, lin, in);\n      }\n\n      FSDataInputStream aIn \u003d fs.open(archiveIndexPath);\n      try {\n        FileStatus archiveStat \u003d fs.getFileStatus(archiveIndexPath);\n        archiveIndexTimestamp \u003d archiveStat.getModificationTime();\n        LineReader aLin;\n\n        // now start reading the real index file\n        for (Store s: stores) {\n          read \u003d 0;\n          aIn.seek(s.begin);\n          aLin \u003d new LineReader(aIn, getConf());\n          while (read + s.begin \u003c s.end) {\n            int tmp \u003d aLin.readLine(line);\n            read +\u003d tmp;\n            String lineFeed \u003d line.toString();\n            String[] parsed \u003d lineFeed.split(\" \");\n            parsed[0] \u003d decodeFileName(parsed[0]);\n            archive.put(new Path(parsed[0]), new HarStatus(lineFeed));\n            line.clear();\n          }\n        }\n      } finally {\n        IOUtils.cleanup(LOG, aIn);\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/HarFileSystem.java",
      "extendedDetails": {}
    },
    "0b565a967d7abb1bdab9827f1209118bf17e4471": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-9278. Fix the file handle leak in HarMetaData.parseMetaData() in HarFileSystem. Contributed by Chris Nauroth\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1442755 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/02/13 1:23 PM",
      "commitName": "0b565a967d7abb1bdab9827f1209118bf17e4471",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "26/11/12 9:45 AM",
      "commitNameOld": "0d92f54e82f1759f012981e92cbe129b3d9f7179",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 71.15,
      "commitsBetweenForRepo": 313,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,66 @@\n     private void parseMetaData() throws IOException {\n-      FSDataInputStream in \u003d fs.open(masterIndexPath);\n-      FileStatus masterStat \u003d fs.getFileStatus(masterIndexPath);\n-      masterIndexTimestamp \u003d masterStat.getModificationTime();\n-      LineReader lin \u003d new LineReader(in, getConf());\n-      Text line \u003d new Text();\n-      long read \u003d lin.readLine(line);\n+      Text line;\n+      long read;\n+      FSDataInputStream in \u003d null;\n+      LineReader lin \u003d null;\n \n-     // the first line contains the version of the index file\n-      String versionLine \u003d line.toString();\n-      String[] arr \u003d versionLine.split(\" \");\n-      version \u003d Integer.parseInt(arr[0]);\n-      // make it always backwards-compatible\n-      if (this.version \u003e HarFileSystem.VERSION) {\n-        throw new IOException(\"Invalid version \" + \n-            this.version + \" expected \" + HarFileSystem.VERSION);\n-      }\n-\n-      // each line contains a hashcode range and the index file name\n-      String[] readStr \u003d null;\n-      while(read \u003c masterStat.getLen()) {\n-        int b \u003d lin.readLine(line);\n-        read +\u003d b;\n-        readStr \u003d line.toString().split(\" \");\n-        int startHash \u003d Integer.parseInt(readStr[0]);\n-        int endHash  \u003d Integer.parseInt(readStr[1]);\n-        stores.add(new Store(Long.parseLong(readStr[2]), \n-            Long.parseLong(readStr[3]), startHash,\n-            endHash));\n-        line.clear();\n-      }\n       try {\n-        // close the master index\n-        lin.close();\n-      } catch(IOException io){\n-        // do nothing just a read.\n+        in \u003d fs.open(masterIndexPath);\n+        FileStatus masterStat \u003d fs.getFileStatus(masterIndexPath);\n+        masterIndexTimestamp \u003d masterStat.getModificationTime();\n+        lin \u003d new LineReader(in, getConf());\n+        line \u003d new Text();\n+        read \u003d lin.readLine(line);\n+\n+        // the first line contains the version of the index file\n+        String versionLine \u003d line.toString();\n+        String[] arr \u003d versionLine.split(\" \");\n+        version \u003d Integer.parseInt(arr[0]);\n+        // make it always backwards-compatible\n+        if (this.version \u003e HarFileSystem.VERSION) {\n+          throw new IOException(\"Invalid version \" + \n+              this.version + \" expected \" + HarFileSystem.VERSION);\n+        }\n+\n+        // each line contains a hashcode range and the index file name\n+        String[] readStr \u003d null;\n+        while(read \u003c masterStat.getLen()) {\n+          int b \u003d lin.readLine(line);\n+          read +\u003d b;\n+          readStr \u003d line.toString().split(\" \");\n+          int startHash \u003d Integer.parseInt(readStr[0]);\n+          int endHash  \u003d Integer.parseInt(readStr[1]);\n+          stores.add(new Store(Long.parseLong(readStr[2]), \n+              Long.parseLong(readStr[3]), startHash,\n+              endHash));\n+          line.clear();\n+        }\n+      } finally {\n+        IOUtils.cleanup(LOG, lin, in);\n       }\n \n       FSDataInputStream aIn \u003d fs.open(archiveIndexPath);\n-      FileStatus archiveStat \u003d fs.getFileStatus(archiveIndexPath);\n-      archiveIndexTimestamp \u003d archiveStat.getModificationTime();\n-      LineReader aLin;\n-\n-      // now start reading the real index file\n-      for (Store s: stores) {\n-        read \u003d 0;\n-        aIn.seek(s.begin);\n-        aLin \u003d new LineReader(aIn, getConf());\n-        while (read + s.begin \u003c s.end) {\n-          int tmp \u003d aLin.readLine(line);\n-          read +\u003d tmp;\n-          String lineFeed \u003d line.toString();\n-          String[] parsed \u003d lineFeed.split(\" \");\n-          parsed[0] \u003d decodeFileName(parsed[0]);\n-          archive.put(new Path(parsed[0]), new HarStatus(lineFeed));\n-          line.clear();\n-        }\n-      }\n       try {\n-        // close the archive index\n-        aIn.close();\n-      } catch(IOException io) {\n-        // do nothing just a read.\n+        FileStatus archiveStat \u003d fs.getFileStatus(archiveIndexPath);\n+        archiveIndexTimestamp \u003d archiveStat.getModificationTime();\n+        LineReader aLin;\n+\n+        // now start reading the real index file\n+        for (Store s: stores) {\n+          read \u003d 0;\n+          aIn.seek(s.begin);\n+          aLin \u003d new LineReader(aIn, getConf());\n+          while (read + s.begin \u003c s.end) {\n+            int tmp \u003d aLin.readLine(line);\n+            read +\u003d tmp;\n+            String lineFeed \u003d line.toString();\n+            String[] parsed \u003d lineFeed.split(\" \");\n+            parsed[0] \u003d decodeFileName(parsed[0]);\n+            archive.put(new Path(parsed[0]), new HarStatus(lineFeed));\n+            line.clear();\n+          }\n+        }\n+      } finally {\n+        IOUtils.cleanup(LOG, aIn);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void parseMetaData() throws IOException {\n      Text line;\n      long read;\n      FSDataInputStream in \u003d null;\n      LineReader lin \u003d null;\n\n      try {\n        in \u003d fs.open(masterIndexPath);\n        FileStatus masterStat \u003d fs.getFileStatus(masterIndexPath);\n        masterIndexTimestamp \u003d masterStat.getModificationTime();\n        lin \u003d new LineReader(in, getConf());\n        line \u003d new Text();\n        read \u003d lin.readLine(line);\n\n        // the first line contains the version of the index file\n        String versionLine \u003d line.toString();\n        String[] arr \u003d versionLine.split(\" \");\n        version \u003d Integer.parseInt(arr[0]);\n        // make it always backwards-compatible\n        if (this.version \u003e HarFileSystem.VERSION) {\n          throw new IOException(\"Invalid version \" + \n              this.version + \" expected \" + HarFileSystem.VERSION);\n        }\n\n        // each line contains a hashcode range and the index file name\n        String[] readStr \u003d null;\n        while(read \u003c masterStat.getLen()) {\n          int b \u003d lin.readLine(line);\n          read +\u003d b;\n          readStr \u003d line.toString().split(\" \");\n          int startHash \u003d Integer.parseInt(readStr[0]);\n          int endHash  \u003d Integer.parseInt(readStr[1]);\n          stores.add(new Store(Long.parseLong(readStr[2]), \n              Long.parseLong(readStr[3]), startHash,\n              endHash));\n          line.clear();\n        }\n      } finally {\n        IOUtils.cleanup(LOG, lin, in);\n      }\n\n      FSDataInputStream aIn \u003d fs.open(archiveIndexPath);\n      try {\n        FileStatus archiveStat \u003d fs.getFileStatus(archiveIndexPath);\n        archiveIndexTimestamp \u003d archiveStat.getModificationTime();\n        LineReader aLin;\n\n        // now start reading the real index file\n        for (Store s: stores) {\n          read \u003d 0;\n          aIn.seek(s.begin);\n          aLin \u003d new LineReader(aIn, getConf());\n          while (read + s.begin \u003c s.end) {\n            int tmp \u003d aLin.readLine(line);\n            read +\u003d tmp;\n            String lineFeed \u003d line.toString();\n            String[] parsed \u003d lineFeed.split(\" \");\n            parsed[0] \u003d decodeFileName(parsed[0]);\n            archive.put(new Path(parsed[0]), new HarStatus(lineFeed));\n            line.clear();\n          }\n        }\n      } finally {\n        IOUtils.cleanup(LOG, aIn);\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/HarFileSystem.java",
      "extendedDetails": {}
    },
    "4c13b6f34e277ae6badaa105abcb8e5515a54f06": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-8587. HarFileSystem access of harMetaCache isn\u0027t threadsafe. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1360448 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/07/12 3:28 PM",
      "commitName": "4c13b6f34e277ae6badaa105abcb8e5515a54f06",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "11/07/12 1:19 AM",
      "commitNameOld": "151a1b0185f13a659d7af302e920d5e3ab04c41e",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.59,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,65 @@\n     private void parseMetaData() throws IOException {\n       FSDataInputStream in \u003d fs.open(masterIndexPath);\n       FileStatus masterStat \u003d fs.getFileStatus(masterIndexPath);\n       masterIndexTimestamp \u003d masterStat.getModificationTime();\n       LineReader lin \u003d new LineReader(in, getConf());\n       Text line \u003d new Text();\n       long read \u003d lin.readLine(line);\n \n      // the first line contains the version of the index file\n       String versionLine \u003d line.toString();\n       String[] arr \u003d versionLine.split(\" \");\n       version \u003d Integer.parseInt(arr[0]);\n       // make it always backwards-compatible\n       if (this.version \u003e HarFileSystem.VERSION) {\n         throw new IOException(\"Invalid version \" + \n             this.version + \" expected \" + HarFileSystem.VERSION);\n       }\n \n       // each line contains a hashcode range and the index file name\n       String[] readStr \u003d null;\n       while(read \u003c masterStat.getLen()) {\n         int b \u003d lin.readLine(line);\n         read +\u003d b;\n         readStr \u003d line.toString().split(\" \");\n         int startHash \u003d Integer.parseInt(readStr[0]);\n         int endHash  \u003d Integer.parseInt(readStr[1]);\n         stores.add(new Store(Long.parseLong(readStr[2]), \n             Long.parseLong(readStr[3]), startHash,\n             endHash));\n         line.clear();\n       }\n       try {\n         // close the master index\n         lin.close();\n       } catch(IOException io){\n         // do nothing just a read.\n       }\n \n       FSDataInputStream aIn \u003d fs.open(archiveIndexPath);\n       FileStatus archiveStat \u003d fs.getFileStatus(archiveIndexPath);\n       archiveIndexTimestamp \u003d archiveStat.getModificationTime();\n       LineReader aLin;\n-      String retStr \u003d null;\n+\n       // now start reading the real index file\n       for (Store s: stores) {\n         read \u003d 0;\n         aIn.seek(s.begin);\n         aLin \u003d new LineReader(aIn, getConf());\n         while (read + s.begin \u003c s.end) {\n           int tmp \u003d aLin.readLine(line);\n           read +\u003d tmp;\n           String lineFeed \u003d line.toString();\n           String[] parsed \u003d lineFeed.split(\" \");\n           parsed[0] \u003d decodeFileName(parsed[0]);\n           archive.put(new Path(parsed[0]), new HarStatus(lineFeed));\n           line.clear();\n         }\n       }\n       try {\n         // close the archive index\n         aIn.close();\n       } catch(IOException io) {\n         // do nothing just a read.\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void parseMetaData() throws IOException {\n      FSDataInputStream in \u003d fs.open(masterIndexPath);\n      FileStatus masterStat \u003d fs.getFileStatus(masterIndexPath);\n      masterIndexTimestamp \u003d masterStat.getModificationTime();\n      LineReader lin \u003d new LineReader(in, getConf());\n      Text line \u003d new Text();\n      long read \u003d lin.readLine(line);\n\n     // the first line contains the version of the index file\n      String versionLine \u003d line.toString();\n      String[] arr \u003d versionLine.split(\" \");\n      version \u003d Integer.parseInt(arr[0]);\n      // make it always backwards-compatible\n      if (this.version \u003e HarFileSystem.VERSION) {\n        throw new IOException(\"Invalid version \" + \n            this.version + \" expected \" + HarFileSystem.VERSION);\n      }\n\n      // each line contains a hashcode range and the index file name\n      String[] readStr \u003d null;\n      while(read \u003c masterStat.getLen()) {\n        int b \u003d lin.readLine(line);\n        read +\u003d b;\n        readStr \u003d line.toString().split(\" \");\n        int startHash \u003d Integer.parseInt(readStr[0]);\n        int endHash  \u003d Integer.parseInt(readStr[1]);\n        stores.add(new Store(Long.parseLong(readStr[2]), \n            Long.parseLong(readStr[3]), startHash,\n            endHash));\n        line.clear();\n      }\n      try {\n        // close the master index\n        lin.close();\n      } catch(IOException io){\n        // do nothing just a read.\n      }\n\n      FSDataInputStream aIn \u003d fs.open(archiveIndexPath);\n      FileStatus archiveStat \u003d fs.getFileStatus(archiveIndexPath);\n      archiveIndexTimestamp \u003d archiveStat.getModificationTime();\n      LineReader aLin;\n\n      // now start reading the real index file\n      for (Store s: stores) {\n        read \u003d 0;\n        aIn.seek(s.begin);\n        aLin \u003d new LineReader(aIn, getConf());\n        while (read + s.begin \u003c s.end) {\n          int tmp \u003d aLin.readLine(line);\n          read +\u003d tmp;\n          String lineFeed \u003d line.toString();\n          String[] parsed \u003d lineFeed.split(\" \");\n          parsed[0] \u003d decodeFileName(parsed[0]);\n          archive.put(new Path(parsed[0]), new HarStatus(lineFeed));\n          line.clear();\n        }\n      }\n      try {\n        // close the archive index\n        aIn.close();\n      } catch(IOException io) {\n        // do nothing just a read.\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/HarFileSystem.java",
      "extendedDetails": {}
    },
    "0201be46c298e94176ec6297e9d9cdba3afc2bbd": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7810. move hadoop archive to core from tools. (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213907 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/12/11 12:17 PM",
      "commitName": "0201be46c298e94176ec6297e9d9cdba3afc2bbd",
      "commitAuthor": "Alejandro Abdelnur",
      "commitDateOld": "13/12/11 10:07 AM",
      "commitNameOld": "f2f4e9341387199e04679ebc8de5e05c0fdbd437",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.09,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void parseMetaData() throws IOException {\n      FSDataInputStream in \u003d fs.open(masterIndexPath);\n      FileStatus masterStat \u003d fs.getFileStatus(masterIndexPath);\n      masterIndexTimestamp \u003d masterStat.getModificationTime();\n      LineReader lin \u003d new LineReader(in, getConf());\n      Text line \u003d new Text();\n      long read \u003d lin.readLine(line);\n\n     // the first line contains the version of the index file\n      String versionLine \u003d line.toString();\n      String[] arr \u003d versionLine.split(\" \");\n      version \u003d Integer.parseInt(arr[0]);\n      // make it always backwards-compatible\n      if (this.version \u003e HarFileSystem.VERSION) {\n        throw new IOException(\"Invalid version \" + \n            this.version + \" expected \" + HarFileSystem.VERSION);\n      }\n\n      // each line contains a hashcode range and the index file name\n      String[] readStr \u003d null;\n      while(read \u003c masterStat.getLen()) {\n        int b \u003d lin.readLine(line);\n        read +\u003d b;\n        readStr \u003d line.toString().split(\" \");\n        int startHash \u003d Integer.parseInt(readStr[0]);\n        int endHash  \u003d Integer.parseInt(readStr[1]);\n        stores.add(new Store(Long.parseLong(readStr[2]), \n            Long.parseLong(readStr[3]), startHash,\n            endHash));\n        line.clear();\n      }\n      try {\n        // close the master index\n        lin.close();\n      } catch(IOException io){\n        // do nothing just a read.\n      }\n\n      FSDataInputStream aIn \u003d fs.open(archiveIndexPath);\n      FileStatus archiveStat \u003d fs.getFileStatus(archiveIndexPath);\n      archiveIndexTimestamp \u003d archiveStat.getModificationTime();\n      LineReader aLin;\n      String retStr \u003d null;\n      // now start reading the real index file\n      for (Store s: stores) {\n        read \u003d 0;\n        aIn.seek(s.begin);\n        aLin \u003d new LineReader(aIn, getConf());\n        while (read + s.begin \u003c s.end) {\n          int tmp \u003d aLin.readLine(line);\n          read +\u003d tmp;\n          String lineFeed \u003d line.toString();\n          String[] parsed \u003d lineFeed.split(\" \");\n          parsed[0] \u003d decodeFileName(parsed[0]);\n          archive.put(new Path(parsed[0]), new HarStatus(lineFeed));\n          line.clear();\n        }\n      }\n      try {\n        // close the archive index\n        aIn.close();\n      } catch(IOException io) {\n        // do nothing just a read.\n      }\n    }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/HarFileSystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/fs/HarFileSystem.java",
        "newPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/HarFileSystem.java"
      }
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void parseMetaData() throws IOException {\n      FSDataInputStream in \u003d fs.open(masterIndexPath);\n      FileStatus masterStat \u003d fs.getFileStatus(masterIndexPath);\n      masterIndexTimestamp \u003d masterStat.getModificationTime();\n      LineReader lin \u003d new LineReader(in, getConf());\n      Text line \u003d new Text();\n      long read \u003d lin.readLine(line);\n\n     // the first line contains the version of the index file\n      String versionLine \u003d line.toString();\n      String[] arr \u003d versionLine.split(\" \");\n      version \u003d Integer.parseInt(arr[0]);\n      // make it always backwards-compatible\n      if (this.version \u003e HarFileSystem.VERSION) {\n        throw new IOException(\"Invalid version \" + \n            this.version + \" expected \" + HarFileSystem.VERSION);\n      }\n\n      // each line contains a hashcode range and the index file name\n      String[] readStr \u003d null;\n      while(read \u003c masterStat.getLen()) {\n        int b \u003d lin.readLine(line);\n        read +\u003d b;\n        readStr \u003d line.toString().split(\" \");\n        int startHash \u003d Integer.parseInt(readStr[0]);\n        int endHash  \u003d Integer.parseInt(readStr[1]);\n        stores.add(new Store(Long.parseLong(readStr[2]), \n            Long.parseLong(readStr[3]), startHash,\n            endHash));\n        line.clear();\n      }\n      try {\n        // close the master index\n        lin.close();\n      } catch(IOException io){\n        // do nothing just a read.\n      }\n\n      FSDataInputStream aIn \u003d fs.open(archiveIndexPath);\n      FileStatus archiveStat \u003d fs.getFileStatus(archiveIndexPath);\n      archiveIndexTimestamp \u003d archiveStat.getModificationTime();\n      LineReader aLin;\n      String retStr \u003d null;\n      // now start reading the real index file\n      for (Store s: stores) {\n        read \u003d 0;\n        aIn.seek(s.begin);\n        aLin \u003d new LineReader(aIn, getConf());\n        while (read + s.begin \u003c s.end) {\n          int tmp \u003d aLin.readLine(line);\n          read +\u003d tmp;\n          String lineFeed \u003d line.toString();\n          String[] parsed \u003d lineFeed.split(\" \");\n          parsed[0] \u003d decodeFileName(parsed[0]);\n          archive.put(new Path(parsed[0]), new HarStatus(lineFeed));\n          line.clear();\n        }\n      }\n      try {\n        // close the archive index\n        aIn.close();\n      } catch(IOException io) {\n        // do nothing just a read.\n      }\n    }",
      "path": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/fs/HarFileSystem.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/src/tools/org/apache/hadoop/fs/HarFileSystem.java",
        "newPath": "hadoop-mapreduce-project/src/tools/org/apache/hadoop/fs/HarFileSystem.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    private void parseMetaData() throws IOException {\n      FSDataInputStream in \u003d fs.open(masterIndexPath);\n      FileStatus masterStat \u003d fs.getFileStatus(masterIndexPath);\n      masterIndexTimestamp \u003d masterStat.getModificationTime();\n      LineReader lin \u003d new LineReader(in, getConf());\n      Text line \u003d new Text();\n      long read \u003d lin.readLine(line);\n\n     // the first line contains the version of the index file\n      String versionLine \u003d line.toString();\n      String[] arr \u003d versionLine.split(\" \");\n      version \u003d Integer.parseInt(arr[0]);\n      // make it always backwards-compatible\n      if (this.version \u003e HarFileSystem.VERSION) {\n        throw new IOException(\"Invalid version \" + \n            this.version + \" expected \" + HarFileSystem.VERSION);\n      }\n\n      // each line contains a hashcode range and the index file name\n      String[] readStr \u003d null;\n      while(read \u003c masterStat.getLen()) {\n        int b \u003d lin.readLine(line);\n        read +\u003d b;\n        readStr \u003d line.toString().split(\" \");\n        int startHash \u003d Integer.parseInt(readStr[0]);\n        int endHash  \u003d Integer.parseInt(readStr[1]);\n        stores.add(new Store(Long.parseLong(readStr[2]), \n            Long.parseLong(readStr[3]), startHash,\n            endHash));\n        line.clear();\n      }\n      try {\n        // close the master index\n        lin.close();\n      } catch(IOException io){\n        // do nothing just a read.\n      }\n\n      FSDataInputStream aIn \u003d fs.open(archiveIndexPath);\n      FileStatus archiveStat \u003d fs.getFileStatus(archiveIndexPath);\n      archiveIndexTimestamp \u003d archiveStat.getModificationTime();\n      LineReader aLin;\n      String retStr \u003d null;\n      // now start reading the real index file\n      for (Store s: stores) {\n        read \u003d 0;\n        aIn.seek(s.begin);\n        aLin \u003d new LineReader(aIn, getConf());\n        while (read + s.begin \u003c s.end) {\n          int tmp \u003d aLin.readLine(line);\n          read +\u003d tmp;\n          String lineFeed \u003d line.toString();\n          String[] parsed \u003d lineFeed.split(\" \");\n          parsed[0] \u003d decodeFileName(parsed[0]);\n          archive.put(new Path(parsed[0]), new HarStatus(lineFeed));\n          line.clear();\n        }\n      }\n      try {\n        // close the archive index\n        aIn.close();\n      } catch(IOException io) {\n        // do nothing just a read.\n      }\n    }",
      "path": "hadoop-mapreduce/src/tools/org/apache/hadoop/fs/HarFileSystem.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/tools/org/apache/hadoop/fs/HarFileSystem.java",
        "newPath": "hadoop-mapreduce/src/tools/org/apache/hadoop/fs/HarFileSystem.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,65 @@\n+    private void parseMetaData() throws IOException {\n+      FSDataInputStream in \u003d fs.open(masterIndexPath);\n+      FileStatus masterStat \u003d fs.getFileStatus(masterIndexPath);\n+      masterIndexTimestamp \u003d masterStat.getModificationTime();\n+      LineReader lin \u003d new LineReader(in, getConf());\n+      Text line \u003d new Text();\n+      long read \u003d lin.readLine(line);\n+\n+     // the first line contains the version of the index file\n+      String versionLine \u003d line.toString();\n+      String[] arr \u003d versionLine.split(\" \");\n+      version \u003d Integer.parseInt(arr[0]);\n+      // make it always backwards-compatible\n+      if (this.version \u003e HarFileSystem.VERSION) {\n+        throw new IOException(\"Invalid version \" + \n+            this.version + \" expected \" + HarFileSystem.VERSION);\n+      }\n+\n+      // each line contains a hashcode range and the index file name\n+      String[] readStr \u003d null;\n+      while(read \u003c masterStat.getLen()) {\n+        int b \u003d lin.readLine(line);\n+        read +\u003d b;\n+        readStr \u003d line.toString().split(\" \");\n+        int startHash \u003d Integer.parseInt(readStr[0]);\n+        int endHash  \u003d Integer.parseInt(readStr[1]);\n+        stores.add(new Store(Long.parseLong(readStr[2]), \n+            Long.parseLong(readStr[3]), startHash,\n+            endHash));\n+        line.clear();\n+      }\n+      try {\n+        // close the master index\n+        lin.close();\n+      } catch(IOException io){\n+        // do nothing just a read.\n+      }\n+\n+      FSDataInputStream aIn \u003d fs.open(archiveIndexPath);\n+      FileStatus archiveStat \u003d fs.getFileStatus(archiveIndexPath);\n+      archiveIndexTimestamp \u003d archiveStat.getModificationTime();\n+      LineReader aLin;\n+      String retStr \u003d null;\n+      // now start reading the real index file\n+      for (Store s: stores) {\n+        read \u003d 0;\n+        aIn.seek(s.begin);\n+        aLin \u003d new LineReader(aIn, getConf());\n+        while (read + s.begin \u003c s.end) {\n+          int tmp \u003d aLin.readLine(line);\n+          read +\u003d tmp;\n+          String lineFeed \u003d line.toString();\n+          String[] parsed \u003d lineFeed.split(\" \");\n+          parsed[0] \u003d decodeFileName(parsed[0]);\n+          archive.put(new Path(parsed[0]), new HarStatus(lineFeed));\n+          line.clear();\n+        }\n+      }\n+      try {\n+        // close the archive index\n+        aIn.close();\n+      } catch(IOException io) {\n+        // do nothing just a read.\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    private void parseMetaData() throws IOException {\n      FSDataInputStream in \u003d fs.open(masterIndexPath);\n      FileStatus masterStat \u003d fs.getFileStatus(masterIndexPath);\n      masterIndexTimestamp \u003d masterStat.getModificationTime();\n      LineReader lin \u003d new LineReader(in, getConf());\n      Text line \u003d new Text();\n      long read \u003d lin.readLine(line);\n\n     // the first line contains the version of the index file\n      String versionLine \u003d line.toString();\n      String[] arr \u003d versionLine.split(\" \");\n      version \u003d Integer.parseInt(arr[0]);\n      // make it always backwards-compatible\n      if (this.version \u003e HarFileSystem.VERSION) {\n        throw new IOException(\"Invalid version \" + \n            this.version + \" expected \" + HarFileSystem.VERSION);\n      }\n\n      // each line contains a hashcode range and the index file name\n      String[] readStr \u003d null;\n      while(read \u003c masterStat.getLen()) {\n        int b \u003d lin.readLine(line);\n        read +\u003d b;\n        readStr \u003d line.toString().split(\" \");\n        int startHash \u003d Integer.parseInt(readStr[0]);\n        int endHash  \u003d Integer.parseInt(readStr[1]);\n        stores.add(new Store(Long.parseLong(readStr[2]), \n            Long.parseLong(readStr[3]), startHash,\n            endHash));\n        line.clear();\n      }\n      try {\n        // close the master index\n        lin.close();\n      } catch(IOException io){\n        // do nothing just a read.\n      }\n\n      FSDataInputStream aIn \u003d fs.open(archiveIndexPath);\n      FileStatus archiveStat \u003d fs.getFileStatus(archiveIndexPath);\n      archiveIndexTimestamp \u003d archiveStat.getModificationTime();\n      LineReader aLin;\n      String retStr \u003d null;\n      // now start reading the real index file\n      for (Store s: stores) {\n        read \u003d 0;\n        aIn.seek(s.begin);\n        aLin \u003d new LineReader(aIn, getConf());\n        while (read + s.begin \u003c s.end) {\n          int tmp \u003d aLin.readLine(line);\n          read +\u003d tmp;\n          String lineFeed \u003d line.toString();\n          String[] parsed \u003d lineFeed.split(\" \");\n          parsed[0] \u003d decodeFileName(parsed[0]);\n          archive.put(new Path(parsed[0]), new HarStatus(lineFeed));\n          line.clear();\n        }\n      }\n      try {\n        // close the archive index\n        aIn.close();\n      } catch(IOException io) {\n        // do nothing just a read.\n      }\n    }",
      "path": "mapreduce/src/tools/org/apache/hadoop/fs/HarFileSystem.java"
    }
  }
}