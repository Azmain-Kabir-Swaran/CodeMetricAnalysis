{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JsonUtilClient.java",
  "functionName": "toDatanodeInfoArray",
  "functionId": "toDatanodeInfoArray___objects-List__?__(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
  "functionStartLine": 354,
  "functionEndLine": 368,
  "numCommitsSeen": 137,
  "timeTaken": 4276,
  "changeHistory": [
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
    "ab04ff9efe632b4eca6faca7407ac35e00e6a379",
    "e2262d3d18c6d5c2aa20f96920104dc07271b869",
    "b4d6c5823b04b2a8834e06e78cd109a359496eed",
    "1b1016beeb716bef8dad93bb2c7c4631a14b3d57",
    "4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de"
  ],
  "changeHistoryShort": {
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": "Yfilerename",
    "ab04ff9efe632b4eca6faca7407ac35e00e6a379": "Ymultichange(Ymovefromfile,Ymodifierchange)",
    "e2262d3d18c6d5c2aa20f96920104dc07271b869": "Ymultichange(Yparameterchange,Ybodychange)",
    "b4d6c5823b04b2a8834e06e78cd109a359496eed": "Yexceptionschange",
    "1b1016beeb716bef8dad93bb2c7c4631a14b3d57": "Ymultichange(Ymodifierchange,Ybodychange)",
    "4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de": "Yintroduced"
  },
  "changeHistoryDetails": {
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8052. Move WebHdfsFileSystem into hadoop-hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "23/04/15 5:33 PM",
      "commitName": "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "23/04/15 4:40 PM",
      "commitNameOld": "0b3f8957a87ada1a275c9904b211fdbdcefafb02",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  static DatanodeInfo[] toDatanodeInfoArray(final List\u003c?\u003e objects)\n      throws IOException {\n    if (objects \u003d\u003d null) {\n      return null;\n    } else if (objects.isEmpty()) {\n      return EMPTY_DATANODE_INFO_ARRAY;\n    } else {\n      final DatanodeInfo[] array \u003d new DatanodeInfo[objects.size()];\n      int i \u003d 0;\n      for (Object object : objects) {\n        array[i++] \u003d toDatanodeInfo((Map\u003c?, ?\u003e) object);\n      }\n      return array;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java"
      }
    },
    "ab04ff9efe632b4eca6faca7407ac35e00e6a379": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange)",
      "commitMessage": "HDFS-8080. Separate JSON related routines used by WebHdfsFileSystem to a package local class. Contributed by Haohui Mai.\n",
      "commitDate": "07/04/15 9:30 PM",
      "commitName": "ab04ff9efe632b4eca6faca7407ac35e00e6a379",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-8080. Separate JSON related routines used by WebHdfsFileSystem to a package local class. Contributed by Haohui Mai.\n",
          "commitDate": "07/04/15 9:30 PM",
          "commitName": "ab04ff9efe632b4eca6faca7407ac35e00e6a379",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "07/04/15 9:26 PM",
          "commitNameOld": "d505c8acd30d6f40d0632fe9c93c886a4499a9fc",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,15 @@\n-  private static DatanodeInfo[] toDatanodeInfoArray(final List\u003c?\u003e objects)\n+  static DatanodeInfo[] toDatanodeInfoArray(final List\u003c?\u003e objects)\n       throws IOException {\n     if (objects \u003d\u003d null) {\n       return null;\n     } else if (objects.isEmpty()) {\n       return EMPTY_DATANODE_INFO_ARRAY;\n     } else {\n       final DatanodeInfo[] array \u003d new DatanodeInfo[objects.size()];\n       int i \u003d 0;\n       for (Object object : objects) {\n         array[i++] \u003d toDatanodeInfo((Map\u003c?, ?\u003e) object);\n       }\n       return array;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static DatanodeInfo[] toDatanodeInfoArray(final List\u003c?\u003e objects)\n      throws IOException {\n    if (objects \u003d\u003d null) {\n      return null;\n    } else if (objects.isEmpty()) {\n      return EMPTY_DATANODE_INFO_ARRAY;\n    } else {\n      final DatanodeInfo[] array \u003d new DatanodeInfo[objects.size()];\n      int i \u003d 0;\n      for (Object object : objects) {\n        array[i++] \u003d toDatanodeInfo((Map\u003c?, ?\u003e) object);\n      }\n      return array;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
            "oldMethodName": "toDatanodeInfoArray",
            "newMethodName": "toDatanodeInfoArray"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-8080. Separate JSON related routines used by WebHdfsFileSystem to a package local class. Contributed by Haohui Mai.\n",
          "commitDate": "07/04/15 9:30 PM",
          "commitName": "ab04ff9efe632b4eca6faca7407ac35e00e6a379",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "07/04/15 9:26 PM",
          "commitNameOld": "d505c8acd30d6f40d0632fe9c93c886a4499a9fc",
          "commitAuthorOld": "Vinayakumar B",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,15 @@\n-  private static DatanodeInfo[] toDatanodeInfoArray(final List\u003c?\u003e objects)\n+  static DatanodeInfo[] toDatanodeInfoArray(final List\u003c?\u003e objects)\n       throws IOException {\n     if (objects \u003d\u003d null) {\n       return null;\n     } else if (objects.isEmpty()) {\n       return EMPTY_DATANODE_INFO_ARRAY;\n     } else {\n       final DatanodeInfo[] array \u003d new DatanodeInfo[objects.size()];\n       int i \u003d 0;\n       for (Object object : objects) {\n         array[i++] \u003d toDatanodeInfo((Map\u003c?, ?\u003e) object);\n       }\n       return array;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static DatanodeInfo[] toDatanodeInfoArray(final List\u003c?\u003e objects)\n      throws IOException {\n    if (objects \u003d\u003d null) {\n      return null;\n    } else if (objects.isEmpty()) {\n      return EMPTY_DATANODE_INFO_ARRAY;\n    } else {\n      final DatanodeInfo[] array \u003d new DatanodeInfo[objects.size()];\n      int i \u003d 0;\n      for (Object object : objects) {\n        array[i++] \u003d toDatanodeInfo((Map\u003c?, ?\u003e) object);\n      }\n      return array;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtilClient.java",
          "extendedDetails": {
            "oldValue": "[private, static]",
            "newValue": "[static]"
          }
        }
      ]
    },
    "e2262d3d18c6d5c2aa20f96920104dc07271b869": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6565. Use jackson instead jetty json in hdfs-client. Contributed by Akira AJISAKA.\n",
      "commitDate": "03/03/15 5:54 PM",
      "commitName": "e2262d3d18c6d5c2aa20f96920104dc07271b869",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6565. Use jackson instead jetty json in hdfs-client. Contributed by Akira AJISAKA.\n",
          "commitDate": "03/03/15 5:54 PM",
          "commitName": "e2262d3d18c6d5c2aa20f96920104dc07271b869",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "08/12/14 10:23 AM",
          "commitNameOld": "ffe942b82c1208bc7b22899da3a233944cb5ab52",
          "commitAuthorOld": "cnauroth",
          "daysBetweenCommits": 85.31,
          "commitsBetweenForRepo": 663,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,15 @@\n-  private static DatanodeInfo[] toDatanodeInfoArray(final Object[] objects) \n+  private static DatanodeInfo[] toDatanodeInfoArray(final List\u003c?\u003e objects)\n       throws IOException {\n     if (objects \u003d\u003d null) {\n       return null;\n-    } else if (objects.length \u003d\u003d 0) {\n+    } else if (objects.isEmpty()) {\n       return EMPTY_DATANODE_INFO_ARRAY;\n     } else {\n-      final DatanodeInfo[] array \u003d new DatanodeInfo[objects.length];\n-      for(int i \u003d 0; i \u003c array.length; i++) {\n-        array[i] \u003d toDatanodeInfo((Map\u003c?, ?\u003e) objects[i]);\n+      final DatanodeInfo[] array \u003d new DatanodeInfo[objects.size()];\n+      int i \u003d 0;\n+      for (Object object : objects) {\n+        array[i++] \u003d toDatanodeInfo((Map\u003c?, ?\u003e) object);\n       }\n       return array;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static DatanodeInfo[] toDatanodeInfoArray(final List\u003c?\u003e objects)\n      throws IOException {\n    if (objects \u003d\u003d null) {\n      return null;\n    } else if (objects.isEmpty()) {\n      return EMPTY_DATANODE_INFO_ARRAY;\n    } else {\n      final DatanodeInfo[] array \u003d new DatanodeInfo[objects.size()];\n      int i \u003d 0;\n      for (Object object : objects) {\n        array[i++] \u003d toDatanodeInfo((Map\u003c?, ?\u003e) object);\n      }\n      return array;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
          "extendedDetails": {
            "oldValue": "[objects-Object[](modifiers-final)]",
            "newValue": "[objects-List\u003c?\u003e(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6565. Use jackson instead jetty json in hdfs-client. Contributed by Akira AJISAKA.\n",
          "commitDate": "03/03/15 5:54 PM",
          "commitName": "e2262d3d18c6d5c2aa20f96920104dc07271b869",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "08/12/14 10:23 AM",
          "commitNameOld": "ffe942b82c1208bc7b22899da3a233944cb5ab52",
          "commitAuthorOld": "cnauroth",
          "daysBetweenCommits": 85.31,
          "commitsBetweenForRepo": 663,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,14 +1,15 @@\n-  private static DatanodeInfo[] toDatanodeInfoArray(final Object[] objects) \n+  private static DatanodeInfo[] toDatanodeInfoArray(final List\u003c?\u003e objects)\n       throws IOException {\n     if (objects \u003d\u003d null) {\n       return null;\n-    } else if (objects.length \u003d\u003d 0) {\n+    } else if (objects.isEmpty()) {\n       return EMPTY_DATANODE_INFO_ARRAY;\n     } else {\n-      final DatanodeInfo[] array \u003d new DatanodeInfo[objects.length];\n-      for(int i \u003d 0; i \u003c array.length; i++) {\n-        array[i] \u003d toDatanodeInfo((Map\u003c?, ?\u003e) objects[i]);\n+      final DatanodeInfo[] array \u003d new DatanodeInfo[objects.size()];\n+      int i \u003d 0;\n+      for (Object object : objects) {\n+        array[i++] \u003d toDatanodeInfo((Map\u003c?, ?\u003e) object);\n       }\n       return array;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static DatanodeInfo[] toDatanodeInfoArray(final List\u003c?\u003e objects)\n      throws IOException {\n    if (objects \u003d\u003d null) {\n      return null;\n    } else if (objects.isEmpty()) {\n      return EMPTY_DATANODE_INFO_ARRAY;\n    } else {\n      final DatanodeInfo[] array \u003d new DatanodeInfo[objects.size()];\n      int i \u003d 0;\n      for (Object object : objects) {\n        array[i++] \u003d toDatanodeInfo((Map\u003c?, ?\u003e) object);\n      }\n      return array;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
          "extendedDetails": {}
        }
      ]
    },
    "b4d6c5823b04b2a8834e06e78cd109a359496eed": {
      "type": "Yexceptionschange",
      "commitMessage": "HDFS-5449. WebHdfs compatibility broken between 2.2 and 1.x / 23.x. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1556927 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/14 11:24 AM",
      "commitName": "b4d6c5823b04b2a8834e06e78cd109a359496eed",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "12/11/13 6:00 PM",
      "commitNameOld": "46cbce9af1272ce0eb6e300f96a1a8d4b08e23e3",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 57.72,
      "commitsBetweenForRepo": 308,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,14 @@\n-  private static DatanodeInfo[] toDatanodeInfoArray(final Object[] objects) {\n+  private static DatanodeInfo[] toDatanodeInfoArray(final Object[] objects) \n+      throws IOException {\n     if (objects \u003d\u003d null) {\n       return null;\n     } else if (objects.length \u003d\u003d 0) {\n       return EMPTY_DATANODE_INFO_ARRAY;\n     } else {\n       final DatanodeInfo[] array \u003d new DatanodeInfo[objects.length];\n       for(int i \u003d 0; i \u003c array.length; i++) {\n         array[i] \u003d toDatanodeInfo((Map\u003c?, ?\u003e) objects[i]);\n       }\n       return array;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static DatanodeInfo[] toDatanodeInfoArray(final Object[] objects) \n      throws IOException {\n    if (objects \u003d\u003d null) {\n      return null;\n    } else if (objects.length \u003d\u003d 0) {\n      return EMPTY_DATANODE_INFO_ARRAY;\n    } else {\n      final DatanodeInfo[] array \u003d new DatanodeInfo[objects.length];\n      for(int i \u003d 0; i \u003c array.length; i++) {\n        array[i] \u003d toDatanodeInfo((Map\u003c?, ?\u003e) objects[i]);\n      }\n      return array;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
      "extendedDetails": {
        "oldValue": "[]",
        "newValue": "[IOException]"
      }
    },
    "1b1016beeb716bef8dad93bb2c7c4631a14b3d57": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-2395. Add a root element in the JSON responses of webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1179169 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/10/11 4:29 AM",
      "commitName": "1b1016beeb716bef8dad93bb2c7c4631a14b3d57",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-2395. Add a root element in the JSON responses of webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1179169 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "05/10/11 4:29 AM",
          "commitName": "1b1016beeb716bef8dad93bb2c7c4631a14b3d57",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "30/09/11 9:49 PM",
          "commitNameOld": "dc8464f943b61b795df0cc8baec171bf07355763",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 4.28,
          "commitsBetweenForRepo": 25,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,13 @@\n-  public static DatanodeInfo[] toDatanodeInfoArray(final Object[] objects) {\n+  private static DatanodeInfo[] toDatanodeInfoArray(final Object[] objects) {\n     if (objects \u003d\u003d null) {\n       return null;\n     } else if (objects.length \u003d\u003d 0) {\n       return EMPTY_DATANODE_INFO_ARRAY;\n     } else {\n       final DatanodeInfo[] array \u003d new DatanodeInfo[objects.length];\n       for(int i \u003d 0; i \u003c array.length; i++) {\n-        array[i] \u003d (DatanodeInfo)toDatanodeInfo((Map\u003c?, ?\u003e) objects[i]);\n+        array[i] \u003d toDatanodeInfo((Map\u003c?, ?\u003e) objects[i]);\n       }\n       return array;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static DatanodeInfo[] toDatanodeInfoArray(final Object[] objects) {\n    if (objects \u003d\u003d null) {\n      return null;\n    } else if (objects.length \u003d\u003d 0) {\n      return EMPTY_DATANODE_INFO_ARRAY;\n    } else {\n      final DatanodeInfo[] array \u003d new DatanodeInfo[objects.length];\n      for(int i \u003d 0; i \u003c array.length; i++) {\n        array[i] \u003d toDatanodeInfo((Map\u003c?, ?\u003e) objects[i]);\n      }\n      return array;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
          "extendedDetails": {
            "oldValue": "[public, static]",
            "newValue": "[private, static]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2395. Add a root element in the JSON responses of webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1179169 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "05/10/11 4:29 AM",
          "commitName": "1b1016beeb716bef8dad93bb2c7c4631a14b3d57",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "30/09/11 9:49 PM",
          "commitNameOld": "dc8464f943b61b795df0cc8baec171bf07355763",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 4.28,
          "commitsBetweenForRepo": 25,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,13 @@\n-  public static DatanodeInfo[] toDatanodeInfoArray(final Object[] objects) {\n+  private static DatanodeInfo[] toDatanodeInfoArray(final Object[] objects) {\n     if (objects \u003d\u003d null) {\n       return null;\n     } else if (objects.length \u003d\u003d 0) {\n       return EMPTY_DATANODE_INFO_ARRAY;\n     } else {\n       final DatanodeInfo[] array \u003d new DatanodeInfo[objects.length];\n       for(int i \u003d 0; i \u003c array.length; i++) {\n-        array[i] \u003d (DatanodeInfo)toDatanodeInfo((Map\u003c?, ?\u003e) objects[i]);\n+        array[i] \u003d toDatanodeInfo((Map\u003c?, ?\u003e) objects[i]);\n       }\n       return array;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static DatanodeInfo[] toDatanodeInfoArray(final Object[] objects) {\n    if (objects \u003d\u003d null) {\n      return null;\n    } else if (objects.length \u003d\u003d 0) {\n      return EMPTY_DATANODE_INFO_ARRAY;\n    } else {\n      final DatanodeInfo[] array \u003d new DatanodeInfo[objects.length];\n      for(int i \u003d 0; i \u003c array.length; i++) {\n        array[i] \u003d toDatanodeInfo((Map\u003c?, ?\u003e) objects[i]);\n      }\n      return array;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java",
          "extendedDetails": {}
        }
      ]
    },
    "4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2340. Support getFileBlockLocations and getDelegationToken in webhdfs.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1173468 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/09/11 7:56 PM",
      "commitName": "4dc4e9e63f7385ddd1d64ae1345e0d32a4acb9de",
      "commitAuthor": "Tsz-wo Sze",
      "diff": "@@ -0,0 +1,13 @@\n+  public static DatanodeInfo[] toDatanodeInfoArray(final Object[] objects) {\n+    if (objects \u003d\u003d null) {\n+      return null;\n+    } else if (objects.length \u003d\u003d 0) {\n+      return EMPTY_DATANODE_INFO_ARRAY;\n+    } else {\n+      final DatanodeInfo[] array \u003d new DatanodeInfo[objects.length];\n+      for(int i \u003d 0; i \u003c array.length; i++) {\n+        array[i] \u003d (DatanodeInfo)toDatanodeInfo((Map\u003c?, ?\u003e) objects[i]);\n+      }\n+      return array;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static DatanodeInfo[] toDatanodeInfoArray(final Object[] objects) {\n    if (objects \u003d\u003d null) {\n      return null;\n    } else if (objects.length \u003d\u003d 0) {\n      return EMPTY_DATANODE_INFO_ARRAY;\n    } else {\n      final DatanodeInfo[] array \u003d new DatanodeInfo[objects.length];\n      for(int i \u003d 0; i \u003c array.length; i++) {\n        array[i] \u003d (DatanodeInfo)toDatanodeInfo((Map\u003c?, ?\u003e) objects[i]);\n      }\n      return array;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java"
    }
  }
}