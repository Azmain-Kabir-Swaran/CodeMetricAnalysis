{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FoldedTreeSet.java",
  "functionName": "compact",
  "functionId": "compact___timeout-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/FoldedTreeSet.java",
  "functionStartLine": 1245,
  "functionEndLine": 1284,
  "numCommitsSeen": 1,
  "timeTaken": 1375,
  "changeHistory": [
    "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a"
  ],
  "changeHistoryShort": {
    "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a": "Yintroduced"
  },
  "changeHistoryDetails": {
    "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-9260. Improve the performance and GC friendliness of NameNode startup and full block reports (Staffan Friberg via cmccabe)\n",
      "commitDate": "02/02/16 11:23 AM",
      "commitName": "dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a",
      "commitAuthor": "Colin Patrick Mccabe",
      "diff": "@@ -0,0 +1,40 @@\n+  public boolean compact(long timeout) {\n+\n+    if (!isEmpty()) {\n+      long start \u003d Time.monotonicNow();\n+      Node\u003cE\u003e node \u003d root.getLeftMostNode();\n+      while (node !\u003d null) {\n+        if (node.prev !\u003d null \u0026\u0026 !node.prev.isFull()) {\n+          Node\u003cE\u003e prev \u003d node.prev;\n+          int count \u003d Math.min(Node.NODE_SIZE - prev.size, node.size);\n+          System.arraycopy(node.entries, node.leftIndex,\n+                           prev.entries, prev.rightIndex + 1, count);\n+          node.leftIndex +\u003d count;\n+          node.size -\u003d count;\n+          prev.rightIndex +\u003d count;\n+          prev.size +\u003d count;\n+        }\n+        if (node.isEmpty()) {\n+          Node\u003cE\u003e temp \u003d node.next;\n+          deleteNode(node);\n+          node \u003d temp;\n+          continue;\n+        } else if (!node.isFull()) {\n+          if (node.leftIndex !\u003d 0) {\n+            System.arraycopy(node.entries, node.leftIndex,\n+                             node.entries, 0, node.size);\n+            Arrays.fill(node.entries, node.size, node.rightIndex + 1, null);\n+            node.leftIndex \u003d 0;\n+            node.rightIndex \u003d node.size - 1;\n+          }\n+        }\n+        node \u003d node.next;\n+\n+        if (Time.monotonicNow() - start \u003e timeout) {\n+          return false;\n+        }\n+      }\n+    }\n+\n+    return true;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public boolean compact(long timeout) {\n\n    if (!isEmpty()) {\n      long start \u003d Time.monotonicNow();\n      Node\u003cE\u003e node \u003d root.getLeftMostNode();\n      while (node !\u003d null) {\n        if (node.prev !\u003d null \u0026\u0026 !node.prev.isFull()) {\n          Node\u003cE\u003e prev \u003d node.prev;\n          int count \u003d Math.min(Node.NODE_SIZE - prev.size, node.size);\n          System.arraycopy(node.entries, node.leftIndex,\n                           prev.entries, prev.rightIndex + 1, count);\n          node.leftIndex +\u003d count;\n          node.size -\u003d count;\n          prev.rightIndex +\u003d count;\n          prev.size +\u003d count;\n        }\n        if (node.isEmpty()) {\n          Node\u003cE\u003e temp \u003d node.next;\n          deleteNode(node);\n          node \u003d temp;\n          continue;\n        } else if (!node.isFull()) {\n          if (node.leftIndex !\u003d 0) {\n            System.arraycopy(node.entries, node.leftIndex,\n                             node.entries, 0, node.size);\n            Arrays.fill(node.entries, node.size, node.rightIndex + 1, null);\n            node.leftIndex \u003d 0;\n            node.rightIndex \u003d node.size - 1;\n          }\n        }\n        node \u003d node.next;\n\n        if (Time.monotonicNow() - start \u003e timeout) {\n          return false;\n        }\n      }\n    }\n\n    return true;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/FoldedTreeSet.java"
    }
  }
}