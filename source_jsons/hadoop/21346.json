{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JobHistoryParser.java",
  "functionName": "handleTaskAttemptStartedEvent",
  "functionId": "handleTaskAttemptStartedEvent___event-TaskAttemptStartedEvent",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java",
  "functionStartLine": 331,
  "functionEndLine": 345,
  "numCommitsSeen": 31,
  "timeTaken": 5047,
  "changeHistory": [
    "def0b949d442ecd27ff1a9623405624db691ecfe",
    "13e4562924a6cb3d16c262e0f595b2ffbf9e0546",
    "277e520579a3452b95a5ffe2616d4f252d3c53fb",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "def0b949d442ecd27ff1a9623405624db691ecfe": "Ybodychange",
    "13e4562924a6cb3d16c262e0f595b2ffbf9e0546": "Ybodychange",
    "277e520579a3452b95a5ffe2616d4f252d3c53fb": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "def0b949d442ecd27ff1a9623405624db691ecfe": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4229. Intern counter names in the JT (bobby via daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1401467 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/10/12 1:57 PM",
      "commitName": "def0b949d442ecd27ff1a9623405624db691ecfe",
      "commitAuthor": "Daryn Sharp",
      "commitDateOld": "21/08/12 8:20 AM",
      "commitNameOld": "0c2887b6172bda7fbff27705ec536715c8e9e2b8",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 63.23,
      "commitsBetweenForRepo": 396,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,15 @@\n   private void handleTaskAttemptStartedEvent(TaskAttemptStartedEvent event) {\n     TaskAttemptID attemptId \u003d event.getTaskAttemptId();\n     TaskInfo taskInfo \u003d info.tasksMap.get(event.getTaskId());\n     \n     TaskAttemptInfo attemptInfo \u003d new TaskAttemptInfo();\n     attemptInfo.startTime \u003d event.getStartTime();\n     attemptInfo.attemptId \u003d event.getTaskAttemptId();\n     attemptInfo.httpPort \u003d event.getHttpPort();\n-    attemptInfo.trackerName \u003d event.getTrackerName();\n+    attemptInfo.trackerName \u003d StringInterner.weakIntern(event.getTrackerName());\n     attemptInfo.taskType \u003d event.getTaskType();\n     attemptInfo.shufflePort \u003d event.getShufflePort();\n     attemptInfo.containerId \u003d event.getContainerId();\n     \n     taskInfo.attemptsMap.put(attemptId, attemptInfo);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void handleTaskAttemptStartedEvent(TaskAttemptStartedEvent event) {\n    TaskAttemptID attemptId \u003d event.getTaskAttemptId();\n    TaskInfo taskInfo \u003d info.tasksMap.get(event.getTaskId());\n    \n    TaskAttemptInfo attemptInfo \u003d new TaskAttemptInfo();\n    attemptInfo.startTime \u003d event.getStartTime();\n    attemptInfo.attemptId \u003d event.getTaskAttemptId();\n    attemptInfo.httpPort \u003d event.getHttpPort();\n    attemptInfo.trackerName \u003d StringInterner.weakIntern(event.getTrackerName());\n    attemptInfo.taskType \u003d event.getTaskType();\n    attemptInfo.shufflePort \u003d event.getShufflePort();\n    attemptInfo.containerId \u003d event.getContainerId();\n    \n    taskInfo.attemptsMap.put(attemptId, attemptInfo);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java",
      "extendedDetails": {}
    },
    "13e4562924a6cb3d16c262e0f595b2ffbf9e0546": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3144. Augmented JobHistory with the information needed for serving aggregated logs. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1185976 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/10/11 10:21 PM",
      "commitName": "13e4562924a6cb3d16c262e0f595b2ffbf9e0546",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "12/10/11 4:12 PM",
      "commitNameOld": "277e520579a3452b95a5ffe2616d4f252d3c53fb",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 6.26,
      "commitsBetweenForRepo": 48,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,15 @@\n   private void handleTaskAttemptStartedEvent(TaskAttemptStartedEvent event) {\n     TaskAttemptID attemptId \u003d event.getTaskAttemptId();\n     TaskInfo taskInfo \u003d info.tasksMap.get(event.getTaskId());\n     \n     TaskAttemptInfo attemptInfo \u003d new TaskAttemptInfo();\n     attemptInfo.startTime \u003d event.getStartTime();\n     attemptInfo.attemptId \u003d event.getTaskAttemptId();\n     attemptInfo.httpPort \u003d event.getHttpPort();\n     attemptInfo.trackerName \u003d event.getTrackerName();\n     attemptInfo.taskType \u003d event.getTaskType();\n     attemptInfo.shufflePort \u003d event.getShufflePort();\n+    attemptInfo.containerId \u003d event.getContainerId();\n     \n     taskInfo.attemptsMap.put(attemptId, attemptInfo);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void handleTaskAttemptStartedEvent(TaskAttemptStartedEvent event) {\n    TaskAttemptID attemptId \u003d event.getTaskAttemptId();\n    TaskInfo taskInfo \u003d info.tasksMap.get(event.getTaskId());\n    \n    TaskAttemptInfo attemptInfo \u003d new TaskAttemptInfo();\n    attemptInfo.startTime \u003d event.getStartTime();\n    attemptInfo.attemptId \u003d event.getTaskAttemptId();\n    attemptInfo.httpPort \u003d event.getHttpPort();\n    attemptInfo.trackerName \u003d event.getTrackerName();\n    attemptInfo.taskType \u003d event.getTaskType();\n    attemptInfo.shufflePort \u003d event.getShufflePort();\n    attemptInfo.containerId \u003d event.getContainerId();\n    \n    taskInfo.attemptsMap.put(attemptId, attemptInfo);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java",
      "extendedDetails": {}
    },
    "277e520579a3452b95a5ffe2616d4f252d3c53fb": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2666. Retrieve shuffle port number from JobHistory on MR AM restart. Contributed by Jonathan Eagles. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1182613 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/10/11 4:12 PM",
      "commitName": "277e520579a3452b95a5ffe2616d4f252d3c53fb",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "29/09/11 11:47 PM",
      "commitNameOld": "964d4a1666441660957a028db33aad560decbe18",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 12.68,
      "commitsBetweenForRepo": 94,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,14 @@\n   private void handleTaskAttemptStartedEvent(TaskAttemptStartedEvent event) {\n     TaskAttemptID attemptId \u003d event.getTaskAttemptId();\n     TaskInfo taskInfo \u003d info.tasksMap.get(event.getTaskId());\n     \n     TaskAttemptInfo attemptInfo \u003d new TaskAttemptInfo();\n     attemptInfo.startTime \u003d event.getStartTime();\n     attemptInfo.attemptId \u003d event.getTaskAttemptId();\n     attemptInfo.httpPort \u003d event.getHttpPort();\n     attemptInfo.trackerName \u003d event.getTrackerName();\n     attemptInfo.taskType \u003d event.getTaskType();\n+    attemptInfo.shufflePort \u003d event.getShufflePort();\n     \n     taskInfo.attemptsMap.put(attemptId, attemptInfo);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void handleTaskAttemptStartedEvent(TaskAttemptStartedEvent event) {\n    TaskAttemptID attemptId \u003d event.getTaskAttemptId();\n    TaskInfo taskInfo \u003d info.tasksMap.get(event.getTaskId());\n    \n    TaskAttemptInfo attemptInfo \u003d new TaskAttemptInfo();\n    attemptInfo.startTime \u003d event.getStartTime();\n    attemptInfo.attemptId \u003d event.getTaskAttemptId();\n    attemptInfo.httpPort \u003d event.getHttpPort();\n    attemptInfo.trackerName \u003d event.getTrackerName();\n    attemptInfo.taskType \u003d event.getTaskType();\n    attemptInfo.shufflePort \u003d event.getShufflePort();\n    \n    taskInfo.attemptsMap.put(attemptId, attemptInfo);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void handleTaskAttemptStartedEvent(TaskAttemptStartedEvent event) {\n    TaskAttemptID attemptId \u003d event.getTaskAttemptId();\n    TaskInfo taskInfo \u003d info.tasksMap.get(event.getTaskId());\n    \n    TaskAttemptInfo attemptInfo \u003d new TaskAttemptInfo();\n    attemptInfo.startTime \u003d event.getStartTime();\n    attemptInfo.attemptId \u003d event.getTaskAttemptId();\n    attemptInfo.httpPort \u003d event.getHttpPort();\n    attemptInfo.trackerName \u003d event.getTrackerName();\n    attemptInfo.taskType \u003d event.getTaskType();\n    \n    taskInfo.attemptsMap.put(attemptId, attemptInfo);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private void handleTaskAttemptStartedEvent(TaskAttemptStartedEvent event) {\n    TaskAttemptID attemptId \u003d event.getTaskAttemptId();\n    TaskInfo taskInfo \u003d info.tasksMap.get(event.getTaskId());\n    \n    TaskAttemptInfo attemptInfo \u003d new TaskAttemptInfo();\n    attemptInfo.startTime \u003d event.getStartTime();\n    attemptInfo.attemptId \u003d event.getTaskAttemptId();\n    attemptInfo.httpPort \u003d event.getHttpPort();\n    attemptInfo.trackerName \u003d event.getTrackerName();\n    attemptInfo.taskType \u003d event.getTaskType();\n    \n    taskInfo.attemptsMap.put(attemptId, attemptInfo);\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java",
        "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,13 @@\n+  private void handleTaskAttemptStartedEvent(TaskAttemptStartedEvent event) {\n+    TaskAttemptID attemptId \u003d event.getTaskAttemptId();\n+    TaskInfo taskInfo \u003d info.tasksMap.get(event.getTaskId());\n+    \n+    TaskAttemptInfo attemptInfo \u003d new TaskAttemptInfo();\n+    attemptInfo.startTime \u003d event.getStartTime();\n+    attemptInfo.attemptId \u003d event.getTaskAttemptId();\n+    attemptInfo.httpPort \u003d event.getHttpPort();\n+    attemptInfo.trackerName \u003d event.getTrackerName();\n+    attemptInfo.taskType \u003d event.getTaskType();\n+    \n+    taskInfo.attemptsMap.put(attemptId, attemptInfo);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void handleTaskAttemptStartedEvent(TaskAttemptStartedEvent event) {\n    TaskAttemptID attemptId \u003d event.getTaskAttemptId();\n    TaskInfo taskInfo \u003d info.tasksMap.get(event.getTaskId());\n    \n    TaskAttemptInfo attemptInfo \u003d new TaskAttemptInfo();\n    attemptInfo.startTime \u003d event.getStartTime();\n    attemptInfo.attemptId \u003d event.getTaskAttemptId();\n    attemptInfo.httpPort \u003d event.getHttpPort();\n    attemptInfo.trackerName \u003d event.getTrackerName();\n    attemptInfo.taskType \u003d event.getTaskType();\n    \n    taskInfo.attemptsMap.put(attemptId, attemptInfo);\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryParser.java"
    }
  }
}