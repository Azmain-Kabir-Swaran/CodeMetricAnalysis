{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Submitter.java",
  "functionName": "run",
  "functionId": "run___args-String[]",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Submitter.java",
  "functionStartLine": 392,
  "functionEndLine": 511,
  "numCommitsSeen": 9,
  "timeTaken": 4425,
  "changeHistory": [
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yfilerename",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int run(String[] args) throws Exception {\n    CommandLineParser cli \u003d new CommandLineParser();\n    if (args.length \u003d\u003d 0) {\n      cli.printUsage();\n      return 1;\n    }\n    cli.addOption(\"input\", false, \"input path to the maps\", \"path\");\n    cli.addOption(\"output\", false, \"output path from the reduces\", \"path\");\n    \n    cli.addOption(\"jar\", false, \"job jar file\", \"path\");\n    cli.addOption(\"inputformat\", false, \"java classname of InputFormat\", \n                  \"class\");\n    //cli.addArgument(\"javareader\", false, \"is the RecordReader in Java\");\n    cli.addOption(\"map\", false, \"java classname of Mapper\", \"class\");\n    cli.addOption(\"partitioner\", false, \"java classname of Partitioner\", \n                  \"class\");\n    cli.addOption(\"reduce\", false, \"java classname of Reducer\", \"class\");\n    cli.addOption(\"writer\", false, \"java classname of OutputFormat\", \"class\");\n    cli.addOption(\"program\", false, \"URI to application executable\", \"class\");\n    cli.addOption(\"reduces\", false, \"number of reduces\", \"num\");\n    cli.addOption(\"jobconf\", false, \n        \"\\\"n1\u003dv1,n2\u003dv2,..\\\" (Deprecated) Optional. Add or override a JobConf property.\",\n        \"key\u003dval\");\n    cli.addOption(\"lazyOutput\", false, \"Optional. Create output lazily\",\n                  \"boolean\");\n    Parser parser \u003d cli.createParser();\n    try {\n      \n      GenericOptionsParser genericParser \u003d new GenericOptionsParser(getConf(), args);\n      CommandLine results \u003d parser.parse(cli.options, genericParser.getRemainingArgs());\n      \n      JobConf job \u003d new JobConf(getConf());\n      \n      if (results.hasOption(\"input\")) {\n        FileInputFormat.setInputPaths(job, results.getOptionValue(\"input\"));\n      }\n      if (results.hasOption(\"output\")) {\n        FileOutputFormat.setOutputPath(job, \n          new Path(results.getOptionValue(\"output\")));\n      }\n      if (results.hasOption(\"jar\")) {\n        job.setJar(results.getOptionValue(\"jar\"));\n      }\n      if (results.hasOption(\"inputformat\")) {\n        setIsJavaRecordReader(job, true);\n        job.setInputFormat(getClass(results, \"inputformat\", job,\n                                     InputFormat.class));\n      }\n      if (results.hasOption(\"javareader\")) {\n        setIsJavaRecordReader(job, true);\n      }\n      if (results.hasOption(\"map\")) {\n        setIsJavaMapper(job, true);\n        job.setMapperClass(getClass(results, \"map\", job, Mapper.class));\n      }\n      if (results.hasOption(\"partitioner\")) {\n        job.setPartitionerClass(getClass(results, \"partitioner\", job,\n                                          Partitioner.class));\n      }\n      if (results.hasOption(\"reduce\")) {\n        setIsJavaReducer(job, true);\n        job.setReducerClass(getClass(results, \"reduce\", job, Reducer.class));\n      }\n      if (results.hasOption(\"reduces\")) {\n        job.setNumReduceTasks(Integer.parseInt( \n                                           results.getOptionValue(\"reduces\")));\n      }\n      if (results.hasOption(\"writer\")) {\n        setIsJavaRecordWriter(job, true);\n        job.setOutputFormat(getClass(results, \"writer\", job, \n                                      OutputFormat.class));\n      }\n      \n      if (results.hasOption(\"lazyOutput\")) {\n        if (Boolean.parseBoolean(results.getOptionValue(\"lazyOutput\"))) {\n          LazyOutputFormat.setOutputFormatClass(job,\n              job.getOutputFormat().getClass());\n        }\n      }\n      \n      if (results.hasOption(\"program\")) {\n        setExecutable(job, results.getOptionValue(\"program\"));\n      }\n      if (results.hasOption(\"jobconf\")) {\n        LOG.warn(\"-jobconf option is deprecated, please use -D instead.\");\n        String options \u003d results.getOptionValue(\"jobconf\");\n        StringTokenizer tokenizer \u003d new StringTokenizer(options, \",\");\n        while (tokenizer.hasMoreTokens()) {\n          String keyVal \u003d tokenizer.nextToken().trim();\n          String[] keyValSplit \u003d keyVal.split(\"\u003d\");\n          job.set(keyValSplit[0], keyValSplit[1]);\n        }\n      }\n      // if they gave us a jar file, include it into the class path\n      String jarFile \u003d job.getJar();\n      if (jarFile !\u003d null) {\n        final URL[] urls \u003d new URL[]{ FileSystem.getLocal(job).\n            pathToFile(new Path(jarFile)).toURL()};\n        //FindBugs complains that creating a URLClassLoader should be\n        //in a doPrivileged() block. \n        ClassLoader loader \u003d\n          AccessController.doPrivileged(\n              new PrivilegedAction\u003cClassLoader\u003e() {\n                public ClassLoader run() {\n                  return new URLClassLoader(urls);\n                }\n              }\n            );\n        job.setClassLoader(loader);\n      }\n      \n      runJob(job);\n      return 0;\n    } catch (ParseException pe) {\n      LOG.info(\"Error : \" + pe);\n      cli.printUsage();\n      return 1;\n    }\n    \n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Submitter.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Submitter.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Submitter.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "17/08/11 8:02 PM",
      "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.34,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int run(String[] args) throws Exception {\n    CommandLineParser cli \u003d new CommandLineParser();\n    if (args.length \u003d\u003d 0) {\n      cli.printUsage();\n      return 1;\n    }\n    cli.addOption(\"input\", false, \"input path to the maps\", \"path\");\n    cli.addOption(\"output\", false, \"output path from the reduces\", \"path\");\n    \n    cli.addOption(\"jar\", false, \"job jar file\", \"path\");\n    cli.addOption(\"inputformat\", false, \"java classname of InputFormat\", \n                  \"class\");\n    //cli.addArgument(\"javareader\", false, \"is the RecordReader in Java\");\n    cli.addOption(\"map\", false, \"java classname of Mapper\", \"class\");\n    cli.addOption(\"partitioner\", false, \"java classname of Partitioner\", \n                  \"class\");\n    cli.addOption(\"reduce\", false, \"java classname of Reducer\", \"class\");\n    cli.addOption(\"writer\", false, \"java classname of OutputFormat\", \"class\");\n    cli.addOption(\"program\", false, \"URI to application executable\", \"class\");\n    cli.addOption(\"reduces\", false, \"number of reduces\", \"num\");\n    cli.addOption(\"jobconf\", false, \n        \"\\\"n1\u003dv1,n2\u003dv2,..\\\" (Deprecated) Optional. Add or override a JobConf property.\",\n        \"key\u003dval\");\n    cli.addOption(\"lazyOutput\", false, \"Optional. Create output lazily\",\n                  \"boolean\");\n    Parser parser \u003d cli.createParser();\n    try {\n      \n      GenericOptionsParser genericParser \u003d new GenericOptionsParser(getConf(), args);\n      CommandLine results \u003d parser.parse(cli.options, genericParser.getRemainingArgs());\n      \n      JobConf job \u003d new JobConf(getConf());\n      \n      if (results.hasOption(\"input\")) {\n        FileInputFormat.setInputPaths(job, results.getOptionValue(\"input\"));\n      }\n      if (results.hasOption(\"output\")) {\n        FileOutputFormat.setOutputPath(job, \n          new Path(results.getOptionValue(\"output\")));\n      }\n      if (results.hasOption(\"jar\")) {\n        job.setJar(results.getOptionValue(\"jar\"));\n      }\n      if (results.hasOption(\"inputformat\")) {\n        setIsJavaRecordReader(job, true);\n        job.setInputFormat(getClass(results, \"inputformat\", job,\n                                     InputFormat.class));\n      }\n      if (results.hasOption(\"javareader\")) {\n        setIsJavaRecordReader(job, true);\n      }\n      if (results.hasOption(\"map\")) {\n        setIsJavaMapper(job, true);\n        job.setMapperClass(getClass(results, \"map\", job, Mapper.class));\n      }\n      if (results.hasOption(\"partitioner\")) {\n        job.setPartitionerClass(getClass(results, \"partitioner\", job,\n                                          Partitioner.class));\n      }\n      if (results.hasOption(\"reduce\")) {\n        setIsJavaReducer(job, true);\n        job.setReducerClass(getClass(results, \"reduce\", job, Reducer.class));\n      }\n      if (results.hasOption(\"reduces\")) {\n        job.setNumReduceTasks(Integer.parseInt( \n                                           results.getOptionValue(\"reduces\")));\n      }\n      if (results.hasOption(\"writer\")) {\n        setIsJavaRecordWriter(job, true);\n        job.setOutputFormat(getClass(results, \"writer\", job, \n                                      OutputFormat.class));\n      }\n      \n      if (results.hasOption(\"lazyOutput\")) {\n        if (Boolean.parseBoolean(results.getOptionValue(\"lazyOutput\"))) {\n          LazyOutputFormat.setOutputFormatClass(job,\n              job.getOutputFormat().getClass());\n        }\n      }\n      \n      if (results.hasOption(\"program\")) {\n        setExecutable(job, results.getOptionValue(\"program\"));\n      }\n      if (results.hasOption(\"jobconf\")) {\n        LOG.warn(\"-jobconf option is deprecated, please use -D instead.\");\n        String options \u003d results.getOptionValue(\"jobconf\");\n        StringTokenizer tokenizer \u003d new StringTokenizer(options, \",\");\n        while (tokenizer.hasMoreTokens()) {\n          String keyVal \u003d tokenizer.nextToken().trim();\n          String[] keyValSplit \u003d keyVal.split(\"\u003d\");\n          job.set(keyValSplit[0], keyValSplit[1]);\n        }\n      }\n      // if they gave us a jar file, include it into the class path\n      String jarFile \u003d job.getJar();\n      if (jarFile !\u003d null) {\n        final URL[] urls \u003d new URL[]{ FileSystem.getLocal(job).\n            pathToFile(new Path(jarFile)).toURL()};\n        //FindBugs complains that creating a URLClassLoader should be\n        //in a doPrivileged() block. \n        ClassLoader loader \u003d\n          AccessController.doPrivileged(\n              new PrivilegedAction\u003cClassLoader\u003e() {\n                public ClassLoader run() {\n                  return new URLClassLoader(urls);\n                }\n              }\n            );\n        job.setClassLoader(loader);\n      }\n      \n      runJob(job);\n      return 0;\n    } catch (ParseException pe) {\n      LOG.info(\"Error : \" + pe);\n      cli.printUsage();\n      return 1;\n    }\n    \n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Submitter.java",
      "extendedDetails": {
        "oldPath": "mapreduce/src/java/org/apache/hadoop/mapred/pipes/Submitter.java",
        "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/pipes/Submitter.java"
      }
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,120 @@\n+  public int run(String[] args) throws Exception {\n+    CommandLineParser cli \u003d new CommandLineParser();\n+    if (args.length \u003d\u003d 0) {\n+      cli.printUsage();\n+      return 1;\n+    }\n+    cli.addOption(\"input\", false, \"input path to the maps\", \"path\");\n+    cli.addOption(\"output\", false, \"output path from the reduces\", \"path\");\n+    \n+    cli.addOption(\"jar\", false, \"job jar file\", \"path\");\n+    cli.addOption(\"inputformat\", false, \"java classname of InputFormat\", \n+                  \"class\");\n+    //cli.addArgument(\"javareader\", false, \"is the RecordReader in Java\");\n+    cli.addOption(\"map\", false, \"java classname of Mapper\", \"class\");\n+    cli.addOption(\"partitioner\", false, \"java classname of Partitioner\", \n+                  \"class\");\n+    cli.addOption(\"reduce\", false, \"java classname of Reducer\", \"class\");\n+    cli.addOption(\"writer\", false, \"java classname of OutputFormat\", \"class\");\n+    cli.addOption(\"program\", false, \"URI to application executable\", \"class\");\n+    cli.addOption(\"reduces\", false, \"number of reduces\", \"num\");\n+    cli.addOption(\"jobconf\", false, \n+        \"\\\"n1\u003dv1,n2\u003dv2,..\\\" (Deprecated) Optional. Add or override a JobConf property.\",\n+        \"key\u003dval\");\n+    cli.addOption(\"lazyOutput\", false, \"Optional. Create output lazily\",\n+                  \"boolean\");\n+    Parser parser \u003d cli.createParser();\n+    try {\n+      \n+      GenericOptionsParser genericParser \u003d new GenericOptionsParser(getConf(), args);\n+      CommandLine results \u003d parser.parse(cli.options, genericParser.getRemainingArgs());\n+      \n+      JobConf job \u003d new JobConf(getConf());\n+      \n+      if (results.hasOption(\"input\")) {\n+        FileInputFormat.setInputPaths(job, results.getOptionValue(\"input\"));\n+      }\n+      if (results.hasOption(\"output\")) {\n+        FileOutputFormat.setOutputPath(job, \n+          new Path(results.getOptionValue(\"output\")));\n+      }\n+      if (results.hasOption(\"jar\")) {\n+        job.setJar(results.getOptionValue(\"jar\"));\n+      }\n+      if (results.hasOption(\"inputformat\")) {\n+        setIsJavaRecordReader(job, true);\n+        job.setInputFormat(getClass(results, \"inputformat\", job,\n+                                     InputFormat.class));\n+      }\n+      if (results.hasOption(\"javareader\")) {\n+        setIsJavaRecordReader(job, true);\n+      }\n+      if (results.hasOption(\"map\")) {\n+        setIsJavaMapper(job, true);\n+        job.setMapperClass(getClass(results, \"map\", job, Mapper.class));\n+      }\n+      if (results.hasOption(\"partitioner\")) {\n+        job.setPartitionerClass(getClass(results, \"partitioner\", job,\n+                                          Partitioner.class));\n+      }\n+      if (results.hasOption(\"reduce\")) {\n+        setIsJavaReducer(job, true);\n+        job.setReducerClass(getClass(results, \"reduce\", job, Reducer.class));\n+      }\n+      if (results.hasOption(\"reduces\")) {\n+        job.setNumReduceTasks(Integer.parseInt( \n+                                           results.getOptionValue(\"reduces\")));\n+      }\n+      if (results.hasOption(\"writer\")) {\n+        setIsJavaRecordWriter(job, true);\n+        job.setOutputFormat(getClass(results, \"writer\", job, \n+                                      OutputFormat.class));\n+      }\n+      \n+      if (results.hasOption(\"lazyOutput\")) {\n+        if (Boolean.parseBoolean(results.getOptionValue(\"lazyOutput\"))) {\n+          LazyOutputFormat.setOutputFormatClass(job,\n+              job.getOutputFormat().getClass());\n+        }\n+      }\n+      \n+      if (results.hasOption(\"program\")) {\n+        setExecutable(job, results.getOptionValue(\"program\"));\n+      }\n+      if (results.hasOption(\"jobconf\")) {\n+        LOG.warn(\"-jobconf option is deprecated, please use -D instead.\");\n+        String options \u003d results.getOptionValue(\"jobconf\");\n+        StringTokenizer tokenizer \u003d new StringTokenizer(options, \",\");\n+        while (tokenizer.hasMoreTokens()) {\n+          String keyVal \u003d tokenizer.nextToken().trim();\n+          String[] keyValSplit \u003d keyVal.split(\"\u003d\");\n+          job.set(keyValSplit[0], keyValSplit[1]);\n+        }\n+      }\n+      // if they gave us a jar file, include it into the class path\n+      String jarFile \u003d job.getJar();\n+      if (jarFile !\u003d null) {\n+        final URL[] urls \u003d new URL[]{ FileSystem.getLocal(job).\n+            pathToFile(new Path(jarFile)).toURL()};\n+        //FindBugs complains that creating a URLClassLoader should be\n+        //in a doPrivileged() block. \n+        ClassLoader loader \u003d\n+          AccessController.doPrivileged(\n+              new PrivilegedAction\u003cClassLoader\u003e() {\n+                public ClassLoader run() {\n+                  return new URLClassLoader(urls);\n+                }\n+              }\n+            );\n+        job.setClassLoader(loader);\n+      }\n+      \n+      runJob(job);\n+      return 0;\n+    } catch (ParseException pe) {\n+      LOG.info(\"Error : \" + pe);\n+      cli.printUsage();\n+      return 1;\n+    }\n+    \n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public int run(String[] args) throws Exception {\n    CommandLineParser cli \u003d new CommandLineParser();\n    if (args.length \u003d\u003d 0) {\n      cli.printUsage();\n      return 1;\n    }\n    cli.addOption(\"input\", false, \"input path to the maps\", \"path\");\n    cli.addOption(\"output\", false, \"output path from the reduces\", \"path\");\n    \n    cli.addOption(\"jar\", false, \"job jar file\", \"path\");\n    cli.addOption(\"inputformat\", false, \"java classname of InputFormat\", \n                  \"class\");\n    //cli.addArgument(\"javareader\", false, \"is the RecordReader in Java\");\n    cli.addOption(\"map\", false, \"java classname of Mapper\", \"class\");\n    cli.addOption(\"partitioner\", false, \"java classname of Partitioner\", \n                  \"class\");\n    cli.addOption(\"reduce\", false, \"java classname of Reducer\", \"class\");\n    cli.addOption(\"writer\", false, \"java classname of OutputFormat\", \"class\");\n    cli.addOption(\"program\", false, \"URI to application executable\", \"class\");\n    cli.addOption(\"reduces\", false, \"number of reduces\", \"num\");\n    cli.addOption(\"jobconf\", false, \n        \"\\\"n1\u003dv1,n2\u003dv2,..\\\" (Deprecated) Optional. Add or override a JobConf property.\",\n        \"key\u003dval\");\n    cli.addOption(\"lazyOutput\", false, \"Optional. Create output lazily\",\n                  \"boolean\");\n    Parser parser \u003d cli.createParser();\n    try {\n      \n      GenericOptionsParser genericParser \u003d new GenericOptionsParser(getConf(), args);\n      CommandLine results \u003d parser.parse(cli.options, genericParser.getRemainingArgs());\n      \n      JobConf job \u003d new JobConf(getConf());\n      \n      if (results.hasOption(\"input\")) {\n        FileInputFormat.setInputPaths(job, results.getOptionValue(\"input\"));\n      }\n      if (results.hasOption(\"output\")) {\n        FileOutputFormat.setOutputPath(job, \n          new Path(results.getOptionValue(\"output\")));\n      }\n      if (results.hasOption(\"jar\")) {\n        job.setJar(results.getOptionValue(\"jar\"));\n      }\n      if (results.hasOption(\"inputformat\")) {\n        setIsJavaRecordReader(job, true);\n        job.setInputFormat(getClass(results, \"inputformat\", job,\n                                     InputFormat.class));\n      }\n      if (results.hasOption(\"javareader\")) {\n        setIsJavaRecordReader(job, true);\n      }\n      if (results.hasOption(\"map\")) {\n        setIsJavaMapper(job, true);\n        job.setMapperClass(getClass(results, \"map\", job, Mapper.class));\n      }\n      if (results.hasOption(\"partitioner\")) {\n        job.setPartitionerClass(getClass(results, \"partitioner\", job,\n                                          Partitioner.class));\n      }\n      if (results.hasOption(\"reduce\")) {\n        setIsJavaReducer(job, true);\n        job.setReducerClass(getClass(results, \"reduce\", job, Reducer.class));\n      }\n      if (results.hasOption(\"reduces\")) {\n        job.setNumReduceTasks(Integer.parseInt( \n                                           results.getOptionValue(\"reduces\")));\n      }\n      if (results.hasOption(\"writer\")) {\n        setIsJavaRecordWriter(job, true);\n        job.setOutputFormat(getClass(results, \"writer\", job, \n                                      OutputFormat.class));\n      }\n      \n      if (results.hasOption(\"lazyOutput\")) {\n        if (Boolean.parseBoolean(results.getOptionValue(\"lazyOutput\"))) {\n          LazyOutputFormat.setOutputFormatClass(job,\n              job.getOutputFormat().getClass());\n        }\n      }\n      \n      if (results.hasOption(\"program\")) {\n        setExecutable(job, results.getOptionValue(\"program\"));\n      }\n      if (results.hasOption(\"jobconf\")) {\n        LOG.warn(\"-jobconf option is deprecated, please use -D instead.\");\n        String options \u003d results.getOptionValue(\"jobconf\");\n        StringTokenizer tokenizer \u003d new StringTokenizer(options, \",\");\n        while (tokenizer.hasMoreTokens()) {\n          String keyVal \u003d tokenizer.nextToken().trim();\n          String[] keyValSplit \u003d keyVal.split(\"\u003d\");\n          job.set(keyValSplit[0], keyValSplit[1]);\n        }\n      }\n      // if they gave us a jar file, include it into the class path\n      String jarFile \u003d job.getJar();\n      if (jarFile !\u003d null) {\n        final URL[] urls \u003d new URL[]{ FileSystem.getLocal(job).\n            pathToFile(new Path(jarFile)).toURL()};\n        //FindBugs complains that creating a URLClassLoader should be\n        //in a doPrivileged() block. \n        ClassLoader loader \u003d\n          AccessController.doPrivileged(\n              new PrivilegedAction\u003cClassLoader\u003e() {\n                public ClassLoader run() {\n                  return new URLClassLoader(urls);\n                }\n              }\n            );\n        job.setClassLoader(loader);\n      }\n      \n      runJob(job);\n      return 0;\n    } catch (ParseException pe) {\n      LOG.info(\"Error : \" + pe);\n      cli.printUsage();\n      return 1;\n    }\n    \n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapred/pipes/Submitter.java"
    }
  }
}