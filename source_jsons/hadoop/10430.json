{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FileIoProvider.java",
  "functionName": "getShareDeleteFileInputStream",
  "functionId": "getShareDeleteFileInputStream___volume-FsVolumeSpi(annotations-@Nullable)__f-File__offset-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/FileIoProvider.java",
  "functionStartLine": 418,
  "functionEndLine": 434,
  "numCommitsSeen": 42,
  "timeTaken": 5955,
  "changeHistory": [
    "4046794a5365f80f9fa002e3889e41c6d29e13a8",
    "603f3ef1386048111940b66f3a0750ab84d0588f",
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
    "638801cce16fc1dc3259c541dc30a599faaddda1"
  ],
  "changeHistoryShort": {
    "4046794a5365f80f9fa002e3889e41c6d29e13a8": "Ybodychange",
    "603f3ef1386048111940b66f3a0750ab84d0588f": "Ybodychange",
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yparameterchange)",
    "638801cce16fc1dc3259c541dc30a599faaddda1": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4046794a5365f80f9fa002e3889e41c6d29e13a8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11299. Support multiple Datanode File IO hooks. Contributed by Hanisha Koneru.\n",
      "commitDate": "10/01/17 10:43 AM",
      "commitName": "4046794a5365f80f9fa002e3889e41c6d29e13a8",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "28/12/16 10:08 PM",
      "commitNameOld": "603f3ef1386048111940b66f3a0750ab84d0588f",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 12.52,
      "commitsBetweenForRepo": 54,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,17 @@\n   public FileInputStream getShareDeleteFileInputStream(\n       @Nullable FsVolumeSpi volume, File f,\n       long offset) throws IOException {\n-    final long begin \u003d eventHooks.beforeMetadataOp(volume, OPEN);\n+    final long begin \u003d profilingEventHook.beforeMetadataOp(volume, OPEN);\n     FileInputStream fis \u003d null;\n     try {\n+      faultInjectorEventHook.beforeMetadataOp(volume, OPEN);\n       fis \u003d new WrappedFileInputStream(volume,\n           NativeIO.getShareDeleteFileDescriptor(f, offset));\n-      eventHooks.afterMetadataOp(volume, OPEN, begin);\n+      profilingEventHook.afterMetadataOp(volume, OPEN, begin);\n       return fis;\n     } catch(Exception e) {\n       org.apache.commons.io.IOUtils.closeQuietly(fis);\n-      eventHooks.onFailure(datanode, volume, OPEN, e, begin);\n+      onFailure(volume, begin);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public FileInputStream getShareDeleteFileInputStream(\n      @Nullable FsVolumeSpi volume, File f,\n      long offset) throws IOException {\n    final long begin \u003d profilingEventHook.beforeMetadataOp(volume, OPEN);\n    FileInputStream fis \u003d null;\n    try {\n      faultInjectorEventHook.beforeMetadataOp(volume, OPEN);\n      fis \u003d new WrappedFileInputStream(volume,\n          NativeIO.getShareDeleteFileDescriptor(f, offset));\n      profilingEventHook.afterMetadataOp(volume, OPEN, begin);\n      return fis;\n    } catch(Exception e) {\n      org.apache.commons.io.IOUtils.closeQuietly(fis);\n      onFailure(volume, begin);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/FileIoProvider.java",
      "extendedDetails": {}
    },
    "603f3ef1386048111940b66f3a0750ab84d0588f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11274. Datanode should only check the failed volume upon IO errors. Contributed by Xiaoyu Yao.\n",
      "commitDate": "28/12/16 10:08 PM",
      "commitName": "603f3ef1386048111940b66f3a0750ab84d0588f",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "14/12/16 11:18 AM",
      "commitNameOld": "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 14.45,
      "commitsBetweenForRepo": 60,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n   public FileInputStream getShareDeleteFileInputStream(\n       @Nullable FsVolumeSpi volume, File f,\n       long offset) throws IOException {\n     final long begin \u003d eventHooks.beforeMetadataOp(volume, OPEN);\n     FileInputStream fis \u003d null;\n     try {\n       fis \u003d new WrappedFileInputStream(volume,\n           NativeIO.getShareDeleteFileDescriptor(f, offset));\n       eventHooks.afterMetadataOp(volume, OPEN, begin);\n       return fis;\n     } catch(Exception e) {\n       org.apache.commons.io.IOUtils.closeQuietly(fis);\n-      eventHooks.onFailure(volume, OPEN, e, begin);\n+      eventHooks.onFailure(datanode, volume, OPEN, e, begin);\n       throw e;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public FileInputStream getShareDeleteFileInputStream(\n      @Nullable FsVolumeSpi volume, File f,\n      long offset) throws IOException {\n    final long begin \u003d eventHooks.beforeMetadataOp(volume, OPEN);\n    FileInputStream fis \u003d null;\n    try {\n      fis \u003d new WrappedFileInputStream(volume,\n          NativeIO.getShareDeleteFileDescriptor(f, offset));\n      eventHooks.afterMetadataOp(volume, OPEN, begin);\n      return fis;\n    } catch(Exception e) {\n      org.apache.commons.io.IOUtils.closeQuietly(fis);\n      eventHooks.onFailure(datanode, volume, OPEN, e, begin);\n      throw e;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/FileIoProvider.java",
      "extendedDetails": {}
    },
    "6ba9587d370fbf39c129c08c00ebbb894ccc1389": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yparameterchange)",
      "commitMessage": "HDFS-10958. Add instrumentation hooks around Datanode disk IO.\n",
      "commitDate": "14/12/16 11:18 AM",
      "commitName": "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
      "commitAuthor": "Arpit Agarwal",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-10958. Add instrumentation hooks around Datanode disk IO.\n",
          "commitDate": "14/12/16 11:18 AM",
          "commitName": "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "14/12/16 1:50 AM",
          "commitNameOld": "72bff192cd37ff97442e0f8dd477fbc2e58fc12d",
          "commitAuthorOld": "Akira Ajisaka",
          "daysBetweenCommits": 0.39,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,16 @@\n-  public static FileInputStream getShareDeleteFileInputStream(File f)\n-      throws IOException {\n-    if (!Shell.WINDOWS) {\n-      // On Linux the default FileInputStream shares delete permission\n-      // on the file opened.\n-      //\n-      return new FileInputStream(f);\n-    } else {\n-      // Use Windows native interface to create a FileInputStream that\n-      // shares delete permission on the file opened.\n-      //\n-      FileDescriptor fd \u003d Windows.createFile(\n-          f.getAbsolutePath(),\n-          Windows.GENERIC_READ,\n-          Windows.FILE_SHARE_READ |\n-              Windows.FILE_SHARE_WRITE |\n-              Windows.FILE_SHARE_DELETE,\n-          Windows.OPEN_EXISTING);\n-      return new FileInputStream(fd);\n+  public FileInputStream getShareDeleteFileInputStream(\n+      @Nullable FsVolumeSpi volume, File f,\n+      long offset) throws IOException {\n+    final long begin \u003d eventHooks.beforeMetadataOp(volume, OPEN);\n+    FileInputStream fis \u003d null;\n+    try {\n+      fis \u003d new WrappedFileInputStream(volume,\n+          NativeIO.getShareDeleteFileDescriptor(f, offset));\n+      eventHooks.afterMetadataOp(volume, OPEN, begin);\n+      return fis;\n+    } catch(Exception e) {\n+      org.apache.commons.io.IOUtils.closeQuietly(fis);\n+      eventHooks.onFailure(volume, OPEN, e, begin);\n+      throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public FileInputStream getShareDeleteFileInputStream(\n      @Nullable FsVolumeSpi volume, File f,\n      long offset) throws IOException {\n    final long begin \u003d eventHooks.beforeMetadataOp(volume, OPEN);\n    FileInputStream fis \u003d null;\n    try {\n      fis \u003d new WrappedFileInputStream(volume,\n          NativeIO.getShareDeleteFileDescriptor(f, offset));\n      eventHooks.afterMetadataOp(volume, OPEN, begin);\n      return fis;\n    } catch(Exception e) {\n      org.apache.commons.io.IOUtils.closeQuietly(fis);\n      eventHooks.onFailure(volume, OPEN, e, begin);\n      throw e;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/FileIoProvider.java",
          "extendedDetails": {
            "oldPath": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/nativeio/NativeIO.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/FileIoProvider.java",
            "oldMethodName": "getShareDeleteFileInputStream",
            "newMethodName": "getShareDeleteFileInputStream"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-10958. Add instrumentation hooks around Datanode disk IO.\n",
          "commitDate": "14/12/16 11:18 AM",
          "commitName": "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "14/12/16 1:50 AM",
          "commitNameOld": "72bff192cd37ff97442e0f8dd477fbc2e58fc12d",
          "commitAuthorOld": "Akira Ajisaka",
          "daysBetweenCommits": 0.39,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,16 @@\n-  public static FileInputStream getShareDeleteFileInputStream(File f)\n-      throws IOException {\n-    if (!Shell.WINDOWS) {\n-      // On Linux the default FileInputStream shares delete permission\n-      // on the file opened.\n-      //\n-      return new FileInputStream(f);\n-    } else {\n-      // Use Windows native interface to create a FileInputStream that\n-      // shares delete permission on the file opened.\n-      //\n-      FileDescriptor fd \u003d Windows.createFile(\n-          f.getAbsolutePath(),\n-          Windows.GENERIC_READ,\n-          Windows.FILE_SHARE_READ |\n-              Windows.FILE_SHARE_WRITE |\n-              Windows.FILE_SHARE_DELETE,\n-          Windows.OPEN_EXISTING);\n-      return new FileInputStream(fd);\n+  public FileInputStream getShareDeleteFileInputStream(\n+      @Nullable FsVolumeSpi volume, File f,\n+      long offset) throws IOException {\n+    final long begin \u003d eventHooks.beforeMetadataOp(volume, OPEN);\n+    FileInputStream fis \u003d null;\n+    try {\n+      fis \u003d new WrappedFileInputStream(volume,\n+          NativeIO.getShareDeleteFileDescriptor(f, offset));\n+      eventHooks.afterMetadataOp(volume, OPEN, begin);\n+      return fis;\n+    } catch(Exception e) {\n+      org.apache.commons.io.IOUtils.closeQuietly(fis);\n+      eventHooks.onFailure(volume, OPEN, e, begin);\n+      throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public FileInputStream getShareDeleteFileInputStream(\n      @Nullable FsVolumeSpi volume, File f,\n      long offset) throws IOException {\n    final long begin \u003d eventHooks.beforeMetadataOp(volume, OPEN);\n    FileInputStream fis \u003d null;\n    try {\n      fis \u003d new WrappedFileInputStream(volume,\n          NativeIO.getShareDeleteFileDescriptor(f, offset));\n      eventHooks.afterMetadataOp(volume, OPEN, begin);\n      return fis;\n    } catch(Exception e) {\n      org.apache.commons.io.IOUtils.closeQuietly(fis);\n      eventHooks.onFailure(volume, OPEN, e, begin);\n      throw e;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/FileIoProvider.java",
          "extendedDetails": {
            "oldValue": "[public, static]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10958. Add instrumentation hooks around Datanode disk IO.\n",
          "commitDate": "14/12/16 11:18 AM",
          "commitName": "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "14/12/16 1:50 AM",
          "commitNameOld": "72bff192cd37ff97442e0f8dd477fbc2e58fc12d",
          "commitAuthorOld": "Akira Ajisaka",
          "daysBetweenCommits": 0.39,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,16 @@\n-  public static FileInputStream getShareDeleteFileInputStream(File f)\n-      throws IOException {\n-    if (!Shell.WINDOWS) {\n-      // On Linux the default FileInputStream shares delete permission\n-      // on the file opened.\n-      //\n-      return new FileInputStream(f);\n-    } else {\n-      // Use Windows native interface to create a FileInputStream that\n-      // shares delete permission on the file opened.\n-      //\n-      FileDescriptor fd \u003d Windows.createFile(\n-          f.getAbsolutePath(),\n-          Windows.GENERIC_READ,\n-          Windows.FILE_SHARE_READ |\n-              Windows.FILE_SHARE_WRITE |\n-              Windows.FILE_SHARE_DELETE,\n-          Windows.OPEN_EXISTING);\n-      return new FileInputStream(fd);\n+  public FileInputStream getShareDeleteFileInputStream(\n+      @Nullable FsVolumeSpi volume, File f,\n+      long offset) throws IOException {\n+    final long begin \u003d eventHooks.beforeMetadataOp(volume, OPEN);\n+    FileInputStream fis \u003d null;\n+    try {\n+      fis \u003d new WrappedFileInputStream(volume,\n+          NativeIO.getShareDeleteFileDescriptor(f, offset));\n+      eventHooks.afterMetadataOp(volume, OPEN, begin);\n+      return fis;\n+    } catch(Exception e) {\n+      org.apache.commons.io.IOUtils.closeQuietly(fis);\n+      eventHooks.onFailure(volume, OPEN, e, begin);\n+      throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public FileInputStream getShareDeleteFileInputStream(\n      @Nullable FsVolumeSpi volume, File f,\n      long offset) throws IOException {\n    final long begin \u003d eventHooks.beforeMetadataOp(volume, OPEN);\n    FileInputStream fis \u003d null;\n    try {\n      fis \u003d new WrappedFileInputStream(volume,\n          NativeIO.getShareDeleteFileDescriptor(f, offset));\n      eventHooks.afterMetadataOp(volume, OPEN, begin);\n      return fis;\n    } catch(Exception e) {\n      org.apache.commons.io.IOUtils.closeQuietly(fis);\n      eventHooks.onFailure(volume, OPEN, e, begin);\n      throw e;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/FileIoProvider.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-10958. Add instrumentation hooks around Datanode disk IO.\n",
          "commitDate": "14/12/16 11:18 AM",
          "commitName": "6ba9587d370fbf39c129c08c00ebbb894ccc1389",
          "commitAuthor": "Arpit Agarwal",
          "commitDateOld": "14/12/16 1:50 AM",
          "commitNameOld": "72bff192cd37ff97442e0f8dd477fbc2e58fc12d",
          "commitAuthorOld": "Akira Ajisaka",
          "daysBetweenCommits": 0.39,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,16 @@\n-  public static FileInputStream getShareDeleteFileInputStream(File f)\n-      throws IOException {\n-    if (!Shell.WINDOWS) {\n-      // On Linux the default FileInputStream shares delete permission\n-      // on the file opened.\n-      //\n-      return new FileInputStream(f);\n-    } else {\n-      // Use Windows native interface to create a FileInputStream that\n-      // shares delete permission on the file opened.\n-      //\n-      FileDescriptor fd \u003d Windows.createFile(\n-          f.getAbsolutePath(),\n-          Windows.GENERIC_READ,\n-          Windows.FILE_SHARE_READ |\n-              Windows.FILE_SHARE_WRITE |\n-              Windows.FILE_SHARE_DELETE,\n-          Windows.OPEN_EXISTING);\n-      return new FileInputStream(fd);\n+  public FileInputStream getShareDeleteFileInputStream(\n+      @Nullable FsVolumeSpi volume, File f,\n+      long offset) throws IOException {\n+    final long begin \u003d eventHooks.beforeMetadataOp(volume, OPEN);\n+    FileInputStream fis \u003d null;\n+    try {\n+      fis \u003d new WrappedFileInputStream(volume,\n+          NativeIO.getShareDeleteFileDescriptor(f, offset));\n+      eventHooks.afterMetadataOp(volume, OPEN, begin);\n+      return fis;\n+    } catch(Exception e) {\n+      org.apache.commons.io.IOUtils.closeQuietly(fis);\n+      eventHooks.onFailure(volume, OPEN, e, begin);\n+      throw e;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public FileInputStream getShareDeleteFileInputStream(\n      @Nullable FsVolumeSpi volume, File f,\n      long offset) throws IOException {\n    final long begin \u003d eventHooks.beforeMetadataOp(volume, OPEN);\n    FileInputStream fis \u003d null;\n    try {\n      fis \u003d new WrappedFileInputStream(volume,\n          NativeIO.getShareDeleteFileDescriptor(f, offset));\n      eventHooks.afterMetadataOp(volume, OPEN, begin);\n      return fis;\n    } catch(Exception e) {\n      org.apache.commons.io.IOUtils.closeQuietly(fis);\n      eventHooks.onFailure(volume, OPEN, e, begin);\n      throw e;\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/FileIoProvider.java",
          "extendedDetails": {
            "oldValue": "[f-File]",
            "newValue": "[volume-FsVolumeSpi(annotations-@Nullable), f-File, offset-long]"
          }
        }
      ]
    },
    "638801cce16fc1dc3259c541dc30a599faaddda1": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-8952. Enhancements to support Hadoop on Windows Server and Windows Azure environments. Contributed by Ivan Mitic, Chuan Liu, Ramya Sunil, Bikas Saha, Kanna Karanam, John Gordon, Brandon Li, Chris Nauroth, David Lao, Sumadhur Reddy Bolli, Arpit Agarwal, Ahmed El Baz, Mike Liddell, Jing Zhao, Thejas Nair, Steve Maine, Ganeshan Iyer, Raja Aluri, Giridharan Kesavan, Ramya Bharathi Nimmagadda.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1453486 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/03/13 11:15 AM",
      "commitName": "638801cce16fc1dc3259c541dc30a599faaddda1",
      "commitAuthor": "Suresh Srinivas",
      "diff": "@@ -0,0 +1,21 @@\n+  public static FileInputStream getShareDeleteFileInputStream(File f)\n+      throws IOException {\n+    if (!Shell.WINDOWS) {\n+      // On Linux the default FileInputStream shares delete permission\n+      // on the file opened.\n+      //\n+      return new FileInputStream(f);\n+    } else {\n+      // Use Windows native interface to create a FileInputStream that\n+      // shares delete permission on the file opened.\n+      //\n+      FileDescriptor fd \u003d Windows.createFile(\n+          f.getAbsolutePath(),\n+          Windows.GENERIC_READ,\n+          Windows.FILE_SHARE_READ |\n+              Windows.FILE_SHARE_WRITE |\n+              Windows.FILE_SHARE_DELETE,\n+          Windows.OPEN_EXISTING);\n+      return new FileInputStream(fd);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static FileInputStream getShareDeleteFileInputStream(File f)\n      throws IOException {\n    if (!Shell.WINDOWS) {\n      // On Linux the default FileInputStream shares delete permission\n      // on the file opened.\n      //\n      return new FileInputStream(f);\n    } else {\n      // Use Windows native interface to create a FileInputStream that\n      // shares delete permission on the file opened.\n      //\n      FileDescriptor fd \u003d Windows.createFile(\n          f.getAbsolutePath(),\n          Windows.GENERIC_READ,\n          Windows.FILE_SHARE_READ |\n              Windows.FILE_SHARE_WRITE |\n              Windows.FILE_SHARE_DELETE,\n          Windows.OPEN_EXISTING);\n      return new FileInputStream(fd);\n    }\n  }",
      "path": "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/nativeio/NativeIO.java"
    }
  }
}