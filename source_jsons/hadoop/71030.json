{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ImageWriter.java",
  "functionName": "setConf",
  "functionId": "setConf___conf-Configuration",
  "sourceFilePath": "hadoop-tools/hadoop-fs2img/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageWriter.java",
  "functionStartLine": 545,
  "functionEndLine": 561,
  "numCommitsSeen": 13,
  "timeTaken": 1381,
  "changeHistory": [
    "9c35be86e17021202823bfd3c2067ff3b312ce5c",
    "6cd80b2521e6283036d8c7058d8e452a93ff8e4b",
    "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5",
    "8da3a6e314609f9124bd9979cd09cddbc2a10d36"
  ],
  "changeHistoryShort": {
    "9c35be86e17021202823bfd3c2067ff3b312ce5c": "Ybodychange",
    "6cd80b2521e6283036d8c7058d8e452a93ff8e4b": "Ybodychange",
    "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5": "Ybodychange",
    "8da3a6e314609f9124bd9979cd09cddbc2a10d36": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9c35be86e17021202823bfd3c2067ff3b312ce5c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12713. [READ] Refactor FileRegion and BlockAliasMap to separate out HDFS metadata and PROVIDED storage metadata. Contributed by Ewan Higgs\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "9c35be86e17021202823bfd3c2067ff3b312ce5c",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "a027055dd2bf5009fe272e9ceb08305bd0a8cc31",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,17 @@\n     public void setConf(Configuration conf) {\n       this.conf \u003d conf;\n       String def \u003d new File(\"hdfs/name\").toURI().toString();\n       outdir \u003d new Path(conf.get(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY, def));\n       startBlock \u003d conf.getLong(FixedBlockResolver.START_BLOCK, (1L \u003c\u003c 30) + 1);\n       startInode \u003d conf.getLong(START_INODE, (1L \u003c\u003c 14) + 1);\n       maxdircache \u003d conf.getInt(CACHE_ENTRY, 100);\n       ugisClass \u003d conf.getClass(UGI_CLASS,\n           SingleUGIResolver.class, UGIResolver.class);\n       aliasMap \u003d conf.getClass(\n           DFSConfigKeys.DFS_PROVIDED_ALIASMAP_CLASS,\n           NullBlockAliasMap.class, BlockAliasMap.class);\n       blockIdsClass \u003d conf.getClass(BLOCK_RESOLVER_CLASS,\n           FixedBlockResolver.class, BlockResolver.class);\n       clusterID \u003d \"\";\n+      blockPoolID \u003d \"\";\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void setConf(Configuration conf) {\n      this.conf \u003d conf;\n      String def \u003d new File(\"hdfs/name\").toURI().toString();\n      outdir \u003d new Path(conf.get(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY, def));\n      startBlock \u003d conf.getLong(FixedBlockResolver.START_BLOCK, (1L \u003c\u003c 30) + 1);\n      startInode \u003d conf.getLong(START_INODE, (1L \u003c\u003c 14) + 1);\n      maxdircache \u003d conf.getInt(CACHE_ENTRY, 100);\n      ugisClass \u003d conf.getClass(UGI_CLASS,\n          SingleUGIResolver.class, UGIResolver.class);\n      aliasMap \u003d conf.getClass(\n          DFSConfigKeys.DFS_PROVIDED_ALIASMAP_CLASS,\n          NullBlockAliasMap.class, BlockAliasMap.class);\n      blockIdsClass \u003d conf.getClass(BLOCK_RESOLVER_CLASS,\n          FixedBlockResolver.class, BlockResolver.class);\n      clusterID \u003d \"\";\n      blockPoolID \u003d \"\";\n    }",
      "path": "hadoop-tools/hadoop-fs2img/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageWriter.java",
      "extendedDetails": {}
    },
    "6cd80b2521e6283036d8c7058d8e452a93ff8e4b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12779. [READ] Allow cluster id to be specified to the Image generation tool\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "6cd80b2521e6283036d8c7058d8e452a93ff8e4b",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "87dc026beec5d69a84771631ebca5fadb2f7195b",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,16 @@\n     public void setConf(Configuration conf) {\n       this.conf \u003d conf;\n       String def \u003d new File(\"hdfs/name\").toURI().toString();\n       outdir \u003d new Path(conf.get(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY, def));\n       startBlock \u003d conf.getLong(FixedBlockResolver.START_BLOCK, (1L \u003c\u003c 30) + 1);\n       startInode \u003d conf.getLong(START_INODE, (1L \u003c\u003c 14) + 1);\n       maxdircache \u003d conf.getInt(CACHE_ENTRY, 100);\n       ugisClass \u003d conf.getClass(UGI_CLASS,\n           SingleUGIResolver.class, UGIResolver.class);\n       aliasMap \u003d conf.getClass(\n           DFSConfigKeys.DFS_PROVIDED_ALIASMAP_CLASS,\n           NullBlockAliasMap.class, BlockAliasMap.class);\n       blockIdsClass \u003d conf.getClass(BLOCK_RESOLVER_CLASS,\n           FixedBlockResolver.class, BlockResolver.class);\n+      clusterID \u003d \"\";\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void setConf(Configuration conf) {\n      this.conf \u003d conf;\n      String def \u003d new File(\"hdfs/name\").toURI().toString();\n      outdir \u003d new Path(conf.get(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY, def));\n      startBlock \u003d conf.getLong(FixedBlockResolver.START_BLOCK, (1L \u003c\u003c 30) + 1);\n      startInode \u003d conf.getLong(START_INODE, (1L \u003c\u003c 14) + 1);\n      maxdircache \u003d conf.getInt(CACHE_ENTRY, 100);\n      ugisClass \u003d conf.getClass(UGI_CLASS,\n          SingleUGIResolver.class, UGIResolver.class);\n      aliasMap \u003d conf.getClass(\n          DFSConfigKeys.DFS_PROVIDED_ALIASMAP_CLASS,\n          NullBlockAliasMap.class, BlockAliasMap.class);\n      blockIdsClass \u003d conf.getClass(BLOCK_RESOLVER_CLASS,\n          FixedBlockResolver.class, BlockResolver.class);\n      clusterID \u003d \"\";\n    }",
      "path": "hadoop-tools/hadoop-fs2img/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageWriter.java",
      "extendedDetails": {}
    },
    "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11902. [READ] Merge BlockFormatProvider and FileRegionProvider.\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "98f5ed5aa377ddd3f35b763b20c499d2ccac2ed5",
      "commitAuthor": "Virajith Jalaparti",
      "commitDateOld": "15/12/17 5:51 PM",
      "commitNameOld": "8da3a6e314609f9124bd9979cd09cddbc2a10d36",
      "commitAuthorOld": "Virajith Jalaparti",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 13,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,15 @@\n     public void setConf(Configuration conf) {\n       this.conf \u003d conf;\n-      //long lastTxn \u003d conf.getLong(LAST_TXN, 0L);\n       String def \u003d new File(\"hdfs/name\").toURI().toString();\n       outdir \u003d new Path(conf.get(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY, def));\n       startBlock \u003d conf.getLong(FixedBlockResolver.START_BLOCK, (1L \u003c\u003c 30) + 1);\n       startInode \u003d conf.getLong(START_INODE, (1L \u003c\u003c 14) + 1);\n       maxdircache \u003d conf.getInt(CACHE_ENTRY, 100);\n       ugisClass \u003d conf.getClass(UGI_CLASS,\n           SingleUGIResolver.class, UGIResolver.class);\n-      blockFormatClass \u003d conf.getClass(\n-          DFSConfigKeys.DFS_PROVIDER_BLK_FORMAT_CLASS,\n-          NullBlockFormat.class, BlockFormat.class);\n+      aliasMap \u003d conf.getClass(\n+          DFSConfigKeys.DFS_PROVIDED_ALIASMAP_CLASS,\n+          NullBlockAliasMap.class, BlockAliasMap.class);\n       blockIdsClass \u003d conf.getClass(BLOCK_RESOLVER_CLASS,\n           FixedBlockResolver.class, BlockResolver.class);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void setConf(Configuration conf) {\n      this.conf \u003d conf;\n      String def \u003d new File(\"hdfs/name\").toURI().toString();\n      outdir \u003d new Path(conf.get(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY, def));\n      startBlock \u003d conf.getLong(FixedBlockResolver.START_BLOCK, (1L \u003c\u003c 30) + 1);\n      startInode \u003d conf.getLong(START_INODE, (1L \u003c\u003c 14) + 1);\n      maxdircache \u003d conf.getInt(CACHE_ENTRY, 100);\n      ugisClass \u003d conf.getClass(UGI_CLASS,\n          SingleUGIResolver.class, UGIResolver.class);\n      aliasMap \u003d conf.getClass(\n          DFSConfigKeys.DFS_PROVIDED_ALIASMAP_CLASS,\n          NullBlockAliasMap.class, BlockAliasMap.class);\n      blockIdsClass \u003d conf.getClass(BLOCK_RESOLVER_CLASS,\n          FixedBlockResolver.class, BlockResolver.class);\n    }",
      "path": "hadoop-tools/hadoop-fs2img/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageWriter.java",
      "extendedDetails": {}
    },
    "8da3a6e314609f9124bd9979cd09cddbc2a10d36": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-10706. [READ] Add tool generating FSImage from external store\n",
      "commitDate": "15/12/17 5:51 PM",
      "commitName": "8da3a6e314609f9124bd9979cd09cddbc2a10d36",
      "commitAuthor": "Virajith Jalaparti",
      "diff": "@@ -0,0 +1,16 @@\n+    public void setConf(Configuration conf) {\n+      this.conf \u003d conf;\n+      //long lastTxn \u003d conf.getLong(LAST_TXN, 0L);\n+      String def \u003d new File(\"hdfs/name\").toURI().toString();\n+      outdir \u003d new Path(conf.get(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY, def));\n+      startBlock \u003d conf.getLong(FixedBlockResolver.START_BLOCK, (1L \u003c\u003c 30) + 1);\n+      startInode \u003d conf.getLong(START_INODE, (1L \u003c\u003c 14) + 1);\n+      maxdircache \u003d conf.getInt(CACHE_ENTRY, 100);\n+      ugisClass \u003d conf.getClass(UGI_CLASS,\n+          SingleUGIResolver.class, UGIResolver.class);\n+      blockFormatClass \u003d conf.getClass(\n+          DFSConfigKeys.DFS_PROVIDER_BLK_FORMAT_CLASS,\n+          NullBlockFormat.class, BlockFormat.class);\n+      blockIdsClass \u003d conf.getClass(BLOCK_RESOLVER_CLASS,\n+          FixedBlockResolver.class, BlockResolver.class);\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public void setConf(Configuration conf) {\n      this.conf \u003d conf;\n      //long lastTxn \u003d conf.getLong(LAST_TXN, 0L);\n      String def \u003d new File(\"hdfs/name\").toURI().toString();\n      outdir \u003d new Path(conf.get(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY, def));\n      startBlock \u003d conf.getLong(FixedBlockResolver.START_BLOCK, (1L \u003c\u003c 30) + 1);\n      startInode \u003d conf.getLong(START_INODE, (1L \u003c\u003c 14) + 1);\n      maxdircache \u003d conf.getInt(CACHE_ENTRY, 100);\n      ugisClass \u003d conf.getClass(UGI_CLASS,\n          SingleUGIResolver.class, UGIResolver.class);\n      blockFormatClass \u003d conf.getClass(\n          DFSConfigKeys.DFS_PROVIDER_BLK_FORMAT_CLASS,\n          NullBlockFormat.class, BlockFormat.class);\n      blockIdsClass \u003d conf.getClass(BLOCK_RESOLVER_CLASS,\n          FixedBlockResolver.class, BlockResolver.class);\n    }",
      "path": "hadoop-tools/hadoop-fs2img/src/main/java/org/apache/hadoop/hdfs/server/namenode/ImageWriter.java"
    }
  }
}