{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPlacementPolicyDefault.java",
  "functionName": "chooseTarget",
  "functionId": "chooseTarget___src-String__numOfReplicas-int__writer-Node__excludedNodes-Set__Node____blocksize-long__favoredNodes-List__DatanodeDescriptor____storagePolicy-BlockStoragePolicy__flags-EnumSet__AddBlockFlag__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
  "functionStartLine": 166,
  "functionEndLine": 230,
  "numCommitsSeen": 173,
  "timeTaken": 5499,
  "changeHistory": [
    "f5ecc0bc080cb8a64c6d4632fc1c121f93d95c5e",
    "c1caab40f27e3e4f58ff1b5ef3e93efc56bbecbe",
    "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
    "bfadf11b36e9d97e03d6ed1e71829907c2301412",
    "588baab160e7c328dca1c45cf3541e79218406e8",
    "0f5f9846edab3ea7e80f35000072136f998bcd46",
    "3ae84e1ba8928879b3eda90e79667ba5a45d60f8",
    "22a41dce4af4d5b533ba875b322551db1c152878",
    "e08701ec71f7c10d8f15122d90c35f9f22e40837"
  ],
  "changeHistoryShort": {
    "f5ecc0bc080cb8a64c6d4632fc1c121f93d95c5e": "Ybodychange",
    "c1caab40f27e3e4f58ff1b5ef3e93efc56bbecbe": "Ybodychange",
    "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7": "Ymultichange(Yparameterchange,Ybodychange)",
    "bfadf11b36e9d97e03d6ed1e71829907c2301412": "Ybodychange",
    "588baab160e7c328dca1c45cf3541e79218406e8": "Ybodychange",
    "0f5f9846edab3ea7e80f35000072136f998bcd46": "Ybodychange",
    "3ae84e1ba8928879b3eda90e79667ba5a45d60f8": "Ybodychange",
    "22a41dce4af4d5b533ba875b322551db1c152878": "Ybodychange",
    "e08701ec71f7c10d8f15122d90c35f9f22e40837": "Ybodychange"
  },
  "changeHistoryDetails": {
    "f5ecc0bc080cb8a64c6d4632fc1c121f93d95c5e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14103. Review Logging of BlockPlacementPolicyDefault. Contributed by David Mollitor.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "19/06/19 10:06 AM",
      "commitName": "f5ecc0bc080cb8a64c6d4632fc1c121f93d95c5e",
      "commitAuthor": "David Mollitor",
      "commitDateOld": "06/06/19 10:20 AM",
      "commitNameOld": "944adc61b1830388d520d4052fc7eb6c7ba2790d",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 12.99,
      "commitsBetweenForRepo": 103,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,67 +1,65 @@\n   DatanodeStorageInfo[] chooseTarget(String src,\n       int numOfReplicas,\n       Node writer,\n       Set\u003cNode\u003e excludedNodes,\n       long blocksize,\n       List\u003cDatanodeDescriptor\u003e favoredNodes,\n       BlockStoragePolicy storagePolicy,\n       EnumSet\u003cAddBlockFlag\u003e flags) {\n     try {\n       if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n         // Favored nodes not specified, fall back to regular block placement.\n         return chooseTarget(src, numOfReplicas, writer,\n             new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n             excludedNodes, blocksize, storagePolicy, flags);\n       }\n \n       Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n           new HashSet\u003cNode\u003e() : new HashSet\u003c\u003e(excludedNodes);\n       final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n           .chooseStorageTypes((short)numOfReplicas);\n       final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n           getRequiredStorageTypes(requiredStorageTypes);\n \n       // Choose favored nodes\n       List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003c\u003e();\n       boolean avoidStaleNodes \u003d stats !\u003d null\n           \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n \n       int maxNodesAndReplicas[] \u003d getMaxNodesPerRack(0, numOfReplicas);\n       numOfReplicas \u003d maxNodesAndReplicas[0];\n       int maxNodesPerRack \u003d maxNodesAndReplicas[1];\n \n       chooseFavouredNodes(src, numOfReplicas, favoredNodes,\n           favoriteAndExcludedNodes, blocksize, maxNodesPerRack, results,\n           avoidStaleNodes, storageTypes);\n \n       if (results.size() \u003c numOfReplicas) {\n         // Not enough favored nodes, choose other nodes, based on block\n         // placement policy (HDFS-9393).\n         numOfReplicas -\u003d results.size();\n         for (DatanodeStorageInfo storage : results) {\n           // add localMachine and related nodes to favoriteAndExcludedNodes\n           addToExcludedNodes(storage.getDatanodeDescriptor(),\n               favoriteAndExcludedNodes);\n         }\n         DatanodeStorageInfo[] remainingTargets \u003d\n             chooseTarget(src, numOfReplicas, writer,\n                 new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false,\n                 favoriteAndExcludedNodes, blocksize, storagePolicy, flags,\n                 storageTypes);\n         for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n           results.add(remainingTargets[i]);\n         }\n       }\n       return getPipeline(writer,\n           results.toArray(new DatanodeStorageInfo[results.size()]));\n     } catch (NotEnoughReplicasException nr) {\n-      if (LOG.isDebugEnabled()) {\n-        LOG.debug(\"Failed to choose with favored nodes (\u003d\" + favoredNodes\n-            + \"), disregard favored nodes hint and retry.\", nr);\n-      }\n+      LOG.debug(\"Failed to choose with favored nodes (\u003d{}), disregard favored\"\n+          + \" nodes hint and retry.\", favoredNodes, nr);\n       // Fall back to regular block placement disregarding favored nodes hint\n       return chooseTarget(src, numOfReplicas, writer, \n           new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n           excludedNodes, blocksize, storagePolicy, flags);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  DatanodeStorageInfo[] chooseTarget(String src,\n      int numOfReplicas,\n      Node writer,\n      Set\u003cNode\u003e excludedNodes,\n      long blocksize,\n      List\u003cDatanodeDescriptor\u003e favoredNodes,\n      BlockStoragePolicy storagePolicy,\n      EnumSet\u003cAddBlockFlag\u003e flags) {\n    try {\n      if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n        // Favored nodes not specified, fall back to regular block placement.\n        return chooseTarget(src, numOfReplicas, writer,\n            new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n            excludedNodes, blocksize, storagePolicy, flags);\n      }\n\n      Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n          new HashSet\u003cNode\u003e() : new HashSet\u003c\u003e(excludedNodes);\n      final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n          .chooseStorageTypes((short)numOfReplicas);\n      final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n          getRequiredStorageTypes(requiredStorageTypes);\n\n      // Choose favored nodes\n      List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003c\u003e();\n      boolean avoidStaleNodes \u003d stats !\u003d null\n          \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n\n      int maxNodesAndReplicas[] \u003d getMaxNodesPerRack(0, numOfReplicas);\n      numOfReplicas \u003d maxNodesAndReplicas[0];\n      int maxNodesPerRack \u003d maxNodesAndReplicas[1];\n\n      chooseFavouredNodes(src, numOfReplicas, favoredNodes,\n          favoriteAndExcludedNodes, blocksize, maxNodesPerRack, results,\n          avoidStaleNodes, storageTypes);\n\n      if (results.size() \u003c numOfReplicas) {\n        // Not enough favored nodes, choose other nodes, based on block\n        // placement policy (HDFS-9393).\n        numOfReplicas -\u003d results.size();\n        for (DatanodeStorageInfo storage : results) {\n          // add localMachine and related nodes to favoriteAndExcludedNodes\n          addToExcludedNodes(storage.getDatanodeDescriptor(),\n              favoriteAndExcludedNodes);\n        }\n        DatanodeStorageInfo[] remainingTargets \u003d\n            chooseTarget(src, numOfReplicas, writer,\n                new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false,\n                favoriteAndExcludedNodes, blocksize, storagePolicy, flags,\n                storageTypes);\n        for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n          results.add(remainingTargets[i]);\n        }\n      }\n      return getPipeline(writer,\n          results.toArray(new DatanodeStorageInfo[results.size()]));\n    } catch (NotEnoughReplicasException nr) {\n      LOG.debug(\"Failed to choose with favored nodes (\u003d{}), disregard favored\"\n          + \" nodes hint and retry.\", favoredNodes, nr);\n      // Fall back to regular block placement disregarding favored nodes hint\n      return chooseTarget(src, numOfReplicas, writer, \n          new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n          excludedNodes, blocksize, storagePolicy, flags);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "c1caab40f27e3e4f58ff1b5ef3e93efc56bbecbe": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14512. ONE_SSD policy will be violated while write data with DistributedFileSystem.create(....favoredNodes). Contributed by Ayush Saxena.\n\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "29/05/19 8:56 PM",
      "commitName": "c1caab40f27e3e4f58ff1b5ef3e93efc56bbecbe",
      "commitAuthor": "Ayush Saxena",
      "commitDateOld": "13/03/19 1:15 PM",
      "commitNameOld": "66357574ae1da09ced735da36bf7d80a40c3fa1b",
      "commitAuthorOld": "Erik Krogen",
      "daysBetweenCommits": 77.32,
      "commitsBetweenForRepo": 467,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,66 +1,67 @@\n   DatanodeStorageInfo[] chooseTarget(String src,\n       int numOfReplicas,\n       Node writer,\n       Set\u003cNode\u003e excludedNodes,\n       long blocksize,\n       List\u003cDatanodeDescriptor\u003e favoredNodes,\n       BlockStoragePolicy storagePolicy,\n       EnumSet\u003cAddBlockFlag\u003e flags) {\n     try {\n       if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n         // Favored nodes not specified, fall back to regular block placement.\n         return chooseTarget(src, numOfReplicas, writer,\n             new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n             excludedNodes, blocksize, storagePolicy, flags);\n       }\n \n       Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n           new HashSet\u003cNode\u003e() : new HashSet\u003c\u003e(excludedNodes);\n       final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n           .chooseStorageTypes((short)numOfReplicas);\n       final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n           getRequiredStorageTypes(requiredStorageTypes);\n \n       // Choose favored nodes\n       List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003c\u003e();\n       boolean avoidStaleNodes \u003d stats !\u003d null\n           \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n \n       int maxNodesAndReplicas[] \u003d getMaxNodesPerRack(0, numOfReplicas);\n       numOfReplicas \u003d maxNodesAndReplicas[0];\n       int maxNodesPerRack \u003d maxNodesAndReplicas[1];\n \n       chooseFavouredNodes(src, numOfReplicas, favoredNodes,\n           favoriteAndExcludedNodes, blocksize, maxNodesPerRack, results,\n           avoidStaleNodes, storageTypes);\n \n       if (results.size() \u003c numOfReplicas) {\n         // Not enough favored nodes, choose other nodes, based on block\n         // placement policy (HDFS-9393).\n         numOfReplicas -\u003d results.size();\n         for (DatanodeStorageInfo storage : results) {\n           // add localMachine and related nodes to favoriteAndExcludedNodes\n           addToExcludedNodes(storage.getDatanodeDescriptor(),\n               favoriteAndExcludedNodes);\n         }\n         DatanodeStorageInfo[] remainingTargets \u003d\n             chooseTarget(src, numOfReplicas, writer,\n                 new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false,\n-                favoriteAndExcludedNodes, blocksize, storagePolicy, flags);\n+                favoriteAndExcludedNodes, blocksize, storagePolicy, flags,\n+                storageTypes);\n         for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n           results.add(remainingTargets[i]);\n         }\n       }\n       return getPipeline(writer,\n           results.toArray(new DatanodeStorageInfo[results.size()]));\n     } catch (NotEnoughReplicasException nr) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Failed to choose with favored nodes (\u003d\" + favoredNodes\n             + \"), disregard favored nodes hint and retry.\", nr);\n       }\n       // Fall back to regular block placement disregarding favored nodes hint\n       return chooseTarget(src, numOfReplicas, writer, \n           new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n           excludedNodes, blocksize, storagePolicy, flags);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  DatanodeStorageInfo[] chooseTarget(String src,\n      int numOfReplicas,\n      Node writer,\n      Set\u003cNode\u003e excludedNodes,\n      long blocksize,\n      List\u003cDatanodeDescriptor\u003e favoredNodes,\n      BlockStoragePolicy storagePolicy,\n      EnumSet\u003cAddBlockFlag\u003e flags) {\n    try {\n      if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n        // Favored nodes not specified, fall back to regular block placement.\n        return chooseTarget(src, numOfReplicas, writer,\n            new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n            excludedNodes, blocksize, storagePolicy, flags);\n      }\n\n      Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n          new HashSet\u003cNode\u003e() : new HashSet\u003c\u003e(excludedNodes);\n      final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n          .chooseStorageTypes((short)numOfReplicas);\n      final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n          getRequiredStorageTypes(requiredStorageTypes);\n\n      // Choose favored nodes\n      List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003c\u003e();\n      boolean avoidStaleNodes \u003d stats !\u003d null\n          \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n\n      int maxNodesAndReplicas[] \u003d getMaxNodesPerRack(0, numOfReplicas);\n      numOfReplicas \u003d maxNodesAndReplicas[0];\n      int maxNodesPerRack \u003d maxNodesAndReplicas[1];\n\n      chooseFavouredNodes(src, numOfReplicas, favoredNodes,\n          favoriteAndExcludedNodes, blocksize, maxNodesPerRack, results,\n          avoidStaleNodes, storageTypes);\n\n      if (results.size() \u003c numOfReplicas) {\n        // Not enough favored nodes, choose other nodes, based on block\n        // placement policy (HDFS-9393).\n        numOfReplicas -\u003d results.size();\n        for (DatanodeStorageInfo storage : results) {\n          // add localMachine and related nodes to favoriteAndExcludedNodes\n          addToExcludedNodes(storage.getDatanodeDescriptor(),\n              favoriteAndExcludedNodes);\n        }\n        DatanodeStorageInfo[] remainingTargets \u003d\n            chooseTarget(src, numOfReplicas, writer,\n                new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false,\n                favoriteAndExcludedNodes, blocksize, storagePolicy, flags,\n                storageTypes);\n        for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n          results.add(remainingTargets[i]);\n        }\n      }\n      return getPipeline(writer,\n          results.toArray(new DatanodeStorageInfo[results.size()]));\n    } catch (NotEnoughReplicasException nr) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Failed to choose with favored nodes (\u003d\" + favoredNodes\n            + \"), disregard favored nodes hint and retry.\", nr);\n      }\n      // Fall back to regular block placement disregarding favored nodes hint\n      return chooseTarget(src, numOfReplicas, writer, \n          new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n          excludedNodes, blocksize, storagePolicy, flags);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-3702. Add an option for NOT writing the blocks locally if there is a datanode on the same box as the client. (Contributed by Lei (Eddy) Xu)\n",
      "commitDate": "27/04/16 2:22 PM",
      "commitName": "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
      "commitAuthor": "Lei Xu",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-3702. Add an option for NOT writing the blocks locally if there is a datanode on the same box as the client. (Contributed by Lei (Eddy) Xu)\n",
          "commitDate": "27/04/16 2:22 PM",
          "commitName": "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "18/04/16 5:58 AM",
          "commitNameOld": "d8b729e16fb253e6c84f414d419b5663d9219a43",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 9.35,
          "commitsBetweenForRepo": 63,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,65 +1,66 @@\n   DatanodeStorageInfo[] chooseTarget(String src,\n       int numOfReplicas,\n       Node writer,\n       Set\u003cNode\u003e excludedNodes,\n       long blocksize,\n       List\u003cDatanodeDescriptor\u003e favoredNodes,\n-      BlockStoragePolicy storagePolicy) {\n+      BlockStoragePolicy storagePolicy,\n+      EnumSet\u003cAddBlockFlag\u003e flags) {\n     try {\n       if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n         // Favored nodes not specified, fall back to regular block placement.\n         return chooseTarget(src, numOfReplicas, writer,\n             new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n-            excludedNodes, blocksize, storagePolicy);\n+            excludedNodes, blocksize, storagePolicy, flags);\n       }\n \n       Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n           new HashSet\u003cNode\u003e() : new HashSet\u003c\u003e(excludedNodes);\n       final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n           .chooseStorageTypes((short)numOfReplicas);\n       final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n           getRequiredStorageTypes(requiredStorageTypes);\n \n       // Choose favored nodes\n       List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003c\u003e();\n       boolean avoidStaleNodes \u003d stats !\u003d null\n           \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n \n       int maxNodesAndReplicas[] \u003d getMaxNodesPerRack(0, numOfReplicas);\n       numOfReplicas \u003d maxNodesAndReplicas[0];\n       int maxNodesPerRack \u003d maxNodesAndReplicas[1];\n \n       chooseFavouredNodes(src, numOfReplicas, favoredNodes,\n           favoriteAndExcludedNodes, blocksize, maxNodesPerRack, results,\n           avoidStaleNodes, storageTypes);\n \n       if (results.size() \u003c numOfReplicas) {\n         // Not enough favored nodes, choose other nodes, based on block\n         // placement policy (HDFS-9393).\n         numOfReplicas -\u003d results.size();\n         for (DatanodeStorageInfo storage : results) {\n           // add localMachine and related nodes to favoriteAndExcludedNodes\n           addToExcludedNodes(storage.getDatanodeDescriptor(),\n               favoriteAndExcludedNodes);\n         }\n         DatanodeStorageInfo[] remainingTargets \u003d\n             chooseTarget(src, numOfReplicas, writer,\n                 new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false,\n-                favoriteAndExcludedNodes, blocksize, storagePolicy);\n+                favoriteAndExcludedNodes, blocksize, storagePolicy, flags);\n         for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n           results.add(remainingTargets[i]);\n         }\n       }\n       return getPipeline(writer,\n           results.toArray(new DatanodeStorageInfo[results.size()]));\n     } catch (NotEnoughReplicasException nr) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Failed to choose with favored nodes (\u003d\" + favoredNodes\n             + \"), disregard favored nodes hint and retry.\", nr);\n       }\n       // Fall back to regular block placement disregarding favored nodes hint\n       return chooseTarget(src, numOfReplicas, writer, \n           new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n-          excludedNodes, blocksize, storagePolicy);\n+          excludedNodes, blocksize, storagePolicy, flags);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  DatanodeStorageInfo[] chooseTarget(String src,\n      int numOfReplicas,\n      Node writer,\n      Set\u003cNode\u003e excludedNodes,\n      long blocksize,\n      List\u003cDatanodeDescriptor\u003e favoredNodes,\n      BlockStoragePolicy storagePolicy,\n      EnumSet\u003cAddBlockFlag\u003e flags) {\n    try {\n      if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n        // Favored nodes not specified, fall back to regular block placement.\n        return chooseTarget(src, numOfReplicas, writer,\n            new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n            excludedNodes, blocksize, storagePolicy, flags);\n      }\n\n      Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n          new HashSet\u003cNode\u003e() : new HashSet\u003c\u003e(excludedNodes);\n      final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n          .chooseStorageTypes((short)numOfReplicas);\n      final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n          getRequiredStorageTypes(requiredStorageTypes);\n\n      // Choose favored nodes\n      List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003c\u003e();\n      boolean avoidStaleNodes \u003d stats !\u003d null\n          \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n\n      int maxNodesAndReplicas[] \u003d getMaxNodesPerRack(0, numOfReplicas);\n      numOfReplicas \u003d maxNodesAndReplicas[0];\n      int maxNodesPerRack \u003d maxNodesAndReplicas[1];\n\n      chooseFavouredNodes(src, numOfReplicas, favoredNodes,\n          favoriteAndExcludedNodes, blocksize, maxNodesPerRack, results,\n          avoidStaleNodes, storageTypes);\n\n      if (results.size() \u003c numOfReplicas) {\n        // Not enough favored nodes, choose other nodes, based on block\n        // placement policy (HDFS-9393).\n        numOfReplicas -\u003d results.size();\n        for (DatanodeStorageInfo storage : results) {\n          // add localMachine and related nodes to favoriteAndExcludedNodes\n          addToExcludedNodes(storage.getDatanodeDescriptor(),\n              favoriteAndExcludedNodes);\n        }\n        DatanodeStorageInfo[] remainingTargets \u003d\n            chooseTarget(src, numOfReplicas, writer,\n                new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false,\n                favoriteAndExcludedNodes, blocksize, storagePolicy, flags);\n        for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n          results.add(remainingTargets[i]);\n        }\n      }\n      return getPipeline(writer,\n          results.toArray(new DatanodeStorageInfo[results.size()]));\n    } catch (NotEnoughReplicasException nr) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Failed to choose with favored nodes (\u003d\" + favoredNodes\n            + \"), disregard favored nodes hint and retry.\", nr);\n      }\n      // Fall back to regular block placement disregarding favored nodes hint\n      return chooseTarget(src, numOfReplicas, writer, \n          new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n          excludedNodes, blocksize, storagePolicy, flags);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
          "extendedDetails": {
            "oldValue": "[src-String, numOfReplicas-int, writer-Node, excludedNodes-Set\u003cNode\u003e, blocksize-long, favoredNodes-List\u003cDatanodeDescriptor\u003e, storagePolicy-BlockStoragePolicy]",
            "newValue": "[src-String, numOfReplicas-int, writer-Node, excludedNodes-Set\u003cNode\u003e, blocksize-long, favoredNodes-List\u003cDatanodeDescriptor\u003e, storagePolicy-BlockStoragePolicy, flags-EnumSet\u003cAddBlockFlag\u003e]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3702. Add an option for NOT writing the blocks locally if there is a datanode on the same box as the client. (Contributed by Lei (Eddy) Xu)\n",
          "commitDate": "27/04/16 2:22 PM",
          "commitName": "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
          "commitAuthor": "Lei Xu",
          "commitDateOld": "18/04/16 5:58 AM",
          "commitNameOld": "d8b729e16fb253e6c84f414d419b5663d9219a43",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 9.35,
          "commitsBetweenForRepo": 63,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,65 +1,66 @@\n   DatanodeStorageInfo[] chooseTarget(String src,\n       int numOfReplicas,\n       Node writer,\n       Set\u003cNode\u003e excludedNodes,\n       long blocksize,\n       List\u003cDatanodeDescriptor\u003e favoredNodes,\n-      BlockStoragePolicy storagePolicy) {\n+      BlockStoragePolicy storagePolicy,\n+      EnumSet\u003cAddBlockFlag\u003e flags) {\n     try {\n       if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n         // Favored nodes not specified, fall back to regular block placement.\n         return chooseTarget(src, numOfReplicas, writer,\n             new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n-            excludedNodes, blocksize, storagePolicy);\n+            excludedNodes, blocksize, storagePolicy, flags);\n       }\n \n       Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n           new HashSet\u003cNode\u003e() : new HashSet\u003c\u003e(excludedNodes);\n       final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n           .chooseStorageTypes((short)numOfReplicas);\n       final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n           getRequiredStorageTypes(requiredStorageTypes);\n \n       // Choose favored nodes\n       List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003c\u003e();\n       boolean avoidStaleNodes \u003d stats !\u003d null\n           \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n \n       int maxNodesAndReplicas[] \u003d getMaxNodesPerRack(0, numOfReplicas);\n       numOfReplicas \u003d maxNodesAndReplicas[0];\n       int maxNodesPerRack \u003d maxNodesAndReplicas[1];\n \n       chooseFavouredNodes(src, numOfReplicas, favoredNodes,\n           favoriteAndExcludedNodes, blocksize, maxNodesPerRack, results,\n           avoidStaleNodes, storageTypes);\n \n       if (results.size() \u003c numOfReplicas) {\n         // Not enough favored nodes, choose other nodes, based on block\n         // placement policy (HDFS-9393).\n         numOfReplicas -\u003d results.size();\n         for (DatanodeStorageInfo storage : results) {\n           // add localMachine and related nodes to favoriteAndExcludedNodes\n           addToExcludedNodes(storage.getDatanodeDescriptor(),\n               favoriteAndExcludedNodes);\n         }\n         DatanodeStorageInfo[] remainingTargets \u003d\n             chooseTarget(src, numOfReplicas, writer,\n                 new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false,\n-                favoriteAndExcludedNodes, blocksize, storagePolicy);\n+                favoriteAndExcludedNodes, blocksize, storagePolicy, flags);\n         for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n           results.add(remainingTargets[i]);\n         }\n       }\n       return getPipeline(writer,\n           results.toArray(new DatanodeStorageInfo[results.size()]));\n     } catch (NotEnoughReplicasException nr) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Failed to choose with favored nodes (\u003d\" + favoredNodes\n             + \"), disregard favored nodes hint and retry.\", nr);\n       }\n       // Fall back to regular block placement disregarding favored nodes hint\n       return chooseTarget(src, numOfReplicas, writer, \n           new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n-          excludedNodes, blocksize, storagePolicy);\n+          excludedNodes, blocksize, storagePolicy, flags);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  DatanodeStorageInfo[] chooseTarget(String src,\n      int numOfReplicas,\n      Node writer,\n      Set\u003cNode\u003e excludedNodes,\n      long blocksize,\n      List\u003cDatanodeDescriptor\u003e favoredNodes,\n      BlockStoragePolicy storagePolicy,\n      EnumSet\u003cAddBlockFlag\u003e flags) {\n    try {\n      if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n        // Favored nodes not specified, fall back to regular block placement.\n        return chooseTarget(src, numOfReplicas, writer,\n            new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n            excludedNodes, blocksize, storagePolicy, flags);\n      }\n\n      Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n          new HashSet\u003cNode\u003e() : new HashSet\u003c\u003e(excludedNodes);\n      final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n          .chooseStorageTypes((short)numOfReplicas);\n      final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n          getRequiredStorageTypes(requiredStorageTypes);\n\n      // Choose favored nodes\n      List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003c\u003e();\n      boolean avoidStaleNodes \u003d stats !\u003d null\n          \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n\n      int maxNodesAndReplicas[] \u003d getMaxNodesPerRack(0, numOfReplicas);\n      numOfReplicas \u003d maxNodesAndReplicas[0];\n      int maxNodesPerRack \u003d maxNodesAndReplicas[1];\n\n      chooseFavouredNodes(src, numOfReplicas, favoredNodes,\n          favoriteAndExcludedNodes, blocksize, maxNodesPerRack, results,\n          avoidStaleNodes, storageTypes);\n\n      if (results.size() \u003c numOfReplicas) {\n        // Not enough favored nodes, choose other nodes, based on block\n        // placement policy (HDFS-9393).\n        numOfReplicas -\u003d results.size();\n        for (DatanodeStorageInfo storage : results) {\n          // add localMachine and related nodes to favoriteAndExcludedNodes\n          addToExcludedNodes(storage.getDatanodeDescriptor(),\n              favoriteAndExcludedNodes);\n        }\n        DatanodeStorageInfo[] remainingTargets \u003d\n            chooseTarget(src, numOfReplicas, writer,\n                new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false,\n                favoriteAndExcludedNodes, blocksize, storagePolicy, flags);\n        for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n          results.add(remainingTargets[i]);\n        }\n      }\n      return getPipeline(writer,\n          results.toArray(new DatanodeStorageInfo[results.size()]));\n    } catch (NotEnoughReplicasException nr) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Failed to choose with favored nodes (\u003d\" + favoredNodes\n            + \"), disregard favored nodes hint and retry.\", nr);\n      }\n      // Fall back to regular block placement disregarding favored nodes hint\n      return chooseTarget(src, numOfReplicas, writer, \n          new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n          excludedNodes, blocksize, storagePolicy, flags);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
          "extendedDetails": {}
        }
      ]
    },
    "bfadf11b36e9d97e03d6ed1e71829907c2301412": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9393. After choosing favored nodes, choosing nodes for remaining replicas should go through BlockPlacementPolicy (Contributed by J.Andreina)\n",
      "commitDate": "17/12/15 10:08 PM",
      "commitName": "bfadf11b36e9d97e03d6ed1e71829907c2301412",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "24/11/15 10:30 AM",
      "commitNameOld": "0e54b164a8d8acf09aca8712116bf7a554cb4846",
      "commitAuthorOld": "Ming Ma",
      "daysBetweenCommits": 23.48,
      "commitsBetweenForRepo": 153,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,58 +1,65 @@\n   DatanodeStorageInfo[] chooseTarget(String src,\n       int numOfReplicas,\n       Node writer,\n       Set\u003cNode\u003e excludedNodes,\n       long blocksize,\n       List\u003cDatanodeDescriptor\u003e favoredNodes,\n       BlockStoragePolicy storagePolicy) {\n     try {\n       if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n         // Favored nodes not specified, fall back to regular block placement.\n         return chooseTarget(src, numOfReplicas, writer,\n             new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n             excludedNodes, blocksize, storagePolicy);\n       }\n \n       Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n           new HashSet\u003cNode\u003e() : new HashSet\u003c\u003e(excludedNodes);\n       final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n           .chooseStorageTypes((short)numOfReplicas);\n       final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n           getRequiredStorageTypes(requiredStorageTypes);\n \n       // Choose favored nodes\n       List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003c\u003e();\n       boolean avoidStaleNodes \u003d stats !\u003d null\n           \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n \n       int maxNodesAndReplicas[] \u003d getMaxNodesPerRack(0, numOfReplicas);\n       numOfReplicas \u003d maxNodesAndReplicas[0];\n       int maxNodesPerRack \u003d maxNodesAndReplicas[1];\n \n       chooseFavouredNodes(src, numOfReplicas, favoredNodes,\n           favoriteAndExcludedNodes, blocksize, maxNodesPerRack, results,\n           avoidStaleNodes, storageTypes);\n \n       if (results.size() \u003c numOfReplicas) {\n-        // Not enough favored nodes, choose other nodes.\n+        // Not enough favored nodes, choose other nodes, based on block\n+        // placement policy (HDFS-9393).\n         numOfReplicas -\u003d results.size();\n-        DatanodeStorageInfo[] remainingTargets \u003d \n-            chooseTarget(src, numOfReplicas, writer, results,\n-                false, favoriteAndExcludedNodes, blocksize, storagePolicy);\n+        for (DatanodeStorageInfo storage : results) {\n+          // add localMachine and related nodes to favoriteAndExcludedNodes\n+          addToExcludedNodes(storage.getDatanodeDescriptor(),\n+              favoriteAndExcludedNodes);\n+        }\n+        DatanodeStorageInfo[] remainingTargets \u003d\n+            chooseTarget(src, numOfReplicas, writer,\n+                new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false,\n+                favoriteAndExcludedNodes, blocksize, storagePolicy);\n         for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n           results.add(remainingTargets[i]);\n         }\n       }\n       return getPipeline(writer,\n           results.toArray(new DatanodeStorageInfo[results.size()]));\n     } catch (NotEnoughReplicasException nr) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Failed to choose with favored nodes (\u003d\" + favoredNodes\n             + \"), disregard favored nodes hint and retry.\", nr);\n       }\n       // Fall back to regular block placement disregarding favored nodes hint\n       return chooseTarget(src, numOfReplicas, writer, \n           new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n           excludedNodes, blocksize, storagePolicy);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  DatanodeStorageInfo[] chooseTarget(String src,\n      int numOfReplicas,\n      Node writer,\n      Set\u003cNode\u003e excludedNodes,\n      long blocksize,\n      List\u003cDatanodeDescriptor\u003e favoredNodes,\n      BlockStoragePolicy storagePolicy) {\n    try {\n      if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n        // Favored nodes not specified, fall back to regular block placement.\n        return chooseTarget(src, numOfReplicas, writer,\n            new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n            excludedNodes, blocksize, storagePolicy);\n      }\n\n      Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n          new HashSet\u003cNode\u003e() : new HashSet\u003c\u003e(excludedNodes);\n      final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n          .chooseStorageTypes((short)numOfReplicas);\n      final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n          getRequiredStorageTypes(requiredStorageTypes);\n\n      // Choose favored nodes\n      List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003c\u003e();\n      boolean avoidStaleNodes \u003d stats !\u003d null\n          \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n\n      int maxNodesAndReplicas[] \u003d getMaxNodesPerRack(0, numOfReplicas);\n      numOfReplicas \u003d maxNodesAndReplicas[0];\n      int maxNodesPerRack \u003d maxNodesAndReplicas[1];\n\n      chooseFavouredNodes(src, numOfReplicas, favoredNodes,\n          favoriteAndExcludedNodes, blocksize, maxNodesPerRack, results,\n          avoidStaleNodes, storageTypes);\n\n      if (results.size() \u003c numOfReplicas) {\n        // Not enough favored nodes, choose other nodes, based on block\n        // placement policy (HDFS-9393).\n        numOfReplicas -\u003d results.size();\n        for (DatanodeStorageInfo storage : results) {\n          // add localMachine and related nodes to favoriteAndExcludedNodes\n          addToExcludedNodes(storage.getDatanodeDescriptor(),\n              favoriteAndExcludedNodes);\n        }\n        DatanodeStorageInfo[] remainingTargets \u003d\n            chooseTarget(src, numOfReplicas, writer,\n                new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false,\n                favoriteAndExcludedNodes, blocksize, storagePolicy);\n        for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n          results.add(remainingTargets[i]);\n        }\n      }\n      return getPipeline(writer,\n          results.toArray(new DatanodeStorageInfo[results.size()]));\n    } catch (NotEnoughReplicasException nr) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Failed to choose with favored nodes (\u003d\" + favoredNodes\n            + \"), disregard favored nodes hint and retry.\", nr);\n      }\n      // Fall back to regular block placement disregarding favored nodes hint\n      return chooseTarget(src, numOfReplicas, writer, \n          new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n          excludedNodes, blocksize, storagePolicy);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "588baab160e7c328dca1c45cf3541e79218406e8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9044. Give Priority to FavouredNodes , before selecting nodes from FavouredNode\u0027s Node Group (Contributed by J.Andreina)\n",
      "commitDate": "28/10/15 11:14 PM",
      "commitName": "588baab160e7c328dca1c45cf3541e79218406e8",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "21/10/15 8:06 AM",
      "commitNameOld": "e27c2ae8bafc94f18eb38f5d839dcef5652d424e",
      "commitAuthorOld": "Ming Ma",
      "daysBetweenCommits": 7.63,
      "commitsBetweenForRepo": 92,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,58 @@\n   DatanodeStorageInfo[] chooseTarget(String src,\n       int numOfReplicas,\n       Node writer,\n       Set\u003cNode\u003e excludedNodes,\n       long blocksize,\n       List\u003cDatanodeDescriptor\u003e favoredNodes,\n       BlockStoragePolicy storagePolicy) {\n     try {\n       if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n         // Favored nodes not specified, fall back to regular block placement.\n         return chooseTarget(src, numOfReplicas, writer,\n             new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n             excludedNodes, blocksize, storagePolicy);\n       }\n \n       Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n           new HashSet\u003cNode\u003e() : new HashSet\u003c\u003e(excludedNodes);\n       final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n           .chooseStorageTypes((short)numOfReplicas);\n       final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n           getRequiredStorageTypes(requiredStorageTypes);\n \n       // Choose favored nodes\n       List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003c\u003e();\n       boolean avoidStaleNodes \u003d stats !\u003d null\n           \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n \n       int maxNodesAndReplicas[] \u003d getMaxNodesPerRack(0, numOfReplicas);\n       numOfReplicas \u003d maxNodesAndReplicas[0];\n       int maxNodesPerRack \u003d maxNodesAndReplicas[1];\n \n-      for (int i \u003d 0; i \u003c favoredNodes.size() \u0026\u0026 results.size() \u003c numOfReplicas; i++) {\n-        DatanodeDescriptor favoredNode \u003d favoredNodes.get(i);\n-        // Choose a single node which is local to favoredNode.\n-        // \u0027results\u0027 is updated within chooseLocalNode\n-        final DatanodeStorageInfo target \u003d chooseLocalStorage(favoredNode,\n-            favoriteAndExcludedNodes, blocksize, maxNodesPerRack,\n-            results, avoidStaleNodes, storageTypes, false);\n-        if (target \u003d\u003d null) {\n-          LOG.warn(\"Could not find a target for file \" + src\n-              + \" with favored node \" + favoredNode); \n-          continue;\n-        }\n-        favoriteAndExcludedNodes.add(target.getDatanodeDescriptor());\n-      }\n+      chooseFavouredNodes(src, numOfReplicas, favoredNodes,\n+          favoriteAndExcludedNodes, blocksize, maxNodesPerRack, results,\n+          avoidStaleNodes, storageTypes);\n \n       if (results.size() \u003c numOfReplicas) {\n         // Not enough favored nodes, choose other nodes.\n         numOfReplicas -\u003d results.size();\n         DatanodeStorageInfo[] remainingTargets \u003d \n             chooseTarget(src, numOfReplicas, writer, results,\n                 false, favoriteAndExcludedNodes, blocksize, storagePolicy);\n         for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n           results.add(remainingTargets[i]);\n         }\n       }\n       return getPipeline(writer,\n           results.toArray(new DatanodeStorageInfo[results.size()]));\n     } catch (NotEnoughReplicasException nr) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Failed to choose with favored nodes (\u003d\" + favoredNodes\n             + \"), disregard favored nodes hint and retry.\", nr);\n       }\n       // Fall back to regular block placement disregarding favored nodes hint\n       return chooseTarget(src, numOfReplicas, writer, \n           new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n           excludedNodes, blocksize, storagePolicy);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  DatanodeStorageInfo[] chooseTarget(String src,\n      int numOfReplicas,\n      Node writer,\n      Set\u003cNode\u003e excludedNodes,\n      long blocksize,\n      List\u003cDatanodeDescriptor\u003e favoredNodes,\n      BlockStoragePolicy storagePolicy) {\n    try {\n      if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n        // Favored nodes not specified, fall back to regular block placement.\n        return chooseTarget(src, numOfReplicas, writer,\n            new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n            excludedNodes, blocksize, storagePolicy);\n      }\n\n      Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n          new HashSet\u003cNode\u003e() : new HashSet\u003c\u003e(excludedNodes);\n      final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n          .chooseStorageTypes((short)numOfReplicas);\n      final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n          getRequiredStorageTypes(requiredStorageTypes);\n\n      // Choose favored nodes\n      List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003c\u003e();\n      boolean avoidStaleNodes \u003d stats !\u003d null\n          \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n\n      int maxNodesAndReplicas[] \u003d getMaxNodesPerRack(0, numOfReplicas);\n      numOfReplicas \u003d maxNodesAndReplicas[0];\n      int maxNodesPerRack \u003d maxNodesAndReplicas[1];\n\n      chooseFavouredNodes(src, numOfReplicas, favoredNodes,\n          favoriteAndExcludedNodes, blocksize, maxNodesPerRack, results,\n          avoidStaleNodes, storageTypes);\n\n      if (results.size() \u003c numOfReplicas) {\n        // Not enough favored nodes, choose other nodes.\n        numOfReplicas -\u003d results.size();\n        DatanodeStorageInfo[] remainingTargets \u003d \n            chooseTarget(src, numOfReplicas, writer, results,\n                false, favoriteAndExcludedNodes, blocksize, storagePolicy);\n        for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n          results.add(remainingTargets[i]);\n        }\n      }\n      return getPipeline(writer,\n          results.toArray(new DatanodeStorageInfo[results.size()]));\n    } catch (NotEnoughReplicasException nr) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Failed to choose with favored nodes (\u003d\" + favoredNodes\n            + \"), disregard favored nodes hint and retry.\", nr);\n      }\n      // Fall back to regular block placement disregarding favored nodes hint\n      return chooseTarget(src, numOfReplicas, writer, \n          new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n          excludedNodes, blocksize, storagePolicy);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "0f5f9846edab3ea7e80f35000072136f998bcd46": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9006. Provide BlockPlacementPolicy that supports upgrade domain. (Ming Ma via lei)\n",
      "commitDate": "12/10/15 4:24 PM",
      "commitName": "0f5f9846edab3ea7e80f35000072136f998bcd46",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "31/08/15 5:52 PM",
      "commitNameOld": "8fa41d9dd4b923bf4141f019414a1a8b079124c6",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 41.94,
      "commitsBetweenForRepo": 298,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,69 +1,69 @@\n   DatanodeStorageInfo[] chooseTarget(String src,\n       int numOfReplicas,\n       Node writer,\n       Set\u003cNode\u003e excludedNodes,\n       long blocksize,\n       List\u003cDatanodeDescriptor\u003e favoredNodes,\n       BlockStoragePolicy storagePolicy) {\n     try {\n       if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n         // Favored nodes not specified, fall back to regular block placement.\n         return chooseTarget(src, numOfReplicas, writer,\n             new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n             excludedNodes, blocksize, storagePolicy);\n       }\n \n       Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n-          new HashSet\u003cNode\u003e() : new HashSet\u003cNode\u003e(excludedNodes);\n+          new HashSet\u003cNode\u003e() : new HashSet\u003c\u003e(excludedNodes);\n       final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n           .chooseStorageTypes((short)numOfReplicas);\n       final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n           getRequiredStorageTypes(requiredStorageTypes);\n \n       // Choose favored nodes\n-      List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003cDatanodeStorageInfo\u003e();\n+      List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003c\u003e();\n       boolean avoidStaleNodes \u003d stats !\u003d null\n           \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n \n       int maxNodesAndReplicas[] \u003d getMaxNodesPerRack(0, numOfReplicas);\n       numOfReplicas \u003d maxNodesAndReplicas[0];\n       int maxNodesPerRack \u003d maxNodesAndReplicas[1];\n \n       for (int i \u003d 0; i \u003c favoredNodes.size() \u0026\u0026 results.size() \u003c numOfReplicas; i++) {\n         DatanodeDescriptor favoredNode \u003d favoredNodes.get(i);\n         // Choose a single node which is local to favoredNode.\n         // \u0027results\u0027 is updated within chooseLocalNode\n         final DatanodeStorageInfo target \u003d chooseLocalStorage(favoredNode,\n             favoriteAndExcludedNodes, blocksize, maxNodesPerRack,\n             results, avoidStaleNodes, storageTypes, false);\n         if (target \u003d\u003d null) {\n           LOG.warn(\"Could not find a target for file \" + src\n               + \" with favored node \" + favoredNode); \n           continue;\n         }\n         favoriteAndExcludedNodes.add(target.getDatanodeDescriptor());\n       }\n \n       if (results.size() \u003c numOfReplicas) {\n         // Not enough favored nodes, choose other nodes.\n         numOfReplicas -\u003d results.size();\n         DatanodeStorageInfo[] remainingTargets \u003d \n             chooseTarget(src, numOfReplicas, writer, results,\n                 false, favoriteAndExcludedNodes, blocksize, storagePolicy);\n         for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n           results.add(remainingTargets[i]);\n         }\n       }\n       return getPipeline(writer,\n           results.toArray(new DatanodeStorageInfo[results.size()]));\n     } catch (NotEnoughReplicasException nr) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Failed to choose with favored nodes (\u003d\" + favoredNodes\n             + \"), disregard favored nodes hint and retry.\", nr);\n       }\n       // Fall back to regular block placement disregarding favored nodes hint\n       return chooseTarget(src, numOfReplicas, writer, \n           new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n           excludedNodes, blocksize, storagePolicy);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  DatanodeStorageInfo[] chooseTarget(String src,\n      int numOfReplicas,\n      Node writer,\n      Set\u003cNode\u003e excludedNodes,\n      long blocksize,\n      List\u003cDatanodeDescriptor\u003e favoredNodes,\n      BlockStoragePolicy storagePolicy) {\n    try {\n      if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n        // Favored nodes not specified, fall back to regular block placement.\n        return chooseTarget(src, numOfReplicas, writer,\n            new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n            excludedNodes, blocksize, storagePolicy);\n      }\n\n      Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n          new HashSet\u003cNode\u003e() : new HashSet\u003c\u003e(excludedNodes);\n      final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n          .chooseStorageTypes((short)numOfReplicas);\n      final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n          getRequiredStorageTypes(requiredStorageTypes);\n\n      // Choose favored nodes\n      List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003c\u003e();\n      boolean avoidStaleNodes \u003d stats !\u003d null\n          \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n\n      int maxNodesAndReplicas[] \u003d getMaxNodesPerRack(0, numOfReplicas);\n      numOfReplicas \u003d maxNodesAndReplicas[0];\n      int maxNodesPerRack \u003d maxNodesAndReplicas[1];\n\n      for (int i \u003d 0; i \u003c favoredNodes.size() \u0026\u0026 results.size() \u003c numOfReplicas; i++) {\n        DatanodeDescriptor favoredNode \u003d favoredNodes.get(i);\n        // Choose a single node which is local to favoredNode.\n        // \u0027results\u0027 is updated within chooseLocalNode\n        final DatanodeStorageInfo target \u003d chooseLocalStorage(favoredNode,\n            favoriteAndExcludedNodes, blocksize, maxNodesPerRack,\n            results, avoidStaleNodes, storageTypes, false);\n        if (target \u003d\u003d null) {\n          LOG.warn(\"Could not find a target for file \" + src\n              + \" with favored node \" + favoredNode); \n          continue;\n        }\n        favoriteAndExcludedNodes.add(target.getDatanodeDescriptor());\n      }\n\n      if (results.size() \u003c numOfReplicas) {\n        // Not enough favored nodes, choose other nodes.\n        numOfReplicas -\u003d results.size();\n        DatanodeStorageInfo[] remainingTargets \u003d \n            chooseTarget(src, numOfReplicas, writer, results,\n                false, favoriteAndExcludedNodes, blocksize, storagePolicy);\n        for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n          results.add(remainingTargets[i]);\n        }\n      }\n      return getPipeline(writer,\n          results.toArray(new DatanodeStorageInfo[results.size()]));\n    } catch (NotEnoughReplicasException nr) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Failed to choose with favored nodes (\u003d\" + favoredNodes\n            + \"), disregard favored nodes hint and retry.\", nr);\n      }\n      // Fall back to regular block placement disregarding favored nodes hint\n      return chooseTarget(src, numOfReplicas, writer, \n          new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n          excludedNodes, blocksize, storagePolicy);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "3ae84e1ba8928879b3eda90e79667ba5a45d60f8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7300.     HDFS-7300. The getMaxNodesPerRack() method in\nBlockPlacementPolicyDefault is flawed. contributed by Kihwal Lee\n",
      "commitDate": "29/10/14 3:23 PM",
      "commitName": "3ae84e1ba8928879b3eda90e79667ba5a45d60f8",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "15/10/14 8:44 PM",
      "commitNameOld": "41980c56d3c01d7a0ddc7deea2d89b7f28026722",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 13.78,
      "commitsBetweenForRepo": 126,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,65 +1,69 @@\n   DatanodeStorageInfo[] chooseTarget(String src,\n       int numOfReplicas,\n       Node writer,\n       Set\u003cNode\u003e excludedNodes,\n       long blocksize,\n       List\u003cDatanodeDescriptor\u003e favoredNodes,\n       BlockStoragePolicy storagePolicy) {\n     try {\n       if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n         // Favored nodes not specified, fall back to regular block placement.\n         return chooseTarget(src, numOfReplicas, writer,\n             new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n             excludedNodes, blocksize, storagePolicy);\n       }\n \n       Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n           new HashSet\u003cNode\u003e() : new HashSet\u003cNode\u003e(excludedNodes);\n       final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n           .chooseStorageTypes((short)numOfReplicas);\n       final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n           getRequiredStorageTypes(requiredStorageTypes);\n \n       // Choose favored nodes\n       List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003cDatanodeStorageInfo\u003e();\n       boolean avoidStaleNodes \u003d stats !\u003d null\n           \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n+\n+      int maxNodesAndReplicas[] \u003d getMaxNodesPerRack(0, numOfReplicas);\n+      numOfReplicas \u003d maxNodesAndReplicas[0];\n+      int maxNodesPerRack \u003d maxNodesAndReplicas[1];\n+\n       for (int i \u003d 0; i \u003c favoredNodes.size() \u0026\u0026 results.size() \u003c numOfReplicas; i++) {\n         DatanodeDescriptor favoredNode \u003d favoredNodes.get(i);\n         // Choose a single node which is local to favoredNode.\n         // \u0027results\u0027 is updated within chooseLocalNode\n         final DatanodeStorageInfo target \u003d chooseLocalStorage(favoredNode,\n-            favoriteAndExcludedNodes, blocksize, \n-            getMaxNodesPerRack(results.size(), numOfReplicas)[1],\n+            favoriteAndExcludedNodes, blocksize, maxNodesPerRack,\n             results, avoidStaleNodes, storageTypes, false);\n         if (target \u003d\u003d null) {\n           LOG.warn(\"Could not find a target for file \" + src\n               + \" with favored node \" + favoredNode); \n           continue;\n         }\n         favoriteAndExcludedNodes.add(target.getDatanodeDescriptor());\n       }\n \n       if (results.size() \u003c numOfReplicas) {\n         // Not enough favored nodes, choose other nodes.\n         numOfReplicas -\u003d results.size();\n         DatanodeStorageInfo[] remainingTargets \u003d \n             chooseTarget(src, numOfReplicas, writer, results,\n                 false, favoriteAndExcludedNodes, blocksize, storagePolicy);\n         for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n           results.add(remainingTargets[i]);\n         }\n       }\n       return getPipeline(writer,\n           results.toArray(new DatanodeStorageInfo[results.size()]));\n     } catch (NotEnoughReplicasException nr) {\n       if (LOG.isDebugEnabled()) {\n         LOG.debug(\"Failed to choose with favored nodes (\u003d\" + favoredNodes\n             + \"), disregard favored nodes hint and retry.\", nr);\n       }\n       // Fall back to regular block placement disregarding favored nodes hint\n       return chooseTarget(src, numOfReplicas, writer, \n           new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n           excludedNodes, blocksize, storagePolicy);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  DatanodeStorageInfo[] chooseTarget(String src,\n      int numOfReplicas,\n      Node writer,\n      Set\u003cNode\u003e excludedNodes,\n      long blocksize,\n      List\u003cDatanodeDescriptor\u003e favoredNodes,\n      BlockStoragePolicy storagePolicy) {\n    try {\n      if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n        // Favored nodes not specified, fall back to regular block placement.\n        return chooseTarget(src, numOfReplicas, writer,\n            new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n            excludedNodes, blocksize, storagePolicy);\n      }\n\n      Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n          new HashSet\u003cNode\u003e() : new HashSet\u003cNode\u003e(excludedNodes);\n      final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n          .chooseStorageTypes((short)numOfReplicas);\n      final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n          getRequiredStorageTypes(requiredStorageTypes);\n\n      // Choose favored nodes\n      List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003cDatanodeStorageInfo\u003e();\n      boolean avoidStaleNodes \u003d stats !\u003d null\n          \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n\n      int maxNodesAndReplicas[] \u003d getMaxNodesPerRack(0, numOfReplicas);\n      numOfReplicas \u003d maxNodesAndReplicas[0];\n      int maxNodesPerRack \u003d maxNodesAndReplicas[1];\n\n      for (int i \u003d 0; i \u003c favoredNodes.size() \u0026\u0026 results.size() \u003c numOfReplicas; i++) {\n        DatanodeDescriptor favoredNode \u003d favoredNodes.get(i);\n        // Choose a single node which is local to favoredNode.\n        // \u0027results\u0027 is updated within chooseLocalNode\n        final DatanodeStorageInfo target \u003d chooseLocalStorage(favoredNode,\n            favoriteAndExcludedNodes, blocksize, maxNodesPerRack,\n            results, avoidStaleNodes, storageTypes, false);\n        if (target \u003d\u003d null) {\n          LOG.warn(\"Could not find a target for file \" + src\n              + \" with favored node \" + favoredNode); \n          continue;\n        }\n        favoriteAndExcludedNodes.add(target.getDatanodeDescriptor());\n      }\n\n      if (results.size() \u003c numOfReplicas) {\n        // Not enough favored nodes, choose other nodes.\n        numOfReplicas -\u003d results.size();\n        DatanodeStorageInfo[] remainingTargets \u003d \n            chooseTarget(src, numOfReplicas, writer, results,\n                false, favoriteAndExcludedNodes, blocksize, storagePolicy);\n        for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n          results.add(remainingTargets[i]);\n        }\n      }\n      return getPipeline(writer,\n          results.toArray(new DatanodeStorageInfo[results.size()]));\n    } catch (NotEnoughReplicasException nr) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Failed to choose with favored nodes (\u003d\" + favoredNodes\n            + \"), disregard favored nodes hint and retry.\", nr);\n      }\n      // Fall back to regular block placement disregarding favored nodes hint\n      return chooseTarget(src, numOfReplicas, writer, \n          new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n          excludedNodes, blocksize, storagePolicy);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "22a41dce4af4d5b533ba875b322551db1c152878": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6997: add more tests for data migration and replicaion.\n",
      "commitDate": "06/09/14 4:44 PM",
      "commitName": "22a41dce4af4d5b533ba875b322551db1c152878",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "04/09/14 2:19 PM",
      "commitNameOld": "e08701ec71f7c10d8f15122d90c35f9f22e40837",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 2.1,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,61 +1,65 @@\n   DatanodeStorageInfo[] chooseTarget(String src,\n       int numOfReplicas,\n       Node writer,\n       Set\u003cNode\u003e excludedNodes,\n       long blocksize,\n       List\u003cDatanodeDescriptor\u003e favoredNodes,\n       BlockStoragePolicy storagePolicy) {\n     try {\n       if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n         // Favored nodes not specified, fall back to regular block placement.\n         return chooseTarget(src, numOfReplicas, writer,\n             new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n             excludedNodes, blocksize, storagePolicy);\n       }\n \n       Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n           new HashSet\u003cNode\u003e() : new HashSet\u003cNode\u003e(excludedNodes);\n       final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n           .chooseStorageTypes((short)numOfReplicas);\n       final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n           getRequiredStorageTypes(requiredStorageTypes);\n \n       // Choose favored nodes\n       List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003cDatanodeStorageInfo\u003e();\n       boolean avoidStaleNodes \u003d stats !\u003d null\n           \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n       for (int i \u003d 0; i \u003c favoredNodes.size() \u0026\u0026 results.size() \u003c numOfReplicas; i++) {\n         DatanodeDescriptor favoredNode \u003d favoredNodes.get(i);\n         // Choose a single node which is local to favoredNode.\n         // \u0027results\u0027 is updated within chooseLocalNode\n         final DatanodeStorageInfo target \u003d chooseLocalStorage(favoredNode,\n             favoriteAndExcludedNodes, blocksize, \n             getMaxNodesPerRack(results.size(), numOfReplicas)[1],\n             results, avoidStaleNodes, storageTypes, false);\n         if (target \u003d\u003d null) {\n           LOG.warn(\"Could not find a target for file \" + src\n               + \" with favored node \" + favoredNode); \n           continue;\n         }\n         favoriteAndExcludedNodes.add(target.getDatanodeDescriptor());\n       }\n \n       if (results.size() \u003c numOfReplicas) {\n         // Not enough favored nodes, choose other nodes.\n         numOfReplicas -\u003d results.size();\n         DatanodeStorageInfo[] remainingTargets \u003d \n             chooseTarget(src, numOfReplicas, writer, results,\n                 false, favoriteAndExcludedNodes, blocksize, storagePolicy);\n         for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n           results.add(remainingTargets[i]);\n         }\n       }\n       return getPipeline(writer,\n           results.toArray(new DatanodeStorageInfo[results.size()]));\n     } catch (NotEnoughReplicasException nr) {\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Failed to choose with favored nodes (\u003d\" + favoredNodes\n+            + \"), disregard favored nodes hint and retry.\", nr);\n+      }\n       // Fall back to regular block placement disregarding favored nodes hint\n       return chooseTarget(src, numOfReplicas, writer, \n           new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n           excludedNodes, blocksize, storagePolicy);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  DatanodeStorageInfo[] chooseTarget(String src,\n      int numOfReplicas,\n      Node writer,\n      Set\u003cNode\u003e excludedNodes,\n      long blocksize,\n      List\u003cDatanodeDescriptor\u003e favoredNodes,\n      BlockStoragePolicy storagePolicy) {\n    try {\n      if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n        // Favored nodes not specified, fall back to regular block placement.\n        return chooseTarget(src, numOfReplicas, writer,\n            new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n            excludedNodes, blocksize, storagePolicy);\n      }\n\n      Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n          new HashSet\u003cNode\u003e() : new HashSet\u003cNode\u003e(excludedNodes);\n      final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n          .chooseStorageTypes((short)numOfReplicas);\n      final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n          getRequiredStorageTypes(requiredStorageTypes);\n\n      // Choose favored nodes\n      List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003cDatanodeStorageInfo\u003e();\n      boolean avoidStaleNodes \u003d stats !\u003d null\n          \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n      for (int i \u003d 0; i \u003c favoredNodes.size() \u0026\u0026 results.size() \u003c numOfReplicas; i++) {\n        DatanodeDescriptor favoredNode \u003d favoredNodes.get(i);\n        // Choose a single node which is local to favoredNode.\n        // \u0027results\u0027 is updated within chooseLocalNode\n        final DatanodeStorageInfo target \u003d chooseLocalStorage(favoredNode,\n            favoriteAndExcludedNodes, blocksize, \n            getMaxNodesPerRack(results.size(), numOfReplicas)[1],\n            results, avoidStaleNodes, storageTypes, false);\n        if (target \u003d\u003d null) {\n          LOG.warn(\"Could not find a target for file \" + src\n              + \" with favored node \" + favoredNode); \n          continue;\n        }\n        favoriteAndExcludedNodes.add(target.getDatanodeDescriptor());\n      }\n\n      if (results.size() \u003c numOfReplicas) {\n        // Not enough favored nodes, choose other nodes.\n        numOfReplicas -\u003d results.size();\n        DatanodeStorageInfo[] remainingTargets \u003d \n            chooseTarget(src, numOfReplicas, writer, results,\n                false, favoriteAndExcludedNodes, blocksize, storagePolicy);\n        for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n          results.add(remainingTargets[i]);\n        }\n      }\n      return getPipeline(writer,\n          results.toArray(new DatanodeStorageInfo[results.size()]));\n    } catch (NotEnoughReplicasException nr) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Failed to choose with favored nodes (\u003d\" + favoredNodes\n            + \"), disregard favored nodes hint and retry.\", nr);\n      }\n      // Fall back to regular block placement disregarding favored nodes hint\n      return chooseTarget(src, numOfReplicas, writer, \n          new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n          excludedNodes, blocksize, storagePolicy);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "e08701ec71f7c10d8f15122d90c35f9f22e40837": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6961. Archival Storage: BlockPlacementPolicy#chooseTarget should check each valid storage type in each choosing round.\n",
      "commitDate": "04/09/14 2:19 PM",
      "commitName": "e08701ec71f7c10d8f15122d90c35f9f22e40837",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "27/08/14 2:08 PM",
      "commitNameOld": "b7ded466b00db0fe273058b844d56d810e0f8cc2",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 8.01,
      "commitsBetweenForRepo": 50,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,60 +1,61 @@\n   DatanodeStorageInfo[] chooseTarget(String src,\n       int numOfReplicas,\n       Node writer,\n       Set\u003cNode\u003e excludedNodes,\n       long blocksize,\n       List\u003cDatanodeDescriptor\u003e favoredNodes,\n       BlockStoragePolicy storagePolicy) {\n     try {\n       if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n         // Favored nodes not specified, fall back to regular block placement.\n         return chooseTarget(src, numOfReplicas, writer,\n             new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n             excludedNodes, blocksize, storagePolicy);\n       }\n \n       Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n           new HashSet\u003cNode\u003e() : new HashSet\u003cNode\u003e(excludedNodes);\n-      final List\u003cStorageType\u003e storageTypes \u003d storagePolicy.chooseStorageTypes(\n-          (short)numOfReplicas);\n+      final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n+          .chooseStorageTypes((short)numOfReplicas);\n+      final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n+          getRequiredStorageTypes(requiredStorageTypes);\n \n       // Choose favored nodes\n       List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003cDatanodeStorageInfo\u003e();\n       boolean avoidStaleNodes \u003d stats !\u003d null\n           \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n       for (int i \u003d 0; i \u003c favoredNodes.size() \u0026\u0026 results.size() \u003c numOfReplicas; i++) {\n         DatanodeDescriptor favoredNode \u003d favoredNodes.get(i);\n         // Choose a single node which is local to favoredNode.\n         // \u0027results\u0027 is updated within chooseLocalNode\n         final DatanodeStorageInfo target \u003d chooseLocalStorage(favoredNode,\n             favoriteAndExcludedNodes, blocksize, \n             getMaxNodesPerRack(results.size(), numOfReplicas)[1],\n-            results, avoidStaleNodes, storageTypes.get(0), false);\n+            results, avoidStaleNodes, storageTypes, false);\n         if (target \u003d\u003d null) {\n           LOG.warn(\"Could not find a target for file \" + src\n               + \" with favored node \" + favoredNode); \n           continue;\n         }\n-        storageTypes.remove(0);\n         favoriteAndExcludedNodes.add(target.getDatanodeDescriptor());\n       }\n \n       if (results.size() \u003c numOfReplicas) {\n         // Not enough favored nodes, choose other nodes.\n         numOfReplicas -\u003d results.size();\n         DatanodeStorageInfo[] remainingTargets \u003d \n             chooseTarget(src, numOfReplicas, writer, results,\n                 false, favoriteAndExcludedNodes, blocksize, storagePolicy);\n         for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n           results.add(remainingTargets[i]);\n         }\n       }\n       return getPipeline(writer,\n           results.toArray(new DatanodeStorageInfo[results.size()]));\n     } catch (NotEnoughReplicasException nr) {\n       // Fall back to regular block placement disregarding favored nodes hint\n       return chooseTarget(src, numOfReplicas, writer, \n           new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n           excludedNodes, blocksize, storagePolicy);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  DatanodeStorageInfo[] chooseTarget(String src,\n      int numOfReplicas,\n      Node writer,\n      Set\u003cNode\u003e excludedNodes,\n      long blocksize,\n      List\u003cDatanodeDescriptor\u003e favoredNodes,\n      BlockStoragePolicy storagePolicy) {\n    try {\n      if (favoredNodes \u003d\u003d null || favoredNodes.size() \u003d\u003d 0) {\n        // Favored nodes not specified, fall back to regular block placement.\n        return chooseTarget(src, numOfReplicas, writer,\n            new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n            excludedNodes, blocksize, storagePolicy);\n      }\n\n      Set\u003cNode\u003e favoriteAndExcludedNodes \u003d excludedNodes \u003d\u003d null ?\n          new HashSet\u003cNode\u003e() : new HashSet\u003cNode\u003e(excludedNodes);\n      final List\u003cStorageType\u003e requiredStorageTypes \u003d storagePolicy\n          .chooseStorageTypes((short)numOfReplicas);\n      final EnumMap\u003cStorageType, Integer\u003e storageTypes \u003d\n          getRequiredStorageTypes(requiredStorageTypes);\n\n      // Choose favored nodes\n      List\u003cDatanodeStorageInfo\u003e results \u003d new ArrayList\u003cDatanodeStorageInfo\u003e();\n      boolean avoidStaleNodes \u003d stats !\u003d null\n          \u0026\u0026 stats.isAvoidingStaleDataNodesForWrite();\n      for (int i \u003d 0; i \u003c favoredNodes.size() \u0026\u0026 results.size() \u003c numOfReplicas; i++) {\n        DatanodeDescriptor favoredNode \u003d favoredNodes.get(i);\n        // Choose a single node which is local to favoredNode.\n        // \u0027results\u0027 is updated within chooseLocalNode\n        final DatanodeStorageInfo target \u003d chooseLocalStorage(favoredNode,\n            favoriteAndExcludedNodes, blocksize, \n            getMaxNodesPerRack(results.size(), numOfReplicas)[1],\n            results, avoidStaleNodes, storageTypes, false);\n        if (target \u003d\u003d null) {\n          LOG.warn(\"Could not find a target for file \" + src\n              + \" with favored node \" + favoredNode); \n          continue;\n        }\n        favoriteAndExcludedNodes.add(target.getDatanodeDescriptor());\n      }\n\n      if (results.size() \u003c numOfReplicas) {\n        // Not enough favored nodes, choose other nodes.\n        numOfReplicas -\u003d results.size();\n        DatanodeStorageInfo[] remainingTargets \u003d \n            chooseTarget(src, numOfReplicas, writer, results,\n                false, favoriteAndExcludedNodes, blocksize, storagePolicy);\n        for (int i \u003d 0; i \u003c remainingTargets.length; i++) {\n          results.add(remainingTargets[i]);\n        }\n      }\n      return getPipeline(writer,\n          results.toArray(new DatanodeStorageInfo[results.size()]));\n    } catch (NotEnoughReplicasException nr) {\n      // Fall back to regular block placement disregarding favored nodes hint\n      return chooseTarget(src, numOfReplicas, writer, \n          new ArrayList\u003cDatanodeStorageInfo\u003e(numOfReplicas), false, \n          excludedNodes, blocksize, storagePolicy);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    }
  }
}