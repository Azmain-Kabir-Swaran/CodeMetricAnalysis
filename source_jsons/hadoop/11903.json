{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RamDiskReplicaLruTracker.java",
  "functionName": "discardReplica",
  "functionId": "discardReplica___bpid-String(modifiers-final)__blockId-long(modifiers-final)__deleteSavedCopies-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaLruTracker.java",
  "functionStartLine": 203,
  "functionEndLine": 226,
  "numCommitsSeen": 13,
  "timeTaken": 3297,
  "changeHistory": [
    "b2d5ed36bcb80e2581191dcdc3976e825c959142",
    "ccdf0054a354fc110124b83de742c2ee6076449e",
    "cb9b485075ce773f2d6189aa2f54bbc69aad4dab",
    "4cf9afacbe3d0814fb616d238aa9b16b1ae68386",
    "eb448e14399e17f11b9e523e4050de245b9b0408"
  ],
  "changeHistoryShort": {
    "b2d5ed36bcb80e2581191dcdc3976e825c959142": "Ymultichange(Ymovefromfile,Ybodychange)",
    "ccdf0054a354fc110124b83de742c2ee6076449e": "Ymultichange(Yparameterchange,Ybodychange)",
    "cb9b485075ce773f2d6189aa2f54bbc69aad4dab": "Ybodychange",
    "4cf9afacbe3d0814fb616d238aa9b16b1ae68386": "Ybodychange",
    "eb448e14399e17f11b9e523e4050de245b9b0408": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b2d5ed36bcb80e2581191dcdc3976e825c959142": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-7100. Make eviction scheme pluggable. (Arpit Agarwal)\n",
      "commitDate": "20/09/14 1:25 PM",
      "commitName": "b2d5ed36bcb80e2581191dcdc3976e825c959142",
      "commitAuthor": "arp",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-7100. Make eviction scheme pluggable. (Arpit Agarwal)\n",
          "commitDate": "20/09/14 1:25 PM",
          "commitName": "b2d5ed36bcb80e2581191dcdc3976e825c959142",
          "commitAuthor": "arp",
          "commitDateOld": "20/09/14 10:34 AM",
          "commitNameOld": "09dab88d3eeb9947211b075d8103f9b836a61e8a",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,24 @@\n   synchronized void discardReplica(\n       final String bpid, final long blockId,\n       boolean deleteSavedCopies) {\n-    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n+    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n \n     if (map \u003d\u003d null) {\n       return;\n     }\n \n-    ReplicaState replicaState \u003d map.get(blockId);\n+    RamDiskReplicaLru ramDiskReplicaLru \u003d map.get(blockId);\n \n-    if (replicaState \u003d\u003d null) {\n+    if (ramDiskReplicaLru \u003d\u003d null) {\n       return;\n     }\n \n     if (deleteSavedCopies) {\n-      replicaState.deleteSavedFiles();\n+      ramDiskReplicaLru.deleteSavedFiles();\n     }\n+\n     map.remove(blockId);\n+    replicasPersisted.remove(ramDiskReplicaLru.lastUsedTime, ramDiskReplicaLru);\n+\n+    // replicasNotPersisted will be lazily GC\u0027ed.\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void discardReplica(\n      final String bpid, final long blockId,\n      boolean deleteSavedCopies) {\n    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n\n    if (map \u003d\u003d null) {\n      return;\n    }\n\n    RamDiskReplicaLru ramDiskReplicaLru \u003d map.get(blockId);\n\n    if (ramDiskReplicaLru \u003d\u003d null) {\n      return;\n    }\n\n    if (deleteSavedCopies) {\n      ramDiskReplicaLru.deleteSavedFiles();\n    }\n\n    map.remove(blockId);\n    replicasPersisted.remove(ramDiskReplicaLru.lastUsedTime, ramDiskReplicaLru);\n\n    // replicasNotPersisted will be lazily GC\u0027ed.\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaLruTracker.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaLruTracker.java",
            "oldMethodName": "discardReplica",
            "newMethodName": "discardReplica"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7100. Make eviction scheme pluggable. (Arpit Agarwal)\n",
          "commitDate": "20/09/14 1:25 PM",
          "commitName": "b2d5ed36bcb80e2581191dcdc3976e825c959142",
          "commitAuthor": "arp",
          "commitDateOld": "20/09/14 10:34 AM",
          "commitNameOld": "09dab88d3eeb9947211b075d8103f9b836a61e8a",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 0.12,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,24 @@\n   synchronized void discardReplica(\n       final String bpid, final long blockId,\n       boolean deleteSavedCopies) {\n-    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n+    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n \n     if (map \u003d\u003d null) {\n       return;\n     }\n \n-    ReplicaState replicaState \u003d map.get(blockId);\n+    RamDiskReplicaLru ramDiskReplicaLru \u003d map.get(blockId);\n \n-    if (replicaState \u003d\u003d null) {\n+    if (ramDiskReplicaLru \u003d\u003d null) {\n       return;\n     }\n \n     if (deleteSavedCopies) {\n-      replicaState.deleteSavedFiles();\n+      ramDiskReplicaLru.deleteSavedFiles();\n     }\n+\n     map.remove(blockId);\n+    replicasPersisted.remove(ramDiskReplicaLru.lastUsedTime, ramDiskReplicaLru);\n+\n+    // replicasNotPersisted will be lazily GC\u0027ed.\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void discardReplica(\n      final String bpid, final long blockId,\n      boolean deleteSavedCopies) {\n    Map\u003cLong, RamDiskReplicaLru\u003e map \u003d replicaMaps.get(bpid);\n\n    if (map \u003d\u003d null) {\n      return;\n    }\n\n    RamDiskReplicaLru ramDiskReplicaLru \u003d map.get(blockId);\n\n    if (ramDiskReplicaLru \u003d\u003d null) {\n      return;\n    }\n\n    if (deleteSavedCopies) {\n      ramDiskReplicaLru.deleteSavedFiles();\n    }\n\n    map.remove(blockId);\n    replicasPersisted.remove(ramDiskReplicaLru.lastUsedTime, ramDiskReplicaLru);\n\n    // replicasNotPersisted will be lazily GC\u0027ed.\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaLruTracker.java",
          "extendedDetails": {}
        }
      ]
    },
    "ccdf0054a354fc110124b83de742c2ee6076449e": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6977. Delete all copies when a block is deleted from the block space. (Arpit Agarwal)\n",
      "commitDate": "08/09/14 10:35 AM",
      "commitName": "ccdf0054a354fc110124b83de742c2ee6076449e",
      "commitAuthor": "arp",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6977. Delete all copies when a block is deleted from the block space. (Arpit Agarwal)\n",
          "commitDate": "08/09/14 10:35 AM",
          "commitName": "ccdf0054a354fc110124b83de742c2ee6076449e",
          "commitAuthor": "arp",
          "commitDateOld": "03/09/14 1:53 PM",
          "commitNameOld": "cb9b485075ce773f2d6189aa2f54bbc69aad4dab",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 4.86,
          "commitsBetweenForRepo": 35,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,20 @@\n   synchronized void discardReplica(\n-      final String bpid, final long blockId, boolean force) {\n+      final String bpid, final long blockId,\n+      boolean deleteSavedCopies) {\n     Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n \n     if (map \u003d\u003d null) {\n       return;\n     }\n \n     ReplicaState replicaState \u003d map.get(blockId);\n \n     if (replicaState \u003d\u003d null) {\n-      if (force) {\n-        return;\n-      }\n-      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n-          bpid + \"; blockId\u003d\" + blockId);\n+      return;\n     }\n \n-    if (replicaState.state !\u003d State.LAZY_PERSIST_COMPLETE \u0026\u0026 !force) {\n-      throw new IllegalStateException(\"Discarding replica without \" +\n-          \"saving it to disk bpid\u003d\" + bpid + \"; blockId\u003d\" + blockId);\n-\n+    if (deleteSavedCopies) {\n+      replicaState.deleteSavedFiles();\n     }\n-\n     map.remove(blockId);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void discardReplica(\n      final String bpid, final long blockId,\n      boolean deleteSavedCopies) {\n    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n\n    if (map \u003d\u003d null) {\n      return;\n    }\n\n    ReplicaState replicaState \u003d map.get(blockId);\n\n    if (replicaState \u003d\u003d null) {\n      return;\n    }\n\n    if (deleteSavedCopies) {\n      replicaState.deleteSavedFiles();\n    }\n    map.remove(blockId);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java",
          "extendedDetails": {
            "oldValue": "[bpid-String(modifiers-final), blockId-long(modifiers-final), force-boolean]",
            "newValue": "[bpid-String(modifiers-final), blockId-long(modifiers-final), deleteSavedCopies-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6977. Delete all copies when a block is deleted from the block space. (Arpit Agarwal)\n",
          "commitDate": "08/09/14 10:35 AM",
          "commitName": "ccdf0054a354fc110124b83de742c2ee6076449e",
          "commitAuthor": "arp",
          "commitDateOld": "03/09/14 1:53 PM",
          "commitNameOld": "cb9b485075ce773f2d6189aa2f54bbc69aad4dab",
          "commitAuthorOld": "arp",
          "daysBetweenCommits": 4.86,
          "commitsBetweenForRepo": 35,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,26 +1,20 @@\n   synchronized void discardReplica(\n-      final String bpid, final long blockId, boolean force) {\n+      final String bpid, final long blockId,\n+      boolean deleteSavedCopies) {\n     Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n \n     if (map \u003d\u003d null) {\n       return;\n     }\n \n     ReplicaState replicaState \u003d map.get(blockId);\n \n     if (replicaState \u003d\u003d null) {\n-      if (force) {\n-        return;\n-      }\n-      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n-          bpid + \"; blockId\u003d\" + blockId);\n+      return;\n     }\n \n-    if (replicaState.state !\u003d State.LAZY_PERSIST_COMPLETE \u0026\u0026 !force) {\n-      throw new IllegalStateException(\"Discarding replica without \" +\n-          \"saving it to disk bpid\u003d\" + bpid + \"; blockId\u003d\" + blockId);\n-\n+    if (deleteSavedCopies) {\n+      replicaState.deleteSavedFiles();\n     }\n-\n     map.remove(blockId);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  synchronized void discardReplica(\n      final String bpid, final long blockId,\n      boolean deleteSavedCopies) {\n    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n\n    if (map \u003d\u003d null) {\n      return;\n    }\n\n    ReplicaState replicaState \u003d map.get(blockId);\n\n    if (replicaState \u003d\u003d null) {\n      return;\n    }\n\n    if (deleteSavedCopies) {\n      replicaState.deleteSavedFiles();\n    }\n    map.remove(blockId);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java",
          "extendedDetails": {}
        }
      ]
    },
    "cb9b485075ce773f2d6189aa2f54bbc69aad4dab": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6930. Improve replica eviction from RAM disk. (Arpit Agarwal)\n",
      "commitDate": "03/09/14 1:53 PM",
      "commitName": "cb9b485075ce773f2d6189aa2f54bbc69aad4dab",
      "commitAuthor": "arp",
      "commitDateOld": "28/08/14 11:05 PM",
      "commitNameOld": "4cf9afacbe3d0814fb616d238aa9b16b1ae68386",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 5.62,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,26 @@\n   synchronized void discardReplica(\n       final String bpid, final long blockId, boolean force) {\n     Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n \n     if (map \u003d\u003d null) {\n       return;\n     }\n \n     ReplicaState replicaState \u003d map.get(blockId);\n \n     if (replicaState \u003d\u003d null) {\n       if (force) {\n         return;\n       }\n       throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n           bpid + \"; blockId\u003d\" + blockId);\n     }\n \n     if (replicaState.state !\u003d State.LAZY_PERSIST_COMPLETE \u0026\u0026 !force) {\n       throw new IllegalStateException(\"Discarding replica without \" +\n           \"saving it to disk bpid\u003d\" + bpid + \"; blockId\u003d\" + blockId);\n \n     }\n \n     map.remove(blockId);\n-    replicasPersisted.remove(replicaState);\n-\n-    // Leave the replica in replicasNotPersisted if its present.\n-    // dequeueNextReplicaToPersist will GC it eventually.\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void discardReplica(\n      final String bpid, final long blockId, boolean force) {\n    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n\n    if (map \u003d\u003d null) {\n      return;\n    }\n\n    ReplicaState replicaState \u003d map.get(blockId);\n\n    if (replicaState \u003d\u003d null) {\n      if (force) {\n        return;\n      }\n      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n          bpid + \"; blockId\u003d\" + blockId);\n    }\n\n    if (replicaState.state !\u003d State.LAZY_PERSIST_COMPLETE \u0026\u0026 !force) {\n      throw new IllegalStateException(\"Discarding replica without \" +\n          \"saving it to disk bpid\u003d\" + bpid + \"; blockId\u003d\" + blockId);\n\n    }\n\n    map.remove(blockId);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java",
      "extendedDetails": {}
    },
    "4cf9afacbe3d0814fb616d238aa9b16b1ae68386": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6960. Bugfix in LazyWriter, fix test case and some refactoring. (Arpit Agarwal)\n",
      "commitDate": "28/08/14 11:05 PM",
      "commitName": "4cf9afacbe3d0814fb616d238aa9b16b1ae68386",
      "commitAuthor": "arp",
      "commitDateOld": "27/08/14 9:47 PM",
      "commitNameOld": "eb448e14399e17f11b9e523e4050de245b9b0408",
      "commitAuthorOld": "arp",
      "daysBetweenCommits": 1.05,
      "commitsBetweenForRepo": 16,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,30 @@\n   synchronized void discardReplica(\n       final String bpid, final long blockId, boolean force) {\n     Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n+\n+    if (map \u003d\u003d null) {\n+      return;\n+    }\n+\n     ReplicaState replicaState \u003d map.get(blockId);\n \n     if (replicaState \u003d\u003d null) {\n       if (force) {\n         return;\n       }\n       throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n           bpid + \"; blockId\u003d\" + blockId);\n     }\n \n     if (replicaState.state !\u003d State.LAZY_PERSIST_COMPLETE \u0026\u0026 !force) {\n       throw new IllegalStateException(\"Discarding replica without \" +\n           \"saving it to disk bpid\u003d\" + bpid + \"; blockId\u003d\" + blockId);\n \n     }\n \n     map.remove(blockId);\n-    persistTimeMap.remove(replicaState);\n+    replicasPersisted.remove(replicaState);\n+\n+    // Leave the replica in replicasNotPersisted if its present.\n+    // dequeueNextReplicaToPersist will GC it eventually.\n   }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void discardReplica(\n      final String bpid, final long blockId, boolean force) {\n    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n\n    if (map \u003d\u003d null) {\n      return;\n    }\n\n    ReplicaState replicaState \u003d map.get(blockId);\n\n    if (replicaState \u003d\u003d null) {\n      if (force) {\n        return;\n      }\n      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n          bpid + \"; blockId\u003d\" + blockId);\n    }\n\n    if (replicaState.state !\u003d State.LAZY_PERSIST_COMPLETE \u0026\u0026 !force) {\n      throw new IllegalStateException(\"Discarding replica without \" +\n          \"saving it to disk bpid\u003d\" + bpid + \"; blockId\u003d\" + blockId);\n\n    }\n\n    map.remove(blockId);\n    replicasPersisted.remove(replicaState);\n\n    // Leave the replica in replicasNotPersisted if its present.\n    // dequeueNextReplicaToPersist will GC it eventually.\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java",
      "extendedDetails": {}
    },
    "eb448e14399e17f11b9e523e4050de245b9b0408": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6926. DN support for saving replicas to persistent storage and evicting in-memory replicas. (Arpit Agarwal)\n",
      "commitDate": "27/08/14 9:47 PM",
      "commitName": "eb448e14399e17f11b9e523e4050de245b9b0408",
      "commitAuthor": "arp",
      "diff": "@@ -0,0 +1,22 @@\n+  synchronized void discardReplica(\n+      final String bpid, final long blockId, boolean force) {\n+    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n+    ReplicaState replicaState \u003d map.get(blockId);\n+\n+    if (replicaState \u003d\u003d null) {\n+      if (force) {\n+        return;\n+      }\n+      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n+          bpid + \"; blockId\u003d\" + blockId);\n+    }\n+\n+    if (replicaState.state !\u003d State.LAZY_PERSIST_COMPLETE \u0026\u0026 !force) {\n+      throw new IllegalStateException(\"Discarding replica without \" +\n+          \"saving it to disk bpid\u003d\" + bpid + \"; blockId\u003d\" + blockId);\n+\n+    }\n+\n+    map.remove(blockId);\n+    persistTimeMap.remove(replicaState);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized void discardReplica(\n      final String bpid, final long blockId, boolean force) {\n    Map\u003cLong, ReplicaState\u003e map \u003d replicaMaps.get(bpid);\n    ReplicaState replicaState \u003d map.get(blockId);\n\n    if (replicaState \u003d\u003d null) {\n      if (force) {\n        return;\n      }\n      throw new IllegalStateException(\"Unknown replica bpid\u003d\" +\n          bpid + \"; blockId\u003d\" + blockId);\n    }\n\n    if (replicaState.state !\u003d State.LAZY_PERSIST_COMPLETE \u0026\u0026 !force) {\n      throw new IllegalStateException(\"Discarding replica without \" +\n          \"saving it to disk bpid\u003d\" + bpid + \"; blockId\u003d\" + blockId);\n\n    }\n\n    map.remove(blockId);\n    persistTimeMap.remove(replicaState);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/LazyWriteReplicaTracker.java"
    }
  }
}