{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "AggregatedLogFormat.java",
  "functionName": "readAcontainerLogs",
  "functionId": "readAcontainerLogs___valueStream-DataInputStream__writer-Writer__logUploadedTime-long",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
  "functionStartLine": 774,
  "functionEndLine": 792,
  "numCommitsSeen": 72,
  "timeTaken": 4192,
  "changeHistory": [
    "22de9449f8aa72c5b0bb586b8253390773502189",
    "c2cb7ea1ef6532020b69031dbd18b0f9b8369f0f",
    "0bc05e40fa7e183efe8463ada459c621da3ce3bf",
    "a696fbb001b946ae75f3b8e962839c2fd3decfa1",
    "58e9f24e0f06efede21085b7ffe36af042fa7b38",
    "f81dc3f995579c1b94b11d60e9fc6da56c8a9496",
    "e1fdf62123625e4ba399af02f8aad500637d29d1",
    "f58e3c8b121859194185fa12bfbd0ff57e6bcc7f",
    "c27601fefebd0af887a12d684bfc6f90d9fc0321",
    "670fa24b48acb407c22fbfdde87ae3123dcbf449"
  ],
  "changeHistoryShort": {
    "22de9449f8aa72c5b0bb586b8253390773502189": "Ybodychange",
    "c2cb7ea1ef6532020b69031dbd18b0f9b8369f0f": "Ybodychange",
    "0bc05e40fa7e183efe8463ada459c621da3ce3bf": "Ybodychange",
    "a696fbb001b946ae75f3b8e962839c2fd3decfa1": "Ybodychange",
    "58e9f24e0f06efede21085b7ffe36af042fa7b38": "Ymultichange(Yparameterchange,Ybodychange)",
    "f81dc3f995579c1b94b11d60e9fc6da56c8a9496": "Ybodychange",
    "e1fdf62123625e4ba399af02f8aad500637d29d1": "Yfilerename",
    "f58e3c8b121859194185fa12bfbd0ff57e6bcc7f": "Ybodychange",
    "c27601fefebd0af887a12d684bfc6f90d9fc0321": "Yfilerename",
    "670fa24b48acb407c22fbfdde87ae3123dcbf449": "Yintroduced"
  },
  "changeHistoryDetails": {
    "22de9449f8aa72c5b0bb586b8253390773502189": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7144. Log Aggregation controller should not swallow the exceptions when it calls closeWriter and closeReader. Contributed by Xuan Gong.\n",
      "commitDate": "06/09/17 2:53 PM",
      "commitName": "22de9449f8aa72c5b0bb586b8253390773502189",
      "commitAuthor": "Junping Du",
      "commitDateOld": "06/09/17 1:19 PM",
      "commitNameOld": "63231a2a3008794c5ebcbc9d3855638fc5f28216",
      "commitAuthorOld": "Junping Du",
      "daysBetweenCommits": 0.07,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,19 @@\n     public static void readAcontainerLogs(DataInputStream valueStream,\n         Writer writer, long logUploadedTime) throws IOException {\n       OutputStream os \u003d null;\n       PrintStream ps \u003d null;\n       try {\n         os \u003d new WriterOutputStream(writer, Charset.forName(\"UTF-8\"));\n         ps \u003d new PrintStream(os);\n         while (true) {\n           try {\n             readContainerLogs(valueStream, ps, logUploadedTime, Long.MAX_VALUE);\n           } catch (EOFException e) {\n             // EndOfFile\n             return;\n           }\n         }\n       } finally {\n-        IOUtils.closeQuietly(ps);\n-        IOUtils.closeQuietly(os);\n+        IOUtils.cleanupWithLogger(LOG, ps, os);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public static void readAcontainerLogs(DataInputStream valueStream,\n        Writer writer, long logUploadedTime) throws IOException {\n      OutputStream os \u003d null;\n      PrintStream ps \u003d null;\n      try {\n        os \u003d new WriterOutputStream(writer, Charset.forName(\"UTF-8\"));\n        ps \u003d new PrintStream(os);\n        while (true) {\n          try {\n            readContainerLogs(valueStream, ps, logUploadedTime, Long.MAX_VALUE);\n          } catch (EOFException e) {\n            // EndOfFile\n            return;\n          }\n        }\n      } finally {\n        IOUtils.cleanupWithLogger(LOG, ps, os);\n      }\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
      "extendedDetails": {}
    },
    "c2cb7ea1ef6532020b69031dbd18b0f9b8369f0f": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6876. Create an abstract log writer for extendability. Contributed by Xuan Gong.\n",
      "commitDate": "24/08/17 1:36 PM",
      "commitName": "c2cb7ea1ef6532020b69031dbd18b0f9b8369f0f",
      "commitAuthor": "Junping Du",
      "commitDateOld": "18/06/17 7:23 AM",
      "commitNameOld": "7582dedad1c73eabdc3eeece0a3a860e7bb33c1a",
      "commitAuthorOld": "Naganarasimha",
      "daysBetweenCommits": 67.26,
      "commitsBetweenForRepo": 421,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n     public static void readAcontainerLogs(DataInputStream valueStream,\n         Writer writer, long logUploadedTime) throws IOException {\n       OutputStream os \u003d null;\n       PrintStream ps \u003d null;\n       try {\n         os \u003d new WriterOutputStream(writer, Charset.forName(\"UTF-8\"));\n         ps \u003d new PrintStream(os);\n         while (true) {\n           try {\n             readContainerLogs(valueStream, ps, logUploadedTime, Long.MAX_VALUE);\n           } catch (EOFException e) {\n             // EndOfFile\n             return;\n           }\n         }\n       } finally {\n-        IOUtils.cleanup(LOG, ps);\n-        IOUtils.cleanup(LOG, os);\n+        IOUtils.closeQuietly(ps);\n+        IOUtils.closeQuietly(os);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public static void readAcontainerLogs(DataInputStream valueStream,\n        Writer writer, long logUploadedTime) throws IOException {\n      OutputStream os \u003d null;\n      PrintStream ps \u003d null;\n      try {\n        os \u003d new WriterOutputStream(writer, Charset.forName(\"UTF-8\"));\n        ps \u003d new PrintStream(os);\n        while (true) {\n          try {\n            readContainerLogs(valueStream, ps, logUploadedTime, Long.MAX_VALUE);\n          } catch (EOFException e) {\n            // EndOfFile\n            return;\n          }\n        }\n      } finally {\n        IOUtils.closeQuietly(ps);\n        IOUtils.closeQuietly(os);\n      }\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
      "extendedDetails": {}
    },
    "0bc05e40fa7e183efe8463ada459c621da3ce3bf": {
      "type": "Ybodychange",
      "commitMessage": "YARN-5088. Improve \"yarn log\" command-line to read the last K bytes for the log files. Contributed by Xuan Gong\n",
      "commitDate": "01/06/16 1:44 PM",
      "commitName": "0bc05e40fa7e183efe8463ada459c621da3ce3bf",
      "commitAuthor": "Xuan",
      "commitDateOld": "26/05/16 11:49 PM",
      "commitNameOld": "bde819abbbcea940cfa6426a9e4920e6c8dc9cf1",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 5.58,
      "commitsBetweenForRepo": 22,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n     public static void readAcontainerLogs(DataInputStream valueStream,\n         Writer writer, long logUploadedTime) throws IOException {\n       OutputStream os \u003d null;\n       PrintStream ps \u003d null;\n       try {\n         os \u003d new WriterOutputStream(writer, Charset.forName(\"UTF-8\"));\n         ps \u003d new PrintStream(os);\n         while (true) {\n           try {\n-            readContainerLogs(valueStream, ps, logUploadedTime);\n+            readContainerLogs(valueStream, ps, logUploadedTime, Long.MAX_VALUE);\n           } catch (EOFException e) {\n             // EndOfFile\n             return;\n           }\n         }\n       } finally {\n         IOUtils.cleanup(LOG, ps);\n         IOUtils.cleanup(LOG, os);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public static void readAcontainerLogs(DataInputStream valueStream,\n        Writer writer, long logUploadedTime) throws IOException {\n      OutputStream os \u003d null;\n      PrintStream ps \u003d null;\n      try {\n        os \u003d new WriterOutputStream(writer, Charset.forName(\"UTF-8\"));\n        ps \u003d new PrintStream(os);\n        while (true) {\n          try {\n            readContainerLogs(valueStream, ps, logUploadedTime, Long.MAX_VALUE);\n          } catch (EOFException e) {\n            // EndOfFile\n            return;\n          }\n        }\n      } finally {\n        IOUtils.cleanup(LOG, ps);\n        IOUtils.cleanup(LOG, os);\n      }\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
      "extendedDetails": {}
    },
    "a696fbb001b946ae75f3b8e962839c2fd3decfa1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2939. Fix new findbugs warnings in hadoop-yarn-common. (Li Lu via junping_du)\n",
      "commitDate": "22/12/14 3:06 AM",
      "commitName": "a696fbb001b946ae75f3b8e962839c2fd3decfa1",
      "commitAuthor": "Junping Du",
      "commitDateOld": "01/12/14 2:29 PM",
      "commitNameOld": "0f9528b99addbb0fd9a19d84db22a8c8e934b05f",
      "commitAuthorOld": "Jason Lowe",
      "daysBetweenCommits": 20.53,
      "commitsBetweenForRepo": 172,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,20 @@\n     public static void readAcontainerLogs(DataInputStream valueStream,\n         Writer writer, long logUploadedTime) throws IOException {\n       OutputStream os \u003d null;\n       PrintStream ps \u003d null;\n       try {\n-        os \u003d new WriterOutputStream(writer);\n+        os \u003d new WriterOutputStream(writer, Charset.forName(\"UTF-8\"));\n         ps \u003d new PrintStream(os);\n         while (true) {\n           try {\n             readContainerLogs(valueStream, ps, logUploadedTime);\n           } catch (EOFException e) {\n             // EndOfFile\n             return;\n           }\n         }\n       } finally {\n         IOUtils.cleanup(LOG, ps);\n         IOUtils.cleanup(LOG, os);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public static void readAcontainerLogs(DataInputStream valueStream,\n        Writer writer, long logUploadedTime) throws IOException {\n      OutputStream os \u003d null;\n      PrintStream ps \u003d null;\n      try {\n        os \u003d new WriterOutputStream(writer, Charset.forName(\"UTF-8\"));\n        ps \u003d new PrintStream(os);\n        while (true) {\n          try {\n            readContainerLogs(valueStream, ps, logUploadedTime);\n          } catch (EOFException e) {\n            // EndOfFile\n            return;\n          }\n        }\n      } finally {\n        IOUtils.cleanup(LOG, ps);\n        IOUtils.cleanup(LOG, os);\n      }\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
      "extendedDetails": {}
    },
    "58e9f24e0f06efede21085b7ffe36af042fa7b38": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "YARN-2788. Fixed backwards compatiblity issues with log-aggregation feature that were caused when adding log-upload-time via YARN-2703. Contributed by Xuan Gong.\n",
      "commitDate": "03/11/14 1:16 PM",
      "commitName": "58e9f24e0f06efede21085b7ffe36af042fa7b38",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "YARN-2788. Fixed backwards compatiblity issues with log-aggregation feature that were caused when adding log-upload-time via YARN-2703. Contributed by Xuan Gong.\n",
          "commitDate": "03/11/14 1:16 PM",
          "commitName": "58e9f24e0f06efede21085b7ffe36af042fa7b38",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "26/10/14 12:57 PM",
          "commitNameOld": "caecd9fffe7c6216be31f3ab65349182045451fa",
          "commitAuthorOld": "Zhijie Shen",
          "daysBetweenCommits": 8.05,
          "commitsBetweenForRepo": 84,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,20 @@\n     public static void readAcontainerLogs(DataInputStream valueStream,\n-        Writer writer) throws IOException {\n-      int bufferSize \u003d 65536;\n-      char[] cbuf \u003d new char[bufferSize];\n-      String fileType;\n-      long uploadTime;\n-      String fileLengthStr;\n-      long fileLength;\n-\n-      while (true) {\n-        try {\n-          fileType \u003d valueStream.readUTF();\n-        } catch (EOFException e) {\n-          // EndOfFile\n-          return;\n+        Writer writer, long logUploadedTime) throws IOException {\n+      OutputStream os \u003d null;\n+      PrintStream ps \u003d null;\n+      try {\n+        os \u003d new WriterOutputStream(writer);\n+        ps \u003d new PrintStream(os);\n+        while (true) {\n+          try {\n+            readContainerLogs(valueStream, ps, logUploadedTime);\n+          } catch (EOFException e) {\n+            // EndOfFile\n+            return;\n+          }\n         }\n-        uploadTime \u003d valueStream.readLong();\n-        fileLengthStr \u003d valueStream.readUTF();\n-        fileLength \u003d Long.parseLong(fileLengthStr);\n-        writer.write(\"\\n\\nLogType:\");\n-        writer.write(fileType);\n-        writer.write(\"\\nLogUploadTime:\");\n-        writer.write(String.valueOf(uploadTime));\n-        writer.write(\"\\nLogLength:\");\n-        writer.write(fileLengthStr);\n-        writer.write(\"\\nLog Contents:\\n\");\n-        // ByteLevel\n-        BoundedInputStream bis \u003d\n-            new BoundedInputStream(valueStream, fileLength);\n-        InputStreamReader reader \u003d new InputStreamReader(bis);\n-        int currentRead \u003d 0;\n-        int totalRead \u003d 0;\n-        while ((currentRead \u003d reader.read(cbuf, 0, bufferSize)) !\u003d -1) {\n-          writer.write(cbuf, 0, currentRead);\n-          totalRead +\u003d currentRead;\n-        }\n+      } finally {\n+        IOUtils.cleanup(LOG, ps);\n+        IOUtils.cleanup(LOG, os);\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    public static void readAcontainerLogs(DataInputStream valueStream,\n        Writer writer, long logUploadedTime) throws IOException {\n      OutputStream os \u003d null;\n      PrintStream ps \u003d null;\n      try {\n        os \u003d new WriterOutputStream(writer);\n        ps \u003d new PrintStream(os);\n        while (true) {\n          try {\n            readContainerLogs(valueStream, ps, logUploadedTime);\n          } catch (EOFException e) {\n            // EndOfFile\n            return;\n          }\n        }\n      } finally {\n        IOUtils.cleanup(LOG, ps);\n        IOUtils.cleanup(LOG, os);\n      }\n    }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
          "extendedDetails": {
            "oldValue": "[valueStream-DataInputStream, writer-Writer]",
            "newValue": "[valueStream-DataInputStream, writer-Writer, logUploadedTime-long]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-2788. Fixed backwards compatiblity issues with log-aggregation feature that were caused when adding log-upload-time via YARN-2703. Contributed by Xuan Gong.\n",
          "commitDate": "03/11/14 1:16 PM",
          "commitName": "58e9f24e0f06efede21085b7ffe36af042fa7b38",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "26/10/14 12:57 PM",
          "commitNameOld": "caecd9fffe7c6216be31f3ab65349182045451fa",
          "commitAuthorOld": "Zhijie Shen",
          "daysBetweenCommits": 8.05,
          "commitsBetweenForRepo": 84,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,38 +1,20 @@\n     public static void readAcontainerLogs(DataInputStream valueStream,\n-        Writer writer) throws IOException {\n-      int bufferSize \u003d 65536;\n-      char[] cbuf \u003d new char[bufferSize];\n-      String fileType;\n-      long uploadTime;\n-      String fileLengthStr;\n-      long fileLength;\n-\n-      while (true) {\n-        try {\n-          fileType \u003d valueStream.readUTF();\n-        } catch (EOFException e) {\n-          // EndOfFile\n-          return;\n+        Writer writer, long logUploadedTime) throws IOException {\n+      OutputStream os \u003d null;\n+      PrintStream ps \u003d null;\n+      try {\n+        os \u003d new WriterOutputStream(writer);\n+        ps \u003d new PrintStream(os);\n+        while (true) {\n+          try {\n+            readContainerLogs(valueStream, ps, logUploadedTime);\n+          } catch (EOFException e) {\n+            // EndOfFile\n+            return;\n+          }\n         }\n-        uploadTime \u003d valueStream.readLong();\n-        fileLengthStr \u003d valueStream.readUTF();\n-        fileLength \u003d Long.parseLong(fileLengthStr);\n-        writer.write(\"\\n\\nLogType:\");\n-        writer.write(fileType);\n-        writer.write(\"\\nLogUploadTime:\");\n-        writer.write(String.valueOf(uploadTime));\n-        writer.write(\"\\nLogLength:\");\n-        writer.write(fileLengthStr);\n-        writer.write(\"\\nLog Contents:\\n\");\n-        // ByteLevel\n-        BoundedInputStream bis \u003d\n-            new BoundedInputStream(valueStream, fileLength);\n-        InputStreamReader reader \u003d new InputStreamReader(bis);\n-        int currentRead \u003d 0;\n-        int totalRead \u003d 0;\n-        while ((currentRead \u003d reader.read(cbuf, 0, bufferSize)) !\u003d -1) {\n-          writer.write(cbuf, 0, currentRead);\n-          totalRead +\u003d currentRead;\n-        }\n+      } finally {\n+        IOUtils.cleanup(LOG, ps);\n+        IOUtils.cleanup(LOG, os);\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    public static void readAcontainerLogs(DataInputStream valueStream,\n        Writer writer, long logUploadedTime) throws IOException {\n      OutputStream os \u003d null;\n      PrintStream ps \u003d null;\n      try {\n        os \u003d new WriterOutputStream(writer);\n        ps \u003d new PrintStream(os);\n        while (true) {\n          try {\n            readContainerLogs(valueStream, ps, logUploadedTime);\n          } catch (EOFException e) {\n            // EndOfFile\n            return;\n          }\n        }\n      } finally {\n        IOUtils.cleanup(LOG, ps);\n        IOUtils.cleanup(LOG, os);\n      }\n    }",
          "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
          "extendedDetails": {}
        }
      ]
    },
    "f81dc3f995579c1b94b11d60e9fc6da56c8a9496": {
      "type": "Ybodychange",
      "commitMessage": "YARN-2703. Added logUploadedTime into LogValue for better display. Contributed by Xuan Gong.\n",
      "commitDate": "24/10/14 2:10 PM",
      "commitName": "f81dc3f995579c1b94b11d60e9fc6da56c8a9496",
      "commitAuthor": "Zhijie Shen",
      "commitDateOld": "24/10/14 11:13 AM",
      "commitNameOld": "e31f0a6558b106662c83e1f797216e412b6689a9",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 0.12,
      "commitsBetweenForRepo": 6,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,38 @@\n     public static void readAcontainerLogs(DataInputStream valueStream,\n         Writer writer) throws IOException {\n       int bufferSize \u003d 65536;\n       char[] cbuf \u003d new char[bufferSize];\n       String fileType;\n+      long uploadTime;\n       String fileLengthStr;\n       long fileLength;\n \n       while (true) {\n         try {\n           fileType \u003d valueStream.readUTF();\n         } catch (EOFException e) {\n           // EndOfFile\n           return;\n         }\n+        uploadTime \u003d valueStream.readLong();\n         fileLengthStr \u003d valueStream.readUTF();\n         fileLength \u003d Long.parseLong(fileLengthStr);\n         writer.write(\"\\n\\nLogType:\");\n         writer.write(fileType);\n+        writer.write(\"\\nLogUploadTime:\");\n+        writer.write(String.valueOf(uploadTime));\n         writer.write(\"\\nLogLength:\");\n         writer.write(fileLengthStr);\n         writer.write(\"\\nLog Contents:\\n\");\n         // ByteLevel\n         BoundedInputStream bis \u003d\n             new BoundedInputStream(valueStream, fileLength);\n         InputStreamReader reader \u003d new InputStreamReader(bis);\n         int currentRead \u003d 0;\n         int totalRead \u003d 0;\n         while ((currentRead \u003d reader.read(cbuf, 0, bufferSize)) !\u003d -1) {\n           writer.write(cbuf, 0, currentRead);\n           totalRead +\u003d currentRead;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public static void readAcontainerLogs(DataInputStream valueStream,\n        Writer writer) throws IOException {\n      int bufferSize \u003d 65536;\n      char[] cbuf \u003d new char[bufferSize];\n      String fileType;\n      long uploadTime;\n      String fileLengthStr;\n      long fileLength;\n\n      while (true) {\n        try {\n          fileType \u003d valueStream.readUTF();\n        } catch (EOFException e) {\n          // EndOfFile\n          return;\n        }\n        uploadTime \u003d valueStream.readLong();\n        fileLengthStr \u003d valueStream.readUTF();\n        fileLength \u003d Long.parseLong(fileLengthStr);\n        writer.write(\"\\n\\nLogType:\");\n        writer.write(fileType);\n        writer.write(\"\\nLogUploadTime:\");\n        writer.write(String.valueOf(uploadTime));\n        writer.write(\"\\nLogLength:\");\n        writer.write(fileLengthStr);\n        writer.write(\"\\nLog Contents:\\n\");\n        // ByteLevel\n        BoundedInputStream bis \u003d\n            new BoundedInputStream(valueStream, fileLength);\n        InputStreamReader reader \u003d new InputStreamReader(bis);\n        int currentRead \u003d 0;\n        int totalRead \u003d 0;\n        while ((currentRead \u003d reader.read(cbuf, 0, bufferSize)) !\u003d -1) {\n          writer.write(cbuf, 0, currentRead);\n          totalRead +\u003d currentRead;\n        }\n      }\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
      "extendedDetails": {}
    },
    "e1fdf62123625e4ba399af02f8aad500637d29d1": {
      "type": "Yfilerename",
      "commitMessage": "YARN-1. Promote YARN to be a sub-project of Apache Hadoop.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1370666 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/08/12 10:22 PM",
      "commitName": "e1fdf62123625e4ba399af02f8aad500637d29d1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "07/08/12 7:53 PM",
      "commitNameOld": "34554d1e11ee1d5b564d7d9ed3e6d55931d72749",
      "commitAuthorOld": "Aaron Myers",
      "daysBetweenCommits": 0.1,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public static void readAcontainerLogs(DataInputStream valueStream,\n        Writer writer) throws IOException {\n      int bufferSize \u003d 65536;\n      char[] cbuf \u003d new char[bufferSize];\n      String fileType;\n      String fileLengthStr;\n      long fileLength;\n\n      while (true) {\n        try {\n          fileType \u003d valueStream.readUTF();\n        } catch (EOFException e) {\n          // EndOfFile\n          return;\n        }\n        fileLengthStr \u003d valueStream.readUTF();\n        fileLength \u003d Long.parseLong(fileLengthStr);\n        writer.write(\"\\n\\nLogType:\");\n        writer.write(fileType);\n        writer.write(\"\\nLogLength:\");\n        writer.write(fileLengthStr);\n        writer.write(\"\\nLog Contents:\\n\");\n        // ByteLevel\n        BoundedInputStream bis \u003d\n            new BoundedInputStream(valueStream, fileLength);\n        InputStreamReader reader \u003d new InputStreamReader(bis);\n        int currentRead \u003d 0;\n        int totalRead \u003d 0;\n        while ((currentRead \u003d reader.read(cbuf, 0, bufferSize)) !\u003d -1) {\n          writer.write(cbuf, 0, currentRead);\n          totalRead +\u003d currentRead;\n        }\n      }\n    }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
        "newPath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java"
      }
    },
    "f58e3c8b121859194185fa12bfbd0ff57e6bcc7f": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-4006. History server container log web UI sometimes combines stderr/stdout/syslog contents together (Siddharth Seth via tgraves)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1301731 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/03/12 1:10 PM",
      "commitName": "f58e3c8b121859194185fa12bfbd0ff57e6bcc7f",
      "commitAuthor": "Thomas Graves",
      "commitDateOld": "29/11/11 3:17 PM",
      "commitNameOld": "ea17da82f7fc4b7fcc05bba82d141e27289fd7cb",
      "commitAuthorOld": "Mahadev Konar",
      "daysBetweenCommits": 107.87,
      "commitsBetweenForRepo": 781,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,34 @@\n     public static void readAcontainerLogs(DataInputStream valueStream,\n         Writer writer) throws IOException {\n       int bufferSize \u003d 65536;\n       char[] cbuf \u003d new char[bufferSize];\n       String fileType;\n       String fileLengthStr;\n       long fileLength;\n \n       while (true) {\n         try {\n           fileType \u003d valueStream.readUTF();\n         } catch (EOFException e) {\n           // EndOfFile\n           return;\n         }\n         fileLengthStr \u003d valueStream.readUTF();\n         fileLength \u003d Long.parseLong(fileLengthStr);\n         writer.write(\"\\n\\nLogType:\");\n         writer.write(fileType);\n         writer.write(\"\\nLogLength:\");\n         writer.write(fileLengthStr);\n         writer.write(\"\\nLog Contents:\\n\");\n         // ByteLevel\n         BoundedInputStream bis \u003d\n             new BoundedInputStream(valueStream, fileLength);\n         InputStreamReader reader \u003d new InputStreamReader(bis);\n         int currentRead \u003d 0;\n         int totalRead \u003d 0;\n         while ((currentRead \u003d reader.read(cbuf, 0, bufferSize)) !\u003d -1) {\n-          writer.write(cbuf);\n+          writer.write(cbuf, 0, currentRead);\n           totalRead +\u003d currentRead;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public static void readAcontainerLogs(DataInputStream valueStream,\n        Writer writer) throws IOException {\n      int bufferSize \u003d 65536;\n      char[] cbuf \u003d new char[bufferSize];\n      String fileType;\n      String fileLengthStr;\n      long fileLength;\n\n      while (true) {\n        try {\n          fileType \u003d valueStream.readUTF();\n        } catch (EOFException e) {\n          // EndOfFile\n          return;\n        }\n        fileLengthStr \u003d valueStream.readUTF();\n        fileLength \u003d Long.parseLong(fileLengthStr);\n        writer.write(\"\\n\\nLogType:\");\n        writer.write(fileType);\n        writer.write(\"\\nLogLength:\");\n        writer.write(fileLengthStr);\n        writer.write(\"\\nLog Contents:\\n\");\n        // ByteLevel\n        BoundedInputStream bis \u003d\n            new BoundedInputStream(valueStream, fileLength);\n        InputStreamReader reader \u003d new InputStreamReader(bis);\n        int currentRead \u003d 0;\n        int totalRead \u003d 0;\n        while ((currentRead \u003d reader.read(cbuf, 0, bufferSize)) !\u003d -1) {\n          writer.write(cbuf, 0, currentRead);\n          totalRead +\u003d currentRead;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
      "extendedDetails": {}
    },
    "c27601fefebd0af887a12d684bfc6f90d9fc0321": {
      "type": "Yfilerename",
      "commitMessage": "MAPREDUCE-3297. Moved log related components into yarn-common so that HistoryServer and clients can use them without depending on the yarn-server-nodemanager module. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1196986 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/11/11 1:02 AM",
      "commitName": "c27601fefebd0af887a12d684bfc6f90d9fc0321",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "03/11/11 12:06 AM",
      "commitNameOld": "0df4878033b797b9313c887ca9d75f8ea104d029",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "    public static void readAcontainerLogs(DataInputStream valueStream,\n        Writer writer) throws IOException {\n      int bufferSize \u003d 65536;\n      char[] cbuf \u003d new char[bufferSize];\n      String fileType;\n      String fileLengthStr;\n      long fileLength;\n\n      while (true) {\n        try {\n          fileType \u003d valueStream.readUTF();\n        } catch (EOFException e) {\n          // EndOfFile\n          return;\n        }\n        fileLengthStr \u003d valueStream.readUTF();\n        fileLength \u003d Long.parseLong(fileLengthStr);\n        writer.write(\"\\n\\nLogType:\");\n        writer.write(fileType);\n        writer.write(\"\\nLogLength:\");\n        writer.write(fileLengthStr);\n        writer.write(\"\\nLog Contents:\\n\");\n        // ByteLevel\n        BoundedInputStream bis \u003d\n            new BoundedInputStream(valueStream, fileLength);\n        InputStreamReader reader \u003d new InputStreamReader(bis);\n        int currentRead \u003d 0;\n        int totalRead \u003d 0;\n        while ((currentRead \u003d reader.read(cbuf, 0, bufferSize)) !\u003d -1) {\n          writer.write(cbuf);\n          totalRead +\u003d currentRead;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/AggregatedLogFormat.java",
        "newPath": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/AggregatedLogFormat.java"
      }
    },
    "670fa24b48acb407c22fbfdde87ae3123dcbf449": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-2989. Modified JobHistory to link to task and AM logs from the JobHistoryServer. Contributed by Siddharth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1190174 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/10/11 11:45 PM",
      "commitName": "670fa24b48acb407c22fbfdde87ae3123dcbf449",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,34 @@\n+    public static void readAcontainerLogs(DataInputStream valueStream,\n+        Writer writer) throws IOException {\n+      int bufferSize \u003d 65536;\n+      char[] cbuf \u003d new char[bufferSize];\n+      String fileType;\n+      String fileLengthStr;\n+      long fileLength;\n+\n+      while (true) {\n+        try {\n+          fileType \u003d valueStream.readUTF();\n+        } catch (EOFException e) {\n+          // EndOfFile\n+          return;\n+        }\n+        fileLengthStr \u003d valueStream.readUTF();\n+        fileLength \u003d Long.parseLong(fileLengthStr);\n+        writer.write(\"\\n\\nLogType:\");\n+        writer.write(fileType);\n+        writer.write(\"\\nLogLength:\");\n+        writer.write(fileLengthStr);\n+        writer.write(\"\\nLog Contents:\\n\");\n+        // ByteLevel\n+        BoundedInputStream bis \u003d\n+            new BoundedInputStream(valueStream, fileLength);\n+        InputStreamReader reader \u003d new InputStreamReader(bis);\n+        int currentRead \u003d 0;\n+        int totalRead \u003d 0;\n+        while ((currentRead \u003d reader.read(cbuf, 0, bufferSize)) !\u003d -1) {\n+          writer.write(cbuf);\n+          totalRead +\u003d currentRead;\n+        }\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public static void readAcontainerLogs(DataInputStream valueStream,\n        Writer writer) throws IOException {\n      int bufferSize \u003d 65536;\n      char[] cbuf \u003d new char[bufferSize];\n      String fileType;\n      String fileLengthStr;\n      long fileLength;\n\n      while (true) {\n        try {\n          fileType \u003d valueStream.readUTF();\n        } catch (EOFException e) {\n          // EndOfFile\n          return;\n        }\n        fileLengthStr \u003d valueStream.readUTF();\n        fileLength \u003d Long.parseLong(fileLengthStr);\n        writer.write(\"\\n\\nLogType:\");\n        writer.write(fileType);\n        writer.write(\"\\nLogLength:\");\n        writer.write(fileLengthStr);\n        writer.write(\"\\nLog Contents:\\n\");\n        // ByteLevel\n        BoundedInputStream bis \u003d\n            new BoundedInputStream(valueStream, fileLength);\n        InputStreamReader reader \u003d new InputStreamReader(bis);\n        int currentRead \u003d 0;\n        int totalRead \u003d 0;\n        while ((currentRead \u003d reader.read(cbuf, 0, bufferSize)) !\u003d -1) {\n          writer.write(cbuf);\n          totalRead +\u003d currentRead;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/AggregatedLogFormat.java"
    }
  }
}