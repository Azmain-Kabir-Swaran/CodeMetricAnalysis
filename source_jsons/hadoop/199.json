{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "OpenFileCtx.java",
  "functionName": "alterWriteRequest",
  "functionId": "alterWriteRequest___request-WRITE3Request__cachedOffset-long",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
  "functionStartLine": 471,
  "functionEndLine": 490,
  "numCommitsSeen": 36,
  "timeTaken": 1634,
  "changeHistory": [
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
    "151fca5032719e561226ef278e002739073c23ec",
    "caa4abd30cfc4361c7bc9f212a9092840d7c3b53"
  ],
  "changeHistoryShort": {
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": "Ybodychange",
    "151fca5032719e561226ef278e002739073c23ec": "Ybodychange",
    "caa4abd30cfc4361c7bc9f212a9092840d7c3b53": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f20dc0d5770d3876954faf0a6e8dcce6539ffc23": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-10571. Use Log.*(Object, Throwable) overload to log exceptions.\nContributed by Andras Bokor.\n",
      "commitDate": "14/02/18 8:20 AM",
      "commitName": "f20dc0d5770d3876954faf0a6e8dcce6539ffc23",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "10/10/17 10:38 AM",
      "commitNameOld": "d6602b5f39833611b4afa4581552f6c4c37e23a8",
      "commitAuthorOld": "Jitendra Pandey",
      "daysBetweenCommits": 126.95,
      "commitsBetweenForRepo": 833,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,20 @@\n   public static void alterWriteRequest(WRITE3Request request, long cachedOffset) {\n     long offset \u003d request.getOffset();\n     int count \u003d request.getCount();\n     long smallerCount \u003d offset + count - cachedOffset;\n-    if (LOG.isDebugEnabled()) {\n-      LOG.debug(String.format(\"Got overwrite with appended data [%d-%d),\"\n-          + \" current offset %d,\" + \" drop the overlapped section [%d-%d)\"\n-          + \" and append new data [%d-%d).\", offset, (offset + count),\n-          cachedOffset, offset, cachedOffset, cachedOffset, (offset\n-              + count)));\n-    }\n+    LOG.debug(\"Got overwrite with appended data [{}-{}),\"\n+            + \" current offset {},\" + \" drop the overlapped section [{}-{})\"\n+            + \" and append new data [{}-{}).\", offset, (offset + count),\n+            cachedOffset, offset, cachedOffset, cachedOffset,\n+        (offset + count));\n     \n     ByteBuffer data \u003d request.getData();\n     Preconditions.checkState(data.position() \u003d\u003d 0,\n         \"The write request data has non-zero position\");\n     data.position((int) (cachedOffset - offset));\n     Preconditions.checkState(data.limit() - data.position() \u003d\u003d smallerCount,\n         \"The write request buffer has wrong limit/position regarding count\");\n     \n     request.setOffset(cachedOffset);\n     request.setCount((int) smallerCount);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void alterWriteRequest(WRITE3Request request, long cachedOffset) {\n    long offset \u003d request.getOffset();\n    int count \u003d request.getCount();\n    long smallerCount \u003d offset + count - cachedOffset;\n    LOG.debug(\"Got overwrite with appended data [{}-{}),\"\n            + \" current offset {},\" + \" drop the overlapped section [{}-{})\"\n            + \" and append new data [{}-{}).\", offset, (offset + count),\n            cachedOffset, offset, cachedOffset, cachedOffset,\n        (offset + count));\n    \n    ByteBuffer data \u003d request.getData();\n    Preconditions.checkState(data.position() \u003d\u003d 0,\n        \"The write request data has non-zero position\");\n    data.position((int) (cachedOffset - offset));\n    Preconditions.checkState(data.limit() - data.position() \u003d\u003d smallerCount,\n        \"The write request buffer has wrong limit/position regarding count\");\n    \n    request.setOffset(cachedOffset);\n    request.setCount((int) smallerCount);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "151fca5032719e561226ef278e002739073c23ec": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9092. Nfs silently drops overlapping write requests and causes data copying to fail. Contributed by Yongjun Zhang.\n",
      "commitDate": "28/09/15 6:45 PM",
      "commitName": "151fca5032719e561226ef278e002739073c23ec",
      "commitAuthor": "Yongjun Zhang",
      "commitDateOld": "28/01/15 12:56 PM",
      "commitNameOld": "f37849188b05a6251584de1aed5e66d5dfa7da4f",
      "commitAuthorOld": "yliu",
      "daysBetweenCommits": 243.2,
      "commitsBetweenForRepo": 1923,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   public static void alterWriteRequest(WRITE3Request request, long cachedOffset) {\n     long offset \u003d request.getOffset();\n     int count \u003d request.getCount();\n     long smallerCount \u003d offset + count - cachedOffset;\n     if (LOG.isDebugEnabled()) {\n-      LOG.debug(String.format(\"Got overwrite with appended data (%d-%d),\"\n-          + \" current offset %d,\" + \" drop the overlapped section (%d-%d)\"\n-          + \" and append new data (%d-%d).\", offset, (offset + count - 1),\n-          cachedOffset, offset, (cachedOffset - 1), cachedOffset, (offset\n-              + count - 1)));\n+      LOG.debug(String.format(\"Got overwrite with appended data [%d-%d),\"\n+          + \" current offset %d,\" + \" drop the overlapped section [%d-%d)\"\n+          + \" and append new data [%d-%d).\", offset, (offset + count),\n+          cachedOffset, offset, cachedOffset, cachedOffset, (offset\n+              + count)));\n     }\n     \n     ByteBuffer data \u003d request.getData();\n     Preconditions.checkState(data.position() \u003d\u003d 0,\n         \"The write request data has non-zero position\");\n     data.position((int) (cachedOffset - offset));\n     Preconditions.checkState(data.limit() - data.position() \u003d\u003d smallerCount,\n         \"The write request buffer has wrong limit/position regarding count\");\n     \n     request.setOffset(cachedOffset);\n     request.setCount((int) smallerCount);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static void alterWriteRequest(WRITE3Request request, long cachedOffset) {\n    long offset \u003d request.getOffset();\n    int count \u003d request.getCount();\n    long smallerCount \u003d offset + count - cachedOffset;\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(String.format(\"Got overwrite with appended data [%d-%d),\"\n          + \" current offset %d,\" + \" drop the overlapped section [%d-%d)\"\n          + \" and append new data [%d-%d).\", offset, (offset + count),\n          cachedOffset, offset, cachedOffset, cachedOffset, (offset\n              + count)));\n    }\n    \n    ByteBuffer data \u003d request.getData();\n    Preconditions.checkState(data.position() \u003d\u003d 0,\n        \"The write request data has non-zero position\");\n    data.position((int) (cachedOffset - offset));\n    Preconditions.checkState(data.limit() - data.position() \u003d\u003d smallerCount,\n        \"The write request buffer has wrong limit/position regarding count\");\n    \n    request.setOffset(cachedOffset);\n    request.setCount((int) smallerCount);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java",
      "extendedDetails": {}
    },
    "caa4abd30cfc4361c7bc9f212a9092840d7c3b53": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5259. Support client which combines appended data with old data before sends it to NFS server. Contributed by Brandon Li\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1529730 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/10/13 7:57 PM",
      "commitName": "caa4abd30cfc4361c7bc9f212a9092840d7c3b53",
      "commitAuthor": "Brandon Li",
      "diff": "@@ -0,0 +1,22 @@\n+  public static void alterWriteRequest(WRITE3Request request, long cachedOffset) {\n+    long offset \u003d request.getOffset();\n+    int count \u003d request.getCount();\n+    long smallerCount \u003d offset + count - cachedOffset;\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(String.format(\"Got overwrite with appended data (%d-%d),\"\n+          + \" current offset %d,\" + \" drop the overlapped section (%d-%d)\"\n+          + \" and append new data (%d-%d).\", offset, (offset + count - 1),\n+          cachedOffset, offset, (cachedOffset - 1), cachedOffset, (offset\n+              + count - 1)));\n+    }\n+    \n+    ByteBuffer data \u003d request.getData();\n+    Preconditions.checkState(data.position() \u003d\u003d 0,\n+        \"The write request data has non-zero position\");\n+    data.position((int) (cachedOffset - offset));\n+    Preconditions.checkState(data.limit() - data.position() \u003d\u003d smallerCount,\n+        \"The write request buffer has wrong limit/position regarding count\");\n+    \n+    request.setOffset(cachedOffset);\n+    request.setCount((int) smallerCount);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static void alterWriteRequest(WRITE3Request request, long cachedOffset) {\n    long offset \u003d request.getOffset();\n    int count \u003d request.getCount();\n    long smallerCount \u003d offset + count - cachedOffset;\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(String.format(\"Got overwrite with appended data (%d-%d),\"\n          + \" current offset %d,\" + \" drop the overlapped section (%d-%d)\"\n          + \" and append new data (%d-%d).\", offset, (offset + count - 1),\n          cachedOffset, offset, (cachedOffset - 1), cachedOffset, (offset\n              + count - 1)));\n    }\n    \n    ByteBuffer data \u003d request.getData();\n    Preconditions.checkState(data.position() \u003d\u003d 0,\n        \"The write request data has non-zero position\");\n    data.position((int) (cachedOffset - offset));\n    Preconditions.checkState(data.limit() - data.position() \u003d\u003d smallerCount,\n        \"The write request buffer has wrong limit/position regarding count\");\n    \n    request.setOffset(cachedOffset);\n    request.setCount((int) smallerCount);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-nfs/src/main/java/org/apache/hadoop/hdfs/nfs/nfs3/OpenFileCtx.java"
    }
  }
}