{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "CosNOutputStream.java",
  "functionName": "close",
  "functionId": "close",
  "sourceFilePath": "hadoop-cloud-storage-project/hadoop-cos/src/main/java/org/apache/hadoop/fs/cosn/CosNOutputStream.java",
  "functionStartLine": 122,
  "functionEndLine": 165,
  "numCommitsSeen": 1,
  "timeTaken": 347,
  "changeHistory": [
    "8a9ede5cff816b66afc37e7c9d2b33aee48795d2"
  ],
  "changeHistoryShort": {
    "8a9ede5cff816b66afc37e7c9d2b33aee48795d2": "Yintroduced"
  },
  "changeHistoryDetails": {
    "8a9ede5cff816b66afc37e7c9d2b33aee48795d2": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-15616. Incorporate Tencent Cloud COS File System Implementation. Contributed by Yang Yu.\n",
      "commitDate": "27/09/19 1:53 AM",
      "commitName": "8a9ede5cff816b66afc37e7c9d2b33aee48795d2",
      "commitAuthor": "Sammi Chen",
      "diff": "@@ -0,0 +1,44 @@\n+  public synchronized void close() throws IOException {\n+    if (this.closed) {\n+      return;\n+    }\n+    this.currentBlockOutputStream.flush();\n+    this.currentBlockOutputStream.close();\n+    LOG.info(\"The output stream has been close, and \"\n+        + \"begin to upload the last block: [{}].\", this.currentBlockId);\n+    this.blockCacheBuffers.add(this.currentBlockBuffer);\n+    if (this.blockCacheBuffers.size() \u003d\u003d 1) {\n+      byte[] md5Hash \u003d this.digest \u003d\u003d null ? null : this.digest.digest();\n+      store.storeFile(this.key,\n+          new ByteBufferInputStream(this.currentBlockBuffer.getByteBuffer()),\n+          md5Hash, this.currentBlockBuffer.getByteBuffer().remaining());\n+    } else {\n+      PartETag partETag \u003d null;\n+      if (this.blockWritten \u003e 0) {\n+        LOG.info(\"Upload the last part..., blockId: [{}], written bytes: [{}]\",\n+            this.currentBlockId, this.blockWritten);\n+        partETag \u003d store.uploadPart(\n+            new ByteBufferInputStream(currentBlockBuffer.getByteBuffer()),\n+            key, uploadId, currentBlockId + 1,\n+            currentBlockBuffer.getByteBuffer().remaining());\n+      }\n+      final List\u003cPartETag\u003e futurePartETagList \u003d this.waitForFinishPartUploads();\n+      if (null \u003d\u003d futurePartETagList) {\n+        throw new IOException(\"Failed to multipart upload to cos, abort it.\");\n+      }\n+      List\u003cPartETag\u003e tmpPartEtagList \u003d new LinkedList\u003c\u003e(futurePartETagList);\n+      if (null !\u003d partETag) {\n+        tmpPartEtagList.add(partETag);\n+      }\n+      store.completeMultipartUpload(this.key, this.uploadId, tmpPartEtagList);\n+    }\n+    try {\n+      BufferPool.getInstance().returnBuffer(this.currentBlockBuffer);\n+    } catch (InterruptedException e) {\n+      LOG.error(\"An exception occurred \"\n+          + \"while returning the buffer to the buffer pool.\", e);\n+    }\n+    LOG.info(\"The outputStream for key: [{}] has been uploaded.\", key);\n+    this.blockWritten \u003d 0;\n+    this.closed \u003d true;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public synchronized void close() throws IOException {\n    if (this.closed) {\n      return;\n    }\n    this.currentBlockOutputStream.flush();\n    this.currentBlockOutputStream.close();\n    LOG.info(\"The output stream has been close, and \"\n        + \"begin to upload the last block: [{}].\", this.currentBlockId);\n    this.blockCacheBuffers.add(this.currentBlockBuffer);\n    if (this.blockCacheBuffers.size() \u003d\u003d 1) {\n      byte[] md5Hash \u003d this.digest \u003d\u003d null ? null : this.digest.digest();\n      store.storeFile(this.key,\n          new ByteBufferInputStream(this.currentBlockBuffer.getByteBuffer()),\n          md5Hash, this.currentBlockBuffer.getByteBuffer().remaining());\n    } else {\n      PartETag partETag \u003d null;\n      if (this.blockWritten \u003e 0) {\n        LOG.info(\"Upload the last part..., blockId: [{}], written bytes: [{}]\",\n            this.currentBlockId, this.blockWritten);\n        partETag \u003d store.uploadPart(\n            new ByteBufferInputStream(currentBlockBuffer.getByteBuffer()),\n            key, uploadId, currentBlockId + 1,\n            currentBlockBuffer.getByteBuffer().remaining());\n      }\n      final List\u003cPartETag\u003e futurePartETagList \u003d this.waitForFinishPartUploads();\n      if (null \u003d\u003d futurePartETagList) {\n        throw new IOException(\"Failed to multipart upload to cos, abort it.\");\n      }\n      List\u003cPartETag\u003e tmpPartEtagList \u003d new LinkedList\u003c\u003e(futurePartETagList);\n      if (null !\u003d partETag) {\n        tmpPartEtagList.add(partETag);\n      }\n      store.completeMultipartUpload(this.key, this.uploadId, tmpPartEtagList);\n    }\n    try {\n      BufferPool.getInstance().returnBuffer(this.currentBlockBuffer);\n    } catch (InterruptedException e) {\n      LOG.error(\"An exception occurred \"\n          + \"while returning the buffer to the buffer pool.\", e);\n    }\n    LOG.info(\"The outputStream for key: [{}] has been uploaded.\", key);\n    this.blockWritten \u003d 0;\n    this.closed \u003d true;\n  }",
      "path": "hadoop-cloud-storage-project/hadoop-cos/src/main/java/org/apache/hadoop/fs/cosn/CosNOutputStream.java"
    }
  }
}