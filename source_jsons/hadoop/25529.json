{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "YarnChild.java",
  "functionName": "reportError",
  "functionId": "reportError___exception-Exception__task-Task__umbilical-TaskUmbilicalProtocol",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java",
  "functionStartLine": 235,
  "functionEndLine": 253,
  "numCommitsSeen": 32,
  "timeTaken": 1378,
  "changeHistory": [
    "0b6625a9735f76ab473b41d8ab9b7f3c7678cfff"
  ],
  "changeHistoryShort": {
    "0b6625a9735f76ab473b41d8ab9b7f3c7678cfff": "Yintroduced"
  },
  "changeHistoryDetails": {
    "0b6625a9735f76ab473b41d8ab9b7f3c7678cfff": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-7148. Fast fail jobs when exceeds dfs quota limitation. Contributed by Wang Yan\n",
      "commitDate": "07/11/18 6:20 AM",
      "commitName": "0b6625a9735f76ab473b41d8ab9b7f3c7678cfff",
      "commitAuthor": "Jason Lowe",
      "diff": "@@ -0,0 +1,19 @@\n+  static void reportError(Exception exception, Task task,\n+      TaskUmbilicalProtocol umbilical) throws IOException {\n+    boolean fastFailJob \u003d false;\n+    boolean hasClusterStorageCapacityExceededException \u003d\n+        ExceptionUtils.indexOfType(exception,\n+            ClusterStorageCapacityExceededException.class) !\u003d -1;\n+    if (hasClusterStorageCapacityExceededException) {\n+      boolean killJobWhenExceedClusterStorageCapacity \u003d task.getConf()\n+          .getBoolean(MRJobConfig.JOB_DFS_STORAGE_CAPACITY_KILL_LIMIT_EXCEED,\n+              MRJobConfig.DEFAULT_JOB_DFS_STORAGE_CAPACITY_KILL_LIMIT_EXCEED);\n+      if (killJobWhenExceedClusterStorageCapacity) {\n+        LOG.error(\n+            \"Fast fail the job because the cluster storage capacity was exceeded.\");\n+        fastFailJob \u003d true;\n+      }\n+    }\n+    umbilical.fatalError(taskid, StringUtils.stringifyException(exception),\n+        fastFailJob);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static void reportError(Exception exception, Task task,\n      TaskUmbilicalProtocol umbilical) throws IOException {\n    boolean fastFailJob \u003d false;\n    boolean hasClusterStorageCapacityExceededException \u003d\n        ExceptionUtils.indexOfType(exception,\n            ClusterStorageCapacityExceededException.class) !\u003d -1;\n    if (hasClusterStorageCapacityExceededException) {\n      boolean killJobWhenExceedClusterStorageCapacity \u003d task.getConf()\n          .getBoolean(MRJobConfig.JOB_DFS_STORAGE_CAPACITY_KILL_LIMIT_EXCEED,\n              MRJobConfig.DEFAULT_JOB_DFS_STORAGE_CAPACITY_KILL_LIMIT_EXCEED);\n      if (killJobWhenExceedClusterStorageCapacity) {\n        LOG.error(\n            \"Fast fail the job because the cluster storage capacity was exceeded.\");\n        fastFailJob \u003d true;\n      }\n    }\n    umbilical.fatalError(taskid, StringUtils.stringifyException(exception),\n        fastFailJob);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java"
    }
  }
}