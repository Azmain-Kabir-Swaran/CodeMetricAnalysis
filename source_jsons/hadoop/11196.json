{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HostRestrictingAuthorizationFilterHandler.java",
  "functionName": "initializeState",
  "functionId": "initializeState___conf-Configuration",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/HostRestrictingAuthorizationFilterHandler.java",
  "functionStartLine": 113,
  "functionEndLine": 135,
  "numCommitsSeen": 1,
  "timeTaken": 783,
  "changeHistory": [
    "101d5b5f865f94e4772051ea8ce4ee0f92ddedca"
  ],
  "changeHistoryShort": {
    "101d5b5f865f94e4772051ea8ce4ee0f92ddedca": "Yintroduced"
  },
  "changeHistoryDetails": {
    "101d5b5f865f94e4772051ea8ce4ee0f92ddedca": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-14234. Limit WebHDFS to specifc user, host, directory triples.\nContributed by Clay B.\n",
      "commitDate": "10/06/19 5:55 PM",
      "commitName": "101d5b5f865f94e4772051ea8ce4ee0f92ddedca",
      "commitAuthor": "Anu Engineer",
      "diff": "@@ -0,0 +1,23 @@\n+  initializeState(Configuration conf) {\n+    String confName \u003d HostRestrictingAuthorizationFilter.HDFS_CONFIG_PREFIX +\n+        HostRestrictingAuthorizationFilter.RESTRICTION_CONFIG;\n+    String confValue \u003d conf.get(confName);\n+    // simply pass a blank value if we do not have one set\n+    confValue \u003d (confValue \u003d\u003d null ? \"\" : confValue);\n+\n+    Map\u003cString, String\u003e confMap \u003d\n+        ImmutableMap.of(HostRestrictingAuthorizationFilter.RESTRICTION_CONFIG\n+            , confValue);\n+    FilterConfig fc \u003d\n+        new DatanodeHttpServer.MapBasedFilterConfig(\n+            HostRestrictingAuthorizationFilter.class.getName(), confMap);\n+    HostRestrictingAuthorizationFilter hostRestrictingAuthorizationFilter \u003d\n+        new HostRestrictingAuthorizationFilter();\n+    try {\n+      hostRestrictingAuthorizationFilter.init(fc);\n+    } catch (ServletException e) {\n+      throw new IllegalStateException(\n+          \"Failed to initialize HostRestrictingAuthorizationFilter.\", e);\n+    }\n+    return hostRestrictingAuthorizationFilter;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  initializeState(Configuration conf) {\n    String confName \u003d HostRestrictingAuthorizationFilter.HDFS_CONFIG_PREFIX +\n        HostRestrictingAuthorizationFilter.RESTRICTION_CONFIG;\n    String confValue \u003d conf.get(confName);\n    // simply pass a blank value if we do not have one set\n    confValue \u003d (confValue \u003d\u003d null ? \"\" : confValue);\n\n    Map\u003cString, String\u003e confMap \u003d\n        ImmutableMap.of(HostRestrictingAuthorizationFilter.RESTRICTION_CONFIG\n            , confValue);\n    FilterConfig fc \u003d\n        new DatanodeHttpServer.MapBasedFilterConfig(\n            HostRestrictingAuthorizationFilter.class.getName(), confMap);\n    HostRestrictingAuthorizationFilter hostRestrictingAuthorizationFilter \u003d\n        new HostRestrictingAuthorizationFilter();\n    try {\n      hostRestrictingAuthorizationFilter.init(fc);\n    } catch (ServletException e) {\n      throw new IllegalStateException(\n          \"Failed to initialize HostRestrictingAuthorizationFilter.\", e);\n    }\n    return hostRestrictingAuthorizationFilter;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/web/HostRestrictingAuthorizationFilterHandler.java"
    }
  }
}