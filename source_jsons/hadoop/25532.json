{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "YarnChild.java",
  "functionName": "configureTask",
  "functionId": "configureTask___job-JobConf__task-Task__credentials-Credentials__jt-Token__JobTokenIdentifier__",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java",
  "functionStartLine": 314,
  "functionEndLine": 358,
  "numCommitsSeen": 51,
  "timeTaken": 8261,
  "changeHistory": [
    "c77a1095dc556e8bea87df6d8ddf36e898f27e86",
    "7039b98e1c459e9e0d8caa28cdaa2868e2bde2eb",
    "2cc851a66e86b82ed6f9fc3b86c2df3001519c51",
    "27e8c86999bc6a972a99216060b11ef35b7de858",
    "009af54d5192c822ba1299c1389e67266dfe7ad1",
    "7d7553c4eb7d9a282410a3213d26a89fea9b7865",
    "0ba7078ef4ee127a47c5042c82db0b113a967b23",
    "408656614495674992349fbda3981559ada3de0b",
    "d00b3c49f6fb3f6a617add6203c6b55f6c345940",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517"
  ],
  "changeHistoryShort": {
    "c77a1095dc556e8bea87df6d8ddf36e898f27e86": "Ybodychange",
    "7039b98e1c459e9e0d8caa28cdaa2868e2bde2eb": "Ybodychange",
    "2cc851a66e86b82ed6f9fc3b86c2df3001519c51": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
    "27e8c86999bc6a972a99216060b11ef35b7de858": "Ybodychange",
    "009af54d5192c822ba1299c1389e67266dfe7ad1": "Ybodychange",
    "7d7553c4eb7d9a282410a3213d26a89fea9b7865": "Ybodychange",
    "0ba7078ef4ee127a47c5042c82db0b113a967b23": "Ybodychange",
    "408656614495674992349fbda3981559ada3de0b": "Ybodychange",
    "d00b3c49f6fb3f6a617add6203c6b55f6c345940": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c77a1095dc556e8bea87df6d8ddf36e898f27e86": {
      "type": "Ybodychange",
      "commitMessage": "YARN-1942. Deprecate toString/fromString methods from ConverterUtils and move them to records classes like ContainerId/ApplicationId, etc. (wangda)\n",
      "commitDate": "14/06/16 3:06 PM",
      "commitName": "c77a1095dc556e8bea87df6d8ddf36e898f27e86",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "23/11/15 5:19 PM",
      "commitNameOld": "8676a118a12165ae5a8b80a2a4596c133471ebc1",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 203.87,
      "commitsBetweenForRepo": 1281,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,45 @@\n   private static void configureTask(JobConf job, Task task,\n       Credentials credentials, Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n     job.setCredentials(credentials);\n-    \n-    ApplicationAttemptId appAttemptId \u003d\n-        ConverterUtils.toContainerId(\n-            System.getenv(Environment.CONTAINER_ID.name()))\n-            .getApplicationAttemptId();\n+\n+    ApplicationAttemptId appAttemptId \u003d ContainerId.fromString(\n+        System.getenv(Environment.CONTAINER_ID.name()))\n+        .getApplicationAttemptId();\n     LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptId);\n     // Set it in conf, so as to be able to be used the the OutputCommitter.\n     job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID,\n         appAttemptId.getAttemptId());\n \n     // set tcp nodelay\n     job.setBoolean(\"ipc.client.tcpnodelay\", true);\n     job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n         YarnOutputFiles.class, MapOutputFile.class);\n     // set the jobToken and shuffle secrets into task\n     task.setJobTokenSecret(\n         JobTokenSecretManager.createSecretKey(jt.getPassword()));\n     byte[] shuffleSecret \u003d TokenCache.getShuffleSecretKey(credentials);\n     if (shuffleSecret \u003d\u003d null) {\n       LOG.warn(\"Shuffle secret missing from task credentials.\"\n           + \" Using job token secret as shuffle secret.\");\n       shuffleSecret \u003d jt.getPassword();\n     }\n     task.setShuffleSecret(\n         JobTokenSecretManager.createSecretKey(shuffleSecret));\n \n     // setup the child\u0027s MRConfig.LOCAL_DIR.\n     configureLocalDirs(task, job);\n \n     // setup the child\u0027s attempt directories\n     // Do the task-type specific localization\n     task.localizeConfiguration(job);\n \n     // Set up the DistributedCache related configs\n     MRApps.setupDistributedCacheLocal(job);\n \n     // Overwrite the localized task jobconf which is linked to in the current\n     // work-dir.\n     Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n     writeLocalJobFile(localTaskFile, job);\n     task.setJobFile(localTaskFile.toString());\n     task.setConf(job);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static void configureTask(JobConf job, Task task,\n      Credentials credentials, Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n    job.setCredentials(credentials);\n\n    ApplicationAttemptId appAttemptId \u003d ContainerId.fromString(\n        System.getenv(Environment.CONTAINER_ID.name()))\n        .getApplicationAttemptId();\n    LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptId);\n    // Set it in conf, so as to be able to be used the the OutputCommitter.\n    job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID,\n        appAttemptId.getAttemptId());\n\n    // set tcp nodelay\n    job.setBoolean(\"ipc.client.tcpnodelay\", true);\n    job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n        YarnOutputFiles.class, MapOutputFile.class);\n    // set the jobToken and shuffle secrets into task\n    task.setJobTokenSecret(\n        JobTokenSecretManager.createSecretKey(jt.getPassword()));\n    byte[] shuffleSecret \u003d TokenCache.getShuffleSecretKey(credentials);\n    if (shuffleSecret \u003d\u003d null) {\n      LOG.warn(\"Shuffle secret missing from task credentials.\"\n          + \" Using job token secret as shuffle secret.\");\n      shuffleSecret \u003d jt.getPassword();\n    }\n    task.setShuffleSecret(\n        JobTokenSecretManager.createSecretKey(shuffleSecret));\n\n    // setup the child\u0027s MRConfig.LOCAL_DIR.\n    configureLocalDirs(task, job);\n\n    // setup the child\u0027s attempt directories\n    // Do the task-type specific localization\n    task.localizeConfiguration(job);\n\n    // Set up the DistributedCache related configs\n    MRApps.setupDistributedCacheLocal(job);\n\n    // Overwrite the localized task jobconf which is linked to in the current\n    // work-dir.\n    Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n    writeLocalJobFile(localTaskFile, job);\n    task.setJobFile(localTaskFile.toString());\n    task.setConf(job);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java",
      "extendedDetails": {}
    },
    "7039b98e1c459e9e0d8caa28cdaa2868e2bde2eb": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-6095. Enable DistributedCache for uber-mode Jobs. Contributed by Gera Shegalov\n",
      "commitDate": "22/09/14 8:20 AM",
      "commitName": "7039b98e1c459e9e0d8caa28cdaa2868e2bde2eb",
      "commitAuthor": "Jason Lowe",
      "commitDateOld": "26/07/14 6:37 PM",
      "commitNameOld": "549bcc2c02983086ee6694982d5f3503f5f4517f",
      "commitAuthorOld": "Zhijie Shen",
      "daysBetweenCommits": 57.57,
      "commitsBetweenForRepo": 522,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,46 @@\n   private static void configureTask(JobConf job, Task task,\n       Credentials credentials, Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n     job.setCredentials(credentials);\n     \n     ApplicationAttemptId appAttemptId \u003d\n         ConverterUtils.toContainerId(\n             System.getenv(Environment.CONTAINER_ID.name()))\n             .getApplicationAttemptId();\n     LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptId);\n     // Set it in conf, so as to be able to be used the the OutputCommitter.\n     job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID,\n         appAttemptId.getAttemptId());\n \n     // set tcp nodelay\n     job.setBoolean(\"ipc.client.tcpnodelay\", true);\n     job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n         YarnOutputFiles.class, MapOutputFile.class);\n     // set the jobToken and shuffle secrets into task\n     task.setJobTokenSecret(\n         JobTokenSecretManager.createSecretKey(jt.getPassword()));\n     byte[] shuffleSecret \u003d TokenCache.getShuffleSecretKey(credentials);\n     if (shuffleSecret \u003d\u003d null) {\n       LOG.warn(\"Shuffle secret missing from task credentials.\"\n           + \" Using job token secret as shuffle secret.\");\n       shuffleSecret \u003d jt.getPassword();\n     }\n     task.setShuffleSecret(\n         JobTokenSecretManager.createSecretKey(shuffleSecret));\n \n     // setup the child\u0027s MRConfig.LOCAL_DIR.\n     configureLocalDirs(task, job);\n \n     // setup the child\u0027s attempt directories\n     // Do the task-type specific localization\n     task.localizeConfiguration(job);\n \n     // Set up the DistributedCache related configs\n-    setupDistributedCacheConfig(job);\n+    MRApps.setupDistributedCacheLocal(job);\n \n     // Overwrite the localized task jobconf which is linked to in the current\n     // work-dir.\n     Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n     writeLocalJobFile(localTaskFile, job);\n     task.setJobFile(localTaskFile.toString());\n     task.setConf(job);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static void configureTask(JobConf job, Task task,\n      Credentials credentials, Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n    job.setCredentials(credentials);\n    \n    ApplicationAttemptId appAttemptId \u003d\n        ConverterUtils.toContainerId(\n            System.getenv(Environment.CONTAINER_ID.name()))\n            .getApplicationAttemptId();\n    LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptId);\n    // Set it in conf, so as to be able to be used the the OutputCommitter.\n    job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID,\n        appAttemptId.getAttemptId());\n\n    // set tcp nodelay\n    job.setBoolean(\"ipc.client.tcpnodelay\", true);\n    job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n        YarnOutputFiles.class, MapOutputFile.class);\n    // set the jobToken and shuffle secrets into task\n    task.setJobTokenSecret(\n        JobTokenSecretManager.createSecretKey(jt.getPassword()));\n    byte[] shuffleSecret \u003d TokenCache.getShuffleSecretKey(credentials);\n    if (shuffleSecret \u003d\u003d null) {\n      LOG.warn(\"Shuffle secret missing from task credentials.\"\n          + \" Using job token secret as shuffle secret.\");\n      shuffleSecret \u003d jt.getPassword();\n    }\n    task.setShuffleSecret(\n        JobTokenSecretManager.createSecretKey(shuffleSecret));\n\n    // setup the child\u0027s MRConfig.LOCAL_DIR.\n    configureLocalDirs(task, job);\n\n    // setup the child\u0027s attempt directories\n    // Do the task-type specific localization\n    task.localizeConfiguration(job);\n\n    // Set up the DistributedCache related configs\n    MRApps.setupDistributedCacheLocal(job);\n\n    // Overwrite the localized task jobconf which is linked to in the current\n    // work-dir.\n    Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n    writeLocalJobFile(localTaskFile, job);\n    task.setJobFile(localTaskFile.toString());\n    task.setConf(job);\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java",
      "extendedDetails": {}
    },
    "2cc851a66e86b82ed6f9fc3b86c2df3001519c51": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "MAPREDUCE-5484. YarnChild unnecessarily loads job conf twice (Sandy Ryza)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1518857 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/08/13 4:45 PM",
      "commitName": "2cc851a66e86b82ed6f9fc3b86c2df3001519c51",
      "commitAuthor": "Sanford Ryza",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "MAPREDUCE-5484. YarnChild unnecessarily loads job conf twice (Sandy Ryza)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1518857 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/08/13 4:45 PM",
          "commitName": "2cc851a66e86b82ed6f9fc3b86c2df3001519c51",
          "commitAuthor": "Sanford Ryza",
          "commitDateOld": "14/05/13 4:43 PM",
          "commitNameOld": "4d8e350750748b919ee2158690a44cd9fd80dcae",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 107.0,
          "commitsBetweenForRepo": 650,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,48 +1,46 @@\n-  private static JobConf configureTask(Task task, Credentials credentials,\n-      Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n-    final JobConf job \u003d new JobConf(MRJobConfig.JOB_CONF_FILE);\n+  private static void configureTask(JobConf job, Task task,\n+      Credentials credentials, Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n     job.setCredentials(credentials);\n-\n+    \n     ApplicationAttemptId appAttemptId \u003d\n         ConverterUtils.toContainerId(\n             System.getenv(Environment.CONTAINER_ID.name()))\n             .getApplicationAttemptId();\n     LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptId);\n     // Set it in conf, so as to be able to be used the the OutputCommitter.\n     job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID,\n         appAttemptId.getAttemptId());\n \n     // set tcp nodelay\n     job.setBoolean(\"ipc.client.tcpnodelay\", true);\n     job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n         YarnOutputFiles.class, MapOutputFile.class);\n     // set the jobToken and shuffle secrets into task\n     task.setJobTokenSecret(\n         JobTokenSecretManager.createSecretKey(jt.getPassword()));\n     byte[] shuffleSecret \u003d TokenCache.getShuffleSecretKey(credentials);\n     if (shuffleSecret \u003d\u003d null) {\n       LOG.warn(\"Shuffle secret missing from task credentials.\"\n           + \" Using job token secret as shuffle secret.\");\n       shuffleSecret \u003d jt.getPassword();\n     }\n     task.setShuffleSecret(\n         JobTokenSecretManager.createSecretKey(shuffleSecret));\n \n     // setup the child\u0027s MRConfig.LOCAL_DIR.\n     configureLocalDirs(task, job);\n \n     // setup the child\u0027s attempt directories\n     // Do the task-type specific localization\n     task.localizeConfiguration(job);\n \n     // Set up the DistributedCache related configs\n     setupDistributedCacheConfig(job);\n \n     // Overwrite the localized task jobconf which is linked to in the current\n     // work-dir.\n     Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n     writeLocalJobFile(localTaskFile, job);\n     task.setJobFile(localTaskFile.toString());\n     task.setConf(job);\n-    return job;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static void configureTask(JobConf job, Task task,\n      Credentials credentials, Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n    job.setCredentials(credentials);\n    \n    ApplicationAttemptId appAttemptId \u003d\n        ConverterUtils.toContainerId(\n            System.getenv(Environment.CONTAINER_ID.name()))\n            .getApplicationAttemptId();\n    LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptId);\n    // Set it in conf, so as to be able to be used the the OutputCommitter.\n    job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID,\n        appAttemptId.getAttemptId());\n\n    // set tcp nodelay\n    job.setBoolean(\"ipc.client.tcpnodelay\", true);\n    job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n        YarnOutputFiles.class, MapOutputFile.class);\n    // set the jobToken and shuffle secrets into task\n    task.setJobTokenSecret(\n        JobTokenSecretManager.createSecretKey(jt.getPassword()));\n    byte[] shuffleSecret \u003d TokenCache.getShuffleSecretKey(credentials);\n    if (shuffleSecret \u003d\u003d null) {\n      LOG.warn(\"Shuffle secret missing from task credentials.\"\n          + \" Using job token secret as shuffle secret.\");\n      shuffleSecret \u003d jt.getPassword();\n    }\n    task.setShuffleSecret(\n        JobTokenSecretManager.createSecretKey(shuffleSecret));\n\n    // setup the child\u0027s MRConfig.LOCAL_DIR.\n    configureLocalDirs(task, job);\n\n    // setup the child\u0027s attempt directories\n    // Do the task-type specific localization\n    task.localizeConfiguration(job);\n\n    // Set up the DistributedCache related configs\n    setupDistributedCacheConfig(job);\n\n    // Overwrite the localized task jobconf which is linked to in the current\n    // work-dir.\n    Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n    writeLocalJobFile(localTaskFile, job);\n    task.setJobFile(localTaskFile.toString());\n    task.setConf(job);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java",
          "extendedDetails": {
            "oldValue": "[task-Task, credentials-Credentials, jt-Token\u003cJobTokenIdentifier\u003e]",
            "newValue": "[job-JobConf, task-Task, credentials-Credentials, jt-Token\u003cJobTokenIdentifier\u003e]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "MAPREDUCE-5484. YarnChild unnecessarily loads job conf twice (Sandy Ryza)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1518857 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/08/13 4:45 PM",
          "commitName": "2cc851a66e86b82ed6f9fc3b86c2df3001519c51",
          "commitAuthor": "Sanford Ryza",
          "commitDateOld": "14/05/13 4:43 PM",
          "commitNameOld": "4d8e350750748b919ee2158690a44cd9fd80dcae",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 107.0,
          "commitsBetweenForRepo": 650,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,48 +1,46 @@\n-  private static JobConf configureTask(Task task, Credentials credentials,\n-      Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n-    final JobConf job \u003d new JobConf(MRJobConfig.JOB_CONF_FILE);\n+  private static void configureTask(JobConf job, Task task,\n+      Credentials credentials, Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n     job.setCredentials(credentials);\n-\n+    \n     ApplicationAttemptId appAttemptId \u003d\n         ConverterUtils.toContainerId(\n             System.getenv(Environment.CONTAINER_ID.name()))\n             .getApplicationAttemptId();\n     LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptId);\n     // Set it in conf, so as to be able to be used the the OutputCommitter.\n     job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID,\n         appAttemptId.getAttemptId());\n \n     // set tcp nodelay\n     job.setBoolean(\"ipc.client.tcpnodelay\", true);\n     job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n         YarnOutputFiles.class, MapOutputFile.class);\n     // set the jobToken and shuffle secrets into task\n     task.setJobTokenSecret(\n         JobTokenSecretManager.createSecretKey(jt.getPassword()));\n     byte[] shuffleSecret \u003d TokenCache.getShuffleSecretKey(credentials);\n     if (shuffleSecret \u003d\u003d null) {\n       LOG.warn(\"Shuffle secret missing from task credentials.\"\n           + \" Using job token secret as shuffle secret.\");\n       shuffleSecret \u003d jt.getPassword();\n     }\n     task.setShuffleSecret(\n         JobTokenSecretManager.createSecretKey(shuffleSecret));\n \n     // setup the child\u0027s MRConfig.LOCAL_DIR.\n     configureLocalDirs(task, job);\n \n     // setup the child\u0027s attempt directories\n     // Do the task-type specific localization\n     task.localizeConfiguration(job);\n \n     // Set up the DistributedCache related configs\n     setupDistributedCacheConfig(job);\n \n     // Overwrite the localized task jobconf which is linked to in the current\n     // work-dir.\n     Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n     writeLocalJobFile(localTaskFile, job);\n     task.setJobFile(localTaskFile.toString());\n     task.setConf(job);\n-    return job;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static void configureTask(JobConf job, Task task,\n      Credentials credentials, Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n    job.setCredentials(credentials);\n    \n    ApplicationAttemptId appAttemptId \u003d\n        ConverterUtils.toContainerId(\n            System.getenv(Environment.CONTAINER_ID.name()))\n            .getApplicationAttemptId();\n    LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptId);\n    // Set it in conf, so as to be able to be used the the OutputCommitter.\n    job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID,\n        appAttemptId.getAttemptId());\n\n    // set tcp nodelay\n    job.setBoolean(\"ipc.client.tcpnodelay\", true);\n    job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n        YarnOutputFiles.class, MapOutputFile.class);\n    // set the jobToken and shuffle secrets into task\n    task.setJobTokenSecret(\n        JobTokenSecretManager.createSecretKey(jt.getPassword()));\n    byte[] shuffleSecret \u003d TokenCache.getShuffleSecretKey(credentials);\n    if (shuffleSecret \u003d\u003d null) {\n      LOG.warn(\"Shuffle secret missing from task credentials.\"\n          + \" Using job token secret as shuffle secret.\");\n      shuffleSecret \u003d jt.getPassword();\n    }\n    task.setShuffleSecret(\n        JobTokenSecretManager.createSecretKey(shuffleSecret));\n\n    // setup the child\u0027s MRConfig.LOCAL_DIR.\n    configureLocalDirs(task, job);\n\n    // setup the child\u0027s attempt directories\n    // Do the task-type specific localization\n    task.localizeConfiguration(job);\n\n    // Set up the DistributedCache related configs\n    setupDistributedCacheConfig(job);\n\n    // Overwrite the localized task jobconf which is linked to in the current\n    // work-dir.\n    Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n    writeLocalJobFile(localTaskFile, job);\n    task.setJobFile(localTaskFile.toString());\n    task.setConf(job);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java",
          "extendedDetails": {
            "oldValue": "JobConf",
            "newValue": "void"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-5484. YarnChild unnecessarily loads job conf twice (Sandy Ryza)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1518857 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "29/08/13 4:45 PM",
          "commitName": "2cc851a66e86b82ed6f9fc3b86c2df3001519c51",
          "commitAuthor": "Sanford Ryza",
          "commitDateOld": "14/05/13 4:43 PM",
          "commitNameOld": "4d8e350750748b919ee2158690a44cd9fd80dcae",
          "commitAuthorOld": "Vinod Kumar Vavilapalli",
          "daysBetweenCommits": 107.0,
          "commitsBetweenForRepo": 650,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,48 +1,46 @@\n-  private static JobConf configureTask(Task task, Credentials credentials,\n-      Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n-    final JobConf job \u003d new JobConf(MRJobConfig.JOB_CONF_FILE);\n+  private static void configureTask(JobConf job, Task task,\n+      Credentials credentials, Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n     job.setCredentials(credentials);\n-\n+    \n     ApplicationAttemptId appAttemptId \u003d\n         ConverterUtils.toContainerId(\n             System.getenv(Environment.CONTAINER_ID.name()))\n             .getApplicationAttemptId();\n     LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptId);\n     // Set it in conf, so as to be able to be used the the OutputCommitter.\n     job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID,\n         appAttemptId.getAttemptId());\n \n     // set tcp nodelay\n     job.setBoolean(\"ipc.client.tcpnodelay\", true);\n     job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n         YarnOutputFiles.class, MapOutputFile.class);\n     // set the jobToken and shuffle secrets into task\n     task.setJobTokenSecret(\n         JobTokenSecretManager.createSecretKey(jt.getPassword()));\n     byte[] shuffleSecret \u003d TokenCache.getShuffleSecretKey(credentials);\n     if (shuffleSecret \u003d\u003d null) {\n       LOG.warn(\"Shuffle secret missing from task credentials.\"\n           + \" Using job token secret as shuffle secret.\");\n       shuffleSecret \u003d jt.getPassword();\n     }\n     task.setShuffleSecret(\n         JobTokenSecretManager.createSecretKey(shuffleSecret));\n \n     // setup the child\u0027s MRConfig.LOCAL_DIR.\n     configureLocalDirs(task, job);\n \n     // setup the child\u0027s attempt directories\n     // Do the task-type specific localization\n     task.localizeConfiguration(job);\n \n     // Set up the DistributedCache related configs\n     setupDistributedCacheConfig(job);\n \n     // Overwrite the localized task jobconf which is linked to in the current\n     // work-dir.\n     Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n     writeLocalJobFile(localTaskFile, job);\n     task.setJobFile(localTaskFile.toString());\n     task.setConf(job);\n-    return job;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private static void configureTask(JobConf job, Task task,\n      Credentials credentials, Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n    job.setCredentials(credentials);\n    \n    ApplicationAttemptId appAttemptId \u003d\n        ConverterUtils.toContainerId(\n            System.getenv(Environment.CONTAINER_ID.name()))\n            .getApplicationAttemptId();\n    LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptId);\n    // Set it in conf, so as to be able to be used the the OutputCommitter.\n    job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID,\n        appAttemptId.getAttemptId());\n\n    // set tcp nodelay\n    job.setBoolean(\"ipc.client.tcpnodelay\", true);\n    job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n        YarnOutputFiles.class, MapOutputFile.class);\n    // set the jobToken and shuffle secrets into task\n    task.setJobTokenSecret(\n        JobTokenSecretManager.createSecretKey(jt.getPassword()));\n    byte[] shuffleSecret \u003d TokenCache.getShuffleSecretKey(credentials);\n    if (shuffleSecret \u003d\u003d null) {\n      LOG.warn(\"Shuffle secret missing from task credentials.\"\n          + \" Using job token secret as shuffle secret.\");\n      shuffleSecret \u003d jt.getPassword();\n    }\n    task.setShuffleSecret(\n        JobTokenSecretManager.createSecretKey(shuffleSecret));\n\n    // setup the child\u0027s MRConfig.LOCAL_DIR.\n    configureLocalDirs(task, job);\n\n    // setup the child\u0027s attempt directories\n    // Do the task-type specific localization\n    task.localizeConfiguration(job);\n\n    // Set up the DistributedCache related configs\n    setupDistributedCacheConfig(job);\n\n    // Overwrite the localized task jobconf which is linked to in the current\n    // work-dir.\n    Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n    writeLocalJobFile(localTaskFile, job);\n    task.setJobFile(localTaskFile.toString());\n    task.setConf(job);\n  }",
          "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java",
          "extendedDetails": {}
        }
      ]
    },
    "27e8c86999bc6a972a99216060b11ef35b7de858": {
      "type": "Ybodychange",
      "commitMessage": "YARN-561. Modified NodeManager to set key information into the environment of every container that it launches. Contributed by Xuan Gong.\nMAPREDUCE-5175. Updated MR App to not set envs that will be set by NMs anyways after YARN-561. Contributed by Xuan Gong.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1471156 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "23/04/13 2:39 PM",
      "commitName": "27e8c86999bc6a972a99216060b11ef35b7de858",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "22/04/13 1:07 PM",
      "commitNameOld": "009af54d5192c822ba1299c1389e67266dfe7ad1",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 1.06,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,48 @@\n   private static JobConf configureTask(Task task, Credentials credentials,\n       Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n     final JobConf job \u003d new JobConf(MRJobConfig.JOB_CONF_FILE);\n     job.setCredentials(credentials);\n \n-    String appAttemptIdEnv \u003d System\n-        .getenv(MRJobConfig.APPLICATION_ATTEMPT_ID_ENV);\n-    LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptIdEnv);\n+    ApplicationAttemptId appAttemptId \u003d\n+        ConverterUtils.toContainerId(\n+            System.getenv(Environment.CONTAINER_ID.name()))\n+            .getApplicationAttemptId();\n+    LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptId);\n     // Set it in conf, so as to be able to be used the the OutputCommitter.\n-    job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID, Integer\n-        .parseInt(appAttemptIdEnv));\n+    job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID,\n+        appAttemptId.getAttemptId());\n \n     // set tcp nodelay\n     job.setBoolean(\"ipc.client.tcpnodelay\", true);\n     job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n         YarnOutputFiles.class, MapOutputFile.class);\n     // set the jobToken and shuffle secrets into task\n     task.setJobTokenSecret(\n         JobTokenSecretManager.createSecretKey(jt.getPassword()));\n     byte[] shuffleSecret \u003d TokenCache.getShuffleSecretKey(credentials);\n     if (shuffleSecret \u003d\u003d null) {\n       LOG.warn(\"Shuffle secret missing from task credentials.\"\n           + \" Using job token secret as shuffle secret.\");\n       shuffleSecret \u003d jt.getPassword();\n     }\n     task.setShuffleSecret(\n         JobTokenSecretManager.createSecretKey(shuffleSecret));\n \n     // setup the child\u0027s MRConfig.LOCAL_DIR.\n     configureLocalDirs(task, job);\n \n     // setup the child\u0027s attempt directories\n     // Do the task-type specific localization\n     task.localizeConfiguration(job);\n \n     // Set up the DistributedCache related configs\n     setupDistributedCacheConfig(job);\n \n     // Overwrite the localized task jobconf which is linked to in the current\n     // work-dir.\n     Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n     writeLocalJobFile(localTaskFile, job);\n     task.setJobFile(localTaskFile.toString());\n     task.setConf(job);\n     return job;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static JobConf configureTask(Task task, Credentials credentials,\n      Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n    final JobConf job \u003d new JobConf(MRJobConfig.JOB_CONF_FILE);\n    job.setCredentials(credentials);\n\n    ApplicationAttemptId appAttemptId \u003d\n        ConverterUtils.toContainerId(\n            System.getenv(Environment.CONTAINER_ID.name()))\n            .getApplicationAttemptId();\n    LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptId);\n    // Set it in conf, so as to be able to be used the the OutputCommitter.\n    job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID,\n        appAttemptId.getAttemptId());\n\n    // set tcp nodelay\n    job.setBoolean(\"ipc.client.tcpnodelay\", true);\n    job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n        YarnOutputFiles.class, MapOutputFile.class);\n    // set the jobToken and shuffle secrets into task\n    task.setJobTokenSecret(\n        JobTokenSecretManager.createSecretKey(jt.getPassword()));\n    byte[] shuffleSecret \u003d TokenCache.getShuffleSecretKey(credentials);\n    if (shuffleSecret \u003d\u003d null) {\n      LOG.warn(\"Shuffle secret missing from task credentials.\"\n          + \" Using job token secret as shuffle secret.\");\n      shuffleSecret \u003d jt.getPassword();\n    }\n    task.setShuffleSecret(\n        JobTokenSecretManager.createSecretKey(shuffleSecret));\n\n    // setup the child\u0027s MRConfig.LOCAL_DIR.\n    configureLocalDirs(task, job);\n\n    // setup the child\u0027s attempt directories\n    // Do the task-type specific localization\n    task.localizeConfiguration(job);\n\n    // Set up the DistributedCache related configs\n    setupDistributedCacheConfig(job);\n\n    // Overwrite the localized task jobconf which is linked to in the current\n    // work-dir.\n    Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n    writeLocalJobFile(localTaskFile, job);\n    task.setJobFile(localTaskFile.toString());\n    task.setConf(job);\n    return job;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java",
      "extendedDetails": {}
    },
    "009af54d5192c822ba1299c1389e67266dfe7ad1": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5146. application classloader may be used too early to load classes. Contributed by Sangjin Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1470694 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/04/13 1:07 PM",
      "commitName": "009af54d5192c822ba1299c1389e67266dfe7ad1",
      "commitAuthor": "Thomas White",
      "commitDateOld": "15/03/13 2:09 PM",
      "commitNameOld": "7d7553c4eb7d9a282410a3213d26a89fea9b7865",
      "commitAuthorOld": "Robert Joseph Evans",
      "daysBetweenCommits": 37.96,
      "commitsBetweenForRepo": 195,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,46 @@\n   private static JobConf configureTask(Task task, Credentials credentials,\n       Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n     final JobConf job \u003d new JobConf(MRJobConfig.JOB_CONF_FILE);\n     job.setCredentials(credentials);\n \n-    // set job classloader if configured\n-    MRApps.setJobClassLoader(job);\n-\n     String appAttemptIdEnv \u003d System\n         .getenv(MRJobConfig.APPLICATION_ATTEMPT_ID_ENV);\n     LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptIdEnv);\n     // Set it in conf, so as to be able to be used the the OutputCommitter.\n     job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID, Integer\n         .parseInt(appAttemptIdEnv));\n \n     // set tcp nodelay\n     job.setBoolean(\"ipc.client.tcpnodelay\", true);\n     job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n         YarnOutputFiles.class, MapOutputFile.class);\n     // set the jobToken and shuffle secrets into task\n     task.setJobTokenSecret(\n         JobTokenSecretManager.createSecretKey(jt.getPassword()));\n     byte[] shuffleSecret \u003d TokenCache.getShuffleSecretKey(credentials);\n     if (shuffleSecret \u003d\u003d null) {\n       LOG.warn(\"Shuffle secret missing from task credentials.\"\n           + \" Using job token secret as shuffle secret.\");\n       shuffleSecret \u003d jt.getPassword();\n     }\n     task.setShuffleSecret(\n         JobTokenSecretManager.createSecretKey(shuffleSecret));\n \n     // setup the child\u0027s MRConfig.LOCAL_DIR.\n     configureLocalDirs(task, job);\n \n     // setup the child\u0027s attempt directories\n     // Do the task-type specific localization\n     task.localizeConfiguration(job);\n \n     // Set up the DistributedCache related configs\n     setupDistributedCacheConfig(job);\n \n     // Overwrite the localized task jobconf which is linked to in the current\n     // work-dir.\n     Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n     writeLocalJobFile(localTaskFile, job);\n     task.setJobFile(localTaskFile.toString());\n     task.setConf(job);\n     return job;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static JobConf configureTask(Task task, Credentials credentials,\n      Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n    final JobConf job \u003d new JobConf(MRJobConfig.JOB_CONF_FILE);\n    job.setCredentials(credentials);\n\n    String appAttemptIdEnv \u003d System\n        .getenv(MRJobConfig.APPLICATION_ATTEMPT_ID_ENV);\n    LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptIdEnv);\n    // Set it in conf, so as to be able to be used the the OutputCommitter.\n    job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID, Integer\n        .parseInt(appAttemptIdEnv));\n\n    // set tcp nodelay\n    job.setBoolean(\"ipc.client.tcpnodelay\", true);\n    job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n        YarnOutputFiles.class, MapOutputFile.class);\n    // set the jobToken and shuffle secrets into task\n    task.setJobTokenSecret(\n        JobTokenSecretManager.createSecretKey(jt.getPassword()));\n    byte[] shuffleSecret \u003d TokenCache.getShuffleSecretKey(credentials);\n    if (shuffleSecret \u003d\u003d null) {\n      LOG.warn(\"Shuffle secret missing from task credentials.\"\n          + \" Using job token secret as shuffle secret.\");\n      shuffleSecret \u003d jt.getPassword();\n    }\n    task.setShuffleSecret(\n        JobTokenSecretManager.createSecretKey(shuffleSecret));\n\n    // setup the child\u0027s MRConfig.LOCAL_DIR.\n    configureLocalDirs(task, job);\n\n    // setup the child\u0027s attempt directories\n    // Do the task-type specific localization\n    task.localizeConfiguration(job);\n\n    // Set up the DistributedCache related configs\n    setupDistributedCacheConfig(job);\n\n    // Overwrite the localized task jobconf which is linked to in the current\n    // work-dir.\n    Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n    writeLocalJobFile(localTaskFile, job);\n    task.setJobFile(localTaskFile.toString());\n    task.setConf(job);\n    return job;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java",
      "extendedDetails": {}
    },
    "7d7553c4eb7d9a282410a3213d26a89fea9b7865": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5042. Reducer unable to fetch for a map task that was recovered (Jason Lowe via bobby)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1457119 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "15/03/13 2:09 PM",
      "commitName": "7d7553c4eb7d9a282410a3213d26a89fea9b7865",
      "commitAuthor": "Robert Joseph Evans",
      "commitDateOld": "09/01/13 8:12 AM",
      "commitNameOld": "0ba7078ef4ee127a47c5042c82db0b113a967b23",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 65.21,
      "commitsBetweenForRepo": 311,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,41 +1,49 @@\n   private static JobConf configureTask(Task task, Credentials credentials,\n       Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n     final JobConf job \u003d new JobConf(MRJobConfig.JOB_CONF_FILE);\n     job.setCredentials(credentials);\n \n     // set job classloader if configured\n     MRApps.setJobClassLoader(job);\n \n     String appAttemptIdEnv \u003d System\n         .getenv(MRJobConfig.APPLICATION_ATTEMPT_ID_ENV);\n     LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptIdEnv);\n     // Set it in conf, so as to be able to be used the the OutputCommitter.\n     job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID, Integer\n         .parseInt(appAttemptIdEnv));\n \n     // set tcp nodelay\n     job.setBoolean(\"ipc.client.tcpnodelay\", true);\n     job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n         YarnOutputFiles.class, MapOutputFile.class);\n-    // set the jobTokenFile into task\n+    // set the jobToken and shuffle secrets into task\n     task.setJobTokenSecret(\n         JobTokenSecretManager.createSecretKey(jt.getPassword()));\n+    byte[] shuffleSecret \u003d TokenCache.getShuffleSecretKey(credentials);\n+    if (shuffleSecret \u003d\u003d null) {\n+      LOG.warn(\"Shuffle secret missing from task credentials.\"\n+          + \" Using job token secret as shuffle secret.\");\n+      shuffleSecret \u003d jt.getPassword();\n+    }\n+    task.setShuffleSecret(\n+        JobTokenSecretManager.createSecretKey(shuffleSecret));\n \n     // setup the child\u0027s MRConfig.LOCAL_DIR.\n     configureLocalDirs(task, job);\n \n     // setup the child\u0027s attempt directories\n     // Do the task-type specific localization\n     task.localizeConfiguration(job);\n \n     // Set up the DistributedCache related configs\n     setupDistributedCacheConfig(job);\n \n     // Overwrite the localized task jobconf which is linked to in the current\n     // work-dir.\n     Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n     writeLocalJobFile(localTaskFile, job);\n     task.setJobFile(localTaskFile.toString());\n     task.setConf(job);\n     return job;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static JobConf configureTask(Task task, Credentials credentials,\n      Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n    final JobConf job \u003d new JobConf(MRJobConfig.JOB_CONF_FILE);\n    job.setCredentials(credentials);\n\n    // set job classloader if configured\n    MRApps.setJobClassLoader(job);\n\n    String appAttemptIdEnv \u003d System\n        .getenv(MRJobConfig.APPLICATION_ATTEMPT_ID_ENV);\n    LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptIdEnv);\n    // Set it in conf, so as to be able to be used the the OutputCommitter.\n    job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID, Integer\n        .parseInt(appAttemptIdEnv));\n\n    // set tcp nodelay\n    job.setBoolean(\"ipc.client.tcpnodelay\", true);\n    job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n        YarnOutputFiles.class, MapOutputFile.class);\n    // set the jobToken and shuffle secrets into task\n    task.setJobTokenSecret(\n        JobTokenSecretManager.createSecretKey(jt.getPassword()));\n    byte[] shuffleSecret \u003d TokenCache.getShuffleSecretKey(credentials);\n    if (shuffleSecret \u003d\u003d null) {\n      LOG.warn(\"Shuffle secret missing from task credentials.\"\n          + \" Using job token secret as shuffle secret.\");\n      shuffleSecret \u003d jt.getPassword();\n    }\n    task.setShuffleSecret(\n        JobTokenSecretManager.createSecretKey(shuffleSecret));\n\n    // setup the child\u0027s MRConfig.LOCAL_DIR.\n    configureLocalDirs(task, job);\n\n    // setup the child\u0027s attempt directories\n    // Do the task-type specific localization\n    task.localizeConfiguration(job);\n\n    // Set up the DistributedCache related configs\n    setupDistributedCacheConfig(job);\n\n    // Overwrite the localized task jobconf which is linked to in the current\n    // work-dir.\n    Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n    writeLocalJobFile(localTaskFile, job);\n    task.setJobFile(localTaskFile.toString());\n    task.setConf(job);\n    return job;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java",
      "extendedDetails": {}
    },
    "0ba7078ef4ee127a47c5042c82db0b113a967b23": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-1700. User supplied dependencies may conflict with MapReduce system JARs.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1430929 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/13 8:12 AM",
      "commitName": "0ba7078ef4ee127a47c5042c82db0b113a967b23",
      "commitAuthor": "Thomas White",
      "commitDateOld": "14/11/12 4:16 PM",
      "commitNameOld": "905b17876c44634545a68300ff2f2d73fb86d3b7",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 55.66,
      "commitsBetweenForRepo": 209,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,41 @@\n   private static JobConf configureTask(Task task, Credentials credentials,\n       Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n     final JobConf job \u003d new JobConf(MRJobConfig.JOB_CONF_FILE);\n     job.setCredentials(credentials);\n-    \n+\n+    // set job classloader if configured\n+    MRApps.setJobClassLoader(job);\n+\n     String appAttemptIdEnv \u003d System\n         .getenv(MRJobConfig.APPLICATION_ATTEMPT_ID_ENV);\n     LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptIdEnv);\n     // Set it in conf, so as to be able to be used the the OutputCommitter.\n     job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID, Integer\n         .parseInt(appAttemptIdEnv));\n \n     // set tcp nodelay\n     job.setBoolean(\"ipc.client.tcpnodelay\", true);\n     job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n         YarnOutputFiles.class, MapOutputFile.class);\n     // set the jobTokenFile into task\n     task.setJobTokenSecret(\n         JobTokenSecretManager.createSecretKey(jt.getPassword()));\n \n     // setup the child\u0027s MRConfig.LOCAL_DIR.\n     configureLocalDirs(task, job);\n \n     // setup the child\u0027s attempt directories\n     // Do the task-type specific localization\n     task.localizeConfiguration(job);\n \n     // Set up the DistributedCache related configs\n     setupDistributedCacheConfig(job);\n \n     // Overwrite the localized task jobconf which is linked to in the current\n     // work-dir.\n     Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n     writeLocalJobFile(localTaskFile, job);\n     task.setJobFile(localTaskFile.toString());\n     task.setConf(job);\n     return job;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static JobConf configureTask(Task task, Credentials credentials,\n      Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n    final JobConf job \u003d new JobConf(MRJobConfig.JOB_CONF_FILE);\n    job.setCredentials(credentials);\n\n    // set job classloader if configured\n    MRApps.setJobClassLoader(job);\n\n    String appAttemptIdEnv \u003d System\n        .getenv(MRJobConfig.APPLICATION_ATTEMPT_ID_ENV);\n    LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptIdEnv);\n    // Set it in conf, so as to be able to be used the the OutputCommitter.\n    job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID, Integer\n        .parseInt(appAttemptIdEnv));\n\n    // set tcp nodelay\n    job.setBoolean(\"ipc.client.tcpnodelay\", true);\n    job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n        YarnOutputFiles.class, MapOutputFile.class);\n    // set the jobTokenFile into task\n    task.setJobTokenSecret(\n        JobTokenSecretManager.createSecretKey(jt.getPassword()));\n\n    // setup the child\u0027s MRConfig.LOCAL_DIR.\n    configureLocalDirs(task, job);\n\n    // setup the child\u0027s attempt directories\n    // Do the task-type specific localization\n    task.localizeConfiguration(job);\n\n    // Set up the DistributedCache related configs\n    setupDistributedCacheConfig(job);\n\n    // Overwrite the localized task jobconf which is linked to in the current\n    // work-dir.\n    Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n    writeLocalJobFile(localTaskFile, job);\n    task.setJobFile(localTaskFile.toString());\n    task.setConf(job);\n    return job;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java",
      "extendedDetails": {}
    },
    "408656614495674992349fbda3981559ada3de0b": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2708. Designed and implemented MR Application Master recovery to make MR AMs resume their progress after restart. Contributed by Sharad Agarwal.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1188043 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/10/11 1:41 AM",
      "commitName": "408656614495674992349fbda3981559ada3de0b",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "21/10/11 11:14 PM",
      "commitNameOld": "5795fcfd9904431ec075fdce7ab8559ff50eccd2",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 2.1,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,38 @@\n   private static JobConf configureTask(Task task, Credentials credentials,\n       Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n     final JobConf job \u003d new JobConf(MRJobConfig.JOB_CONF_FILE);\n     job.setCredentials(credentials);\n+    \n+    String appAttemptIdEnv \u003d System\n+        .getenv(MRJobConfig.APPLICATION_ATTEMPT_ID_ENV);\n+    LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptIdEnv);\n+    // Set it in conf, so as to be able to be used the the OutputCommitter.\n+    job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID, Integer\n+        .parseInt(appAttemptIdEnv));\n+\n     // set tcp nodelay\n     job.setBoolean(\"ipc.client.tcpnodelay\", true);\n     job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n         YarnOutputFiles.class, MapOutputFile.class);\n     // set the jobTokenFile into task\n     task.setJobTokenSecret(\n         JobTokenSecretManager.createSecretKey(jt.getPassword()));\n \n     // setup the child\u0027s MRConfig.LOCAL_DIR.\n     configureLocalDirs(task, job);\n \n     // setup the child\u0027s attempt directories\n     // Do the task-type specific localization\n     task.localizeConfiguration(job);\n \n     // Set up the DistributedCache related configs\n     setupDistributedCacheConfig(job);\n \n     // Overwrite the localized task jobconf which is linked to in the current\n     // work-dir.\n     Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n     writeLocalJobFile(localTaskFile, job);\n     task.setJobFile(localTaskFile.toString());\n     task.setConf(job);\n     return job;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static JobConf configureTask(Task task, Credentials credentials,\n      Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n    final JobConf job \u003d new JobConf(MRJobConfig.JOB_CONF_FILE);\n    job.setCredentials(credentials);\n    \n    String appAttemptIdEnv \u003d System\n        .getenv(MRJobConfig.APPLICATION_ATTEMPT_ID_ENV);\n    LOG.debug(\"APPLICATION_ATTEMPT_ID: \" + appAttemptIdEnv);\n    // Set it in conf, so as to be able to be used the the OutputCommitter.\n    job.setInt(MRJobConfig.APPLICATION_ATTEMPT_ID, Integer\n        .parseInt(appAttemptIdEnv));\n\n    // set tcp nodelay\n    job.setBoolean(\"ipc.client.tcpnodelay\", true);\n    job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n        YarnOutputFiles.class, MapOutputFile.class);\n    // set the jobTokenFile into task\n    task.setJobTokenSecret(\n        JobTokenSecretManager.createSecretKey(jt.getPassword()));\n\n    // setup the child\u0027s MRConfig.LOCAL_DIR.\n    configureLocalDirs(task, job);\n\n    // setup the child\u0027s attempt directories\n    // Do the task-type specific localization\n    task.localizeConfiguration(job);\n\n    // Set up the DistributedCache related configs\n    setupDistributedCacheConfig(job);\n\n    // Overwrite the localized task jobconf which is linked to in the current\n    // work-dir.\n    Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n    writeLocalJobFile(localTaskFile, job);\n    task.setJobFile(localTaskFile.toString());\n    task.setConf(job);\n    return job;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java",
      "extendedDetails": {}
    },
    "d00b3c49f6fb3f6a617add6203c6b55f6c345940": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-2880. Improved classpath-construction for mapreduce AM and containers. Contributed by Arun C Murthy.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1173783 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/09/11 11:28 AM",
      "commitName": "d00b3c49f6fb3f6a617add6203c6b55f6c345940",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "24/08/11 5:14 PM",
      "commitNameOld": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 27.76,
      "commitsBetweenForRepo": 171,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,30 @@\n   private static JobConf configureTask(Task task, Credentials credentials,\n       Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n-    final JobConf job \u003d new JobConf(MRConstants.JOB_CONF_FILE);\n+    final JobConf job \u003d new JobConf(MRJobConfig.JOB_CONF_FILE);\n     job.setCredentials(credentials);\n     // set tcp nodelay\n     job.setBoolean(\"ipc.client.tcpnodelay\", true);\n     job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n         YarnOutputFiles.class, MapOutputFile.class);\n     // set the jobTokenFile into task\n     task.setJobTokenSecret(\n         JobTokenSecretManager.createSecretKey(jt.getPassword()));\n \n     // setup the child\u0027s MRConfig.LOCAL_DIR.\n     configureLocalDirs(task, job);\n \n     // setup the child\u0027s attempt directories\n     // Do the task-type specific localization\n     task.localizeConfiguration(job);\n \n     // Set up the DistributedCache related configs\n     setupDistributedCacheConfig(job);\n \n     // Overwrite the localized task jobconf which is linked to in the current\n     // work-dir.\n-    Path localTaskFile \u003d new Path(Constants.JOBFILE);\n+    Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n     writeLocalJobFile(localTaskFile, job);\n     task.setJobFile(localTaskFile.toString());\n     task.setConf(job);\n     return job;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private static JobConf configureTask(Task task, Credentials credentials,\n      Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n    final JobConf job \u003d new JobConf(MRJobConfig.JOB_CONF_FILE);\n    job.setCredentials(credentials);\n    // set tcp nodelay\n    job.setBoolean(\"ipc.client.tcpnodelay\", true);\n    job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n        YarnOutputFiles.class, MapOutputFile.class);\n    // set the jobTokenFile into task\n    task.setJobTokenSecret(\n        JobTokenSecretManager.createSecretKey(jt.getPassword()));\n\n    // setup the child\u0027s MRConfig.LOCAL_DIR.\n    configureLocalDirs(task, job);\n\n    // setup the child\u0027s attempt directories\n    // Do the task-type specific localization\n    task.localizeConfiguration(job);\n\n    // Set up the DistributedCache related configs\n    setupDistributedCacheConfig(job);\n\n    // Overwrite the localized task jobconf which is linked to in the current\n    // work-dir.\n    Path localTaskFile \u003d new Path(MRJobConfig.JOB_CONF_FILE);\n    writeLocalJobFile(localTaskFile, job);\n    task.setJobFile(localTaskFile.toString());\n    task.setConf(job);\n    return job;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private static JobConf configureTask(Task task, Credentials credentials,\n      Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n    final JobConf job \u003d new JobConf(MRConstants.JOB_CONF_FILE);\n    job.setCredentials(credentials);\n    // set tcp nodelay\n    job.setBoolean(\"ipc.client.tcpnodelay\", true);\n    job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n        YarnOutputFiles.class, MapOutputFile.class);\n    // set the jobTokenFile into task\n    task.setJobTokenSecret(\n        JobTokenSecretManager.createSecretKey(jt.getPassword()));\n\n    // setup the child\u0027s MRConfig.LOCAL_DIR.\n    configureLocalDirs(task, job);\n\n    // setup the child\u0027s attempt directories\n    // Do the task-type specific localization\n    task.localizeConfiguration(job);\n\n    // Set up the DistributedCache related configs\n    setupDistributedCacheConfig(job);\n\n    // Overwrite the localized task jobconf which is linked to in the current\n    // work-dir.\n    Path localTaskFile \u003d new Path(Constants.JOBFILE);\n    writeLocalJobFile(localTaskFile, job);\n    task.setJobFile(localTaskFile.toString());\n    task.setConf(job);\n    return job;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "diff": "@@ -0,0 +1,30 @@\n+  private static JobConf configureTask(Task task, Credentials credentials,\n+      Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n+    final JobConf job \u003d new JobConf(MRConstants.JOB_CONF_FILE);\n+    job.setCredentials(credentials);\n+    // set tcp nodelay\n+    job.setBoolean(\"ipc.client.tcpnodelay\", true);\n+    job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n+        YarnOutputFiles.class, MapOutputFile.class);\n+    // set the jobTokenFile into task\n+    task.setJobTokenSecret(\n+        JobTokenSecretManager.createSecretKey(jt.getPassword()));\n+\n+    // setup the child\u0027s MRConfig.LOCAL_DIR.\n+    configureLocalDirs(task, job);\n+\n+    // setup the child\u0027s attempt directories\n+    // Do the task-type specific localization\n+    task.localizeConfiguration(job);\n+\n+    // Set up the DistributedCache related configs\n+    setupDistributedCacheConfig(job);\n+\n+    // Overwrite the localized task jobconf which is linked to in the current\n+    // work-dir.\n+    Path localTaskFile \u003d new Path(Constants.JOBFILE);\n+    writeLocalJobFile(localTaskFile, job);\n+    task.setJobFile(localTaskFile.toString());\n+    task.setConf(job);\n+    return job;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private static JobConf configureTask(Task task, Credentials credentials,\n      Token\u003cJobTokenIdentifier\u003e jt) throws IOException {\n    final JobConf job \u003d new JobConf(MRConstants.JOB_CONF_FILE);\n    job.setCredentials(credentials);\n    // set tcp nodelay\n    job.setBoolean(\"ipc.client.tcpnodelay\", true);\n    job.setClass(MRConfig.TASK_LOCAL_OUTPUT_CLASS,\n        YarnOutputFiles.class, MapOutputFile.class);\n    // set the jobTokenFile into task\n    task.setJobTokenSecret(\n        JobTokenSecretManager.createSecretKey(jt.getPassword()));\n\n    // setup the child\u0027s MRConfig.LOCAL_DIR.\n    configureLocalDirs(task, job);\n\n    // setup the child\u0027s attempt directories\n    // Do the task-type specific localization\n    task.localizeConfiguration(job);\n\n    // Set up the DistributedCache related configs\n    setupDistributedCacheConfig(job);\n\n    // Overwrite the localized task jobconf which is linked to in the current\n    // work-dir.\n    Path localTaskFile \u003d new Path(Constants.JOBFILE);\n    writeLocalJobFile(localTaskFile, job);\n    task.setJobFile(localTaskFile.toString());\n    task.setConf(job);\n    return job;\n  }",
      "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java"
    }
  }
}