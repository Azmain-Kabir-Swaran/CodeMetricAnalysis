{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeAdminManager.java",
  "functionName": "stopDecommission",
  "functionId": "stopDecommission___node-DatanodeDescriptor",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
  "functionStartLine": 200,
  "functionEndLine": 215,
  "numCommitsSeen": 169,
  "timeTaken": 13468,
  "changeHistory": [
    "c93cb6790e0f1c64efd03d859f907a0522010894",
    "6f81cc0beea00843b44424417f09d8ee12cd7bae",
    "79df1e750ef558afed6d166ce225a23061b36aed",
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
    "9dcbdbdb5a34d85910707f81ebc1bb1f81c99978",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
    "be7a0add8b6561d3c566237cc0370b06e7f32bb4",
    "6af0d74a75f0f58d5e92e2e91e87735b9a62bb12",
    "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a",
    "54b70db347c2ebf577919f2c42f171c6801e9ba1",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
    "be7dd8333a7e56e732171db0781786987de03195",
    "0663dbaac0a19719ddf9cd4290ba893bfca69da2",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "7fac946ac983e31613fd62836c8ac9c4a579210a",
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
    "08928d067bb9e1d38b5e7db9e23fcf20fe161435",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": "Ybodychange",
    "6f81cc0beea00843b44424417f09d8ee12cd7bae": "Ybodychange",
    "79df1e750ef558afed6d166ce225a23061b36aed": "Ymultichange(Yfilerename,Ybodychange)",
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": "Ybodychange",
    "9dcbdbdb5a34d85910707f81ebc1bb1f81c99978": "Ybodychange",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": "Ybodychange",
    "be7a0add8b6561d3c566237cc0370b06e7f32bb4": "Ybodychange",
    "6af0d74a75f0f58d5e92e2e91e87735b9a62bb12": "Ymultichange(Ymodifierchange,Ybodychange)",
    "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a": "Ymultichange(Ymovefromfile,Ybodychange)",
    "54b70db347c2ebf577919f2c42f171c6801e9ba1": "Ybodychange",
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": "Ybodychange",
    "be7dd8333a7e56e732171db0781786987de03195": "Ybodychange",
    "0663dbaac0a19719ddf9cd4290ba893bfca69da2": "Yexceptionschange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "7fac946ac983e31613fd62836c8ac9c4a579210a": "Ymultichange(Ymovefromfile,Ybodychange)",
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange)",
    "08928d067bb9e1d38b5e7db9e23fcf20fe161435": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14854. Create improved decommission monitor implementation. Contributed by Stephen O\u0027Donnell.\n\nReviewed-by: Inigo Goiri \u003cinigoiri@apache.org\u003e\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "10/12/19 5:16 PM",
      "commitName": "c93cb6790e0f1c64efd03d859f907a0522010894",
      "commitAuthor": "Stephen O\u0027Donnell",
      "commitDateOld": "19/10/19 5:40 PM",
      "commitNameOld": "447f46d9628db54e77f88e2d109587cc7dfd6154",
      "commitAuthorOld": "Ayush Saxena",
      "daysBetweenCommits": 52.02,
      "commitsBetweenForRepo": 198,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,16 @@\n   public void stopDecommission(DatanodeDescriptor node) {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n       // Update DN stats maintained by HeartbeatManager\n       hbManager.stopDecommission(node);\n       // extra redundancy blocks will be detected and processed when\n       // the dead node comes back and send in its full block report.\n       if (node.isAlive()) {\n         blockManager.processExtraRedundancyBlocksOnInService(node);\n       }\n       // Remove from tracking in DatanodeAdminManager\n-      pendingNodes.remove(node);\n-      outOfServiceNodeBlocks.remove(node);\n+      monitor.stopTrackingNode(node);\n     } else {\n       LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\",\n           node, node.getAdminState());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void stopDecommission(DatanodeDescriptor node) {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      // Update DN stats maintained by HeartbeatManager\n      hbManager.stopDecommission(node);\n      // extra redundancy blocks will be detected and processed when\n      // the dead node comes back and send in its full block report.\n      if (node.isAlive()) {\n        blockManager.processExtraRedundancyBlocksOnInService(node);\n      }\n      // Remove from tracking in DatanodeAdminManager\n      monitor.stopTrackingNode(node);\n    } else {\n      LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\",\n          node, node.getAdminState());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
      "extendedDetails": {}
    },
    "6f81cc0beea00843b44424417f09d8ee12cd7bae": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13167. DatanodeAdminManager Improvements. Contributed by BELUGA BEHR.\n",
      "commitDate": "20/02/18 3:18 PM",
      "commitName": "6f81cc0beea00843b44424417f09d8ee12cd7bae",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "02/01/18 2:59 PM",
      "commitNameOld": "42a1c98597e6dba2e371510a6b2b6b1fb94e4090",
      "commitAuthorOld": "Manoj Govindassamy",
      "daysBetweenCommits": 49.01,
      "commitsBetweenForRepo": 297,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   public void stopDecommission(DatanodeDescriptor node) {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n       // Update DN stats maintained by HeartbeatManager\n       hbManager.stopDecommission(node);\n       // extra redundancy blocks will be detected and processed when\n       // the dead node comes back and send in its full block report.\n       if (node.isAlive()) {\n         blockManager.processExtraRedundancyBlocksOnInService(node);\n       }\n       // Remove from tracking in DatanodeAdminManager\n       pendingNodes.remove(node);\n       outOfServiceNodeBlocks.remove(node);\n     } else {\n-      LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\" +\n+      LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\",\n           node, node.getAdminState());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void stopDecommission(DatanodeDescriptor node) {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      // Update DN stats maintained by HeartbeatManager\n      hbManager.stopDecommission(node);\n      // extra redundancy blocks will be detected and processed when\n      // the dead node comes back and send in its full block report.\n      if (node.isAlive()) {\n        blockManager.processExtraRedundancyBlocksOnInService(node);\n      }\n      // Remove from tracking in DatanodeAdminManager\n      pendingNodes.remove(node);\n      outOfServiceNodeBlocks.remove(node);\n    } else {\n      LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\",\n          node, node.getAdminState());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
      "extendedDetails": {}
    },
    "79df1e750ef558afed6d166ce225a23061b36aed": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "HDFS-9388. Decommission related code to support Maintenance State for datanodes.\n",
      "commitDate": "02/08/17 2:22 PM",
      "commitName": "79df1e750ef558afed6d166ce225a23061b36aed",
      "commitAuthor": "Manoj Govindassamy",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "HDFS-9388. Decommission related code to support Maintenance State for datanodes.\n",
          "commitDate": "02/08/17 2:22 PM",
          "commitName": "79df1e750ef558afed6d166ce225a23061b36aed",
          "commitAuthor": "Manoj Govindassamy",
          "commitDateOld": "02/08/17 12:12 PM",
          "commitNameOld": "12e44e7bdaf53d3720a89d32f0cc2717241bd6b2",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 0.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,17 @@\n   public void stopDecommission(DatanodeDescriptor node) {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n       // Update DN stats maintained by HeartbeatManager\n       hbManager.stopDecommission(node);\n       // extra redundancy blocks will be detected and processed when\n       // the dead node comes back and send in its full block report.\n       if (node.isAlive()) {\n         blockManager.processExtraRedundancyBlocksOnInService(node);\n       }\n-      // Remove from tracking in DecommissionManager\n+      // Remove from tracking in DatanodeAdminManager\n       pendingNodes.remove(node);\n       outOfServiceNodeBlocks.remove(node);\n     } else {\n       LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\" +\n           node, node.getAdminState());\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void stopDecommission(DatanodeDescriptor node) {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      // Update DN stats maintained by HeartbeatManager\n      hbManager.stopDecommission(node);\n      // extra redundancy blocks will be detected and processed when\n      // the dead node comes back and send in its full block report.\n      if (node.isAlive()) {\n        blockManager.processExtraRedundancyBlocksOnInService(node);\n      }\n      // Remove from tracking in DatanodeAdminManager\n      pendingNodes.remove(node);\n      outOfServiceNodeBlocks.remove(node);\n    } else {\n      LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\" +\n          node, node.getAdminState());\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9388. Decommission related code to support Maintenance State for datanodes.\n",
          "commitDate": "02/08/17 2:22 PM",
          "commitName": "79df1e750ef558afed6d166ce225a23061b36aed",
          "commitAuthor": "Manoj Govindassamy",
          "commitDateOld": "02/08/17 12:12 PM",
          "commitNameOld": "12e44e7bdaf53d3720a89d32f0cc2717241bd6b2",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 0.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,17 @@\n   public void stopDecommission(DatanodeDescriptor node) {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n       // Update DN stats maintained by HeartbeatManager\n       hbManager.stopDecommission(node);\n       // extra redundancy blocks will be detected and processed when\n       // the dead node comes back and send in its full block report.\n       if (node.isAlive()) {\n         blockManager.processExtraRedundancyBlocksOnInService(node);\n       }\n-      // Remove from tracking in DecommissionManager\n+      // Remove from tracking in DatanodeAdminManager\n       pendingNodes.remove(node);\n       outOfServiceNodeBlocks.remove(node);\n     } else {\n       LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\" +\n           node, node.getAdminState());\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void stopDecommission(DatanodeDescriptor node) {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      // Update DN stats maintained by HeartbeatManager\n      hbManager.stopDecommission(node);\n      // extra redundancy blocks will be detected and processed when\n      // the dead node comes back and send in its full block report.\n      if (node.isAlive()) {\n        blockManager.processExtraRedundancyBlocksOnInService(node);\n      }\n      // Remove from tracking in DatanodeAdminManager\n      pendingNodes.remove(node);\n      outOfServiceNodeBlocks.remove(node);\n    } else {\n      LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\" +\n          node, node.getAdminState());\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
      "commitDate": "17/10/16 5:45 PM",
      "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
      "commitAuthor": "Ming Ma",
      "commitDateOld": "13/10/16 11:52 AM",
      "commitNameOld": "332a61fd74fd2a9874319232c583ab5d2c53ff03",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 4.25,
      "commitsBetweenForRepo": 27,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   public void stopDecommission(DatanodeDescriptor node) {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n       // Update DN stats maintained by HeartbeatManager\n       hbManager.stopDecommission(node);\n       // extra redundancy blocks will be detected and processed when\n       // the dead node comes back and send in its full block report.\n       if (node.isAlive()) {\n-        blockManager.processExtraRedundancyBlocksOnReCommission(node);\n+        blockManager.processExtraRedundancyBlocksOnInService(node);\n       }\n       // Remove from tracking in DecommissionManager\n       pendingNodes.remove(node);\n       outOfServiceNodeBlocks.remove(node);\n     } else {\n       LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\" +\n           node, node.getAdminState());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void stopDecommission(DatanodeDescriptor node) {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      // Update DN stats maintained by HeartbeatManager\n      hbManager.stopDecommission(node);\n      // extra redundancy blocks will be detected and processed when\n      // the dead node comes back and send in its full block report.\n      if (node.isAlive()) {\n        blockManager.processExtraRedundancyBlocksOnInService(node);\n      }\n      // Remove from tracking in DecommissionManager\n      pendingNodes.remove(node);\n      outOfServiceNodeBlocks.remove(node);\n    } else {\n      LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\" +\n          node, node.getAdminState());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
      "extendedDetails": {}
    },
    "9dcbdbdb5a34d85910707f81ebc1bb1f81c99978": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9392. Admins support for maintenance state. Contributed by Ming Ma.\n",
      "commitDate": "30/08/16 2:00 PM",
      "commitName": "9dcbdbdb5a34d85910707f81ebc1bb1f81c99978",
      "commitAuthor": "Ming Ma",
      "commitDateOld": "26/05/16 4:50 PM",
      "commitNameOld": "8c84a2a93c22a93b4ff46dd917f6efb995675fbd",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 95.88,
      "commitsBetweenForRepo": 766,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   public void stopDecommission(DatanodeDescriptor node) {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n       // Update DN stats maintained by HeartbeatManager\n       hbManager.stopDecommission(node);\n       // extra redundancy blocks will be detected and processed when\n       // the dead node comes back and send in its full block report.\n       if (node.isAlive()) {\n         blockManager.processExtraRedundancyBlocksOnReCommission(node);\n       }\n       // Remove from tracking in DecommissionManager\n       pendingNodes.remove(node);\n-      decomNodeBlocks.remove(node);\n+      outOfServiceNodeBlocks.remove(node);\n     } else {\n       LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\" +\n           node, node.getAdminState());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void stopDecommission(DatanodeDescriptor node) {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      // Update DN stats maintained by HeartbeatManager\n      hbManager.stopDecommission(node);\n      // extra redundancy blocks will be detected and processed when\n      // the dead node comes back and send in its full block report.\n      if (node.isAlive()) {\n        blockManager.processExtraRedundancyBlocksOnReCommission(node);\n      }\n      // Remove from tracking in DecommissionManager\n      pendingNodes.remove(node);\n      outOfServiceNodeBlocks.remove(node);\n    } else {\n      LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\" +\n          node, node.getAdminState());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
      "extendedDetails": {}
    },
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9857. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-1]. Contributed by Rakesh R.\n",
      "commitDate": "16/03/16 4:53 PM",
      "commitName": "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "14/03/16 9:54 AM",
      "commitNameOld": "5644137adad30c84e40d2c4719627b3aabc73628",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 2.29,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   public void stopDecommission(DatanodeDescriptor node) {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n       // Update DN stats maintained by HeartbeatManager\n       hbManager.stopDecommission(node);\n-      // Over-replicated blocks will be detected and processed when\n+      // extra redundancy blocks will be detected and processed when\n       // the dead node comes back and send in its full block report.\n       if (node.isAlive()) {\n-        blockManager.processOverReplicatedBlocksOnReCommission(node);\n+        blockManager.processExtraRedundancyBlocksOnReCommission(node);\n       }\n       // Remove from tracking in DecommissionManager\n       pendingNodes.remove(node);\n       decomNodeBlocks.remove(node);\n     } else {\n       LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\" +\n           node, node.getAdminState());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void stopDecommission(DatanodeDescriptor node) {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      // Update DN stats maintained by HeartbeatManager\n      hbManager.stopDecommission(node);\n      // extra redundancy blocks will be detected and processed when\n      // the dead node comes back and send in its full block report.\n      if (node.isAlive()) {\n        blockManager.processExtraRedundancyBlocksOnReCommission(node);\n      }\n      // Remove from tracking in DecommissionManager\n      pendingNodes.remove(node);\n      decomNodeBlocks.remove(node);\n    } else {\n      LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\" +\n          node, node.getAdminState());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
      "extendedDetails": {}
    },
    "be7a0add8b6561d3c566237cc0370b06e7f32bb4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9223. Code cleanup for DatanodeDescriptor and HeartbeatManager. Contributed by Jing Zhao.\n",
      "commitDate": "14/10/15 4:17 PM",
      "commitName": "be7a0add8b6561d3c566237cc0370b06e7f32bb4",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "22/09/15 1:27 PM",
      "commitNameOld": "1080c3730068177ddd10dc313890ac1f5dc58f1a",
      "commitAuthorOld": "",
      "daysBetweenCommits": 22.12,
      "commitsBetweenForRepo": 178,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,17 @@\n   public void stopDecommission(DatanodeDescriptor node) {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n       // Update DN stats maintained by HeartbeatManager\n       hbManager.stopDecommission(node);\n       // Over-replicated blocks will be detected and processed when\n       // the dead node comes back and send in its full block report.\n-      if (node.isAlive) {\n+      if (node.isAlive()) {\n         blockManager.processOverReplicatedBlocksOnReCommission(node);\n       }\n       // Remove from tracking in DecommissionManager\n       pendingNodes.remove(node);\n       decomNodeBlocks.remove(node);\n     } else {\n       LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\" +\n           node, node.getAdminState());\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void stopDecommission(DatanodeDescriptor node) {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      // Update DN stats maintained by HeartbeatManager\n      hbManager.stopDecommission(node);\n      // Over-replicated blocks will be detected and processed when\n      // the dead node comes back and send in its full block report.\n      if (node.isAlive()) {\n        blockManager.processOverReplicatedBlocksOnReCommission(node);\n      }\n      // Remove from tracking in DecommissionManager\n      pendingNodes.remove(node);\n      decomNodeBlocks.remove(node);\n    } else {\n      LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\" +\n          node, node.getAdminState());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
      "extendedDetails": {}
    },
    "6af0d74a75f0f58d5e92e2e91e87735b9a62bb12": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-7725. Incorrect \u0027nodes in service\u0027 metrics caused all writes to fail. Contributed by Ming Ma.\n",
      "commitDate": "08/04/15 3:52 PM",
      "commitName": "6af0d74a75f0f58d5e92e2e91e87735b9a62bb12",
      "commitAuthor": "Andrew Wang",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-7725. Incorrect \u0027nodes in service\u0027 metrics caused all writes to fail. Contributed by Ming Ma.\n",
          "commitDate": "08/04/15 3:52 PM",
          "commitName": "6af0d74a75f0f58d5e92e2e91e87735b9a62bb12",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "20/03/15 12:02 PM",
          "commitNameOld": "75ead273bea8a7dad61c4f99c3a16cab2697c498",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 19.16,
          "commitsBetweenForRepo": 165,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,17 @@\n-  void stopDecommission(DatanodeDescriptor node) {\n+  public void stopDecommission(DatanodeDescriptor node) {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n-      LOG.info(\"Stopping decommissioning of node {}\", node);\n       // Update DN stats maintained by HeartbeatManager\n       hbManager.stopDecommission(node);\n-      // Over-replicated blocks will be detected and processed when \n+      // Over-replicated blocks will be detected and processed when\n       // the dead node comes back and send in its full block report.\n       if (node.isAlive) {\n         blockManager.processOverReplicatedBlocksOnReCommission(node);\n       }\n       // Remove from tracking in DecommissionManager\n       pendingNodes.remove(node);\n       decomNodeBlocks.remove(node);\n     } else {\n-      LOG.trace(\"stopDecommission: Node {} is not decommission in progress \" +\n-          \"or decommissioned, nothing to do.\", node);\n+      LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\" +\n+          node, node.getAdminState());\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void stopDecommission(DatanodeDescriptor node) {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      // Update DN stats maintained by HeartbeatManager\n      hbManager.stopDecommission(node);\n      // Over-replicated blocks will be detected and processed when\n      // the dead node comes back and send in its full block report.\n      if (node.isAlive) {\n        blockManager.processOverReplicatedBlocksOnReCommission(node);\n      }\n      // Remove from tracking in DecommissionManager\n      pendingNodes.remove(node);\n      decomNodeBlocks.remove(node);\n    } else {\n      LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\" +\n          node, node.getAdminState());\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7725. Incorrect \u0027nodes in service\u0027 metrics caused all writes to fail. Contributed by Ming Ma.\n",
          "commitDate": "08/04/15 3:52 PM",
          "commitName": "6af0d74a75f0f58d5e92e2e91e87735b9a62bb12",
          "commitAuthor": "Andrew Wang",
          "commitDateOld": "20/03/15 12:02 PM",
          "commitNameOld": "75ead273bea8a7dad61c4f99c3a16cab2697c498",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 19.16,
          "commitsBetweenForRepo": 165,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,18 +1,17 @@\n-  void stopDecommission(DatanodeDescriptor node) {\n+  public void stopDecommission(DatanodeDescriptor node) {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n-      LOG.info(\"Stopping decommissioning of node {}\", node);\n       // Update DN stats maintained by HeartbeatManager\n       hbManager.stopDecommission(node);\n-      // Over-replicated blocks will be detected and processed when \n+      // Over-replicated blocks will be detected and processed when\n       // the dead node comes back and send in its full block report.\n       if (node.isAlive) {\n         blockManager.processOverReplicatedBlocksOnReCommission(node);\n       }\n       // Remove from tracking in DecommissionManager\n       pendingNodes.remove(node);\n       decomNodeBlocks.remove(node);\n     } else {\n-      LOG.trace(\"stopDecommission: Node {} is not decommission in progress \" +\n-          \"or decommissioned, nothing to do.\", node);\n+      LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\" +\n+          node, node.getAdminState());\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public void stopDecommission(DatanodeDescriptor node) {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      // Update DN stats maintained by HeartbeatManager\n      hbManager.stopDecommission(node);\n      // Over-replicated blocks will be detected and processed when\n      // the dead node comes back and send in its full block report.\n      if (node.isAlive) {\n        blockManager.processOverReplicatedBlocksOnReCommission(node);\n      }\n      // Remove from tracking in DecommissionManager\n      pendingNodes.remove(node);\n      decomNodeBlocks.remove(node);\n    } else {\n      LOG.trace(\"stopDecommission: Node {} in {}, nothing to do.\" +\n          node, node.getAdminState());\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-7411. Change decommission logic to throttle by blocks rather\nthan nodes in each interval. Contributed by Andrew Wang\n",
      "commitDate": "08/03/15 6:31 PM",
      "commitName": "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a",
      "commitAuthor": "Chris Douglas",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-7411. Change decommission logic to throttle by blocks rather\nthan nodes in each interval. Contributed by Andrew Wang\n",
          "commitDate": "08/03/15 6:31 PM",
          "commitName": "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a",
          "commitAuthor": "Chris Douglas",
          "commitDateOld": "08/03/15 2:47 PM",
          "commitNameOld": "7ce3c7635392c32f0504191ddd8417fb20509caa",
          "commitAuthorOld": "Junping Du",
          "daysBetweenCommits": 0.16,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,18 @@\n   void stopDecommission(DatanodeDescriptor node) {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n-      LOG.info(\"Stop Decommissioning \" + node);\n-      heartbeatManager.stopDecommission(node);\n+      LOG.info(\"Stopping decommissioning of node {}\", node);\n+      // Update DN stats maintained by HeartbeatManager\n+      hbManager.stopDecommission(node);\n       // Over-replicated blocks will be detected and processed when \n       // the dead node comes back and send in its full block report.\n       if (node.isAlive) {\n         blockManager.processOverReplicatedBlocksOnReCommission(node);\n       }\n+      // Remove from tracking in DecommissionManager\n+      pendingNodes.remove(node);\n+      decomNodeBlocks.remove(node);\n+    } else {\n+      LOG.trace(\"stopDecommission: Node {} is not decommission in progress \" +\n+          \"or decommissioned, nothing to do.\", node);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void stopDecommission(DatanodeDescriptor node) {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      LOG.info(\"Stopping decommissioning of node {}\", node);\n      // Update DN stats maintained by HeartbeatManager\n      hbManager.stopDecommission(node);\n      // Over-replicated blocks will be detected and processed when \n      // the dead node comes back and send in its full block report.\n      if (node.isAlive) {\n        blockManager.processOverReplicatedBlocksOnReCommission(node);\n      }\n      // Remove from tracking in DecommissionManager\n      pendingNodes.remove(node);\n      decomNodeBlocks.remove(node);\n    } else {\n      LOG.trace(\"stopDecommission: Node {} is not decommission in progress \" +\n          \"or decommissioned, nothing to do.\", node);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
            "oldMethodName": "stopDecommission",
            "newMethodName": "stopDecommission"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7411. Change decommission logic to throttle by blocks rather\nthan nodes in each interval. Contributed by Andrew Wang\n",
          "commitDate": "08/03/15 6:31 PM",
          "commitName": "6ee0d32b98bc3aa5ed42859f1325d5a14fd1722a",
          "commitAuthor": "Chris Douglas",
          "commitDateOld": "08/03/15 2:47 PM",
          "commitNameOld": "7ce3c7635392c32f0504191ddd8417fb20509caa",
          "commitAuthorOld": "Junping Du",
          "daysBetweenCommits": 0.16,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,18 @@\n   void stopDecommission(DatanodeDescriptor node) {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n-      LOG.info(\"Stop Decommissioning \" + node);\n-      heartbeatManager.stopDecommission(node);\n+      LOG.info(\"Stopping decommissioning of node {}\", node);\n+      // Update DN stats maintained by HeartbeatManager\n+      hbManager.stopDecommission(node);\n       // Over-replicated blocks will be detected and processed when \n       // the dead node comes back and send in its full block report.\n       if (node.isAlive) {\n         blockManager.processOverReplicatedBlocksOnReCommission(node);\n       }\n+      // Remove from tracking in DecommissionManager\n+      pendingNodes.remove(node);\n+      decomNodeBlocks.remove(node);\n+    } else {\n+      LOG.trace(\"stopDecommission: Node {} is not decommission in progress \" +\n+          \"or decommissioned, nothing to do.\", node);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void stopDecommission(DatanodeDescriptor node) {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      LOG.info(\"Stopping decommissioning of node {}\", node);\n      // Update DN stats maintained by HeartbeatManager\n      hbManager.stopDecommission(node);\n      // Over-replicated blocks will be detected and processed when \n      // the dead node comes back and send in its full block report.\n      if (node.isAlive) {\n        blockManager.processOverReplicatedBlocksOnReCommission(node);\n      }\n      // Remove from tracking in DecommissionManager\n      pendingNodes.remove(node);\n      decomNodeBlocks.remove(node);\n    } else {\n      LOG.trace(\"stopDecommission: Node {} is not decommission in progress \" +\n          \"or decommissioned, nothing to do.\", node);\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "54b70db347c2ebf577919f2c42f171c6801e9ba1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4075. Reduce recommissioning overhead (Kihwal Lee via daryn)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1406278 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/11/12 11:27 AM",
      "commitName": "54b70db347c2ebf577919f2c42f171c6801e9ba1",
      "commitAuthor": "Daryn Sharp",
      "commitDateOld": "28/10/12 4:10 PM",
      "commitNameOld": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 8.85,
      "commitsBetweenForRepo": 38,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,11 @@\n   void stopDecommission(DatanodeDescriptor node) {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n       LOG.info(\"Stop Decommissioning \" + node);\n       heartbeatManager.stopDecommission(node);\n-      blockManager.processOverReplicatedBlocksOnReCommission(node);\n+      // Over-replicated blocks will be detected and processed when \n+      // the dead node comes back and send in its full block report.\n+      if (node.isAlive) {\n+        blockManager.processOverReplicatedBlocksOnReCommission(node);\n+      }\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void stopDecommission(DatanodeDescriptor node) {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      LOG.info(\"Stop Decommissioning \" + node);\n      heartbeatManager.stopDecommission(node);\n      // Over-replicated blocks will be detected and processed when \n      // the dead node comes back and send in its full block report.\n      if (node.isAlive) {\n        blockManager.processOverReplicatedBlocksOnReCommission(node);\n      }\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "cea7bbc630deede93dbe6a1bbda56ad49de4f3de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-4122. Cleanup HDFS logs and reduce the size of logged messages. Contributed by Suresh Srinivas.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1403120 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/10/12 4:10 PM",
      "commitName": "cea7bbc630deede93dbe6a1bbda56ad49de4f3de",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "17/10/12 2:34 PM",
      "commitNameOld": "4d5600f6c714732d16bed29f0bc210eb72901545",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 11.07,
      "commitsBetweenForRepo": 61,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n   void stopDecommission(DatanodeDescriptor node) {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n-      LOG.info(\"Stop Decommissioning node \" + node);\n+      LOG.info(\"Stop Decommissioning \" + node);\n       heartbeatManager.stopDecommission(node);\n       blockManager.processOverReplicatedBlocksOnReCommission(node);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void stopDecommission(DatanodeDescriptor node) {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      LOG.info(\"Stop Decommissioning \" + node);\n      heartbeatManager.stopDecommission(node);\n      blockManager.processOverReplicatedBlocksOnReCommission(node);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "be7dd8333a7e56e732171db0781786987de03195": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3144. Refactor DatanodeID#getName by use. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308205 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/04/12 3:12 PM",
      "commitName": "be7dd8333a7e56e732171db0781786987de03195",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "31/03/12 8:41 PM",
      "commitNameOld": "0663dbaac0a19719ddf9cd4290ba893bfca69da2",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.77,
      "commitsBetweenForRepo": 5,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n   void stopDecommission(DatanodeDescriptor node) {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n-      LOG.info(\"Stop Decommissioning node \" + node.getName());\n+      LOG.info(\"Stop Decommissioning node \" + node);\n       heartbeatManager.stopDecommission(node);\n       blockManager.processOverReplicatedBlocksOnReCommission(node);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void stopDecommission(DatanodeDescriptor node) {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      LOG.info(\"Stop Decommissioning node \" + node);\n      heartbeatManager.stopDecommission(node);\n      blockManager.processOverReplicatedBlocksOnReCommission(node);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {}
    },
    "0663dbaac0a19719ddf9cd4290ba893bfca69da2": {
      "type": "Yexceptionschange",
      "commitMessage": "HDFS-3171. The DatanodeID \"name\" field is overloaded. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308014 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "31/03/12 8:41 PM",
      "commitName": "0663dbaac0a19719ddf9cd4290ba893bfca69da2",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "31/03/12 12:58 PM",
      "commitNameOld": "8bd825bb6f35fd6fef397e3ccae0898bf7bed201",
      "commitAuthorOld": "Eli Collins",
      "daysBetweenCommits": 0.32,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,7 @@\n-  void stopDecommission(DatanodeDescriptor node) throws IOException {\n+  void stopDecommission(DatanodeDescriptor node) {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n       LOG.info(\"Stop Decommissioning node \" + node.getName());\n       heartbeatManager.stopDecommission(node);\n       blockManager.processOverReplicatedBlocksOnReCommission(node);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void stopDecommission(DatanodeDescriptor node) {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      LOG.info(\"Stop Decommissioning node \" + node.getName());\n      heartbeatManager.stopDecommission(node);\n      blockManager.processOverReplicatedBlocksOnReCommission(node);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldValue": "[IOException]",
        "newValue": "[]"
      }
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  void stopDecommission(DatanodeDescriptor node) throws IOException {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      LOG.info(\"Stop Decommissioning node \" + node.getName());\n      heartbeatManager.stopDecommission(node);\n      blockManager.processOverReplicatedBlocksOnReCommission(node);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  void stopDecommission(DatanodeDescriptor node) throws IOException {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      LOG.info(\"Stop Decommissioning node \" + node.getName());\n      heartbeatManager.stopDecommission(node);\n      blockManager.processOverReplicatedBlocksOnReCommission(node);\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java"
      }
    },
    "7fac946ac983e31613fd62836c8ac9c4a579210a": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-2108. Move datanode heartbeat handling from namenode package to blockmanagement package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154042 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/08/11 3:55 PM",
      "commitName": "7fac946ac983e31613fd62836c8ac9c4a579210a",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-2108. Move datanode heartbeat handling from namenode package to blockmanagement package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154042 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/08/11 3:55 PM",
          "commitName": "7fac946ac983e31613fd62836c8ac9c4a579210a",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "04/08/11 2:56 PM",
          "commitNameOld": "23762da4fa17ce6ea7b70722147977123a28a7e6",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,7 @@\n   void stopDecommission(DatanodeDescriptor node) throws IOException {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n       LOG.info(\"Stop Decommissioning node \" + node.getName());\n-      synchronized (namesystem.heartbeats) {\n-        namesystem.updateStats(node, false);\n-        node.stopDecommission();\n-        namesystem.updateStats(node, true);\n-      }\n-      processOverReplicatedBlocksOnReCommission(node);\n+      heartbeatManager.stopDecommission(node);\n+      blockManager.processOverReplicatedBlocksOnReCommission(node);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void stopDecommission(DatanodeDescriptor node) throws IOException {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      LOG.info(\"Stop Decommissioning node \" + node.getName());\n      heartbeatManager.stopDecommission(node);\n      blockManager.processOverReplicatedBlocksOnReCommission(node);\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {
            "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
            "newPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
            "oldMethodName": "stopDecommission",
            "newMethodName": "stopDecommission"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2108. Move datanode heartbeat handling from namenode package to blockmanagement package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154042 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "04/08/11 3:55 PM",
          "commitName": "7fac946ac983e31613fd62836c8ac9c4a579210a",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "04/08/11 2:56 PM",
          "commitNameOld": "23762da4fa17ce6ea7b70722147977123a28a7e6",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.04,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,11 +1,7 @@\n   void stopDecommission(DatanodeDescriptor node) throws IOException {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n       LOG.info(\"Stop Decommissioning node \" + node.getName());\n-      synchronized (namesystem.heartbeats) {\n-        namesystem.updateStats(node, false);\n-        node.stopDecommission();\n-        namesystem.updateStats(node, true);\n-      }\n-      processOverReplicatedBlocksOnReCommission(node);\n+      heartbeatManager.stopDecommission(node);\n+      blockManager.processOverReplicatedBlocksOnReCommission(node);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void stopDecommission(DatanodeDescriptor node) throws IOException {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      LOG.info(\"Stop Decommissioning node \" + node.getName());\n      heartbeatManager.stopDecommission(node);\n      blockManager.processOverReplicatedBlocksOnReCommission(node);\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "233a7aa34f37350bf7bcdd9c84b97d613e7344c9": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-2167.  Move dnsToSwitchMapping and hostsReader from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149455 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/07/11 9:20 PM",
      "commitName": "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-2167.  Move dnsToSwitchMapping and hostsReader from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149455 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/07/11 9:20 PM",
          "commitName": "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/07/11 12:16 PM",
          "commitNameOld": "c187bdc0a28e4f3b9378e2b1daa964c23b599383",
          "commitAuthorOld": "Owen O\u0027Malley",
          "daysBetweenCommits": 0.38,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,11 @@\n-  public void stopDecommission(DatanodeDescriptor node) \n-    throws IOException {\n-    assert hasWriteLock();\n+  void stopDecommission(DatanodeDescriptor node) throws IOException {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n       LOG.info(\"Stop Decommissioning node \" + node.getName());\n-      synchronized (heartbeats) {\n-        updateStats(node, false);\n+      synchronized (namesystem.heartbeats) {\n+        namesystem.updateStats(node, false);\n         node.stopDecommission();\n-        updateStats(node, true);\n+        namesystem.updateStats(node, true);\n       }\n-      blockManager.processOverReplicatedBlocksOnReCommission(node);\n+      processOverReplicatedBlocksOnReCommission(node);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void stopDecommission(DatanodeDescriptor node) throws IOException {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      LOG.info(\"Stop Decommissioning node \" + node.getName());\n      synchronized (namesystem.heartbeats) {\n        namesystem.updateStats(node, false);\n        node.stopDecommission();\n        namesystem.updateStats(node, true);\n      }\n      processOverReplicatedBlocksOnReCommission(node);\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
            "newPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
            "oldMethodName": "stopDecommission",
            "newMethodName": "stopDecommission"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-2167.  Move dnsToSwitchMapping and hostsReader from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149455 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/07/11 9:20 PM",
          "commitName": "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/07/11 12:16 PM",
          "commitNameOld": "c187bdc0a28e4f3b9378e2b1daa964c23b599383",
          "commitAuthorOld": "Owen O\u0027Malley",
          "daysBetweenCommits": 0.38,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,11 @@\n-  public void stopDecommission(DatanodeDescriptor node) \n-    throws IOException {\n-    assert hasWriteLock();\n+  void stopDecommission(DatanodeDescriptor node) throws IOException {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n       LOG.info(\"Stop Decommissioning node \" + node.getName());\n-      synchronized (heartbeats) {\n-        updateStats(node, false);\n+      synchronized (namesystem.heartbeats) {\n+        namesystem.updateStats(node, false);\n         node.stopDecommission();\n-        updateStats(node, true);\n+        namesystem.updateStats(node, true);\n       }\n-      blockManager.processOverReplicatedBlocksOnReCommission(node);\n+      processOverReplicatedBlocksOnReCommission(node);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void stopDecommission(DatanodeDescriptor node) throws IOException {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      LOG.info(\"Stop Decommissioning node \" + node.getName());\n      synchronized (namesystem.heartbeats) {\n        namesystem.updateStats(node, false);\n        node.stopDecommission();\n        namesystem.updateStats(node, true);\n      }\n      processOverReplicatedBlocksOnReCommission(node);\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-2167.  Move dnsToSwitchMapping and hostsReader from FSNamesystem to DatanodeManager.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1149455 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/07/11 9:20 PM",
          "commitName": "233a7aa34f37350bf7bcdd9c84b97d613e7344c9",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "21/07/11 12:16 PM",
          "commitNameOld": "c187bdc0a28e4f3b9378e2b1daa964c23b599383",
          "commitAuthorOld": "Owen O\u0027Malley",
          "daysBetweenCommits": 0.38,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,11 @@\n-  public void stopDecommission(DatanodeDescriptor node) \n-    throws IOException {\n-    assert hasWriteLock();\n+  void stopDecommission(DatanodeDescriptor node) throws IOException {\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n       LOG.info(\"Stop Decommissioning node \" + node.getName());\n-      synchronized (heartbeats) {\n-        updateStats(node, false);\n+      synchronized (namesystem.heartbeats) {\n+        namesystem.updateStats(node, false);\n         node.stopDecommission();\n-        updateStats(node, true);\n+        namesystem.updateStats(node, true);\n       }\n-      blockManager.processOverReplicatedBlocksOnReCommission(node);\n+      processOverReplicatedBlocksOnReCommission(node);\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void stopDecommission(DatanodeDescriptor node) throws IOException {\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      LOG.info(\"Stop Decommissioning node \" + node.getName());\n      synchronized (namesystem.heartbeats) {\n        namesystem.updateStats(node, false);\n        node.stopDecommission();\n        namesystem.updateStats(node, true);\n      }\n      processOverReplicatedBlocksOnReCommission(node);\n    }\n  }",
          "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "08928d067bb9e1d38b5e7db9e23fcf20fe161435": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2114. re-commission of a decommissioned node does not delete excess replicas. Contributed by John George.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1148981 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/07/11 4:35 PM",
      "commitName": "08928d067bb9e1d38b5e7db9e23fcf20fe161435",
      "commitAuthor": "Matthew Foley",
      "commitDateOld": "19/07/11 7:23 AM",
      "commitNameOld": "710e5a960e8af1d4c73e386041096aacfee8b828",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 1.38,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,13 @@\n   public void stopDecommission(DatanodeDescriptor node) \n     throws IOException {\n     assert hasWriteLock();\n     if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n       LOG.info(\"Stop Decommissioning node \" + node.getName());\n       synchronized (heartbeats) {\n         updateStats(node, false);\n         node.stopDecommission();\n         updateStats(node, true);\n       }\n+      blockManager.processOverReplicatedBlocksOnReCommission(node);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void stopDecommission(DatanodeDescriptor node) \n    throws IOException {\n    assert hasWriteLock();\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      LOG.info(\"Stop Decommissioning node \" + node.getName());\n      synchronized (heartbeats) {\n        updateStats(node, false);\n        node.stopDecommission();\n        updateStats(node, true);\n      }\n      blockManager.processOverReplicatedBlocksOnReCommission(node);\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,12 @@\n+  public void stopDecommission(DatanodeDescriptor node) \n+    throws IOException {\n+    assert hasWriteLock();\n+    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n+      LOG.info(\"Stop Decommissioning node \" + node.getName());\n+      synchronized (heartbeats) {\n+        updateStats(node, false);\n+        node.stopDecommission();\n+        updateStats(node, true);\n+      }\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void stopDecommission(DatanodeDescriptor node) \n    throws IOException {\n    assert hasWriteLock();\n    if (node.isDecommissionInProgress() || node.isDecommissioned()) {\n      LOG.info(\"Stop Decommissioning node \" + node.getName());\n      synchronized (heartbeats) {\n        updateStats(node, false);\n        node.stopDecommission();\n        updateStats(node, true);\n      }\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
    }
  }
}