{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ImageLoaderCurrent.java",
  "functionName": "processINodesUC",
  "functionId": "processINodesUC___in-DataInputStream__v-ImageVisitor__skipBlocks-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/ImageLoaderCurrent.java",
  "functionStartLine": 313,
  "functionEndLine": 360,
  "numCommitsSeen": 35,
  "timeTaken": 1943,
  "changeHistory": [
    "97f58955a6045b373ab73653bf26ab5922b00cf3"
  ],
  "changeHistoryShort": {
    "97f58955a6045b373ab73653bf26ab5922b00cf3": "Yintroduced"
  },
  "changeHistoryDetails": {
    "97f58955a6045b373ab73653bf26ab5922b00cf3": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-6293. Issues with OIV processing PB-based fsimages. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594439 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/05/14 6:15 PM",
      "commitName": "97f58955a6045b373ab73653bf26ab5922b00cf3",
      "commitAuthor": "Kihwal Lee",
      "diff": "@@ -0,0 +1,48 @@\n+  private void processINodesUC(DataInputStream in, ImageVisitor v,\n+      boolean skipBlocks) throws IOException {\n+    int numINUC \u003d in.readInt();\n+\n+    v.visitEnclosingElement(ImageElement.INODES_UNDER_CONSTRUCTION,\n+                           ImageElement.NUM_INODES_UNDER_CONSTRUCTION, numINUC);\n+\n+    for(int i \u003d 0; i \u003c numINUC; i++) {\n+      v.visitEnclosingElement(ImageElement.INODE_UNDER_CONSTRUCTION);\n+      byte [] name \u003d FSImageSerialization.readBytes(in);\n+      String n \u003d new String(name, \"UTF8\");\n+      v.visit(ImageElement.INODE_PATH, n);\n+      \n+      if (NameNodeLayoutVersion.supports(Feature.ADD_INODE_ID, imageVersion)) {\n+        long inodeId \u003d in.readLong();\n+        v.visit(ImageElement.INODE_ID, inodeId);\n+      }\n+      \n+      v.visit(ImageElement.REPLICATION, in.readShort());\n+      v.visit(ImageElement.MODIFICATION_TIME, formatDate(in.readLong()));\n+\n+      v.visit(ImageElement.PREFERRED_BLOCK_SIZE, in.readLong());\n+      int numBlocks \u003d in.readInt();\n+      processBlocks(in, v, numBlocks, skipBlocks);\n+\n+      processPermission(in, v);\n+      v.visit(ImageElement.CLIENT_NAME, FSImageSerialization.readString(in));\n+      v.visit(ImageElement.CLIENT_MACHINE, FSImageSerialization.readString(in));\n+\n+      // Skip over the datanode descriptors, which are still stored in the\n+      // file but are not used by the datanode or loaded into memory\n+      int numLocs \u003d in.readInt();\n+      for(int j \u003d 0; j \u003c numLocs; j++) {\n+        in.readShort();\n+        in.readLong();\n+        in.readLong();\n+        in.readLong();\n+        in.readInt();\n+        FSImageSerialization.readString(in);\n+        FSImageSerialization.readString(in);\n+        WritableUtils.readEnum(in, AdminStates.class);\n+      }\n+\n+      v.leaveEnclosingElement(); // INodeUnderConstruction\n+    }\n+\n+    v.leaveEnclosingElement(); // INodesUnderConstruction\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void processINodesUC(DataInputStream in, ImageVisitor v,\n      boolean skipBlocks) throws IOException {\n    int numINUC \u003d in.readInt();\n\n    v.visitEnclosingElement(ImageElement.INODES_UNDER_CONSTRUCTION,\n                           ImageElement.NUM_INODES_UNDER_CONSTRUCTION, numINUC);\n\n    for(int i \u003d 0; i \u003c numINUC; i++) {\n      v.visitEnclosingElement(ImageElement.INODE_UNDER_CONSTRUCTION);\n      byte [] name \u003d FSImageSerialization.readBytes(in);\n      String n \u003d new String(name, \"UTF8\");\n      v.visit(ImageElement.INODE_PATH, n);\n      \n      if (NameNodeLayoutVersion.supports(Feature.ADD_INODE_ID, imageVersion)) {\n        long inodeId \u003d in.readLong();\n        v.visit(ImageElement.INODE_ID, inodeId);\n      }\n      \n      v.visit(ImageElement.REPLICATION, in.readShort());\n      v.visit(ImageElement.MODIFICATION_TIME, formatDate(in.readLong()));\n\n      v.visit(ImageElement.PREFERRED_BLOCK_SIZE, in.readLong());\n      int numBlocks \u003d in.readInt();\n      processBlocks(in, v, numBlocks, skipBlocks);\n\n      processPermission(in, v);\n      v.visit(ImageElement.CLIENT_NAME, FSImageSerialization.readString(in));\n      v.visit(ImageElement.CLIENT_MACHINE, FSImageSerialization.readString(in));\n\n      // Skip over the datanode descriptors, which are still stored in the\n      // file but are not used by the datanode or loaded into memory\n      int numLocs \u003d in.readInt();\n      for(int j \u003d 0; j \u003c numLocs; j++) {\n        in.readShort();\n        in.readLong();\n        in.readLong();\n        in.readLong();\n        in.readInt();\n        FSImageSerialization.readString(in);\n        FSImageSerialization.readString(in);\n        WritableUtils.readEnum(in, AdminStates.class);\n      }\n\n      v.leaveEnclosingElement(); // INodeUnderConstruction\n    }\n\n    v.leaveEnclosingElement(); // INodesUnderConstruction\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/ImageLoaderCurrent.java"
    }
  }
}