{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeProtocolServerSideTranslatorPB.java",
  "functionName": "sendHeartbeat",
  "functionId": "sendHeartbeat___controller-RpcController__request-HeartbeatRequestProto",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
  "functionStartLine": 110,
  "functionEndLine": 156,
  "numCommitsSeen": 42,
  "timeTaken": 6869,
  "changeHistory": [
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
    "0f2d1ddc2c41c8db800c58cabb150e71804fe23a",
    "e7c8da614c37e36fb8081234f4c639d6054f6082",
    "b57368b6f893cb27d77fc9425e116f1312f4790f",
    "9f256d1d716a7e17606245fcfc619901a8fa299a",
    "06022b8fdc40e50eaac63758246353058e8cfa6d",
    "12b5b06c063d93e6c683c9b6fac9a96912f59e59",
    "9729b244de50322c2cc889c97c2ffb2b4675cf77",
    "b2ce764093ba3007df67022b3bcbc43d3fe2b173",
    "4f92eb2f613e4de59c2d31a563e16aba4846c61a",
    "9673baa7e8b43fa6300080f72ebce0189ea775e5",
    "907fb15ee8c150e5ecc0560b7374441c57a84122",
    "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
    "eb9f1b670726e1af03f2e940ce2696b880964972",
    "fc14a92c6b46cc435a8f33e6fa0512c70caa06e0",
    "28eadb7cd71e99d563fb5c41aec563ab11e293e5",
    "f88574acdefae2816236bf6180916be96c6a6874",
    "ecdf9da770b2b0efc1ca5940366aaef6c58364ff",
    "3cffe34177c72ea67194c3b0aaf0ddbf67ff3a0c",
    "3954a2fb1cbc7a8a0d1ad5859e7f5c9415530f4c",
    "6a609cb471d413b15e3659cc9d7cd6f5f3357256",
    "b5229fd19bfecc2e5249db652ad34ec08152334b",
    "3001a172c8868763f8e59e866e36f7f50dee62cc",
    "13345f3a85b6b66c71a38e7c187c8ebb7cb5c35e",
    "38a19bc293dec6221ae96e304fc6ab660d94e706"
  ],
  "changeHistoryShort": {
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": "Ybodychange",
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": "Ybodychange",
    "0f2d1ddc2c41c8db800c58cabb150e71804fe23a": "Ybodychange",
    "e7c8da614c37e36fb8081234f4c639d6054f6082": "Ybodychange",
    "b57368b6f893cb27d77fc9425e116f1312f4790f": "Ybodychange",
    "9f256d1d716a7e17606245fcfc619901a8fa299a": "Ybodychange",
    "06022b8fdc40e50eaac63758246353058e8cfa6d": "Ybodychange",
    "12b5b06c063d93e6c683c9b6fac9a96912f59e59": "Ybodychange",
    "9729b244de50322c2cc889c97c2ffb2b4675cf77": "Ybodychange",
    "b2ce764093ba3007df67022b3bcbc43d3fe2b173": "Ybodychange",
    "4f92eb2f613e4de59c2d31a563e16aba4846c61a": "Ybodychange",
    "9673baa7e8b43fa6300080f72ebce0189ea775e5": "Ybodychange",
    "907fb15ee8c150e5ecc0560b7374441c57a84122": "Ybodychange",
    "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48": "Ybodychange",
    "eb9f1b670726e1af03f2e940ce2696b880964972": "Ybodychange",
    "fc14a92c6b46cc435a8f33e6fa0512c70caa06e0": "Ybodychange",
    "28eadb7cd71e99d563fb5c41aec563ab11e293e5": "Ybodychange",
    "f88574acdefae2816236bf6180916be96c6a6874": "Ybodychange",
    "ecdf9da770b2b0efc1ca5940366aaef6c58364ff": "Ybodychange",
    "3cffe34177c72ea67194c3b0aaf0ddbf67ff3a0c": "Ybodychange",
    "3954a2fb1cbc7a8a0d1ad5859e7f5c9415530f4c": "Ybodychange",
    "6a609cb471d413b15e3659cc9d7cd6f5f3357256": "Ybodychange",
    "b5229fd19bfecc2e5249db652ad34ec08152334b": "Ybodychange",
    "3001a172c8868763f8e59e866e36f7f50dee62cc": "Ybodychange",
    "13345f3a85b6b66c71a38e7c187c8ebb7cb5c35e": "Ybodychange",
    "38a19bc293dec6221ae96e304fc6ab660d94e706": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,47 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     HeartbeatResponse response;\n     try {\n       final StorageReport[] report \u003d PBHelperClient.convertStorageReports(\n           request.getReportsList());\n       VolumeFailureSummary volumeFailureSummary \u003d\n           request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n               request.getVolumeFailureSummary()) : null;\n       response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           report, request.getCacheCapacity(), request.getCacheUsed(),\n           request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes(),\n           volumeFailureSummary, request.getRequestFullBlockReportLease(),\n           PBHelper.convertSlowPeerInfo(request.getSlowPeersList()),\n-          PBHelper.convertSlowDiskInfo(request.getSlowDisksList()),\n-          PBHelper.convertBlksMovReport(\n-              request.getStorageMoveAttemptFinishedBlks()));\n+          PBHelper.convertSlowDiskInfo(request.getSlowDisksList()));\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     DatanodeCommand[] cmds \u003d response.getCommands();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n     RollingUpgradeStatus rollingUpdateStatus \u003d response\n         .getRollingUpdateStatus();\n     if (rollingUpdateStatus !\u003d null) {\n       // V2 is always set for newer datanodes.\n       // To be compatible with older datanodes, V1 is set to null\n       //  if the RU was finalized.\n       RollingUpgradeStatusProto rus \u003d PBHelperClient.\n           convertRollingUpgradeStatus(rollingUpdateStatus);\n       builder.setRollingUpgradeStatusV2(rus);\n       if (!rollingUpdateStatus.isFinalized()) {\n         builder.setRollingUpgradeStatus(rus);\n       }\n     }\n \n     builder.setFullBlockReportLeaseId(response.getFullBlockReportLeaseId());\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    HeartbeatResponse response;\n    try {\n      final StorageReport[] report \u003d PBHelperClient.convertStorageReports(\n          request.getReportsList());\n      VolumeFailureSummary volumeFailureSummary \u003d\n          request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n              request.getVolumeFailureSummary()) : null;\n      response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report, request.getCacheCapacity(), request.getCacheUsed(),\n          request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes(),\n          volumeFailureSummary, request.getRequestFullBlockReportLease(),\n          PBHelper.convertSlowPeerInfo(request.getSlowPeersList()),\n          PBHelper.convertSlowDiskInfo(request.getSlowDisksList()));\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    DatanodeCommand[] cmds \u003d response.getCommands();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n    RollingUpgradeStatus rollingUpdateStatus \u003d response\n        .getRollingUpdateStatus();\n    if (rollingUpdateStatus !\u003d null) {\n      // V2 is always set for newer datanodes.\n      // To be compatible with older datanodes, V1 is set to null\n      //  if the RU was finalized.\n      RollingUpgradeStatusProto rus \u003d PBHelperClient.\n          convertRollingUpgradeStatus(rollingUpdateStatus);\n      builder.setRollingUpgradeStatusV2(rus);\n      if (!rollingUpdateStatus.isFinalized()) {\n        builder.setRollingUpgradeStatus(rus);\n      }\n    }\n\n    builder.setFullBlockReportLeaseId(response.getFullBlockReportLeaseId());\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "00eceed233d6e80d5c7137bf5b5286746ec4d5fb": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12570: [SPS]: Refactor Co-ordinator datanode logic to track the block storage movements. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "00eceed233d6e80d5c7137bf5b5286746ec4d5fb",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "0f2d1ddc2c41c8db800c58cabb150e71804fe23a",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 36,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,49 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     HeartbeatResponse response;\n     try {\n       final StorageReport[] report \u003d PBHelperClient.convertStorageReports(\n           request.getReportsList());\n       VolumeFailureSummary volumeFailureSummary \u003d\n           request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n               request.getVolumeFailureSummary()) : null;\n       response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           report, request.getCacheCapacity(), request.getCacheUsed(),\n           request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes(),\n           volumeFailureSummary, request.getRequestFullBlockReportLease(),\n           PBHelper.convertSlowPeerInfo(request.getSlowPeersList()),\n           PBHelper.convertSlowDiskInfo(request.getSlowDisksList()),\n-          PBHelper.convertBlksMovResults(\n-              request.getBlksMovementResultsList()));\n+          PBHelper.convertBlksMovReport(\n+              request.getStorageMoveAttemptFinishedBlks()));\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     DatanodeCommand[] cmds \u003d response.getCommands();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n     RollingUpgradeStatus rollingUpdateStatus \u003d response\n         .getRollingUpdateStatus();\n     if (rollingUpdateStatus !\u003d null) {\n       // V2 is always set for newer datanodes.\n       // To be compatible with older datanodes, V1 is set to null\n       //  if the RU was finalized.\n       RollingUpgradeStatusProto rus \u003d PBHelperClient.\n           convertRollingUpgradeStatus(rollingUpdateStatus);\n       builder.setRollingUpgradeStatusV2(rus);\n       if (!rollingUpdateStatus.isFinalized()) {\n         builder.setRollingUpgradeStatus(rus);\n       }\n     }\n \n     builder.setFullBlockReportLeaseId(response.getFullBlockReportLeaseId());\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    HeartbeatResponse response;\n    try {\n      final StorageReport[] report \u003d PBHelperClient.convertStorageReports(\n          request.getReportsList());\n      VolumeFailureSummary volumeFailureSummary \u003d\n          request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n              request.getVolumeFailureSummary()) : null;\n      response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report, request.getCacheCapacity(), request.getCacheUsed(),\n          request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes(),\n          volumeFailureSummary, request.getRequestFullBlockReportLease(),\n          PBHelper.convertSlowPeerInfo(request.getSlowPeersList()),\n          PBHelper.convertSlowDiskInfo(request.getSlowDisksList()),\n          PBHelper.convertBlksMovReport(\n              request.getStorageMoveAttemptFinishedBlks()));\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    DatanodeCommand[] cmds \u003d response.getCommands();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n    RollingUpgradeStatus rollingUpdateStatus \u003d response\n        .getRollingUpdateStatus();\n    if (rollingUpdateStatus !\u003d null) {\n      // V2 is always set for newer datanodes.\n      // To be compatible with older datanodes, V1 is set to null\n      //  if the RU was finalized.\n      RollingUpgradeStatusProto rus \u003d PBHelperClient.\n          convertRollingUpgradeStatus(rollingUpdateStatus);\n      builder.setRollingUpgradeStatusV2(rus);\n      if (!rollingUpdateStatus.isFinalized()) {\n        builder.setRollingUpgradeStatus(rus);\n      }\n    }\n\n    builder.setFullBlockReportLeaseId(response.getFullBlockReportLeaseId());\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "0f2d1ddc2c41c8db800c58cabb150e71804fe23a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10954. [SPS]: Provide mechanism to send blocks movement result back to NN from coordinator DN. Contributed by Rakesh R\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "0f2d1ddc2c41c8db800c58cabb150e71804fe23a",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "20/03/17 9:54 PM",
      "commitNameOld": "e7c8da614c37e36fb8081234f4c639d6054f6082",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 509.22,
      "commitsBetweenForRepo": 4067,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,49 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     HeartbeatResponse response;\n     try {\n       final StorageReport[] report \u003d PBHelperClient.convertStorageReports(\n           request.getReportsList());\n       VolumeFailureSummary volumeFailureSummary \u003d\n           request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n               request.getVolumeFailureSummary()) : null;\n       response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           report, request.getCacheCapacity(), request.getCacheUsed(),\n           request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes(),\n           volumeFailureSummary, request.getRequestFullBlockReportLease(),\n           PBHelper.convertSlowPeerInfo(request.getSlowPeersList()),\n-          PBHelper.convertSlowDiskInfo(request.getSlowDisksList()));\n+          PBHelper.convertSlowDiskInfo(request.getSlowDisksList()),\n+          PBHelper.convertBlksMovResults(\n+              request.getBlksMovementResultsList()));\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     DatanodeCommand[] cmds \u003d response.getCommands();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n     RollingUpgradeStatus rollingUpdateStatus \u003d response\n         .getRollingUpdateStatus();\n     if (rollingUpdateStatus !\u003d null) {\n       // V2 is always set for newer datanodes.\n       // To be compatible with older datanodes, V1 is set to null\n       //  if the RU was finalized.\n       RollingUpgradeStatusProto rus \u003d PBHelperClient.\n           convertRollingUpgradeStatus(rollingUpdateStatus);\n       builder.setRollingUpgradeStatusV2(rus);\n       if (!rollingUpdateStatus.isFinalized()) {\n         builder.setRollingUpgradeStatus(rus);\n       }\n     }\n \n     builder.setFullBlockReportLeaseId(response.getFullBlockReportLeaseId());\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    HeartbeatResponse response;\n    try {\n      final StorageReport[] report \u003d PBHelperClient.convertStorageReports(\n          request.getReportsList());\n      VolumeFailureSummary volumeFailureSummary \u003d\n          request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n              request.getVolumeFailureSummary()) : null;\n      response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report, request.getCacheCapacity(), request.getCacheUsed(),\n          request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes(),\n          volumeFailureSummary, request.getRequestFullBlockReportLease(),\n          PBHelper.convertSlowPeerInfo(request.getSlowPeersList()),\n          PBHelper.convertSlowDiskInfo(request.getSlowDisksList()),\n          PBHelper.convertBlksMovResults(\n              request.getBlksMovementResultsList()));\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    DatanodeCommand[] cmds \u003d response.getCommands();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n    RollingUpgradeStatus rollingUpdateStatus \u003d response\n        .getRollingUpdateStatus();\n    if (rollingUpdateStatus !\u003d null) {\n      // V2 is always set for newer datanodes.\n      // To be compatible with older datanodes, V1 is set to null\n      //  if the RU was finalized.\n      RollingUpgradeStatusProto rus \u003d PBHelperClient.\n          convertRollingUpgradeStatus(rollingUpdateStatus);\n      builder.setRollingUpgradeStatusV2(rus);\n      if (!rollingUpdateStatus.isFinalized()) {\n        builder.setRollingUpgradeStatus(rus);\n      }\n    }\n\n    builder.setFullBlockReportLeaseId(response.getFullBlockReportLeaseId());\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "e7c8da614c37e36fb8081234f4c639d6054f6082": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11545. Propagate DataNode\u0027s slow disks info to the NameNode via Heartbeats. Contributed by Hanisha Koneru.\n",
      "commitDate": "20/03/17 9:54 PM",
      "commitName": "e7c8da614c37e36fb8081234f4c639d6054f6082",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "24/01/17 4:58 PM",
      "commitNameOld": "b57368b6f893cb27d77fc9425e116f1312f4790f",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 55.16,
      "commitsBetweenForRepo": 295,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,47 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     HeartbeatResponse response;\n     try {\n       final StorageReport[] report \u003d PBHelperClient.convertStorageReports(\n           request.getReportsList());\n       VolumeFailureSummary volumeFailureSummary \u003d\n           request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n               request.getVolumeFailureSummary()) : null;\n       response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           report, request.getCacheCapacity(), request.getCacheUsed(),\n           request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes(),\n           volumeFailureSummary, request.getRequestFullBlockReportLease(),\n-          PBHelper.convertSlowPeerInfo(request.getSlowPeersList()));\n+          PBHelper.convertSlowPeerInfo(request.getSlowPeersList()),\n+          PBHelper.convertSlowDiskInfo(request.getSlowDisksList()));\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     DatanodeCommand[] cmds \u003d response.getCommands();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n     RollingUpgradeStatus rollingUpdateStatus \u003d response\n         .getRollingUpdateStatus();\n     if (rollingUpdateStatus !\u003d null) {\n       // V2 is always set for newer datanodes.\n       // To be compatible with older datanodes, V1 is set to null\n       //  if the RU was finalized.\n       RollingUpgradeStatusProto rus \u003d PBHelperClient.\n           convertRollingUpgradeStatus(rollingUpdateStatus);\n       builder.setRollingUpgradeStatusV2(rus);\n       if (!rollingUpdateStatus.isFinalized()) {\n         builder.setRollingUpgradeStatus(rus);\n       }\n     }\n \n     builder.setFullBlockReportLeaseId(response.getFullBlockReportLeaseId());\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    HeartbeatResponse response;\n    try {\n      final StorageReport[] report \u003d PBHelperClient.convertStorageReports(\n          request.getReportsList());\n      VolumeFailureSummary volumeFailureSummary \u003d\n          request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n              request.getVolumeFailureSummary()) : null;\n      response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report, request.getCacheCapacity(), request.getCacheUsed(),\n          request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes(),\n          volumeFailureSummary, request.getRequestFullBlockReportLease(),\n          PBHelper.convertSlowPeerInfo(request.getSlowPeersList()),\n          PBHelper.convertSlowDiskInfo(request.getSlowDisksList()));\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    DatanodeCommand[] cmds \u003d response.getCommands();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n    RollingUpgradeStatus rollingUpdateStatus \u003d response\n        .getRollingUpdateStatus();\n    if (rollingUpdateStatus !\u003d null) {\n      // V2 is always set for newer datanodes.\n      // To be compatible with older datanodes, V1 is set to null\n      //  if the RU was finalized.\n      RollingUpgradeStatusProto rus \u003d PBHelperClient.\n          convertRollingUpgradeStatus(rollingUpdateStatus);\n      builder.setRollingUpgradeStatusV2(rus);\n      if (!rollingUpdateStatus.isFinalized()) {\n        builder.setRollingUpgradeStatus(rus);\n      }\n    }\n\n    builder.setFullBlockReportLeaseId(response.getFullBlockReportLeaseId());\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "b57368b6f893cb27d77fc9425e116f1312f4790f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11194. Maintain aggregated peer performance metrics on NameNode.\n",
      "commitDate": "24/01/17 4:58 PM",
      "commitName": "b57368b6f893cb27d77fc9425e116f1312f4790f",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "03/11/16 10:27 AM",
      "commitNameOld": "b71907b2ae3d8f05b4332e06d52ec2096681ea6b",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 82.31,
      "commitsBetweenForRepo": 476,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,45 +1,46 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     HeartbeatResponse response;\n     try {\n       final StorageReport[] report \u003d PBHelperClient.convertStorageReports(\n           request.getReportsList());\n       VolumeFailureSummary volumeFailureSummary \u003d\n           request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n               request.getVolumeFailureSummary()) : null;\n       response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           report, request.getCacheCapacity(), request.getCacheUsed(),\n           request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes(),\n-          volumeFailureSummary, request.getRequestFullBlockReportLease());\n+          volumeFailureSummary, request.getRequestFullBlockReportLease(),\n+          PBHelper.convertSlowPeerInfo(request.getSlowPeersList()));\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     DatanodeCommand[] cmds \u003d response.getCommands();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n     RollingUpgradeStatus rollingUpdateStatus \u003d response\n         .getRollingUpdateStatus();\n     if (rollingUpdateStatus !\u003d null) {\n       // V2 is always set for newer datanodes.\n       // To be compatible with older datanodes, V1 is set to null\n       //  if the RU was finalized.\n       RollingUpgradeStatusProto rus \u003d PBHelperClient.\n           convertRollingUpgradeStatus(rollingUpdateStatus);\n       builder.setRollingUpgradeStatusV2(rus);\n       if (!rollingUpdateStatus.isFinalized()) {\n         builder.setRollingUpgradeStatus(rus);\n       }\n     }\n \n     builder.setFullBlockReportLeaseId(response.getFullBlockReportLeaseId());\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    HeartbeatResponse response;\n    try {\n      final StorageReport[] report \u003d PBHelperClient.convertStorageReports(\n          request.getReportsList());\n      VolumeFailureSummary volumeFailureSummary \u003d\n          request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n              request.getVolumeFailureSummary()) : null;\n      response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report, request.getCacheCapacity(), request.getCacheUsed(),\n          request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes(),\n          volumeFailureSummary, request.getRequestFullBlockReportLease(),\n          PBHelper.convertSlowPeerInfo(request.getSlowPeersList()));\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    DatanodeCommand[] cmds \u003d response.getCommands();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n    RollingUpgradeStatus rollingUpdateStatus \u003d response\n        .getRollingUpdateStatus();\n    if (rollingUpdateStatus !\u003d null) {\n      // V2 is always set for newer datanodes.\n      // To be compatible with older datanodes, V1 is set to null\n      //  if the RU was finalized.\n      RollingUpgradeStatusProto rus \u003d PBHelperClient.\n          convertRollingUpgradeStatus(rollingUpdateStatus);\n      builder.setRollingUpgradeStatusV2(rus);\n      if (!rollingUpdateStatus.isFinalized()) {\n        builder.setRollingUpgradeStatus(rus);\n      }\n    }\n\n    builder.setFullBlockReportLeaseId(response.getFullBlockReportLeaseId());\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "9f256d1d716a7e17606245fcfc619901a8fa299a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9426. Rollingupgrade finalization is not backward compatible (Contributed by Kihwal Lee)\n\n(cherry picked from commit c62d42cd8bb09a5ffc0c5eefa2d87913e71b9e7e)\n\nConflicts:\n\thadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolClientSideTranslatorPB.java\n\thadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java\n\thadoop-hdfs-project/hadoop-hdfs/src/main/proto/DatanodeProtocol.proto\n",
      "commitDate": "25/11/15 8:09 PM",
      "commitName": "9f256d1d716a7e17606245fcfc619901a8fa299a",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "29/09/15 1:39 AM",
      "commitNameOld": "8fd55202468b28422b0df888641c9b08906fe4a7",
      "commitAuthorOld": "",
      "daysBetweenCommits": 57.81,
      "commitsBetweenForRepo": 473,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,45 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     HeartbeatResponse response;\n     try {\n       final StorageReport[] report \u003d PBHelperClient.convertStorageReports(\n           request.getReportsList());\n       VolumeFailureSummary volumeFailureSummary \u003d\n           request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n               request.getVolumeFailureSummary()) : null;\n       response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           report, request.getCacheCapacity(), request.getCacheUsed(),\n           request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes(),\n           volumeFailureSummary, request.getRequestFullBlockReportLease());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     DatanodeCommand[] cmds \u003d response.getCommands();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n     RollingUpgradeStatus rollingUpdateStatus \u003d response\n         .getRollingUpdateStatus();\n     if (rollingUpdateStatus !\u003d null) {\n-      builder.setRollingUpgradeStatus(PBHelperClient\n-          .convertRollingUpgradeStatus(rollingUpdateStatus));\n+      // V2 is always set for newer datanodes.\n+      // To be compatible with older datanodes, V1 is set to null\n+      //  if the RU was finalized.\n+      RollingUpgradeStatusProto rus \u003d PBHelperClient.\n+          convertRollingUpgradeStatus(rollingUpdateStatus);\n+      builder.setRollingUpgradeStatusV2(rus);\n+      if (!rollingUpdateStatus.isFinalized()) {\n+        builder.setRollingUpgradeStatus(rus);\n+      }\n     }\n+\n     builder.setFullBlockReportLeaseId(response.getFullBlockReportLeaseId());\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    HeartbeatResponse response;\n    try {\n      final StorageReport[] report \u003d PBHelperClient.convertStorageReports(\n          request.getReportsList());\n      VolumeFailureSummary volumeFailureSummary \u003d\n          request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n              request.getVolumeFailureSummary()) : null;\n      response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report, request.getCacheCapacity(), request.getCacheUsed(),\n          request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes(),\n          volumeFailureSummary, request.getRequestFullBlockReportLease());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    DatanodeCommand[] cmds \u003d response.getCommands();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n    RollingUpgradeStatus rollingUpdateStatus \u003d response\n        .getRollingUpdateStatus();\n    if (rollingUpdateStatus !\u003d null) {\n      // V2 is always set for newer datanodes.\n      // To be compatible with older datanodes, V1 is set to null\n      //  if the RU was finalized.\n      RollingUpgradeStatusProto rus \u003d PBHelperClient.\n          convertRollingUpgradeStatus(rollingUpdateStatus);\n      builder.setRollingUpgradeStatusV2(rus);\n      if (!rollingUpdateStatus.isFinalized()) {\n        builder.setRollingUpgradeStatus(rus);\n      }\n    }\n\n    builder.setFullBlockReportLeaseId(response.getFullBlockReportLeaseId());\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "06022b8fdc40e50eaac63758246353058e8cfa6d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9111. Move hdfs-client protobuf convert methods from PBHelper to PBHelperClient. Contributed by Mingliang Liu.\n",
      "commitDate": "21/09/15 6:53 PM",
      "commitName": "06022b8fdc40e50eaac63758246353058e8cfa6d",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "28/08/15 2:38 PM",
      "commitNameOld": "e2c9b288b223b9fd82dc12018936e13128413492",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 24.18,
      "commitsBetweenForRepo": 143,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,37 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     HeartbeatResponse response;\n     try {\n-      final StorageReport[] report \u003d PBHelper.convertStorageReports(\n+      final StorageReport[] report \u003d PBHelperClient.convertStorageReports(\n           request.getReportsList());\n       VolumeFailureSummary volumeFailureSummary \u003d\n           request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n               request.getVolumeFailureSummary()) : null;\n       response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           report, request.getCacheCapacity(), request.getCacheUsed(),\n           request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes(),\n           volumeFailureSummary, request.getRequestFullBlockReportLease());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     DatanodeCommand[] cmds \u003d response.getCommands();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n     RollingUpgradeStatus rollingUpdateStatus \u003d response\n         .getRollingUpdateStatus();\n     if (rollingUpdateStatus !\u003d null) {\n-      builder.setRollingUpgradeStatus(PBHelper\n+      builder.setRollingUpgradeStatus(PBHelperClient\n           .convertRollingUpgradeStatus(rollingUpdateStatus));\n     }\n     builder.setFullBlockReportLeaseId(response.getFullBlockReportLeaseId());\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    HeartbeatResponse response;\n    try {\n      final StorageReport[] report \u003d PBHelperClient.convertStorageReports(\n          request.getReportsList());\n      VolumeFailureSummary volumeFailureSummary \u003d\n          request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n              request.getVolumeFailureSummary()) : null;\n      response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report, request.getCacheCapacity(), request.getCacheUsed(),\n          request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes(),\n          volumeFailureSummary, request.getRequestFullBlockReportLease());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    DatanodeCommand[] cmds \u003d response.getCommands();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n    RollingUpgradeStatus rollingUpdateStatus \u003d response\n        .getRollingUpdateStatus();\n    if (rollingUpdateStatus !\u003d null) {\n      builder.setRollingUpgradeStatus(PBHelperClient\n          .convertRollingUpgradeStatus(rollingUpdateStatus));\n    }\n    builder.setFullBlockReportLeaseId(response.getFullBlockReportLeaseId());\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "12b5b06c063d93e6c683c9b6fac9a96912f59e59": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7923. The DataNodes should rate-limit their full block reports by asking the NN on heartbeat messages (cmccabe)\n",
      "commitDate": "12/06/15 11:17 AM",
      "commitName": "12b5b06c063d93e6c683c9b6fac9a96912f59e59",
      "commitAuthor": "Colin Patrick Mccabe",
      "commitDateOld": "23/03/15 10:00 PM",
      "commitNameOld": "50ee8f4e67a66aa77c5359182f61f3e951844db6",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 80.55,
      "commitsBetweenForRepo": 743,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,37 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     HeartbeatResponse response;\n     try {\n       final StorageReport[] report \u003d PBHelper.convertStorageReports(\n           request.getReportsList());\n       VolumeFailureSummary volumeFailureSummary \u003d\n           request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n               request.getVolumeFailureSummary()) : null;\n       response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           report, request.getCacheCapacity(), request.getCacheUsed(),\n           request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes(),\n-          volumeFailureSummary);\n+          volumeFailureSummary, request.getRequestFullBlockReportLease());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     DatanodeCommand[] cmds \u003d response.getCommands();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n     RollingUpgradeStatus rollingUpdateStatus \u003d response\n         .getRollingUpdateStatus();\n     if (rollingUpdateStatus !\u003d null) {\n       builder.setRollingUpgradeStatus(PBHelper\n           .convertRollingUpgradeStatus(rollingUpdateStatus));\n     }\n+    builder.setFullBlockReportLeaseId(response.getFullBlockReportLeaseId());\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    HeartbeatResponse response;\n    try {\n      final StorageReport[] report \u003d PBHelper.convertStorageReports(\n          request.getReportsList());\n      VolumeFailureSummary volumeFailureSummary \u003d\n          request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n              request.getVolumeFailureSummary()) : null;\n      response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report, request.getCacheCapacity(), request.getCacheUsed(),\n          request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes(),\n          volumeFailureSummary, request.getRequestFullBlockReportLease());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    DatanodeCommand[] cmds \u003d response.getCommands();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n    RollingUpgradeStatus rollingUpdateStatus \u003d response\n        .getRollingUpdateStatus();\n    if (rollingUpdateStatus !\u003d null) {\n      builder.setRollingUpgradeStatus(PBHelper\n          .convertRollingUpgradeStatus(rollingUpdateStatus));\n    }\n    builder.setFullBlockReportLeaseId(response.getFullBlockReportLeaseId());\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "9729b244de50322c2cc889c97c2ffb2b4675cf77": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7604. Track and display failed DataNode storage locations in NameNode. Contributed by Chris Nauroth.\n",
      "commitDate": "16/02/15 2:43 PM",
      "commitName": "9729b244de50322c2cc889c97c2ffb2b4675cf77",
      "commitAuthor": "cnauroth",
      "commitDateOld": "17/03/14 10:37 AM",
      "commitNameOld": "809e8bf5b7fdfdb18f719614d1e54ca4fb47fa2b",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 336.21,
      "commitsBetweenForRepo": 2670,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,36 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     HeartbeatResponse response;\n     try {\n       final StorageReport[] report \u003d PBHelper.convertStorageReports(\n           request.getReportsList());\n+      VolumeFailureSummary volumeFailureSummary \u003d\n+          request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n+              request.getVolumeFailureSummary()) : null;\n       response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           report, request.getCacheCapacity(), request.getCacheUsed(),\n           request.getXmitsInProgress(),\n-          request.getXceiverCount(), request.getFailedVolumes());\n+          request.getXceiverCount(), request.getFailedVolumes(),\n+          volumeFailureSummary);\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     DatanodeCommand[] cmds \u003d response.getCommands();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n     RollingUpgradeStatus rollingUpdateStatus \u003d response\n         .getRollingUpdateStatus();\n     if (rollingUpdateStatus !\u003d null) {\n       builder.setRollingUpgradeStatus(PBHelper\n           .convertRollingUpgradeStatus(rollingUpdateStatus));\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    HeartbeatResponse response;\n    try {\n      final StorageReport[] report \u003d PBHelper.convertStorageReports(\n          request.getReportsList());\n      VolumeFailureSummary volumeFailureSummary \u003d\n          request.hasVolumeFailureSummary() ? PBHelper.convertVolumeFailureSummary(\n              request.getVolumeFailureSummary()) : null;\n      response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report, request.getCacheCapacity(), request.getCacheUsed(),\n          request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes(),\n          volumeFailureSummary);\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    DatanodeCommand[] cmds \u003d response.getCommands();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n    RollingUpgradeStatus rollingUpdateStatus \u003d response\n        .getRollingUpdateStatus();\n    if (rollingUpdateStatus !\u003d null) {\n      builder.setRollingUpgradeStatus(PBHelper\n          .convertRollingUpgradeStatus(rollingUpdateStatus));\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "b2ce764093ba3007df67022b3bcbc43d3fe2b173": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5890. Avoid NPE in Datanode heartbeat. Contributed by Vinay\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1565023 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/02/14 4:40 PM",
      "commitName": "b2ce764093ba3007df67022b3bcbc43d3fe2b173",
      "commitAuthor": "Brandon Li",
      "commitDateOld": "01/02/14 12:58 AM",
      "commitNameOld": "4f92eb2f613e4de59c2d31a563e16aba4846c61a",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 4.65,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,32 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     HeartbeatResponse response;\n     try {\n       final StorageReport[] report \u003d PBHelper.convertStorageReports(\n           request.getReportsList());\n       response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           report, request.getCacheCapacity(), request.getCacheUsed(),\n           request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     DatanodeCommand[] cmds \u003d response.getCommands();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n-    builder.setRollingUpgradeStatus(PBHelper.convertRollingUpgradeStatus(\n-        response.getRollingUpdateStatus()));\n+    RollingUpgradeStatus rollingUpdateStatus \u003d response\n+        .getRollingUpdateStatus();\n+    if (rollingUpdateStatus !\u003d null) {\n+      builder.setRollingUpgradeStatus(PBHelper\n+          .convertRollingUpgradeStatus(rollingUpdateStatus));\n+    }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    HeartbeatResponse response;\n    try {\n      final StorageReport[] report \u003d PBHelper.convertStorageReports(\n          request.getReportsList());\n      response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report, request.getCacheCapacity(), request.getCacheUsed(),\n          request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    DatanodeCommand[] cmds \u003d response.getCommands();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n    RollingUpgradeStatus rollingUpdateStatus \u003d response\n        .getRollingUpdateStatus();\n    if (rollingUpdateStatus !\u003d null) {\n      builder.setRollingUpgradeStatus(PBHelper\n          .convertRollingUpgradeStatus(rollingUpdateStatus));\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "4f92eb2f613e4de59c2d31a563e16aba4846c61a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5848. Add rolling upgrade status to heartbeat response.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-5535@1563384 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/02/14 12:58 AM",
      "commitName": "4f92eb2f613e4de59c2d31a563e16aba4846c61a",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "11/11/13 5:16 PM",
      "commitNameOld": "ec5eebc450c54171ac783a20a030a637de1722de",
      "commitAuthorOld": "",
      "daysBetweenCommits": 81.32,
      "commitsBetweenForRepo": 459,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,28 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     HeartbeatResponse response;\n     try {\n       final StorageReport[] report \u003d PBHelper.convertStorageReports(\n           request.getReportsList());\n       response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           report, request.getCacheCapacity(), request.getCacheUsed(),\n           request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     DatanodeCommand[] cmds \u003d response.getCommands();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n+    builder.setRollingUpgradeStatus(PBHelper.convertRollingUpgradeStatus(\n+        response.getRollingUpdateStatus()));\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    HeartbeatResponse response;\n    try {\n      final StorageReport[] report \u003d PBHelper.convertStorageReports(\n          request.getReportsList());\n      response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report, request.getCacheCapacity(), request.getCacheUsed(),\n          request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    DatanodeCommand[] cmds \u003d response.getCommands();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n    builder.setRollingUpgradeStatus(PBHelper.convertRollingUpgradeStatus(\n        response.getRollingUpdateStatus()));\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "9673baa7e8b43fa6300080f72ebce0189ea775e5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5320. Add datanode caching metrics. Contributed by Andrew Wang.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1540796 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/11/13 10:30 AM",
      "commitName": "9673baa7e8b43fa6300080f72ebce0189ea775e5",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "21/10/13 12:29 PM",
      "commitNameOld": "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 20.96,
      "commitsBetweenForRepo": 85,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,32 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     HeartbeatResponse response;\n     try {\n       List\u003cStorageReportProto\u003e list \u003d request.getReportsList();\n       StorageReport[] report \u003d new StorageReport[list.size()];\n       int i \u003d 0;\n       for (StorageReportProto p : list) {\n         report[i++] \u003d new StorageReport(p.getStorageID(), p.getFailed(),\n             p.getCapacity(), p.getDfsUsed(), p.getRemaining(),\n             p.getBlockPoolUsed());\n       }\n       response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n-          report, request.getDnCacheCapacity(), request.getDnCacheUsed(),\n+          report, request.getCacheCapacity(), request.getCacheUsed(),\n           request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     DatanodeCommand[] cmds \u003d response.getCommands();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    HeartbeatResponse response;\n    try {\n      List\u003cStorageReportProto\u003e list \u003d request.getReportsList();\n      StorageReport[] report \u003d new StorageReport[list.size()];\n      int i \u003d 0;\n      for (StorageReportProto p : list) {\n        report[i++] \u003d new StorageReport(p.getStorageID(), p.getFailed(),\n            p.getCapacity(), p.getDfsUsed(), p.getRemaining(),\n            p.getBlockPoolUsed());\n      }\n      response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report, request.getCacheCapacity(), request.getCacheUsed(),\n          request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    DatanodeCommand[] cmds \u003d response.getCommands();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "907fb15ee8c150e5ecc0560b7374441c57a84122": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5480. Update Balancer for HDFS-2832. (Contributed by szetszwo)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1540547 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/11/13 12:59 PM",
      "commitName": "907fb15ee8c150e5ecc0560b7374441c57a84122",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "29/10/13 2:04 PM",
      "commitNameOld": "c2495a7bff01df9660d50484cf3c15c1083a70d2",
      "commitAuthorOld": "",
      "daysBetweenCommits": 12.0,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,26 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     HeartbeatResponse response;\n     try {\n-      List\u003cStorageReportProto\u003e list \u003d request.getReportsList();\n-      StorageReport[] report \u003d new StorageReport[list.size()];\n-      int i \u003d 0;\n-      for (StorageReportProto p : list) {\n-        report[i++] \u003d new StorageReport(p.getStorageUuid(), p.getFailed(),\n-            p.getCapacity(), p.getDfsUsed(), p.getRemaining(),\n-            p.getBlockPoolUsed());\n-      }\n+      final StorageReport[] report \u003d PBHelper.convertStorageReports(\n+          request.getReportsList());\n       response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           report, request.getDnCacheCapacity(), request.getDnCacheUsed(),\n           request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     DatanodeCommand[] cmds \u003d response.getCommands();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    HeartbeatResponse response;\n    try {\n      final StorageReport[] report \u003d PBHelper.convertStorageReports(\n          request.getReportsList());\n      response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report, request.getDnCacheCapacity(), request.getDnCacheUsed(),\n          request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    DatanodeCommand[] cmds \u003d response.getCommands();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5378. In CacheReport, don\u0027t send genstamp and length on the wire (Contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1534334 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/10/13 12:29 PM",
      "commitName": "f9c08d02ebe4a5477cf5d753f0d9d48fc6f9fa48",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "30/08/13 3:15 PM",
      "commitNameOld": "fc14a92c6b46cc435a8f33e6fa0512c70caa06e0",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 51.88,
      "commitsBetweenForRepo": 332,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,38 +1,32 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     HeartbeatResponse response;\n     try {\n       List\u003cStorageReportProto\u003e list \u003d request.getReportsList();\n       StorageReport[] report \u003d new StorageReport[list.size()];\n       int i \u003d 0;\n       for (StorageReportProto p : list) {\n         report[i++] \u003d new StorageReport(p.getStorageID(), p.getFailed(),\n             p.getCapacity(), p.getDfsUsed(), p.getRemaining(),\n             p.getBlockPoolUsed());\n       }\n-      List\u003cCacheReportProto\u003e cacheList \u003d request.getCacheReportsList();\n-      CacheReport[] cacheReport \u003d new CacheReport[list.size()];\n-      i \u003d 0;\n-      for (CacheReportProto p : cacheList) {\n-        cacheReport[i++] \u003d new CacheReport(p.getCacheCapacity(),\n-            p.getCacheUsed());\n-      }\n       response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n-          report, cacheReport, request.getXmitsInProgress(),\n+          report, request.getDnCacheCapacity(), request.getDnCacheUsed(),\n+          request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     DatanodeCommand[] cmds \u003d response.getCommands();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    HeartbeatResponse response;\n    try {\n      List\u003cStorageReportProto\u003e list \u003d request.getReportsList();\n      StorageReport[] report \u003d new StorageReport[list.size()];\n      int i \u003d 0;\n      for (StorageReportProto p : list) {\n        report[i++] \u003d new StorageReport(p.getStorageID(), p.getFailed(),\n            p.getCapacity(), p.getDfsUsed(), p.getRemaining(),\n            p.getBlockPoolUsed());\n      }\n      response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report, request.getDnCacheCapacity(), request.getDnCacheUsed(),\n          request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    DatanodeCommand[] cmds \u003d response.getCommands();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "eb9f1b670726e1af03f2e940ce2696b880964972": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5232. Protocol changes to transmit StorageUuid.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1525153 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/09/13 3:06 PM",
      "commitName": "eb9f1b670726e1af03f2e940ce2696b880964972",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "17/01/13 10:21 AM",
      "commitNameOld": "8f70a25b1c5df498c441a9b3475a8ada5a92111f",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 246.16,
      "commitsBetweenForRepo": 1429,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,31 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     HeartbeatResponse response;\n     try {\n       List\u003cStorageReportProto\u003e list \u003d request.getReportsList();\n       StorageReport[] report \u003d new StorageReport[list.size()];\n       int i \u003d 0;\n       for (StorageReportProto p : list) {\n-        report[i++] \u003d new StorageReport(p.getStorageID(), p.getFailed(),\n+        report[i++] \u003d new StorageReport(p.getStorageUuid(), p.getFailed(),\n             p.getCapacity(), p.getDfsUsed(), p.getRemaining(),\n             p.getBlockPoolUsed());\n       }\n       response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           report, request.getXmitsInProgress(), request.getXceiverCount(),\n           request.getFailedVolumes());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     DatanodeCommand[] cmds \u003d response.getCommands();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    HeartbeatResponse response;\n    try {\n      List\u003cStorageReportProto\u003e list \u003d request.getReportsList();\n      StorageReport[] report \u003d new StorageReport[list.size()];\n      int i \u003d 0;\n      for (StorageReportProto p : list) {\n        report[i++] \u003d new StorageReport(p.getStorageUuid(), p.getFailed(),\n            p.getCapacity(), p.getDfsUsed(), p.getRemaining(),\n            p.getBlockPoolUsed());\n      }\n      response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report, request.getXmitsInProgress(), request.getXceiverCount(),\n          request.getFailedVolumes());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    DatanodeCommand[] cmds \u003d response.getCommands();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "fc14a92c6b46cc435a8f33e6fa0512c70caa06e0": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5141. Add cache status information to datanode heartbeat. (Contributed by Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1519101 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "30/08/13 3:15 PM",
      "commitName": "fc14a92c6b46cc435a8f33e6fa0512c70caa06e0",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "13/08/13 2:05 PM",
      "commitNameOld": "52ccc6c6d539d0587c3fd9693709bd1f6e12619d",
      "commitAuthorOld": "Colin McCabe",
      "daysBetweenCommits": 17.05,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,31 +1,38 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     HeartbeatResponse response;\n     try {\n       List\u003cStorageReportProto\u003e list \u003d request.getReportsList();\n       StorageReport[] report \u003d new StorageReport[list.size()];\n       int i \u003d 0;\n       for (StorageReportProto p : list) {\n         report[i++] \u003d new StorageReport(p.getStorageID(), p.getFailed(),\n             p.getCapacity(), p.getDfsUsed(), p.getRemaining(),\n             p.getBlockPoolUsed());\n       }\n+      List\u003cCacheReportProto\u003e cacheList \u003d request.getCacheReportsList();\n+      CacheReport[] cacheReport \u003d new CacheReport[list.size()];\n+      i \u003d 0;\n+      for (CacheReportProto p : cacheList) {\n+        cacheReport[i++] \u003d new CacheReport(p.getCacheCapacity(),\n+            p.getCacheUsed());\n+      }\n       response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n-          report, request.getXmitsInProgress(), request.getXceiverCount(),\n-          request.getFailedVolumes());\n+          report, cacheReport, request.getXmitsInProgress(),\n+          request.getXceiverCount(), request.getFailedVolumes());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     DatanodeCommand[] cmds \u003d response.getCommands();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    HeartbeatResponse response;\n    try {\n      List\u003cStorageReportProto\u003e list \u003d request.getReportsList();\n      StorageReport[] report \u003d new StorageReport[list.size()];\n      int i \u003d 0;\n      for (StorageReportProto p : list) {\n        report[i++] \u003d new StorageReport(p.getStorageID(), p.getFailed(),\n            p.getCapacity(), p.getDfsUsed(), p.getRemaining(),\n            p.getBlockPoolUsed());\n      }\n      List\u003cCacheReportProto\u003e cacheList \u003d request.getCacheReportsList();\n      CacheReport[] cacheReport \u003d new CacheReport[list.size()];\n      i \u003d 0;\n      for (CacheReportProto p : cacheList) {\n        cacheReport[i++] \u003d new CacheReport(p.getCacheCapacity(),\n            p.getCacheUsed());\n      }\n      response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report, cacheReport, request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    DatanodeCommand[] cmds \u003d response.getCommands();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "28eadb7cd71e99d563fb5c41aec563ab11e293e5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2899. Service protocol changes in DatanodeProtocol to add multiple storages. Contributed by Suresh Srinivas.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1241519 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "07/02/12 8:59 AM",
      "commitName": "28eadb7cd71e99d563fb5c41aec563ab11e293e5",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "04/02/12 5:39 PM",
      "commitNameOld": "f88574acdefae2816236bf6180916be96c6a6874",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 2.64,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,29 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     DatanodeCommand[] cmds \u003d null;\n     try {\n-      StorageReportProto report \u003d request.getReports(0);\n+      List\u003cStorageReportProto\u003e list \u003d request.getReportsList();\n+      StorageReport[] report \u003d new StorageReport[list.size()];\n+      int i \u003d 0;\n+      for (StorageReportProto p : list) {\n+        report[i++] \u003d new StorageReport(p.getStorageID(), p.getFailed(),\n+            p.getCapacity(), p.getDfsUsed(), p.getRemaining(),\n+            p.getBlockPoolUsed());\n+      }\n       cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n-          report.getCapacity(), report.getDfsUsed(), report.getRemaining(),\n-          report.getBlockPoolUsed(), request.getXmitsInProgress(),\n-          request.getXceiverCount(), request.getFailedVolumes());\n+          report, request.getXmitsInProgress(), request.getXceiverCount(),\n+          request.getFailedVolumes());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    DatanodeCommand[] cmds \u003d null;\n    try {\n      List\u003cStorageReportProto\u003e list \u003d request.getReportsList();\n      StorageReport[] report \u003d new StorageReport[list.size()];\n      int i \u003d 0;\n      for (StorageReportProto p : list) {\n        report[i++] \u003d new StorageReport(p.getStorageID(), p.getFailed(),\n            p.getCapacity(), p.getDfsUsed(), p.getRemaining(),\n            p.getBlockPoolUsed());\n      }\n      cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report, request.getXmitsInProgress(), request.getXceiverCount(),\n          request.getFailedVolumes());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "f88574acdefae2816236bf6180916be96c6a6874": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2880. Protobuf chagnes in DatanodeProtocol to add multiple storages. Contributed by Suresh Srinivas.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1240653 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/02/12 5:39 PM",
      "commitName": "f88574acdefae2816236bf6180916be96c6a6874",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "13/12/11 6:15 PM",
      "commitNameOld": "3cffe34177c72ea67194c3b0aaf0ddbf67ff3a0c",
      "commitAuthorOld": "Jitendra Nath Pandey",
      "daysBetweenCommits": 52.97,
      "commitsBetweenForRepo": 265,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,23 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     DatanodeCommand[] cmds \u003d null;\n     try {\n+      StorageReportProto report \u003d request.getReports(0);\n       cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n-          request.getCapacity(), request.getDfsUsed(), request.getRemaining(),\n-          request.getBlockPoolUsed(), request.getXmitsInProgress(),\n+          report.getCapacity(), report.getDfsUsed(), report.getRemaining(),\n+          report.getBlockPoolUsed(), request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    DatanodeCommand[] cmds \u003d null;\n    try {\n      StorageReportProto report \u003d request.getReports(0);\n      cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          report.getCapacity(), report.getDfsUsed(), report.getRemaining(),\n          report.getBlockPoolUsed(), request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "ecdf9da770b2b0efc1ca5940366aaef6c58364ff": {
      "type": "Ybodychange",
      "commitMessage": "Fix treatment of NNHAStatusHeartbeat in protobuffer.\n\nCommitting without pre-commit review since it\u0027s a pretty trivial merge fix\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1214543 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/12/11 3:28 PM",
      "commitName": "ecdf9da770b2b0efc1ca5940366aaef6c58364ff",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "14/12/11 2:47 PM",
      "commitNameOld": "8134b1c8702d7d6b3994c73b34afc7f8ee33ac6e",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.03,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,24 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     HeartbeatResponse response;\n     try {\n       response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           request.getCapacity(), request.getDfsUsed(), request.getRemaining(),\n           request.getBlockPoolUsed(), request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     DatanodeCommand[] cmds \u003d response.getCommands();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n+    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    HeartbeatResponse response;\n    try {\n      response \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          request.getCapacity(), request.getDfsUsed(), request.getRemaining(),\n          request.getBlockPoolUsed(), request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    DatanodeCommand[] cmds \u003d response.getCommands();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    builder.setHaStatus(PBHelper.convert(response.getNameNodeHaState()));\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "3cffe34177c72ea67194c3b0aaf0ddbf67ff3a0c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2661. Enable protobuf RPC for DatanodeProtocol.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1214033 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/12/11 6:15 PM",
      "commitName": "3cffe34177c72ea67194c3b0aaf0ddbf67ff3a0c",
      "commitAuthor": "Jitendra Nath Pandey",
      "commitDateOld": "13/12/11 3:31 PM",
      "commitNameOld": "3954a2fb1cbc7a8a0d1ad5859e7f5c9415530f4c",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.11,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,22 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n-    DatanodeCommand[] cmds;\n+    DatanodeCommand[] cmds \u003d null;\n     try {\n       cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           request.getCapacity(), request.getDfsUsed(), request.getRemaining(),\n           request.getBlockPoolUsed(), request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n         if (cmds[i] !\u003d null) {\n           builder.addCmds(PBHelper.convert(cmds[i]));\n         }\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    DatanodeCommand[] cmds \u003d null;\n    try {\n      cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          request.getCapacity(), request.getDfsUsed(), request.getRemaining(),\n          request.getBlockPoolUsed(), request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "3954a2fb1cbc7a8a0d1ad5859e7f5c9415530f4c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2663. Optional protobuf parameters are not handled correctly. Contributed by Suresh Srinivas.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213985 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/12/11 3:31 PM",
      "commitName": "3954a2fb1cbc7a8a0d1ad5859e7f5c9415530f4c",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "13/12/11 3:27 PM",
      "commitNameOld": "6a609cb471d413b15e3659cc9d7cd6f5f3357256",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,22 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     DatanodeCommand[] cmds;\n     try {\n       cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           request.getCapacity(), request.getDfsUsed(), request.getRemaining(),\n           request.getBlockPoolUsed(), request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n-        builder.addCmds(i, PBHelper.convert(cmds[i]));\n+        if (cmds[i] !\u003d null) {\n+          builder.addCmds(PBHelper.convert(cmds[i]));\n+        }\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    DatanodeCommand[] cmds;\n    try {\n      cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          request.getCapacity(), request.getDfsUsed(), request.getRemaining(),\n          request.getBlockPoolUsed(), request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "6a609cb471d413b15e3659cc9d7cd6f5f3357256": {
      "type": "Ybodychange",
      "commitMessage": "Reverting the patch r1213981\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213984 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/12/11 3:27 PM",
      "commitName": "6a609cb471d413b15e3659cc9d7cd6f5f3357256",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "13/12/11 3:22 PM",
      "commitNameOld": "b5229fd19bfecc2e5249db652ad34ec08152334b",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,20 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     DatanodeCommand[] cmds;\n     try {\n       cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           request.getCapacity(), request.getDfsUsed(), request.getRemaining(),\n           request.getBlockPoolUsed(), request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n-        if (cmds[i] !\u003d null) {\n-          builder.addCmds(PBHelper.convert(cmds[i]));\n-        }\n+        builder.addCmds(i, PBHelper.convert(cmds[i]));\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    DatanodeCommand[] cmds;\n    try {\n      cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          request.getCapacity(), request.getDfsUsed(), request.getRemaining(),\n          request.getBlockPoolUsed(), request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        builder.addCmds(i, PBHelper.convert(cmds[i]));\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "b5229fd19bfecc2e5249db652ad34ec08152334b": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2663. Optional protobuf parameters are not handled correctly. Contributed by Suresh Srinivas.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213981 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/12/11 3:22 PM",
      "commitName": "b5229fd19bfecc2e5249db652ad34ec08152334b",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "13/12/11 3:17 PM",
      "commitNameOld": "3001a172c8868763f8e59e866e36f7f50dee62cc",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,22 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     DatanodeCommand[] cmds;\n     try {\n       cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           request.getCapacity(), request.getDfsUsed(), request.getRemaining(),\n           request.getBlockPoolUsed(), request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n-        builder.addCmds(i, PBHelper.convert(cmds[i]));\n+        if (cmds[i] !\u003d null) {\n+          builder.addCmds(PBHelper.convert(cmds[i]));\n+        }\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    DatanodeCommand[] cmds;\n    try {\n      cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          request.getCapacity(), request.getDfsUsed(), request.getRemaining(),\n          request.getBlockPoolUsed(), request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "3001a172c8868763f8e59e866e36f7f50dee62cc": {
      "type": "Ybodychange",
      "commitMessage": "Reverting r1213512 because it committed changes that were not part of the patch.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213980 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/12/11 3:17 PM",
      "commitName": "3001a172c8868763f8e59e866e36f7f50dee62cc",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "12/12/11 4:21 PM",
      "commitNameOld": "13345f3a85b6b66c71a38e7c187c8ebb7cb5c35e",
      "commitAuthorOld": "Suresh Srinivas",
      "daysBetweenCommits": 0.96,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,20 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     DatanodeCommand[] cmds;\n     try {\n       cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           request.getCapacity(), request.getDfsUsed(), request.getRemaining(),\n           request.getBlockPoolUsed(), request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n-        if (cmds[i] !\u003d null) {\n-          builder.addCmds(PBHelper.convert(cmds[i]));\n-        }\n+        builder.addCmds(i, PBHelper.convert(cmds[i]));\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    DatanodeCommand[] cmds;\n    try {\n      cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          request.getCapacity(), request.getDfsUsed(), request.getRemaining(),\n          request.getBlockPoolUsed(), request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        builder.addCmds(i, PBHelper.convert(cmds[i]));\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "13345f3a85b6b66c71a38e7c187c8ebb7cb5c35e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2663. Handle protobuf optional parameters correctly. Contributed by Suresh Srinivas.\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1213512 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/12/11 4:21 PM",
      "commitName": "13345f3a85b6b66c71a38e7c187c8ebb7cb5c35e",
      "commitAuthor": "Suresh Srinivas",
      "commitDateOld": "09/12/11 12:02 PM",
      "commitNameOld": "38a19bc293dec6221ae96e304fc6ab660d94e706",
      "commitAuthorOld": "Jitendra Nath Pandey",
      "daysBetweenCommits": 3.18,
      "commitsBetweenForRepo": 15,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,22 @@\n   public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n       HeartbeatRequestProto request) throws ServiceException {\n     DatanodeCommand[] cmds;\n     try {\n       cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n           request.getCapacity(), request.getDfsUsed(), request.getRemaining(),\n           request.getBlockPoolUsed(), request.getXmitsInProgress(),\n           request.getXceiverCount(), request.getFailedVolumes());\n     } catch (IOException e) {\n       throw new ServiceException(e);\n     }\n     HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n         .newBuilder();\n     if (cmds !\u003d null) {\n       for (int i \u003d 0; i \u003c cmds.length; i++) {\n-        builder.addCmds(i, PBHelper.convert(cmds[i]));\n+        if (cmds[i] !\u003d null) {\n+          builder.addCmds(PBHelper.convert(cmds[i]));\n+        }\n       }\n     }\n     return builder.build();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    DatanodeCommand[] cmds;\n    try {\n      cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          request.getCapacity(), request.getDfsUsed(), request.getRemaining(),\n          request.getBlockPoolUsed(), request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        if (cmds[i] !\u003d null) {\n          builder.addCmds(PBHelper.convert(cmds[i]));\n        }\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java",
      "extendedDetails": {}
    },
    "38a19bc293dec6221ae96e304fc6ab660d94e706": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2642. Protobuf translators for DatanodeProtocol.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1212606 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/12/11 12:02 PM",
      "commitName": "38a19bc293dec6221ae96e304fc6ab660d94e706",
      "commitAuthor": "Jitendra Nath Pandey",
      "diff": "@@ -0,0 +1,20 @@\n+  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n+      HeartbeatRequestProto request) throws ServiceException {\n+    DatanodeCommand[] cmds;\n+    try {\n+      cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n+          request.getCapacity(), request.getDfsUsed(), request.getRemaining(),\n+          request.getBlockPoolUsed(), request.getXmitsInProgress(),\n+          request.getXceiverCount(), request.getFailedVolumes());\n+    } catch (IOException e) {\n+      throw new ServiceException(e);\n+    }\n+    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n+        .newBuilder();\n+    if (cmds !\u003d null) {\n+      for (int i \u003d 0; i \u003c cmds.length; i++) {\n+        builder.addCmds(i, PBHelper.convert(cmds[i]));\n+      }\n+    }\n+    return builder.build();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public HeartbeatResponseProto sendHeartbeat(RpcController controller,\n      HeartbeatRequestProto request) throws ServiceException {\n    DatanodeCommand[] cmds;\n    try {\n      cmds \u003d impl.sendHeartbeat(PBHelper.convert(request.getRegistration()),\n          request.getCapacity(), request.getDfsUsed(), request.getRemaining(),\n          request.getBlockPoolUsed(), request.getXmitsInProgress(),\n          request.getXceiverCount(), request.getFailedVolumes());\n    } catch (IOException e) {\n      throw new ServiceException(e);\n    }\n    HeartbeatResponseProto.Builder builder \u003d HeartbeatResponseProto\n        .newBuilder();\n    if (cmds !\u003d null) {\n      for (int i \u003d 0; i \u003c cmds.length; i++) {\n        builder.addCmds(i, PBHelper.convert(cmds[i]));\n      }\n    }\n    return builder.build();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.java"
    }
  }
}