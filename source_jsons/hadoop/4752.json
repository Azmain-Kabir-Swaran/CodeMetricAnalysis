{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "INodesInPath.java",
  "functionName": "getExistingINodes",
  "functionId": "getExistingINodes",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodesInPath.java",
  "functionStartLine": 441,
  "functionEndLine": 449,
  "numCommitsSeen": 31,
  "timeTaken": 3112,
  "changeHistory": [
    "8b7adf4ddf420a93c586c4b2eac27dd0f649682e",
    "ec252ce0fc0998ce13f31af3440c08a236328e5a",
    "3ca4d6ddfd199c95677721ff3bcb95d1da45bd88",
    "22fc46d7659972ff016ccf1c6f781f0c160be26f",
    "5caebbae8c2fc9ba2e32384657aee21641a1a6d0"
  ],
  "changeHistoryShort": {
    "8b7adf4ddf420a93c586c4b2eac27dd0f649682e": "Ybodychange",
    "ec252ce0fc0998ce13f31af3440c08a236328e5a": "Ybodychange",
    "3ca4d6ddfd199c95677721ff3bcb95d1da45bd88": "Ybodychange",
    "22fc46d7659972ff016ccf1c6f781f0c160be26f": "Ybodychange",
    "5caebbae8c2fc9ba2e32384657aee21641a1a6d0": "Yintroduced"
  },
  "changeHistoryDetails": {
    "8b7adf4ddf420a93c586c4b2eac27dd0f649682e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10768. Optimize mkdir ops. Contributed by Daryn Sharp.\n",
      "commitDate": "26/08/16 1:39 PM",
      "commitName": "8b7adf4ddf420a93c586c4b2eac27dd0f649682e",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "24/08/16 6:46 AM",
      "commitNameOld": "ec252ce0fc0998ce13f31af3440c08a236328e5a",
      "commitAuthorOld": "Daryn Sharp",
      "daysBetweenCommits": 2.29,
      "commitsBetweenForRepo": 24,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,9 @@\n   public INodesInPath getExistingINodes() {\n     Preconditions.checkState(!isSnapshot());\n-    int i \u003d 0;\n-    for (; i \u003c inodes.length; i++) {\n-      if (inodes[i] \u003d\u003d null) {\n-        break;\n+    for (int i \u003d inodes.length; i \u003e 0; i--) {\n+      if (inodes[i - 1] !\u003d null) {\n+        return (i \u003d\u003d inodes.length) ? this : getAncestorINodesInPath(i);\n       }\n     }\n-    INode[] existing \u003d new INode[i];\n-    byte[][] existingPath \u003d new byte[i][];\n-    System.arraycopy(inodes, 0, existing, 0, i);\n-    System.arraycopy(path, 0, existingPath, 0, i);\n-    return new INodesInPath(existing, existingPath, isRaw, false, snapshotId);\n+    return null;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public INodesInPath getExistingINodes() {\n    Preconditions.checkState(!isSnapshot());\n    for (int i \u003d inodes.length; i \u003e 0; i--) {\n      if (inodes[i - 1] !\u003d null) {\n        return (i \u003d\u003d inodes.length) ? this : getAncestorINodesInPath(i);\n      }\n    }\n    return null;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodesInPath.java",
      "extendedDetails": {}
    },
    "ec252ce0fc0998ce13f31af3440c08a236328e5a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10762. Pass IIP for file status related methods\n",
      "commitDate": "24/08/16 6:46 AM",
      "commitName": "ec252ce0fc0998ce13f31af3440c08a236328e5a",
      "commitAuthor": "Daryn Sharp",
      "commitDateOld": "22/08/16 2:57 PM",
      "commitNameOld": "3ca4d6ddfd199c95677721ff3bcb95d1da45bd88",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 1.66,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   public INodesInPath getExistingINodes() {\n     Preconditions.checkState(!isSnapshot());\n     int i \u003d 0;\n     for (; i \u003c inodes.length; i++) {\n       if (inodes[i] \u003d\u003d null) {\n         break;\n       }\n     }\n     INode[] existing \u003d new INode[i];\n     byte[][] existingPath \u003d new byte[i][];\n     System.arraycopy(inodes, 0, existing, 0, i);\n     System.arraycopy(path, 0, existingPath, 0, i);\n-    return new INodesInPath(existing, existingPath, false, snapshotId);\n+    return new INodesInPath(existing, existingPath, isRaw, false, snapshotId);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public INodesInPath getExistingINodes() {\n    Preconditions.checkState(!isSnapshot());\n    int i \u003d 0;\n    for (; i \u003c inodes.length; i++) {\n      if (inodes[i] \u003d\u003d null) {\n        break;\n      }\n    }\n    INode[] existing \u003d new INode[i];\n    byte[][] existingPath \u003d new byte[i][];\n    System.arraycopy(inodes, 0, existing, 0, i);\n    System.arraycopy(path, 0, existingPath, 0, i);\n    return new INodesInPath(existing, existingPath, isRaw, false, snapshotId);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodesInPath.java",
      "extendedDetails": {}
    },
    "3ca4d6ddfd199c95677721ff3bcb95d1da45bd88": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-10762. Pass IIP for file status related methods. Contributed by Daryn Sharp.\"\n\nThis reverts commit 22fc46d7659972ff016ccf1c6f781f0c160be26f.\n",
      "commitDate": "22/08/16 2:57 PM",
      "commitName": "3ca4d6ddfd199c95677721ff3bcb95d1da45bd88",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "22/08/16 1:37 PM",
      "commitNameOld": "22fc46d7659972ff016ccf1c6f781f0c160be26f",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 0.06,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   public INodesInPath getExistingINodes() {\n     Preconditions.checkState(!isSnapshot());\n     int i \u003d 0;\n     for (; i \u003c inodes.length; i++) {\n       if (inodes[i] \u003d\u003d null) {\n         break;\n       }\n     }\n     INode[] existing \u003d new INode[i];\n     byte[][] existingPath \u003d new byte[i][];\n     System.arraycopy(inodes, 0, existing, 0, i);\n     System.arraycopy(path, 0, existingPath, 0, i);\n-    return new INodesInPath(existing, existingPath, isRaw, false, snapshotId);\n+    return new INodesInPath(existing, existingPath, false, snapshotId);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public INodesInPath getExistingINodes() {\n    Preconditions.checkState(!isSnapshot());\n    int i \u003d 0;\n    for (; i \u003c inodes.length; i++) {\n      if (inodes[i] \u003d\u003d null) {\n        break;\n      }\n    }\n    INode[] existing \u003d new INode[i];\n    byte[][] existingPath \u003d new byte[i][];\n    System.arraycopy(inodes, 0, existing, 0, i);\n    System.arraycopy(path, 0, existingPath, 0, i);\n    return new INodesInPath(existing, existingPath, false, snapshotId);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodesInPath.java",
      "extendedDetails": {}
    },
    "22fc46d7659972ff016ccf1c6f781f0c160be26f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10762. Pass IIP for file status related methods. Contributed by Daryn Sharp.\n",
      "commitDate": "22/08/16 1:37 PM",
      "commitName": "22fc46d7659972ff016ccf1c6f781f0c160be26f",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "17/08/16 1:53 PM",
      "commitNameOld": "869393643de23dcb010cc33091c8eb398de0fd6c",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 4.99,
      "commitsBetweenForRepo": 29,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n   public INodesInPath getExistingINodes() {\n     Preconditions.checkState(!isSnapshot());\n     int i \u003d 0;\n     for (; i \u003c inodes.length; i++) {\n       if (inodes[i] \u003d\u003d null) {\n         break;\n       }\n     }\n     INode[] existing \u003d new INode[i];\n     byte[][] existingPath \u003d new byte[i][];\n     System.arraycopy(inodes, 0, existing, 0, i);\n     System.arraycopy(path, 0, existingPath, 0, i);\n-    return new INodesInPath(existing, existingPath, false, snapshotId);\n+    return new INodesInPath(existing, existingPath, isRaw, false, snapshotId);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public INodesInPath getExistingINodes() {\n    Preconditions.checkState(!isSnapshot());\n    int i \u003d 0;\n    for (; i \u003c inodes.length; i++) {\n      if (inodes[i] \u003d\u003d null) {\n        break;\n      }\n    }\n    INode[] existing \u003d new INode[i];\n    byte[][] existingPath \u003d new byte[i][];\n    System.arraycopy(inodes, 0, existing, 0, i);\n    System.arraycopy(path, 0, existingPath, 0, i);\n    return new INodesInPath(existing, existingPath, isRaw, false, snapshotId);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodesInPath.java",
      "extendedDetails": {}
    },
    "5caebbae8c2fc9ba2e32384657aee21641a1a6d0": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-7484. Make FSDirectory#addINode take existing INodes as its parameter. Contributed by Jing Zhao.\n",
      "commitDate": "22/12/14 11:19 PM",
      "commitName": "5caebbae8c2fc9ba2e32384657aee21641a1a6d0",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,14 @@\n+  public INodesInPath getExistingINodes() {\n+    Preconditions.checkState(!isSnapshot());\n+    int i \u003d 0;\n+    for (; i \u003c inodes.length; i++) {\n+      if (inodes[i] \u003d\u003d null) {\n+        break;\n+      }\n+    }\n+    INode[] existing \u003d new INode[i];\n+    byte[][] existingPath \u003d new byte[i][];\n+    System.arraycopy(inodes, 0, existing, 0, i);\n+    System.arraycopy(path, 0, existingPath, 0, i);\n+    return new INodesInPath(existing, existingPath, false, snapshotId);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public INodesInPath getExistingINodes() {\n    Preconditions.checkState(!isSnapshot());\n    int i \u003d 0;\n    for (; i \u003c inodes.length; i++) {\n      if (inodes[i] \u003d\u003d null) {\n        break;\n      }\n    }\n    INode[] existing \u003d new INode[i];\n    byte[][] existingPath \u003d new byte[i][];\n    System.arraycopy(inodes, 0, existing, 0, i);\n    System.arraycopy(path, 0, existingPath, 0, i);\n    return new INodesInPath(existing, existingPath, false, snapshotId);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/INodesInPath.java"
    }
  }
}