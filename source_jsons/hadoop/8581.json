{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImageFormatPBINode.java",
  "functionName": "loadINodeDirectory",
  "functionId": "loadINodeDirectory___n-INodeSection.INode__state-LoaderContext",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.java",
  "functionStartLine": 144,
  "functionEndLine": 192,
  "numCommitsSeen": 63,
  "timeTaken": 2368,
  "changeHistory": [
    "f2231cebcddc80f0b753c4a7cb45ee4040846951",
    "5dae97a584d30cef3e34141edfaca49c4ec57913",
    "0653918dad855b394e8e3b8b3f512f474d872ee9",
    "ac23a55547716df29b3e25c98a113399e184d9d1"
  ],
  "changeHistoryShort": {
    "f2231cebcddc80f0b753c4a7cb45ee4040846951": "Ybodychange",
    "5dae97a584d30cef3e34141edfaca49c4ec57913": "Ybodychange",
    "0653918dad855b394e8e3b8b3f512f474d872ee9": "Ybodychange",
    "ac23a55547716df29b3e25c98a113399e184d9d1": "Ybodychange"
  },
  "changeHistoryDetails": {
    "f2231cebcddc80f0b753c4a7cb45ee4040846951": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7775. Use consistent naming for NN-internal quota related types and functions. (Contributed bu Xiaoyu Yao)\n",
      "commitDate": "13/02/15 9:01 PM",
      "commitName": "f2231cebcddc80f0b753c4a7cb45ee4040846951",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "11/02/15 10:41 AM",
      "commitNameOld": "5dae97a584d30cef3e34141edfaca49c4ec57913",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 2.43,
      "commitsBetweenForRepo": 58,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,49 @@\n     public static INodeDirectory loadINodeDirectory(INodeSection.INode n,\n         LoaderContext state) {\n       assert n.getType() \u003d\u003d INodeSection.INode.Type.DIRECTORY;\n       INodeSection.INodeDirectory d \u003d n.getDirectory();\n \n       final PermissionStatus permissions \u003d loadPermission(d.getPermission(),\n           state.getStringTable());\n       final INodeDirectory dir \u003d new INodeDirectory(n.getId(), n.getName()\n           .toByteArray(), permissions, d.getModificationTime());\n       final long nsQuota \u003d d.getNsQuota(), dsQuota \u003d d.getDsQuota();\n       if (nsQuota \u003e\u003d 0 || dsQuota \u003e\u003d 0) {\n         dir.addDirectoryWithQuotaFeature(new DirectoryWithQuotaFeature.Builder().\n-            nameSpaceQuota(nsQuota).spaceQuota(dsQuota).build());\n+            nameSpaceQuota(nsQuota).storageSpaceQuota(dsQuota).build());\n       }\n       EnumCounters\u003cStorageType\u003e typeQuotas \u003d null;\n       if (d.hasTypeQuotas()) {\n         ImmutableList\u003cQuotaByStorageTypeEntry\u003e qes \u003d\n             loadQuotaByStorageTypeEntries(d.getTypeQuotas());\n         typeQuotas \u003d new EnumCounters\u003cStorageType\u003e(StorageType.class,\n             HdfsConstants.QUOTA_RESET);\n         for (QuotaByStorageTypeEntry qe : qes) {\n           if (qe.getQuota() \u003e\u003d 0 \u0026\u0026 qe.getStorageType() !\u003d null \u0026\u0026\n               qe.getStorageType().supportTypeQuota()) {\n             typeQuotas.set(qe.getStorageType(), qe.getQuota());\n           }\n         }\n \n         if (typeQuotas.anyGreaterOrEqual(0)) {\n           DirectoryWithQuotaFeature q \u003d dir.getDirectoryWithQuotaFeature();\n           if (q \u003d\u003d null) {\n             dir.addDirectoryWithQuotaFeature(new DirectoryWithQuotaFeature.\n                 Builder().typeQuotas(typeQuotas).build());\n           } else {\n             q.setQuota(typeQuotas);\n           }\n         }\n       }\n \n       if (d.hasAcl()) {\n         int[] entries \u003d AclEntryStatusFormat.toInt(loadAclEntries(\n             d.getAcl(), state.getStringTable()));\n         dir.addAclFeature(new AclFeature(entries));\n       }\n       if (d.hasXAttrs()) {\n         dir.addXAttrFeature(new XAttrFeature(\n             loadXAttrs(d.getXAttrs(), state.getStringTable())));\n       }\n       return dir;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public static INodeDirectory loadINodeDirectory(INodeSection.INode n,\n        LoaderContext state) {\n      assert n.getType() \u003d\u003d INodeSection.INode.Type.DIRECTORY;\n      INodeSection.INodeDirectory d \u003d n.getDirectory();\n\n      final PermissionStatus permissions \u003d loadPermission(d.getPermission(),\n          state.getStringTable());\n      final INodeDirectory dir \u003d new INodeDirectory(n.getId(), n.getName()\n          .toByteArray(), permissions, d.getModificationTime());\n      final long nsQuota \u003d d.getNsQuota(), dsQuota \u003d d.getDsQuota();\n      if (nsQuota \u003e\u003d 0 || dsQuota \u003e\u003d 0) {\n        dir.addDirectoryWithQuotaFeature(new DirectoryWithQuotaFeature.Builder().\n            nameSpaceQuota(nsQuota).storageSpaceQuota(dsQuota).build());\n      }\n      EnumCounters\u003cStorageType\u003e typeQuotas \u003d null;\n      if (d.hasTypeQuotas()) {\n        ImmutableList\u003cQuotaByStorageTypeEntry\u003e qes \u003d\n            loadQuotaByStorageTypeEntries(d.getTypeQuotas());\n        typeQuotas \u003d new EnumCounters\u003cStorageType\u003e(StorageType.class,\n            HdfsConstants.QUOTA_RESET);\n        for (QuotaByStorageTypeEntry qe : qes) {\n          if (qe.getQuota() \u003e\u003d 0 \u0026\u0026 qe.getStorageType() !\u003d null \u0026\u0026\n              qe.getStorageType().supportTypeQuota()) {\n            typeQuotas.set(qe.getStorageType(), qe.getQuota());\n          }\n        }\n\n        if (typeQuotas.anyGreaterOrEqual(0)) {\n          DirectoryWithQuotaFeature q \u003d dir.getDirectoryWithQuotaFeature();\n          if (q \u003d\u003d null) {\n            dir.addDirectoryWithQuotaFeature(new DirectoryWithQuotaFeature.\n                Builder().typeQuotas(typeQuotas).build());\n          } else {\n            q.setQuota(typeQuotas);\n          }\n        }\n      }\n\n      if (d.hasAcl()) {\n        int[] entries \u003d AclEntryStatusFormat.toInt(loadAclEntries(\n            d.getAcl(), state.getStringTable()));\n        dir.addAclFeature(new AclFeature(entries));\n      }\n      if (d.hasXAttrs()) {\n        dir.addXAttrFeature(new XAttrFeature(\n            loadXAttrs(d.getXAttrs(), state.getStringTable())));\n      }\n      return dir;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.java",
      "extendedDetails": {}
    },
    "5dae97a584d30cef3e34141edfaca49c4ec57913": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7723. Quota By Storage Type namenode implemenation. (Contributed by Xiaoyu Yao)\n",
      "commitDate": "11/02/15 10:41 AM",
      "commitName": "5dae97a584d30cef3e34141edfaca49c4ec57913",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "08/02/15 11:51 AM",
      "commitNameOld": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 2.95,
      "commitsBetweenForRepo": 40,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,26 +1,49 @@\n     public static INodeDirectory loadINodeDirectory(INodeSection.INode n,\n         LoaderContext state) {\n       assert n.getType() \u003d\u003d INodeSection.INode.Type.DIRECTORY;\n       INodeSection.INodeDirectory d \u003d n.getDirectory();\n \n       final PermissionStatus permissions \u003d loadPermission(d.getPermission(),\n           state.getStringTable());\n       final INodeDirectory dir \u003d new INodeDirectory(n.getId(), n.getName()\n           .toByteArray(), permissions, d.getModificationTime());\n-\n       final long nsQuota \u003d d.getNsQuota(), dsQuota \u003d d.getDsQuota();\n       if (nsQuota \u003e\u003d 0 || dsQuota \u003e\u003d 0) {\n-        dir.addDirectoryWithQuotaFeature(nsQuota, dsQuota);\n+        dir.addDirectoryWithQuotaFeature(new DirectoryWithQuotaFeature.Builder().\n+            nameSpaceQuota(nsQuota).spaceQuota(dsQuota).build());\n+      }\n+      EnumCounters\u003cStorageType\u003e typeQuotas \u003d null;\n+      if (d.hasTypeQuotas()) {\n+        ImmutableList\u003cQuotaByStorageTypeEntry\u003e qes \u003d\n+            loadQuotaByStorageTypeEntries(d.getTypeQuotas());\n+        typeQuotas \u003d new EnumCounters\u003cStorageType\u003e(StorageType.class,\n+            HdfsConstants.QUOTA_RESET);\n+        for (QuotaByStorageTypeEntry qe : qes) {\n+          if (qe.getQuota() \u003e\u003d 0 \u0026\u0026 qe.getStorageType() !\u003d null \u0026\u0026\n+              qe.getStorageType().supportTypeQuota()) {\n+            typeQuotas.set(qe.getStorageType(), qe.getQuota());\n+          }\n+        }\n+\n+        if (typeQuotas.anyGreaterOrEqual(0)) {\n+          DirectoryWithQuotaFeature q \u003d dir.getDirectoryWithQuotaFeature();\n+          if (q \u003d\u003d null) {\n+            dir.addDirectoryWithQuotaFeature(new DirectoryWithQuotaFeature.\n+                Builder().typeQuotas(typeQuotas).build());\n+          } else {\n+            q.setQuota(typeQuotas);\n+          }\n+        }\n       }\n \n       if (d.hasAcl()) {\n         int[] entries \u003d AclEntryStatusFormat.toInt(loadAclEntries(\n             d.getAcl(), state.getStringTable()));\n         dir.addAclFeature(new AclFeature(entries));\n       }\n       if (d.hasXAttrs()) {\n         dir.addXAttrFeature(new XAttrFeature(\n             loadXAttrs(d.getXAttrs(), state.getStringTable())));\n       }\n       return dir;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public static INodeDirectory loadINodeDirectory(INodeSection.INode n,\n        LoaderContext state) {\n      assert n.getType() \u003d\u003d INodeSection.INode.Type.DIRECTORY;\n      INodeSection.INodeDirectory d \u003d n.getDirectory();\n\n      final PermissionStatus permissions \u003d loadPermission(d.getPermission(),\n          state.getStringTable());\n      final INodeDirectory dir \u003d new INodeDirectory(n.getId(), n.getName()\n          .toByteArray(), permissions, d.getModificationTime());\n      final long nsQuota \u003d d.getNsQuota(), dsQuota \u003d d.getDsQuota();\n      if (nsQuota \u003e\u003d 0 || dsQuota \u003e\u003d 0) {\n        dir.addDirectoryWithQuotaFeature(new DirectoryWithQuotaFeature.Builder().\n            nameSpaceQuota(nsQuota).spaceQuota(dsQuota).build());\n      }\n      EnumCounters\u003cStorageType\u003e typeQuotas \u003d null;\n      if (d.hasTypeQuotas()) {\n        ImmutableList\u003cQuotaByStorageTypeEntry\u003e qes \u003d\n            loadQuotaByStorageTypeEntries(d.getTypeQuotas());\n        typeQuotas \u003d new EnumCounters\u003cStorageType\u003e(StorageType.class,\n            HdfsConstants.QUOTA_RESET);\n        for (QuotaByStorageTypeEntry qe : qes) {\n          if (qe.getQuota() \u003e\u003d 0 \u0026\u0026 qe.getStorageType() !\u003d null \u0026\u0026\n              qe.getStorageType().supportTypeQuota()) {\n            typeQuotas.set(qe.getStorageType(), qe.getQuota());\n          }\n        }\n\n        if (typeQuotas.anyGreaterOrEqual(0)) {\n          DirectoryWithQuotaFeature q \u003d dir.getDirectoryWithQuotaFeature();\n          if (q \u003d\u003d null) {\n            dir.addDirectoryWithQuotaFeature(new DirectoryWithQuotaFeature.\n                Builder().typeQuotas(typeQuotas).build());\n          } else {\n            q.setQuota(typeQuotas);\n          }\n        }\n      }\n\n      if (d.hasAcl()) {\n        int[] entries \u003d AclEntryStatusFormat.toInt(loadAclEntries(\n            d.getAcl(), state.getStringTable()));\n        dir.addAclFeature(new AclFeature(entries));\n      }\n      if (d.hasXAttrs()) {\n        dir.addXAttrFeature(new XAttrFeature(\n            loadXAttrs(d.getXAttrs(), state.getStringTable())));\n      }\n      return dir;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.java",
      "extendedDetails": {}
    },
    "0653918dad855b394e8e3b8b3f512f474d872ee9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7454. Reduce memory footprint for AclEntries in NameNode. Contributed by Vinayakumar B.\n",
      "commitDate": "04/12/14 8:49 PM",
      "commitName": "0653918dad855b394e8e3b8b3f512f474d872ee9",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "02/12/14 2:53 PM",
      "commitNameOld": "185e0c7b4c056b88f606362c71e4a22aae7076e0",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 2.25,
      "commitsBetweenForRepo": 20,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,25 +1,26 @@\n     public static INodeDirectory loadINodeDirectory(INodeSection.INode n,\n         LoaderContext state) {\n       assert n.getType() \u003d\u003d INodeSection.INode.Type.DIRECTORY;\n       INodeSection.INodeDirectory d \u003d n.getDirectory();\n \n       final PermissionStatus permissions \u003d loadPermission(d.getPermission(),\n           state.getStringTable());\n       final INodeDirectory dir \u003d new INodeDirectory(n.getId(), n.getName()\n           .toByteArray(), permissions, d.getModificationTime());\n \n       final long nsQuota \u003d d.getNsQuota(), dsQuota \u003d d.getDsQuota();\n       if (nsQuota \u003e\u003d 0 || dsQuota \u003e\u003d 0) {\n         dir.addDirectoryWithQuotaFeature(nsQuota, dsQuota);\n       }\n \n       if (d.hasAcl()) {\n-        dir.addAclFeature(new AclFeature(loadAclEntries(d.getAcl(),\n-            state.getStringTable())));\n+        int[] entries \u003d AclEntryStatusFormat.toInt(loadAclEntries(\n+            d.getAcl(), state.getStringTable()));\n+        dir.addAclFeature(new AclFeature(entries));\n       }\n       if (d.hasXAttrs()) {\n         dir.addXAttrFeature(new XAttrFeature(\n             loadXAttrs(d.getXAttrs(), state.getStringTable())));\n       }\n       return dir;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public static INodeDirectory loadINodeDirectory(INodeSection.INode n,\n        LoaderContext state) {\n      assert n.getType() \u003d\u003d INodeSection.INode.Type.DIRECTORY;\n      INodeSection.INodeDirectory d \u003d n.getDirectory();\n\n      final PermissionStatus permissions \u003d loadPermission(d.getPermission(),\n          state.getStringTable());\n      final INodeDirectory dir \u003d new INodeDirectory(n.getId(), n.getName()\n          .toByteArray(), permissions, d.getModificationTime());\n\n      final long nsQuota \u003d d.getNsQuota(), dsQuota \u003d d.getDsQuota();\n      if (nsQuota \u003e\u003d 0 || dsQuota \u003e\u003d 0) {\n        dir.addDirectoryWithQuotaFeature(nsQuota, dsQuota);\n      }\n\n      if (d.hasAcl()) {\n        int[] entries \u003d AclEntryStatusFormat.toInt(loadAclEntries(\n            d.getAcl(), state.getStringTable()));\n        dir.addAclFeature(new AclFeature(entries));\n      }\n      if (d.hasXAttrs()) {\n        dir.addXAttrFeature(new XAttrFeature(\n            loadXAttrs(d.getXAttrs(), state.getStringTable())));\n      }\n      return dir;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.java",
      "extendedDetails": {}
    },
    "ac23a55547716df29b3e25c98a113399e184d9d1": {
      "type": "Ybodychange",
      "commitMessage": "Merge HDFS-2006 HDFS XAttrs branch to Trunk\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1596575 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/05/14 6:57 AM",
      "commitName": "ac23a55547716df29b3e25c98a113399e184d9d1",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "20/02/14 8:09 AM",
      "commitNameOld": "b23f6cc1f2dd779a683bd452b5ca014848a9b782",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 89.91,
      "commitsBetweenForRepo": 636,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,25 @@\n     public static INodeDirectory loadINodeDirectory(INodeSection.INode n,\n         LoaderContext state) {\n       assert n.getType() \u003d\u003d INodeSection.INode.Type.DIRECTORY;\n       INodeSection.INodeDirectory d \u003d n.getDirectory();\n \n       final PermissionStatus permissions \u003d loadPermission(d.getPermission(),\n           state.getStringTable());\n       final INodeDirectory dir \u003d new INodeDirectory(n.getId(), n.getName()\n           .toByteArray(), permissions, d.getModificationTime());\n \n       final long nsQuota \u003d d.getNsQuota(), dsQuota \u003d d.getDsQuota();\n       if (nsQuota \u003e\u003d 0 || dsQuota \u003e\u003d 0) {\n         dir.addDirectoryWithQuotaFeature(nsQuota, dsQuota);\n       }\n \n       if (d.hasAcl()) {\n         dir.addAclFeature(new AclFeature(loadAclEntries(d.getAcl(),\n             state.getStringTable())));\n       }\n+      if (d.hasXAttrs()) {\n+        dir.addXAttrFeature(new XAttrFeature(\n+            loadXAttrs(d.getXAttrs(), state.getStringTable())));\n+      }\n       return dir;\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public static INodeDirectory loadINodeDirectory(INodeSection.INode n,\n        LoaderContext state) {\n      assert n.getType() \u003d\u003d INodeSection.INode.Type.DIRECTORY;\n      INodeSection.INodeDirectory d \u003d n.getDirectory();\n\n      final PermissionStatus permissions \u003d loadPermission(d.getPermission(),\n          state.getStringTable());\n      final INodeDirectory dir \u003d new INodeDirectory(n.getId(), n.getName()\n          .toByteArray(), permissions, d.getModificationTime());\n\n      final long nsQuota \u003d d.getNsQuota(), dsQuota \u003d d.getDsQuota();\n      if (nsQuota \u003e\u003d 0 || dsQuota \u003e\u003d 0) {\n        dir.addDirectoryWithQuotaFeature(nsQuota, dsQuota);\n      }\n\n      if (d.hasAcl()) {\n        dir.addAclFeature(new AclFeature(loadAclEntries(d.getAcl(),\n            state.getStringTable())));\n      }\n      if (d.hasXAttrs()) {\n        dir.addXAttrFeature(new XAttrFeature(\n            loadXAttrs(d.getXAttrs(), state.getStringTable())));\n      }\n      return dir;\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.java",
      "extendedDetails": {}
    }
  }
}