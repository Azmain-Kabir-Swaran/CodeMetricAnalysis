{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeAdminDefaultMonitor.java",
  "functionName": "processBlocksInternal",
  "functionId": "processBlocksInternal___datanode-DatanodeDescriptor(modifiers-final)__it-Iterator__BlockInfo__(modifiers-final)__insufficientList-List__BlockInfo__(modifiers-final)__pruneReliableBlocks-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminDefaultMonitor.java",
  "functionStartLine": 329,
  "functionEndLine": 445,
  "numCommitsSeen": 68,
  "timeTaken": 8634,
  "changeHistory": [
    "c93cb6790e0f1c64efd03d859f907a0522010894",
    "f9a7b442fdd7855e3c7b28e19a12580df48d92bf",
    "6f81cc0beea00843b44424417f09d8ee12cd7bae",
    "42a1c98597e6dba2e371510a6b2b6b1fb94e4090",
    "79df1e750ef558afed6d166ce225a23061b36aed",
    "467f5f1735494c5ef74e6591069884d3771c17e4",
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
    "332a61fd74fd2a9874319232c583ab5d2c53ff03",
    "8c84a2a93c22a93b4ff46dd917f6efb995675fbd",
    "5865fe2bf01284993572ea60b3ec3bf8b4492818",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
    "132478e805ba0f955345217b8ad87c2d17cccb2d",
    "5411dc559d5f73e4153e76fdff94a26869c17a37"
  ],
  "changeHistoryShort": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": "Ymultichange(Ymovefromfile,Ybodychange)",
    "f9a7b442fdd7855e3c7b28e19a12580df48d92bf": "Ybodychange",
    "6f81cc0beea00843b44424417f09d8ee12cd7bae": "Ybodychange",
    "42a1c98597e6dba2e371510a6b2b6b1fb94e4090": "Ybodychange",
    "79df1e750ef558afed6d166ce225a23061b36aed": "Ymultichange(Yfilerename,Ybodychange)",
    "467f5f1735494c5ef74e6591069884d3771c17e4": "Ybodychange",
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": "Ymultichange(Yrename,Ybodychange)",
    "332a61fd74fd2a9874319232c583ab5d2c53ff03": "Ybodychange",
    "8c84a2a93c22a93b4ff46dd917f6efb995675fbd": "Ybodychange",
    "5865fe2bf01284993572ea60b3ec3bf8b4492818": "Ybodychange",
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": "Ybodychange",
    "132478e805ba0f955345217b8ad87c2d17cccb2d": "Ybodychange",
    "5411dc559d5f73e4153e76fdff94a26869c17a37": "Ybodychange"
  },
  "changeHistoryDetails": {
    "c93cb6790e0f1c64efd03d859f907a0522010894": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HDFS-14854. Create improved decommission monitor implementation. Contributed by Stephen O\u0027Donnell.\n\nReviewed-by: Inigo Goiri \u003cinigoiri@apache.org\u003e\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "10/12/19 5:16 PM",
      "commitName": "c93cb6790e0f1c64efd03d859f907a0522010894",
      "commitAuthor": "Stephen O\u0027Donnell",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-14854. Create improved decommission monitor implementation. Contributed by Stephen O\u0027Donnell.\n\nReviewed-by: Inigo Goiri \u003cinigoiri@apache.org\u003e\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
          "commitDate": "10/12/19 5:16 PM",
          "commitName": "c93cb6790e0f1c64efd03d859f907a0522010894",
          "commitAuthor": "Stephen O\u0027Donnell",
          "commitDateOld": "10/12/19 6:51 AM",
          "commitNameOld": "875a3e97dd4a26fe224a1858c54d1b4512db6be3",
          "commitAuthorOld": "Gabor Bota",
          "daysBetweenCommits": 0.43,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,117 +1,117 @@\n-    private void processBlocksInternal(\n-        final DatanodeDescriptor datanode,\n-        final Iterator\u003cBlockInfo\u003e it,\n-        final List\u003cBlockInfo\u003e insufficientList,\n-        boolean pruneReliableBlocks) {\n-      boolean firstReplicationLog \u003d true;\n-      // Low redundancy in UC Blocks only\n-      int lowRedundancyBlocksInOpenFiles \u003d 0;\n-      LightWeightHashSet\u003cLong\u003e lowRedundancyOpenFiles \u003d\n-          new LightWeightLinkedSet\u003c\u003e();\n-      // All low redundancy blocks. Includes lowRedundancyOpenFiles.\n-      int lowRedundancyBlocks \u003d 0;\n-      // All maintenance and decommission replicas.\n-      int outOfServiceOnlyReplicas \u003d 0;\n-      while (it.hasNext()) {\n-        if (insufficientList \u003d\u003d null\n-            \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n-          // During fullscan insufficientlyReplicated will NOT be null, iterator\n-          // will be DN\u0027s iterator. So should not yield lock, otherwise\n-          // ConcurrentModificationException could occur.\n-          // Once the fullscan done, iterator will be a copy. So can yield the\n-          // lock.\n-          // Yielding is required in case of block number is greater than the\n-          // configured per-iteration-limit.\n-          namesystem.writeUnlock();\n-          try {\n-            LOG.debug(\"Yielded lock during decommission/maintenance check\");\n-            Thread.sleep(0, 500);\n-          } catch (InterruptedException ignored) {\n-            return;\n-          }\n-          // reset\n-          numBlocksCheckedPerLock \u003d 0;\n-          namesystem.writeLock();\n+  private void processBlocksInternal(\n+      final DatanodeDescriptor datanode,\n+      final Iterator\u003cBlockInfo\u003e it,\n+      final List\u003cBlockInfo\u003e insufficientList,\n+      boolean pruneReliableBlocks) {\n+    boolean firstReplicationLog \u003d true;\n+    // Low redundancy in UC Blocks only\n+    int lowRedundancyBlocksInOpenFiles \u003d 0;\n+    LightWeightHashSet\u003cLong\u003e lowRedundancyOpenFiles \u003d\n+        new LightWeightLinkedSet\u003c\u003e();\n+    // All low redundancy blocks. Includes lowRedundancyOpenFiles.\n+    int lowRedundancyBlocks \u003d 0;\n+    // All maintenance and decommission replicas.\n+    int outOfServiceOnlyReplicas \u003d 0;\n+    while (it.hasNext()) {\n+      if (insufficientList \u003d\u003d null\n+          \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n+        // During fullscan insufficientlyReplicated will NOT be null, iterator\n+        // will be DN\u0027s iterator. So should not yield lock, otherwise\n+        // ConcurrentModificationException could occur.\n+        // Once the fullscan done, iterator will be a copy. So can yield the\n+        // lock.\n+        // Yielding is required in case of block number is greater than the\n+        // configured per-iteration-limit.\n+        namesystem.writeUnlock();\n+        try {\n+          LOG.debug(\"Yielded lock during decommission/maintenance check\");\n+          Thread.sleep(0, 500);\n+        } catch (InterruptedException ignored) {\n+          return;\n         }\n-        numBlocksChecked++;\n-        numBlocksCheckedPerLock++;\n-        final BlockInfo block \u003d it.next();\n-        // Remove the block from the list if it\u0027s no longer in the block map,\n-        // e.g. the containing file has been deleted\n-        if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n-          LOG.trace(\"Removing unknown block {}\", block);\n-          it.remove();\n-          continue;\n-        }\n+        // reset\n+        numBlocksCheckedPerLock \u003d 0;\n+        namesystem.writeLock();\n+      }\n+      numBlocksChecked++;\n+      numBlocksCheckedPerLock++;\n+      final BlockInfo block \u003d it.next();\n+      // Remove the block from the list if it\u0027s no longer in the block map,\n+      // e.g. the containing file has been deleted\n+      if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n+        LOG.trace(\"Removing unknown block {}\", block);\n+        it.remove();\n+        continue;\n+      }\n \n-        long bcId \u003d block.getBlockCollectionId();\n-        if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n-          // Orphan block, will be invalidated eventually. Skip.\n-          continue;\n-        }\n+      long bcId \u003d block.getBlockCollectionId();\n+      if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n+        // Orphan block, will be invalidated eventually. Skip.\n+        continue;\n+      }\n \n-        final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n-        final NumberReplicas num \u003d blockManager.countNodes(block);\n-        final int liveReplicas \u003d num.liveReplicas();\n+      final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n+      final NumberReplicas num \u003d blockManager.countNodes(block);\n+      final int liveReplicas \u003d num.liveReplicas();\n \n-        // Schedule low redundancy blocks for reconstruction\n-        // if not already pending.\n-        boolean isDecommission \u003d datanode.isDecommissionInProgress();\n-        boolean isMaintenance \u003d datanode.isEnteringMaintenance();\n-        boolean neededReconstruction \u003d isDecommission ?\n-            blockManager.isNeededReconstruction(block, num) :\n-            blockManager.isNeededReconstructionForMaintenance(block, num);\n-        if (neededReconstruction) {\n-          if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n-              blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n-              blockManager.isPopulatingReplQueues()) {\n-            // Process these blocks only when active NN is out of safe mode.\n-            blockManager.neededReconstruction.add(block,\n-                liveReplicas, num.readOnlyReplicas(),\n-                num.outOfServiceReplicas(),\n-                blockManager.getExpectedRedundancyNum(block));\n-          }\n-        }\n-\n-        // Even if the block is without sufficient redundancy,\n-        // it might not block decommission/maintenance if it\n-        // has sufficient redundancy.\n-        if (isSufficient(block, bc, num, isDecommission, isMaintenance)) {\n-          if (pruneReliableBlocks) {\n-            it.remove();\n-          }\n-          continue;\n-        }\n-\n-        // We\u0027ve found a block without sufficient redundancy.\n-        if (insufficientList !\u003d null) {\n-          insufficientList.add(block);\n-        }\n-        // Log if this is our first time through\n-        if (firstReplicationLog) {\n-          logBlockReplicationInfo(block, bc, datanode, num,\n-              blockManager.blocksMap.getStorages(block));\n-          firstReplicationLog \u003d false;\n-        }\n-        // Update various counts\n-        lowRedundancyBlocks++;\n-        if (bc.isUnderConstruction()) {\n-          INode ucFile \u003d namesystem.getFSDirectory().getInode(bc.getId());\n-          if (!(ucFile instanceof  INodeFile) ||\n-              !ucFile.asFile().isUnderConstruction()) {\n-            LOG.warn(\"File {} is not under construction. Skipping add to \" +\n-                \"low redundancy open files!\", ucFile.getLocalName());\n-          } else {\n-            lowRedundancyBlocksInOpenFiles++;\n-            lowRedundancyOpenFiles.add(ucFile.getId());\n-          }\n-        }\n-        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n-          outOfServiceOnlyReplicas++;\n+      // Schedule low redundancy blocks for reconstruction\n+      // if not already pending.\n+      boolean isDecommission \u003d datanode.isDecommissionInProgress();\n+      boolean isMaintenance \u003d datanode.isEnteringMaintenance();\n+      boolean neededReconstruction \u003d isDecommission ?\n+          blockManager.isNeededReconstruction(block, num) :\n+          blockManager.isNeededReconstructionForMaintenance(block, num);\n+      if (neededReconstruction) {\n+        if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n+            blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n+            blockManager.isPopulatingReplQueues()) {\n+          // Process these blocks only when active NN is out of safe mode.\n+          blockManager.neededReconstruction.add(block,\n+              liveReplicas, num.readOnlyReplicas(),\n+              num.outOfServiceReplicas(),\n+              blockManager.getExpectedRedundancyNum(block));\n         }\n       }\n \n-      datanode.getLeavingServiceStatus().set(lowRedundancyBlocksInOpenFiles,\n-          lowRedundancyOpenFiles, lowRedundancyBlocks,\n-          outOfServiceOnlyReplicas);\n-    }\n\\ No newline at end of file\n+      // Even if the block is without sufficient redundancy,\n+      // it might not block decommission/maintenance if it\n+      // has sufficient redundancy.\n+      if (dnAdmin.isSufficient(block, bc, num, isDecommission, isMaintenance)) {\n+        if (pruneReliableBlocks) {\n+          it.remove();\n+        }\n+        continue;\n+      }\n+\n+      // We\u0027ve found a block without sufficient redundancy.\n+      if (insufficientList !\u003d null) {\n+        insufficientList.add(block);\n+      }\n+      // Log if this is our first time through\n+      if (firstReplicationLog) {\n+        dnAdmin.logBlockReplicationInfo(block, bc, datanode, num,\n+            blockManager.blocksMap.getStorages(block));\n+        firstReplicationLog \u003d false;\n+      }\n+      // Update various counts\n+      lowRedundancyBlocks++;\n+      if (bc.isUnderConstruction()) {\n+        INode ucFile \u003d namesystem.getFSDirectory().getInode(bc.getId());\n+        if (!(ucFile instanceof INodeFile) ||\n+            !ucFile.asFile().isUnderConstruction()) {\n+          LOG.warn(\"File {} is not under construction. Skipping add to \" +\n+              \"low redundancy open files!\", ucFile.getLocalName());\n+        } else {\n+          lowRedundancyBlocksInOpenFiles++;\n+          lowRedundancyOpenFiles.add(ucFile.getId());\n+        }\n+      }\n+      if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n+        outOfServiceOnlyReplicas++;\n+      }\n+    }\n+\n+    datanode.getLeavingServiceStatus().set(lowRedundancyBlocksInOpenFiles,\n+        lowRedundancyOpenFiles, lowRedundancyBlocks,\n+        outOfServiceOnlyReplicas);\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  private void processBlocksInternal(\n      final DatanodeDescriptor datanode,\n      final Iterator\u003cBlockInfo\u003e it,\n      final List\u003cBlockInfo\u003e insufficientList,\n      boolean pruneReliableBlocks) {\n    boolean firstReplicationLog \u003d true;\n    // Low redundancy in UC Blocks only\n    int lowRedundancyBlocksInOpenFiles \u003d 0;\n    LightWeightHashSet\u003cLong\u003e lowRedundancyOpenFiles \u003d\n        new LightWeightLinkedSet\u003c\u003e();\n    // All low redundancy blocks. Includes lowRedundancyOpenFiles.\n    int lowRedundancyBlocks \u003d 0;\n    // All maintenance and decommission replicas.\n    int outOfServiceOnlyReplicas \u003d 0;\n    while (it.hasNext()) {\n      if (insufficientList \u003d\u003d null\n          \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n        // During fullscan insufficientlyReplicated will NOT be null, iterator\n        // will be DN\u0027s iterator. So should not yield lock, otherwise\n        // ConcurrentModificationException could occur.\n        // Once the fullscan done, iterator will be a copy. So can yield the\n        // lock.\n        // Yielding is required in case of block number is greater than the\n        // configured per-iteration-limit.\n        namesystem.writeUnlock();\n        try {\n          LOG.debug(\"Yielded lock during decommission/maintenance check\");\n          Thread.sleep(0, 500);\n        } catch (InterruptedException ignored) {\n          return;\n        }\n        // reset\n        numBlocksCheckedPerLock \u003d 0;\n        namesystem.writeLock();\n      }\n      numBlocksChecked++;\n      numBlocksCheckedPerLock++;\n      final BlockInfo block \u003d it.next();\n      // Remove the block from the list if it\u0027s no longer in the block map,\n      // e.g. the containing file has been deleted\n      if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n        LOG.trace(\"Removing unknown block {}\", block);\n        it.remove();\n        continue;\n      }\n\n      long bcId \u003d block.getBlockCollectionId();\n      if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n        // Orphan block, will be invalidated eventually. Skip.\n        continue;\n      }\n\n      final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n      final NumberReplicas num \u003d blockManager.countNodes(block);\n      final int liveReplicas \u003d num.liveReplicas();\n\n      // Schedule low redundancy blocks for reconstruction\n      // if not already pending.\n      boolean isDecommission \u003d datanode.isDecommissionInProgress();\n      boolean isMaintenance \u003d datanode.isEnteringMaintenance();\n      boolean neededReconstruction \u003d isDecommission ?\n          blockManager.isNeededReconstruction(block, num) :\n          blockManager.isNeededReconstructionForMaintenance(block, num);\n      if (neededReconstruction) {\n        if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n            blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n            blockManager.isPopulatingReplQueues()) {\n          // Process these blocks only when active NN is out of safe mode.\n          blockManager.neededReconstruction.add(block,\n              liveReplicas, num.readOnlyReplicas(),\n              num.outOfServiceReplicas(),\n              blockManager.getExpectedRedundancyNum(block));\n        }\n      }\n\n      // Even if the block is without sufficient redundancy,\n      // it might not block decommission/maintenance if it\n      // has sufficient redundancy.\n      if (dnAdmin.isSufficient(block, bc, num, isDecommission, isMaintenance)) {\n        if (pruneReliableBlocks) {\n          it.remove();\n        }\n        continue;\n      }\n\n      // We\u0027ve found a block without sufficient redundancy.\n      if (insufficientList !\u003d null) {\n        insufficientList.add(block);\n      }\n      // Log if this is our first time through\n      if (firstReplicationLog) {\n        dnAdmin.logBlockReplicationInfo(block, bc, datanode, num,\n            blockManager.blocksMap.getStorages(block));\n        firstReplicationLog \u003d false;\n      }\n      // Update various counts\n      lowRedundancyBlocks++;\n      if (bc.isUnderConstruction()) {\n        INode ucFile \u003d namesystem.getFSDirectory().getInode(bc.getId());\n        if (!(ucFile instanceof INodeFile) ||\n            !ucFile.asFile().isUnderConstruction()) {\n          LOG.warn(\"File {} is not under construction. Skipping add to \" +\n              \"low redundancy open files!\", ucFile.getLocalName());\n        } else {\n          lowRedundancyBlocksInOpenFiles++;\n          lowRedundancyOpenFiles.add(ucFile.getId());\n        }\n      }\n      if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n        outOfServiceOnlyReplicas++;\n      }\n    }\n\n    datanode.getLeavingServiceStatus().set(lowRedundancyBlocksInOpenFiles,\n        lowRedundancyOpenFiles, lowRedundancyBlocks,\n        outOfServiceOnlyReplicas);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminDefaultMonitor.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminDefaultMonitor.java",
            "oldMethodName": "processBlocksInternal",
            "newMethodName": "processBlocksInternal"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-14854. Create improved decommission monitor implementation. Contributed by Stephen O\u0027Donnell.\n\nReviewed-by: Inigo Goiri \u003cinigoiri@apache.org\u003e\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
          "commitDate": "10/12/19 5:16 PM",
          "commitName": "c93cb6790e0f1c64efd03d859f907a0522010894",
          "commitAuthor": "Stephen O\u0027Donnell",
          "commitDateOld": "10/12/19 6:51 AM",
          "commitNameOld": "875a3e97dd4a26fe224a1858c54d1b4512db6be3",
          "commitAuthorOld": "Gabor Bota",
          "daysBetweenCommits": 0.43,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,117 +1,117 @@\n-    private void processBlocksInternal(\n-        final DatanodeDescriptor datanode,\n-        final Iterator\u003cBlockInfo\u003e it,\n-        final List\u003cBlockInfo\u003e insufficientList,\n-        boolean pruneReliableBlocks) {\n-      boolean firstReplicationLog \u003d true;\n-      // Low redundancy in UC Blocks only\n-      int lowRedundancyBlocksInOpenFiles \u003d 0;\n-      LightWeightHashSet\u003cLong\u003e lowRedundancyOpenFiles \u003d\n-          new LightWeightLinkedSet\u003c\u003e();\n-      // All low redundancy blocks. Includes lowRedundancyOpenFiles.\n-      int lowRedundancyBlocks \u003d 0;\n-      // All maintenance and decommission replicas.\n-      int outOfServiceOnlyReplicas \u003d 0;\n-      while (it.hasNext()) {\n-        if (insufficientList \u003d\u003d null\n-            \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n-          // During fullscan insufficientlyReplicated will NOT be null, iterator\n-          // will be DN\u0027s iterator. So should not yield lock, otherwise\n-          // ConcurrentModificationException could occur.\n-          // Once the fullscan done, iterator will be a copy. So can yield the\n-          // lock.\n-          // Yielding is required in case of block number is greater than the\n-          // configured per-iteration-limit.\n-          namesystem.writeUnlock();\n-          try {\n-            LOG.debug(\"Yielded lock during decommission/maintenance check\");\n-            Thread.sleep(0, 500);\n-          } catch (InterruptedException ignored) {\n-            return;\n-          }\n-          // reset\n-          numBlocksCheckedPerLock \u003d 0;\n-          namesystem.writeLock();\n+  private void processBlocksInternal(\n+      final DatanodeDescriptor datanode,\n+      final Iterator\u003cBlockInfo\u003e it,\n+      final List\u003cBlockInfo\u003e insufficientList,\n+      boolean pruneReliableBlocks) {\n+    boolean firstReplicationLog \u003d true;\n+    // Low redundancy in UC Blocks only\n+    int lowRedundancyBlocksInOpenFiles \u003d 0;\n+    LightWeightHashSet\u003cLong\u003e lowRedundancyOpenFiles \u003d\n+        new LightWeightLinkedSet\u003c\u003e();\n+    // All low redundancy blocks. Includes lowRedundancyOpenFiles.\n+    int lowRedundancyBlocks \u003d 0;\n+    // All maintenance and decommission replicas.\n+    int outOfServiceOnlyReplicas \u003d 0;\n+    while (it.hasNext()) {\n+      if (insufficientList \u003d\u003d null\n+          \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n+        // During fullscan insufficientlyReplicated will NOT be null, iterator\n+        // will be DN\u0027s iterator. So should not yield lock, otherwise\n+        // ConcurrentModificationException could occur.\n+        // Once the fullscan done, iterator will be a copy. So can yield the\n+        // lock.\n+        // Yielding is required in case of block number is greater than the\n+        // configured per-iteration-limit.\n+        namesystem.writeUnlock();\n+        try {\n+          LOG.debug(\"Yielded lock during decommission/maintenance check\");\n+          Thread.sleep(0, 500);\n+        } catch (InterruptedException ignored) {\n+          return;\n         }\n-        numBlocksChecked++;\n-        numBlocksCheckedPerLock++;\n-        final BlockInfo block \u003d it.next();\n-        // Remove the block from the list if it\u0027s no longer in the block map,\n-        // e.g. the containing file has been deleted\n-        if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n-          LOG.trace(\"Removing unknown block {}\", block);\n-          it.remove();\n-          continue;\n-        }\n+        // reset\n+        numBlocksCheckedPerLock \u003d 0;\n+        namesystem.writeLock();\n+      }\n+      numBlocksChecked++;\n+      numBlocksCheckedPerLock++;\n+      final BlockInfo block \u003d it.next();\n+      // Remove the block from the list if it\u0027s no longer in the block map,\n+      // e.g. the containing file has been deleted\n+      if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n+        LOG.trace(\"Removing unknown block {}\", block);\n+        it.remove();\n+        continue;\n+      }\n \n-        long bcId \u003d block.getBlockCollectionId();\n-        if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n-          // Orphan block, will be invalidated eventually. Skip.\n-          continue;\n-        }\n+      long bcId \u003d block.getBlockCollectionId();\n+      if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n+        // Orphan block, will be invalidated eventually. Skip.\n+        continue;\n+      }\n \n-        final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n-        final NumberReplicas num \u003d blockManager.countNodes(block);\n-        final int liveReplicas \u003d num.liveReplicas();\n+      final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n+      final NumberReplicas num \u003d blockManager.countNodes(block);\n+      final int liveReplicas \u003d num.liveReplicas();\n \n-        // Schedule low redundancy blocks for reconstruction\n-        // if not already pending.\n-        boolean isDecommission \u003d datanode.isDecommissionInProgress();\n-        boolean isMaintenance \u003d datanode.isEnteringMaintenance();\n-        boolean neededReconstruction \u003d isDecommission ?\n-            blockManager.isNeededReconstruction(block, num) :\n-            blockManager.isNeededReconstructionForMaintenance(block, num);\n-        if (neededReconstruction) {\n-          if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n-              blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n-              blockManager.isPopulatingReplQueues()) {\n-            // Process these blocks only when active NN is out of safe mode.\n-            blockManager.neededReconstruction.add(block,\n-                liveReplicas, num.readOnlyReplicas(),\n-                num.outOfServiceReplicas(),\n-                blockManager.getExpectedRedundancyNum(block));\n-          }\n-        }\n-\n-        // Even if the block is without sufficient redundancy,\n-        // it might not block decommission/maintenance if it\n-        // has sufficient redundancy.\n-        if (isSufficient(block, bc, num, isDecommission, isMaintenance)) {\n-          if (pruneReliableBlocks) {\n-            it.remove();\n-          }\n-          continue;\n-        }\n-\n-        // We\u0027ve found a block without sufficient redundancy.\n-        if (insufficientList !\u003d null) {\n-          insufficientList.add(block);\n-        }\n-        // Log if this is our first time through\n-        if (firstReplicationLog) {\n-          logBlockReplicationInfo(block, bc, datanode, num,\n-              blockManager.blocksMap.getStorages(block));\n-          firstReplicationLog \u003d false;\n-        }\n-        // Update various counts\n-        lowRedundancyBlocks++;\n-        if (bc.isUnderConstruction()) {\n-          INode ucFile \u003d namesystem.getFSDirectory().getInode(bc.getId());\n-          if (!(ucFile instanceof  INodeFile) ||\n-              !ucFile.asFile().isUnderConstruction()) {\n-            LOG.warn(\"File {} is not under construction. Skipping add to \" +\n-                \"low redundancy open files!\", ucFile.getLocalName());\n-          } else {\n-            lowRedundancyBlocksInOpenFiles++;\n-            lowRedundancyOpenFiles.add(ucFile.getId());\n-          }\n-        }\n-        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n-          outOfServiceOnlyReplicas++;\n+      // Schedule low redundancy blocks for reconstruction\n+      // if not already pending.\n+      boolean isDecommission \u003d datanode.isDecommissionInProgress();\n+      boolean isMaintenance \u003d datanode.isEnteringMaintenance();\n+      boolean neededReconstruction \u003d isDecommission ?\n+          blockManager.isNeededReconstruction(block, num) :\n+          blockManager.isNeededReconstructionForMaintenance(block, num);\n+      if (neededReconstruction) {\n+        if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n+            blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n+            blockManager.isPopulatingReplQueues()) {\n+          // Process these blocks only when active NN is out of safe mode.\n+          blockManager.neededReconstruction.add(block,\n+              liveReplicas, num.readOnlyReplicas(),\n+              num.outOfServiceReplicas(),\n+              blockManager.getExpectedRedundancyNum(block));\n         }\n       }\n \n-      datanode.getLeavingServiceStatus().set(lowRedundancyBlocksInOpenFiles,\n-          lowRedundancyOpenFiles, lowRedundancyBlocks,\n-          outOfServiceOnlyReplicas);\n-    }\n\\ No newline at end of file\n+      // Even if the block is without sufficient redundancy,\n+      // it might not block decommission/maintenance if it\n+      // has sufficient redundancy.\n+      if (dnAdmin.isSufficient(block, bc, num, isDecommission, isMaintenance)) {\n+        if (pruneReliableBlocks) {\n+          it.remove();\n+        }\n+        continue;\n+      }\n+\n+      // We\u0027ve found a block without sufficient redundancy.\n+      if (insufficientList !\u003d null) {\n+        insufficientList.add(block);\n+      }\n+      // Log if this is our first time through\n+      if (firstReplicationLog) {\n+        dnAdmin.logBlockReplicationInfo(block, bc, datanode, num,\n+            blockManager.blocksMap.getStorages(block));\n+        firstReplicationLog \u003d false;\n+      }\n+      // Update various counts\n+      lowRedundancyBlocks++;\n+      if (bc.isUnderConstruction()) {\n+        INode ucFile \u003d namesystem.getFSDirectory().getInode(bc.getId());\n+        if (!(ucFile instanceof INodeFile) ||\n+            !ucFile.asFile().isUnderConstruction()) {\n+          LOG.warn(\"File {} is not under construction. Skipping add to \" +\n+              \"low redundancy open files!\", ucFile.getLocalName());\n+        } else {\n+          lowRedundancyBlocksInOpenFiles++;\n+          lowRedundancyOpenFiles.add(ucFile.getId());\n+        }\n+      }\n+      if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n+        outOfServiceOnlyReplicas++;\n+      }\n+    }\n+\n+    datanode.getLeavingServiceStatus().set(lowRedundancyBlocksInOpenFiles,\n+        lowRedundancyOpenFiles, lowRedundancyBlocks,\n+        outOfServiceOnlyReplicas);\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  private void processBlocksInternal(\n      final DatanodeDescriptor datanode,\n      final Iterator\u003cBlockInfo\u003e it,\n      final List\u003cBlockInfo\u003e insufficientList,\n      boolean pruneReliableBlocks) {\n    boolean firstReplicationLog \u003d true;\n    // Low redundancy in UC Blocks only\n    int lowRedundancyBlocksInOpenFiles \u003d 0;\n    LightWeightHashSet\u003cLong\u003e lowRedundancyOpenFiles \u003d\n        new LightWeightLinkedSet\u003c\u003e();\n    // All low redundancy blocks. Includes lowRedundancyOpenFiles.\n    int lowRedundancyBlocks \u003d 0;\n    // All maintenance and decommission replicas.\n    int outOfServiceOnlyReplicas \u003d 0;\n    while (it.hasNext()) {\n      if (insufficientList \u003d\u003d null\n          \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n        // During fullscan insufficientlyReplicated will NOT be null, iterator\n        // will be DN\u0027s iterator. So should not yield lock, otherwise\n        // ConcurrentModificationException could occur.\n        // Once the fullscan done, iterator will be a copy. So can yield the\n        // lock.\n        // Yielding is required in case of block number is greater than the\n        // configured per-iteration-limit.\n        namesystem.writeUnlock();\n        try {\n          LOG.debug(\"Yielded lock during decommission/maintenance check\");\n          Thread.sleep(0, 500);\n        } catch (InterruptedException ignored) {\n          return;\n        }\n        // reset\n        numBlocksCheckedPerLock \u003d 0;\n        namesystem.writeLock();\n      }\n      numBlocksChecked++;\n      numBlocksCheckedPerLock++;\n      final BlockInfo block \u003d it.next();\n      // Remove the block from the list if it\u0027s no longer in the block map,\n      // e.g. the containing file has been deleted\n      if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n        LOG.trace(\"Removing unknown block {}\", block);\n        it.remove();\n        continue;\n      }\n\n      long bcId \u003d block.getBlockCollectionId();\n      if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n        // Orphan block, will be invalidated eventually. Skip.\n        continue;\n      }\n\n      final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n      final NumberReplicas num \u003d blockManager.countNodes(block);\n      final int liveReplicas \u003d num.liveReplicas();\n\n      // Schedule low redundancy blocks for reconstruction\n      // if not already pending.\n      boolean isDecommission \u003d datanode.isDecommissionInProgress();\n      boolean isMaintenance \u003d datanode.isEnteringMaintenance();\n      boolean neededReconstruction \u003d isDecommission ?\n          blockManager.isNeededReconstruction(block, num) :\n          blockManager.isNeededReconstructionForMaintenance(block, num);\n      if (neededReconstruction) {\n        if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n            blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n            blockManager.isPopulatingReplQueues()) {\n          // Process these blocks only when active NN is out of safe mode.\n          blockManager.neededReconstruction.add(block,\n              liveReplicas, num.readOnlyReplicas(),\n              num.outOfServiceReplicas(),\n              blockManager.getExpectedRedundancyNum(block));\n        }\n      }\n\n      // Even if the block is without sufficient redundancy,\n      // it might not block decommission/maintenance if it\n      // has sufficient redundancy.\n      if (dnAdmin.isSufficient(block, bc, num, isDecommission, isMaintenance)) {\n        if (pruneReliableBlocks) {\n          it.remove();\n        }\n        continue;\n      }\n\n      // We\u0027ve found a block without sufficient redundancy.\n      if (insufficientList !\u003d null) {\n        insufficientList.add(block);\n      }\n      // Log if this is our first time through\n      if (firstReplicationLog) {\n        dnAdmin.logBlockReplicationInfo(block, bc, datanode, num,\n            blockManager.blocksMap.getStorages(block));\n        firstReplicationLog \u003d false;\n      }\n      // Update various counts\n      lowRedundancyBlocks++;\n      if (bc.isUnderConstruction()) {\n        INode ucFile \u003d namesystem.getFSDirectory().getInode(bc.getId());\n        if (!(ucFile instanceof INodeFile) ||\n            !ucFile.asFile().isUnderConstruction()) {\n          LOG.warn(\"File {} is not under construction. Skipping add to \" +\n              \"low redundancy open files!\", ucFile.getLocalName());\n        } else {\n          lowRedundancyBlocksInOpenFiles++;\n          lowRedundancyOpenFiles.add(ucFile.getId());\n        }\n      }\n      if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n        outOfServiceOnlyReplicas++;\n      }\n    }\n\n    datanode.getLeavingServiceStatus().set(lowRedundancyBlocksInOpenFiles,\n        lowRedundancyOpenFiles, lowRedundancyBlocks,\n        outOfServiceOnlyReplicas);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminDefaultMonitor.java",
          "extendedDetails": {}
        }
      ]
    },
    "f9a7b442fdd7855e3c7b28e19a12580df48d92bf": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14465. When the Block expected replications is larger than the number of DataNodes, entering maintenance will never exit. Contributed by Yicong Cai.\n",
      "commitDate": "17/06/19 3:18 PM",
      "commitName": "f9a7b442fdd7855e3c7b28e19a12580df48d92bf",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "11/01/19 10:54 AM",
      "commitNameOld": "fb8932a727f757b2e9c1c61a18145878d0eb77bd",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 157.14,
      "commitsBetweenForRepo": 1107,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,116 +1,117 @@\n     private void processBlocksInternal(\n         final DatanodeDescriptor datanode,\n         final Iterator\u003cBlockInfo\u003e it,\n         final List\u003cBlockInfo\u003e insufficientList,\n         boolean pruneReliableBlocks) {\n       boolean firstReplicationLog \u003d true;\n       // Low redundancy in UC Blocks only\n       int lowRedundancyBlocksInOpenFiles \u003d 0;\n       LightWeightHashSet\u003cLong\u003e lowRedundancyOpenFiles \u003d\n           new LightWeightLinkedSet\u003c\u003e();\n       // All low redundancy blocks. Includes lowRedundancyOpenFiles.\n       int lowRedundancyBlocks \u003d 0;\n       // All maintenance and decommission replicas.\n       int outOfServiceOnlyReplicas \u003d 0;\n       while (it.hasNext()) {\n         if (insufficientList \u003d\u003d null\n             \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n           // During fullscan insufficientlyReplicated will NOT be null, iterator\n           // will be DN\u0027s iterator. So should not yield lock, otherwise\n           // ConcurrentModificationException could occur.\n           // Once the fullscan done, iterator will be a copy. So can yield the\n           // lock.\n           // Yielding is required in case of block number is greater than the\n           // configured per-iteration-limit.\n           namesystem.writeUnlock();\n           try {\n             LOG.debug(\"Yielded lock during decommission/maintenance check\");\n             Thread.sleep(0, 500);\n           } catch (InterruptedException ignored) {\n             return;\n           }\n           // reset\n           numBlocksCheckedPerLock \u003d 0;\n           namesystem.writeLock();\n         }\n         numBlocksChecked++;\n         numBlocksCheckedPerLock++;\n         final BlockInfo block \u003d it.next();\n         // Remove the block from the list if it\u0027s no longer in the block map,\n         // e.g. the containing file has been deleted\n         if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n           LOG.trace(\"Removing unknown block {}\", block);\n           it.remove();\n           continue;\n         }\n \n         long bcId \u003d block.getBlockCollectionId();\n         if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n           // Orphan block, will be invalidated eventually. Skip.\n           continue;\n         }\n \n         final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n         final NumberReplicas num \u003d blockManager.countNodes(block);\n         final int liveReplicas \u003d num.liveReplicas();\n \n         // Schedule low redundancy blocks for reconstruction\n         // if not already pending.\n         boolean isDecommission \u003d datanode.isDecommissionInProgress();\n+        boolean isMaintenance \u003d datanode.isEnteringMaintenance();\n         boolean neededReconstruction \u003d isDecommission ?\n             blockManager.isNeededReconstruction(block, num) :\n             blockManager.isNeededReconstructionForMaintenance(block, num);\n         if (neededReconstruction) {\n           if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n               blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n               blockManager.isPopulatingReplQueues()) {\n             // Process these blocks only when active NN is out of safe mode.\n             blockManager.neededReconstruction.add(block,\n                 liveReplicas, num.readOnlyReplicas(),\n                 num.outOfServiceReplicas(),\n                 blockManager.getExpectedRedundancyNum(block));\n           }\n         }\n \n         // Even if the block is without sufficient redundancy,\n         // it might not block decommission/maintenance if it\n         // has sufficient redundancy.\n-        if (isSufficient(block, bc, num, isDecommission)) {\n+        if (isSufficient(block, bc, num, isDecommission, isMaintenance)) {\n           if (pruneReliableBlocks) {\n             it.remove();\n           }\n           continue;\n         }\n \n         // We\u0027ve found a block without sufficient redundancy.\n         if (insufficientList !\u003d null) {\n           insufficientList.add(block);\n         }\n         // Log if this is our first time through\n         if (firstReplicationLog) {\n           logBlockReplicationInfo(block, bc, datanode, num,\n               blockManager.blocksMap.getStorages(block));\n           firstReplicationLog \u003d false;\n         }\n         // Update various counts\n         lowRedundancyBlocks++;\n         if (bc.isUnderConstruction()) {\n           INode ucFile \u003d namesystem.getFSDirectory().getInode(bc.getId());\n           if (!(ucFile instanceof  INodeFile) ||\n               !ucFile.asFile().isUnderConstruction()) {\n             LOG.warn(\"File {} is not under construction. Skipping add to \" +\n                 \"low redundancy open files!\", ucFile.getLocalName());\n           } else {\n             lowRedundancyBlocksInOpenFiles++;\n             lowRedundancyOpenFiles.add(ucFile.getId());\n           }\n         }\n         if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n           outOfServiceOnlyReplicas++;\n         }\n       }\n \n       datanode.getLeavingServiceStatus().set(lowRedundancyBlocksInOpenFiles,\n           lowRedundancyOpenFiles, lowRedundancyBlocks,\n           outOfServiceOnlyReplicas);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processBlocksInternal(\n        final DatanodeDescriptor datanode,\n        final Iterator\u003cBlockInfo\u003e it,\n        final List\u003cBlockInfo\u003e insufficientList,\n        boolean pruneReliableBlocks) {\n      boolean firstReplicationLog \u003d true;\n      // Low redundancy in UC Blocks only\n      int lowRedundancyBlocksInOpenFiles \u003d 0;\n      LightWeightHashSet\u003cLong\u003e lowRedundancyOpenFiles \u003d\n          new LightWeightLinkedSet\u003c\u003e();\n      // All low redundancy blocks. Includes lowRedundancyOpenFiles.\n      int lowRedundancyBlocks \u003d 0;\n      // All maintenance and decommission replicas.\n      int outOfServiceOnlyReplicas \u003d 0;\n      while (it.hasNext()) {\n        if (insufficientList \u003d\u003d null\n            \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n          // During fullscan insufficientlyReplicated will NOT be null, iterator\n          // will be DN\u0027s iterator. So should not yield lock, otherwise\n          // ConcurrentModificationException could occur.\n          // Once the fullscan done, iterator will be a copy. So can yield the\n          // lock.\n          // Yielding is required in case of block number is greater than the\n          // configured per-iteration-limit.\n          namesystem.writeUnlock();\n          try {\n            LOG.debug(\"Yielded lock during decommission/maintenance check\");\n            Thread.sleep(0, 500);\n          } catch (InterruptedException ignored) {\n            return;\n          }\n          // reset\n          numBlocksCheckedPerLock \u003d 0;\n          namesystem.writeLock();\n        }\n        numBlocksChecked++;\n        numBlocksCheckedPerLock++;\n        final BlockInfo block \u003d it.next();\n        // Remove the block from the list if it\u0027s no longer in the block map,\n        // e.g. the containing file has been deleted\n        if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n          LOG.trace(\"Removing unknown block {}\", block);\n          it.remove();\n          continue;\n        }\n\n        long bcId \u003d block.getBlockCollectionId();\n        if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n          // Orphan block, will be invalidated eventually. Skip.\n          continue;\n        }\n\n        final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n        final NumberReplicas num \u003d blockManager.countNodes(block);\n        final int liveReplicas \u003d num.liveReplicas();\n\n        // Schedule low redundancy blocks for reconstruction\n        // if not already pending.\n        boolean isDecommission \u003d datanode.isDecommissionInProgress();\n        boolean isMaintenance \u003d datanode.isEnteringMaintenance();\n        boolean neededReconstruction \u003d isDecommission ?\n            blockManager.isNeededReconstruction(block, num) :\n            blockManager.isNeededReconstructionForMaintenance(block, num);\n        if (neededReconstruction) {\n          if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n              blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n              blockManager.isPopulatingReplQueues()) {\n            // Process these blocks only when active NN is out of safe mode.\n            blockManager.neededReconstruction.add(block,\n                liveReplicas, num.readOnlyReplicas(),\n                num.outOfServiceReplicas(),\n                blockManager.getExpectedRedundancyNum(block));\n          }\n        }\n\n        // Even if the block is without sufficient redundancy,\n        // it might not block decommission/maintenance if it\n        // has sufficient redundancy.\n        if (isSufficient(block, bc, num, isDecommission, isMaintenance)) {\n          if (pruneReliableBlocks) {\n            it.remove();\n          }\n          continue;\n        }\n\n        // We\u0027ve found a block without sufficient redundancy.\n        if (insufficientList !\u003d null) {\n          insufficientList.add(block);\n        }\n        // Log if this is our first time through\n        if (firstReplicationLog) {\n          logBlockReplicationInfo(block, bc, datanode, num,\n              blockManager.blocksMap.getStorages(block));\n          firstReplicationLog \u003d false;\n        }\n        // Update various counts\n        lowRedundancyBlocks++;\n        if (bc.isUnderConstruction()) {\n          INode ucFile \u003d namesystem.getFSDirectory().getInode(bc.getId());\n          if (!(ucFile instanceof  INodeFile) ||\n              !ucFile.asFile().isUnderConstruction()) {\n            LOG.warn(\"File {} is not under construction. Skipping add to \" +\n                \"low redundancy open files!\", ucFile.getLocalName());\n          } else {\n            lowRedundancyBlocksInOpenFiles++;\n            lowRedundancyOpenFiles.add(ucFile.getId());\n          }\n        }\n        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n          outOfServiceOnlyReplicas++;\n        }\n      }\n\n      datanode.getLeavingServiceStatus().set(lowRedundancyBlocksInOpenFiles,\n          lowRedundancyOpenFiles, lowRedundancyBlocks,\n          outOfServiceOnlyReplicas);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
      "extendedDetails": {}
    },
    "6f81cc0beea00843b44424417f09d8ee12cd7bae": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13167. DatanodeAdminManager Improvements. Contributed by BELUGA BEHR.\n",
      "commitDate": "20/02/18 3:18 PM",
      "commitName": "6f81cc0beea00843b44424417f09d8ee12cd7bae",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "02/01/18 2:59 PM",
      "commitNameOld": "42a1c98597e6dba2e371510a6b2b6b1fb94e4090",
      "commitAuthorOld": "Manoj Govindassamy",
      "daysBetweenCommits": 49.01,
      "commitsBetweenForRepo": 297,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,116 +1,116 @@\n     private void processBlocksInternal(\n         final DatanodeDescriptor datanode,\n         final Iterator\u003cBlockInfo\u003e it,\n         final List\u003cBlockInfo\u003e insufficientList,\n         boolean pruneReliableBlocks) {\n       boolean firstReplicationLog \u003d true;\n       // Low redundancy in UC Blocks only\n       int lowRedundancyBlocksInOpenFiles \u003d 0;\n       LightWeightHashSet\u003cLong\u003e lowRedundancyOpenFiles \u003d\n           new LightWeightLinkedSet\u003c\u003e();\n       // All low redundancy blocks. Includes lowRedundancyOpenFiles.\n       int lowRedundancyBlocks \u003d 0;\n       // All maintenance and decommission replicas.\n       int outOfServiceOnlyReplicas \u003d 0;\n       while (it.hasNext()) {\n         if (insufficientList \u003d\u003d null\n             \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n           // During fullscan insufficientlyReplicated will NOT be null, iterator\n           // will be DN\u0027s iterator. So should not yield lock, otherwise\n           // ConcurrentModificationException could occur.\n           // Once the fullscan done, iterator will be a copy. So can yield the\n           // lock.\n           // Yielding is required in case of block number is greater than the\n           // configured per-iteration-limit.\n           namesystem.writeUnlock();\n           try {\n             LOG.debug(\"Yielded lock during decommission/maintenance check\");\n             Thread.sleep(0, 500);\n           } catch (InterruptedException ignored) {\n             return;\n           }\n           // reset\n           numBlocksCheckedPerLock \u003d 0;\n           namesystem.writeLock();\n         }\n         numBlocksChecked++;\n         numBlocksCheckedPerLock++;\n         final BlockInfo block \u003d it.next();\n         // Remove the block from the list if it\u0027s no longer in the block map,\n         // e.g. the containing file has been deleted\n         if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n           LOG.trace(\"Removing unknown block {}\", block);\n           it.remove();\n           continue;\n         }\n \n         long bcId \u003d block.getBlockCollectionId();\n         if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n           // Orphan block, will be invalidated eventually. Skip.\n           continue;\n         }\n \n         final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n         final NumberReplicas num \u003d blockManager.countNodes(block);\n         final int liveReplicas \u003d num.liveReplicas();\n \n         // Schedule low redundancy blocks for reconstruction\n         // if not already pending.\n         boolean isDecommission \u003d datanode.isDecommissionInProgress();\n         boolean neededReconstruction \u003d isDecommission ?\n             blockManager.isNeededReconstruction(block, num) :\n             blockManager.isNeededReconstructionForMaintenance(block, num);\n         if (neededReconstruction) {\n           if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n               blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n               blockManager.isPopulatingReplQueues()) {\n             // Process these blocks only when active NN is out of safe mode.\n             blockManager.neededReconstruction.add(block,\n                 liveReplicas, num.readOnlyReplicas(),\n                 num.outOfServiceReplicas(),\n                 blockManager.getExpectedRedundancyNum(block));\n           }\n         }\n \n         // Even if the block is without sufficient redundancy,\n         // it might not block decommission/maintenance if it\n         // has sufficient redundancy.\n         if (isSufficient(block, bc, num, isDecommission)) {\n           if (pruneReliableBlocks) {\n             it.remove();\n           }\n           continue;\n         }\n \n         // We\u0027ve found a block without sufficient redundancy.\n         if (insufficientList !\u003d null) {\n           insufficientList.add(block);\n         }\n         // Log if this is our first time through\n         if (firstReplicationLog) {\n           logBlockReplicationInfo(block, bc, datanode, num,\n               blockManager.blocksMap.getStorages(block));\n           firstReplicationLog \u003d false;\n         }\n         // Update various counts\n         lowRedundancyBlocks++;\n         if (bc.isUnderConstruction()) {\n           INode ucFile \u003d namesystem.getFSDirectory().getInode(bc.getId());\n-          if(!(ucFile instanceof  INodeFile) ||\n+          if (!(ucFile instanceof  INodeFile) ||\n               !ucFile.asFile().isUnderConstruction()) {\n-            LOG.warn(\"File \" + ucFile.getLocalName() + \" is not under \" +\n-                \"construction. Skipping add to low redundancy open files!\");\n+            LOG.warn(\"File {} is not under construction. Skipping add to \" +\n+                \"low redundancy open files!\", ucFile.getLocalName());\n           } else {\n             lowRedundancyBlocksInOpenFiles++;\n             lowRedundancyOpenFiles.add(ucFile.getId());\n           }\n         }\n         if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n           outOfServiceOnlyReplicas++;\n         }\n       }\n \n       datanode.getLeavingServiceStatus().set(lowRedundancyBlocksInOpenFiles,\n           lowRedundancyOpenFiles, lowRedundancyBlocks,\n           outOfServiceOnlyReplicas);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processBlocksInternal(\n        final DatanodeDescriptor datanode,\n        final Iterator\u003cBlockInfo\u003e it,\n        final List\u003cBlockInfo\u003e insufficientList,\n        boolean pruneReliableBlocks) {\n      boolean firstReplicationLog \u003d true;\n      // Low redundancy in UC Blocks only\n      int lowRedundancyBlocksInOpenFiles \u003d 0;\n      LightWeightHashSet\u003cLong\u003e lowRedundancyOpenFiles \u003d\n          new LightWeightLinkedSet\u003c\u003e();\n      // All low redundancy blocks. Includes lowRedundancyOpenFiles.\n      int lowRedundancyBlocks \u003d 0;\n      // All maintenance and decommission replicas.\n      int outOfServiceOnlyReplicas \u003d 0;\n      while (it.hasNext()) {\n        if (insufficientList \u003d\u003d null\n            \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n          // During fullscan insufficientlyReplicated will NOT be null, iterator\n          // will be DN\u0027s iterator. So should not yield lock, otherwise\n          // ConcurrentModificationException could occur.\n          // Once the fullscan done, iterator will be a copy. So can yield the\n          // lock.\n          // Yielding is required in case of block number is greater than the\n          // configured per-iteration-limit.\n          namesystem.writeUnlock();\n          try {\n            LOG.debug(\"Yielded lock during decommission/maintenance check\");\n            Thread.sleep(0, 500);\n          } catch (InterruptedException ignored) {\n            return;\n          }\n          // reset\n          numBlocksCheckedPerLock \u003d 0;\n          namesystem.writeLock();\n        }\n        numBlocksChecked++;\n        numBlocksCheckedPerLock++;\n        final BlockInfo block \u003d it.next();\n        // Remove the block from the list if it\u0027s no longer in the block map,\n        // e.g. the containing file has been deleted\n        if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n          LOG.trace(\"Removing unknown block {}\", block);\n          it.remove();\n          continue;\n        }\n\n        long bcId \u003d block.getBlockCollectionId();\n        if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n          // Orphan block, will be invalidated eventually. Skip.\n          continue;\n        }\n\n        final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n        final NumberReplicas num \u003d blockManager.countNodes(block);\n        final int liveReplicas \u003d num.liveReplicas();\n\n        // Schedule low redundancy blocks for reconstruction\n        // if not already pending.\n        boolean isDecommission \u003d datanode.isDecommissionInProgress();\n        boolean neededReconstruction \u003d isDecommission ?\n            blockManager.isNeededReconstruction(block, num) :\n            blockManager.isNeededReconstructionForMaintenance(block, num);\n        if (neededReconstruction) {\n          if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n              blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n              blockManager.isPopulatingReplQueues()) {\n            // Process these blocks only when active NN is out of safe mode.\n            blockManager.neededReconstruction.add(block,\n                liveReplicas, num.readOnlyReplicas(),\n                num.outOfServiceReplicas(),\n                blockManager.getExpectedRedundancyNum(block));\n          }\n        }\n\n        // Even if the block is without sufficient redundancy,\n        // it might not block decommission/maintenance if it\n        // has sufficient redundancy.\n        if (isSufficient(block, bc, num, isDecommission)) {\n          if (pruneReliableBlocks) {\n            it.remove();\n          }\n          continue;\n        }\n\n        // We\u0027ve found a block without sufficient redundancy.\n        if (insufficientList !\u003d null) {\n          insufficientList.add(block);\n        }\n        // Log if this is our first time through\n        if (firstReplicationLog) {\n          logBlockReplicationInfo(block, bc, datanode, num,\n              blockManager.blocksMap.getStorages(block));\n          firstReplicationLog \u003d false;\n        }\n        // Update various counts\n        lowRedundancyBlocks++;\n        if (bc.isUnderConstruction()) {\n          INode ucFile \u003d namesystem.getFSDirectory().getInode(bc.getId());\n          if (!(ucFile instanceof  INodeFile) ||\n              !ucFile.asFile().isUnderConstruction()) {\n            LOG.warn(\"File {} is not under construction. Skipping add to \" +\n                \"low redundancy open files!\", ucFile.getLocalName());\n          } else {\n            lowRedundancyBlocksInOpenFiles++;\n            lowRedundancyOpenFiles.add(ucFile.getId());\n          }\n        }\n        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n          outOfServiceOnlyReplicas++;\n        }\n      }\n\n      datanode.getLeavingServiceStatus().set(lowRedundancyBlocksInOpenFiles,\n          lowRedundancyOpenFiles, lowRedundancyBlocks,\n          outOfServiceOnlyReplicas);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
      "extendedDetails": {}
    },
    "42a1c98597e6dba2e371510a6b2b6b1fb94e4090": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11847. Enhance dfsadmin listOpenFiles command to list files blocking datanode decommissioning.\n",
      "commitDate": "02/01/18 2:59 PM",
      "commitName": "42a1c98597e6dba2e371510a6b2b6b1fb94e4090",
      "commitAuthor": "Manoj Govindassamy",
      "commitDateOld": "02/08/17 2:22 PM",
      "commitNameOld": "79df1e750ef558afed6d166ce225a23061b36aed",
      "commitAuthorOld": "Manoj Govindassamy",
      "daysBetweenCommits": 153.07,
      "commitsBetweenForRepo": 1174,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,105 +1,116 @@\n     private void processBlocksInternal(\n         final DatanodeDescriptor datanode,\n         final Iterator\u003cBlockInfo\u003e it,\n         final List\u003cBlockInfo\u003e insufficientList,\n         boolean pruneReliableBlocks) {\n       boolean firstReplicationLog \u003d true;\n       // Low redundancy in UC Blocks only\n-      int lowRedundancyInOpenFiles \u003d 0;\n-      // All low redundancy blocks. Includes lowRedundancyInOpenFiles.\n+      int lowRedundancyBlocksInOpenFiles \u003d 0;\n+      LightWeightHashSet\u003cLong\u003e lowRedundancyOpenFiles \u003d\n+          new LightWeightLinkedSet\u003c\u003e();\n+      // All low redundancy blocks. Includes lowRedundancyOpenFiles.\n       int lowRedundancyBlocks \u003d 0;\n       // All maintenance and decommission replicas.\n       int outOfServiceOnlyReplicas \u003d 0;\n       while (it.hasNext()) {\n         if (insufficientList \u003d\u003d null\n             \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n           // During fullscan insufficientlyReplicated will NOT be null, iterator\n           // will be DN\u0027s iterator. So should not yield lock, otherwise\n           // ConcurrentModificationException could occur.\n           // Once the fullscan done, iterator will be a copy. So can yield the\n           // lock.\n           // Yielding is required in case of block number is greater than the\n           // configured per-iteration-limit.\n           namesystem.writeUnlock();\n           try {\n             LOG.debug(\"Yielded lock during decommission/maintenance check\");\n             Thread.sleep(0, 500);\n           } catch (InterruptedException ignored) {\n             return;\n           }\n           // reset\n           numBlocksCheckedPerLock \u003d 0;\n           namesystem.writeLock();\n         }\n         numBlocksChecked++;\n         numBlocksCheckedPerLock++;\n         final BlockInfo block \u003d it.next();\n         // Remove the block from the list if it\u0027s no longer in the block map,\n         // e.g. the containing file has been deleted\n         if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n           LOG.trace(\"Removing unknown block {}\", block);\n           it.remove();\n           continue;\n         }\n \n         long bcId \u003d block.getBlockCollectionId();\n         if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n           // Orphan block, will be invalidated eventually. Skip.\n           continue;\n         }\n \n         final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n         final NumberReplicas num \u003d blockManager.countNodes(block);\n         final int liveReplicas \u003d num.liveReplicas();\n \n         // Schedule low redundancy blocks for reconstruction\n         // if not already pending.\n         boolean isDecommission \u003d datanode.isDecommissionInProgress();\n         boolean neededReconstruction \u003d isDecommission ?\n             blockManager.isNeededReconstruction(block, num) :\n             blockManager.isNeededReconstructionForMaintenance(block, num);\n         if (neededReconstruction) {\n           if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n               blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n               blockManager.isPopulatingReplQueues()) {\n             // Process these blocks only when active NN is out of safe mode.\n             blockManager.neededReconstruction.add(block,\n                 liveReplicas, num.readOnlyReplicas(),\n                 num.outOfServiceReplicas(),\n                 blockManager.getExpectedRedundancyNum(block));\n           }\n         }\n \n         // Even if the block is without sufficient redundancy,\n         // it might not block decommission/maintenance if it\n         // has sufficient redundancy.\n         if (isSufficient(block, bc, num, isDecommission)) {\n           if (pruneReliableBlocks) {\n             it.remove();\n           }\n           continue;\n         }\n \n         // We\u0027ve found a block without sufficient redundancy.\n         if (insufficientList !\u003d null) {\n           insufficientList.add(block);\n         }\n         // Log if this is our first time through\n         if (firstReplicationLog) {\n           logBlockReplicationInfo(block, bc, datanode, num,\n               blockManager.blocksMap.getStorages(block));\n           firstReplicationLog \u003d false;\n         }\n         // Update various counts\n         lowRedundancyBlocks++;\n         if (bc.isUnderConstruction()) {\n-          lowRedundancyInOpenFiles++;\n+          INode ucFile \u003d namesystem.getFSDirectory().getInode(bc.getId());\n+          if(!(ucFile instanceof  INodeFile) ||\n+              !ucFile.asFile().isUnderConstruction()) {\n+            LOG.warn(\"File \" + ucFile.getLocalName() + \" is not under \" +\n+                \"construction. Skipping add to low redundancy open files!\");\n+          } else {\n+            lowRedundancyBlocksInOpenFiles++;\n+            lowRedundancyOpenFiles.add(ucFile.getId());\n+          }\n         }\n         if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n           outOfServiceOnlyReplicas++;\n         }\n       }\n \n-      datanode.getLeavingServiceStatus().set(lowRedundancyInOpenFiles,\n-          lowRedundancyBlocks, outOfServiceOnlyReplicas);\n+      datanode.getLeavingServiceStatus().set(lowRedundancyBlocksInOpenFiles,\n+          lowRedundancyOpenFiles, lowRedundancyBlocks,\n+          outOfServiceOnlyReplicas);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processBlocksInternal(\n        final DatanodeDescriptor datanode,\n        final Iterator\u003cBlockInfo\u003e it,\n        final List\u003cBlockInfo\u003e insufficientList,\n        boolean pruneReliableBlocks) {\n      boolean firstReplicationLog \u003d true;\n      // Low redundancy in UC Blocks only\n      int lowRedundancyBlocksInOpenFiles \u003d 0;\n      LightWeightHashSet\u003cLong\u003e lowRedundancyOpenFiles \u003d\n          new LightWeightLinkedSet\u003c\u003e();\n      // All low redundancy blocks. Includes lowRedundancyOpenFiles.\n      int lowRedundancyBlocks \u003d 0;\n      // All maintenance and decommission replicas.\n      int outOfServiceOnlyReplicas \u003d 0;\n      while (it.hasNext()) {\n        if (insufficientList \u003d\u003d null\n            \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n          // During fullscan insufficientlyReplicated will NOT be null, iterator\n          // will be DN\u0027s iterator. So should not yield lock, otherwise\n          // ConcurrentModificationException could occur.\n          // Once the fullscan done, iterator will be a copy. So can yield the\n          // lock.\n          // Yielding is required in case of block number is greater than the\n          // configured per-iteration-limit.\n          namesystem.writeUnlock();\n          try {\n            LOG.debug(\"Yielded lock during decommission/maintenance check\");\n            Thread.sleep(0, 500);\n          } catch (InterruptedException ignored) {\n            return;\n          }\n          // reset\n          numBlocksCheckedPerLock \u003d 0;\n          namesystem.writeLock();\n        }\n        numBlocksChecked++;\n        numBlocksCheckedPerLock++;\n        final BlockInfo block \u003d it.next();\n        // Remove the block from the list if it\u0027s no longer in the block map,\n        // e.g. the containing file has been deleted\n        if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n          LOG.trace(\"Removing unknown block {}\", block);\n          it.remove();\n          continue;\n        }\n\n        long bcId \u003d block.getBlockCollectionId();\n        if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n          // Orphan block, will be invalidated eventually. Skip.\n          continue;\n        }\n\n        final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n        final NumberReplicas num \u003d blockManager.countNodes(block);\n        final int liveReplicas \u003d num.liveReplicas();\n\n        // Schedule low redundancy blocks for reconstruction\n        // if not already pending.\n        boolean isDecommission \u003d datanode.isDecommissionInProgress();\n        boolean neededReconstruction \u003d isDecommission ?\n            blockManager.isNeededReconstruction(block, num) :\n            blockManager.isNeededReconstructionForMaintenance(block, num);\n        if (neededReconstruction) {\n          if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n              blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n              blockManager.isPopulatingReplQueues()) {\n            // Process these blocks only when active NN is out of safe mode.\n            blockManager.neededReconstruction.add(block,\n                liveReplicas, num.readOnlyReplicas(),\n                num.outOfServiceReplicas(),\n                blockManager.getExpectedRedundancyNum(block));\n          }\n        }\n\n        // Even if the block is without sufficient redundancy,\n        // it might not block decommission/maintenance if it\n        // has sufficient redundancy.\n        if (isSufficient(block, bc, num, isDecommission)) {\n          if (pruneReliableBlocks) {\n            it.remove();\n          }\n          continue;\n        }\n\n        // We\u0027ve found a block without sufficient redundancy.\n        if (insufficientList !\u003d null) {\n          insufficientList.add(block);\n        }\n        // Log if this is our first time through\n        if (firstReplicationLog) {\n          logBlockReplicationInfo(block, bc, datanode, num,\n              blockManager.blocksMap.getStorages(block));\n          firstReplicationLog \u003d false;\n        }\n        // Update various counts\n        lowRedundancyBlocks++;\n        if (bc.isUnderConstruction()) {\n          INode ucFile \u003d namesystem.getFSDirectory().getInode(bc.getId());\n          if(!(ucFile instanceof  INodeFile) ||\n              !ucFile.asFile().isUnderConstruction()) {\n            LOG.warn(\"File \" + ucFile.getLocalName() + \" is not under \" +\n                \"construction. Skipping add to low redundancy open files!\");\n          } else {\n            lowRedundancyBlocksInOpenFiles++;\n            lowRedundancyOpenFiles.add(ucFile.getId());\n          }\n        }\n        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n          outOfServiceOnlyReplicas++;\n        }\n      }\n\n      datanode.getLeavingServiceStatus().set(lowRedundancyBlocksInOpenFiles,\n          lowRedundancyOpenFiles, lowRedundancyBlocks,\n          outOfServiceOnlyReplicas);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
      "extendedDetails": {}
    },
    "79df1e750ef558afed6d166ce225a23061b36aed": {
      "type": "Ymultichange(Yfilerename,Ybodychange)",
      "commitMessage": "HDFS-9388. Decommission related code to support Maintenance State for datanodes.\n",
      "commitDate": "02/08/17 2:22 PM",
      "commitName": "79df1e750ef558afed6d166ce225a23061b36aed",
      "commitAuthor": "Manoj Govindassamy",
      "subchanges": [
        {
          "type": "Yfilerename",
          "commitMessage": "HDFS-9388. Decommission related code to support Maintenance State for datanodes.\n",
          "commitDate": "02/08/17 2:22 PM",
          "commitName": "79df1e750ef558afed6d166ce225a23061b36aed",
          "commitAuthor": "Manoj Govindassamy",
          "commitDateOld": "02/08/17 12:12 PM",
          "commitNameOld": "12e44e7bdaf53d3720a89d32f0cc2717241bd6b2",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 0.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,104 +1,105 @@\n     private void processBlocksInternal(\n         final DatanodeDescriptor datanode,\n         final Iterator\u003cBlockInfo\u003e it,\n         final List\u003cBlockInfo\u003e insufficientList,\n         boolean pruneReliableBlocks) {\n       boolean firstReplicationLog \u003d true;\n       // Low redundancy in UC Blocks only\n       int lowRedundancyInOpenFiles \u003d 0;\n       // All low redundancy blocks. Includes lowRedundancyInOpenFiles.\n       int lowRedundancyBlocks \u003d 0;\n       // All maintenance and decommission replicas.\n       int outOfServiceOnlyReplicas \u003d 0;\n       while (it.hasNext()) {\n         if (insufficientList \u003d\u003d null\n             \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n           // During fullscan insufficientlyReplicated will NOT be null, iterator\n           // will be DN\u0027s iterator. So should not yield lock, otherwise\n           // ConcurrentModificationException could occur.\n           // Once the fullscan done, iterator will be a copy. So can yield the\n           // lock.\n           // Yielding is required in case of block number is greater than the\n           // configured per-iteration-limit.\n           namesystem.writeUnlock();\n           try {\n-            LOG.debug(\"Yielded lock during decommission check\");\n+            LOG.debug(\"Yielded lock during decommission/maintenance check\");\n             Thread.sleep(0, 500);\n           } catch (InterruptedException ignored) {\n             return;\n           }\n           // reset\n           numBlocksCheckedPerLock \u003d 0;\n           namesystem.writeLock();\n         }\n         numBlocksChecked++;\n         numBlocksCheckedPerLock++;\n         final BlockInfo block \u003d it.next();\n         // Remove the block from the list if it\u0027s no longer in the block map,\n         // e.g. the containing file has been deleted\n         if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n           LOG.trace(\"Removing unknown block {}\", block);\n           it.remove();\n           continue;\n         }\n \n         long bcId \u003d block.getBlockCollectionId();\n         if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n           // Orphan block, will be invalidated eventually. Skip.\n           continue;\n         }\n \n         final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n         final NumberReplicas num \u003d blockManager.countNodes(block);\n         final int liveReplicas \u003d num.liveReplicas();\n \n-        // Schedule low redundancy blocks for reconstruction if not already\n-        // pending\n+        // Schedule low redundancy blocks for reconstruction\n+        // if not already pending.\n         boolean isDecommission \u003d datanode.isDecommissionInProgress();\n         boolean neededReconstruction \u003d isDecommission ?\n             blockManager.isNeededReconstruction(block, num) :\n             blockManager.isNeededReconstructionForMaintenance(block, num);\n         if (neededReconstruction) {\n           if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n               blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n               blockManager.isPopulatingReplQueues()) {\n             // Process these blocks only when active NN is out of safe mode.\n             blockManager.neededReconstruction.add(block,\n                 liveReplicas, num.readOnlyReplicas(),\n                 num.outOfServiceReplicas(),\n                 blockManager.getExpectedRedundancyNum(block));\n           }\n         }\n \n         // Even if the block is without sufficient redundancy,\n-        // it doesn\u0027t block decommission if has sufficient redundancy\n+        // it might not block decommission/maintenance if it\n+        // has sufficient redundancy.\n         if (isSufficient(block, bc, num, isDecommission)) {\n           if (pruneReliableBlocks) {\n             it.remove();\n           }\n           continue;\n         }\n \n         // We\u0027ve found a block without sufficient redundancy.\n         if (insufficientList !\u003d null) {\n           insufficientList.add(block);\n         }\n         // Log if this is our first time through\n         if (firstReplicationLog) {\n           logBlockReplicationInfo(block, bc, datanode, num,\n               blockManager.blocksMap.getStorages(block));\n           firstReplicationLog \u003d false;\n         }\n         // Update various counts\n         lowRedundancyBlocks++;\n         if (bc.isUnderConstruction()) {\n           lowRedundancyInOpenFiles++;\n         }\n         if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n           outOfServiceOnlyReplicas++;\n         }\n       }\n \n       datanode.getLeavingServiceStatus().set(lowRedundancyInOpenFiles,\n           lowRedundancyBlocks, outOfServiceOnlyReplicas);\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void processBlocksInternal(\n        final DatanodeDescriptor datanode,\n        final Iterator\u003cBlockInfo\u003e it,\n        final List\u003cBlockInfo\u003e insufficientList,\n        boolean pruneReliableBlocks) {\n      boolean firstReplicationLog \u003d true;\n      // Low redundancy in UC Blocks only\n      int lowRedundancyInOpenFiles \u003d 0;\n      // All low redundancy blocks. Includes lowRedundancyInOpenFiles.\n      int lowRedundancyBlocks \u003d 0;\n      // All maintenance and decommission replicas.\n      int outOfServiceOnlyReplicas \u003d 0;\n      while (it.hasNext()) {\n        if (insufficientList \u003d\u003d null\n            \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n          // During fullscan insufficientlyReplicated will NOT be null, iterator\n          // will be DN\u0027s iterator. So should not yield lock, otherwise\n          // ConcurrentModificationException could occur.\n          // Once the fullscan done, iterator will be a copy. So can yield the\n          // lock.\n          // Yielding is required in case of block number is greater than the\n          // configured per-iteration-limit.\n          namesystem.writeUnlock();\n          try {\n            LOG.debug(\"Yielded lock during decommission/maintenance check\");\n            Thread.sleep(0, 500);\n          } catch (InterruptedException ignored) {\n            return;\n          }\n          // reset\n          numBlocksCheckedPerLock \u003d 0;\n          namesystem.writeLock();\n        }\n        numBlocksChecked++;\n        numBlocksCheckedPerLock++;\n        final BlockInfo block \u003d it.next();\n        // Remove the block from the list if it\u0027s no longer in the block map,\n        // e.g. the containing file has been deleted\n        if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n          LOG.trace(\"Removing unknown block {}\", block);\n          it.remove();\n          continue;\n        }\n\n        long bcId \u003d block.getBlockCollectionId();\n        if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n          // Orphan block, will be invalidated eventually. Skip.\n          continue;\n        }\n\n        final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n        final NumberReplicas num \u003d blockManager.countNodes(block);\n        final int liveReplicas \u003d num.liveReplicas();\n\n        // Schedule low redundancy blocks for reconstruction\n        // if not already pending.\n        boolean isDecommission \u003d datanode.isDecommissionInProgress();\n        boolean neededReconstruction \u003d isDecommission ?\n            blockManager.isNeededReconstruction(block, num) :\n            blockManager.isNeededReconstructionForMaintenance(block, num);\n        if (neededReconstruction) {\n          if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n              blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n              blockManager.isPopulatingReplQueues()) {\n            // Process these blocks only when active NN is out of safe mode.\n            blockManager.neededReconstruction.add(block,\n                liveReplicas, num.readOnlyReplicas(),\n                num.outOfServiceReplicas(),\n                blockManager.getExpectedRedundancyNum(block));\n          }\n        }\n\n        // Even if the block is without sufficient redundancy,\n        // it might not block decommission/maintenance if it\n        // has sufficient redundancy.\n        if (isSufficient(block, bc, num, isDecommission)) {\n          if (pruneReliableBlocks) {\n            it.remove();\n          }\n          continue;\n        }\n\n        // We\u0027ve found a block without sufficient redundancy.\n        if (insufficientList !\u003d null) {\n          insufficientList.add(block);\n        }\n        // Log if this is our first time through\n        if (firstReplicationLog) {\n          logBlockReplicationInfo(block, bc, datanode, num,\n              blockManager.blocksMap.getStorages(block));\n          firstReplicationLog \u003d false;\n        }\n        // Update various counts\n        lowRedundancyBlocks++;\n        if (bc.isUnderConstruction()) {\n          lowRedundancyInOpenFiles++;\n        }\n        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n          outOfServiceOnlyReplicas++;\n        }\n      }\n\n      datanode.getLeavingServiceStatus().set(lowRedundancyInOpenFiles,\n          lowRedundancyBlocks, outOfServiceOnlyReplicas);\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9388. Decommission related code to support Maintenance State for datanodes.\n",
          "commitDate": "02/08/17 2:22 PM",
          "commitName": "79df1e750ef558afed6d166ce225a23061b36aed",
          "commitAuthor": "Manoj Govindassamy",
          "commitDateOld": "02/08/17 12:12 PM",
          "commitNameOld": "12e44e7bdaf53d3720a89d32f0cc2717241bd6b2",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 0.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,104 +1,105 @@\n     private void processBlocksInternal(\n         final DatanodeDescriptor datanode,\n         final Iterator\u003cBlockInfo\u003e it,\n         final List\u003cBlockInfo\u003e insufficientList,\n         boolean pruneReliableBlocks) {\n       boolean firstReplicationLog \u003d true;\n       // Low redundancy in UC Blocks only\n       int lowRedundancyInOpenFiles \u003d 0;\n       // All low redundancy blocks. Includes lowRedundancyInOpenFiles.\n       int lowRedundancyBlocks \u003d 0;\n       // All maintenance and decommission replicas.\n       int outOfServiceOnlyReplicas \u003d 0;\n       while (it.hasNext()) {\n         if (insufficientList \u003d\u003d null\n             \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n           // During fullscan insufficientlyReplicated will NOT be null, iterator\n           // will be DN\u0027s iterator. So should not yield lock, otherwise\n           // ConcurrentModificationException could occur.\n           // Once the fullscan done, iterator will be a copy. So can yield the\n           // lock.\n           // Yielding is required in case of block number is greater than the\n           // configured per-iteration-limit.\n           namesystem.writeUnlock();\n           try {\n-            LOG.debug(\"Yielded lock during decommission check\");\n+            LOG.debug(\"Yielded lock during decommission/maintenance check\");\n             Thread.sleep(0, 500);\n           } catch (InterruptedException ignored) {\n             return;\n           }\n           // reset\n           numBlocksCheckedPerLock \u003d 0;\n           namesystem.writeLock();\n         }\n         numBlocksChecked++;\n         numBlocksCheckedPerLock++;\n         final BlockInfo block \u003d it.next();\n         // Remove the block from the list if it\u0027s no longer in the block map,\n         // e.g. the containing file has been deleted\n         if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n           LOG.trace(\"Removing unknown block {}\", block);\n           it.remove();\n           continue;\n         }\n \n         long bcId \u003d block.getBlockCollectionId();\n         if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n           // Orphan block, will be invalidated eventually. Skip.\n           continue;\n         }\n \n         final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n         final NumberReplicas num \u003d blockManager.countNodes(block);\n         final int liveReplicas \u003d num.liveReplicas();\n \n-        // Schedule low redundancy blocks for reconstruction if not already\n-        // pending\n+        // Schedule low redundancy blocks for reconstruction\n+        // if not already pending.\n         boolean isDecommission \u003d datanode.isDecommissionInProgress();\n         boolean neededReconstruction \u003d isDecommission ?\n             blockManager.isNeededReconstruction(block, num) :\n             blockManager.isNeededReconstructionForMaintenance(block, num);\n         if (neededReconstruction) {\n           if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n               blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n               blockManager.isPopulatingReplQueues()) {\n             // Process these blocks only when active NN is out of safe mode.\n             blockManager.neededReconstruction.add(block,\n                 liveReplicas, num.readOnlyReplicas(),\n                 num.outOfServiceReplicas(),\n                 blockManager.getExpectedRedundancyNum(block));\n           }\n         }\n \n         // Even if the block is without sufficient redundancy,\n-        // it doesn\u0027t block decommission if has sufficient redundancy\n+        // it might not block decommission/maintenance if it\n+        // has sufficient redundancy.\n         if (isSufficient(block, bc, num, isDecommission)) {\n           if (pruneReliableBlocks) {\n             it.remove();\n           }\n           continue;\n         }\n \n         // We\u0027ve found a block without sufficient redundancy.\n         if (insufficientList !\u003d null) {\n           insufficientList.add(block);\n         }\n         // Log if this is our first time through\n         if (firstReplicationLog) {\n           logBlockReplicationInfo(block, bc, datanode, num,\n               blockManager.blocksMap.getStorages(block));\n           firstReplicationLog \u003d false;\n         }\n         // Update various counts\n         lowRedundancyBlocks++;\n         if (bc.isUnderConstruction()) {\n           lowRedundancyInOpenFiles++;\n         }\n         if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n           outOfServiceOnlyReplicas++;\n         }\n       }\n \n       datanode.getLeavingServiceStatus().set(lowRedundancyInOpenFiles,\n           lowRedundancyBlocks, outOfServiceOnlyReplicas);\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void processBlocksInternal(\n        final DatanodeDescriptor datanode,\n        final Iterator\u003cBlockInfo\u003e it,\n        final List\u003cBlockInfo\u003e insufficientList,\n        boolean pruneReliableBlocks) {\n      boolean firstReplicationLog \u003d true;\n      // Low redundancy in UC Blocks only\n      int lowRedundancyInOpenFiles \u003d 0;\n      // All low redundancy blocks. Includes lowRedundancyInOpenFiles.\n      int lowRedundancyBlocks \u003d 0;\n      // All maintenance and decommission replicas.\n      int outOfServiceOnlyReplicas \u003d 0;\n      while (it.hasNext()) {\n        if (insufficientList \u003d\u003d null\n            \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n          // During fullscan insufficientlyReplicated will NOT be null, iterator\n          // will be DN\u0027s iterator. So should not yield lock, otherwise\n          // ConcurrentModificationException could occur.\n          // Once the fullscan done, iterator will be a copy. So can yield the\n          // lock.\n          // Yielding is required in case of block number is greater than the\n          // configured per-iteration-limit.\n          namesystem.writeUnlock();\n          try {\n            LOG.debug(\"Yielded lock during decommission/maintenance check\");\n            Thread.sleep(0, 500);\n          } catch (InterruptedException ignored) {\n            return;\n          }\n          // reset\n          numBlocksCheckedPerLock \u003d 0;\n          namesystem.writeLock();\n        }\n        numBlocksChecked++;\n        numBlocksCheckedPerLock++;\n        final BlockInfo block \u003d it.next();\n        // Remove the block from the list if it\u0027s no longer in the block map,\n        // e.g. the containing file has been deleted\n        if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n          LOG.trace(\"Removing unknown block {}\", block);\n          it.remove();\n          continue;\n        }\n\n        long bcId \u003d block.getBlockCollectionId();\n        if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n          // Orphan block, will be invalidated eventually. Skip.\n          continue;\n        }\n\n        final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n        final NumberReplicas num \u003d blockManager.countNodes(block);\n        final int liveReplicas \u003d num.liveReplicas();\n\n        // Schedule low redundancy blocks for reconstruction\n        // if not already pending.\n        boolean isDecommission \u003d datanode.isDecommissionInProgress();\n        boolean neededReconstruction \u003d isDecommission ?\n            blockManager.isNeededReconstruction(block, num) :\n            blockManager.isNeededReconstructionForMaintenance(block, num);\n        if (neededReconstruction) {\n          if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n              blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n              blockManager.isPopulatingReplQueues()) {\n            // Process these blocks only when active NN is out of safe mode.\n            blockManager.neededReconstruction.add(block,\n                liveReplicas, num.readOnlyReplicas(),\n                num.outOfServiceReplicas(),\n                blockManager.getExpectedRedundancyNum(block));\n          }\n        }\n\n        // Even if the block is without sufficient redundancy,\n        // it might not block decommission/maintenance if it\n        // has sufficient redundancy.\n        if (isSufficient(block, bc, num, isDecommission)) {\n          if (pruneReliableBlocks) {\n            it.remove();\n          }\n          continue;\n        }\n\n        // We\u0027ve found a block without sufficient redundancy.\n        if (insufficientList !\u003d null) {\n          insufficientList.add(block);\n        }\n        // Log if this is our first time through\n        if (firstReplicationLog) {\n          logBlockReplicationInfo(block, bc, datanode, num,\n              blockManager.blocksMap.getStorages(block));\n          firstReplicationLog \u003d false;\n        }\n        // Update various counts\n        lowRedundancyBlocks++;\n        if (bc.isUnderConstruction()) {\n          lowRedundancyInOpenFiles++;\n        }\n        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n          outOfServiceOnlyReplicas++;\n        }\n      }\n\n      datanode.getLeavingServiceStatus().set(lowRedundancyInOpenFiles,\n          lowRedundancyBlocks, outOfServiceOnlyReplicas);\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "467f5f1735494c5ef74e6591069884d3771c17e4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9391. Update webUI/JMX to display maintenance state info. (Manoj Govindassamy via mingma)\n",
      "commitDate": "10/01/17 8:12 PM",
      "commitName": "467f5f1735494c5ef74e6591069884d3771c17e4",
      "commitAuthor": "Ming Ma",
      "commitDateOld": "17/10/16 5:45 PM",
      "commitNameOld": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
      "commitAuthorOld": "Ming Ma",
      "daysBetweenCommits": 85.14,
      "commitsBetweenForRepo": 576,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,101 +1,104 @@\n     private void processBlocksInternal(\n         final DatanodeDescriptor datanode,\n         final Iterator\u003cBlockInfo\u003e it,\n         final List\u003cBlockInfo\u003e insufficientList,\n         boolean pruneReliableBlocks) {\n       boolean firstReplicationLog \u003d true;\n-      int lowRedundancyBlocks \u003d 0;\n-      int outOfServiceOnlyReplicas \u003d 0;\n+      // Low redundancy in UC Blocks only\n       int lowRedundancyInOpenFiles \u003d 0;\n+      // All low redundancy blocks. Includes lowRedundancyInOpenFiles.\n+      int lowRedundancyBlocks \u003d 0;\n+      // All maintenance and decommission replicas.\n+      int outOfServiceOnlyReplicas \u003d 0;\n       while (it.hasNext()) {\n         if (insufficientList \u003d\u003d null\n             \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n           // During fullscan insufficientlyReplicated will NOT be null, iterator\n           // will be DN\u0027s iterator. So should not yield lock, otherwise\n           // ConcurrentModificationException could occur.\n           // Once the fullscan done, iterator will be a copy. So can yield the\n           // lock.\n           // Yielding is required in case of block number is greater than the\n           // configured per-iteration-limit.\n           namesystem.writeUnlock();\n           try {\n             LOG.debug(\"Yielded lock during decommission check\");\n             Thread.sleep(0, 500);\n           } catch (InterruptedException ignored) {\n             return;\n           }\n           // reset\n           numBlocksCheckedPerLock \u003d 0;\n           namesystem.writeLock();\n         }\n         numBlocksChecked++;\n         numBlocksCheckedPerLock++;\n         final BlockInfo block \u003d it.next();\n         // Remove the block from the list if it\u0027s no longer in the block map,\n         // e.g. the containing file has been deleted\n         if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n           LOG.trace(\"Removing unknown block {}\", block);\n           it.remove();\n           continue;\n         }\n \n         long bcId \u003d block.getBlockCollectionId();\n         if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n           // Orphan block, will be invalidated eventually. Skip.\n           continue;\n         }\n \n         final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n         final NumberReplicas num \u003d blockManager.countNodes(block);\n         final int liveReplicas \u003d num.liveReplicas();\n \n         // Schedule low redundancy blocks for reconstruction if not already\n         // pending\n         boolean isDecommission \u003d datanode.isDecommissionInProgress();\n         boolean neededReconstruction \u003d isDecommission ?\n             blockManager.isNeededReconstruction(block, num) :\n             blockManager.isNeededReconstructionForMaintenance(block, num);\n         if (neededReconstruction) {\n           if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n               blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n               blockManager.isPopulatingReplQueues()) {\n             // Process these blocks only when active NN is out of safe mode.\n             blockManager.neededReconstruction.add(block,\n                 liveReplicas, num.readOnlyReplicas(),\n                 num.outOfServiceReplicas(),\n                 blockManager.getExpectedRedundancyNum(block));\n           }\n         }\n \n         // Even if the block is without sufficient redundancy,\n         // it doesn\u0027t block decommission if has sufficient redundancy\n         if (isSufficient(block, bc, num, isDecommission)) {\n           if (pruneReliableBlocks) {\n             it.remove();\n           }\n           continue;\n         }\n \n         // We\u0027ve found a block without sufficient redundancy.\n         if (insufficientList !\u003d null) {\n           insufficientList.add(block);\n         }\n         // Log if this is our first time through\n         if (firstReplicationLog) {\n           logBlockReplicationInfo(block, bc, datanode, num,\n               blockManager.blocksMap.getStorages(block));\n           firstReplicationLog \u003d false;\n         }\n         // Update various counts\n         lowRedundancyBlocks++;\n         if (bc.isUnderConstruction()) {\n           lowRedundancyInOpenFiles++;\n         }\n         if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n           outOfServiceOnlyReplicas++;\n         }\n       }\n \n-      datanode.getLeavingServiceStatus().set(lowRedundancyBlocks,\n-          outOfServiceOnlyReplicas, lowRedundancyInOpenFiles);\n+      datanode.getLeavingServiceStatus().set(lowRedundancyInOpenFiles,\n+          lowRedundancyBlocks, outOfServiceOnlyReplicas);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processBlocksInternal(\n        final DatanodeDescriptor datanode,\n        final Iterator\u003cBlockInfo\u003e it,\n        final List\u003cBlockInfo\u003e insufficientList,\n        boolean pruneReliableBlocks) {\n      boolean firstReplicationLog \u003d true;\n      // Low redundancy in UC Blocks only\n      int lowRedundancyInOpenFiles \u003d 0;\n      // All low redundancy blocks. Includes lowRedundancyInOpenFiles.\n      int lowRedundancyBlocks \u003d 0;\n      // All maintenance and decommission replicas.\n      int outOfServiceOnlyReplicas \u003d 0;\n      while (it.hasNext()) {\n        if (insufficientList \u003d\u003d null\n            \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n          // During fullscan insufficientlyReplicated will NOT be null, iterator\n          // will be DN\u0027s iterator. So should not yield lock, otherwise\n          // ConcurrentModificationException could occur.\n          // Once the fullscan done, iterator will be a copy. So can yield the\n          // lock.\n          // Yielding is required in case of block number is greater than the\n          // configured per-iteration-limit.\n          namesystem.writeUnlock();\n          try {\n            LOG.debug(\"Yielded lock during decommission check\");\n            Thread.sleep(0, 500);\n          } catch (InterruptedException ignored) {\n            return;\n          }\n          // reset\n          numBlocksCheckedPerLock \u003d 0;\n          namesystem.writeLock();\n        }\n        numBlocksChecked++;\n        numBlocksCheckedPerLock++;\n        final BlockInfo block \u003d it.next();\n        // Remove the block from the list if it\u0027s no longer in the block map,\n        // e.g. the containing file has been deleted\n        if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n          LOG.trace(\"Removing unknown block {}\", block);\n          it.remove();\n          continue;\n        }\n\n        long bcId \u003d block.getBlockCollectionId();\n        if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n          // Orphan block, will be invalidated eventually. Skip.\n          continue;\n        }\n\n        final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n        final NumberReplicas num \u003d blockManager.countNodes(block);\n        final int liveReplicas \u003d num.liveReplicas();\n\n        // Schedule low redundancy blocks for reconstruction if not already\n        // pending\n        boolean isDecommission \u003d datanode.isDecommissionInProgress();\n        boolean neededReconstruction \u003d isDecommission ?\n            blockManager.isNeededReconstruction(block, num) :\n            blockManager.isNeededReconstructionForMaintenance(block, num);\n        if (neededReconstruction) {\n          if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n              blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n              blockManager.isPopulatingReplQueues()) {\n            // Process these blocks only when active NN is out of safe mode.\n            blockManager.neededReconstruction.add(block,\n                liveReplicas, num.readOnlyReplicas(),\n                num.outOfServiceReplicas(),\n                blockManager.getExpectedRedundancyNum(block));\n          }\n        }\n\n        // Even if the block is without sufficient redundancy,\n        // it doesn\u0027t block decommission if has sufficient redundancy\n        if (isSufficient(block, bc, num, isDecommission)) {\n          if (pruneReliableBlocks) {\n            it.remove();\n          }\n          continue;\n        }\n\n        // We\u0027ve found a block without sufficient redundancy.\n        if (insufficientList !\u003d null) {\n          insufficientList.add(block);\n        }\n        // Log if this is our first time through\n        if (firstReplicationLog) {\n          logBlockReplicationInfo(block, bc, datanode, num,\n              blockManager.blocksMap.getStorages(block));\n          firstReplicationLog \u003d false;\n        }\n        // Update various counts\n        lowRedundancyBlocks++;\n        if (bc.isUnderConstruction()) {\n          lowRedundancyInOpenFiles++;\n        }\n        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n          outOfServiceOnlyReplicas++;\n        }\n      }\n\n      datanode.getLeavingServiceStatus().set(lowRedundancyInOpenFiles,\n          lowRedundancyBlocks, outOfServiceOnlyReplicas);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
      "extendedDetails": {}
    },
    "b61fb267b92b2736920b4bd0c673d31e7632ebb9": {
      "type": "Ymultichange(Yrename,Ybodychange)",
      "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
      "commitDate": "17/10/16 5:45 PM",
      "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
      "commitAuthor": "Ming Ma",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
          "commitDate": "17/10/16 5:45 PM",
          "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
          "commitAuthor": "Ming Ma",
          "commitDateOld": "13/10/16 11:52 AM",
          "commitNameOld": "332a61fd74fd2a9874319232c583ab5d2c53ff03",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 4.25,
          "commitsBetweenForRepo": 27,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,98 +1,101 @@\n-    private void processBlocksForDecomInternal(\n+    private void processBlocksInternal(\n         final DatanodeDescriptor datanode,\n         final Iterator\u003cBlockInfo\u003e it,\n         final List\u003cBlockInfo\u003e insufficientList,\n         boolean pruneReliableBlocks) {\n       boolean firstReplicationLog \u003d true;\n       int lowRedundancyBlocks \u003d 0;\n-      int decommissionOnlyReplicas \u003d 0;\n+      int outOfServiceOnlyReplicas \u003d 0;\n       int lowRedundancyInOpenFiles \u003d 0;\n       while (it.hasNext()) {\n         if (insufficientList \u003d\u003d null\n             \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n           // During fullscan insufficientlyReplicated will NOT be null, iterator\n           // will be DN\u0027s iterator. So should not yield lock, otherwise\n           // ConcurrentModificationException could occur.\n           // Once the fullscan done, iterator will be a copy. So can yield the\n           // lock.\n           // Yielding is required in case of block number is greater than the\n           // configured per-iteration-limit.\n           namesystem.writeUnlock();\n           try {\n             LOG.debug(\"Yielded lock during decommission check\");\n             Thread.sleep(0, 500);\n           } catch (InterruptedException ignored) {\n             return;\n           }\n           // reset\n           numBlocksCheckedPerLock \u003d 0;\n           namesystem.writeLock();\n         }\n         numBlocksChecked++;\n         numBlocksCheckedPerLock++;\n         final BlockInfo block \u003d it.next();\n         // Remove the block from the list if it\u0027s no longer in the block map,\n         // e.g. the containing file has been deleted\n         if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n           LOG.trace(\"Removing unknown block {}\", block);\n           it.remove();\n           continue;\n         }\n \n         long bcId \u003d block.getBlockCollectionId();\n         if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n           // Orphan block, will be invalidated eventually. Skip.\n           continue;\n         }\n \n         final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n         final NumberReplicas num \u003d blockManager.countNodes(block);\n         final int liveReplicas \u003d num.liveReplicas();\n \n         // Schedule low redundancy blocks for reconstruction if not already\n         // pending\n-        if (blockManager.isNeededReconstruction(block, liveReplicas)) {\n+        boolean isDecommission \u003d datanode.isDecommissionInProgress();\n+        boolean neededReconstruction \u003d isDecommission ?\n+            blockManager.isNeededReconstruction(block, num) :\n+            blockManager.isNeededReconstructionForMaintenance(block, num);\n+        if (neededReconstruction) {\n           if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n               blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n               blockManager.isPopulatingReplQueues()) {\n             // Process these blocks only when active NN is out of safe mode.\n             blockManager.neededReconstruction.add(block,\n                 liveReplicas, num.readOnlyReplicas(),\n-                num.decommissionedAndDecommissioning(),\n+                num.outOfServiceReplicas(),\n                 blockManager.getExpectedRedundancyNum(block));\n           }\n         }\n \n         // Even if the block is without sufficient redundancy,\n         // it doesn\u0027t block decommission if has sufficient redundancy\n-        if (isSufficient(block, bc, num)) {\n+        if (isSufficient(block, bc, num, isDecommission)) {\n           if (pruneReliableBlocks) {\n             it.remove();\n           }\n           continue;\n         }\n \n         // We\u0027ve found a block without sufficient redundancy.\n         if (insufficientList !\u003d null) {\n           insufficientList.add(block);\n         }\n         // Log if this is our first time through\n         if (firstReplicationLog) {\n           logBlockReplicationInfo(block, bc, datanode, num,\n               blockManager.blocksMap.getStorages(block));\n           firstReplicationLog \u003d false;\n         }\n         // Update various counts\n         lowRedundancyBlocks++;\n         if (bc.isUnderConstruction()) {\n           lowRedundancyInOpenFiles++;\n         }\n-        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.decommissionedAndDecommissioning() \u003e 0)) {\n-          decommissionOnlyReplicas++;\n+        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n+          outOfServiceOnlyReplicas++;\n         }\n       }\n \n-      datanode.decommissioningStatus.set(lowRedundancyBlocks,\n-          decommissionOnlyReplicas,\n-          lowRedundancyInOpenFiles);\n+      datanode.getLeavingServiceStatus().set(lowRedundancyBlocks,\n+          outOfServiceOnlyReplicas, lowRedundancyInOpenFiles);\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void processBlocksInternal(\n        final DatanodeDescriptor datanode,\n        final Iterator\u003cBlockInfo\u003e it,\n        final List\u003cBlockInfo\u003e insufficientList,\n        boolean pruneReliableBlocks) {\n      boolean firstReplicationLog \u003d true;\n      int lowRedundancyBlocks \u003d 0;\n      int outOfServiceOnlyReplicas \u003d 0;\n      int lowRedundancyInOpenFiles \u003d 0;\n      while (it.hasNext()) {\n        if (insufficientList \u003d\u003d null\n            \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n          // During fullscan insufficientlyReplicated will NOT be null, iterator\n          // will be DN\u0027s iterator. So should not yield lock, otherwise\n          // ConcurrentModificationException could occur.\n          // Once the fullscan done, iterator will be a copy. So can yield the\n          // lock.\n          // Yielding is required in case of block number is greater than the\n          // configured per-iteration-limit.\n          namesystem.writeUnlock();\n          try {\n            LOG.debug(\"Yielded lock during decommission check\");\n            Thread.sleep(0, 500);\n          } catch (InterruptedException ignored) {\n            return;\n          }\n          // reset\n          numBlocksCheckedPerLock \u003d 0;\n          namesystem.writeLock();\n        }\n        numBlocksChecked++;\n        numBlocksCheckedPerLock++;\n        final BlockInfo block \u003d it.next();\n        // Remove the block from the list if it\u0027s no longer in the block map,\n        // e.g. the containing file has been deleted\n        if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n          LOG.trace(\"Removing unknown block {}\", block);\n          it.remove();\n          continue;\n        }\n\n        long bcId \u003d block.getBlockCollectionId();\n        if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n          // Orphan block, will be invalidated eventually. Skip.\n          continue;\n        }\n\n        final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n        final NumberReplicas num \u003d blockManager.countNodes(block);\n        final int liveReplicas \u003d num.liveReplicas();\n\n        // Schedule low redundancy blocks for reconstruction if not already\n        // pending\n        boolean isDecommission \u003d datanode.isDecommissionInProgress();\n        boolean neededReconstruction \u003d isDecommission ?\n            blockManager.isNeededReconstruction(block, num) :\n            blockManager.isNeededReconstructionForMaintenance(block, num);\n        if (neededReconstruction) {\n          if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n              blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n              blockManager.isPopulatingReplQueues()) {\n            // Process these blocks only when active NN is out of safe mode.\n            blockManager.neededReconstruction.add(block,\n                liveReplicas, num.readOnlyReplicas(),\n                num.outOfServiceReplicas(),\n                blockManager.getExpectedRedundancyNum(block));\n          }\n        }\n\n        // Even if the block is without sufficient redundancy,\n        // it doesn\u0027t block decommission if has sufficient redundancy\n        if (isSufficient(block, bc, num, isDecommission)) {\n          if (pruneReliableBlocks) {\n            it.remove();\n          }\n          continue;\n        }\n\n        // We\u0027ve found a block without sufficient redundancy.\n        if (insufficientList !\u003d null) {\n          insufficientList.add(block);\n        }\n        // Log if this is our first time through\n        if (firstReplicationLog) {\n          logBlockReplicationInfo(block, bc, datanode, num,\n              blockManager.blocksMap.getStorages(block));\n          firstReplicationLog \u003d false;\n        }\n        // Update various counts\n        lowRedundancyBlocks++;\n        if (bc.isUnderConstruction()) {\n          lowRedundancyInOpenFiles++;\n        }\n        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n          outOfServiceOnlyReplicas++;\n        }\n      }\n\n      datanode.getLeavingServiceStatus().set(lowRedundancyBlocks,\n          outOfServiceOnlyReplicas, lowRedundancyInOpenFiles);\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
          "extendedDetails": {
            "oldValue": "processBlocksForDecomInternal",
            "newValue": "processBlocksInternal"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9390. Block management for maintenance states.\n",
          "commitDate": "17/10/16 5:45 PM",
          "commitName": "b61fb267b92b2736920b4bd0c673d31e7632ebb9",
          "commitAuthor": "Ming Ma",
          "commitDateOld": "13/10/16 11:52 AM",
          "commitNameOld": "332a61fd74fd2a9874319232c583ab5d2c53ff03",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 4.25,
          "commitsBetweenForRepo": 27,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,98 +1,101 @@\n-    private void processBlocksForDecomInternal(\n+    private void processBlocksInternal(\n         final DatanodeDescriptor datanode,\n         final Iterator\u003cBlockInfo\u003e it,\n         final List\u003cBlockInfo\u003e insufficientList,\n         boolean pruneReliableBlocks) {\n       boolean firstReplicationLog \u003d true;\n       int lowRedundancyBlocks \u003d 0;\n-      int decommissionOnlyReplicas \u003d 0;\n+      int outOfServiceOnlyReplicas \u003d 0;\n       int lowRedundancyInOpenFiles \u003d 0;\n       while (it.hasNext()) {\n         if (insufficientList \u003d\u003d null\n             \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n           // During fullscan insufficientlyReplicated will NOT be null, iterator\n           // will be DN\u0027s iterator. So should not yield lock, otherwise\n           // ConcurrentModificationException could occur.\n           // Once the fullscan done, iterator will be a copy. So can yield the\n           // lock.\n           // Yielding is required in case of block number is greater than the\n           // configured per-iteration-limit.\n           namesystem.writeUnlock();\n           try {\n             LOG.debug(\"Yielded lock during decommission check\");\n             Thread.sleep(0, 500);\n           } catch (InterruptedException ignored) {\n             return;\n           }\n           // reset\n           numBlocksCheckedPerLock \u003d 0;\n           namesystem.writeLock();\n         }\n         numBlocksChecked++;\n         numBlocksCheckedPerLock++;\n         final BlockInfo block \u003d it.next();\n         // Remove the block from the list if it\u0027s no longer in the block map,\n         // e.g. the containing file has been deleted\n         if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n           LOG.trace(\"Removing unknown block {}\", block);\n           it.remove();\n           continue;\n         }\n \n         long bcId \u003d block.getBlockCollectionId();\n         if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n           // Orphan block, will be invalidated eventually. Skip.\n           continue;\n         }\n \n         final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n         final NumberReplicas num \u003d blockManager.countNodes(block);\n         final int liveReplicas \u003d num.liveReplicas();\n \n         // Schedule low redundancy blocks for reconstruction if not already\n         // pending\n-        if (blockManager.isNeededReconstruction(block, liveReplicas)) {\n+        boolean isDecommission \u003d datanode.isDecommissionInProgress();\n+        boolean neededReconstruction \u003d isDecommission ?\n+            blockManager.isNeededReconstruction(block, num) :\n+            blockManager.isNeededReconstructionForMaintenance(block, num);\n+        if (neededReconstruction) {\n           if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n               blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n               blockManager.isPopulatingReplQueues()) {\n             // Process these blocks only when active NN is out of safe mode.\n             blockManager.neededReconstruction.add(block,\n                 liveReplicas, num.readOnlyReplicas(),\n-                num.decommissionedAndDecommissioning(),\n+                num.outOfServiceReplicas(),\n                 blockManager.getExpectedRedundancyNum(block));\n           }\n         }\n \n         // Even if the block is without sufficient redundancy,\n         // it doesn\u0027t block decommission if has sufficient redundancy\n-        if (isSufficient(block, bc, num)) {\n+        if (isSufficient(block, bc, num, isDecommission)) {\n           if (pruneReliableBlocks) {\n             it.remove();\n           }\n           continue;\n         }\n \n         // We\u0027ve found a block without sufficient redundancy.\n         if (insufficientList !\u003d null) {\n           insufficientList.add(block);\n         }\n         // Log if this is our first time through\n         if (firstReplicationLog) {\n           logBlockReplicationInfo(block, bc, datanode, num,\n               blockManager.blocksMap.getStorages(block));\n           firstReplicationLog \u003d false;\n         }\n         // Update various counts\n         lowRedundancyBlocks++;\n         if (bc.isUnderConstruction()) {\n           lowRedundancyInOpenFiles++;\n         }\n-        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.decommissionedAndDecommissioning() \u003e 0)) {\n-          decommissionOnlyReplicas++;\n+        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n+          outOfServiceOnlyReplicas++;\n         }\n       }\n \n-      datanode.decommissioningStatus.set(lowRedundancyBlocks,\n-          decommissionOnlyReplicas,\n-          lowRedundancyInOpenFiles);\n+      datanode.getLeavingServiceStatus().set(lowRedundancyBlocks,\n+          outOfServiceOnlyReplicas, lowRedundancyInOpenFiles);\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private void processBlocksInternal(\n        final DatanodeDescriptor datanode,\n        final Iterator\u003cBlockInfo\u003e it,\n        final List\u003cBlockInfo\u003e insufficientList,\n        boolean pruneReliableBlocks) {\n      boolean firstReplicationLog \u003d true;\n      int lowRedundancyBlocks \u003d 0;\n      int outOfServiceOnlyReplicas \u003d 0;\n      int lowRedundancyInOpenFiles \u003d 0;\n      while (it.hasNext()) {\n        if (insufficientList \u003d\u003d null\n            \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n          // During fullscan insufficientlyReplicated will NOT be null, iterator\n          // will be DN\u0027s iterator. So should not yield lock, otherwise\n          // ConcurrentModificationException could occur.\n          // Once the fullscan done, iterator will be a copy. So can yield the\n          // lock.\n          // Yielding is required in case of block number is greater than the\n          // configured per-iteration-limit.\n          namesystem.writeUnlock();\n          try {\n            LOG.debug(\"Yielded lock during decommission check\");\n            Thread.sleep(0, 500);\n          } catch (InterruptedException ignored) {\n            return;\n          }\n          // reset\n          numBlocksCheckedPerLock \u003d 0;\n          namesystem.writeLock();\n        }\n        numBlocksChecked++;\n        numBlocksCheckedPerLock++;\n        final BlockInfo block \u003d it.next();\n        // Remove the block from the list if it\u0027s no longer in the block map,\n        // e.g. the containing file has been deleted\n        if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n          LOG.trace(\"Removing unknown block {}\", block);\n          it.remove();\n          continue;\n        }\n\n        long bcId \u003d block.getBlockCollectionId();\n        if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n          // Orphan block, will be invalidated eventually. Skip.\n          continue;\n        }\n\n        final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n        final NumberReplicas num \u003d blockManager.countNodes(block);\n        final int liveReplicas \u003d num.liveReplicas();\n\n        // Schedule low redundancy blocks for reconstruction if not already\n        // pending\n        boolean isDecommission \u003d datanode.isDecommissionInProgress();\n        boolean neededReconstruction \u003d isDecommission ?\n            blockManager.isNeededReconstruction(block, num) :\n            blockManager.isNeededReconstructionForMaintenance(block, num);\n        if (neededReconstruction) {\n          if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n              blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n              blockManager.isPopulatingReplQueues()) {\n            // Process these blocks only when active NN is out of safe mode.\n            blockManager.neededReconstruction.add(block,\n                liveReplicas, num.readOnlyReplicas(),\n                num.outOfServiceReplicas(),\n                blockManager.getExpectedRedundancyNum(block));\n          }\n        }\n\n        // Even if the block is without sufficient redundancy,\n        // it doesn\u0027t block decommission if has sufficient redundancy\n        if (isSufficient(block, bc, num, isDecommission)) {\n          if (pruneReliableBlocks) {\n            it.remove();\n          }\n          continue;\n        }\n\n        // We\u0027ve found a block without sufficient redundancy.\n        if (insufficientList !\u003d null) {\n          insufficientList.add(block);\n        }\n        // Log if this is our first time through\n        if (firstReplicationLog) {\n          logBlockReplicationInfo(block, bc, datanode, num,\n              blockManager.blocksMap.getStorages(block));\n          firstReplicationLog \u003d false;\n        }\n        // Update various counts\n        lowRedundancyBlocks++;\n        if (bc.isUnderConstruction()) {\n          lowRedundancyInOpenFiles++;\n        }\n        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.outOfServiceReplicas() \u003e 0)) {\n          outOfServiceOnlyReplicas++;\n        }\n      }\n\n      datanode.getLeavingServiceStatus().set(lowRedundancyBlocks,\n          outOfServiceOnlyReplicas, lowRedundancyInOpenFiles);\n    }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
          "extendedDetails": {}
        }
      ]
    },
    "332a61fd74fd2a9874319232c583ab5d2c53ff03": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10987. Make Decommission less expensive when lot of blocks present. Contributed by Brahma Reddy Battula.\n",
      "commitDate": "13/10/16 11:52 AM",
      "commitName": "332a61fd74fd2a9874319232c583ab5d2c53ff03",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "06/09/16 10:38 AM",
      "commitNameOld": "d37dc5d1b8e022a7085118a2e7066623483c293f",
      "commitAuthorOld": "Chris Douglas",
      "daysBetweenCommits": 37.05,
      "commitsBetweenForRepo": 251,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,98 @@\n     private void processBlocksForDecomInternal(\n         final DatanodeDescriptor datanode,\n         final Iterator\u003cBlockInfo\u003e it,\n         final List\u003cBlockInfo\u003e insufficientList,\n         boolean pruneReliableBlocks) {\n       boolean firstReplicationLog \u003d true;\n       int lowRedundancyBlocks \u003d 0;\n       int decommissionOnlyReplicas \u003d 0;\n       int lowRedundancyInOpenFiles \u003d 0;\n       while (it.hasNext()) {\n+        if (insufficientList \u003d\u003d null\n+            \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n+          // During fullscan insufficientlyReplicated will NOT be null, iterator\n+          // will be DN\u0027s iterator. So should not yield lock, otherwise\n+          // ConcurrentModificationException could occur.\n+          // Once the fullscan done, iterator will be a copy. So can yield the\n+          // lock.\n+          // Yielding is required in case of block number is greater than the\n+          // configured per-iteration-limit.\n+          namesystem.writeUnlock();\n+          try {\n+            LOG.debug(\"Yielded lock during decommission check\");\n+            Thread.sleep(0, 500);\n+          } catch (InterruptedException ignored) {\n+            return;\n+          }\n+          // reset\n+          numBlocksCheckedPerLock \u003d 0;\n+          namesystem.writeLock();\n+        }\n         numBlocksChecked++;\n+        numBlocksCheckedPerLock++;\n         final BlockInfo block \u003d it.next();\n         // Remove the block from the list if it\u0027s no longer in the block map,\n         // e.g. the containing file has been deleted\n         if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n           LOG.trace(\"Removing unknown block {}\", block);\n           it.remove();\n           continue;\n         }\n \n         long bcId \u003d block.getBlockCollectionId();\n         if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n           // Orphan block, will be invalidated eventually. Skip.\n           continue;\n         }\n \n         final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n         final NumberReplicas num \u003d blockManager.countNodes(block);\n         final int liveReplicas \u003d num.liveReplicas();\n \n         // Schedule low redundancy blocks for reconstruction if not already\n         // pending\n         if (blockManager.isNeededReconstruction(block, liveReplicas)) {\n           if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n               blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n               blockManager.isPopulatingReplQueues()) {\n             // Process these blocks only when active NN is out of safe mode.\n             blockManager.neededReconstruction.add(block,\n                 liveReplicas, num.readOnlyReplicas(),\n                 num.decommissionedAndDecommissioning(),\n                 blockManager.getExpectedRedundancyNum(block));\n           }\n         }\n \n         // Even if the block is without sufficient redundancy,\n         // it doesn\u0027t block decommission if has sufficient redundancy\n         if (isSufficient(block, bc, num)) {\n           if (pruneReliableBlocks) {\n             it.remove();\n           }\n           continue;\n         }\n \n         // We\u0027ve found a block without sufficient redundancy.\n         if (insufficientList !\u003d null) {\n           insufficientList.add(block);\n         }\n         // Log if this is our first time through\n         if (firstReplicationLog) {\n           logBlockReplicationInfo(block, bc, datanode, num,\n               blockManager.blocksMap.getStorages(block));\n           firstReplicationLog \u003d false;\n         }\n         // Update various counts\n         lowRedundancyBlocks++;\n         if (bc.isUnderConstruction()) {\n           lowRedundancyInOpenFiles++;\n         }\n         if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.decommissionedAndDecommissioning() \u003e 0)) {\n           decommissionOnlyReplicas++;\n         }\n       }\n \n       datanode.decommissioningStatus.set(lowRedundancyBlocks,\n           decommissionOnlyReplicas,\n           lowRedundancyInOpenFiles);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processBlocksForDecomInternal(\n        final DatanodeDescriptor datanode,\n        final Iterator\u003cBlockInfo\u003e it,\n        final List\u003cBlockInfo\u003e insufficientList,\n        boolean pruneReliableBlocks) {\n      boolean firstReplicationLog \u003d true;\n      int lowRedundancyBlocks \u003d 0;\n      int decommissionOnlyReplicas \u003d 0;\n      int lowRedundancyInOpenFiles \u003d 0;\n      while (it.hasNext()) {\n        if (insufficientList \u003d\u003d null\n            \u0026\u0026 numBlocksCheckedPerLock \u003e\u003d numBlocksPerCheck) {\n          // During fullscan insufficientlyReplicated will NOT be null, iterator\n          // will be DN\u0027s iterator. So should not yield lock, otherwise\n          // ConcurrentModificationException could occur.\n          // Once the fullscan done, iterator will be a copy. So can yield the\n          // lock.\n          // Yielding is required in case of block number is greater than the\n          // configured per-iteration-limit.\n          namesystem.writeUnlock();\n          try {\n            LOG.debug(\"Yielded lock during decommission check\");\n            Thread.sleep(0, 500);\n          } catch (InterruptedException ignored) {\n            return;\n          }\n          // reset\n          numBlocksCheckedPerLock \u003d 0;\n          namesystem.writeLock();\n        }\n        numBlocksChecked++;\n        numBlocksCheckedPerLock++;\n        final BlockInfo block \u003d it.next();\n        // Remove the block from the list if it\u0027s no longer in the block map,\n        // e.g. the containing file has been deleted\n        if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n          LOG.trace(\"Removing unknown block {}\", block);\n          it.remove();\n          continue;\n        }\n\n        long bcId \u003d block.getBlockCollectionId();\n        if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n          // Orphan block, will be invalidated eventually. Skip.\n          continue;\n        }\n\n        final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n        final NumberReplicas num \u003d blockManager.countNodes(block);\n        final int liveReplicas \u003d num.liveReplicas();\n\n        // Schedule low redundancy blocks for reconstruction if not already\n        // pending\n        if (blockManager.isNeededReconstruction(block, liveReplicas)) {\n          if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n              blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n              blockManager.isPopulatingReplQueues()) {\n            // Process these blocks only when active NN is out of safe mode.\n            blockManager.neededReconstruction.add(block,\n                liveReplicas, num.readOnlyReplicas(),\n                num.decommissionedAndDecommissioning(),\n                blockManager.getExpectedRedundancyNum(block));\n          }\n        }\n\n        // Even if the block is without sufficient redundancy,\n        // it doesn\u0027t block decommission if has sufficient redundancy\n        if (isSufficient(block, bc, num)) {\n          if (pruneReliableBlocks) {\n            it.remove();\n          }\n          continue;\n        }\n\n        // We\u0027ve found a block without sufficient redundancy.\n        if (insufficientList !\u003d null) {\n          insufficientList.add(block);\n        }\n        // Log if this is our first time through\n        if (firstReplicationLog) {\n          logBlockReplicationInfo(block, bc, datanode, num,\n              blockManager.blocksMap.getStorages(block));\n          firstReplicationLog \u003d false;\n        }\n        // Update various counts\n        lowRedundancyBlocks++;\n        if (bc.isUnderConstruction()) {\n          lowRedundancyInOpenFiles++;\n        }\n        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.decommissionedAndDecommissioning() \u003e 0)) {\n          decommissionOnlyReplicas++;\n        }\n      }\n\n      datanode.decommissioningStatus.set(lowRedundancyBlocks,\n          decommissionOnlyReplicas,\n          lowRedundancyInOpenFiles);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
      "extendedDetails": {}
    },
    "8c84a2a93c22a93b4ff46dd917f6efb995675fbd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10236. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-3]. Contributed by Rakesh R.\n",
      "commitDate": "26/05/16 4:50 PM",
      "commitName": "8c84a2a93c22a93b4ff46dd917f6efb995675fbd",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "25/04/16 10:01 PM",
      "commitNameOld": "5865fe2bf01284993572ea60b3ec3bf8b4492818",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 30.78,
      "commitsBetweenForRepo": 218,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,77 @@\n     private void processBlocksForDecomInternal(\n         final DatanodeDescriptor datanode,\n         final Iterator\u003cBlockInfo\u003e it,\n         final List\u003cBlockInfo\u003e insufficientList,\n         boolean pruneReliableBlocks) {\n       boolean firstReplicationLog \u003d true;\n       int lowRedundancyBlocks \u003d 0;\n       int decommissionOnlyReplicas \u003d 0;\n       int lowRedundancyInOpenFiles \u003d 0;\n       while (it.hasNext()) {\n         numBlocksChecked++;\n         final BlockInfo block \u003d it.next();\n         // Remove the block from the list if it\u0027s no longer in the block map,\n         // e.g. the containing file has been deleted\n         if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n           LOG.trace(\"Removing unknown block {}\", block);\n           it.remove();\n           continue;\n         }\n \n         long bcId \u003d block.getBlockCollectionId();\n         if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n           // Orphan block, will be invalidated eventually. Skip.\n           continue;\n         }\n \n         final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n         final NumberReplicas num \u003d blockManager.countNodes(block);\n         final int liveReplicas \u003d num.liveReplicas();\n \n         // Schedule low redundancy blocks for reconstruction if not already\n         // pending\n         if (blockManager.isNeededReconstruction(block, liveReplicas)) {\n           if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n               blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n               blockManager.isPopulatingReplQueues()) {\n             // Process these blocks only when active NN is out of safe mode.\n             blockManager.neededReconstruction.add(block,\n                 liveReplicas, num.readOnlyReplicas(),\n                 num.decommissionedAndDecommissioning(),\n-                blockManager.getExpectedReplicaNum(block));\n+                blockManager.getExpectedRedundancyNum(block));\n           }\n         }\n \n         // Even if the block is without sufficient redundancy,\n         // it doesn\u0027t block decommission if has sufficient redundancy\n         if (isSufficient(block, bc, num)) {\n           if (pruneReliableBlocks) {\n             it.remove();\n           }\n           continue;\n         }\n \n         // We\u0027ve found a block without sufficient redundancy.\n         if (insufficientList !\u003d null) {\n           insufficientList.add(block);\n         }\n         // Log if this is our first time through\n         if (firstReplicationLog) {\n           logBlockReplicationInfo(block, bc, datanode, num,\n               blockManager.blocksMap.getStorages(block));\n           firstReplicationLog \u003d false;\n         }\n         // Update various counts\n         lowRedundancyBlocks++;\n         if (bc.isUnderConstruction()) {\n           lowRedundancyInOpenFiles++;\n         }\n         if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.decommissionedAndDecommissioning() \u003e 0)) {\n           decommissionOnlyReplicas++;\n         }\n       }\n \n       datanode.decommissioningStatus.set(lowRedundancyBlocks,\n           decommissionOnlyReplicas,\n           lowRedundancyInOpenFiles);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processBlocksForDecomInternal(\n        final DatanodeDescriptor datanode,\n        final Iterator\u003cBlockInfo\u003e it,\n        final List\u003cBlockInfo\u003e insufficientList,\n        boolean pruneReliableBlocks) {\n      boolean firstReplicationLog \u003d true;\n      int lowRedundancyBlocks \u003d 0;\n      int decommissionOnlyReplicas \u003d 0;\n      int lowRedundancyInOpenFiles \u003d 0;\n      while (it.hasNext()) {\n        numBlocksChecked++;\n        final BlockInfo block \u003d it.next();\n        // Remove the block from the list if it\u0027s no longer in the block map,\n        // e.g. the containing file has been deleted\n        if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n          LOG.trace(\"Removing unknown block {}\", block);\n          it.remove();\n          continue;\n        }\n\n        long bcId \u003d block.getBlockCollectionId();\n        if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n          // Orphan block, will be invalidated eventually. Skip.\n          continue;\n        }\n\n        final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n        final NumberReplicas num \u003d blockManager.countNodes(block);\n        final int liveReplicas \u003d num.liveReplicas();\n\n        // Schedule low redundancy blocks for reconstruction if not already\n        // pending\n        if (blockManager.isNeededReconstruction(block, liveReplicas)) {\n          if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n              blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n              blockManager.isPopulatingReplQueues()) {\n            // Process these blocks only when active NN is out of safe mode.\n            blockManager.neededReconstruction.add(block,\n                liveReplicas, num.readOnlyReplicas(),\n                num.decommissionedAndDecommissioning(),\n                blockManager.getExpectedRedundancyNum(block));\n          }\n        }\n\n        // Even if the block is without sufficient redundancy,\n        // it doesn\u0027t block decommission if has sufficient redundancy\n        if (isSufficient(block, bc, num)) {\n          if (pruneReliableBlocks) {\n            it.remove();\n          }\n          continue;\n        }\n\n        // We\u0027ve found a block without sufficient redundancy.\n        if (insufficientList !\u003d null) {\n          insufficientList.add(block);\n        }\n        // Log if this is our first time through\n        if (firstReplicationLog) {\n          logBlockReplicationInfo(block, bc, datanode, num,\n              blockManager.blocksMap.getStorages(block));\n          firstReplicationLog \u003d false;\n        }\n        // Update various counts\n        lowRedundancyBlocks++;\n        if (bc.isUnderConstruction()) {\n          lowRedundancyInOpenFiles++;\n        }\n        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.decommissionedAndDecommissioning() \u003e 0)) {\n          decommissionOnlyReplicas++;\n        }\n      }\n\n      datanode.decommissioningStatus.set(lowRedundancyBlocks,\n          decommissionOnlyReplicas,\n          lowRedundancyInOpenFiles);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
      "extendedDetails": {}
    },
    "5865fe2bf01284993572ea60b3ec3bf8b4492818": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9869. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-2]. Contributed by Rakesh R.\n",
      "commitDate": "25/04/16 10:01 PM",
      "commitName": "5865fe2bf01284993572ea60b3ec3bf8b4492818",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "16/03/16 4:53 PM",
      "commitNameOld": "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
      "commitAuthorOld": "Zhe Zhang",
      "daysBetweenCommits": 40.21,
      "commitsBetweenForRepo": 237,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,77 @@\n     private void processBlocksForDecomInternal(\n         final DatanodeDescriptor datanode,\n         final Iterator\u003cBlockInfo\u003e it,\n         final List\u003cBlockInfo\u003e insufficientList,\n         boolean pruneReliableBlocks) {\n       boolean firstReplicationLog \u003d true;\n       int lowRedundancyBlocks \u003d 0;\n       int decommissionOnlyReplicas \u003d 0;\n       int lowRedundancyInOpenFiles \u003d 0;\n       while (it.hasNext()) {\n         numBlocksChecked++;\n         final BlockInfo block \u003d it.next();\n         // Remove the block from the list if it\u0027s no longer in the block map,\n         // e.g. the containing file has been deleted\n         if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n           LOG.trace(\"Removing unknown block {}\", block);\n           it.remove();\n           continue;\n         }\n \n         long bcId \u003d block.getBlockCollectionId();\n         if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n           // Orphan block, will be invalidated eventually. Skip.\n           continue;\n         }\n \n         final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n         final NumberReplicas num \u003d blockManager.countNodes(block);\n         final int liveReplicas \u003d num.liveReplicas();\n \n         // Schedule low redundancy blocks for reconstruction if not already\n         // pending\n         if (blockManager.isNeededReconstruction(block, liveReplicas)) {\n           if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n-              blockManager.pendingReplications.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n+              blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n               blockManager.isPopulatingReplQueues()) {\n             // Process these blocks only when active NN is out of safe mode.\n             blockManager.neededReconstruction.add(block,\n                 liveReplicas, num.readOnlyReplicas(),\n                 num.decommissionedAndDecommissioning(),\n                 blockManager.getExpectedReplicaNum(block));\n           }\n         }\n \n         // Even if the block is without sufficient redundancy,\n         // it doesn\u0027t block decommission if has sufficient redundancy\n         if (isSufficient(block, bc, num)) {\n           if (pruneReliableBlocks) {\n             it.remove();\n           }\n           continue;\n         }\n \n         // We\u0027ve found a block without sufficient redundancy.\n         if (insufficientList !\u003d null) {\n           insufficientList.add(block);\n         }\n         // Log if this is our first time through\n         if (firstReplicationLog) {\n           logBlockReplicationInfo(block, bc, datanode, num,\n               blockManager.blocksMap.getStorages(block));\n           firstReplicationLog \u003d false;\n         }\n         // Update various counts\n         lowRedundancyBlocks++;\n         if (bc.isUnderConstruction()) {\n           lowRedundancyInOpenFiles++;\n         }\n         if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.decommissionedAndDecommissioning() \u003e 0)) {\n           decommissionOnlyReplicas++;\n         }\n       }\n \n       datanode.decommissioningStatus.set(lowRedundancyBlocks,\n           decommissionOnlyReplicas,\n           lowRedundancyInOpenFiles);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processBlocksForDecomInternal(\n        final DatanodeDescriptor datanode,\n        final Iterator\u003cBlockInfo\u003e it,\n        final List\u003cBlockInfo\u003e insufficientList,\n        boolean pruneReliableBlocks) {\n      boolean firstReplicationLog \u003d true;\n      int lowRedundancyBlocks \u003d 0;\n      int decommissionOnlyReplicas \u003d 0;\n      int lowRedundancyInOpenFiles \u003d 0;\n      while (it.hasNext()) {\n        numBlocksChecked++;\n        final BlockInfo block \u003d it.next();\n        // Remove the block from the list if it\u0027s no longer in the block map,\n        // e.g. the containing file has been deleted\n        if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n          LOG.trace(\"Removing unknown block {}\", block);\n          it.remove();\n          continue;\n        }\n\n        long bcId \u003d block.getBlockCollectionId();\n        if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n          // Orphan block, will be invalidated eventually. Skip.\n          continue;\n        }\n\n        final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n        final NumberReplicas num \u003d blockManager.countNodes(block);\n        final int liveReplicas \u003d num.liveReplicas();\n\n        // Schedule low redundancy blocks for reconstruction if not already\n        // pending\n        if (blockManager.isNeededReconstruction(block, liveReplicas)) {\n          if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n              blockManager.pendingReconstruction.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n              blockManager.isPopulatingReplQueues()) {\n            // Process these blocks only when active NN is out of safe mode.\n            blockManager.neededReconstruction.add(block,\n                liveReplicas, num.readOnlyReplicas(),\n                num.decommissionedAndDecommissioning(),\n                blockManager.getExpectedReplicaNum(block));\n          }\n        }\n\n        // Even if the block is without sufficient redundancy,\n        // it doesn\u0027t block decommission if has sufficient redundancy\n        if (isSufficient(block, bc, num)) {\n          if (pruneReliableBlocks) {\n            it.remove();\n          }\n          continue;\n        }\n\n        // We\u0027ve found a block without sufficient redundancy.\n        if (insufficientList !\u003d null) {\n          insufficientList.add(block);\n        }\n        // Log if this is our first time through\n        if (firstReplicationLog) {\n          logBlockReplicationInfo(block, bc, datanode, num,\n              blockManager.blocksMap.getStorages(block));\n          firstReplicationLog \u003d false;\n        }\n        // Update various counts\n        lowRedundancyBlocks++;\n        if (bc.isUnderConstruction()) {\n          lowRedundancyInOpenFiles++;\n        }\n        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.decommissionedAndDecommissioning() \u003e 0)) {\n          decommissionOnlyReplicas++;\n        }\n      }\n\n      datanode.decommissioningStatus.set(lowRedundancyBlocks,\n          decommissionOnlyReplicas,\n          lowRedundancyInOpenFiles);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
      "extendedDetails": {}
    },
    "32d043d9c5f4615058ea4f65a58ba271ba47fcb5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9857. Erasure Coding: Rename replication-based names in BlockManager to more generic [part-1]. Contributed by Rakesh R.\n",
      "commitDate": "16/03/16 4:53 PM",
      "commitName": "32d043d9c5f4615058ea4f65a58ba271ba47fcb5",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "14/03/16 9:54 AM",
      "commitNameOld": "5644137adad30c84e40d2c4719627b3aabc73628",
      "commitAuthorOld": "Chris Nauroth",
      "daysBetweenCommits": 2.29,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,77 @@\n     private void processBlocksForDecomInternal(\n         final DatanodeDescriptor datanode,\n         final Iterator\u003cBlockInfo\u003e it,\n         final List\u003cBlockInfo\u003e insufficientList,\n         boolean pruneReliableBlocks) {\n       boolean firstReplicationLog \u003d true;\n-      int underReplicatedBlocks \u003d 0;\n+      int lowRedundancyBlocks \u003d 0;\n       int decommissionOnlyReplicas \u003d 0;\n-      int underReplicatedInOpenFiles \u003d 0;\n+      int lowRedundancyInOpenFiles \u003d 0;\n       while (it.hasNext()) {\n         numBlocksChecked++;\n         final BlockInfo block \u003d it.next();\n         // Remove the block from the list if it\u0027s no longer in the block map,\n         // e.g. the containing file has been deleted\n         if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n           LOG.trace(\"Removing unknown block {}\", block);\n           it.remove();\n           continue;\n         }\n \n         long bcId \u003d block.getBlockCollectionId();\n         if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n           // Orphan block, will be invalidated eventually. Skip.\n           continue;\n         }\n \n         final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n         final NumberReplicas num \u003d blockManager.countNodes(block);\n         final int liveReplicas \u003d num.liveReplicas();\n \n-        // Schedule under-replicated blocks for replication if not already\n+        // Schedule low redundancy blocks for reconstruction if not already\n         // pending\n-        if (blockManager.isNeededReplication(block, liveReplicas)) {\n-          if (!blockManager.neededReplications.contains(block) \u0026\u0026\n+        if (blockManager.isNeededReconstruction(block, liveReplicas)) {\n+          if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n               blockManager.pendingReplications.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n               blockManager.isPopulatingReplQueues()) {\n             // Process these blocks only when active NN is out of safe mode.\n-            blockManager.neededReplications.add(block,\n+            blockManager.neededReconstruction.add(block,\n                 liveReplicas, num.readOnlyReplicas(),\n                 num.decommissionedAndDecommissioning(),\n                 blockManager.getExpectedReplicaNum(block));\n           }\n         }\n \n-        // Even if the block is under-replicated, \n-        // it doesn\u0027t block decommission if it\u0027s sufficiently replicated\n+        // Even if the block is without sufficient redundancy,\n+        // it doesn\u0027t block decommission if has sufficient redundancy\n         if (isSufficient(block, bc, num)) {\n           if (pruneReliableBlocks) {\n             it.remove();\n           }\n           continue;\n         }\n \n-        // We\u0027ve found an insufficiently replicated block.\n+        // We\u0027ve found a block without sufficient redundancy.\n         if (insufficientList !\u003d null) {\n           insufficientList.add(block);\n         }\n         // Log if this is our first time through\n         if (firstReplicationLog) {\n           logBlockReplicationInfo(block, bc, datanode, num,\n               blockManager.blocksMap.getStorages(block));\n           firstReplicationLog \u003d false;\n         }\n         // Update various counts\n-        underReplicatedBlocks++;\n+        lowRedundancyBlocks++;\n         if (bc.isUnderConstruction()) {\n-          underReplicatedInOpenFiles++;\n+          lowRedundancyInOpenFiles++;\n         }\n         if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.decommissionedAndDecommissioning() \u003e 0)) {\n           decommissionOnlyReplicas++;\n         }\n       }\n \n-      datanode.decommissioningStatus.set(underReplicatedBlocks,\n+      datanode.decommissioningStatus.set(lowRedundancyBlocks,\n           decommissionOnlyReplicas,\n-          underReplicatedInOpenFiles);\n+          lowRedundancyInOpenFiles);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processBlocksForDecomInternal(\n        final DatanodeDescriptor datanode,\n        final Iterator\u003cBlockInfo\u003e it,\n        final List\u003cBlockInfo\u003e insufficientList,\n        boolean pruneReliableBlocks) {\n      boolean firstReplicationLog \u003d true;\n      int lowRedundancyBlocks \u003d 0;\n      int decommissionOnlyReplicas \u003d 0;\n      int lowRedundancyInOpenFiles \u003d 0;\n      while (it.hasNext()) {\n        numBlocksChecked++;\n        final BlockInfo block \u003d it.next();\n        // Remove the block from the list if it\u0027s no longer in the block map,\n        // e.g. the containing file has been deleted\n        if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n          LOG.trace(\"Removing unknown block {}\", block);\n          it.remove();\n          continue;\n        }\n\n        long bcId \u003d block.getBlockCollectionId();\n        if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n          // Orphan block, will be invalidated eventually. Skip.\n          continue;\n        }\n\n        final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n        final NumberReplicas num \u003d blockManager.countNodes(block);\n        final int liveReplicas \u003d num.liveReplicas();\n\n        // Schedule low redundancy blocks for reconstruction if not already\n        // pending\n        if (blockManager.isNeededReconstruction(block, liveReplicas)) {\n          if (!blockManager.neededReconstruction.contains(block) \u0026\u0026\n              blockManager.pendingReplications.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n              blockManager.isPopulatingReplQueues()) {\n            // Process these blocks only when active NN is out of safe mode.\n            blockManager.neededReconstruction.add(block,\n                liveReplicas, num.readOnlyReplicas(),\n                num.decommissionedAndDecommissioning(),\n                blockManager.getExpectedReplicaNum(block));\n          }\n        }\n\n        // Even if the block is without sufficient redundancy,\n        // it doesn\u0027t block decommission if has sufficient redundancy\n        if (isSufficient(block, bc, num)) {\n          if (pruneReliableBlocks) {\n            it.remove();\n          }\n          continue;\n        }\n\n        // We\u0027ve found a block without sufficient redundancy.\n        if (insufficientList !\u003d null) {\n          insufficientList.add(block);\n        }\n        // Log if this is our first time through\n        if (firstReplicationLog) {\n          logBlockReplicationInfo(block, bc, datanode, num,\n              blockManager.blocksMap.getStorages(block));\n          firstReplicationLog \u003d false;\n        }\n        // Update various counts\n        lowRedundancyBlocks++;\n        if (bc.isUnderConstruction()) {\n          lowRedundancyInOpenFiles++;\n        }\n        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.decommissionedAndDecommissioning() \u003e 0)) {\n          decommissionOnlyReplicas++;\n        }\n      }\n\n      datanode.decommissioningStatus.set(lowRedundancyBlocks,\n          decommissionOnlyReplicas,\n          lowRedundancyInOpenFiles);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
      "extendedDetails": {}
    },
    "132478e805ba0f955345217b8ad87c2d17cccb2d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9527. The return type of FSNamesystem.getBlockCollection should be changed to INodeFile.\n",
      "commitDate": "09/12/15 5:55 PM",
      "commitName": "132478e805ba0f955345217b8ad87c2d17cccb2d",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "15/10/15 3:07 AM",
      "commitNameOld": "5411dc559d5f73e4153e76fdff94a26869c17a37",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 55.66,
      "commitsBetweenForRepo": 412,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,77 @@\n     private void processBlocksForDecomInternal(\n         final DatanodeDescriptor datanode,\n         final Iterator\u003cBlockInfo\u003e it,\n         final List\u003cBlockInfo\u003e insufficientList,\n         boolean pruneReliableBlocks) {\n       boolean firstReplicationLog \u003d true;\n       int underReplicatedBlocks \u003d 0;\n       int decommissionOnlyReplicas \u003d 0;\n       int underReplicatedInOpenFiles \u003d 0;\n       while (it.hasNext()) {\n         numBlocksChecked++;\n         final BlockInfo block \u003d it.next();\n         // Remove the block from the list if it\u0027s no longer in the block map,\n         // e.g. the containing file has been deleted\n         if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n           LOG.trace(\"Removing unknown block {}\", block);\n           it.remove();\n           continue;\n         }\n \n         long bcId \u003d block.getBlockCollectionId();\n         if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n           // Orphan block, will be invalidated eventually. Skip.\n           continue;\n         }\n \n-        BlockCollection bc \u003d namesystem.getBlockCollection(bcId);\n+        final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n         final NumberReplicas num \u003d blockManager.countNodes(block);\n         final int liveReplicas \u003d num.liveReplicas();\n \n         // Schedule under-replicated blocks for replication if not already\n         // pending\n         if (blockManager.isNeededReplication(block, liveReplicas)) {\n           if (!blockManager.neededReplications.contains(block) \u0026\u0026\n               blockManager.pendingReplications.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n               blockManager.isPopulatingReplQueues()) {\n             // Process these blocks only when active NN is out of safe mode.\n             blockManager.neededReplications.add(block,\n                 liveReplicas, num.readOnlyReplicas(),\n                 num.decommissionedAndDecommissioning(),\n                 blockManager.getExpectedReplicaNum(block));\n           }\n         }\n \n         // Even if the block is under-replicated, \n         // it doesn\u0027t block decommission if it\u0027s sufficiently replicated\n         if (isSufficient(block, bc, num)) {\n           if (pruneReliableBlocks) {\n             it.remove();\n           }\n           continue;\n         }\n \n         // We\u0027ve found an insufficiently replicated block.\n         if (insufficientList !\u003d null) {\n           insufficientList.add(block);\n         }\n         // Log if this is our first time through\n         if (firstReplicationLog) {\n           logBlockReplicationInfo(block, bc, datanode, num,\n               blockManager.blocksMap.getStorages(block));\n           firstReplicationLog \u003d false;\n         }\n         // Update various counts\n         underReplicatedBlocks++;\n         if (bc.isUnderConstruction()) {\n           underReplicatedInOpenFiles++;\n         }\n         if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.decommissionedAndDecommissioning() \u003e 0)) {\n           decommissionOnlyReplicas++;\n         }\n       }\n \n       datanode.decommissioningStatus.set(underReplicatedBlocks,\n           decommissionOnlyReplicas,\n           underReplicatedInOpenFiles);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processBlocksForDecomInternal(\n        final DatanodeDescriptor datanode,\n        final Iterator\u003cBlockInfo\u003e it,\n        final List\u003cBlockInfo\u003e insufficientList,\n        boolean pruneReliableBlocks) {\n      boolean firstReplicationLog \u003d true;\n      int underReplicatedBlocks \u003d 0;\n      int decommissionOnlyReplicas \u003d 0;\n      int underReplicatedInOpenFiles \u003d 0;\n      while (it.hasNext()) {\n        numBlocksChecked++;\n        final BlockInfo block \u003d it.next();\n        // Remove the block from the list if it\u0027s no longer in the block map,\n        // e.g. the containing file has been deleted\n        if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n          LOG.trace(\"Removing unknown block {}\", block);\n          it.remove();\n          continue;\n        }\n\n        long bcId \u003d block.getBlockCollectionId();\n        if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n          // Orphan block, will be invalidated eventually. Skip.\n          continue;\n        }\n\n        final BlockCollection bc \u003d blockManager.getBlockCollection(block);\n        final NumberReplicas num \u003d blockManager.countNodes(block);\n        final int liveReplicas \u003d num.liveReplicas();\n\n        // Schedule under-replicated blocks for replication if not already\n        // pending\n        if (blockManager.isNeededReplication(block, liveReplicas)) {\n          if (!blockManager.neededReplications.contains(block) \u0026\u0026\n              blockManager.pendingReplications.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n              blockManager.isPopulatingReplQueues()) {\n            // Process these blocks only when active NN is out of safe mode.\n            blockManager.neededReplications.add(block,\n                liveReplicas, num.readOnlyReplicas(),\n                num.decommissionedAndDecommissioning(),\n                blockManager.getExpectedReplicaNum(block));\n          }\n        }\n\n        // Even if the block is under-replicated, \n        // it doesn\u0027t block decommission if it\u0027s sufficiently replicated\n        if (isSufficient(block, bc, num)) {\n          if (pruneReliableBlocks) {\n            it.remove();\n          }\n          continue;\n        }\n\n        // We\u0027ve found an insufficiently replicated block.\n        if (insufficientList !\u003d null) {\n          insufficientList.add(block);\n        }\n        // Log if this is our first time through\n        if (firstReplicationLog) {\n          logBlockReplicationInfo(block, bc, datanode, num,\n              blockManager.blocksMap.getStorages(block));\n          firstReplicationLog \u003d false;\n        }\n        // Update various counts\n        underReplicatedBlocks++;\n        if (bc.isUnderConstruction()) {\n          underReplicatedInOpenFiles++;\n        }\n        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.decommissionedAndDecommissioning() \u003e 0)) {\n          decommissionOnlyReplicas++;\n        }\n      }\n\n      datanode.decommissioningStatus.set(underReplicatedBlocks,\n          decommissionOnlyReplicas,\n          underReplicatedInOpenFiles);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
      "extendedDetails": {}
    },
    "5411dc559d5f73e4153e76fdff94a26869c17a37": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9205. Do not schedule corrupt blocks for replication.  (szetszwo)\n",
      "commitDate": "15/10/15 3:07 AM",
      "commitName": "5411dc559d5f73e4153e76fdff94a26869c17a37",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "14/10/15 4:17 PM",
      "commitNameOld": "be7a0add8b6561d3c566237cc0370b06e7f32bb4",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.45,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,77 @@\n     private void processBlocksForDecomInternal(\n         final DatanodeDescriptor datanode,\n         final Iterator\u003cBlockInfo\u003e it,\n         final List\u003cBlockInfo\u003e insufficientList,\n         boolean pruneReliableBlocks) {\n       boolean firstReplicationLog \u003d true;\n       int underReplicatedBlocks \u003d 0;\n       int decommissionOnlyReplicas \u003d 0;\n       int underReplicatedInOpenFiles \u003d 0;\n       while (it.hasNext()) {\n         numBlocksChecked++;\n         final BlockInfo block \u003d it.next();\n         // Remove the block from the list if it\u0027s no longer in the block map,\n         // e.g. the containing file has been deleted\n         if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n           LOG.trace(\"Removing unknown block {}\", block);\n           it.remove();\n           continue;\n         }\n \n         long bcId \u003d block.getBlockCollectionId();\n         if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n           // Orphan block, will be invalidated eventually. Skip.\n           continue;\n         }\n \n         BlockCollection bc \u003d namesystem.getBlockCollection(bcId);\n         final NumberReplicas num \u003d blockManager.countNodes(block);\n         final int liveReplicas \u003d num.liveReplicas();\n \n         // Schedule under-replicated blocks for replication if not already\n         // pending\n         if (blockManager.isNeededReplication(block, liveReplicas)) {\n           if (!blockManager.neededReplications.contains(block) \u0026\u0026\n               blockManager.pendingReplications.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n               blockManager.isPopulatingReplQueues()) {\n             // Process these blocks only when active NN is out of safe mode.\n             blockManager.neededReplications.add(block,\n-                liveReplicas,\n+                liveReplicas, num.readOnlyReplicas(),\n                 num.decommissionedAndDecommissioning(),\n                 blockManager.getExpectedReplicaNum(block));\n           }\n         }\n \n         // Even if the block is under-replicated, \n         // it doesn\u0027t block decommission if it\u0027s sufficiently replicated\n         if (isSufficient(block, bc, num)) {\n           if (pruneReliableBlocks) {\n             it.remove();\n           }\n           continue;\n         }\n \n         // We\u0027ve found an insufficiently replicated block.\n         if (insufficientList !\u003d null) {\n           insufficientList.add(block);\n         }\n         // Log if this is our first time through\n         if (firstReplicationLog) {\n           logBlockReplicationInfo(block, bc, datanode, num,\n               blockManager.blocksMap.getStorages(block));\n           firstReplicationLog \u003d false;\n         }\n         // Update various counts\n         underReplicatedBlocks++;\n         if (bc.isUnderConstruction()) {\n           underReplicatedInOpenFiles++;\n         }\n         if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.decommissionedAndDecommissioning() \u003e 0)) {\n           decommissionOnlyReplicas++;\n         }\n       }\n \n       datanode.decommissioningStatus.set(underReplicatedBlocks,\n           decommissionOnlyReplicas,\n           underReplicatedInOpenFiles);\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private void processBlocksForDecomInternal(\n        final DatanodeDescriptor datanode,\n        final Iterator\u003cBlockInfo\u003e it,\n        final List\u003cBlockInfo\u003e insufficientList,\n        boolean pruneReliableBlocks) {\n      boolean firstReplicationLog \u003d true;\n      int underReplicatedBlocks \u003d 0;\n      int decommissionOnlyReplicas \u003d 0;\n      int underReplicatedInOpenFiles \u003d 0;\n      while (it.hasNext()) {\n        numBlocksChecked++;\n        final BlockInfo block \u003d it.next();\n        // Remove the block from the list if it\u0027s no longer in the block map,\n        // e.g. the containing file has been deleted\n        if (blockManager.blocksMap.getStoredBlock(block) \u003d\u003d null) {\n          LOG.trace(\"Removing unknown block {}\", block);\n          it.remove();\n          continue;\n        }\n\n        long bcId \u003d block.getBlockCollectionId();\n        if (bcId \u003d\u003d INodeId.INVALID_INODE_ID) {\n          // Orphan block, will be invalidated eventually. Skip.\n          continue;\n        }\n\n        BlockCollection bc \u003d namesystem.getBlockCollection(bcId);\n        final NumberReplicas num \u003d blockManager.countNodes(block);\n        final int liveReplicas \u003d num.liveReplicas();\n\n        // Schedule under-replicated blocks for replication if not already\n        // pending\n        if (blockManager.isNeededReplication(block, liveReplicas)) {\n          if (!blockManager.neededReplications.contains(block) \u0026\u0026\n              blockManager.pendingReplications.getNumReplicas(block) \u003d\u003d 0 \u0026\u0026\n              blockManager.isPopulatingReplQueues()) {\n            // Process these blocks only when active NN is out of safe mode.\n            blockManager.neededReplications.add(block,\n                liveReplicas, num.readOnlyReplicas(),\n                num.decommissionedAndDecommissioning(),\n                blockManager.getExpectedReplicaNum(block));\n          }\n        }\n\n        // Even if the block is under-replicated, \n        // it doesn\u0027t block decommission if it\u0027s sufficiently replicated\n        if (isSufficient(block, bc, num)) {\n          if (pruneReliableBlocks) {\n            it.remove();\n          }\n          continue;\n        }\n\n        // We\u0027ve found an insufficiently replicated block.\n        if (insufficientList !\u003d null) {\n          insufficientList.add(block);\n        }\n        // Log if this is our first time through\n        if (firstReplicationLog) {\n          logBlockReplicationInfo(block, bc, datanode, num,\n              blockManager.blocksMap.getStorages(block));\n          firstReplicationLog \u003d false;\n        }\n        // Update various counts\n        underReplicatedBlocks++;\n        if (bc.isUnderConstruction()) {\n          underReplicatedInOpenFiles++;\n        }\n        if ((liveReplicas \u003d\u003d 0) \u0026\u0026 (num.decommissionedAndDecommissioning() \u003e 0)) {\n          decommissionOnlyReplicas++;\n        }\n      }\n\n      datanode.decommissioningStatus.set(underReplicatedBlocks,\n          decommissionOnlyReplicas,\n          underReplicatedInOpenFiles);\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DecommissionManager.java",
      "extendedDetails": {}
    }
  }
}