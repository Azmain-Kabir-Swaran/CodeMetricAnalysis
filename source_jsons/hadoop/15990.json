{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "Server.java",
  "functionName": "loadServices",
  "functionId": "loadServices",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/lib/server/Server.java",
  "functionStartLine": 542,
  "functionEndLine": 567,
  "numCommitsSeen": 12,
  "timeTaken": 613,
  "changeHistory": [
    "3334306512b5dc932814fded31a89ba1ee97cd9f"
  ],
  "changeHistoryShort": {
    "3334306512b5dc932814fded31a89ba1ee97cd9f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "3334306512b5dc932814fded31a89ba1ee97cd9f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2178. Contributing Hoop to HDFS, replacement for HDFS proxy with read/write capabilities. (tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1212060 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "08/12/11 11:25 AM",
      "commitName": "3334306512b5dc932814fded31a89ba1ee97cd9f",
      "commitAuthor": "Alejandro Abdelnur",
      "diff": "@@ -0,0 +1,26 @@\n+  protected List\u003cService\u003e loadServices() throws ServerException {\n+    try {\n+      Map\u003cClass, Service\u003e map \u003d new LinkedHashMap\u003cClass, Service\u003e();\n+      Class[] classes \u003d getConfig().getClasses(getPrefixedName(CONF_SERVICES));\n+      Class[] classesExt \u003d getConfig().getClasses(getPrefixedName(CONF_SERVICES_EXT));\n+      List\u003cService\u003e list \u003d new ArrayList\u003cService\u003e();\n+      loadServices(classes, list);\n+      loadServices(classesExt, list);\n+\n+      //removing duplicate services, strategy: last one wins\n+      for (Service service : list) {\n+        if (map.containsKey(service.getInterface())) {\n+          log.debug(\"Replacing service [{}] implementation [{}]\", service.getInterface(),\n+                    service.getClass());\n+        }\n+        map.put(service.getInterface(), service);\n+      }\n+      list \u003d new ArrayList\u003cService\u003e();\n+      for (Map.Entry\u003cClass, Service\u003e entry : map.entrySet()) {\n+        list.add(entry.getValue());\n+      }\n+      return list;\n+    } catch (RuntimeException ex) {\n+      throw new ServerException(ServerException.ERROR.S08, ex.getMessage(), ex);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  protected List\u003cService\u003e loadServices() throws ServerException {\n    try {\n      Map\u003cClass, Service\u003e map \u003d new LinkedHashMap\u003cClass, Service\u003e();\n      Class[] classes \u003d getConfig().getClasses(getPrefixedName(CONF_SERVICES));\n      Class[] classesExt \u003d getConfig().getClasses(getPrefixedName(CONF_SERVICES_EXT));\n      List\u003cService\u003e list \u003d new ArrayList\u003cService\u003e();\n      loadServices(classes, list);\n      loadServices(classesExt, list);\n\n      //removing duplicate services, strategy: last one wins\n      for (Service service : list) {\n        if (map.containsKey(service.getInterface())) {\n          log.debug(\"Replacing service [{}] implementation [{}]\", service.getInterface(),\n                    service.getClass());\n        }\n        map.put(service.getInterface(), service);\n      }\n      list \u003d new ArrayList\u003cService\u003e();\n      for (Map.Entry\u003cClass, Service\u003e entry : map.entrySet()) {\n        list.add(entry.getValue());\n      }\n      return list;\n    } catch (RuntimeException ex) {\n      throw new ServerException(ServerException.ERROR.S08, ex.getMessage(), ex);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-httpfs/src/main/java/org/apache/hadoop/lib/server/Server.java"
    }
  }
}