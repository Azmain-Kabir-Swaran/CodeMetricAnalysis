{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NameNodeRpcServer.java",
  "functionName": "errorReport",
  "functionId": "errorReport___nodeReg-DatanodeRegistration__errorCode-int__msg-String",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
  "functionStartLine": 1693,
  "functionEndLine": 1713,
  "numCommitsSeen": 324,
  "timeTaken": 9201,
  "changeHistory": [
    "db334bb8625da97c7e518cbcf477530c7ba7001e",
    "be7dd8333a7e56e732171db0781786987de03195",
    "b0632df93ae5d00180b21983d960d50a45f8fb7a",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "7fac946ac983e31613fd62836c8ac9c4a579210a",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "db334bb8625da97c7e518cbcf477530c7ba7001e": "Ybodychange",
    "be7dd8333a7e56e732171db0781786987de03195": "Ybodychange",
    "b0632df93ae5d00180b21983d960d50a45f8fb7a": "Ymovefromfile",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "7fac946ac983e31613fd62836c8ac9c4a579210a": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "db334bb8625da97c7e518cbcf477530c7ba7001e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3443. Fix NPE when namenode transition to active during startup by adding checkNNStartup() in NameNodeRpcServer.  Contributed by Vinayakumar B\n",
      "commitDate": "21/01/15 11:33 AM",
      "commitName": "db334bb8625da97c7e518cbcf477530c7ba7001e",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "12/01/15 10:50 PM",
      "commitNameOld": "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
      "commitAuthorOld": "Plamen Jeliazkov",
      "daysBetweenCommits": 8.53,
      "commitsBetweenForRepo": 59,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,20 +1,21 @@\n   public void errorReport(DatanodeRegistration nodeReg,\n                           int errorCode, String msg) throws IOException { \n+    checkNNStartup();\n     String dnName \u003d \n        (nodeReg \u003d\u003d null) ? \"Unknown DataNode\" : nodeReg.toString();\n \n     if (errorCode \u003d\u003d DatanodeProtocol.NOTIFY) {\n       LOG.info(\"Error report from \" + dnName + \": \" + msg);\n       return;\n     }\n     verifyRequest(nodeReg);\n \n     if (errorCode \u003d\u003d DatanodeProtocol.DISK_ERROR) {\n       LOG.warn(\"Disk error on \" + dnName + \": \" + msg);\n     } else if (errorCode \u003d\u003d DatanodeProtocol.FATAL_DISK_ERROR) {\n       LOG.warn(\"Fatal disk error on \" + dnName + \": \" + msg);\n       namesystem.getBlockManager().getDatanodeManager().removeDatanode(nodeReg);            \n     } else {\n       LOG.info(\"Error report from \" + dnName + \": \" + msg);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void errorReport(DatanodeRegistration nodeReg,\n                          int errorCode, String msg) throws IOException { \n    checkNNStartup();\n    String dnName \u003d \n       (nodeReg \u003d\u003d null) ? \"Unknown DataNode\" : nodeReg.toString();\n\n    if (errorCode \u003d\u003d DatanodeProtocol.NOTIFY) {\n      LOG.info(\"Error report from \" + dnName + \": \" + msg);\n      return;\n    }\n    verifyRequest(nodeReg);\n\n    if (errorCode \u003d\u003d DatanodeProtocol.DISK_ERROR) {\n      LOG.warn(\"Disk error on \" + dnName + \": \" + msg);\n    } else if (errorCode \u003d\u003d DatanodeProtocol.FATAL_DISK_ERROR) {\n      LOG.warn(\"Fatal disk error on \" + dnName + \": \" + msg);\n      namesystem.getBlockManager().getDatanodeManager().removeDatanode(nodeReg);            \n    } else {\n      LOG.info(\"Error report from \" + dnName + \": \" + msg);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
      "extendedDetails": {}
    },
    "be7dd8333a7e56e732171db0781786987de03195": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3144. Refactor DatanodeID#getName by use. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1308205 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "01/04/12 3:12 PM",
      "commitName": "be7dd8333a7e56e732171db0781786987de03195",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "22/03/12 11:29 PM",
      "commitNameOld": "b795c65f4929330972c07ec2d5d7ce987c5c2316",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 9.65,
      "commitsBetweenForRepo": 62,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,20 @@\n   public void errorReport(DatanodeRegistration nodeReg,\n                           int errorCode, String msg) throws IOException { \n-    String dnName \u003d (nodeReg \u003d\u003d null ? \"unknown DataNode\" : nodeReg.getName());\n+    String dnName \u003d \n+       (nodeReg \u003d\u003d null) ? \"Unknown DataNode\" : nodeReg.toString();\n \n     if (errorCode \u003d\u003d DatanodeProtocol.NOTIFY) {\n       LOG.info(\"Error report from \" + dnName + \": \" + msg);\n       return;\n     }\n     verifyRequest(nodeReg);\n \n     if (errorCode \u003d\u003d DatanodeProtocol.DISK_ERROR) {\n       LOG.warn(\"Disk error on \" + dnName + \": \" + msg);\n     } else if (errorCode \u003d\u003d DatanodeProtocol.FATAL_DISK_ERROR) {\n       LOG.warn(\"Fatal disk error on \" + dnName + \": \" + msg);\n       namesystem.getBlockManager().getDatanodeManager().removeDatanode(nodeReg);            \n     } else {\n       LOG.info(\"Error report from \" + dnName + \": \" + msg);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void errorReport(DatanodeRegistration nodeReg,\n                          int errorCode, String msg) throws IOException { \n    String dnName \u003d \n       (nodeReg \u003d\u003d null) ? \"Unknown DataNode\" : nodeReg.toString();\n\n    if (errorCode \u003d\u003d DatanodeProtocol.NOTIFY) {\n      LOG.info(\"Error report from \" + dnName + \": \" + msg);\n      return;\n    }\n    verifyRequest(nodeReg);\n\n    if (errorCode \u003d\u003d DatanodeProtocol.DISK_ERROR) {\n      LOG.warn(\"Disk error on \" + dnName + \": \" + msg);\n    } else if (errorCode \u003d\u003d DatanodeProtocol.FATAL_DISK_ERROR) {\n      LOG.warn(\"Fatal disk error on \" + dnName + \": \" + msg);\n      namesystem.getBlockManager().getDatanodeManager().removeDatanode(nodeReg);            \n    } else {\n      LOG.info(\"Error report from \" + dnName + \": \" + msg);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
      "extendedDetails": {}
    },
    "b0632df93ae5d00180b21983d960d50a45f8fb7a": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-2197. Refactor RPC call implementations out of NameNode class. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1165463 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "05/09/11 5:41 PM",
      "commitName": "b0632df93ae5d00180b21983d960d50a45f8fb7a",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "05/09/11 5:34 PM",
      "commitNameOld": "d1438b501dae9efc7aa84de35a57e1b8e6f5645e",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void errorReport(DatanodeRegistration nodeReg,\n                          int errorCode, String msg) throws IOException { \n    String dnName \u003d (nodeReg \u003d\u003d null ? \"unknown DataNode\" : nodeReg.getName());\n\n    if (errorCode \u003d\u003d DatanodeProtocol.NOTIFY) {\n      LOG.info(\"Error report from \" + dnName + \": \" + msg);\n      return;\n    }\n    verifyRequest(nodeReg);\n\n    if (errorCode \u003d\u003d DatanodeProtocol.DISK_ERROR) {\n      LOG.warn(\"Disk error on \" + dnName + \": \" + msg);\n    } else if (errorCode \u003d\u003d DatanodeProtocol.FATAL_DISK_ERROR) {\n      LOG.warn(\"Fatal disk error on \" + dnName + \": \" + msg);\n      namesystem.getBlockManager().getDatanodeManager().removeDatanode(nodeReg);            \n    } else {\n      LOG.info(\"Error report from \" + dnName + \": \" + msg);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java",
        "oldMethodName": "errorReport",
        "newMethodName": "errorReport"
      }
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void errorReport(DatanodeRegistration nodeReg,\n                          int errorCode, String msg) throws IOException { \n    String dnName \u003d (nodeReg \u003d\u003d null ? \"unknown DataNode\" : nodeReg.getName());\n\n    if (errorCode \u003d\u003d DatanodeProtocol.NOTIFY) {\n      LOG.info(\"Error report from \" + dnName + \": \" + msg);\n      return;\n    }\n    verifyRequest(nodeReg);\n\n    if (errorCode \u003d\u003d DatanodeProtocol.DISK_ERROR) {\n      LOG.warn(\"Disk error on \" + dnName + \": \" + msg);\n    } else if (errorCode \u003d\u003d DatanodeProtocol.FATAL_DISK_ERROR) {\n      LOG.warn(\"Fatal disk error on \" + dnName + \": \" + msg);\n      namesystem.getBlockManager().getDatanodeManager().removeDatanode(nodeReg);            \n    } else {\n      LOG.info(\"Error report from \" + dnName + \": \" + msg);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public void errorReport(DatanodeRegistration nodeReg,\n                          int errorCode, String msg) throws IOException { \n    String dnName \u003d (nodeReg \u003d\u003d null ? \"unknown DataNode\" : nodeReg.getName());\n\n    if (errorCode \u003d\u003d DatanodeProtocol.NOTIFY) {\n      LOG.info(\"Error report from \" + dnName + \": \" + msg);\n      return;\n    }\n    verifyRequest(nodeReg);\n\n    if (errorCode \u003d\u003d DatanodeProtocol.DISK_ERROR) {\n      LOG.warn(\"Disk error on \" + dnName + \": \" + msg);\n    } else if (errorCode \u003d\u003d DatanodeProtocol.FATAL_DISK_ERROR) {\n      LOG.warn(\"Fatal disk error on \" + dnName + \": \" + msg);\n      namesystem.getBlockManager().getDatanodeManager().removeDatanode(nodeReg);            \n    } else {\n      LOG.info(\"Error report from \" + dnName + \": \" + msg);\n    }\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java"
      }
    },
    "7fac946ac983e31613fd62836c8ac9c4a579210a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2108. Move datanode heartbeat handling from namenode package to blockmanagement package.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1154042 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/08/11 3:55 PM",
      "commitName": "7fac946ac983e31613fd62836c8ac9c4a579210a",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "01/08/11 6:57 AM",
      "commitNameOld": "d68e38b78d9687987c4de2046ce9aa0016685e98",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 3.37,
      "commitsBetweenForRepo": 18,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n   public void errorReport(DatanodeRegistration nodeReg,\n                           int errorCode, String msg) throws IOException { \n     String dnName \u003d (nodeReg \u003d\u003d null ? \"unknown DataNode\" : nodeReg.getName());\n \n     if (errorCode \u003d\u003d DatanodeProtocol.NOTIFY) {\n       LOG.info(\"Error report from \" + dnName + \": \" + msg);\n       return;\n     }\n     verifyRequest(nodeReg);\n \n     if (errorCode \u003d\u003d DatanodeProtocol.DISK_ERROR) {\n       LOG.warn(\"Disk error on \" + dnName + \": \" + msg);\n     } else if (errorCode \u003d\u003d DatanodeProtocol.FATAL_DISK_ERROR) {\n       LOG.warn(\"Fatal disk error on \" + dnName + \": \" + msg);\n-      namesystem.removeDatanode(nodeReg);            \n+      namesystem.getBlockManager().getDatanodeManager().removeDatanode(nodeReg);            \n     } else {\n       LOG.info(\"Error report from \" + dnName + \": \" + msg);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void errorReport(DatanodeRegistration nodeReg,\n                          int errorCode, String msg) throws IOException { \n    String dnName \u003d (nodeReg \u003d\u003d null ? \"unknown DataNode\" : nodeReg.getName());\n\n    if (errorCode \u003d\u003d DatanodeProtocol.NOTIFY) {\n      LOG.info(\"Error report from \" + dnName + \": \" + msg);\n      return;\n    }\n    verifyRequest(nodeReg);\n\n    if (errorCode \u003d\u003d DatanodeProtocol.DISK_ERROR) {\n      LOG.warn(\"Disk error on \" + dnName + \": \" + msg);\n    } else if (errorCode \u003d\u003d DatanodeProtocol.FATAL_DISK_ERROR) {\n      LOG.warn(\"Fatal disk error on \" + dnName + \": \" + msg);\n      namesystem.getBlockManager().getDatanodeManager().removeDatanode(nodeReg);            \n    } else {\n      LOG.info(\"Error report from \" + dnName + \": \" + msg);\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,19 @@\n+  public void errorReport(DatanodeRegistration nodeReg,\n+                          int errorCode, String msg) throws IOException { \n+    String dnName \u003d (nodeReg \u003d\u003d null ? \"unknown DataNode\" : nodeReg.getName());\n+\n+    if (errorCode \u003d\u003d DatanodeProtocol.NOTIFY) {\n+      LOG.info(\"Error report from \" + dnName + \": \" + msg);\n+      return;\n+    }\n+    verifyRequest(nodeReg);\n+\n+    if (errorCode \u003d\u003d DatanodeProtocol.DISK_ERROR) {\n+      LOG.warn(\"Disk error on \" + dnName + \": \" + msg);\n+    } else if (errorCode \u003d\u003d DatanodeProtocol.FATAL_DISK_ERROR) {\n+      LOG.warn(\"Fatal disk error on \" + dnName + \": \" + msg);\n+      namesystem.removeDatanode(nodeReg);            \n+    } else {\n+      LOG.info(\"Error report from \" + dnName + \": \" + msg);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void errorReport(DatanodeRegistration nodeReg,\n                          int errorCode, String msg) throws IOException { \n    String dnName \u003d (nodeReg \u003d\u003d null ? \"unknown DataNode\" : nodeReg.getName());\n\n    if (errorCode \u003d\u003d DatanodeProtocol.NOTIFY) {\n      LOG.info(\"Error report from \" + dnName + \": \" + msg);\n      return;\n    }\n    verifyRequest(nodeReg);\n\n    if (errorCode \u003d\u003d DatanodeProtocol.DISK_ERROR) {\n      LOG.warn(\"Disk error on \" + dnName + \": \" + msg);\n    } else if (errorCode \u003d\u003d DatanodeProtocol.FATAL_DISK_ERROR) {\n      LOG.warn(\"Fatal disk error on \" + dnName + \": \" + msg);\n      namesystem.removeDatanode(nodeReg);            \n    } else {\n      LOG.info(\"Error report from \" + dnName + \": \" + msg);\n    }\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java"
    }
  }
}