{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ExternalSPSFilePathCollector.java",
  "functionName": "remainingCapacity",
  "functionId": "remainingCapacity",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/sps/ExternalSPSFilePathCollector.java",
  "functionStartLine": 140,
  "functionEndLine": 151,
  "numCommitsSeen": 5,
  "timeTaken": 2185,
  "changeHistory": [
    "8467ec24fb74f30371d5a13e893fc56309ee9372",
    "5845c36c16c423107183287cce3be9357dad7564",
    "3159b39cf8ef704835325263154fb1a1cecc109d"
  ],
  "changeHistoryShort": {
    "8467ec24fb74f30371d5a13e893fc56309ee9372": "Yfilerename",
    "5845c36c16c423107183287cce3be9357dad7564": "Ybodychange",
    "3159b39cf8ef704835325263154fb1a1cecc109d": "Yintroduced"
  },
  "changeHistoryDetails": {
    "8467ec24fb74f30371d5a13e893fc56309ee9372": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-13110: [SPS]: Reduce the number of APIs in NamenodeProtocol used by external satisfier. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "8467ec24fb74f30371d5a13e893fc56309ee9372",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public int remainingCapacity() {\n    int size \u003d service.processingQueueSize();\n    int remainingSize \u003d 0;\n    if (size \u003c maxQueueLimitToScan) {\n      remainingSize \u003d maxQueueLimitToScan - size;\n    }\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"SPS processing Q -\u003e maximum capacity:{}, current size:{},\"\n          + \" remaining size:{}\", maxQueueLimitToScan, size, remainingSize);\n    }\n    return remainingSize;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/sps/ExternalSPSFilePathCollector.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/sps/ExternalSPSFileIDCollector.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/sps/ExternalSPSFilePathCollector.java"
      }
    },
    "5845c36c16c423107183287cce3be9357dad7564": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13050: [SPS]: Create start/stop script to start external SPS process. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "5845c36c16c423107183287cce3be9357dad7564",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "3b83110d5ed582b9f913ecf3f62ce410535f8fca",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,12 @@\n   public int remainingCapacity() {\n     int size \u003d service.processingQueueSize();\n-    if (size \u003e\u003d maxQueueLimitToScan) {\n-      return 0;\n-    } else {\n-      return (maxQueueLimitToScan - size);\n+    int remainingSize \u003d 0;\n+    if (size \u003c maxQueueLimitToScan) {\n+      remainingSize \u003d maxQueueLimitToScan - size;\n     }\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"SPS processing Q -\u003e maximum capacity:{}, current size:{},\"\n+          + \" remaining size:{}\", maxQueueLimitToScan, size, remainingSize);\n+    }\n+    return remainingSize;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public int remainingCapacity() {\n    int size \u003d service.processingQueueSize();\n    int remainingSize \u003d 0;\n    if (size \u003c maxQueueLimitToScan) {\n      remainingSize \u003d maxQueueLimitToScan - size;\n    }\n    if (LOG.isDebugEnabled()) {\n      LOG.debug(\"SPS processing Q -\u003e maximum capacity:{}, current size:{},\"\n          + \" remaining size:{}\", maxQueueLimitToScan, size, remainingSize);\n    }\n    return remainingSize;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/sps/ExternalSPSFileIDCollector.java",
      "extendedDetails": {}
    },
    "3159b39cf8ef704835325263154fb1a1cecc109d": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13025. [SPS]: Implement a mechanism to scan the files for external SPS. Contributed by Uma Maheswara Rao G.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "3159b39cf8ef704835325263154fb1a1cecc109d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "diff": "@@ -0,0 +1,8 @@\n+  public int remainingCapacity() {\n+    int size \u003d service.processingQueueSize();\n+    if (size \u003e\u003d maxQueueLimitToScan) {\n+      return 0;\n+    } else {\n+      return (maxQueueLimitToScan - size);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public int remainingCapacity() {\n    int size \u003d service.processingQueueSize();\n    if (size \u003e\u003d maxQueueLimitToScan) {\n      return 0;\n    } else {\n      return (maxQueueLimitToScan - size);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/sps/ExternalSPSFileIDCollector.java"
    }
  }
}