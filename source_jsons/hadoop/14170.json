{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "QuorumJournalManager.java",
  "functionName": "selectInputStreams",
  "functionId": "selectInputStreams___streams-Collection__EditLogInputStream____fromTxnId-long__inProgressOk-boolean__onlyDurableTxns-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
  "functionStartLine": 514,
  "functionEndLine": 537,
  "numCommitsSeen": 42,
  "timeTaken": 5168,
  "changeHistory": [
    "4c9baba06629e3b3f8eddc52afb62c5fbcb06178",
    "1e22f2bfbb1d9a29f5d4fa641b7a0dabd5b1dbf5",
    "00e99c65943e64fd696ec715cf21e851b93115f1",
    "ae290a4bb4e514e2fe9b40d28426a7589afe2a3f",
    "0faf50624580b86b64a828cdbbb630ae8994e2cd",
    "098ec2b11ff3f677eb823f75b147a1ac8dbf959e"
  ],
  "changeHistoryShort": {
    "4c9baba06629e3b3f8eddc52afb62c5fbcb06178": "Ybodychange",
    "1e22f2bfbb1d9a29f5d4fa641b7a0dabd5b1dbf5": "Ybodychange",
    "00e99c65943e64fd696ec715cf21e851b93115f1": "Ybodychange",
    "ae290a4bb4e514e2fe9b40d28426a7589afe2a3f": "Ybodychange",
    "0faf50624580b86b64a828cdbbb630ae8994e2cd": "Ybodychange",
    "098ec2b11ff3f677eb823f75b147a1ac8dbf959e": "Yintroduced"
  },
  "changeHistoryDetails": {
    "4c9baba06629e3b3f8eddc52afb62c5fbcb06178": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13789. Reduce logging frequency of QuorumJournalManager#selectInputStreams. Contributed by Erik Krogen.\n",
      "commitDate": "24/12/18 9:34 AM",
      "commitName": "4c9baba06629e3b3f8eddc52afb62c5fbcb06178",
      "commitAuthor": "Chao Sun",
      "commitDateOld": "24/12/18 9:34 AM",
      "commitNameOld": "1e22f2bfbb1d9a29f5d4fa641b7a0dabd5b1dbf5",
      "commitAuthorOld": "Erik Krogen",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,24 @@\n   public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n       long fromTxnId, boolean inProgressOk,\n       boolean onlyDurableTxns) throws IOException {\n     // Some calls will use inProgressOK to get in-progress edits even if\n     // the cache used for RPC calls is not enabled; fall back to using the\n     // streaming mechanism to serve such requests\n     if (inProgressOk \u0026\u0026 inProgressTailingEnabled) {\n-      LOG.info(\"Tailing edits starting from txn ID \" + fromTxnId +\n-          \" via RPC mechanism\");\n+      if (LOG.isDebugEnabled()) {\n+        LOG.debug(\"Tailing edits starting from txn ID \" + fromTxnId +\n+            \" via RPC mechanism\");\n+      }\n       try {\n         Collection\u003cEditLogInputStream\u003e rpcStreams \u003d new ArrayList\u003c\u003e();\n         selectRpcInputStreams(rpcStreams, fromTxnId, onlyDurableTxns);\n         streams.addAll(rpcStreams);\n         return;\n       } catch (IOException ioe) {\n         LOG.warn(\"Encountered exception while tailing edits \u003e\u003d \" + fromTxnId +\n             \" via RPC; falling back to streaming.\", ioe);\n       }\n     }\n     selectStreamingInputStreams(streams, fromTxnId, inProgressOk,\n         onlyDurableTxns);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n      long fromTxnId, boolean inProgressOk,\n      boolean onlyDurableTxns) throws IOException {\n    // Some calls will use inProgressOK to get in-progress edits even if\n    // the cache used for RPC calls is not enabled; fall back to using the\n    // streaming mechanism to serve such requests\n    if (inProgressOk \u0026\u0026 inProgressTailingEnabled) {\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Tailing edits starting from txn ID \" + fromTxnId +\n            \" via RPC mechanism\");\n      }\n      try {\n        Collection\u003cEditLogInputStream\u003e rpcStreams \u003d new ArrayList\u003c\u003e();\n        selectRpcInputStreams(rpcStreams, fromTxnId, onlyDurableTxns);\n        streams.addAll(rpcStreams);\n        return;\n      } catch (IOException ioe) {\n        LOG.warn(\"Encountered exception while tailing edits \u003e\u003d \" + fromTxnId +\n            \" via RPC; falling back to streaming.\", ioe);\n      }\n    }\n    selectStreamingInputStreams(streams, fromTxnId, inProgressOk,\n        onlyDurableTxns);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
      "extendedDetails": {}
    },
    "1e22f2bfbb1d9a29f5d4fa641b7a0dabd5b1dbf5": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13610. [SBN read] Edit Tail Fast Path Part 4: Cleanup. Integration test, documentation, remove unnecessary dummy sync, minors fixups. Contributed by Erik Krogen.\n",
      "commitDate": "24/12/18 9:34 AM",
      "commitName": "1e22f2bfbb1d9a29f5d4fa641b7a0dabd5b1dbf5",
      "commitAuthor": "Erik Krogen",
      "commitDateOld": "24/12/18 9:33 AM",
      "commitNameOld": "00e99c65943e64fd696ec715cf21e851b93115f1",
      "commitAuthorOld": "Erik Krogen",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 4,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,22 @@\n   public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n       long fromTxnId, boolean inProgressOk,\n       boolean onlyDurableTxns) throws IOException {\n-    if (inProgressOk) {\n+    // Some calls will use inProgressOK to get in-progress edits even if\n+    // the cache used for RPC calls is not enabled; fall back to using the\n+    // streaming mechanism to serve such requests\n+    if (inProgressOk \u0026\u0026 inProgressTailingEnabled) {\n       LOG.info(\"Tailing edits starting from txn ID \" + fromTxnId +\n           \" via RPC mechanism\");\n       try {\n         Collection\u003cEditLogInputStream\u003e rpcStreams \u003d new ArrayList\u003c\u003e();\n         selectRpcInputStreams(rpcStreams, fromTxnId, onlyDurableTxns);\n         streams.addAll(rpcStreams);\n         return;\n       } catch (IOException ioe) {\n         LOG.warn(\"Encountered exception while tailing edits \u003e\u003d \" + fromTxnId +\n             \" via RPC; falling back to streaming.\", ioe);\n       }\n     }\n     selectStreamingInputStreams(streams, fromTxnId, inProgressOk,\n         onlyDurableTxns);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n      long fromTxnId, boolean inProgressOk,\n      boolean onlyDurableTxns) throws IOException {\n    // Some calls will use inProgressOK to get in-progress edits even if\n    // the cache used for RPC calls is not enabled; fall back to using the\n    // streaming mechanism to serve such requests\n    if (inProgressOk \u0026\u0026 inProgressTailingEnabled) {\n      LOG.info(\"Tailing edits starting from txn ID \" + fromTxnId +\n          \" via RPC mechanism\");\n      try {\n        Collection\u003cEditLogInputStream\u003e rpcStreams \u003d new ArrayList\u003c\u003e();\n        selectRpcInputStreams(rpcStreams, fromTxnId, onlyDurableTxns);\n        streams.addAll(rpcStreams);\n        return;\n      } catch (IOException ioe) {\n        LOG.warn(\"Encountered exception while tailing edits \u003e\u003d \" + fromTxnId +\n            \" via RPC; falling back to streaming.\", ioe);\n      }\n    }\n    selectStreamingInputStreams(streams, fromTxnId, inProgressOk,\n        onlyDurableTxns);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
      "extendedDetails": {}
    },
    "00e99c65943e64fd696ec715cf21e851b93115f1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13609. [SBN read] Edit Tail Fast Path Part 3: NameNode-side changes to support tailing edits via RPC. Contributed by Erik Krogen.\n",
      "commitDate": "24/12/18 9:33 AM",
      "commitName": "00e99c65943e64fd696ec715cf21e851b93115f1",
      "commitAuthor": "Erik Krogen",
      "commitDateOld": "06/09/18 2:48 PM",
      "commitNameOld": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 108.82,
      "commitsBetweenForRepo": 927,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,48 +1,19 @@\n   public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n       long fromTxnId, boolean inProgressOk,\n       boolean onlyDurableTxns) throws IOException {\n-\n-    QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n-        loggers.getEditLogManifest(fromTxnId, inProgressOk);\n-    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps \u003d\n-        loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs,\n-            \"selectInputStreams\");\n-    \n-    LOG.debug(\"selectInputStream manifests:\\n\" +\n-        Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n-    \n-    final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n-        new PriorityQueue\u003cEditLogInputStream\u003e(64,\n-            JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n-    for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n-      AsyncLogger logger \u003d e.getKey();\n-      RemoteEditLogManifest manifest \u003d e.getValue();\n-      long committedTxnId \u003d manifest.getCommittedTxnId();\n-\n-      for (RemoteEditLog remoteLog : manifest.getLogs()) {\n-        URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n-\n-        long endTxId \u003d remoteLog.getEndTxId();\n-\n-        // If it\u0027s bounded by durable Txns, endTxId could not be larger\n-        // than committedTxnId. This ensures the consistency.\n-        // We don\u0027t do the following for finalized log segments, since all\n-        // edits in those are guaranteed to be committed.\n-        if (onlyDurableTxns \u0026\u0026 inProgressOk \u0026\u0026 remoteLog.isInProgress()) {\n-          endTxId \u003d Math.min(endTxId, committedTxnId);\n-          if (endTxId \u003c remoteLog.getStartTxId()) {\n-            LOG.warn(\"Found endTxId (\" + endTxId + \") that is less than \" +\n-                \"the startTxId (\" + remoteLog.getStartTxId() +\n-                \") - setting it to startTxId.\");\n-            endTxId \u003d remoteLog.getStartTxId();\n-          }\n-        }\n-\n-        EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n-            connectionFactory, url, remoteLog.getStartTxId(),\n-            endTxId, remoteLog.isInProgress());\n-        allStreams.add(elis);\n+    if (inProgressOk) {\n+      LOG.info(\"Tailing edits starting from txn ID \" + fromTxnId +\n+          \" via RPC mechanism\");\n+      try {\n+        Collection\u003cEditLogInputStream\u003e rpcStreams \u003d new ArrayList\u003c\u003e();\n+        selectRpcInputStreams(rpcStreams, fromTxnId, onlyDurableTxns);\n+        streams.addAll(rpcStreams);\n+        return;\n+      } catch (IOException ioe) {\n+        LOG.warn(\"Encountered exception while tailing edits \u003e\u003d \" + fromTxnId +\n+            \" via RPC; falling back to streaming.\", ioe);\n       }\n     }\n-    JournalSet.chainAndMakeRedundantStreams(streams, allStreams, fromTxnId);\n+    selectStreamingInputStreams(streams, fromTxnId, inProgressOk,\n+        onlyDurableTxns);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n      long fromTxnId, boolean inProgressOk,\n      boolean onlyDurableTxns) throws IOException {\n    if (inProgressOk) {\n      LOG.info(\"Tailing edits starting from txn ID \" + fromTxnId +\n          \" via RPC mechanism\");\n      try {\n        Collection\u003cEditLogInputStream\u003e rpcStreams \u003d new ArrayList\u003c\u003e();\n        selectRpcInputStreams(rpcStreams, fromTxnId, onlyDurableTxns);\n        streams.addAll(rpcStreams);\n        return;\n      } catch (IOException ioe) {\n        LOG.warn(\"Encountered exception while tailing edits \u003e\u003d \" + fromTxnId +\n            \" via RPC; falling back to streaming.\", ioe);\n      }\n    }\n    selectStreamingInputStreams(streams, fromTxnId, inProgressOk,\n        onlyDurableTxns);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
      "extendedDetails": {}
    },
    "ae290a4bb4e514e2fe9b40d28426a7589afe2a3f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13145. SBN crash when transition to ANN with in-progress edit tailing enabled. Contributed by Chao Sun.",
      "commitDate": "26/02/18 4:15 PM",
      "commitName": "ae290a4bb4e514e2fe9b40d28426a7589afe2a3f",
      "commitAuthor": "Chao Sun",
      "commitDateOld": "01/12/17 12:01 PM",
      "commitNameOld": "0faf50624580b86b64a828cdbbb630ae8994e2cd",
      "commitAuthorOld": "Wei-Chiu Chuang",
      "daysBetweenCommits": 87.18,
      "commitsBetweenForRepo": 512,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,46 +1,48 @@\n   public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n       long fromTxnId, boolean inProgressOk,\n       boolean onlyDurableTxns) throws IOException {\n \n     QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n         loggers.getEditLogManifest(fromTxnId, inProgressOk);\n     Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps \u003d\n         loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs,\n             \"selectInputStreams\");\n     \n     LOG.debug(\"selectInputStream manifests:\\n\" +\n         Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n     \n     final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n         new PriorityQueue\u003cEditLogInputStream\u003e(64,\n             JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n     for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n       AsyncLogger logger \u003d e.getKey();\n       RemoteEditLogManifest manifest \u003d e.getValue();\n       long committedTxnId \u003d manifest.getCommittedTxnId();\n \n       for (RemoteEditLog remoteLog : manifest.getLogs()) {\n         URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n \n         long endTxId \u003d remoteLog.getEndTxId();\n \n         // If it\u0027s bounded by durable Txns, endTxId could not be larger\n         // than committedTxnId. This ensures the consistency.\n-        if (onlyDurableTxns \u0026\u0026 inProgressOk) {\n+        // We don\u0027t do the following for finalized log segments, since all\n+        // edits in those are guaranteed to be committed.\n+        if (onlyDurableTxns \u0026\u0026 inProgressOk \u0026\u0026 remoteLog.isInProgress()) {\n           endTxId \u003d Math.min(endTxId, committedTxnId);\n           if (endTxId \u003c remoteLog.getStartTxId()) {\n             LOG.warn(\"Found endTxId (\" + endTxId + \") that is less than \" +\n                 \"the startTxId (\" + remoteLog.getStartTxId() +\n                 \") - setting it to startTxId.\");\n             endTxId \u003d remoteLog.getStartTxId();\n           }\n         }\n \n         EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n             connectionFactory, url, remoteLog.getStartTxId(),\n             endTxId, remoteLog.isInProgress());\n         allStreams.add(elis);\n       }\n     }\n     JournalSet.chainAndMakeRedundantStreams(streams, allStreams, fromTxnId);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n      long fromTxnId, boolean inProgressOk,\n      boolean onlyDurableTxns) throws IOException {\n\n    QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n        loggers.getEditLogManifest(fromTxnId, inProgressOk);\n    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps \u003d\n        loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs,\n            \"selectInputStreams\");\n    \n    LOG.debug(\"selectInputStream manifests:\\n\" +\n        Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n    \n    final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n        new PriorityQueue\u003cEditLogInputStream\u003e(64,\n            JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n    for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n      AsyncLogger logger \u003d e.getKey();\n      RemoteEditLogManifest manifest \u003d e.getValue();\n      long committedTxnId \u003d manifest.getCommittedTxnId();\n\n      for (RemoteEditLog remoteLog : manifest.getLogs()) {\n        URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n\n        long endTxId \u003d remoteLog.getEndTxId();\n\n        // If it\u0027s bounded by durable Txns, endTxId could not be larger\n        // than committedTxnId. This ensures the consistency.\n        // We don\u0027t do the following for finalized log segments, since all\n        // edits in those are guaranteed to be committed.\n        if (onlyDurableTxns \u0026\u0026 inProgressOk \u0026\u0026 remoteLog.isInProgress()) {\n          endTxId \u003d Math.min(endTxId, committedTxnId);\n          if (endTxId \u003c remoteLog.getStartTxId()) {\n            LOG.warn(\"Found endTxId (\" + endTxId + \") that is less than \" +\n                \"the startTxId (\" + remoteLog.getStartTxId() +\n                \") - setting it to startTxId.\");\n            endTxId \u003d remoteLog.getStartTxId();\n          }\n        }\n\n        EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n            connectionFactory, url, remoteLog.getStartTxId(),\n            endTxId, remoteLog.isInProgress());\n        allStreams.add(elis);\n      }\n    }\n    JournalSet.chainAndMakeRedundantStreams(streams, allStreams, fromTxnId);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
      "extendedDetails": {}
    },
    "0faf50624580b86b64a828cdbbb630ae8994e2cd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12836. startTxId could be greater than endTxId when tailing in-progress edit log. Contributed by Chao Sun.\n",
      "commitDate": "01/12/17 12:01 PM",
      "commitName": "0faf50624580b86b64a828cdbbb630ae8994e2cd",
      "commitAuthor": "Wei-Chiu Chuang",
      "commitDateOld": "13/10/17 2:22 PM",
      "commitNameOld": "8dd1eeb94fef59feaf19182dd8f1fcf1389c7f34",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 48.94,
      "commitsBetweenForRepo": 369,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,46 @@\n   public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n       long fromTxnId, boolean inProgressOk,\n       boolean onlyDurableTxns) throws IOException {\n \n     QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n         loggers.getEditLogManifest(fromTxnId, inProgressOk);\n     Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps \u003d\n         loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs,\n             \"selectInputStreams\");\n     \n     LOG.debug(\"selectInputStream manifests:\\n\" +\n         Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n     \n     final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n         new PriorityQueue\u003cEditLogInputStream\u003e(64,\n             JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n     for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n       AsyncLogger logger \u003d e.getKey();\n       RemoteEditLogManifest manifest \u003d e.getValue();\n       long committedTxnId \u003d manifest.getCommittedTxnId();\n \n       for (RemoteEditLog remoteLog : manifest.getLogs()) {\n         URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n \n         long endTxId \u003d remoteLog.getEndTxId();\n \n         // If it\u0027s bounded by durable Txns, endTxId could not be larger\n         // than committedTxnId. This ensures the consistency.\n         if (onlyDurableTxns \u0026\u0026 inProgressOk) {\n           endTxId \u003d Math.min(endTxId, committedTxnId);\n+          if (endTxId \u003c remoteLog.getStartTxId()) {\n+            LOG.warn(\"Found endTxId (\" + endTxId + \") that is less than \" +\n+                \"the startTxId (\" + remoteLog.getStartTxId() +\n+                \") - setting it to startTxId.\");\n+            endTxId \u003d remoteLog.getStartTxId();\n+          }\n         }\n \n         EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n             connectionFactory, url, remoteLog.getStartTxId(),\n             endTxId, remoteLog.isInProgress());\n         allStreams.add(elis);\n       }\n     }\n     JournalSet.chainAndMakeRedundantStreams(streams, allStreams, fromTxnId);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n      long fromTxnId, boolean inProgressOk,\n      boolean onlyDurableTxns) throws IOException {\n\n    QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n        loggers.getEditLogManifest(fromTxnId, inProgressOk);\n    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps \u003d\n        loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs,\n            \"selectInputStreams\");\n    \n    LOG.debug(\"selectInputStream manifests:\\n\" +\n        Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n    \n    final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n        new PriorityQueue\u003cEditLogInputStream\u003e(64,\n            JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n    for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n      AsyncLogger logger \u003d e.getKey();\n      RemoteEditLogManifest manifest \u003d e.getValue();\n      long committedTxnId \u003d manifest.getCommittedTxnId();\n\n      for (RemoteEditLog remoteLog : manifest.getLogs()) {\n        URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n\n        long endTxId \u003d remoteLog.getEndTxId();\n\n        // If it\u0027s bounded by durable Txns, endTxId could not be larger\n        // than committedTxnId. This ensures the consistency.\n        if (onlyDurableTxns \u0026\u0026 inProgressOk) {\n          endTxId \u003d Math.min(endTxId, committedTxnId);\n          if (endTxId \u003c remoteLog.getStartTxId()) {\n            LOG.warn(\"Found endTxId (\" + endTxId + \") that is less than \" +\n                \"the startTxId (\" + remoteLog.getStartTxId() +\n                \") - setting it to startTxId.\");\n            endTxId \u003d remoteLog.getStartTxId();\n          }\n        }\n\n        EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n            connectionFactory, url, remoteLog.getStartTxId(),\n            endTxId, remoteLog.isInProgress());\n        allStreams.add(elis);\n      }\n    }\n    JournalSet.chainAndMakeRedundantStreams(streams, allStreams, fromTxnId);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
      "extendedDetails": {}
    },
    "098ec2b11ff3f677eb823f75b147a1ac8dbf959e": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-10519. Add a configuration option to enable in-progress edit log tailing. Contributed by Jiayi Zhou.\n",
      "commitDate": "27/07/16 5:55 PM",
      "commitName": "098ec2b11ff3f677eb823f75b147a1ac8dbf959e",
      "commitAuthor": "Andrew Wang",
      "diff": "@@ -0,0 +1,40 @@\n+  public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n+      long fromTxnId, boolean inProgressOk,\n+      boolean onlyDurableTxns) throws IOException {\n+\n+    QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n+        loggers.getEditLogManifest(fromTxnId, inProgressOk);\n+    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps \u003d\n+        loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs,\n+            \"selectInputStreams\");\n+    \n+    LOG.debug(\"selectInputStream manifests:\\n\" +\n+        Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n+    \n+    final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n+        new PriorityQueue\u003cEditLogInputStream\u003e(64,\n+            JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n+    for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n+      AsyncLogger logger \u003d e.getKey();\n+      RemoteEditLogManifest manifest \u003d e.getValue();\n+      long committedTxnId \u003d manifest.getCommittedTxnId();\n+\n+      for (RemoteEditLog remoteLog : manifest.getLogs()) {\n+        URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n+\n+        long endTxId \u003d remoteLog.getEndTxId();\n+\n+        // If it\u0027s bounded by durable Txns, endTxId could not be larger\n+        // than committedTxnId. This ensures the consistency.\n+        if (onlyDurableTxns \u0026\u0026 inProgressOk) {\n+          endTxId \u003d Math.min(endTxId, committedTxnId);\n+        }\n+\n+        EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n+            connectionFactory, url, remoteLog.getStartTxId(),\n+            endTxId, remoteLog.isInProgress());\n+        allStreams.add(elis);\n+      }\n+    }\n+    JournalSet.chainAndMakeRedundantStreams(streams, allStreams, fromTxnId);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void selectInputStreams(Collection\u003cEditLogInputStream\u003e streams,\n      long fromTxnId, boolean inProgressOk,\n      boolean onlyDurableTxns) throws IOException {\n\n    QuorumCall\u003cAsyncLogger, RemoteEditLogManifest\u003e q \u003d\n        loggers.getEditLogManifest(fromTxnId, inProgressOk);\n    Map\u003cAsyncLogger, RemoteEditLogManifest\u003e resps \u003d\n        loggers.waitForWriteQuorum(q, selectInputStreamsTimeoutMs,\n            \"selectInputStreams\");\n    \n    LOG.debug(\"selectInputStream manifests:\\n\" +\n        Joiner.on(\"\\n\").withKeyValueSeparator(\": \").join(resps));\n    \n    final PriorityQueue\u003cEditLogInputStream\u003e allStreams \u003d \n        new PriorityQueue\u003cEditLogInputStream\u003e(64,\n            JournalSet.EDIT_LOG_INPUT_STREAM_COMPARATOR);\n    for (Map.Entry\u003cAsyncLogger, RemoteEditLogManifest\u003e e : resps.entrySet()) {\n      AsyncLogger logger \u003d e.getKey();\n      RemoteEditLogManifest manifest \u003d e.getValue();\n      long committedTxnId \u003d manifest.getCommittedTxnId();\n\n      for (RemoteEditLog remoteLog : manifest.getLogs()) {\n        URL url \u003d logger.buildURLToFetchLogs(remoteLog.getStartTxId());\n\n        long endTxId \u003d remoteLog.getEndTxId();\n\n        // If it\u0027s bounded by durable Txns, endTxId could not be larger\n        // than committedTxnId. This ensures the consistency.\n        if (onlyDurableTxns \u0026\u0026 inProgressOk) {\n          endTxId \u003d Math.min(endTxId, committedTxnId);\n        }\n\n        EditLogInputStream elis \u003d EditLogFileInputStream.fromUrl(\n            connectionFactory, url, remoteLog.getStartTxId(),\n            endTxId, remoteLog.isInProgress());\n        allStreams.add(elis);\n      }\n    }\n    JournalSet.chainAndMakeRedundantStreams(streams, allStreams, fromTxnId);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java"
    }
  }
}