{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DataNode.java",
  "functionName": "checkDiskErrorAsync",
  "functionId": "checkDiskErrorAsync___volume-FsVolumeSpi",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java",
  "functionStartLine": 2206,
  "functionEndLine": 2218,
  "numCommitsSeen": 358,
  "timeTaken": 2079,
  "changeHistory": [
    "dfcb331ba3516264398121c9f23af3a79c0509cc"
  ],
  "changeHistoryShort": {
    "dfcb331ba3516264398121c9f23af3a79c0509cc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "dfcb331ba3516264398121c9f23af3a79c0509cc": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-13076: [SPS]: Addendum. Resolve conflicts after rebasing branch to trunk. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "dfcb331ba3516264398121c9f23af3a79c0509cc",
      "commitAuthor": "Rakesh Radhakrishnan",
      "diff": "@@ -0,0 +1,13 @@\n+  public void checkDiskErrorAsync(FsVolumeSpi volume) {\n+    volumeChecker.checkVolume(\n+        volume, (healthyVolumes, failedVolumes) -\u003e {\n+          if (failedVolumes.size() \u003e 0) {\n+            LOG.warn(\"checkDiskErrorAsync callback got {} failed volumes: {}\",\n+                failedVolumes.size(), failedVolumes);\n+          } else {\n+            LOG.debug(\"checkDiskErrorAsync: no volume failures detected\");\n+          }\n+          lastDiskErrorCheck \u003d Time.monotonicNow();\n+          handleVolumeFailures(failedVolumes);\n+        });\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void checkDiskErrorAsync(FsVolumeSpi volume) {\n    volumeChecker.checkVolume(\n        volume, (healthyVolumes, failedVolumes) -\u003e {\n          if (failedVolumes.size() \u003e 0) {\n            LOG.warn(\"checkDiskErrorAsync callback got {} failed volumes: {}\",\n                failedVolumes.size(), failedVolumes);\n          } else {\n            LOG.debug(\"checkDiskErrorAsync: no volume failures detected\");\n          }\n          lastDiskErrorCheck \u003d Time.monotonicNow();\n          handleVolumeFailures(failedVolumes);\n        });\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNode.java"
    }
  }
}