{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NameNodeProxies.java",
  "functionName": "createProxy",
  "functionId": "createProxy___conf-Configuration__nameNodeUri-URI__xface-Class__T____fallbackToSimpleAuth-AtomicBoolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
  "functionStartLine": 118,
  "functionEndLine": 133,
  "numCommitsSeen": 69,
  "timeTaken": 4725,
  "changeHistory": [
    "64f28f9efa2ef3cd9dd54a6c5009029721e030ed",
    "9e0e430f18d45cfe125dda8d85916edddf79e8d6",
    "63d9f1596c92206cce3b72e3214d2fb5f6242b90",
    "9eee97508f350ed4629abb04e7781514ffa04070",
    "54f83d9bd917e8641e902c5f0695e65ded472f9a",
    "ac742c762d5b01af61022827e9f78fd81b69d717",
    "6f8003dc7bc9e8be7b0512c514d370c303faf003",
    "2cc9514ad643ae49d30524743420ee9744e571bd",
    "f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5",
    "7ba5913797c49d5001ad95558eadd119c3361060",
    "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85",
    "33ade356b35223654a077103ed7fbed89f3f2321",
    "0aa09f6d5a97f523e9ee6f30bb44f206433ead0a",
    "965ce2041a7adfbbe5fc8b77a85c0d1179ef20df",
    "36d0b822ef46fcacdb773abbdd3e81386eb4d63c"
  ],
  "changeHistoryShort": {
    "64f28f9efa2ef3cd9dd54a6c5009029721e030ed": "Ybodychange",
    "9e0e430f18d45cfe125dda8d85916edddf79e8d6": "Ybodychange",
    "63d9f1596c92206cce3b72e3214d2fb5f6242b90": "Ybodychange",
    "9eee97508f350ed4629abb04e7781514ffa04070": "Ybodychange",
    "54f83d9bd917e8641e902c5f0695e65ded472f9a": "Ybodychange",
    "ac742c762d5b01af61022827e9f78fd81b69d717": "Ybodychange",
    "6f8003dc7bc9e8be7b0512c514d370c303faf003": "Ybodychange",
    "2cc9514ad643ae49d30524743420ee9744e571bd": "Ybodychange",
    "f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5": "Ymultichange(Yrename,Yparameterchange,Ybodychange)",
    "7ba5913797c49d5001ad95558eadd119c3361060": "Ybodychange",
    "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85": "Ybodychange",
    "33ade356b35223654a077103ed7fbed89f3f2321": "Ybodychange",
    "0aa09f6d5a97f523e9ee6f30bb44f206433ead0a": "Ybodychange",
    "965ce2041a7adfbbe5fc8b77a85c0d1179ef20df": "Ybodychange",
    "36d0b822ef46fcacdb773abbdd3e81386eb4d63c": "Yintroduced"
  },
  "changeHistoryDetails": {
    "64f28f9efa2ef3cd9dd54a6c5009029721e030ed": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14162. [SBN read] Allow Balancer to work with Observer node. Add a new ProxyCombiner allowing for multiple related protocols to be combined. Allow AlignmentContext to be passed in NameNodeProxyFactory. Contributed by Erik Krogen.\n",
      "commitDate": "14/02/19 11:22 AM",
      "commitName": "64f28f9efa2ef3cd9dd54a6c5009029721e030ed",
      "commitAuthor": "Erik Krogen",
      "commitDateOld": "06/09/18 2:48 PM",
      "commitNameOld": "eca1a4bfe952fc184fe90dde50bac9b0e5293568",
      "commitAuthorOld": "Giovanni Matteo Fumarola",
      "daysBetweenCommits": 160.9,
      "commitsBetweenForRepo": 1283,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n       URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n       throws IOException {\n     AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n         NameNodeProxiesClient.createFailoverProxyProvider(conf, nameNodeUri,\n             xface, true, fallbackToSimpleAuth, new NameNodeHAProxyFactory\u003cT\u003e());\n \n     if (failoverProxyProvider \u003d\u003d null) {\n       return createNonHAProxy(conf, DFSUtilClient.getNNAddress(nameNodeUri),\n           xface, UserGroupInformation.getCurrentUser(), true,\n-          fallbackToSimpleAuth);\n+          fallbackToSimpleAuth, null);\n     } else {\n       return NameNodeProxiesClient.createHAProxy(conf, nameNodeUri, xface,\n           failoverProxyProvider);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n        NameNodeProxiesClient.createFailoverProxyProvider(conf, nameNodeUri,\n            xface, true, fallbackToSimpleAuth, new NameNodeHAProxyFactory\u003cT\u003e());\n\n    if (failoverProxyProvider \u003d\u003d null) {\n      return createNonHAProxy(conf, DFSUtilClient.getNNAddress(nameNodeUri),\n          xface, UserGroupInformation.getCurrentUser(), true,\n          fallbackToSimpleAuth, null);\n    } else {\n      return NameNodeProxiesClient.createHAProxy(conf, nameNodeUri, xface,\n          failoverProxyProvider);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "9e0e430f18d45cfe125dda8d85916edddf79e8d6": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11538. Move ClientProtocol HA proxies into hadoop-hdfs-client. Contributed by Huafeng Wang.\n",
      "commitDate": "04/04/17 11:05 PM",
      "commitName": "9e0e430f18d45cfe125dda8d85916edddf79e8d6",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "22/09/15 8:52 PM",
      "commitNameOld": "63d9f1596c92206cce3b72e3214d2fb5f6242b90",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 560.09,
      "commitsBetweenForRepo": 3771,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,16 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n       URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n       throws IOException {\n     AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n         NameNodeProxiesClient.createFailoverProxyProvider(conf, nameNodeUri,\n-            xface, true, fallbackToSimpleAuth);\n+            xface, true, fallbackToSimpleAuth, new NameNodeHAProxyFactory\u003cT\u003e());\n \n     if (failoverProxyProvider \u003d\u003d null) {\n       return createNonHAProxy(conf, DFSUtilClient.getNNAddress(nameNodeUri),\n           xface, UserGroupInformation.getCurrentUser(), true,\n           fallbackToSimpleAuth);\n     } else {\n       return NameNodeProxiesClient.createHAProxy(conf, nameNodeUri, xface,\n           failoverProxyProvider);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n        NameNodeProxiesClient.createFailoverProxyProvider(conf, nameNodeUri,\n            xface, true, fallbackToSimpleAuth, new NameNodeHAProxyFactory\u003cT\u003e());\n\n    if (failoverProxyProvider \u003d\u003d null) {\n      return createNonHAProxy(conf, DFSUtilClient.getNNAddress(nameNodeUri),\n          xface, UserGroupInformation.getCurrentUser(), true,\n          fallbackToSimpleAuth);\n    } else {\n      return NameNodeProxiesClient.createHAProxy(conf, nameNodeUri, xface,\n          failoverProxyProvider);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "63d9f1596c92206cce3b72e3214d2fb5f6242b90": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9039. Separate client and server side methods of o.a.h.hdfs.NameNodeProxies. Contributed by Mingliang Liu.\n",
      "commitDate": "22/09/15 8:52 PM",
      "commitName": "63d9f1596c92206cce3b72e3214d2fb5f6242b90",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "17/09/15 2:18 PM",
      "commitNameOld": "9eee97508f350ed4629abb04e7781514ffa04070",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 5.27,
      "commitsBetweenForRepo": 29,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,16 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n       URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n       throws IOException {\n     AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n-        createFailoverProxyProvider(conf, nameNodeUri, xface, true,\n-          fallbackToSimpleAuth);\n-  \n+        NameNodeProxiesClient.createFailoverProxyProvider(conf, nameNodeUri,\n+            xface, true, fallbackToSimpleAuth);\n+\n     if (failoverProxyProvider \u003d\u003d null) {\n-      // Non-HA case\n       return createNonHAProxy(conf, DFSUtilClient.getNNAddress(nameNodeUri),\n           xface, UserGroupInformation.getCurrentUser(), true,\n           fallbackToSimpleAuth);\n     } else {\n-      // HA case\n-      DfsClientConf config \u003d new DfsClientConf(conf);\n-      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n-          RetryPolicies.failoverOnNetworkException(\n-              RetryPolicies.TRY_ONCE_THEN_FAIL, config.getMaxFailoverAttempts(),\n-              config.getMaxRetryAttempts(), config.getFailoverSleepBaseMillis(),\n-              config.getFailoverSleepMaxMillis()));\n-\n-      Text dtService;\n-      if (failoverProxyProvider.useLogicalURI()) {\n-        dtService \u003d HAUtilClient.buildTokenServiceForLogicalUri(nameNodeUri,\n-                                                                HdfsConstants.HDFS_URI_SCHEME);\n-      } else {\n-        dtService \u003d SecurityUtil.buildTokenService(\n-            DFSUtilClient.getNNAddress(nameNodeUri));\n-      }\n-      return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n-          DFSUtilClient.getNNAddress(nameNodeUri));\n+      return NameNodeProxiesClient.createHAProxy(conf, nameNodeUri, xface,\n+          failoverProxyProvider);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n        NameNodeProxiesClient.createFailoverProxyProvider(conf, nameNodeUri,\n            xface, true, fallbackToSimpleAuth);\n\n    if (failoverProxyProvider \u003d\u003d null) {\n      return createNonHAProxy(conf, DFSUtilClient.getNNAddress(nameNodeUri),\n          xface, UserGroupInformation.getCurrentUser(), true,\n          fallbackToSimpleAuth);\n    } else {\n      return NameNodeProxiesClient.createHAProxy(conf, nameNodeUri, xface,\n          failoverProxyProvider);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "9eee97508f350ed4629abb04e7781514ffa04070": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9022. Move NameNode.getAddress() and NameNode.getUri() to hadoop-hdfs-client. Contributed by Mingliang Liu.\n",
      "commitDate": "17/09/15 2:18 PM",
      "commitName": "9eee97508f350ed4629abb04e7781514ffa04070",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "14/09/15 6:22 PM",
      "commitNameOld": "76957a485b526468498f93e443544131a88b5684",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 2.83,
      "commitsBetweenForRepo": 26,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,33 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n       URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n       throws IOException {\n     AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n         createFailoverProxyProvider(conf, nameNodeUri, xface, true,\n           fallbackToSimpleAuth);\n   \n     if (failoverProxyProvider \u003d\u003d null) {\n       // Non-HA case\n-      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n-          UserGroupInformation.getCurrentUser(), true,\n+      return createNonHAProxy(conf, DFSUtilClient.getNNAddress(nameNodeUri),\n+          xface, UserGroupInformation.getCurrentUser(), true,\n           fallbackToSimpleAuth);\n     } else {\n       // HA case\n       DfsClientConf config \u003d new DfsClientConf(conf);\n       T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n           RetryPolicies.failoverOnNetworkException(\n               RetryPolicies.TRY_ONCE_THEN_FAIL, config.getMaxFailoverAttempts(),\n               config.getMaxRetryAttempts(), config.getFailoverSleepBaseMillis(),\n               config.getFailoverSleepMaxMillis()));\n \n       Text dtService;\n       if (failoverProxyProvider.useLogicalURI()) {\n         dtService \u003d HAUtilClient.buildTokenServiceForLogicalUri(nameNodeUri,\n                                                                 HdfsConstants.HDFS_URI_SCHEME);\n       } else {\n         dtService \u003d SecurityUtil.buildTokenService(\n-            NameNode.getAddress(nameNodeUri));\n+            DFSUtilClient.getNNAddress(nameNodeUri));\n       }\n       return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n-          NameNode.getAddress(nameNodeUri));\n+          DFSUtilClient.getNNAddress(nameNodeUri));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n        createFailoverProxyProvider(conf, nameNodeUri, xface, true,\n          fallbackToSimpleAuth);\n  \n    if (failoverProxyProvider \u003d\u003d null) {\n      // Non-HA case\n      return createNonHAProxy(conf, DFSUtilClient.getNNAddress(nameNodeUri),\n          xface, UserGroupInformation.getCurrentUser(), true,\n          fallbackToSimpleAuth);\n    } else {\n      // HA case\n      DfsClientConf config \u003d new DfsClientConf(conf);\n      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n          RetryPolicies.failoverOnNetworkException(\n              RetryPolicies.TRY_ONCE_THEN_FAIL, config.getMaxFailoverAttempts(),\n              config.getMaxRetryAttempts(), config.getFailoverSleepBaseMillis(),\n              config.getFailoverSleepMaxMillis()));\n\n      Text dtService;\n      if (failoverProxyProvider.useLogicalURI()) {\n        dtService \u003d HAUtilClient.buildTokenServiceForLogicalUri(nameNodeUri,\n                                                                HdfsConstants.HDFS_URI_SCHEME);\n      } else {\n        dtService \u003d SecurityUtil.buildTokenService(\n            DFSUtilClient.getNNAddress(nameNodeUri));\n      }\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n          DFSUtilClient.getNNAddress(nameNodeUri));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "54f83d9bd917e8641e902c5f0695e65ded472f9a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8270. create() always retried with hardcoded timeout when file already exists with open lease (Contributed by J.Andreina)\n",
      "commitDate": "02/06/15 11:41 PM",
      "commitName": "54f83d9bd917e8641e902c5f0695e65ded472f9a",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "15/05/15 7:12 PM",
      "commitNameOld": "ac742c762d5b01af61022827e9f78fd81b69d717",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 18.19,
      "commitsBetweenForRepo": 127,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,33 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n       URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n       throws IOException {\n-    return createProxy(conf, nameNodeUri, xface, fallbackToSimpleAuth, true);\n+    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n+        createFailoverProxyProvider(conf, nameNodeUri, xface, true,\n+          fallbackToSimpleAuth);\n+  \n+    if (failoverProxyProvider \u003d\u003d null) {\n+      // Non-HA case\n+      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n+          UserGroupInformation.getCurrentUser(), true,\n+          fallbackToSimpleAuth);\n+    } else {\n+      // HA case\n+      DfsClientConf config \u003d new DfsClientConf(conf);\n+      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n+          RetryPolicies.failoverOnNetworkException(\n+              RetryPolicies.TRY_ONCE_THEN_FAIL, config.getMaxFailoverAttempts(),\n+              config.getMaxRetryAttempts(), config.getFailoverSleepBaseMillis(),\n+              config.getFailoverSleepMaxMillis()));\n+\n+      Text dtService;\n+      if (failoverProxyProvider.useLogicalURI()) {\n+        dtService \u003d HAUtilClient.buildTokenServiceForLogicalUri(nameNodeUri,\n+                                                                HdfsConstants.HDFS_URI_SCHEME);\n+      } else {\n+        dtService \u003d SecurityUtil.buildTokenService(\n+            NameNode.getAddress(nameNodeUri));\n+      }\n+      return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n+          NameNode.getAddress(nameNodeUri));\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n        createFailoverProxyProvider(conf, nameNodeUri, xface, true,\n          fallbackToSimpleAuth);\n  \n    if (failoverProxyProvider \u003d\u003d null) {\n      // Non-HA case\n      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n          UserGroupInformation.getCurrentUser(), true,\n          fallbackToSimpleAuth);\n    } else {\n      // HA case\n      DfsClientConf config \u003d new DfsClientConf(conf);\n      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n          RetryPolicies.failoverOnNetworkException(\n              RetryPolicies.TRY_ONCE_THEN_FAIL, config.getMaxFailoverAttempts(),\n              config.getMaxRetryAttempts(), config.getFailoverSleepBaseMillis(),\n              config.getFailoverSleepMaxMillis()));\n\n      Text dtService;\n      if (failoverProxyProvider.useLogicalURI()) {\n        dtService \u003d HAUtilClient.buildTokenServiceForLogicalUri(nameNodeUri,\n                                                                HdfsConstants.HDFS_URI_SCHEME);\n      } else {\n        dtService \u003d SecurityUtil.buildTokenService(\n            NameNode.getAddress(nameNodeUri));\n      }\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n          NameNode.getAddress(nameNodeUri));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "ac742c762d5b01af61022827e9f78fd81b69d717": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8403. Eliminate retries in TestFileCreation#testOverwriteOpenForWrite. Contributed by Arpit Agarwal.\n",
      "commitDate": "15/05/15 7:12 PM",
      "commitName": "ac742c762d5b01af61022827e9f78fd81b69d717",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "02/05/15 10:03 AM",
      "commitNameOld": "6ae2a0d048e133b43249c248a75a4d77d9abb80d",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 13.38,
      "commitsBetweenForRepo": 198,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,5 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n       URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n       throws IOException {\n-    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n-        createFailoverProxyProvider(conf, nameNodeUri, xface, true,\n-          fallbackToSimpleAuth);\n-  \n-    if (failoverProxyProvider \u003d\u003d null) {\n-      // Non-HA case\n-      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n-          UserGroupInformation.getCurrentUser(), true, fallbackToSimpleAuth);\n-    } else {\n-      // HA case\n-      DfsClientConf config \u003d new DfsClientConf(conf);\n-      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n-          RetryPolicies.failoverOnNetworkException(\n-              RetryPolicies.TRY_ONCE_THEN_FAIL, config.getMaxFailoverAttempts(),\n-              config.getMaxRetryAttempts(), config.getFailoverSleepBaseMillis(),\n-              config.getFailoverSleepMaxMillis()));\n-\n-      Text dtService;\n-      if (failoverProxyProvider.useLogicalURI()) {\n-        dtService \u003d HAUtilClient.buildTokenServiceForLogicalUri(nameNodeUri,\n-                                                                HdfsConstants.HDFS_URI_SCHEME);\n-      } else {\n-        dtService \u003d SecurityUtil.buildTokenService(\n-            NameNode.getAddress(nameNodeUri));\n-      }\n-      return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n-          NameNode.getAddress(nameNodeUri));\n-    }\n+    return createProxy(conf, nameNodeUri, xface, fallbackToSimpleAuth, true);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    return createProxy(conf, nameNodeUri, xface, fallbackToSimpleAuth, true);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "6f8003dc7bc9e8be7b0512c514d370c303faf003": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8185. Separate client related routines in HAUtil into a new class. Contributed by Haohui Mai.\n",
      "commitDate": "21/04/15 9:59 PM",
      "commitName": "6f8003dc7bc9e8be7b0512c514d370c303faf003",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "10/04/15 7:38 PM",
      "commitNameOld": "60da0e49e7316892d63e9c7cdc3214057e68009a",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 11.1,
      "commitsBetweenForRepo": 72,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,32 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n       URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n       throws IOException {\n     AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n         createFailoverProxyProvider(conf, nameNodeUri, xface, true,\n           fallbackToSimpleAuth);\n   \n     if (failoverProxyProvider \u003d\u003d null) {\n       // Non-HA case\n       return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n           UserGroupInformation.getCurrentUser(), true, fallbackToSimpleAuth);\n     } else {\n       // HA case\n       DfsClientConf config \u003d new DfsClientConf(conf);\n       T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n           RetryPolicies.failoverOnNetworkException(\n               RetryPolicies.TRY_ONCE_THEN_FAIL, config.getMaxFailoverAttempts(),\n               config.getMaxRetryAttempts(), config.getFailoverSleepBaseMillis(),\n               config.getFailoverSleepMaxMillis()));\n \n       Text dtService;\n       if (failoverProxyProvider.useLogicalURI()) {\n-        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri,\n-            HdfsConstants.HDFS_URI_SCHEME);\n+        dtService \u003d HAUtilClient.buildTokenServiceForLogicalUri(nameNodeUri,\n+                                                                HdfsConstants.HDFS_URI_SCHEME);\n       } else {\n         dtService \u003d SecurityUtil.buildTokenService(\n             NameNode.getAddress(nameNodeUri));\n       }\n       return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n           NameNode.getAddress(nameNodeUri));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n        createFailoverProxyProvider(conf, nameNodeUri, xface, true,\n          fallbackToSimpleAuth);\n  \n    if (failoverProxyProvider \u003d\u003d null) {\n      // Non-HA case\n      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n          UserGroupInformation.getCurrentUser(), true, fallbackToSimpleAuth);\n    } else {\n      // HA case\n      DfsClientConf config \u003d new DfsClientConf(conf);\n      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n          RetryPolicies.failoverOnNetworkException(\n              RetryPolicies.TRY_ONCE_THEN_FAIL, config.getMaxFailoverAttempts(),\n              config.getMaxRetryAttempts(), config.getFailoverSleepBaseMillis(),\n              config.getFailoverSleepMaxMillis()));\n\n      Text dtService;\n      if (failoverProxyProvider.useLogicalURI()) {\n        dtService \u003d HAUtilClient.buildTokenServiceForLogicalUri(nameNodeUri,\n                                                                HdfsConstants.HDFS_URI_SCHEME);\n      } else {\n        dtService \u003d SecurityUtil.buildTokenService(\n            NameNode.getAddress(nameNodeUri));\n      }\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n          NameNode.getAddress(nameNodeUri));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "2cc9514ad643ae49d30524743420ee9744e571bd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8100. Refactor DFSClient.Conf to a standalone class and separates short-circuit related conf to ShortCircuitConf.\n",
      "commitDate": "10/04/15 2:48 PM",
      "commitName": "2cc9514ad643ae49d30524743420ee9744e571bd",
      "commitAuthor": "Tsz-Wo Nicholas Sze",
      "commitDateOld": "07/04/15 7:48 PM",
      "commitNameOld": "4be648b55c1ce8743f6e0ea1683168e9ed9c3ee4",
      "commitAuthorOld": "Tsz-Wo Nicholas Sze",
      "daysBetweenCommits": 2.79,
      "commitsBetweenForRepo": 42,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,32 +1,32 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n       URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n       throws IOException {\n     AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n         createFailoverProxyProvider(conf, nameNodeUri, xface, true,\n           fallbackToSimpleAuth);\n   \n     if (failoverProxyProvider \u003d\u003d null) {\n       // Non-HA case\n       return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n           UserGroupInformation.getCurrentUser(), true, fallbackToSimpleAuth);\n     } else {\n       // HA case\n-      Conf config \u003d new Conf(conf);\n+      DfsClientConf config \u003d new DfsClientConf(conf);\n       T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n           RetryPolicies.failoverOnNetworkException(\n-              RetryPolicies.TRY_ONCE_THEN_FAIL, config.maxFailoverAttempts,\n-              config.maxRetryAttempts, config.failoverSleepBaseMillis,\n-              config.failoverSleepMaxMillis));\n+              RetryPolicies.TRY_ONCE_THEN_FAIL, config.getMaxFailoverAttempts(),\n+              config.getMaxRetryAttempts(), config.getFailoverSleepBaseMillis(),\n+              config.getFailoverSleepMaxMillis()));\n \n       Text dtService;\n       if (failoverProxyProvider.useLogicalURI()) {\n         dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri,\n             HdfsConstants.HDFS_URI_SCHEME);\n       } else {\n         dtService \u003d SecurityUtil.buildTokenService(\n             NameNode.getAddress(nameNodeUri));\n       }\n       return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n           NameNode.getAddress(nameNodeUri));\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n        createFailoverProxyProvider(conf, nameNodeUri, xface, true,\n          fallbackToSimpleAuth);\n  \n    if (failoverProxyProvider \u003d\u003d null) {\n      // Non-HA case\n      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n          UserGroupInformation.getCurrentUser(), true, fallbackToSimpleAuth);\n    } else {\n      // HA case\n      DfsClientConf config \u003d new DfsClientConf(conf);\n      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n          RetryPolicies.failoverOnNetworkException(\n              RetryPolicies.TRY_ONCE_THEN_FAIL, config.getMaxFailoverAttempts(),\n              config.getMaxRetryAttempts(), config.getFailoverSleepBaseMillis(),\n              config.getFailoverSleepMaxMillis()));\n\n      Text dtService;\n      if (failoverProxyProvider.useLogicalURI()) {\n        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri,\n            HdfsConstants.HDFS_URI_SCHEME);\n      } else {\n        dtService \u003d SecurityUtil.buildTokenService(\n            NameNode.getAddress(nameNodeUri));\n      }\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n          NameNode.getAddress(nameNodeUri));\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5": {
      "type": "Ymultichange(Yrename,Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7073. Allow falling back to a non-SASL connection on DataTransferProtocol in several edge cases. Contributed by Chris Nauroth.\n",
      "commitDate": "19/09/14 9:23 PM",
      "commitName": "f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5",
      "commitAuthor": "cnauroth",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-7073. Allow falling back to a non-SASL connection on DataTransferProtocol in several edge cases. Contributed by Chris Nauroth.\n",
          "commitDate": "19/09/14 9:23 PM",
          "commitName": "f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5",
          "commitAuthor": "cnauroth",
          "commitDateOld": "17/07/14 4:11 PM",
          "commitNameOld": "7ba5913797c49d5001ad95558eadd119c3361060",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 64.22,
          "commitsBetweenForRepo": 611,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,46 +1,32 @@\n-  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxyWithLossyRetryHandler(\n-      Configuration config, URI nameNodeUri, Class\u003cT\u003e xface,\n-      int numResponseToDrop) throws IOException {\n-    Preconditions.checkArgument(numResponseToDrop \u003e 0);\n+  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n+      URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n+      throws IOException {\n     AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n-        createFailoverProxyProvider(config, nameNodeUri, xface, true);\n+        createFailoverProxyProvider(conf, nameNodeUri, xface, true,\n+          fallbackToSimpleAuth);\n+  \n+    if (failoverProxyProvider \u003d\u003d null) {\n+      // Non-HA case\n+      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n+          UserGroupInformation.getCurrentUser(), true, fallbackToSimpleAuth);\n+    } else {\n+      // HA case\n+      Conf config \u003d new Conf(conf);\n+      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n+          RetryPolicies.failoverOnNetworkException(\n+              RetryPolicies.TRY_ONCE_THEN_FAIL, config.maxFailoverAttempts,\n+              config.maxRetryAttempts, config.failoverSleepBaseMillis,\n+              config.failoverSleepMaxMillis));\n \n-    if (failoverProxyProvider !\u003d null) { // HA case\n-      int delay \u003d config.getInt(\n-          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_KEY,\n-          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_DEFAULT);\n-      int maxCap \u003d config.getInt(\n-          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_KEY,\n-          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_DEFAULT);\n-      int maxFailoverAttempts \u003d config.getInt(\n-          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_KEY,\n-          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_DEFAULT);\n-      int maxRetryAttempts \u003d config.getInt(\n-          DFS_CLIENT_RETRY_MAX_ATTEMPTS_KEY,\n-          DFS_CLIENT_RETRY_MAX_ATTEMPTS_DEFAULT);\n-      InvocationHandler dummyHandler \u003d new LossyRetryInvocationHandler\u003cT\u003e(\n-              numResponseToDrop, failoverProxyProvider,\n-              RetryPolicies.failoverOnNetworkException(\n-                  RetryPolicies.TRY_ONCE_THEN_FAIL, maxFailoverAttempts, \n-                  Math.max(numResponseToDrop + 1, maxRetryAttempts), delay, \n-                  maxCap));\n-      \n-      T proxy \u003d (T) Proxy.newProxyInstance(\n-          failoverProxyProvider.getInterface().getClassLoader(),\n-          new Class[] { xface }, dummyHandler);\n       Text dtService;\n       if (failoverProxyProvider.useLogicalURI()) {\n         dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri,\n             HdfsConstants.HDFS_URI_SCHEME);\n       } else {\n         dtService \u003d SecurityUtil.buildTokenService(\n             NameNode.getAddress(nameNodeUri));\n       }\n       return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n           NameNode.getAddress(nameNodeUri));\n-    } else {\n-      LOG.warn(\"Currently creating proxy using \" +\n-      \t\t\"LossyRetryInvocationHandler requires NN HA setup\");\n-      return null;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n        createFailoverProxyProvider(conf, nameNodeUri, xface, true,\n          fallbackToSimpleAuth);\n  \n    if (failoverProxyProvider \u003d\u003d null) {\n      // Non-HA case\n      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n          UserGroupInformation.getCurrentUser(), true, fallbackToSimpleAuth);\n    } else {\n      // HA case\n      Conf config \u003d new Conf(conf);\n      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n          RetryPolicies.failoverOnNetworkException(\n              RetryPolicies.TRY_ONCE_THEN_FAIL, config.maxFailoverAttempts,\n              config.maxRetryAttempts, config.failoverSleepBaseMillis,\n              config.failoverSleepMaxMillis));\n\n      Text dtService;\n      if (failoverProxyProvider.useLogicalURI()) {\n        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri,\n            HdfsConstants.HDFS_URI_SCHEME);\n      } else {\n        dtService \u003d SecurityUtil.buildTokenService(\n            NameNode.getAddress(nameNodeUri));\n      }\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n          NameNode.getAddress(nameNodeUri));\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
          "extendedDetails": {
            "oldValue": "createProxyWithLossyRetryHandler",
            "newValue": "createProxy"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7073. Allow falling back to a non-SASL connection on DataTransferProtocol in several edge cases. Contributed by Chris Nauroth.\n",
          "commitDate": "19/09/14 9:23 PM",
          "commitName": "f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5",
          "commitAuthor": "cnauroth",
          "commitDateOld": "17/07/14 4:11 PM",
          "commitNameOld": "7ba5913797c49d5001ad95558eadd119c3361060",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 64.22,
          "commitsBetweenForRepo": 611,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,46 +1,32 @@\n-  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxyWithLossyRetryHandler(\n-      Configuration config, URI nameNodeUri, Class\u003cT\u003e xface,\n-      int numResponseToDrop) throws IOException {\n-    Preconditions.checkArgument(numResponseToDrop \u003e 0);\n+  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n+      URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n+      throws IOException {\n     AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n-        createFailoverProxyProvider(config, nameNodeUri, xface, true);\n+        createFailoverProxyProvider(conf, nameNodeUri, xface, true,\n+          fallbackToSimpleAuth);\n+  \n+    if (failoverProxyProvider \u003d\u003d null) {\n+      // Non-HA case\n+      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n+          UserGroupInformation.getCurrentUser(), true, fallbackToSimpleAuth);\n+    } else {\n+      // HA case\n+      Conf config \u003d new Conf(conf);\n+      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n+          RetryPolicies.failoverOnNetworkException(\n+              RetryPolicies.TRY_ONCE_THEN_FAIL, config.maxFailoverAttempts,\n+              config.maxRetryAttempts, config.failoverSleepBaseMillis,\n+              config.failoverSleepMaxMillis));\n \n-    if (failoverProxyProvider !\u003d null) { // HA case\n-      int delay \u003d config.getInt(\n-          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_KEY,\n-          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_DEFAULT);\n-      int maxCap \u003d config.getInt(\n-          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_KEY,\n-          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_DEFAULT);\n-      int maxFailoverAttempts \u003d config.getInt(\n-          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_KEY,\n-          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_DEFAULT);\n-      int maxRetryAttempts \u003d config.getInt(\n-          DFS_CLIENT_RETRY_MAX_ATTEMPTS_KEY,\n-          DFS_CLIENT_RETRY_MAX_ATTEMPTS_DEFAULT);\n-      InvocationHandler dummyHandler \u003d new LossyRetryInvocationHandler\u003cT\u003e(\n-              numResponseToDrop, failoverProxyProvider,\n-              RetryPolicies.failoverOnNetworkException(\n-                  RetryPolicies.TRY_ONCE_THEN_FAIL, maxFailoverAttempts, \n-                  Math.max(numResponseToDrop + 1, maxRetryAttempts), delay, \n-                  maxCap));\n-      \n-      T proxy \u003d (T) Proxy.newProxyInstance(\n-          failoverProxyProvider.getInterface().getClassLoader(),\n-          new Class[] { xface }, dummyHandler);\n       Text dtService;\n       if (failoverProxyProvider.useLogicalURI()) {\n         dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri,\n             HdfsConstants.HDFS_URI_SCHEME);\n       } else {\n         dtService \u003d SecurityUtil.buildTokenService(\n             NameNode.getAddress(nameNodeUri));\n       }\n       return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n           NameNode.getAddress(nameNodeUri));\n-    } else {\n-      LOG.warn(\"Currently creating proxy using \" +\n-      \t\t\"LossyRetryInvocationHandler requires NN HA setup\");\n-      return null;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n        createFailoverProxyProvider(conf, nameNodeUri, xface, true,\n          fallbackToSimpleAuth);\n  \n    if (failoverProxyProvider \u003d\u003d null) {\n      // Non-HA case\n      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n          UserGroupInformation.getCurrentUser(), true, fallbackToSimpleAuth);\n    } else {\n      // HA case\n      Conf config \u003d new Conf(conf);\n      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n          RetryPolicies.failoverOnNetworkException(\n              RetryPolicies.TRY_ONCE_THEN_FAIL, config.maxFailoverAttempts,\n              config.maxRetryAttempts, config.failoverSleepBaseMillis,\n              config.failoverSleepMaxMillis));\n\n      Text dtService;\n      if (failoverProxyProvider.useLogicalURI()) {\n        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri,\n            HdfsConstants.HDFS_URI_SCHEME);\n      } else {\n        dtService \u003d SecurityUtil.buildTokenService(\n            NameNode.getAddress(nameNodeUri));\n      }\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n          NameNode.getAddress(nameNodeUri));\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
          "extendedDetails": {
            "oldValue": "[config-Configuration, nameNodeUri-URI, xface-Class\u003cT\u003e, numResponseToDrop-int]",
            "newValue": "[conf-Configuration, nameNodeUri-URI, xface-Class\u003cT\u003e, fallbackToSimpleAuth-AtomicBoolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7073. Allow falling back to a non-SASL connection on DataTransferProtocol in several edge cases. Contributed by Chris Nauroth.\n",
          "commitDate": "19/09/14 9:23 PM",
          "commitName": "f85cc14eb49a46e81d2edcdc1ffe4d0852f193a5",
          "commitAuthor": "cnauroth",
          "commitDateOld": "17/07/14 4:11 PM",
          "commitNameOld": "7ba5913797c49d5001ad95558eadd119c3361060",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 64.22,
          "commitsBetweenForRepo": 611,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,46 +1,32 @@\n-  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxyWithLossyRetryHandler(\n-      Configuration config, URI nameNodeUri, Class\u003cT\u003e xface,\n-      int numResponseToDrop) throws IOException {\n-    Preconditions.checkArgument(numResponseToDrop \u003e 0);\n+  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n+      URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n+      throws IOException {\n     AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n-        createFailoverProxyProvider(config, nameNodeUri, xface, true);\n+        createFailoverProxyProvider(conf, nameNodeUri, xface, true,\n+          fallbackToSimpleAuth);\n+  \n+    if (failoverProxyProvider \u003d\u003d null) {\n+      // Non-HA case\n+      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n+          UserGroupInformation.getCurrentUser(), true, fallbackToSimpleAuth);\n+    } else {\n+      // HA case\n+      Conf config \u003d new Conf(conf);\n+      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n+          RetryPolicies.failoverOnNetworkException(\n+              RetryPolicies.TRY_ONCE_THEN_FAIL, config.maxFailoverAttempts,\n+              config.maxRetryAttempts, config.failoverSleepBaseMillis,\n+              config.failoverSleepMaxMillis));\n \n-    if (failoverProxyProvider !\u003d null) { // HA case\n-      int delay \u003d config.getInt(\n-          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_KEY,\n-          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_DEFAULT);\n-      int maxCap \u003d config.getInt(\n-          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_KEY,\n-          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_DEFAULT);\n-      int maxFailoverAttempts \u003d config.getInt(\n-          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_KEY,\n-          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_DEFAULT);\n-      int maxRetryAttempts \u003d config.getInt(\n-          DFS_CLIENT_RETRY_MAX_ATTEMPTS_KEY,\n-          DFS_CLIENT_RETRY_MAX_ATTEMPTS_DEFAULT);\n-      InvocationHandler dummyHandler \u003d new LossyRetryInvocationHandler\u003cT\u003e(\n-              numResponseToDrop, failoverProxyProvider,\n-              RetryPolicies.failoverOnNetworkException(\n-                  RetryPolicies.TRY_ONCE_THEN_FAIL, maxFailoverAttempts, \n-                  Math.max(numResponseToDrop + 1, maxRetryAttempts), delay, \n-                  maxCap));\n-      \n-      T proxy \u003d (T) Proxy.newProxyInstance(\n-          failoverProxyProvider.getInterface().getClassLoader(),\n-          new Class[] { xface }, dummyHandler);\n       Text dtService;\n       if (failoverProxyProvider.useLogicalURI()) {\n         dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri,\n             HdfsConstants.HDFS_URI_SCHEME);\n       } else {\n         dtService \u003d SecurityUtil.buildTokenService(\n             NameNode.getAddress(nameNodeUri));\n       }\n       return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n           NameNode.getAddress(nameNodeUri));\n-    } else {\n-      LOG.warn(\"Currently creating proxy using \" +\n-      \t\t\"LossyRetryInvocationHandler requires NN HA setup\");\n-      return null;\n     }\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxy(Configuration conf,\n      URI nameNodeUri, Class\u003cT\u003e xface, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n        createFailoverProxyProvider(conf, nameNodeUri, xface, true,\n          fallbackToSimpleAuth);\n  \n    if (failoverProxyProvider \u003d\u003d null) {\n      // Non-HA case\n      return createNonHAProxy(conf, NameNode.getAddress(nameNodeUri), xface,\n          UserGroupInformation.getCurrentUser(), true, fallbackToSimpleAuth);\n    } else {\n      // HA case\n      Conf config \u003d new Conf(conf);\n      T proxy \u003d (T) RetryProxy.create(xface, failoverProxyProvider,\n          RetryPolicies.failoverOnNetworkException(\n              RetryPolicies.TRY_ONCE_THEN_FAIL, config.maxFailoverAttempts,\n              config.maxRetryAttempts, config.failoverSleepBaseMillis,\n              config.failoverSleepMaxMillis));\n\n      Text dtService;\n      if (failoverProxyProvider.useLogicalURI()) {\n        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri,\n            HdfsConstants.HDFS_URI_SCHEME);\n      } else {\n        dtService \u003d SecurityUtil.buildTokenService(\n            NameNode.getAddress(nameNodeUri));\n      }\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n          NameNode.getAddress(nameNodeUri));\n    }\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
          "extendedDetails": {}
        }
      ]
    },
    "7ba5913797c49d5001ad95558eadd119c3361060": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6667. In HDFS HA mode, Distcp/SLive with webhdfs on secure cluster fails with Client cannot authenticate via:[TOKEN, KERBEROS] error. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1611508 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/07/14 4:11 PM",
      "commitName": "7ba5913797c49d5001ad95558eadd119c3361060",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "17/07/14 10:37 AM",
      "commitNameOld": "f4151bbf4f54dc33836c76e6860aa043a9626e48",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.23,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,45 +1,46 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxyWithLossyRetryHandler(\n       Configuration config, URI nameNodeUri, Class\u003cT\u003e xface,\n       int numResponseToDrop) throws IOException {\n     Preconditions.checkArgument(numResponseToDrop \u003e 0);\n     AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n         createFailoverProxyProvider(config, nameNodeUri, xface, true);\n \n     if (failoverProxyProvider !\u003d null) { // HA case\n       int delay \u003d config.getInt(\n           DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_KEY,\n           DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_DEFAULT);\n       int maxCap \u003d config.getInt(\n           DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_KEY,\n           DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_DEFAULT);\n       int maxFailoverAttempts \u003d config.getInt(\n           DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_KEY,\n           DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_DEFAULT);\n       int maxRetryAttempts \u003d config.getInt(\n           DFS_CLIENT_RETRY_MAX_ATTEMPTS_KEY,\n           DFS_CLIENT_RETRY_MAX_ATTEMPTS_DEFAULT);\n       InvocationHandler dummyHandler \u003d new LossyRetryInvocationHandler\u003cT\u003e(\n               numResponseToDrop, failoverProxyProvider,\n               RetryPolicies.failoverOnNetworkException(\n                   RetryPolicies.TRY_ONCE_THEN_FAIL, maxFailoverAttempts, \n                   Math.max(numResponseToDrop + 1, maxRetryAttempts), delay, \n                   maxCap));\n       \n       T proxy \u003d (T) Proxy.newProxyInstance(\n           failoverProxyProvider.getInterface().getClassLoader(),\n           new Class[] { xface }, dummyHandler);\n       Text dtService;\n       if (failoverProxyProvider.useLogicalURI()) {\n-        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n+        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri,\n+            HdfsConstants.HDFS_URI_SCHEME);\n       } else {\n         dtService \u003d SecurityUtil.buildTokenService(\n             NameNode.getAddress(nameNodeUri));\n       }\n       return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n           NameNode.getAddress(nameNodeUri));\n     } else {\n       LOG.warn(\"Currently creating proxy using \" +\n       \t\t\"LossyRetryInvocationHandler requires NN HA setup\");\n       return null;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxyWithLossyRetryHandler(\n      Configuration config, URI nameNodeUri, Class\u003cT\u003e xface,\n      int numResponseToDrop) throws IOException {\n    Preconditions.checkArgument(numResponseToDrop \u003e 0);\n    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n        createFailoverProxyProvider(config, nameNodeUri, xface, true);\n\n    if (failoverProxyProvider !\u003d null) { // HA case\n      int delay \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_KEY,\n          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_DEFAULT);\n      int maxCap \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_KEY,\n          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_DEFAULT);\n      int maxFailoverAttempts \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_KEY,\n          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_DEFAULT);\n      int maxRetryAttempts \u003d config.getInt(\n          DFS_CLIENT_RETRY_MAX_ATTEMPTS_KEY,\n          DFS_CLIENT_RETRY_MAX_ATTEMPTS_DEFAULT);\n      InvocationHandler dummyHandler \u003d new LossyRetryInvocationHandler\u003cT\u003e(\n              numResponseToDrop, failoverProxyProvider,\n              RetryPolicies.failoverOnNetworkException(\n                  RetryPolicies.TRY_ONCE_THEN_FAIL, maxFailoverAttempts, \n                  Math.max(numResponseToDrop + 1, maxRetryAttempts), delay, \n                  maxCap));\n      \n      T proxy \u003d (T) Proxy.newProxyInstance(\n          failoverProxyProvider.getInterface().getClassLoader(),\n          new Class[] { xface }, dummyHandler);\n      Text dtService;\n      if (failoverProxyProvider.useLogicalURI()) {\n        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri,\n            HdfsConstants.HDFS_URI_SCHEME);\n      } else {\n        dtService \u003d SecurityUtil.buildTokenService(\n            NameNode.getAddress(nameNodeUri));\n      }\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n          NameNode.getAddress(nameNodeUri));\n    } else {\n      LOG.warn(\"Currently creating proxy using \" +\n      \t\t\"LossyRetryInvocationHandler requires NN HA setup\");\n      return null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6507. Improve DFSAdmin to support HA cluster better. (Contributd by Zesheng Wu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1604692 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "22/06/14 10:16 PM",
      "commitName": "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "13/05/14 9:19 AM",
      "commitNameOld": "33ade356b35223654a077103ed7fbed89f3f2321",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 40.54,
      "commitsBetweenForRepo": 250,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,45 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxyWithLossyRetryHandler(\n       Configuration config, URI nameNodeUri, Class\u003cT\u003e xface,\n       int numResponseToDrop) throws IOException {\n     Preconditions.checkArgument(numResponseToDrop \u003e 0);\n     AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n         createFailoverProxyProvider(config, nameNodeUri, xface, true);\n \n     if (failoverProxyProvider !\u003d null) { // HA case\n       int delay \u003d config.getInt(\n           DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_KEY,\n           DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_DEFAULT);\n       int maxCap \u003d config.getInt(\n           DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_KEY,\n           DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_DEFAULT);\n       int maxFailoverAttempts \u003d config.getInt(\n           DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_KEY,\n           DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_DEFAULT);\n       int maxRetryAttempts \u003d config.getInt(\n           DFS_CLIENT_RETRY_MAX_ATTEMPTS_KEY,\n           DFS_CLIENT_RETRY_MAX_ATTEMPTS_DEFAULT);\n       InvocationHandler dummyHandler \u003d new LossyRetryInvocationHandler\u003cT\u003e(\n               numResponseToDrop, failoverProxyProvider,\n               RetryPolicies.failoverOnNetworkException(\n                   RetryPolicies.TRY_ONCE_THEN_FAIL, maxFailoverAttempts, \n                   Math.max(numResponseToDrop + 1, maxRetryAttempts), delay, \n                   maxCap));\n       \n       T proxy \u003d (T) Proxy.newProxyInstance(\n           failoverProxyProvider.getInterface().getClassLoader(),\n           new Class[] { xface }, dummyHandler);\n       Text dtService;\n       if (failoverProxyProvider.useLogicalURI()) {\n         dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n       } else {\n         dtService \u003d SecurityUtil.buildTokenService(\n             NameNode.getAddress(nameNodeUri));\n       }\n-      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n+      return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n+          NameNode.getAddress(nameNodeUri));\n     } else {\n       LOG.warn(\"Currently creating proxy using \" +\n       \t\t\"LossyRetryInvocationHandler requires NN HA setup\");\n       return null;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxyWithLossyRetryHandler(\n      Configuration config, URI nameNodeUri, Class\u003cT\u003e xface,\n      int numResponseToDrop) throws IOException {\n    Preconditions.checkArgument(numResponseToDrop \u003e 0);\n    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n        createFailoverProxyProvider(config, nameNodeUri, xface, true);\n\n    if (failoverProxyProvider !\u003d null) { // HA case\n      int delay \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_KEY,\n          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_DEFAULT);\n      int maxCap \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_KEY,\n          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_DEFAULT);\n      int maxFailoverAttempts \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_KEY,\n          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_DEFAULT);\n      int maxRetryAttempts \u003d config.getInt(\n          DFS_CLIENT_RETRY_MAX_ATTEMPTS_KEY,\n          DFS_CLIENT_RETRY_MAX_ATTEMPTS_DEFAULT);\n      InvocationHandler dummyHandler \u003d new LossyRetryInvocationHandler\u003cT\u003e(\n              numResponseToDrop, failoverProxyProvider,\n              RetryPolicies.failoverOnNetworkException(\n                  RetryPolicies.TRY_ONCE_THEN_FAIL, maxFailoverAttempts, \n                  Math.max(numResponseToDrop + 1, maxRetryAttempts), delay, \n                  maxCap));\n      \n      T proxy \u003d (T) Proxy.newProxyInstance(\n          failoverProxyProvider.getInterface().getClassLoader(),\n          new Class[] { xface }, dummyHandler);\n      Text dtService;\n      if (failoverProxyProvider.useLogicalURI()) {\n        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n      } else {\n        dtService \u003d SecurityUtil.buildTokenService(\n            NameNode.getAddress(nameNodeUri));\n      }\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService,\n          NameNode.getAddress(nameNodeUri));\n    } else {\n      LOG.warn(\"Currently creating proxy using \" +\n      \t\t\"LossyRetryInvocationHandler requires NN HA setup\");\n      return null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "33ade356b35223654a077103ed7fbed89f3f2321": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6334. Client failover proxy provider for IP failover based NN HA. Contributed by Kihwal Lee.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1594263 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/05/14 9:19 AM",
      "commitName": "33ade356b35223654a077103ed7fbed89f3f2321",
      "commitAuthor": "Kihwal Lee",
      "commitDateOld": "28/02/14 11:48 AM",
      "commitNameOld": "d00605f8f0214ed8e2304db8688e140f0a1d62d8",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 73.85,
      "commitsBetweenForRepo": 483,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,44 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxyWithLossyRetryHandler(\n       Configuration config, URI nameNodeUri, Class\u003cT\u003e xface,\n       int numResponseToDrop) throws IOException {\n     Preconditions.checkArgument(numResponseToDrop \u003e 0);\n-    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d \n-        getFailoverProxyProviderClass(config, nameNodeUri, xface);\n-    if (failoverProxyProviderClass !\u003d null) { // HA case\n-      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d \n-          createFailoverProxyProvider(config, failoverProxyProviderClass, \n-              xface, nameNodeUri);\n+    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n+        createFailoverProxyProvider(config, nameNodeUri, xface, true);\n+\n+    if (failoverProxyProvider !\u003d null) { // HA case\n       int delay \u003d config.getInt(\n           DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_KEY,\n           DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_DEFAULT);\n       int maxCap \u003d config.getInt(\n           DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_KEY,\n           DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_DEFAULT);\n       int maxFailoverAttempts \u003d config.getInt(\n           DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_KEY,\n           DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_DEFAULT);\n       int maxRetryAttempts \u003d config.getInt(\n           DFS_CLIENT_RETRY_MAX_ATTEMPTS_KEY,\n           DFS_CLIENT_RETRY_MAX_ATTEMPTS_DEFAULT);\n       InvocationHandler dummyHandler \u003d new LossyRetryInvocationHandler\u003cT\u003e(\n               numResponseToDrop, failoverProxyProvider,\n               RetryPolicies.failoverOnNetworkException(\n                   RetryPolicies.TRY_ONCE_THEN_FAIL, maxFailoverAttempts, \n                   Math.max(numResponseToDrop + 1, maxRetryAttempts), delay, \n                   maxCap));\n       \n       T proxy \u003d (T) Proxy.newProxyInstance(\n           failoverProxyProvider.getInterface().getClassLoader(),\n           new Class[] { xface }, dummyHandler);\n-      Text dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n+      Text dtService;\n+      if (failoverProxyProvider.useLogicalURI()) {\n+        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n+      } else {\n+        dtService \u003d SecurityUtil.buildTokenService(\n+            NameNode.getAddress(nameNodeUri));\n+      }\n       return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n     } else {\n       LOG.warn(\"Currently creating proxy using \" +\n       \t\t\"LossyRetryInvocationHandler requires NN HA setup\");\n       return null;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxyWithLossyRetryHandler(\n      Configuration config, URI nameNodeUri, Class\u003cT\u003e xface,\n      int numResponseToDrop) throws IOException {\n    Preconditions.checkArgument(numResponseToDrop \u003e 0);\n    AbstractNNFailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d\n        createFailoverProxyProvider(config, nameNodeUri, xface, true);\n\n    if (failoverProxyProvider !\u003d null) { // HA case\n      int delay \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_KEY,\n          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_DEFAULT);\n      int maxCap \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_KEY,\n          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_DEFAULT);\n      int maxFailoverAttempts \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_KEY,\n          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_DEFAULT);\n      int maxRetryAttempts \u003d config.getInt(\n          DFS_CLIENT_RETRY_MAX_ATTEMPTS_KEY,\n          DFS_CLIENT_RETRY_MAX_ATTEMPTS_DEFAULT);\n      InvocationHandler dummyHandler \u003d new LossyRetryInvocationHandler\u003cT\u003e(\n              numResponseToDrop, failoverProxyProvider,\n              RetryPolicies.failoverOnNetworkException(\n                  RetryPolicies.TRY_ONCE_THEN_FAIL, maxFailoverAttempts, \n                  Math.max(numResponseToDrop + 1, maxRetryAttempts), delay, \n                  maxCap));\n      \n      T proxy \u003d (T) Proxy.newProxyInstance(\n          failoverProxyProvider.getInterface().getClassLoader(),\n          new Class[] { xface }, dummyHandler);\n      Text dtService;\n      if (failoverProxyProvider.useLogicalURI()) {\n        dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n      } else {\n        dtService \u003d SecurityUtil.buildTokenService(\n            NameNode.getAddress(nameNodeUri));\n      }\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n    } else {\n      LOG.warn(\"Currently creating proxy using \" +\n      \t\t\"LossyRetryInvocationHandler requires NN HA setup\");\n      return null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "0aa09f6d5a97f523e9ee6f30bb44f206433ead0a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5399. Revisit SafeModeException and corresponding retry policies. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1564629 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "04/02/14 8:18 PM",
      "commitName": "0aa09f6d5a97f523e9ee6f30bb44f206433ead0a",
      "commitAuthor": "Todd Lipcon",
      "commitDateOld": "12/09/13 9:29 PM",
      "commitNameOld": "965ce2041a7adfbbe5fc8b77a85c0d1179ef20df",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 144.99,
      "commitsBetweenForRepo": 889,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,37 +1,40 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxyWithLossyRetryHandler(\n       Configuration config, URI nameNodeUri, Class\u003cT\u003e xface,\n       int numResponseToDrop) throws IOException {\n     Preconditions.checkArgument(numResponseToDrop \u003e 0);\n     Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d \n         getFailoverProxyProviderClass(config, nameNodeUri, xface);\n     if (failoverProxyProviderClass !\u003d null) { // HA case\n       FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d \n           createFailoverProxyProvider(config, failoverProxyProviderClass, \n               xface, nameNodeUri);\n       int delay \u003d config.getInt(\n           DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_KEY,\n           DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_DEFAULT);\n       int maxCap \u003d config.getInt(\n           DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_KEY,\n           DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_DEFAULT);\n       int maxFailoverAttempts \u003d config.getInt(\n           DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_KEY,\n           DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_DEFAULT);\n+      int maxRetryAttempts \u003d config.getInt(\n+          DFS_CLIENT_RETRY_MAX_ATTEMPTS_KEY,\n+          DFS_CLIENT_RETRY_MAX_ATTEMPTS_DEFAULT);\n       InvocationHandler dummyHandler \u003d new LossyRetryInvocationHandler\u003cT\u003e(\n               numResponseToDrop, failoverProxyProvider,\n               RetryPolicies.failoverOnNetworkException(\n-                  RetryPolicies.TRY_ONCE_THEN_FAIL, \n-                  Math.max(numResponseToDrop + 1, maxFailoverAttempts), delay, \n+                  RetryPolicies.TRY_ONCE_THEN_FAIL, maxFailoverAttempts, \n+                  Math.max(numResponseToDrop + 1, maxRetryAttempts), delay, \n                   maxCap));\n       \n       T proxy \u003d (T) Proxy.newProxyInstance(\n           failoverProxyProvider.getInterface().getClassLoader(),\n           new Class[] { xface }, dummyHandler);\n       Text dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n       return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n     } else {\n       LOG.warn(\"Currently creating proxy using \" +\n       \t\t\"LossyRetryInvocationHandler requires NN HA setup\");\n       return null;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxyWithLossyRetryHandler(\n      Configuration config, URI nameNodeUri, Class\u003cT\u003e xface,\n      int numResponseToDrop) throws IOException {\n    Preconditions.checkArgument(numResponseToDrop \u003e 0);\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d \n        getFailoverProxyProviderClass(config, nameNodeUri, xface);\n    if (failoverProxyProviderClass !\u003d null) { // HA case\n      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d \n          createFailoverProxyProvider(config, failoverProxyProviderClass, \n              xface, nameNodeUri);\n      int delay \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_KEY,\n          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_DEFAULT);\n      int maxCap \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_KEY,\n          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_DEFAULT);\n      int maxFailoverAttempts \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_KEY,\n          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_DEFAULT);\n      int maxRetryAttempts \u003d config.getInt(\n          DFS_CLIENT_RETRY_MAX_ATTEMPTS_KEY,\n          DFS_CLIENT_RETRY_MAX_ATTEMPTS_DEFAULT);\n      InvocationHandler dummyHandler \u003d new LossyRetryInvocationHandler\u003cT\u003e(\n              numResponseToDrop, failoverProxyProvider,\n              RetryPolicies.failoverOnNetworkException(\n                  RetryPolicies.TRY_ONCE_THEN_FAIL, maxFailoverAttempts, \n                  Math.max(numResponseToDrop + 1, maxRetryAttempts), delay, \n                  maxCap));\n      \n      T proxy \u003d (T) Proxy.newProxyInstance(\n          failoverProxyProvider.getInterface().getClassLoader(),\n          new Class[] { xface }, dummyHandler);\n      Text dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n    } else {\n      LOG.warn(\"Currently creating proxy using \" +\n      \t\t\"LossyRetryInvocationHandler requires NN HA setup\");\n      return null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "965ce2041a7adfbbe5fc8b77a85c0d1179ef20df": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5192. NameNode may fail to start when dfs.client.test.drop.namenode.response.number is set. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1522775 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/09/13 9:29 PM",
      "commitName": "965ce2041a7adfbbe5fc8b77a85c0d1179ef20df",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "06/09/13 10:17 AM",
      "commitNameOld": "36d0b822ef46fcacdb773abbdd3e81386eb4d63c",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 6.47,
      "commitsBetweenForRepo": 30,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,36 +1,37 @@\n   public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxyWithLossyRetryHandler(\n       Configuration config, URI nameNodeUri, Class\u003cT\u003e xface,\n       int numResponseToDrop) throws IOException {\n     Preconditions.checkArgument(numResponseToDrop \u003e 0);\n     Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d \n         getFailoverProxyProviderClass(config, nameNodeUri, xface);\n     if (failoverProxyProviderClass !\u003d null) { // HA case\n       FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d \n           createFailoverProxyProvider(config, failoverProxyProviderClass, \n               xface, nameNodeUri);\n       int delay \u003d config.getInt(\n           DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_KEY,\n           DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_DEFAULT);\n       int maxCap \u003d config.getInt(\n           DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_KEY,\n           DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_DEFAULT);\n       int maxFailoverAttempts \u003d config.getInt(\n           DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_KEY,\n           DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_DEFAULT);\n       InvocationHandler dummyHandler \u003d new LossyRetryInvocationHandler\u003cT\u003e(\n               numResponseToDrop, failoverProxyProvider,\n               RetryPolicies.failoverOnNetworkException(\n                   RetryPolicies.TRY_ONCE_THEN_FAIL, \n                   Math.max(numResponseToDrop + 1, maxFailoverAttempts), delay, \n                   maxCap));\n       \n       T proxy \u003d (T) Proxy.newProxyInstance(\n           failoverProxyProvider.getInterface().getClassLoader(),\n           new Class[] { xface }, dummyHandler);\n       Text dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n       return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n     } else {\n-      throw new IllegalStateException(\"Currently creating proxy using \" +\n+      LOG.warn(\"Currently creating proxy using \" +\n       \t\t\"LossyRetryInvocationHandler requires NN HA setup\");\n+      return null;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxyWithLossyRetryHandler(\n      Configuration config, URI nameNodeUri, Class\u003cT\u003e xface,\n      int numResponseToDrop) throws IOException {\n    Preconditions.checkArgument(numResponseToDrop \u003e 0);\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d \n        getFailoverProxyProviderClass(config, nameNodeUri, xface);\n    if (failoverProxyProviderClass !\u003d null) { // HA case\n      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d \n          createFailoverProxyProvider(config, failoverProxyProviderClass, \n              xface, nameNodeUri);\n      int delay \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_KEY,\n          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_DEFAULT);\n      int maxCap \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_KEY,\n          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_DEFAULT);\n      int maxFailoverAttempts \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_KEY,\n          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_DEFAULT);\n      InvocationHandler dummyHandler \u003d new LossyRetryInvocationHandler\u003cT\u003e(\n              numResponseToDrop, failoverProxyProvider,\n              RetryPolicies.failoverOnNetworkException(\n                  RetryPolicies.TRY_ONCE_THEN_FAIL, \n                  Math.max(numResponseToDrop + 1, maxFailoverAttempts), delay, \n                  maxCap));\n      \n      T proxy \u003d (T) Proxy.newProxyInstance(\n          failoverProxyProvider.getInterface().getClassLoader(),\n          new Class[] { xface }, dummyHandler);\n      Text dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n    } else {\n      LOG.warn(\"Currently creating proxy using \" +\n      \t\t\"LossyRetryInvocationHandler requires NN HA setup\");\n      return null;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java",
      "extendedDetails": {}
    },
    "36d0b822ef46fcacdb773abbdd3e81386eb4d63c": {
      "type": "Yintroduced",
      "commitMessage": "HDS-5118. Provide testing support for DFSClient to drop RPC responses. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1520637 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "06/09/13 10:17 AM",
      "commitName": "36d0b822ef46fcacdb773abbdd3e81386eb4d63c",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,36 @@\n+  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxyWithLossyRetryHandler(\n+      Configuration config, URI nameNodeUri, Class\u003cT\u003e xface,\n+      int numResponseToDrop) throws IOException {\n+    Preconditions.checkArgument(numResponseToDrop \u003e 0);\n+    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d \n+        getFailoverProxyProviderClass(config, nameNodeUri, xface);\n+    if (failoverProxyProviderClass !\u003d null) { // HA case\n+      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d \n+          createFailoverProxyProvider(config, failoverProxyProviderClass, \n+              xface, nameNodeUri);\n+      int delay \u003d config.getInt(\n+          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_KEY,\n+          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_DEFAULT);\n+      int maxCap \u003d config.getInt(\n+          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_KEY,\n+          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_DEFAULT);\n+      int maxFailoverAttempts \u003d config.getInt(\n+          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_KEY,\n+          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_DEFAULT);\n+      InvocationHandler dummyHandler \u003d new LossyRetryInvocationHandler\u003cT\u003e(\n+              numResponseToDrop, failoverProxyProvider,\n+              RetryPolicies.failoverOnNetworkException(\n+                  RetryPolicies.TRY_ONCE_THEN_FAIL, \n+                  Math.max(numResponseToDrop + 1, maxFailoverAttempts), delay, \n+                  maxCap));\n+      \n+      T proxy \u003d (T) Proxy.newProxyInstance(\n+          failoverProxyProvider.getInterface().getClassLoader(),\n+          new Class[] { xface }, dummyHandler);\n+      Text dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n+      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n+    } else {\n+      throw new IllegalStateException(\"Currently creating proxy using \" +\n+      \t\t\"LossyRetryInvocationHandler requires NN HA setup\");\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static \u003cT\u003e ProxyAndInfo\u003cT\u003e createProxyWithLossyRetryHandler(\n      Configuration config, URI nameNodeUri, Class\u003cT\u003e xface,\n      int numResponseToDrop) throws IOException {\n    Preconditions.checkArgument(numResponseToDrop \u003e 0);\n    Class\u003cFailoverProxyProvider\u003cT\u003e\u003e failoverProxyProviderClass \u003d \n        getFailoverProxyProviderClass(config, nameNodeUri, xface);\n    if (failoverProxyProviderClass !\u003d null) { // HA case\n      FailoverProxyProvider\u003cT\u003e failoverProxyProvider \u003d \n          createFailoverProxyProvider(config, failoverProxyProviderClass, \n              xface, nameNodeUri);\n      int delay \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_KEY,\n          DFS_CLIENT_FAILOVER_SLEEPTIME_BASE_DEFAULT);\n      int maxCap \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_KEY,\n          DFS_CLIENT_FAILOVER_SLEEPTIME_MAX_DEFAULT);\n      int maxFailoverAttempts \u003d config.getInt(\n          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_KEY,\n          DFS_CLIENT_FAILOVER_MAX_ATTEMPTS_DEFAULT);\n      InvocationHandler dummyHandler \u003d new LossyRetryInvocationHandler\u003cT\u003e(\n              numResponseToDrop, failoverProxyProvider,\n              RetryPolicies.failoverOnNetworkException(\n                  RetryPolicies.TRY_ONCE_THEN_FAIL, \n                  Math.max(numResponseToDrop + 1, maxFailoverAttempts), delay, \n                  maxCap));\n      \n      T proxy \u003d (T) Proxy.newProxyInstance(\n          failoverProxyProvider.getInterface().getClassLoader(),\n          new Class[] { xface }, dummyHandler);\n      Text dtService \u003d HAUtil.buildTokenServiceForLogicalUri(nameNodeUri);\n      return new ProxyAndInfo\u003cT\u003e(proxy, dtService);\n    } else {\n      throw new IllegalStateException(\"Currently creating proxy using \" +\n      \t\t\"LossyRetryInvocationHandler requires NN HA setup\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/NameNodeProxies.java"
    }
  }
}