{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "PendingRecoveryBlocks.java",
  "functionName": "add",
  "functionId": "add___block-BlockInfo",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/PendingRecoveryBlocks.java",
  "functionStartLine": 63,
  "functionEndLine": 84,
  "numCommitsSeen": 3,
  "timeTaken": 1426,
  "changeHistory": [
    "42307e3c3abbfe0b83d9a2581deba327435b910f"
  ],
  "changeHistoryShort": {
    "42307e3c3abbfe0b83d9a2581deba327435b910f": "Yintroduced"
  },
  "changeHistoryDetails": {
    "42307e3c3abbfe0b83d9a2581deba327435b910f": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11576. Block recovery will fail indefinitely if recovery time \u003e heartbeat interval. Contributed by Lukas Majercak\n",
      "commitDate": "01/12/17 10:34 PM",
      "commitName": "42307e3c3abbfe0b83d9a2581deba327435b910f",
      "commitAuthor": "Chris Douglas",
      "diff": "@@ -0,0 +1,22 @@\n+  synchronized boolean add(BlockInfo block) {\n+    boolean added \u003d false;\n+    long curTime \u003d getTime();\n+    BlockRecoveryAttempt recoveryAttempt \u003d\n+        recoveryTimeouts.getElement(new BlockRecoveryAttempt(block));\n+\n+    if (recoveryAttempt \u003d\u003d null) {\n+      BlockRecoveryAttempt newAttempt \u003d new BlockRecoveryAttempt(\n+          block, curTime + recoveryTimeoutInterval);\n+      added \u003d recoveryTimeouts.add(newAttempt);\n+    } else if (recoveryAttempt.hasTimedOut(curTime)) {\n+      // Previous attempt timed out, reset the timeout\n+      recoveryAttempt.setTimeout(curTime + recoveryTimeoutInterval);\n+      added \u003d true;\n+    } else {\n+      long timeoutIn \u003d TimeUnit.MILLISECONDS.toSeconds(\n+          recoveryAttempt.timeoutAt - curTime);\n+      LOG.info(\"Block recovery attempt for \" + block + \" rejected, as the \" +\n+          \"previous attempt times out in \" + timeoutIn + \" seconds.\");\n+    }\n+    return added;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  synchronized boolean add(BlockInfo block) {\n    boolean added \u003d false;\n    long curTime \u003d getTime();\n    BlockRecoveryAttempt recoveryAttempt \u003d\n        recoveryTimeouts.getElement(new BlockRecoveryAttempt(block));\n\n    if (recoveryAttempt \u003d\u003d null) {\n      BlockRecoveryAttempt newAttempt \u003d new BlockRecoveryAttempt(\n          block, curTime + recoveryTimeoutInterval);\n      added \u003d recoveryTimeouts.add(newAttempt);\n    } else if (recoveryAttempt.hasTimedOut(curTime)) {\n      // Previous attempt timed out, reset the timeout\n      recoveryAttempt.setTimeout(curTime + recoveryTimeoutInterval);\n      added \u003d true;\n    } else {\n      long timeoutIn \u003d TimeUnit.MILLISECONDS.toSeconds(\n          recoveryAttempt.timeoutAt - curTime);\n      LOG.info(\"Block recovery attempt for \" + block + \" rejected, as the \" +\n          \"previous attempt times out in \" + timeoutIn + \" seconds.\");\n    }\n    return added;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/PendingRecoveryBlocks.java"
    }
  }
}