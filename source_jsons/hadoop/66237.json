{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "SLSRunner.java",
  "functionName": "startNM",
  "functionId": "startNM",
  "sourceFilePath": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
  "functionStartLine": 330,
  "functionEndLine": 406,
  "numCommitsSeen": 40,
  "timeTaken": 4251,
  "changeHistory": [
    "3d41f330186f6481850b46e0c345d3ecf7b1b818",
    "a92b7a5491ea5f0f98297f216fe7d27d2378a85e",
    "9fea5c9ee76bd36f273ae93afef5f3ef3c477a53",
    "fd24fd0ff771a6cba3097179fbb040d3b4f2a2d1",
    "78860372bd8048168c6aa27a9526c40f5869cf2c",
    "7af4f34de54f6e667b47374e31fc9328eba869f0",
    "ba8136615ab66c450884614557eddc6509d63b7c",
    "3082552b3b991df846caf572b58e44308ddf8eeb",
    "de69d6e81128470dd5d2fd865d4b3a79188f740b",
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b"
  ],
  "changeHistoryShort": {
    "3d41f330186f6481850b46e0c345d3ecf7b1b818": "Ybodychange",
    "a92b7a5491ea5f0f98297f216fe7d27d2378a85e": "Ybodychange",
    "9fea5c9ee76bd36f273ae93afef5f3ef3c477a53": "Ybodychange",
    "fd24fd0ff771a6cba3097179fbb040d3b4f2a2d1": "Ymultichange(Yexceptionschange,Ybodychange)",
    "78860372bd8048168c6aa27a9526c40f5869cf2c": "Ybodychange",
    "7af4f34de54f6e667b47374e31fc9328eba869f0": "Ybodychange",
    "ba8136615ab66c450884614557eddc6509d63b7c": "Ybodychange",
    "3082552b3b991df846caf572b58e44308ddf8eeb": "Ybodychange",
    "de69d6e81128470dd5d2fd865d4b3a79188f740b": "Ybodychange",
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b": "Yintroduced"
  },
  "changeHistoryDetails": {
    "3d41f330186f6481850b46e0c345d3ecf7b1b818": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16152. Upgrade Eclipse Jetty version to 9.4.x. Contributed by Yuming Wang, Siyao Meng.\n\nCo-authored-By: Siyao Meng \u003csmeng@cloudera.com\u003e\nSigned-off-by: Wei-Chiu Chuang \u003cweichiu@apache.org\u003e\n",
      "commitDate": "18/10/19 8:25 AM",
      "commitName": "3d41f330186f6481850b46e0c345d3ecf7b1b818",
      "commitAuthor": "Yuming Wang",
      "commitDateOld": "04/10/19 2:15 AM",
      "commitNameOld": "2478cbafe6deaf3a190360120234610d6208394b",
      "commitAuthorOld": "Abhishek Modi",
      "daysBetweenCommits": 14.26,
      "commitsBetweenForRepo": 84,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,77 +1,77 @@\n   private void startNM() throws YarnException, IOException,\n       InterruptedException {\n     // nm configuration\n     int heartbeatInterval \u003d getConf().getInt(\n         SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n         SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n     float resourceUtilizationRatio \u003d getConf().getFloat(\n         SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO,\n         SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO_DEFAULT);\n     // nm information (fetch from topology file, or from sls/rumen json file)\n     Set\u003cNodeDetails\u003e nodeSet \u003d null;\n     if (nodeFile.isEmpty()) {\n       for (String inputTrace : inputTraces) {\n         switch (inputType) {\n         case SLS:\n           nodeSet \u003d SLSUtils.parseNodesFromSLSTrace(inputTrace);\n           break;\n         case RUMEN:\n           nodeSet \u003d SLSUtils.parseNodesFromRumenTrace(inputTrace);\n           break;\n         case SYNTH:\n           stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n           nodeSet \u003d SLSUtils.generateNodes(stjp.getNumNodes(),\n               stjp.getNumNodes()/stjp.getNodesPerRack());\n           break;\n         default:\n           throw new YarnException(\"Input configuration not recognized, \"\n               + \"trace type should be SLS, RUMEN, or SYNTH\");\n         }\n       }\n     } else {\n       nodeSet \u003d SLSUtils.parseNodesFromNodeFile(nodeFile,\n           nodeManagerResource);\n     }\n \n     if (nodeSet \u003d\u003d null || nodeSet.isEmpty()) {\n       throw new YarnException(\"No node! Please configure nodes.\");\n     }\n \n     SLSUtils.generateNodeTableMapping(nodeSet, tableMapping);\n \n     // create NM simulators\n     Random random \u003d new Random();\n-    Set\u003cString\u003e rackSet \u003d new ConcurrentHashSet\u003c\u003e();\n+    Set\u003cString\u003e rackSet \u003d ConcurrentHashMap.newKeySet();\n     int threadPoolSize \u003d Math.max(poolSize,\n         SLSConfiguration.RUNNER_POOL_SIZE_DEFAULT);\n     ExecutorService executorService \u003d Executors.\n         newFixedThreadPool(threadPoolSize);\n     for (NodeDetails nodeDetails : nodeSet) {\n       executorService.submit(new Runnable() {\n         @Override public void run() {\n           try {\n             // we randomize the heartbeat start time from zero to 1 interval\n             NMSimulator nm \u003d new NMSimulator();\n             Resource nmResource \u003d nodeManagerResource;\n             String hostName \u003d nodeDetails.getHostname();\n             if (nodeDetails.getNodeResource() !\u003d null) {\n               nmResource \u003d nodeDetails.getNodeResource();\n             }\n             Set\u003cNodeLabel\u003e nodeLabels \u003d nodeDetails.getLabels();\n             nm.init(hostName, nmResource,\n                 random.nextInt(heartbeatInterval),\n                 heartbeatInterval, rm, resourceUtilizationRatio, nodeLabels);\n             nmMap.put(nm.getNode().getNodeID(), nm);\n             runner.schedule(nm);\n             rackSet.add(nm.getNode().getRackName());\n           } catch (IOException | YarnException e) {\n             LOG.error(\"Got an error while adding node\", e);\n           }\n         }\n       });\n     }\n     executorService.shutdown();\n     executorService.awaitTermination(10, TimeUnit.MINUTES);\n     numRacks \u003d rackSet.size();\n     numNMs \u003d nmMap.size();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startNM() throws YarnException, IOException,\n      InterruptedException {\n    // nm configuration\n    int heartbeatInterval \u003d getConf().getInt(\n        SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n        SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n    float resourceUtilizationRatio \u003d getConf().getFloat(\n        SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO,\n        SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO_DEFAULT);\n    // nm information (fetch from topology file, or from sls/rumen json file)\n    Set\u003cNodeDetails\u003e nodeSet \u003d null;\n    if (nodeFile.isEmpty()) {\n      for (String inputTrace : inputTraces) {\n        switch (inputType) {\n        case SLS:\n          nodeSet \u003d SLSUtils.parseNodesFromSLSTrace(inputTrace);\n          break;\n        case RUMEN:\n          nodeSet \u003d SLSUtils.parseNodesFromRumenTrace(inputTrace);\n          break;\n        case SYNTH:\n          stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n          nodeSet \u003d SLSUtils.generateNodes(stjp.getNumNodes(),\n              stjp.getNumNodes()/stjp.getNodesPerRack());\n          break;\n        default:\n          throw new YarnException(\"Input configuration not recognized, \"\n              + \"trace type should be SLS, RUMEN, or SYNTH\");\n        }\n      }\n    } else {\n      nodeSet \u003d SLSUtils.parseNodesFromNodeFile(nodeFile,\n          nodeManagerResource);\n    }\n\n    if (nodeSet \u003d\u003d null || nodeSet.isEmpty()) {\n      throw new YarnException(\"No node! Please configure nodes.\");\n    }\n\n    SLSUtils.generateNodeTableMapping(nodeSet, tableMapping);\n\n    // create NM simulators\n    Random random \u003d new Random();\n    Set\u003cString\u003e rackSet \u003d ConcurrentHashMap.newKeySet();\n    int threadPoolSize \u003d Math.max(poolSize,\n        SLSConfiguration.RUNNER_POOL_SIZE_DEFAULT);\n    ExecutorService executorService \u003d Executors.\n        newFixedThreadPool(threadPoolSize);\n    for (NodeDetails nodeDetails : nodeSet) {\n      executorService.submit(new Runnable() {\n        @Override public void run() {\n          try {\n            // we randomize the heartbeat start time from zero to 1 interval\n            NMSimulator nm \u003d new NMSimulator();\n            Resource nmResource \u003d nodeManagerResource;\n            String hostName \u003d nodeDetails.getHostname();\n            if (nodeDetails.getNodeResource() !\u003d null) {\n              nmResource \u003d nodeDetails.getNodeResource();\n            }\n            Set\u003cNodeLabel\u003e nodeLabels \u003d nodeDetails.getLabels();\n            nm.init(hostName, nmResource,\n                random.nextInt(heartbeatInterval),\n                heartbeatInterval, rm, resourceUtilizationRatio, nodeLabels);\n            nmMap.put(nm.getNode().getNodeID(), nm);\n            runner.schedule(nm);\n            rackSet.add(nm.getNode().getRackName());\n          } catch (IOException | YarnException e) {\n            LOG.error(\"Got an error while adding node\", e);\n          }\n        }\n      });\n    }\n    executorService.shutdown();\n    executorService.awaitTermination(10, TimeUnit.MINUTES);\n    numRacks \u003d rackSet.size();\n    numNMs \u003d nmMap.size();\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "a92b7a5491ea5f0f98297f216fe7d27d2378a85e": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9694. UI always show default-rack for all the nodes while running SLS.\n",
      "commitDate": "08/08/19 11:11 PM",
      "commitName": "a92b7a5491ea5f0f98297f216fe7d27d2378a85e",
      "commitAuthor": "Abhishek Modi",
      "commitDateOld": "14/02/19 9:26 AM",
      "commitNameOld": "134ae8fc8045e2ae1ed7ca54df95f14ffc863d09",
      "commitAuthorOld": "bibinchundatt",
      "daysBetweenCommits": 175.53,
      "commitsBetweenForRepo": 1321,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,75 +1,77 @@\n   private void startNM() throws YarnException, IOException,\n       InterruptedException {\n     // nm configuration\n     int heartbeatInterval \u003d getConf().getInt(\n         SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n         SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n     float resourceUtilizationRatio \u003d getConf().getFloat(\n         SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO,\n         SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO_DEFAULT);\n     // nm information (fetch from topology file, or from sls/rumen json file)\n     Set\u003cNodeDetails\u003e nodeSet \u003d null;\n     if (nodeFile.isEmpty()) {\n       for (String inputTrace : inputTraces) {\n         switch (inputType) {\n         case SLS:\n           nodeSet \u003d SLSUtils.parseNodesFromSLSTrace(inputTrace);\n           break;\n         case RUMEN:\n           nodeSet \u003d SLSUtils.parseNodesFromRumenTrace(inputTrace);\n           break;\n         case SYNTH:\n           stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n           nodeSet \u003d SLSUtils.generateNodes(stjp.getNumNodes(),\n               stjp.getNumNodes()/stjp.getNodesPerRack());\n           break;\n         default:\n           throw new YarnException(\"Input configuration not recognized, \"\n               + \"trace type should be SLS, RUMEN, or SYNTH\");\n         }\n       }\n     } else {\n       nodeSet \u003d SLSUtils.parseNodesFromNodeFile(nodeFile,\n           nodeManagerResource);\n     }\n \n     if (nodeSet \u003d\u003d null || nodeSet.isEmpty()) {\n       throw new YarnException(\"No node! Please configure nodes.\");\n     }\n \n+    SLSUtils.generateNodeTableMapping(nodeSet, tableMapping);\n+\n     // create NM simulators\n     Random random \u003d new Random();\n     Set\u003cString\u003e rackSet \u003d new ConcurrentHashSet\u003c\u003e();\n     int threadPoolSize \u003d Math.max(poolSize,\n         SLSConfiguration.RUNNER_POOL_SIZE_DEFAULT);\n     ExecutorService executorService \u003d Executors.\n         newFixedThreadPool(threadPoolSize);\n     for (NodeDetails nodeDetails : nodeSet) {\n       executorService.submit(new Runnable() {\n         @Override public void run() {\n           try {\n             // we randomize the heartbeat start time from zero to 1 interval\n             NMSimulator nm \u003d new NMSimulator();\n             Resource nmResource \u003d nodeManagerResource;\n             String hostName \u003d nodeDetails.getHostname();\n             if (nodeDetails.getNodeResource() !\u003d null) {\n               nmResource \u003d nodeDetails.getNodeResource();\n             }\n             Set\u003cNodeLabel\u003e nodeLabels \u003d nodeDetails.getLabels();\n             nm.init(hostName, nmResource,\n                 random.nextInt(heartbeatInterval),\n                 heartbeatInterval, rm, resourceUtilizationRatio, nodeLabels);\n             nmMap.put(nm.getNode().getNodeID(), nm);\n             runner.schedule(nm);\n             rackSet.add(nm.getNode().getRackName());\n           } catch (IOException | YarnException e) {\n             LOG.error(\"Got an error while adding node\", e);\n           }\n         }\n       });\n     }\n     executorService.shutdown();\n     executorService.awaitTermination(10, TimeUnit.MINUTES);\n     numRacks \u003d rackSet.size();\n     numNMs \u003d nmMap.size();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startNM() throws YarnException, IOException,\n      InterruptedException {\n    // nm configuration\n    int heartbeatInterval \u003d getConf().getInt(\n        SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n        SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n    float resourceUtilizationRatio \u003d getConf().getFloat(\n        SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO,\n        SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO_DEFAULT);\n    // nm information (fetch from topology file, or from sls/rumen json file)\n    Set\u003cNodeDetails\u003e nodeSet \u003d null;\n    if (nodeFile.isEmpty()) {\n      for (String inputTrace : inputTraces) {\n        switch (inputType) {\n        case SLS:\n          nodeSet \u003d SLSUtils.parseNodesFromSLSTrace(inputTrace);\n          break;\n        case RUMEN:\n          nodeSet \u003d SLSUtils.parseNodesFromRumenTrace(inputTrace);\n          break;\n        case SYNTH:\n          stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n          nodeSet \u003d SLSUtils.generateNodes(stjp.getNumNodes(),\n              stjp.getNumNodes()/stjp.getNodesPerRack());\n          break;\n        default:\n          throw new YarnException(\"Input configuration not recognized, \"\n              + \"trace type should be SLS, RUMEN, or SYNTH\");\n        }\n      }\n    } else {\n      nodeSet \u003d SLSUtils.parseNodesFromNodeFile(nodeFile,\n          nodeManagerResource);\n    }\n\n    if (nodeSet \u003d\u003d null || nodeSet.isEmpty()) {\n      throw new YarnException(\"No node! Please configure nodes.\");\n    }\n\n    SLSUtils.generateNodeTableMapping(nodeSet, tableMapping);\n\n    // create NM simulators\n    Random random \u003d new Random();\n    Set\u003cString\u003e rackSet \u003d new ConcurrentHashSet\u003c\u003e();\n    int threadPoolSize \u003d Math.max(poolSize,\n        SLSConfiguration.RUNNER_POOL_SIZE_DEFAULT);\n    ExecutorService executorService \u003d Executors.\n        newFixedThreadPool(threadPoolSize);\n    for (NodeDetails nodeDetails : nodeSet) {\n      executorService.submit(new Runnable() {\n        @Override public void run() {\n          try {\n            // we randomize the heartbeat start time from zero to 1 interval\n            NMSimulator nm \u003d new NMSimulator();\n            Resource nmResource \u003d nodeManagerResource;\n            String hostName \u003d nodeDetails.getHostname();\n            if (nodeDetails.getNodeResource() !\u003d null) {\n              nmResource \u003d nodeDetails.getNodeResource();\n            }\n            Set\u003cNodeLabel\u003e nodeLabels \u003d nodeDetails.getLabels();\n            nm.init(hostName, nmResource,\n                random.nextInt(heartbeatInterval),\n                heartbeatInterval, rm, resourceUtilizationRatio, nodeLabels);\n            nmMap.put(nm.getNode().getNodeID(), nm);\n            runner.schedule(nm);\n            rackSet.add(nm.getNode().getRackName());\n          } catch (IOException | YarnException e) {\n            LOG.error(\"Got an error while adding node\", e);\n          }\n        }\n      });\n    }\n    executorService.shutdown();\n    executorService.awaitTermination(10, TimeUnit.MINUTES);\n    numRacks \u003d rackSet.size();\n    numNMs \u003d nmMap.size();\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "9fea5c9ee76bd36f273ae93afef5f3ef3c477a53": {
      "type": "Ybodychange",
      "commitMessage": "YARN-8175. Add support for Node Labels in SLS. Contributed by Abhishek Modi.\n",
      "commitDate": "31/07/18 9:36 AM",
      "commitName": "9fea5c9ee76bd36f273ae93afef5f3ef3c477a53",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "26/04/18 1:52 PM",
      "commitNameOld": "2adda92de1535c0472c0df33a145fa1814703f4f",
      "commitAuthorOld": "Owen O\u0027Malley",
      "daysBetweenCommits": 95.82,
      "commitsBetweenForRepo": 689,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,84 +1,75 @@\n   private void startNM() throws YarnException, IOException,\n       InterruptedException {\n     // nm configuration\n     int heartbeatInterval \u003d getConf().getInt(\n         SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n         SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n     float resourceUtilizationRatio \u003d getConf().getFloat(\n         SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO,\n         SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO_DEFAULT);\n     // nm information (fetch from topology file, or from sls/rumen json file)\n-    Map\u003cString, Resource\u003e nodeResourceMap \u003d new HashMap\u003c\u003e();\n-    Set\u003c? extends  String\u003e nodeSet;\n+    Set\u003cNodeDetails\u003e nodeSet \u003d null;\n     if (nodeFile.isEmpty()) {\n       for (String inputTrace : inputTraces) {\n         switch (inputType) {\n         case SLS:\n           nodeSet \u003d SLSUtils.parseNodesFromSLSTrace(inputTrace);\n-          for (String node : nodeSet) {\n-            nodeResourceMap.put(node, null);\n-          }\n           break;\n         case RUMEN:\n           nodeSet \u003d SLSUtils.parseNodesFromRumenTrace(inputTrace);\n-          for (String node : nodeSet) {\n-            nodeResourceMap.put(node, null);\n-          }\n           break;\n         case SYNTH:\n           stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n           nodeSet \u003d SLSUtils.generateNodes(stjp.getNumNodes(),\n               stjp.getNumNodes()/stjp.getNodesPerRack());\n-          for (String node : nodeSet) {\n-            nodeResourceMap.put(node, null);\n-          }\n           break;\n         default:\n           throw new YarnException(\"Input configuration not recognized, \"\n               + \"trace type should be SLS, RUMEN, or SYNTH\");\n         }\n       }\n     } else {\n-      nodeResourceMap \u003d SLSUtils.parseNodesFromNodeFile(nodeFile,\n+      nodeSet \u003d SLSUtils.parseNodesFromNodeFile(nodeFile,\n           nodeManagerResource);\n     }\n \n-    if (nodeResourceMap.size() \u003d\u003d 0) {\n+    if (nodeSet \u003d\u003d null || nodeSet.isEmpty()) {\n       throw new YarnException(\"No node! Please configure nodes.\");\n     }\n \n     // create NM simulators\n     Random random \u003d new Random();\n     Set\u003cString\u003e rackSet \u003d new ConcurrentHashSet\u003c\u003e();\n     int threadPoolSize \u003d Math.max(poolSize,\n         SLSConfiguration.RUNNER_POOL_SIZE_DEFAULT);\n     ExecutorService executorService \u003d Executors.\n         newFixedThreadPool(threadPoolSize);\n-    for (Map.Entry\u003cString, Resource\u003e entry : nodeResourceMap.entrySet()) {\n+    for (NodeDetails nodeDetails : nodeSet) {\n       executorService.submit(new Runnable() {\n         @Override public void run() {\n           try {\n             // we randomize the heartbeat start time from zero to 1 interval\n             NMSimulator nm \u003d new NMSimulator();\n             Resource nmResource \u003d nodeManagerResource;\n-            String hostName \u003d entry.getKey();\n-            if (entry.getValue() !\u003d null) {\n-              nmResource \u003d entry.getValue();\n+            String hostName \u003d nodeDetails.getHostname();\n+            if (nodeDetails.getNodeResource() !\u003d null) {\n+              nmResource \u003d nodeDetails.getNodeResource();\n             }\n+            Set\u003cNodeLabel\u003e nodeLabels \u003d nodeDetails.getLabels();\n             nm.init(hostName, nmResource,\n                 random.nextInt(heartbeatInterval),\n-                heartbeatInterval, rm, resourceUtilizationRatio);\n+                heartbeatInterval, rm, resourceUtilizationRatio, nodeLabels);\n             nmMap.put(nm.getNode().getNodeID(), nm);\n             runner.schedule(nm);\n             rackSet.add(nm.getNode().getRackName());\n           } catch (IOException | YarnException e) {\n             LOG.error(\"Got an error while adding node\", e);\n           }\n         }\n       });\n     }\n     executorService.shutdown();\n     executorService.awaitTermination(10, TimeUnit.MINUTES);\n     numRacks \u003d rackSet.size();\n     numNMs \u003d nmMap.size();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startNM() throws YarnException, IOException,\n      InterruptedException {\n    // nm configuration\n    int heartbeatInterval \u003d getConf().getInt(\n        SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n        SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n    float resourceUtilizationRatio \u003d getConf().getFloat(\n        SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO,\n        SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO_DEFAULT);\n    // nm information (fetch from topology file, or from sls/rumen json file)\n    Set\u003cNodeDetails\u003e nodeSet \u003d null;\n    if (nodeFile.isEmpty()) {\n      for (String inputTrace : inputTraces) {\n        switch (inputType) {\n        case SLS:\n          nodeSet \u003d SLSUtils.parseNodesFromSLSTrace(inputTrace);\n          break;\n        case RUMEN:\n          nodeSet \u003d SLSUtils.parseNodesFromRumenTrace(inputTrace);\n          break;\n        case SYNTH:\n          stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n          nodeSet \u003d SLSUtils.generateNodes(stjp.getNumNodes(),\n              stjp.getNumNodes()/stjp.getNodesPerRack());\n          break;\n        default:\n          throw new YarnException(\"Input configuration not recognized, \"\n              + \"trace type should be SLS, RUMEN, or SYNTH\");\n        }\n      }\n    } else {\n      nodeSet \u003d SLSUtils.parseNodesFromNodeFile(nodeFile,\n          nodeManagerResource);\n    }\n\n    if (nodeSet \u003d\u003d null || nodeSet.isEmpty()) {\n      throw new YarnException(\"No node! Please configure nodes.\");\n    }\n\n    // create NM simulators\n    Random random \u003d new Random();\n    Set\u003cString\u003e rackSet \u003d new ConcurrentHashSet\u003c\u003e();\n    int threadPoolSize \u003d Math.max(poolSize,\n        SLSConfiguration.RUNNER_POOL_SIZE_DEFAULT);\n    ExecutorService executorService \u003d Executors.\n        newFixedThreadPool(threadPoolSize);\n    for (NodeDetails nodeDetails : nodeSet) {\n      executorService.submit(new Runnable() {\n        @Override public void run() {\n          try {\n            // we randomize the heartbeat start time from zero to 1 interval\n            NMSimulator nm \u003d new NMSimulator();\n            Resource nmResource \u003d nodeManagerResource;\n            String hostName \u003d nodeDetails.getHostname();\n            if (nodeDetails.getNodeResource() !\u003d null) {\n              nmResource \u003d nodeDetails.getNodeResource();\n            }\n            Set\u003cNodeLabel\u003e nodeLabels \u003d nodeDetails.getLabels();\n            nm.init(hostName, nmResource,\n                random.nextInt(heartbeatInterval),\n                heartbeatInterval, rm, resourceUtilizationRatio, nodeLabels);\n            nmMap.put(nm.getNode().getNodeID(), nm);\n            runner.schedule(nm);\n            rackSet.add(nm.getNode().getRackName());\n          } catch (IOException | YarnException e) {\n            LOG.error(\"Got an error while adding node\", e);\n          }\n        }\n      });\n    }\n    executorService.shutdown();\n    executorService.awaitTermination(10, TimeUnit.MINUTES);\n    numRacks \u003d rackSet.size();\n    numNMs \u003d nmMap.size();\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "fd24fd0ff771a6cba3097179fbb040d3b4f2a2d1": {
      "type": "Ymultichange(Yexceptionschange,Ybodychange)",
      "commitMessage": "YARN-8137. Parallelize node addition in SLS. Contributed by Abhishek Modi.\n",
      "commitDate": "20/04/18 9:09 AM",
      "commitName": "fd24fd0ff771a6cba3097179fbb040d3b4f2a2d1",
      "commitAuthor": "Inigo Goiri",
      "subchanges": [
        {
          "type": "Yexceptionschange",
          "commitMessage": "YARN-8137. Parallelize node addition in SLS. Contributed by Abhishek Modi.\n",
          "commitDate": "20/04/18 9:09 AM",
          "commitName": "fd24fd0ff771a6cba3097179fbb040d3b4f2a2d1",
          "commitAuthor": "Inigo Goiri",
          "commitDateOld": "17/04/18 1:11 PM",
          "commitNameOld": "78860372bd8048168c6aa27a9526c40f5869cf2c",
          "commitAuthorOld": "Inigo Goiri",
          "daysBetweenCommits": 2.83,
          "commitsBetweenForRepo": 21,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,68 +1,84 @@\n-  private void startNM() throws YarnException, IOException {\n+  private void startNM() throws YarnException, IOException,\n+      InterruptedException {\n     // nm configuration\n     int heartbeatInterval \u003d getConf().getInt(\n         SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n         SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n     float resourceUtilizationRatio \u003d getConf().getFloat(\n         SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO,\n         SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO_DEFAULT);\n     // nm information (fetch from topology file, or from sls/rumen json file)\n     Map\u003cString, Resource\u003e nodeResourceMap \u003d new HashMap\u003c\u003e();\n     Set\u003c? extends  String\u003e nodeSet;\n     if (nodeFile.isEmpty()) {\n       for (String inputTrace : inputTraces) {\n         switch (inputType) {\n         case SLS:\n           nodeSet \u003d SLSUtils.parseNodesFromSLSTrace(inputTrace);\n           for (String node : nodeSet) {\n             nodeResourceMap.put(node, null);\n           }\n           break;\n         case RUMEN:\n           nodeSet \u003d SLSUtils.parseNodesFromRumenTrace(inputTrace);\n           for (String node : nodeSet) {\n             nodeResourceMap.put(node, null);\n           }\n           break;\n         case SYNTH:\n           stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n           nodeSet \u003d SLSUtils.generateNodes(stjp.getNumNodes(),\n               stjp.getNumNodes()/stjp.getNodesPerRack());\n           for (String node : nodeSet) {\n             nodeResourceMap.put(node, null);\n           }\n           break;\n         default:\n           throw new YarnException(\"Input configuration not recognized, \"\n               + \"trace type should be SLS, RUMEN, or SYNTH\");\n         }\n       }\n     } else {\n       nodeResourceMap \u003d SLSUtils.parseNodesFromNodeFile(nodeFile,\n           nodeManagerResource);\n     }\n \n     if (nodeResourceMap.size() \u003d\u003d 0) {\n       throw new YarnException(\"No node! Please configure nodes.\");\n     }\n \n     // create NM simulators\n     Random random \u003d new Random();\n-    Set\u003cString\u003e rackSet \u003d new HashSet\u003cString\u003e();\n+    Set\u003cString\u003e rackSet \u003d new ConcurrentHashSet\u003c\u003e();\n+    int threadPoolSize \u003d Math.max(poolSize,\n+        SLSConfiguration.RUNNER_POOL_SIZE_DEFAULT);\n+    ExecutorService executorService \u003d Executors.\n+        newFixedThreadPool(threadPoolSize);\n     for (Map.Entry\u003cString, Resource\u003e entry : nodeResourceMap.entrySet()) {\n-      // we randomize the heartbeat start time from zero to 1 interval\n-      NMSimulator nm \u003d new NMSimulator();\n-      Resource nmResource \u003d nodeManagerResource;\n-      String hostName \u003d entry.getKey();\n-      if (entry.getValue() !\u003d null) {\n-        nmResource \u003d entry.getValue();\n-      }\n-      nm.init(hostName, nmResource, random.nextInt(heartbeatInterval),\n-          heartbeatInterval, rm, resourceUtilizationRatio);\n-      nmMap.put(nm.getNode().getNodeID(), nm);\n-      runner.schedule(nm);\n-      rackSet.add(nm.getNode().getRackName());\n+      executorService.submit(new Runnable() {\n+        @Override public void run() {\n+          try {\n+            // we randomize the heartbeat start time from zero to 1 interval\n+            NMSimulator nm \u003d new NMSimulator();\n+            Resource nmResource \u003d nodeManagerResource;\n+            String hostName \u003d entry.getKey();\n+            if (entry.getValue() !\u003d null) {\n+              nmResource \u003d entry.getValue();\n+            }\n+            nm.init(hostName, nmResource,\n+                random.nextInt(heartbeatInterval),\n+                heartbeatInterval, rm, resourceUtilizationRatio);\n+            nmMap.put(nm.getNode().getNodeID(), nm);\n+            runner.schedule(nm);\n+            rackSet.add(nm.getNode().getRackName());\n+          } catch (IOException | YarnException e) {\n+            LOG.error(\"Got an error while adding node\", e);\n+          }\n+        }\n+      });\n     }\n+    executorService.shutdown();\n+    executorService.awaitTermination(10, TimeUnit.MINUTES);\n     numRacks \u003d rackSet.size();\n     numNMs \u003d nmMap.size();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void startNM() throws YarnException, IOException,\n      InterruptedException {\n    // nm configuration\n    int heartbeatInterval \u003d getConf().getInt(\n        SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n        SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n    float resourceUtilizationRatio \u003d getConf().getFloat(\n        SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO,\n        SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO_DEFAULT);\n    // nm information (fetch from topology file, or from sls/rumen json file)\n    Map\u003cString, Resource\u003e nodeResourceMap \u003d new HashMap\u003c\u003e();\n    Set\u003c? extends  String\u003e nodeSet;\n    if (nodeFile.isEmpty()) {\n      for (String inputTrace : inputTraces) {\n        switch (inputType) {\n        case SLS:\n          nodeSet \u003d SLSUtils.parseNodesFromSLSTrace(inputTrace);\n          for (String node : nodeSet) {\n            nodeResourceMap.put(node, null);\n          }\n          break;\n        case RUMEN:\n          nodeSet \u003d SLSUtils.parseNodesFromRumenTrace(inputTrace);\n          for (String node : nodeSet) {\n            nodeResourceMap.put(node, null);\n          }\n          break;\n        case SYNTH:\n          stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n          nodeSet \u003d SLSUtils.generateNodes(stjp.getNumNodes(),\n              stjp.getNumNodes()/stjp.getNodesPerRack());\n          for (String node : nodeSet) {\n            nodeResourceMap.put(node, null);\n          }\n          break;\n        default:\n          throw new YarnException(\"Input configuration not recognized, \"\n              + \"trace type should be SLS, RUMEN, or SYNTH\");\n        }\n      }\n    } else {\n      nodeResourceMap \u003d SLSUtils.parseNodesFromNodeFile(nodeFile,\n          nodeManagerResource);\n    }\n\n    if (nodeResourceMap.size() \u003d\u003d 0) {\n      throw new YarnException(\"No node! Please configure nodes.\");\n    }\n\n    // create NM simulators\n    Random random \u003d new Random();\n    Set\u003cString\u003e rackSet \u003d new ConcurrentHashSet\u003c\u003e();\n    int threadPoolSize \u003d Math.max(poolSize,\n        SLSConfiguration.RUNNER_POOL_SIZE_DEFAULT);\n    ExecutorService executorService \u003d Executors.\n        newFixedThreadPool(threadPoolSize);\n    for (Map.Entry\u003cString, Resource\u003e entry : nodeResourceMap.entrySet()) {\n      executorService.submit(new Runnable() {\n        @Override public void run() {\n          try {\n            // we randomize the heartbeat start time from zero to 1 interval\n            NMSimulator nm \u003d new NMSimulator();\n            Resource nmResource \u003d nodeManagerResource;\n            String hostName \u003d entry.getKey();\n            if (entry.getValue() !\u003d null) {\n              nmResource \u003d entry.getValue();\n            }\n            nm.init(hostName, nmResource,\n                random.nextInt(heartbeatInterval),\n                heartbeatInterval, rm, resourceUtilizationRatio);\n            nmMap.put(nm.getNode().getNodeID(), nm);\n            runner.schedule(nm);\n            rackSet.add(nm.getNode().getRackName());\n          } catch (IOException | YarnException e) {\n            LOG.error(\"Got an error while adding node\", e);\n          }\n        }\n      });\n    }\n    executorService.shutdown();\n    executorService.awaitTermination(10, TimeUnit.MINUTES);\n    numRacks \u003d rackSet.size();\n    numNMs \u003d nmMap.size();\n  }",
          "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
          "extendedDetails": {
            "oldValue": "[YarnException, IOException]",
            "newValue": "[YarnException, IOException, InterruptedException]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "YARN-8137. Parallelize node addition in SLS. Contributed by Abhishek Modi.\n",
          "commitDate": "20/04/18 9:09 AM",
          "commitName": "fd24fd0ff771a6cba3097179fbb040d3b4f2a2d1",
          "commitAuthor": "Inigo Goiri",
          "commitDateOld": "17/04/18 1:11 PM",
          "commitNameOld": "78860372bd8048168c6aa27a9526c40f5869cf2c",
          "commitAuthorOld": "Inigo Goiri",
          "daysBetweenCommits": 2.83,
          "commitsBetweenForRepo": 21,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,68 +1,84 @@\n-  private void startNM() throws YarnException, IOException {\n+  private void startNM() throws YarnException, IOException,\n+      InterruptedException {\n     // nm configuration\n     int heartbeatInterval \u003d getConf().getInt(\n         SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n         SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n     float resourceUtilizationRatio \u003d getConf().getFloat(\n         SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO,\n         SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO_DEFAULT);\n     // nm information (fetch from topology file, or from sls/rumen json file)\n     Map\u003cString, Resource\u003e nodeResourceMap \u003d new HashMap\u003c\u003e();\n     Set\u003c? extends  String\u003e nodeSet;\n     if (nodeFile.isEmpty()) {\n       for (String inputTrace : inputTraces) {\n         switch (inputType) {\n         case SLS:\n           nodeSet \u003d SLSUtils.parseNodesFromSLSTrace(inputTrace);\n           for (String node : nodeSet) {\n             nodeResourceMap.put(node, null);\n           }\n           break;\n         case RUMEN:\n           nodeSet \u003d SLSUtils.parseNodesFromRumenTrace(inputTrace);\n           for (String node : nodeSet) {\n             nodeResourceMap.put(node, null);\n           }\n           break;\n         case SYNTH:\n           stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n           nodeSet \u003d SLSUtils.generateNodes(stjp.getNumNodes(),\n               stjp.getNumNodes()/stjp.getNodesPerRack());\n           for (String node : nodeSet) {\n             nodeResourceMap.put(node, null);\n           }\n           break;\n         default:\n           throw new YarnException(\"Input configuration not recognized, \"\n               + \"trace type should be SLS, RUMEN, or SYNTH\");\n         }\n       }\n     } else {\n       nodeResourceMap \u003d SLSUtils.parseNodesFromNodeFile(nodeFile,\n           nodeManagerResource);\n     }\n \n     if (nodeResourceMap.size() \u003d\u003d 0) {\n       throw new YarnException(\"No node! Please configure nodes.\");\n     }\n \n     // create NM simulators\n     Random random \u003d new Random();\n-    Set\u003cString\u003e rackSet \u003d new HashSet\u003cString\u003e();\n+    Set\u003cString\u003e rackSet \u003d new ConcurrentHashSet\u003c\u003e();\n+    int threadPoolSize \u003d Math.max(poolSize,\n+        SLSConfiguration.RUNNER_POOL_SIZE_DEFAULT);\n+    ExecutorService executorService \u003d Executors.\n+        newFixedThreadPool(threadPoolSize);\n     for (Map.Entry\u003cString, Resource\u003e entry : nodeResourceMap.entrySet()) {\n-      // we randomize the heartbeat start time from zero to 1 interval\n-      NMSimulator nm \u003d new NMSimulator();\n-      Resource nmResource \u003d nodeManagerResource;\n-      String hostName \u003d entry.getKey();\n-      if (entry.getValue() !\u003d null) {\n-        nmResource \u003d entry.getValue();\n-      }\n-      nm.init(hostName, nmResource, random.nextInt(heartbeatInterval),\n-          heartbeatInterval, rm, resourceUtilizationRatio);\n-      nmMap.put(nm.getNode().getNodeID(), nm);\n-      runner.schedule(nm);\n-      rackSet.add(nm.getNode().getRackName());\n+      executorService.submit(new Runnable() {\n+        @Override public void run() {\n+          try {\n+            // we randomize the heartbeat start time from zero to 1 interval\n+            NMSimulator nm \u003d new NMSimulator();\n+            Resource nmResource \u003d nodeManagerResource;\n+            String hostName \u003d entry.getKey();\n+            if (entry.getValue() !\u003d null) {\n+              nmResource \u003d entry.getValue();\n+            }\n+            nm.init(hostName, nmResource,\n+                random.nextInt(heartbeatInterval),\n+                heartbeatInterval, rm, resourceUtilizationRatio);\n+            nmMap.put(nm.getNode().getNodeID(), nm);\n+            runner.schedule(nm);\n+            rackSet.add(nm.getNode().getRackName());\n+          } catch (IOException | YarnException e) {\n+            LOG.error(\"Got an error while adding node\", e);\n+          }\n+        }\n+      });\n     }\n+    executorService.shutdown();\n+    executorService.awaitTermination(10, TimeUnit.MINUTES);\n     numRacks \u003d rackSet.size();\n     numNMs \u003d nmMap.size();\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private void startNM() throws YarnException, IOException,\n      InterruptedException {\n    // nm configuration\n    int heartbeatInterval \u003d getConf().getInt(\n        SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n        SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n    float resourceUtilizationRatio \u003d getConf().getFloat(\n        SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO,\n        SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO_DEFAULT);\n    // nm information (fetch from topology file, or from sls/rumen json file)\n    Map\u003cString, Resource\u003e nodeResourceMap \u003d new HashMap\u003c\u003e();\n    Set\u003c? extends  String\u003e nodeSet;\n    if (nodeFile.isEmpty()) {\n      for (String inputTrace : inputTraces) {\n        switch (inputType) {\n        case SLS:\n          nodeSet \u003d SLSUtils.parseNodesFromSLSTrace(inputTrace);\n          for (String node : nodeSet) {\n            nodeResourceMap.put(node, null);\n          }\n          break;\n        case RUMEN:\n          nodeSet \u003d SLSUtils.parseNodesFromRumenTrace(inputTrace);\n          for (String node : nodeSet) {\n            nodeResourceMap.put(node, null);\n          }\n          break;\n        case SYNTH:\n          stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n          nodeSet \u003d SLSUtils.generateNodes(stjp.getNumNodes(),\n              stjp.getNumNodes()/stjp.getNodesPerRack());\n          for (String node : nodeSet) {\n            nodeResourceMap.put(node, null);\n          }\n          break;\n        default:\n          throw new YarnException(\"Input configuration not recognized, \"\n              + \"trace type should be SLS, RUMEN, or SYNTH\");\n        }\n      }\n    } else {\n      nodeResourceMap \u003d SLSUtils.parseNodesFromNodeFile(nodeFile,\n          nodeManagerResource);\n    }\n\n    if (nodeResourceMap.size() \u003d\u003d 0) {\n      throw new YarnException(\"No node! Please configure nodes.\");\n    }\n\n    // create NM simulators\n    Random random \u003d new Random();\n    Set\u003cString\u003e rackSet \u003d new ConcurrentHashSet\u003c\u003e();\n    int threadPoolSize \u003d Math.max(poolSize,\n        SLSConfiguration.RUNNER_POOL_SIZE_DEFAULT);\n    ExecutorService executorService \u003d Executors.\n        newFixedThreadPool(threadPoolSize);\n    for (Map.Entry\u003cString, Resource\u003e entry : nodeResourceMap.entrySet()) {\n      executorService.submit(new Runnable() {\n        @Override public void run() {\n          try {\n            // we randomize the heartbeat start time from zero to 1 interval\n            NMSimulator nm \u003d new NMSimulator();\n            Resource nmResource \u003d nodeManagerResource;\n            String hostName \u003d entry.getKey();\n            if (entry.getValue() !\u003d null) {\n              nmResource \u003d entry.getValue();\n            }\n            nm.init(hostName, nmResource,\n                random.nextInt(heartbeatInterval),\n                heartbeatInterval, rm, resourceUtilizationRatio);\n            nmMap.put(nm.getNode().getNodeID(), nm);\n            runner.schedule(nm);\n            rackSet.add(nm.getNode().getRackName());\n          } catch (IOException | YarnException e) {\n            LOG.error(\"Got an error while adding node\", e);\n          }\n        }\n      });\n    }\n    executorService.shutdown();\n    executorService.awaitTermination(10, TimeUnit.MINUTES);\n    numRacks \u003d rackSet.size();\n    numNMs \u003d nmMap.size();\n  }",
          "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
          "extendedDetails": {}
        }
      ]
    },
    "78860372bd8048168c6aa27a9526c40f5869cf2c": {
      "type": "Ybodychange",
      "commitMessage": "YARN-8134. Support specifying node resources in SLS. Contributed by Abhishek Modi.\n",
      "commitDate": "17/04/18 1:11 PM",
      "commitName": "78860372bd8048168c6aa27a9526c40f5869cf2c",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "28/02/18 1:58 AM",
      "commitNameOld": "7af4f34de54f6e667b47374e31fc9328eba869f0",
      "commitAuthorOld": "Weiwei Yang",
      "daysBetweenCommits": 48.43,
      "commitsBetweenForRepo": 459,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,53 +1,68 @@\n   private void startNM() throws YarnException, IOException {\n     // nm configuration\n     int heartbeatInterval \u003d getConf().getInt(\n         SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n         SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n     float resourceUtilizationRatio \u003d getConf().getFloat(\n         SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO,\n         SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO_DEFAULT);\n     // nm information (fetch from topology file, or from sls/rumen json file)\n-    Set\u003cString\u003e nodeSet \u003d new HashSet\u003cString\u003e();\n+    Map\u003cString, Resource\u003e nodeResourceMap \u003d new HashMap\u003c\u003e();\n+    Set\u003c? extends  String\u003e nodeSet;\n     if (nodeFile.isEmpty()) {\n       for (String inputTrace : inputTraces) {\n-\n         switch (inputType) {\n         case SLS:\n-          nodeSet.addAll(SLSUtils.parseNodesFromSLSTrace(inputTrace));\n+          nodeSet \u003d SLSUtils.parseNodesFromSLSTrace(inputTrace);\n+          for (String node : nodeSet) {\n+            nodeResourceMap.put(node, null);\n+          }\n           break;\n         case RUMEN:\n-          nodeSet.addAll(SLSUtils.parseNodesFromRumenTrace(inputTrace));\n+          nodeSet \u003d SLSUtils.parseNodesFromRumenTrace(inputTrace);\n+          for (String node : nodeSet) {\n+            nodeResourceMap.put(node, null);\n+          }\n           break;\n         case SYNTH:\n           stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n-          nodeSet.addAll(SLSUtils.generateNodes(stjp.getNumNodes(),\n-              stjp.getNumNodes()/stjp.getNodesPerRack()));\n+          nodeSet \u003d SLSUtils.generateNodes(stjp.getNumNodes(),\n+              stjp.getNumNodes()/stjp.getNodesPerRack());\n+          for (String node : nodeSet) {\n+            nodeResourceMap.put(node, null);\n+          }\n           break;\n         default:\n           throw new YarnException(\"Input configuration not recognized, \"\n               + \"trace type should be SLS, RUMEN, or SYNTH\");\n         }\n       }\n     } else {\n-      nodeSet.addAll(SLSUtils.parseNodesFromNodeFile(nodeFile));\n+      nodeResourceMap \u003d SLSUtils.parseNodesFromNodeFile(nodeFile,\n+          nodeManagerResource);\n     }\n \n-    if (nodeSet.size() \u003d\u003d 0) {\n+    if (nodeResourceMap.size() \u003d\u003d 0) {\n       throw new YarnException(\"No node! Please configure nodes.\");\n     }\n \n     // create NM simulators\n     Random random \u003d new Random();\n     Set\u003cString\u003e rackSet \u003d new HashSet\u003cString\u003e();\n-    for (String hostName : nodeSet) {\n+    for (Map.Entry\u003cString, Resource\u003e entry : nodeResourceMap.entrySet()) {\n       // we randomize the heartbeat start time from zero to 1 interval\n       NMSimulator nm \u003d new NMSimulator();\n-      nm.init(hostName, nodeManagerResource, random.nextInt(heartbeatInterval),\n+      Resource nmResource \u003d nodeManagerResource;\n+      String hostName \u003d entry.getKey();\n+      if (entry.getValue() !\u003d null) {\n+        nmResource \u003d entry.getValue();\n+      }\n+      nm.init(hostName, nmResource, random.nextInt(heartbeatInterval),\n           heartbeatInterval, rm, resourceUtilizationRatio);\n       nmMap.put(nm.getNode().getNodeID(), nm);\n       runner.schedule(nm);\n       rackSet.add(nm.getNode().getRackName());\n     }\n     numRacks \u003d rackSet.size();\n     numNMs \u003d nmMap.size();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startNM() throws YarnException, IOException {\n    // nm configuration\n    int heartbeatInterval \u003d getConf().getInt(\n        SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n        SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n    float resourceUtilizationRatio \u003d getConf().getFloat(\n        SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO,\n        SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO_DEFAULT);\n    // nm information (fetch from topology file, or from sls/rumen json file)\n    Map\u003cString, Resource\u003e nodeResourceMap \u003d new HashMap\u003c\u003e();\n    Set\u003c? extends  String\u003e nodeSet;\n    if (nodeFile.isEmpty()) {\n      for (String inputTrace : inputTraces) {\n        switch (inputType) {\n        case SLS:\n          nodeSet \u003d SLSUtils.parseNodesFromSLSTrace(inputTrace);\n          for (String node : nodeSet) {\n            nodeResourceMap.put(node, null);\n          }\n          break;\n        case RUMEN:\n          nodeSet \u003d SLSUtils.parseNodesFromRumenTrace(inputTrace);\n          for (String node : nodeSet) {\n            nodeResourceMap.put(node, null);\n          }\n          break;\n        case SYNTH:\n          stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n          nodeSet \u003d SLSUtils.generateNodes(stjp.getNumNodes(),\n              stjp.getNumNodes()/stjp.getNodesPerRack());\n          for (String node : nodeSet) {\n            nodeResourceMap.put(node, null);\n          }\n          break;\n        default:\n          throw new YarnException(\"Input configuration not recognized, \"\n              + \"trace type should be SLS, RUMEN, or SYNTH\");\n        }\n      }\n    } else {\n      nodeResourceMap \u003d SLSUtils.parseNodesFromNodeFile(nodeFile,\n          nodeManagerResource);\n    }\n\n    if (nodeResourceMap.size() \u003d\u003d 0) {\n      throw new YarnException(\"No node! Please configure nodes.\");\n    }\n\n    // create NM simulators\n    Random random \u003d new Random();\n    Set\u003cString\u003e rackSet \u003d new HashSet\u003cString\u003e();\n    for (Map.Entry\u003cString, Resource\u003e entry : nodeResourceMap.entrySet()) {\n      // we randomize the heartbeat start time from zero to 1 interval\n      NMSimulator nm \u003d new NMSimulator();\n      Resource nmResource \u003d nodeManagerResource;\n      String hostName \u003d entry.getKey();\n      if (entry.getValue() !\u003d null) {\n        nmResource \u003d entry.getValue();\n      }\n      nm.init(hostName, nmResource, random.nextInt(heartbeatInterval),\n          heartbeatInterval, rm, resourceUtilizationRatio);\n      nmMap.put(nm.getNode().getNodeID(), nm);\n      runner.schedule(nm);\n      rackSet.add(nm.getNode().getRackName());\n    }\n    numRacks \u003d rackSet.size();\n    numNMs \u003d nmMap.size();\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "7af4f34de54f6e667b47374e31fc9328eba869f0": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7929. Support to set container execution type in SLS. (Jiandan Yang via Weiwei Yang)\n",
      "commitDate": "28/02/18 1:58 AM",
      "commitName": "7af4f34de54f6e667b47374e31fc9328eba869f0",
      "commitAuthor": "Weiwei Yang",
      "commitDateOld": "20/02/18 5:00 PM",
      "commitNameOld": "84cea0011ffe510d24cf9f2952944f7a6fe622cf",
      "commitAuthorOld": "Carlo Curino",
      "daysBetweenCommits": 7.37,
      "commitsBetweenForRepo": 48,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,53 @@\n   private void startNM() throws YarnException, IOException {\n     // nm configuration\n-    int heartbeatInterval \u003d\n-        getConf().getInt(SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n-            SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n+    int heartbeatInterval \u003d getConf().getInt(\n+        SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n+        SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n+    float resourceUtilizationRatio \u003d getConf().getFloat(\n+        SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO,\n+        SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO_DEFAULT);\n     // nm information (fetch from topology file, or from sls/rumen json file)\n     Set\u003cString\u003e nodeSet \u003d new HashSet\u003cString\u003e();\n     if (nodeFile.isEmpty()) {\n       for (String inputTrace : inputTraces) {\n \n         switch (inputType) {\n         case SLS:\n           nodeSet.addAll(SLSUtils.parseNodesFromSLSTrace(inputTrace));\n           break;\n         case RUMEN:\n           nodeSet.addAll(SLSUtils.parseNodesFromRumenTrace(inputTrace));\n           break;\n         case SYNTH:\n           stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n           nodeSet.addAll(SLSUtils.generateNodes(stjp.getNumNodes(),\n               stjp.getNumNodes()/stjp.getNodesPerRack()));\n           break;\n         default:\n           throw new YarnException(\"Input configuration not recognized, \"\n               + \"trace type should be SLS, RUMEN, or SYNTH\");\n         }\n       }\n     } else {\n       nodeSet.addAll(SLSUtils.parseNodesFromNodeFile(nodeFile));\n     }\n \n     if (nodeSet.size() \u003d\u003d 0) {\n       throw new YarnException(\"No node! Please configure nodes.\");\n     }\n \n     // create NM simulators\n     Random random \u003d new Random();\n     Set\u003cString\u003e rackSet \u003d new HashSet\u003cString\u003e();\n     for (String hostName : nodeSet) {\n       // we randomize the heartbeat start time from zero to 1 interval\n       NMSimulator nm \u003d new NMSimulator();\n       nm.init(hostName, nodeManagerResource, random.nextInt(heartbeatInterval),\n-          heartbeatInterval, rm);\n+          heartbeatInterval, rm, resourceUtilizationRatio);\n       nmMap.put(nm.getNode().getNodeID(), nm);\n       runner.schedule(nm);\n       rackSet.add(nm.getNode().getRackName());\n     }\n     numRacks \u003d rackSet.size();\n     numNMs \u003d nmMap.size();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startNM() throws YarnException, IOException {\n    // nm configuration\n    int heartbeatInterval \u003d getConf().getInt(\n        SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n        SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n    float resourceUtilizationRatio \u003d getConf().getFloat(\n        SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO,\n        SLSConfiguration.NM_RESOURCE_UTILIZATION_RATIO_DEFAULT);\n    // nm information (fetch from topology file, or from sls/rumen json file)\n    Set\u003cString\u003e nodeSet \u003d new HashSet\u003cString\u003e();\n    if (nodeFile.isEmpty()) {\n      for (String inputTrace : inputTraces) {\n\n        switch (inputType) {\n        case SLS:\n          nodeSet.addAll(SLSUtils.parseNodesFromSLSTrace(inputTrace));\n          break;\n        case RUMEN:\n          nodeSet.addAll(SLSUtils.parseNodesFromRumenTrace(inputTrace));\n          break;\n        case SYNTH:\n          stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n          nodeSet.addAll(SLSUtils.generateNodes(stjp.getNumNodes(),\n              stjp.getNumNodes()/stjp.getNodesPerRack()));\n          break;\n        default:\n          throw new YarnException(\"Input configuration not recognized, \"\n              + \"trace type should be SLS, RUMEN, or SYNTH\");\n        }\n      }\n    } else {\n      nodeSet.addAll(SLSUtils.parseNodesFromNodeFile(nodeFile));\n    }\n\n    if (nodeSet.size() \u003d\u003d 0) {\n      throw new YarnException(\"No node! Please configure nodes.\");\n    }\n\n    // create NM simulators\n    Random random \u003d new Random();\n    Set\u003cString\u003e rackSet \u003d new HashSet\u003cString\u003e();\n    for (String hostName : nodeSet) {\n      // we randomize the heartbeat start time from zero to 1 interval\n      NMSimulator nm \u003d new NMSimulator();\n      nm.init(hostName, nodeManagerResource, random.nextInt(heartbeatInterval),\n          heartbeatInterval, rm, resourceUtilizationRatio);\n      nmMap.put(nm.getNode().getNodeID(), nm);\n      runner.schedule(nm);\n      rackSet.add(nm.getNode().getRackName());\n    }\n    numRacks \u003d rackSet.size();\n    numNMs \u003d nmMap.size();\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "ba8136615ab66c450884614557eddc6509d63b7c": {
      "type": "Ybodychange",
      "commitMessage": "YARN-7413. Support resource type in SLS (Contributed by Yufei Gu via Daniel Templeton)\n\nChange-Id: Ic0a897c123c5d2f57aae757ca6bcf1dad7b90d2b\n",
      "commitDate": "09/11/17 12:09 PM",
      "commitName": "ba8136615ab66c450884614557eddc6509d63b7c",
      "commitAuthor": "Daniel Templeton",
      "commitDateOld": "27/10/17 2:41 PM",
      "commitNameOld": "99880d0a16727c770da053464da87960c5b02065",
      "commitAuthorOld": "Yufei Gu",
      "daysBetweenCommits": 12.94,
      "commitsBetweenForRepo": 184,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,54 +1,50 @@\n   private void startNM() throws YarnException, IOException {\n     // nm configuration\n-    nmMemoryMB \u003d getConf().getInt(SLSConfiguration.NM_MEMORY_MB,\n-        SLSConfiguration.NM_MEMORY_MB_DEFAULT);\n-    nmVCores \u003d getConf().getInt(SLSConfiguration.NM_VCORES,\n-        SLSConfiguration.NM_VCORES_DEFAULT);\n     int heartbeatInterval \u003d\n         getConf().getInt(SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n             SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n     // nm information (fetch from topology file, or from sls/rumen json file)\n     Set\u003cString\u003e nodeSet \u003d new HashSet\u003cString\u003e();\n     if (nodeFile.isEmpty()) {\n       for (String inputTrace : inputTraces) {\n \n         switch (inputType) {\n         case SLS:\n           nodeSet.addAll(SLSUtils.parseNodesFromSLSTrace(inputTrace));\n           break;\n         case RUMEN:\n           nodeSet.addAll(SLSUtils.parseNodesFromRumenTrace(inputTrace));\n           break;\n         case SYNTH:\n           stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n           nodeSet.addAll(SLSUtils.generateNodes(stjp.getNumNodes(),\n               stjp.getNumNodes()/stjp.getNodesPerRack()));\n           break;\n         default:\n           throw new YarnException(\"Input configuration not recognized, \"\n               + \"trace type should be SLS, RUMEN, or SYNTH\");\n         }\n       }\n     } else {\n       nodeSet.addAll(SLSUtils.parseNodesFromNodeFile(nodeFile));\n     }\n \n     if (nodeSet.size() \u003d\u003d 0) {\n       throw new YarnException(\"No node! Please configure nodes.\");\n     }\n \n     // create NM simulators\n     Random random \u003d new Random();\n     Set\u003cString\u003e rackSet \u003d new HashSet\u003cString\u003e();\n     for (String hostName : nodeSet) {\n       // we randomize the heartbeat start time from zero to 1 interval\n       NMSimulator nm \u003d new NMSimulator();\n-      nm.init(hostName, nmMemoryMB, nmVCores, random.nextInt(heartbeatInterval),\n+      nm.init(hostName, nodeManagerResource, random.nextInt(heartbeatInterval),\n           heartbeatInterval, rm);\n       nmMap.put(nm.getNode().getNodeID(), nm);\n       runner.schedule(nm);\n       rackSet.add(nm.getNode().getRackName());\n     }\n     numRacks \u003d rackSet.size();\n     numNMs \u003d nmMap.size();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startNM() throws YarnException, IOException {\n    // nm configuration\n    int heartbeatInterval \u003d\n        getConf().getInt(SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n            SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n    // nm information (fetch from topology file, or from sls/rumen json file)\n    Set\u003cString\u003e nodeSet \u003d new HashSet\u003cString\u003e();\n    if (nodeFile.isEmpty()) {\n      for (String inputTrace : inputTraces) {\n\n        switch (inputType) {\n        case SLS:\n          nodeSet.addAll(SLSUtils.parseNodesFromSLSTrace(inputTrace));\n          break;\n        case RUMEN:\n          nodeSet.addAll(SLSUtils.parseNodesFromRumenTrace(inputTrace));\n          break;\n        case SYNTH:\n          stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n          nodeSet.addAll(SLSUtils.generateNodes(stjp.getNumNodes(),\n              stjp.getNumNodes()/stjp.getNodesPerRack()));\n          break;\n        default:\n          throw new YarnException(\"Input configuration not recognized, \"\n              + \"trace type should be SLS, RUMEN, or SYNTH\");\n        }\n      }\n    } else {\n      nodeSet.addAll(SLSUtils.parseNodesFromNodeFile(nodeFile));\n    }\n\n    if (nodeSet.size() \u003d\u003d 0) {\n      throw new YarnException(\"No node! Please configure nodes.\");\n    }\n\n    // create NM simulators\n    Random random \u003d new Random();\n    Set\u003cString\u003e rackSet \u003d new HashSet\u003cString\u003e();\n    for (String hostName : nodeSet) {\n      // we randomize the heartbeat start time from zero to 1 interval\n      NMSimulator nm \u003d new NMSimulator();\n      nm.init(hostName, nodeManagerResource, random.nextInt(heartbeatInterval),\n          heartbeatInterval, rm);\n      nmMap.put(nm.getNode().getNodeID(), nm);\n      runner.schedule(nm);\n      rackSet.add(nm.getNode().getRackName());\n    }\n    numRacks \u003d rackSet.size();\n    numNMs \u003d nmMap.size();\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "3082552b3b991df846caf572b58e44308ddf8eeb": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6522. Make SLS JSON input file format simple and scalable (yufeigu via rkanter)\n",
      "commitDate": "04/05/17 5:21 PM",
      "commitName": "3082552b3b991df846caf572b58e44308ddf8eeb",
      "commitAuthor": "Robert Kanter",
      "commitDateOld": "25/04/17 4:26 PM",
      "commitNameOld": "475f933b41276b1bdeeec09e30369120f7eccdb8",
      "commitAuthorOld": "Robert Kanter",
      "daysBetweenCommits": 9.04,
      "commitsBetweenForRepo": 67,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,50 +1,54 @@\n   private void startNM() throws YarnException, IOException {\n     // nm configuration\n     nmMemoryMB \u003d getConf().getInt(SLSConfiguration.NM_MEMORY_MB,\n         SLSConfiguration.NM_MEMORY_MB_DEFAULT);\n     nmVCores \u003d getConf().getInt(SLSConfiguration.NM_VCORES,\n         SLSConfiguration.NM_VCORES_DEFAULT);\n     int heartbeatInterval \u003d\n         getConf().getInt(SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n             SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n     // nm information (fetch from topology file, or from sls/rumen json file)\n     Set\u003cString\u003e nodeSet \u003d new HashSet\u003cString\u003e();\n     if (nodeFile.isEmpty()) {\n       for (String inputTrace : inputTraces) {\n \n         switch (inputType) {\n         case SLS:\n           nodeSet.addAll(SLSUtils.parseNodesFromSLSTrace(inputTrace));\n           break;\n         case RUMEN:\n           nodeSet.addAll(SLSUtils.parseNodesFromRumenTrace(inputTrace));\n           break;\n         case SYNTH:\n           stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n-          nodeSet.addAll(SLSUtils.generateNodesFromSynth(stjp.getNumNodes(),\n-              stjp.getNodesPerRack()));\n+          nodeSet.addAll(SLSUtils.generateNodes(stjp.getNumNodes(),\n+              stjp.getNumNodes()/stjp.getNodesPerRack()));\n           break;\n         default:\n           throw new YarnException(\"Input configuration not recognized, \"\n               + \"trace type should be SLS, RUMEN, or SYNTH\");\n         }\n       }\n     } else {\n       nodeSet.addAll(SLSUtils.parseNodesFromNodeFile(nodeFile));\n     }\n \n+    if (nodeSet.size() \u003d\u003d 0) {\n+      throw new YarnException(\"No node! Please configure nodes.\");\n+    }\n+\n     // create NM simulators\n     Random random \u003d new Random();\n     Set\u003cString\u003e rackSet \u003d new HashSet\u003cString\u003e();\n     for (String hostName : nodeSet) {\n       // we randomize the heartbeat start time from zero to 1 interval\n       NMSimulator nm \u003d new NMSimulator();\n       nm.init(hostName, nmMemoryMB, nmVCores, random.nextInt(heartbeatInterval),\n           heartbeatInterval, rm);\n       nmMap.put(nm.getNode().getNodeID(), nm);\n       runner.schedule(nm);\n       rackSet.add(nm.getNode().getRackName());\n     }\n     numRacks \u003d rackSet.size();\n     numNMs \u003d nmMap.size();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startNM() throws YarnException, IOException {\n    // nm configuration\n    nmMemoryMB \u003d getConf().getInt(SLSConfiguration.NM_MEMORY_MB,\n        SLSConfiguration.NM_MEMORY_MB_DEFAULT);\n    nmVCores \u003d getConf().getInt(SLSConfiguration.NM_VCORES,\n        SLSConfiguration.NM_VCORES_DEFAULT);\n    int heartbeatInterval \u003d\n        getConf().getInt(SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n            SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n    // nm information (fetch from topology file, or from sls/rumen json file)\n    Set\u003cString\u003e nodeSet \u003d new HashSet\u003cString\u003e();\n    if (nodeFile.isEmpty()) {\n      for (String inputTrace : inputTraces) {\n\n        switch (inputType) {\n        case SLS:\n          nodeSet.addAll(SLSUtils.parseNodesFromSLSTrace(inputTrace));\n          break;\n        case RUMEN:\n          nodeSet.addAll(SLSUtils.parseNodesFromRumenTrace(inputTrace));\n          break;\n        case SYNTH:\n          stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n          nodeSet.addAll(SLSUtils.generateNodes(stjp.getNumNodes(),\n              stjp.getNumNodes()/stjp.getNodesPerRack()));\n          break;\n        default:\n          throw new YarnException(\"Input configuration not recognized, \"\n              + \"trace type should be SLS, RUMEN, or SYNTH\");\n        }\n      }\n    } else {\n      nodeSet.addAll(SLSUtils.parseNodesFromNodeFile(nodeFile));\n    }\n\n    if (nodeSet.size() \u003d\u003d 0) {\n      throw new YarnException(\"No node! Please configure nodes.\");\n    }\n\n    // create NM simulators\n    Random random \u003d new Random();\n    Set\u003cString\u003e rackSet \u003d new HashSet\u003cString\u003e();\n    for (String hostName : nodeSet) {\n      // we randomize the heartbeat start time from zero to 1 interval\n      NMSimulator nm \u003d new NMSimulator();\n      nm.init(hostName, nmMemoryMB, nmVCores, random.nextInt(heartbeatInterval),\n          heartbeatInterval, rm);\n      nmMap.put(nm.getNode().getNodeID(), nm);\n      runner.schedule(nm);\n      rackSet.add(nm.getNode().getRackName());\n    }\n    numRacks \u003d rackSet.size();\n    numNMs \u003d nmMap.size();\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "de69d6e81128470dd5d2fd865d4b3a79188f740b": {
      "type": "Ybodychange",
      "commitMessage": "YARN-6363. Extending SLS: Synthetic Load Generator. (Carlo Curino via wangda)\n",
      "commitDate": "20/04/17 9:54 PM",
      "commitName": "de69d6e81128470dd5d2fd865d4b3a79188f740b",
      "commitAuthor": "Wangda Tan",
      "commitDateOld": "29/03/17 4:18 PM",
      "commitNameOld": "6a5516c2381f107d96b8326939514de3c6e53d3d",
      "commitAuthorOld": "Robert Kanter",
      "daysBetweenCommits": 22.23,
      "commitsBetweenForRepo": 128,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,40 +1,50 @@\n   private void startNM() throws YarnException, IOException {\n     // nm configuration\n-    nmMemoryMB \u003d conf.getInt(SLSConfiguration.NM_MEMORY_MB,\n-            SLSConfiguration.NM_MEMORY_MB_DEFAULT);\n-    nmVCores \u003d conf.getInt(SLSConfiguration.NM_VCORES,\n-            SLSConfiguration.NM_VCORES_DEFAULT);\n-    int heartbeatInterval \u003d conf.getInt(\n-            SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n+    nmMemoryMB \u003d getConf().getInt(SLSConfiguration.NM_MEMORY_MB,\n+        SLSConfiguration.NM_MEMORY_MB_DEFAULT);\n+    nmVCores \u003d getConf().getInt(SLSConfiguration.NM_VCORES,\n+        SLSConfiguration.NM_VCORES_DEFAULT);\n+    int heartbeatInterval \u003d\n+        getConf().getInt(SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n             SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n     // nm information (fetch from topology file, or from sls/rumen json file)\n     Set\u003cString\u003e nodeSet \u003d new HashSet\u003cString\u003e();\n     if (nodeFile.isEmpty()) {\n-      if (isSLS) {\n-        for (String inputTrace : inputTraces) {\n+      for (String inputTrace : inputTraces) {\n+\n+        switch (inputType) {\n+        case SLS:\n           nodeSet.addAll(SLSUtils.parseNodesFromSLSTrace(inputTrace));\n-        }\n-      } else {\n-        for (String inputTrace : inputTraces) {\n+          break;\n+        case RUMEN:\n           nodeSet.addAll(SLSUtils.parseNodesFromRumenTrace(inputTrace));\n+          break;\n+        case SYNTH:\n+          stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n+          nodeSet.addAll(SLSUtils.generateNodesFromSynth(stjp.getNumNodes(),\n+              stjp.getNodesPerRack()));\n+          break;\n+        default:\n+          throw new YarnException(\"Input configuration not recognized, \"\n+              + \"trace type should be SLS, RUMEN, or SYNTH\");\n         }\n       }\n-\n     } else {\n       nodeSet.addAll(SLSUtils.parseNodesFromNodeFile(nodeFile));\n     }\n+\n     // create NM simulators\n     Random random \u003d new Random();\n     Set\u003cString\u003e rackSet \u003d new HashSet\u003cString\u003e();\n     for (String hostName : nodeSet) {\n       // we randomize the heartbeat start time from zero to 1 interval\n       NMSimulator nm \u003d new NMSimulator();\n-      nm.init(hostName, nmMemoryMB, nmVCores, \n-          random.nextInt(heartbeatInterval), heartbeatInterval, rm);\n+      nm.init(hostName, nmMemoryMB, nmVCores, random.nextInt(heartbeatInterval),\n+          heartbeatInterval, rm);\n       nmMap.put(nm.getNode().getNodeID(), nm);\n       runner.schedule(nm);\n       rackSet.add(nm.getNode().getRackName());\n     }\n     numRacks \u003d rackSet.size();\n     numNMs \u003d nmMap.size();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private void startNM() throws YarnException, IOException {\n    // nm configuration\n    nmMemoryMB \u003d getConf().getInt(SLSConfiguration.NM_MEMORY_MB,\n        SLSConfiguration.NM_MEMORY_MB_DEFAULT);\n    nmVCores \u003d getConf().getInt(SLSConfiguration.NM_VCORES,\n        SLSConfiguration.NM_VCORES_DEFAULT);\n    int heartbeatInterval \u003d\n        getConf().getInt(SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n            SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n    // nm information (fetch from topology file, or from sls/rumen json file)\n    Set\u003cString\u003e nodeSet \u003d new HashSet\u003cString\u003e();\n    if (nodeFile.isEmpty()) {\n      for (String inputTrace : inputTraces) {\n\n        switch (inputType) {\n        case SLS:\n          nodeSet.addAll(SLSUtils.parseNodesFromSLSTrace(inputTrace));\n          break;\n        case RUMEN:\n          nodeSet.addAll(SLSUtils.parseNodesFromRumenTrace(inputTrace));\n          break;\n        case SYNTH:\n          stjp \u003d new SynthTraceJobProducer(getConf(), new Path(inputTraces[0]));\n          nodeSet.addAll(SLSUtils.generateNodesFromSynth(stjp.getNumNodes(),\n              stjp.getNodesPerRack()));\n          break;\n        default:\n          throw new YarnException(\"Input configuration not recognized, \"\n              + \"trace type should be SLS, RUMEN, or SYNTH\");\n        }\n      }\n    } else {\n      nodeSet.addAll(SLSUtils.parseNodesFromNodeFile(nodeFile));\n    }\n\n    // create NM simulators\n    Random random \u003d new Random();\n    Set\u003cString\u003e rackSet \u003d new HashSet\u003cString\u003e();\n    for (String hostName : nodeSet) {\n      // we randomize the heartbeat start time from zero to 1 interval\n      NMSimulator nm \u003d new NMSimulator();\n      nm.init(hostName, nmMemoryMB, nmVCores, random.nextInt(heartbeatInterval),\n          heartbeatInterval, rm);\n      nmMap.put(nm.getNode().getNodeID(), nm);\n      runner.schedule(nm);\n      rackSet.add(nm.getNode().getRackName());\n    }\n    numRacks \u003d rackSet.size();\n    numNMs \u003d nmMap.size();\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java",
      "extendedDetails": {}
    },
    "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b": {
      "type": "Yintroduced",
      "commitMessage": "YARN-1021. Yarn Scheduler Load Simulator. (ywskycn via tucu)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1527059 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/09/13 1:23 PM",
      "commitName": "58b08e11b9f04c9190ab4a07473f0ee04e01ec6b",
      "commitAuthor": "Alejandro Abdelnur",
      "diff": "@@ -0,0 +1,40 @@\n+  private void startNM() throws YarnException, IOException {\n+    // nm configuration\n+    nmMemoryMB \u003d conf.getInt(SLSConfiguration.NM_MEMORY_MB,\n+            SLSConfiguration.NM_MEMORY_MB_DEFAULT);\n+    nmVCores \u003d conf.getInt(SLSConfiguration.NM_VCORES,\n+            SLSConfiguration.NM_VCORES_DEFAULT);\n+    int heartbeatInterval \u003d conf.getInt(\n+            SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n+            SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n+    // nm information (fetch from topology file, or from sls/rumen json file)\n+    Set\u003cString\u003e nodeSet \u003d new HashSet\u003cString\u003e();\n+    if (nodeFile.isEmpty()) {\n+      if (isSLS) {\n+        for (String inputTrace : inputTraces) {\n+          nodeSet.addAll(SLSUtils.parseNodesFromSLSTrace(inputTrace));\n+        }\n+      } else {\n+        for (String inputTrace : inputTraces) {\n+          nodeSet.addAll(SLSUtils.parseNodesFromRumenTrace(inputTrace));\n+        }\n+      }\n+\n+    } else {\n+      nodeSet.addAll(SLSUtils.parseNodesFromNodeFile(nodeFile));\n+    }\n+    // create NM simulators\n+    Random random \u003d new Random();\n+    Set\u003cString\u003e rackSet \u003d new HashSet\u003cString\u003e();\n+    for (String hostName : nodeSet) {\n+      // we randomize the heartbeat start time from zero to 1 interval\n+      NMSimulator nm \u003d new NMSimulator();\n+      nm.init(hostName, nmMemoryMB, nmVCores, \n+          random.nextInt(heartbeatInterval), heartbeatInterval, rm);\n+      nmMap.put(nm.getNode().getNodeID(), nm);\n+      runner.schedule(nm);\n+      rackSet.add(nm.getNode().getRackName());\n+    }\n+    numRacks \u003d rackSet.size();\n+    numNMs \u003d nmMap.size();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private void startNM() throws YarnException, IOException {\n    // nm configuration\n    nmMemoryMB \u003d conf.getInt(SLSConfiguration.NM_MEMORY_MB,\n            SLSConfiguration.NM_MEMORY_MB_DEFAULT);\n    nmVCores \u003d conf.getInt(SLSConfiguration.NM_VCORES,\n            SLSConfiguration.NM_VCORES_DEFAULT);\n    int heartbeatInterval \u003d conf.getInt(\n            SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS,\n            SLSConfiguration.NM_HEARTBEAT_INTERVAL_MS_DEFAULT);\n    // nm information (fetch from topology file, or from sls/rumen json file)\n    Set\u003cString\u003e nodeSet \u003d new HashSet\u003cString\u003e();\n    if (nodeFile.isEmpty()) {\n      if (isSLS) {\n        for (String inputTrace : inputTraces) {\n          nodeSet.addAll(SLSUtils.parseNodesFromSLSTrace(inputTrace));\n        }\n      } else {\n        for (String inputTrace : inputTraces) {\n          nodeSet.addAll(SLSUtils.parseNodesFromRumenTrace(inputTrace));\n        }\n      }\n\n    } else {\n      nodeSet.addAll(SLSUtils.parseNodesFromNodeFile(nodeFile));\n    }\n    // create NM simulators\n    Random random \u003d new Random();\n    Set\u003cString\u003e rackSet \u003d new HashSet\u003cString\u003e();\n    for (String hostName : nodeSet) {\n      // we randomize the heartbeat start time from zero to 1 interval\n      NMSimulator nm \u003d new NMSimulator();\n      nm.init(hostName, nmMemoryMB, nmVCores, \n          random.nextInt(heartbeatInterval), heartbeatInterval, rm);\n      nmMap.put(nm.getNode().getNodeID(), nm);\n      runner.schedule(nm);\n      rackSet.add(nm.getNode().getRackName());\n    }\n    numRacks \u003d rackSet.size();\n    numNMs \u003d nmMap.size();\n  }",
      "path": "hadoop-tools/hadoop-sls/src/main/java/org/apache/hadoop/yarn/sls/SLSRunner.java"
    }
  }
}