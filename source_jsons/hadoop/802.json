{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "StripeReader.java",
  "functionName": "readCells",
  "functionId": "readCells___reader-BlockReader(modifiers-final)__datanode-DatanodeInfo(modifiers-final)__currentReaderOffset-long(modifiers-final)__targetReaderOffset-long(modifiers-final)__strategies-ByteBufferStrategy[](modifiers-final)__currentBlock-ExtendedBlock(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/StripeReader.java",
  "functionStartLine": 266,
  "functionEndLine": 292,
  "numCommitsSeen": 25,
  "timeTaken": 2752,
  "changeHistory": [
    "08bb6c49a5aec32b7d9f29238560f947420405d6",
    "734d54c1a8950446e68098f62d8964e02ecc2890",
    "8808779db351fe444388d4acb3094766b5980718"
  ],
  "changeHistoryShort": {
    "08bb6c49a5aec32b7d9f29238560f947420405d6": "Ymultichange(Yreturntypechange,Ybodychange)",
    "734d54c1a8950446e68098f62d8964e02ecc2890": "Ymultichange(Ymovefromfile,Ybodychange,Yparameterchange)",
    "8808779db351fe444388d4acb3094766b5980718": "Ymultichange(Yparameterchange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "08bb6c49a5aec32b7d9f29238560f947420405d6": {
      "type": "Ymultichange(Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-13926. ThreadLocal aggregations for FileSystem.Statistics are incorrect with striped reads.\nContributed by Xiao Chen, Hrishikesh Gadre.\n\nSigned-off-by: Xiao Chen \u003cxiao@apache.org\u003e\n",
      "commitDate": "08/10/18 8:31 PM",
      "commitName": "08bb6c49a5aec32b7d9f29238560f947420405d6",
      "commitAuthor": "Hrishikesh Gadre",
      "subchanges": [
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-13926. ThreadLocal aggregations for FileSystem.Statistics are incorrect with striped reads.\nContributed by Xiao Chen, Hrishikesh Gadre.\n\nSigned-off-by: Xiao Chen \u003cxiao@apache.org\u003e\n",
          "commitDate": "08/10/18 8:31 PM",
          "commitName": "08bb6c49a5aec32b7d9f29238560f947420405d6",
          "commitAuthor": "Hrishikesh Gadre",
          "commitDateOld": "26/04/18 1:54 PM",
          "commitNameOld": "a8e428b2dc0883184b43cb776d5c7196aaa3bf56",
          "commitAuthorOld": "Lei Xu",
          "daysBetweenCommits": 165.28,
          "commitsBetweenForRepo": 1297,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,27 @@\n-  private Callable\u003cVoid\u003e readCells(final BlockReader reader,\n+  private Callable\u003cBlockReadStats\u003e readCells(final BlockReader reader,\n       final DatanodeInfo datanode, final long currentReaderOffset,\n       final long targetReaderOffset, final ByteBufferStrategy[] strategies,\n       final ExtendedBlock currentBlock) {\n     return () -\u003e {\n       // reader can be null if getBlockReaderWithRetry failed or\n       // the reader hit exception before\n       if (reader \u003d\u003d null) {\n         throw new IOException(\"The BlockReader is null. \" +\n             \"The BlockReader creation failed or the reader hit exception.\");\n       }\n       Preconditions.checkState(currentReaderOffset \u003c\u003d targetReaderOffset);\n       if (currentReaderOffset \u003c targetReaderOffset) {\n         long skipped \u003d reader.skip(targetReaderOffset - currentReaderOffset);\n         Preconditions.checkState(\n             skipped \u003d\u003d targetReaderOffset - currentReaderOffset);\n       }\n \n+      int ret \u003d 0;\n       for (ByteBufferStrategy strategy : strategies) {\n-        readToBuffer(reader, datanode, strategy, currentBlock);\n+        int bytesReead \u003d readToBuffer(reader, datanode, strategy, currentBlock);\n+        ret +\u003d bytesReead;\n       }\n-      return null;\n+      return new BlockReadStats(ret, reader.isShortCircuit(),\n+          reader.getNetworkDistance());\n     };\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Callable\u003cBlockReadStats\u003e readCells(final BlockReader reader,\n      final DatanodeInfo datanode, final long currentReaderOffset,\n      final long targetReaderOffset, final ByteBufferStrategy[] strategies,\n      final ExtendedBlock currentBlock) {\n    return () -\u003e {\n      // reader can be null if getBlockReaderWithRetry failed or\n      // the reader hit exception before\n      if (reader \u003d\u003d null) {\n        throw new IOException(\"The BlockReader is null. \" +\n            \"The BlockReader creation failed or the reader hit exception.\");\n      }\n      Preconditions.checkState(currentReaderOffset \u003c\u003d targetReaderOffset);\n      if (currentReaderOffset \u003c targetReaderOffset) {\n        long skipped \u003d reader.skip(targetReaderOffset - currentReaderOffset);\n        Preconditions.checkState(\n            skipped \u003d\u003d targetReaderOffset - currentReaderOffset);\n      }\n\n      int ret \u003d 0;\n      for (ByteBufferStrategy strategy : strategies) {\n        int bytesReead \u003d readToBuffer(reader, datanode, strategy, currentBlock);\n        ret +\u003d bytesReead;\n      }\n      return new BlockReadStats(ret, reader.isShortCircuit(),\n          reader.getNetworkDistance());\n    };\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/StripeReader.java",
          "extendedDetails": {
            "oldValue": "Callable\u003cVoid\u003e",
            "newValue": "Callable\u003cBlockReadStats\u003e"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13926. ThreadLocal aggregations for FileSystem.Statistics are incorrect with striped reads.\nContributed by Xiao Chen, Hrishikesh Gadre.\n\nSigned-off-by: Xiao Chen \u003cxiao@apache.org\u003e\n",
          "commitDate": "08/10/18 8:31 PM",
          "commitName": "08bb6c49a5aec32b7d9f29238560f947420405d6",
          "commitAuthor": "Hrishikesh Gadre",
          "commitDateOld": "26/04/18 1:54 PM",
          "commitNameOld": "a8e428b2dc0883184b43cb776d5c7196aaa3bf56",
          "commitAuthorOld": "Lei Xu",
          "daysBetweenCommits": 165.28,
          "commitsBetweenForRepo": 1297,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,24 +1,27 @@\n-  private Callable\u003cVoid\u003e readCells(final BlockReader reader,\n+  private Callable\u003cBlockReadStats\u003e readCells(final BlockReader reader,\n       final DatanodeInfo datanode, final long currentReaderOffset,\n       final long targetReaderOffset, final ByteBufferStrategy[] strategies,\n       final ExtendedBlock currentBlock) {\n     return () -\u003e {\n       // reader can be null if getBlockReaderWithRetry failed or\n       // the reader hit exception before\n       if (reader \u003d\u003d null) {\n         throw new IOException(\"The BlockReader is null. \" +\n             \"The BlockReader creation failed or the reader hit exception.\");\n       }\n       Preconditions.checkState(currentReaderOffset \u003c\u003d targetReaderOffset);\n       if (currentReaderOffset \u003c targetReaderOffset) {\n         long skipped \u003d reader.skip(targetReaderOffset - currentReaderOffset);\n         Preconditions.checkState(\n             skipped \u003d\u003d targetReaderOffset - currentReaderOffset);\n       }\n \n+      int ret \u003d 0;\n       for (ByteBufferStrategy strategy : strategies) {\n-        readToBuffer(reader, datanode, strategy, currentBlock);\n+        int bytesReead \u003d readToBuffer(reader, datanode, strategy, currentBlock);\n+        ret +\u003d bytesReead;\n       }\n-      return null;\n+      return new BlockReadStats(ret, reader.isShortCircuit(),\n+          reader.getNetworkDistance());\n     };\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Callable\u003cBlockReadStats\u003e readCells(final BlockReader reader,\n      final DatanodeInfo datanode, final long currentReaderOffset,\n      final long targetReaderOffset, final ByteBufferStrategy[] strategies,\n      final ExtendedBlock currentBlock) {\n    return () -\u003e {\n      // reader can be null if getBlockReaderWithRetry failed or\n      // the reader hit exception before\n      if (reader \u003d\u003d null) {\n        throw new IOException(\"The BlockReader is null. \" +\n            \"The BlockReader creation failed or the reader hit exception.\");\n      }\n      Preconditions.checkState(currentReaderOffset \u003c\u003d targetReaderOffset);\n      if (currentReaderOffset \u003c targetReaderOffset) {\n        long skipped \u003d reader.skip(targetReaderOffset - currentReaderOffset);\n        Preconditions.checkState(\n            skipped \u003d\u003d targetReaderOffset - currentReaderOffset);\n      }\n\n      int ret \u003d 0;\n      for (ByteBufferStrategy strategy : strategies) {\n        int bytesReead \u003d readToBuffer(reader, datanode, strategy, currentBlock);\n        ret +\u003d bytesReead;\n      }\n      return new BlockReadStats(ret, reader.isShortCircuit(),\n          reader.getNetworkDistance());\n    };\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/StripeReader.java",
          "extendedDetails": {}
        }
      ]
    },
    "734d54c1a8950446e68098f62d8964e02ecc2890": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange,Yparameterchange)",
      "commitMessage": "HDFS-10861. Refactor StripeReaders and use ECChunk version decode API. Contributed by Sammi Chen\n",
      "commitDate": "21/09/16 6:34 AM",
      "commitName": "734d54c1a8950446e68098f62d8964e02ecc2890",
      "commitAuthor": "Kai Zheng",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-10861. Refactor StripeReaders and use ECChunk version decode API. Contributed by Sammi Chen\n",
          "commitDate": "21/09/16 6:34 AM",
          "commitName": "734d54c1a8950446e68098f62d8964e02ecc2890",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "20/09/16 12:03 AM",
          "commitNameOld": "2b66d9ec5bdaec7e6b278926fbb6f222c4e3afaa",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 1.27,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,24 @@\n   private Callable\u003cVoid\u003e readCells(final BlockReader reader,\n       final DatanodeInfo datanode, final long currentReaderOffset,\n       final long targetReaderOffset, final ByteBufferStrategy[] strategies,\n-      final ExtendedBlock currentBlock,\n-      final CorruptedBlocks corruptedBlocks) {\n-    return new Callable\u003cVoid\u003e() {\n-      @Override\n-      public Void call() throws Exception {\n-        // reader can be null if getBlockReaderWithRetry failed or\n-        // the reader hit exception before\n-        if (reader \u003d\u003d null) {\n-          throw new IOException(\"The BlockReader is null. \" +\n-              \"The BlockReader creation failed or the reader hit exception.\");\n-        }\n-        Preconditions.checkState(currentReaderOffset \u003c\u003d targetReaderOffset);\n-        if (currentReaderOffset \u003c targetReaderOffset) {\n-          long skipped \u003d reader.skip(targetReaderOffset - currentReaderOffset);\n-          Preconditions.checkState(\n-              skipped \u003d\u003d targetReaderOffset - currentReaderOffset);\n-        }\n-        int result \u003d 0;\n-        for (ByteBufferStrategy strategy : strategies) {\n-          result +\u003d readToBuffer(reader, datanode, strategy, currentBlock,\n-              corruptedBlocks);\n-        }\n-        return null;\n+      final ExtendedBlock currentBlock) {\n+    return () -\u003e {\n+      // reader can be null if getBlockReaderWithRetry failed or\n+      // the reader hit exception before\n+      if (reader \u003d\u003d null) {\n+        throw new IOException(\"The BlockReader is null. \" +\n+            \"The BlockReader creation failed or the reader hit exception.\");\n       }\n+      Preconditions.checkState(currentReaderOffset \u003c\u003d targetReaderOffset);\n+      if (currentReaderOffset \u003c targetReaderOffset) {\n+        long skipped \u003d reader.skip(targetReaderOffset - currentReaderOffset);\n+        Preconditions.checkState(\n+            skipped \u003d\u003d targetReaderOffset - currentReaderOffset);\n+      }\n+\n+      for (ByteBufferStrategy strategy : strategies) {\n+        readToBuffer(reader, datanode, strategy, currentBlock);\n+      }\n+      return null;\n     };\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Callable\u003cVoid\u003e readCells(final BlockReader reader,\n      final DatanodeInfo datanode, final long currentReaderOffset,\n      final long targetReaderOffset, final ByteBufferStrategy[] strategies,\n      final ExtendedBlock currentBlock) {\n    return () -\u003e {\n      // reader can be null if getBlockReaderWithRetry failed or\n      // the reader hit exception before\n      if (reader \u003d\u003d null) {\n        throw new IOException(\"The BlockReader is null. \" +\n            \"The BlockReader creation failed or the reader hit exception.\");\n      }\n      Preconditions.checkState(currentReaderOffset \u003c\u003d targetReaderOffset);\n      if (currentReaderOffset \u003c targetReaderOffset) {\n        long skipped \u003d reader.skip(targetReaderOffset - currentReaderOffset);\n        Preconditions.checkState(\n            skipped \u003d\u003d targetReaderOffset - currentReaderOffset);\n      }\n\n      for (ByteBufferStrategy strategy : strategies) {\n        readToBuffer(reader, datanode, strategy, currentBlock);\n      }\n      return null;\n    };\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/StripeReader.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/StripeReader.java",
            "oldMethodName": "readCells",
            "newMethodName": "readCells"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10861. Refactor StripeReaders and use ECChunk version decode API. Contributed by Sammi Chen\n",
          "commitDate": "21/09/16 6:34 AM",
          "commitName": "734d54c1a8950446e68098f62d8964e02ecc2890",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "20/09/16 12:03 AM",
          "commitNameOld": "2b66d9ec5bdaec7e6b278926fbb6f222c4e3afaa",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 1.27,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,24 @@\n   private Callable\u003cVoid\u003e readCells(final BlockReader reader,\n       final DatanodeInfo datanode, final long currentReaderOffset,\n       final long targetReaderOffset, final ByteBufferStrategy[] strategies,\n-      final ExtendedBlock currentBlock,\n-      final CorruptedBlocks corruptedBlocks) {\n-    return new Callable\u003cVoid\u003e() {\n-      @Override\n-      public Void call() throws Exception {\n-        // reader can be null if getBlockReaderWithRetry failed or\n-        // the reader hit exception before\n-        if (reader \u003d\u003d null) {\n-          throw new IOException(\"The BlockReader is null. \" +\n-              \"The BlockReader creation failed or the reader hit exception.\");\n-        }\n-        Preconditions.checkState(currentReaderOffset \u003c\u003d targetReaderOffset);\n-        if (currentReaderOffset \u003c targetReaderOffset) {\n-          long skipped \u003d reader.skip(targetReaderOffset - currentReaderOffset);\n-          Preconditions.checkState(\n-              skipped \u003d\u003d targetReaderOffset - currentReaderOffset);\n-        }\n-        int result \u003d 0;\n-        for (ByteBufferStrategy strategy : strategies) {\n-          result +\u003d readToBuffer(reader, datanode, strategy, currentBlock,\n-              corruptedBlocks);\n-        }\n-        return null;\n+      final ExtendedBlock currentBlock) {\n+    return () -\u003e {\n+      // reader can be null if getBlockReaderWithRetry failed or\n+      // the reader hit exception before\n+      if (reader \u003d\u003d null) {\n+        throw new IOException(\"The BlockReader is null. \" +\n+            \"The BlockReader creation failed or the reader hit exception.\");\n       }\n+      Preconditions.checkState(currentReaderOffset \u003c\u003d targetReaderOffset);\n+      if (currentReaderOffset \u003c targetReaderOffset) {\n+        long skipped \u003d reader.skip(targetReaderOffset - currentReaderOffset);\n+        Preconditions.checkState(\n+            skipped \u003d\u003d targetReaderOffset - currentReaderOffset);\n+      }\n+\n+      for (ByteBufferStrategy strategy : strategies) {\n+        readToBuffer(reader, datanode, strategy, currentBlock);\n+      }\n+      return null;\n     };\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Callable\u003cVoid\u003e readCells(final BlockReader reader,\n      final DatanodeInfo datanode, final long currentReaderOffset,\n      final long targetReaderOffset, final ByteBufferStrategy[] strategies,\n      final ExtendedBlock currentBlock) {\n    return () -\u003e {\n      // reader can be null if getBlockReaderWithRetry failed or\n      // the reader hit exception before\n      if (reader \u003d\u003d null) {\n        throw new IOException(\"The BlockReader is null. \" +\n            \"The BlockReader creation failed or the reader hit exception.\");\n      }\n      Preconditions.checkState(currentReaderOffset \u003c\u003d targetReaderOffset);\n      if (currentReaderOffset \u003c targetReaderOffset) {\n        long skipped \u003d reader.skip(targetReaderOffset - currentReaderOffset);\n        Preconditions.checkState(\n            skipped \u003d\u003d targetReaderOffset - currentReaderOffset);\n      }\n\n      for (ByteBufferStrategy strategy : strategies) {\n        readToBuffer(reader, datanode, strategy, currentBlock);\n      }\n      return null;\n    };\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/StripeReader.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-10861. Refactor StripeReaders and use ECChunk version decode API. Contributed by Sammi Chen\n",
          "commitDate": "21/09/16 6:34 AM",
          "commitName": "734d54c1a8950446e68098f62d8964e02ecc2890",
          "commitAuthor": "Kai Zheng",
          "commitDateOld": "20/09/16 12:03 AM",
          "commitNameOld": "2b66d9ec5bdaec7e6b278926fbb6f222c4e3afaa",
          "commitAuthorOld": "Jian He",
          "daysBetweenCommits": 1.27,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,24 @@\n   private Callable\u003cVoid\u003e readCells(final BlockReader reader,\n       final DatanodeInfo datanode, final long currentReaderOffset,\n       final long targetReaderOffset, final ByteBufferStrategy[] strategies,\n-      final ExtendedBlock currentBlock,\n-      final CorruptedBlocks corruptedBlocks) {\n-    return new Callable\u003cVoid\u003e() {\n-      @Override\n-      public Void call() throws Exception {\n-        // reader can be null if getBlockReaderWithRetry failed or\n-        // the reader hit exception before\n-        if (reader \u003d\u003d null) {\n-          throw new IOException(\"The BlockReader is null. \" +\n-              \"The BlockReader creation failed or the reader hit exception.\");\n-        }\n-        Preconditions.checkState(currentReaderOffset \u003c\u003d targetReaderOffset);\n-        if (currentReaderOffset \u003c targetReaderOffset) {\n-          long skipped \u003d reader.skip(targetReaderOffset - currentReaderOffset);\n-          Preconditions.checkState(\n-              skipped \u003d\u003d targetReaderOffset - currentReaderOffset);\n-        }\n-        int result \u003d 0;\n-        for (ByteBufferStrategy strategy : strategies) {\n-          result +\u003d readToBuffer(reader, datanode, strategy, currentBlock,\n-              corruptedBlocks);\n-        }\n-        return null;\n+      final ExtendedBlock currentBlock) {\n+    return () -\u003e {\n+      // reader can be null if getBlockReaderWithRetry failed or\n+      // the reader hit exception before\n+      if (reader \u003d\u003d null) {\n+        throw new IOException(\"The BlockReader is null. \" +\n+            \"The BlockReader creation failed or the reader hit exception.\");\n       }\n+      Preconditions.checkState(currentReaderOffset \u003c\u003d targetReaderOffset);\n+      if (currentReaderOffset \u003c targetReaderOffset) {\n+        long skipped \u003d reader.skip(targetReaderOffset - currentReaderOffset);\n+        Preconditions.checkState(\n+            skipped \u003d\u003d targetReaderOffset - currentReaderOffset);\n+      }\n+\n+      for (ByteBufferStrategy strategy : strategies) {\n+        readToBuffer(reader, datanode, strategy, currentBlock);\n+      }\n+      return null;\n     };\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Callable\u003cVoid\u003e readCells(final BlockReader reader,\n      final DatanodeInfo datanode, final long currentReaderOffset,\n      final long targetReaderOffset, final ByteBufferStrategy[] strategies,\n      final ExtendedBlock currentBlock) {\n    return () -\u003e {\n      // reader can be null if getBlockReaderWithRetry failed or\n      // the reader hit exception before\n      if (reader \u003d\u003d null) {\n        throw new IOException(\"The BlockReader is null. \" +\n            \"The BlockReader creation failed or the reader hit exception.\");\n      }\n      Preconditions.checkState(currentReaderOffset \u003c\u003d targetReaderOffset);\n      if (currentReaderOffset \u003c targetReaderOffset) {\n        long skipped \u003d reader.skip(targetReaderOffset - currentReaderOffset);\n        Preconditions.checkState(\n            skipped \u003d\u003d targetReaderOffset - currentReaderOffset);\n      }\n\n      for (ByteBufferStrategy strategy : strategies) {\n        readToBuffer(reader, datanode, strategy, currentBlock);\n      }\n      return null;\n    };\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/StripeReader.java",
          "extendedDetails": {
            "oldValue": "[reader-BlockReader(modifiers-final), datanode-DatanodeInfo(modifiers-final), currentReaderOffset-long(modifiers-final), targetReaderOffset-long(modifiers-final), strategies-ByteBufferStrategy[](modifiers-final), currentBlock-ExtendedBlock(modifiers-final), corruptedBlocks-CorruptedBlocks(modifiers-final)]",
            "newValue": "[reader-BlockReader(modifiers-final), datanode-DatanodeInfo(modifiers-final), currentReaderOffset-long(modifiers-final), targetReaderOffset-long(modifiers-final), strategies-ByteBufferStrategy[](modifiers-final), currentBlock-ExtendedBlock(modifiers-final)]"
          }
        }
      ]
    },
    "8808779db351fe444388d4acb3094766b5980718": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-9734. Refactoring of checksum failure report related codes. Contributed by Kai Zheng.\n\nChange-Id: Ie69a77e3498a360959f8e213c51fb2b17c28b64a\n",
      "commitDate": "25/02/16 9:55 AM",
      "commitName": "8808779db351fe444388d4acb3094766b5980718",
      "commitAuthor": "Zhe Zhang",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-9734. Refactoring of checksum failure report related codes. Contributed by Kai Zheng.\n\nChange-Id: Ie69a77e3498a360959f8e213c51fb2b17c28b64a\n",
          "commitDate": "25/02/16 9:55 AM",
          "commitName": "8808779db351fe444388d4acb3094766b5980718",
          "commitAuthor": "Zhe Zhang",
          "commitDateOld": "19/02/16 7:02 PM",
          "commitNameOld": "e54cc2931262bf49682a8323da9811976218c03b",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 5.62,
          "commitsBetweenForRepo": 38,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,29 @@\n   private Callable\u003cVoid\u003e readCells(final BlockReader reader,\n       final DatanodeInfo datanode, final long currentReaderOffset,\n       final long targetReaderOffset, final ByteBufferStrategy[] strategies,\n       final ExtendedBlock currentBlock,\n-      final Map\u003cExtendedBlock, Set\u003cDatanodeInfo\u003e\u003e corruptedBlockMap) {\n+      final CorruptedBlocks corruptedBlocks) {\n     return new Callable\u003cVoid\u003e() {\n       @Override\n       public Void call() throws Exception {\n         // reader can be null if getBlockReaderWithRetry failed or\n         // the reader hit exception before\n         if (reader \u003d\u003d null) {\n           throw new IOException(\"The BlockReader is null. \" +\n               \"The BlockReader creation failed or the reader hit exception.\");\n         }\n         Preconditions.checkState(currentReaderOffset \u003c\u003d targetReaderOffset);\n         if (currentReaderOffset \u003c targetReaderOffset) {\n           long skipped \u003d reader.skip(targetReaderOffset - currentReaderOffset);\n           Preconditions.checkState(\n               skipped \u003d\u003d targetReaderOffset - currentReaderOffset);\n         }\n         int result \u003d 0;\n         for (ByteBufferStrategy strategy : strategies) {\n           result +\u003d readToBuffer(reader, datanode, strategy, currentBlock,\n-              corruptedBlockMap);\n+              corruptedBlocks);\n         }\n         return null;\n       }\n     };\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Callable\u003cVoid\u003e readCells(final BlockReader reader,\n      final DatanodeInfo datanode, final long currentReaderOffset,\n      final long targetReaderOffset, final ByteBufferStrategy[] strategies,\n      final ExtendedBlock currentBlock,\n      final CorruptedBlocks corruptedBlocks) {\n    return new Callable\u003cVoid\u003e() {\n      @Override\n      public Void call() throws Exception {\n        // reader can be null if getBlockReaderWithRetry failed or\n        // the reader hit exception before\n        if (reader \u003d\u003d null) {\n          throw new IOException(\"The BlockReader is null. \" +\n              \"The BlockReader creation failed or the reader hit exception.\");\n        }\n        Preconditions.checkState(currentReaderOffset \u003c\u003d targetReaderOffset);\n        if (currentReaderOffset \u003c targetReaderOffset) {\n          long skipped \u003d reader.skip(targetReaderOffset - currentReaderOffset);\n          Preconditions.checkState(\n              skipped \u003d\u003d targetReaderOffset - currentReaderOffset);\n        }\n        int result \u003d 0;\n        for (ByteBufferStrategy strategy : strategies) {\n          result +\u003d readToBuffer(reader, datanode, strategy, currentBlock,\n              corruptedBlocks);\n        }\n        return null;\n      }\n    };\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
          "extendedDetails": {
            "oldValue": "[reader-BlockReader(modifiers-final), datanode-DatanodeInfo(modifiers-final), currentReaderOffset-long(modifiers-final), targetReaderOffset-long(modifiers-final), strategies-ByteBufferStrategy[](modifiers-final), currentBlock-ExtendedBlock(modifiers-final), corruptedBlockMap-Map\u003cExtendedBlock,Set\u003cDatanodeInfo\u003e\u003e(modifiers-final)]",
            "newValue": "[reader-BlockReader(modifiers-final), datanode-DatanodeInfo(modifiers-final), currentReaderOffset-long(modifiers-final), targetReaderOffset-long(modifiers-final), strategies-ByteBufferStrategy[](modifiers-final), currentBlock-ExtendedBlock(modifiers-final), corruptedBlocks-CorruptedBlocks(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-9734. Refactoring of checksum failure report related codes. Contributed by Kai Zheng.\n\nChange-Id: Ie69a77e3498a360959f8e213c51fb2b17c28b64a\n",
          "commitDate": "25/02/16 9:55 AM",
          "commitName": "8808779db351fe444388d4acb3094766b5980718",
          "commitAuthor": "Zhe Zhang",
          "commitDateOld": "19/02/16 7:02 PM",
          "commitNameOld": "e54cc2931262bf49682a8323da9811976218c03b",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 5.62,
          "commitsBetweenForRepo": 38,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,29 @@\n   private Callable\u003cVoid\u003e readCells(final BlockReader reader,\n       final DatanodeInfo datanode, final long currentReaderOffset,\n       final long targetReaderOffset, final ByteBufferStrategy[] strategies,\n       final ExtendedBlock currentBlock,\n-      final Map\u003cExtendedBlock, Set\u003cDatanodeInfo\u003e\u003e corruptedBlockMap) {\n+      final CorruptedBlocks corruptedBlocks) {\n     return new Callable\u003cVoid\u003e() {\n       @Override\n       public Void call() throws Exception {\n         // reader can be null if getBlockReaderWithRetry failed or\n         // the reader hit exception before\n         if (reader \u003d\u003d null) {\n           throw new IOException(\"The BlockReader is null. \" +\n               \"The BlockReader creation failed or the reader hit exception.\");\n         }\n         Preconditions.checkState(currentReaderOffset \u003c\u003d targetReaderOffset);\n         if (currentReaderOffset \u003c targetReaderOffset) {\n           long skipped \u003d reader.skip(targetReaderOffset - currentReaderOffset);\n           Preconditions.checkState(\n               skipped \u003d\u003d targetReaderOffset - currentReaderOffset);\n         }\n         int result \u003d 0;\n         for (ByteBufferStrategy strategy : strategies) {\n           result +\u003d readToBuffer(reader, datanode, strategy, currentBlock,\n-              corruptedBlockMap);\n+              corruptedBlocks);\n         }\n         return null;\n       }\n     };\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private Callable\u003cVoid\u003e readCells(final BlockReader reader,\n      final DatanodeInfo datanode, final long currentReaderOffset,\n      final long targetReaderOffset, final ByteBufferStrategy[] strategies,\n      final ExtendedBlock currentBlock,\n      final CorruptedBlocks corruptedBlocks) {\n    return new Callable\u003cVoid\u003e() {\n      @Override\n      public Void call() throws Exception {\n        // reader can be null if getBlockReaderWithRetry failed or\n        // the reader hit exception before\n        if (reader \u003d\u003d null) {\n          throw new IOException(\"The BlockReader is null. \" +\n              \"The BlockReader creation failed or the reader hit exception.\");\n        }\n        Preconditions.checkState(currentReaderOffset \u003c\u003d targetReaderOffset);\n        if (currentReaderOffset \u003c targetReaderOffset) {\n          long skipped \u003d reader.skip(targetReaderOffset - currentReaderOffset);\n          Preconditions.checkState(\n              skipped \u003d\u003d targetReaderOffset - currentReaderOffset);\n        }\n        int result \u003d 0;\n        for (ByteBufferStrategy strategy : strategies) {\n          result +\u003d readToBuffer(reader, datanode, strategy, currentBlock,\n              corruptedBlocks);\n        }\n        return null;\n      }\n    };\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSStripedInputStream.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}