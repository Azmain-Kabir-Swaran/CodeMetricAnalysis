{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSDirSatisfyStoragePolicyOp.java",
  "functionName": "unprotectedSatisfyStoragePolicy",
  "functionId": "unprotectedSatisfyStoragePolicy___inode-INode__fsd-FSDirectory",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
  "functionStartLine": 118,
  "functionEndLine": 131,
  "numCommitsSeen": 81,
  "timeTaken": 9021,
  "changeHistory": [
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
    "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d",
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
    "d638a7dc0363dbe07deb8c389116132814267b10",
    "5ce332dc9a072f8850ab71ba16898faf8e866c06",
    "6215e35bb633706753a464ad3e8633366e6a10b2",
    "b67ae6d9d741e79ccf2bd6f08a37fce070e6ad77"
  ],
  "changeHistoryShort": {
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": "Ybodychange",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": "Ybodychange",
    "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d": "Ybodychange",
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064": "Ymultichange(Yparameterchange,Yreturntypechange,Yexceptionschange,Ybodychange)",
    "d638a7dc0363dbe07deb8c389116132814267b10": "Ybodychange",
    "5ce332dc9a072f8850ab71ba16898faf8e866c06": "Ymovefromfile",
    "6215e35bb633706753a464ad3e8633366e6a10b2": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
    "b67ae6d9d741e79ccf2bd6f08a37fce070e6ad77": "Yintroduced"
  },
  "changeHistoryDetails": {
    "2acc50b826fa8b00f2b09d9546c4b3215b89d46d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13165: [SPS]: Collects successfully moved block details via IBR. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "2acc50b826fa8b00f2b09d9546c4b3215b89d46d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 3,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,14 @@\n   static boolean unprotectedSatisfyStoragePolicy(INode inode, FSDirectory fsd) {\n     if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() \u003d\u003d 0) {\n       return false;\n     } else {\n       // Adding directory in the pending queue, so FileInodeIdCollector process\n       // directory child in batch and recursively\n-      fsd.getBlockManager().getSPSManager().addPathId(inode.getId());\n+      StoragePolicySatisfyManager spsManager \u003d\n+          fsd.getBlockManager().getSPSManager();\n+      if (spsManager !\u003d null) {\n+        spsManager.addPathId(inode.getId());\n+      }\n       return true;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static boolean unprotectedSatisfyStoragePolicy(INode inode, FSDirectory fsd) {\n    if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() \u003d\u003d 0) {\n      return false;\n    } else {\n      // Adding directory in the pending queue, so FileInodeIdCollector process\n      // directory child in batch and recursively\n      StoragePolicySatisfyManager spsManager \u003d\n          fsd.getBlockManager().getSPSManager();\n      if (spsManager !\u003d null) {\n        spsManager.addPathId(inode.getId());\n      }\n      return true;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
      "extendedDetails": {}
    },
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13097: [SPS]: Fix the branch review comments(Part1). Contributed by Surendra Singh.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "d3de4fb2a084cbadab8ef91f11aa7732d3b0f308",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,10 @@\n   static boolean unprotectedSatisfyStoragePolicy(INode inode, FSDirectory fsd) {\n     if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() \u003d\u003d 0) {\n       return false;\n     } else {\n       // Adding directory in the pending queue, so FileInodeIdCollector process\n       // directory child in batch and recursively\n-      fsd.getBlockManager().addSPSPathId(inode.getId());\n+      fsd.getBlockManager().getSPSManager().addPathId(inode.getId());\n       return true;\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static boolean unprotectedSatisfyStoragePolicy(INode inode, FSDirectory fsd) {\n    if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() \u003d\u003d 0) {\n      return false;\n    } else {\n      // Adding directory in the pending queue, so FileInodeIdCollector process\n      // directory child in batch and recursively\n      fsd.getBlockManager().getSPSManager().addPathId(inode.getId());\n      return true;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
      "extendedDetails": {}
    },
    "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12911. [SPS]: Modularize the SPS code and expose necessary interfaces for external/internal implementations. Contributed by Uma Maheswara Rao G\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "8d4f74e7339abc77dc0daa162d7bd2814bd79b3d",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 9,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,17 +1,10 @@\n   static boolean unprotectedSatisfyStoragePolicy(INode inode, FSDirectory fsd) {\n-    if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() !\u003d 0) {\n-      // Adding directly in the storageMovementNeeded queue, So it can\n-      // get more priority compare to directory.\n-      fsd.getBlockManager().getStoragePolicySatisfier()\n-          .satisfyStoragePolicy(inode.getId());\n-      return true;\n-    } else if (inode.isDirectory()\n-        \u0026\u0026 inode.asDirectory().getChildrenNum(Snapshot.CURRENT_STATE_ID) \u003e 0) {\n+    if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() \u003d\u003d 0) {\n+      return false;\n+    } else {\n       // Adding directory in the pending queue, so FileInodeIdCollector process\n       // directory child in batch and recursively\n-      fsd.getBlockManager().getStoragePolicySatisfier()\n-          .addInodeToPendingDirQueue(inode.getId());\n+      fsd.getBlockManager().addSPSPathId(inode.getId());\n       return true;\n     }\n-    return false;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static boolean unprotectedSatisfyStoragePolicy(INode inode, FSDirectory fsd) {\n    if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() \u003d\u003d 0) {\n      return false;\n    } else {\n      // Adding directory in the pending queue, so FileInodeIdCollector process\n      // directory child in batch and recursively\n      fsd.getBlockManager().addSPSPathId(inode.getId());\n      return true;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
      "extendedDetails": {}
    },
    "7ea24fc06c081e2ba6f5f66d212abb14b80c9064": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-12225: [SPS]: Optimize extended attributes for tracking SPS movements. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-12225: [SPS]: Optimize extended attributes for tracking SPS movements. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "d638a7dc0363dbe07deb8c389116132814267b10",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 11,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,46 +1,17 @@\n-  static XAttr unprotectedSatisfyStoragePolicy(INodesInPath iip,\n-      BlockManager bm, FSDirectory fsd) throws IOException {\n-\n-    final INode inode \u003d FSDirectory.resolveLastINode(iip);\n-    final int snapshotId \u003d iip.getLatestSnapshotId();\n-    final List\u003cINode\u003e candidateNodes \u003d new ArrayList\u003c\u003e();\n-\n-    // TODO: think about optimization here, label the dir instead\n-    // of the sub-files of the dir.\n+  static boolean unprotectedSatisfyStoragePolicy(INode inode, FSDirectory fsd) {\n     if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() !\u003d 0) {\n-      candidateNodes.add(inode);\n-    } else if (inode.isDirectory()) {\n-      for (INode node : inode.asDirectory().getChildrenList(snapshotId)) {\n-        if (node.isFile() \u0026\u0026 node.asFile().numBlocks() !\u003d 0) {\n-          candidateNodes.add(node);\n-        }\n-      }\n+      // Adding directly in the storageMovementNeeded queue, So it can\n+      // get more priority compare to directory.\n+      fsd.getBlockManager().getStoragePolicySatisfier()\n+          .satisfyStoragePolicy(inode.getId());\n+      return true;\n+    } else if (inode.isDirectory()\n+        \u0026\u0026 inode.asDirectory().getChildrenNum(Snapshot.CURRENT_STATE_ID) \u003e 0) {\n+      // Adding directory in the pending queue, so FileInodeIdCollector process\n+      // directory child in batch and recursively\n+      fsd.getBlockManager().getStoragePolicySatisfier()\n+          .addInodeToPendingDirQueue(inode.getId());\n+      return true;\n     }\n-\n-    if (candidateNodes.isEmpty()) {\n-      return null;\n-    }\n-    // If node has satisfy xattr, then stop adding it\n-    // to satisfy movement queue.\n-    if (inodeHasSatisfyXAttr(candidateNodes)) {\n-      throw new IOException(\n-          \"Cannot request to call satisfy storage policy on path \"\n-              + iip.getPath()\n-              + \", as this file/dir was already called for satisfying \"\n-              + \"storage policy.\");\n-    }\n-\n-    final List\u003cXAttr\u003e xattrs \u003d Lists.newArrayListWithCapacity(1);\n-    final XAttr satisfyXAttr \u003d XAttrHelper\n-        .buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n-    xattrs.add(satisfyXAttr);\n-\n-    for (INode node : candidateNodes) {\n-      bm.satisfyStoragePolicy(node.getId());\n-      List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(node);\n-      List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(fsd, existingXAttrs,\n-          xattrs, EnumSet.of(XAttrSetFlag.CREATE));\n-      XAttrStorage.updateINodeXAttrs(node, newXAttrs, snapshotId);\n-    }\n-    return satisfyXAttr;\n+    return false;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static boolean unprotectedSatisfyStoragePolicy(INode inode, FSDirectory fsd) {\n    if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() !\u003d 0) {\n      // Adding directly in the storageMovementNeeded queue, So it can\n      // get more priority compare to directory.\n      fsd.getBlockManager().getStoragePolicySatisfier()\n          .satisfyStoragePolicy(inode.getId());\n      return true;\n    } else if (inode.isDirectory()\n        \u0026\u0026 inode.asDirectory().getChildrenNum(Snapshot.CURRENT_STATE_ID) \u003e 0) {\n      // Adding directory in the pending queue, so FileInodeIdCollector process\n      // directory child in batch and recursively\n      fsd.getBlockManager().getStoragePolicySatisfier()\n          .addInodeToPendingDirQueue(inode.getId());\n      return true;\n    }\n    return false;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
          "extendedDetails": {
            "oldValue": "[iip-INodesInPath, bm-BlockManager, fsd-FSDirectory]",
            "newValue": "[inode-INode, fsd-FSDirectory]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-12225: [SPS]: Optimize extended attributes for tracking SPS movements. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "d638a7dc0363dbe07deb8c389116132814267b10",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 11,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,46 +1,17 @@\n-  static XAttr unprotectedSatisfyStoragePolicy(INodesInPath iip,\n-      BlockManager bm, FSDirectory fsd) throws IOException {\n-\n-    final INode inode \u003d FSDirectory.resolveLastINode(iip);\n-    final int snapshotId \u003d iip.getLatestSnapshotId();\n-    final List\u003cINode\u003e candidateNodes \u003d new ArrayList\u003c\u003e();\n-\n-    // TODO: think about optimization here, label the dir instead\n-    // of the sub-files of the dir.\n+  static boolean unprotectedSatisfyStoragePolicy(INode inode, FSDirectory fsd) {\n     if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() !\u003d 0) {\n-      candidateNodes.add(inode);\n-    } else if (inode.isDirectory()) {\n-      for (INode node : inode.asDirectory().getChildrenList(snapshotId)) {\n-        if (node.isFile() \u0026\u0026 node.asFile().numBlocks() !\u003d 0) {\n-          candidateNodes.add(node);\n-        }\n-      }\n+      // Adding directly in the storageMovementNeeded queue, So it can\n+      // get more priority compare to directory.\n+      fsd.getBlockManager().getStoragePolicySatisfier()\n+          .satisfyStoragePolicy(inode.getId());\n+      return true;\n+    } else if (inode.isDirectory()\n+        \u0026\u0026 inode.asDirectory().getChildrenNum(Snapshot.CURRENT_STATE_ID) \u003e 0) {\n+      // Adding directory in the pending queue, so FileInodeIdCollector process\n+      // directory child in batch and recursively\n+      fsd.getBlockManager().getStoragePolicySatisfier()\n+          .addInodeToPendingDirQueue(inode.getId());\n+      return true;\n     }\n-\n-    if (candidateNodes.isEmpty()) {\n-      return null;\n-    }\n-    // If node has satisfy xattr, then stop adding it\n-    // to satisfy movement queue.\n-    if (inodeHasSatisfyXAttr(candidateNodes)) {\n-      throw new IOException(\n-          \"Cannot request to call satisfy storage policy on path \"\n-              + iip.getPath()\n-              + \", as this file/dir was already called for satisfying \"\n-              + \"storage policy.\");\n-    }\n-\n-    final List\u003cXAttr\u003e xattrs \u003d Lists.newArrayListWithCapacity(1);\n-    final XAttr satisfyXAttr \u003d XAttrHelper\n-        .buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n-    xattrs.add(satisfyXAttr);\n-\n-    for (INode node : candidateNodes) {\n-      bm.satisfyStoragePolicy(node.getId());\n-      List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(node);\n-      List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(fsd, existingXAttrs,\n-          xattrs, EnumSet.of(XAttrSetFlag.CREATE));\n-      XAttrStorage.updateINodeXAttrs(node, newXAttrs, snapshotId);\n-    }\n-    return satisfyXAttr;\n+    return false;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static boolean unprotectedSatisfyStoragePolicy(INode inode, FSDirectory fsd) {\n    if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() !\u003d 0) {\n      // Adding directly in the storageMovementNeeded queue, So it can\n      // get more priority compare to directory.\n      fsd.getBlockManager().getStoragePolicySatisfier()\n          .satisfyStoragePolicy(inode.getId());\n      return true;\n    } else if (inode.isDirectory()\n        \u0026\u0026 inode.asDirectory().getChildrenNum(Snapshot.CURRENT_STATE_ID) \u003e 0) {\n      // Adding directory in the pending queue, so FileInodeIdCollector process\n      // directory child in batch and recursively\n      fsd.getBlockManager().getStoragePolicySatisfier()\n          .addInodeToPendingDirQueue(inode.getId());\n      return true;\n    }\n    return false;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
          "extendedDetails": {
            "oldValue": "XAttr",
            "newValue": "boolean"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-12225: [SPS]: Optimize extended attributes for tracking SPS movements. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "d638a7dc0363dbe07deb8c389116132814267b10",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 11,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,46 +1,17 @@\n-  static XAttr unprotectedSatisfyStoragePolicy(INodesInPath iip,\n-      BlockManager bm, FSDirectory fsd) throws IOException {\n-\n-    final INode inode \u003d FSDirectory.resolveLastINode(iip);\n-    final int snapshotId \u003d iip.getLatestSnapshotId();\n-    final List\u003cINode\u003e candidateNodes \u003d new ArrayList\u003c\u003e();\n-\n-    // TODO: think about optimization here, label the dir instead\n-    // of the sub-files of the dir.\n+  static boolean unprotectedSatisfyStoragePolicy(INode inode, FSDirectory fsd) {\n     if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() !\u003d 0) {\n-      candidateNodes.add(inode);\n-    } else if (inode.isDirectory()) {\n-      for (INode node : inode.asDirectory().getChildrenList(snapshotId)) {\n-        if (node.isFile() \u0026\u0026 node.asFile().numBlocks() !\u003d 0) {\n-          candidateNodes.add(node);\n-        }\n-      }\n+      // Adding directly in the storageMovementNeeded queue, So it can\n+      // get more priority compare to directory.\n+      fsd.getBlockManager().getStoragePolicySatisfier()\n+          .satisfyStoragePolicy(inode.getId());\n+      return true;\n+    } else if (inode.isDirectory()\n+        \u0026\u0026 inode.asDirectory().getChildrenNum(Snapshot.CURRENT_STATE_ID) \u003e 0) {\n+      // Adding directory in the pending queue, so FileInodeIdCollector process\n+      // directory child in batch and recursively\n+      fsd.getBlockManager().getStoragePolicySatisfier()\n+          .addInodeToPendingDirQueue(inode.getId());\n+      return true;\n     }\n-\n-    if (candidateNodes.isEmpty()) {\n-      return null;\n-    }\n-    // If node has satisfy xattr, then stop adding it\n-    // to satisfy movement queue.\n-    if (inodeHasSatisfyXAttr(candidateNodes)) {\n-      throw new IOException(\n-          \"Cannot request to call satisfy storage policy on path \"\n-              + iip.getPath()\n-              + \", as this file/dir was already called for satisfying \"\n-              + \"storage policy.\");\n-    }\n-\n-    final List\u003cXAttr\u003e xattrs \u003d Lists.newArrayListWithCapacity(1);\n-    final XAttr satisfyXAttr \u003d XAttrHelper\n-        .buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n-    xattrs.add(satisfyXAttr);\n-\n-    for (INode node : candidateNodes) {\n-      bm.satisfyStoragePolicy(node.getId());\n-      List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(node);\n-      List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(fsd, existingXAttrs,\n-          xattrs, EnumSet.of(XAttrSetFlag.CREATE));\n-      XAttrStorage.updateINodeXAttrs(node, newXAttrs, snapshotId);\n-    }\n-    return satisfyXAttr;\n+    return false;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static boolean unprotectedSatisfyStoragePolicy(INode inode, FSDirectory fsd) {\n    if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() !\u003d 0) {\n      // Adding directly in the storageMovementNeeded queue, So it can\n      // get more priority compare to directory.\n      fsd.getBlockManager().getStoragePolicySatisfier()\n          .satisfyStoragePolicy(inode.getId());\n      return true;\n    } else if (inode.isDirectory()\n        \u0026\u0026 inode.asDirectory().getChildrenNum(Snapshot.CURRENT_STATE_ID) \u003e 0) {\n      // Adding directory in the pending queue, so FileInodeIdCollector process\n      // directory child in batch and recursively\n      fsd.getBlockManager().getStoragePolicySatisfier()\n          .addInodeToPendingDirQueue(inode.getId());\n      return true;\n    }\n    return false;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
          "extendedDetails": {
            "oldValue": "[IOException]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-12225: [SPS]: Optimize extended attributes for tracking SPS movements. Contributed by Surendra Singh Lilhore.\n",
          "commitDate": "12/08/18 3:06 AM",
          "commitName": "7ea24fc06c081e2ba6f5f66d212abb14b80c9064",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "d638a7dc0363dbe07deb8c389116132814267b10",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 11,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,46 +1,17 @@\n-  static XAttr unprotectedSatisfyStoragePolicy(INodesInPath iip,\n-      BlockManager bm, FSDirectory fsd) throws IOException {\n-\n-    final INode inode \u003d FSDirectory.resolveLastINode(iip);\n-    final int snapshotId \u003d iip.getLatestSnapshotId();\n-    final List\u003cINode\u003e candidateNodes \u003d new ArrayList\u003c\u003e();\n-\n-    // TODO: think about optimization here, label the dir instead\n-    // of the sub-files of the dir.\n+  static boolean unprotectedSatisfyStoragePolicy(INode inode, FSDirectory fsd) {\n     if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() !\u003d 0) {\n-      candidateNodes.add(inode);\n-    } else if (inode.isDirectory()) {\n-      for (INode node : inode.asDirectory().getChildrenList(snapshotId)) {\n-        if (node.isFile() \u0026\u0026 node.asFile().numBlocks() !\u003d 0) {\n-          candidateNodes.add(node);\n-        }\n-      }\n+      // Adding directly in the storageMovementNeeded queue, So it can\n+      // get more priority compare to directory.\n+      fsd.getBlockManager().getStoragePolicySatisfier()\n+          .satisfyStoragePolicy(inode.getId());\n+      return true;\n+    } else if (inode.isDirectory()\n+        \u0026\u0026 inode.asDirectory().getChildrenNum(Snapshot.CURRENT_STATE_ID) \u003e 0) {\n+      // Adding directory in the pending queue, so FileInodeIdCollector process\n+      // directory child in batch and recursively\n+      fsd.getBlockManager().getStoragePolicySatisfier()\n+          .addInodeToPendingDirQueue(inode.getId());\n+      return true;\n     }\n-\n-    if (candidateNodes.isEmpty()) {\n-      return null;\n-    }\n-    // If node has satisfy xattr, then stop adding it\n-    // to satisfy movement queue.\n-    if (inodeHasSatisfyXAttr(candidateNodes)) {\n-      throw new IOException(\n-          \"Cannot request to call satisfy storage policy on path \"\n-              + iip.getPath()\n-              + \", as this file/dir was already called for satisfying \"\n-              + \"storage policy.\");\n-    }\n-\n-    final List\u003cXAttr\u003e xattrs \u003d Lists.newArrayListWithCapacity(1);\n-    final XAttr satisfyXAttr \u003d XAttrHelper\n-        .buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n-    xattrs.add(satisfyXAttr);\n-\n-    for (INode node : candidateNodes) {\n-      bm.satisfyStoragePolicy(node.getId());\n-      List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(node);\n-      List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(fsd, existingXAttrs,\n-          xattrs, EnumSet.of(XAttrSetFlag.CREATE));\n-      XAttrStorage.updateINodeXAttrs(node, newXAttrs, snapshotId);\n-    }\n-    return satisfyXAttr;\n+    return false;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static boolean unprotectedSatisfyStoragePolicy(INode inode, FSDirectory fsd) {\n    if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() !\u003d 0) {\n      // Adding directly in the storageMovementNeeded queue, So it can\n      // get more priority compare to directory.\n      fsd.getBlockManager().getStoragePolicySatisfier()\n          .satisfyStoragePolicy(inode.getId());\n      return true;\n    } else if (inode.isDirectory()\n        \u0026\u0026 inode.asDirectory().getChildrenNum(Snapshot.CURRENT_STATE_ID) \u003e 0) {\n      // Adding directory in the pending queue, so FileInodeIdCollector process\n      // directory child in batch and recursively\n      fsd.getBlockManager().getStoragePolicySatisfier()\n          .addInodeToPendingDirQueue(inode.getId());\n      return true;\n    }\n    return false;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
          "extendedDetails": {}
        }
      ]
    },
    "d638a7dc0363dbe07deb8c389116132814267b10": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-11762. [SPS]: Empty files should be ignored in StoragePolicySatisfier. Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "d638a7dc0363dbe07deb8c389116132814267b10",
      "commitAuthor": "Rakesh Radhakrishnan",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "5ce332dc9a072f8850ab71ba16898faf8e866c06",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,46 @@\n   static XAttr unprotectedSatisfyStoragePolicy(INodesInPath iip,\n       BlockManager bm, FSDirectory fsd) throws IOException {\n \n     final INode inode \u003d FSDirectory.resolveLastINode(iip);\n     final int snapshotId \u003d iip.getLatestSnapshotId();\n     final List\u003cINode\u003e candidateNodes \u003d new ArrayList\u003c\u003e();\n \n     // TODO: think about optimization here, label the dir instead\n     // of the sub-files of the dir.\n-    if (inode.isFile()) {\n+    if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() !\u003d 0) {\n       candidateNodes.add(inode);\n     } else if (inode.isDirectory()) {\n       for (INode node : inode.asDirectory().getChildrenList(snapshotId)) {\n-        if (node.isFile()) {\n+        if (node.isFile() \u0026\u0026 node.asFile().numBlocks() !\u003d 0) {\n           candidateNodes.add(node);\n         }\n       }\n     }\n \n+    if (candidateNodes.isEmpty()) {\n+      return null;\n+    }\n     // If node has satisfy xattr, then stop adding it\n     // to satisfy movement queue.\n     if (inodeHasSatisfyXAttr(candidateNodes)) {\n       throw new IOException(\n           \"Cannot request to call satisfy storage policy on path \"\n               + iip.getPath()\n               + \", as this file/dir was already called for satisfying \"\n               + \"storage policy.\");\n     }\n \n     final List\u003cXAttr\u003e xattrs \u003d Lists.newArrayListWithCapacity(1);\n     final XAttr satisfyXAttr \u003d XAttrHelper\n         .buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n     xattrs.add(satisfyXAttr);\n \n     for (INode node : candidateNodes) {\n       bm.satisfyStoragePolicy(node.getId());\n       List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(node);\n       List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(fsd, existingXAttrs,\n           xattrs, EnumSet.of(XAttrSetFlag.CREATE));\n       XAttrStorage.updateINodeXAttrs(node, newXAttrs, snapshotId);\n     }\n     return satisfyXAttr;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static XAttr unprotectedSatisfyStoragePolicy(INodesInPath iip,\n      BlockManager bm, FSDirectory fsd) throws IOException {\n\n    final INode inode \u003d FSDirectory.resolveLastINode(iip);\n    final int snapshotId \u003d iip.getLatestSnapshotId();\n    final List\u003cINode\u003e candidateNodes \u003d new ArrayList\u003c\u003e();\n\n    // TODO: think about optimization here, label the dir instead\n    // of the sub-files of the dir.\n    if (inode.isFile() \u0026\u0026 inode.asFile().numBlocks() !\u003d 0) {\n      candidateNodes.add(inode);\n    } else if (inode.isDirectory()) {\n      for (INode node : inode.asDirectory().getChildrenList(snapshotId)) {\n        if (node.isFile() \u0026\u0026 node.asFile().numBlocks() !\u003d 0) {\n          candidateNodes.add(node);\n        }\n      }\n    }\n\n    if (candidateNodes.isEmpty()) {\n      return null;\n    }\n    // If node has satisfy xattr, then stop adding it\n    // to satisfy movement queue.\n    if (inodeHasSatisfyXAttr(candidateNodes)) {\n      throw new IOException(\n          \"Cannot request to call satisfy storage policy on path \"\n              + iip.getPath()\n              + \", as this file/dir was already called for satisfying \"\n              + \"storage policy.\");\n    }\n\n    final List\u003cXAttr\u003e xattrs \u003d Lists.newArrayListWithCapacity(1);\n    final XAttr satisfyXAttr \u003d XAttrHelper\n        .buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n    xattrs.add(satisfyXAttr);\n\n    for (INode node : candidateNodes) {\n      bm.satisfyStoragePolicy(node.getId());\n      List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(node);\n      List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(fsd, existingXAttrs,\n          xattrs, EnumSet.of(XAttrSetFlag.CREATE));\n      XAttrStorage.updateINodeXAttrs(node, newXAttrs, snapshotId);\n    }\n    return satisfyXAttr;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
      "extendedDetails": {}
    },
    "5ce332dc9a072f8850ab71ba16898faf8e866c06": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-11695: [SPS]: Namenode failed to start while loading SPS xAttrs from the edits log. Contributed by Surendra Singh Lilhore.\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "5ce332dc9a072f8850ab71ba16898faf8e866c06",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:05 AM",
      "commitNameOld": "6fe6c549e8226b4893f502186f52452dcd9408a2",
      "commitAuthorOld": "Rakesh Radhakrishnan",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,43 @@\n   static XAttr unprotectedSatisfyStoragePolicy(INodesInPath iip,\n       BlockManager bm, FSDirectory fsd) throws IOException {\n \n     final INode inode \u003d FSDirectory.resolveLastINode(iip);\n     final int snapshotId \u003d iip.getLatestSnapshotId();\n     final List\u003cINode\u003e candidateNodes \u003d new ArrayList\u003c\u003e();\n \n     // TODO: think about optimization here, label the dir instead\n     // of the sub-files of the dir.\n     if (inode.isFile()) {\n       candidateNodes.add(inode);\n     } else if (inode.isDirectory()) {\n       for (INode node : inode.asDirectory().getChildrenList(snapshotId)) {\n         if (node.isFile()) {\n           candidateNodes.add(node);\n         }\n       }\n     }\n \n     // If node has satisfy xattr, then stop adding it\n     // to satisfy movement queue.\n     if (inodeHasSatisfyXAttr(candidateNodes)) {\n       throw new IOException(\n           \"Cannot request to call satisfy storage policy on path \"\n-          + iip.getPath()\n-          + \", as this file/dir was already called for satisfying \"\n-          + \"storage policy.\");\n+              + iip.getPath()\n+              + \", as this file/dir was already called for satisfying \"\n+              + \"storage policy.\");\n     }\n \n     final List\u003cXAttr\u003e xattrs \u003d Lists.newArrayListWithCapacity(1);\n-    final XAttr satisfyXAttr \u003d\n-        XAttrHelper.buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n+    final XAttr satisfyXAttr \u003d XAttrHelper\n+        .buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n     xattrs.add(satisfyXAttr);\n \n     for (INode node : candidateNodes) {\n       bm.satisfyStoragePolicy(node.getId());\n       List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(node);\n-      List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(\n-          fsd, existingXAttrs, xattrs, EnumSet.of(XAttrSetFlag.CREATE));\n+      List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(fsd, existingXAttrs,\n+          xattrs, EnumSet.of(XAttrSetFlag.CREATE));\n       XAttrStorage.updateINodeXAttrs(node, newXAttrs, snapshotId);\n     }\n     return satisfyXAttr;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static XAttr unprotectedSatisfyStoragePolicy(INodesInPath iip,\n      BlockManager bm, FSDirectory fsd) throws IOException {\n\n    final INode inode \u003d FSDirectory.resolveLastINode(iip);\n    final int snapshotId \u003d iip.getLatestSnapshotId();\n    final List\u003cINode\u003e candidateNodes \u003d new ArrayList\u003c\u003e();\n\n    // TODO: think about optimization here, label the dir instead\n    // of the sub-files of the dir.\n    if (inode.isFile()) {\n      candidateNodes.add(inode);\n    } else if (inode.isDirectory()) {\n      for (INode node : inode.asDirectory().getChildrenList(snapshotId)) {\n        if (node.isFile()) {\n          candidateNodes.add(node);\n        }\n      }\n    }\n\n    // If node has satisfy xattr, then stop adding it\n    // to satisfy movement queue.\n    if (inodeHasSatisfyXAttr(candidateNodes)) {\n      throw new IOException(\n          \"Cannot request to call satisfy storage policy on path \"\n              + iip.getPath()\n              + \", as this file/dir was already called for satisfying \"\n              + \"storage policy.\");\n    }\n\n    final List\u003cXAttr\u003e xattrs \u003d Lists.newArrayListWithCapacity(1);\n    final XAttr satisfyXAttr \u003d XAttrHelper\n        .buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n    xattrs.add(satisfyXAttr);\n\n    for (INode node : candidateNodes) {\n      bm.satisfyStoragePolicy(node.getId());\n      List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(node);\n      List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(fsd, existingXAttrs,\n          xattrs, EnumSet.of(XAttrSetFlag.CREATE));\n      XAttrStorage.updateINodeXAttrs(node, newXAttrs, snapshotId);\n    }\n    return satisfyXAttr;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirAttrOp.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSatisfyStoragePolicyOp.java",
        "oldMethodName": "unprotectedSatisfyStoragePolicy",
        "newMethodName": "unprotectedSatisfyStoragePolicy"
      }
    },
    "6215e35bb633706753a464ad3e8633366e6a10b2": {
      "type": "Ymultichange(Yparameterchange,Yreturntypechange,Ybodychange)",
      "commitMessage": "HDFS-11150: [SPS]: Provide persistence when satisfying storage policy. Contributed by Yuanbo Liu\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "6215e35bb633706753a464ad3e8633366e6a10b2",
      "commitAuthor": "Uma Maheswara Rao G",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-11150: [SPS]: Provide persistence when satisfying storage policy. Contributed by Yuanbo Liu\n",
          "commitDate": "12/08/18 3:05 AM",
          "commitName": "6215e35bb633706753a464ad3e8633366e6a10b2",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "5179d99b7e1faeac1ce041967480115913d9f795",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,43 @@\n-  static void unprotectedSatisfyStoragePolicy(BlockManager bm,\n-      INodesInPath iip) throws IOException {\n+  static XAttr unprotectedSatisfyStoragePolicy(INodesInPath iip,\n+      BlockManager bm, FSDirectory fsd) throws IOException {\n \n-    // check whether file exists.\n-    INode inode \u003d iip.getLastINode();\n-    if (inode \u003d\u003d null) {\n-      throw new FileNotFoundException(\"File/Directory does not exist: \"\n-          + iip.getPath());\n-    }\n+    final INode inode \u003d FSDirectory.resolveLastINode(iip);\n+    final int snapshotId \u003d iip.getLatestSnapshotId();\n+    final List\u003cINode\u003e candidateNodes \u003d new ArrayList\u003c\u003e();\n \n-    // TODO: need to check whether inode\u0027s storage policy\n-    // has been satisfied or inode exists in the satisfier\n-    // list before calling satisfyStoragePolicy in BlockManager.\n-    if (inode.isDirectory()) {\n-      final int snapshotId \u003d iip.getLatestSnapshotId();\n+    // TODO: think about optimization here, label the dir instead\n+    // of the sub-files of the dir.\n+    if (inode.isFile()) {\n+      candidateNodes.add(inode);\n+    } else if (inode.isDirectory()) {\n       for (INode node : inode.asDirectory().getChildrenList(snapshotId)) {\n         if (node.isFile()) {\n-          bm.satisfyStoragePolicy(node.getId());\n-\n+          candidateNodes.add(node);\n         }\n       }\n-    } else if (inode.isFile()) {\n-      bm.satisfyStoragePolicy(inode.getId());\n-    } else {\n-      throw new FileNotFoundException(\"File/Directory does not exist: \"\n-          + iip.getPath());\n     }\n+\n+    // If node has satisfy xattr, then stop adding it\n+    // to satisfy movement queue.\n+    if (inodeHasSatisfyXAttr(candidateNodes)) {\n+      throw new IOException(\n+          \"Cannot request to call satisfy storage policy on path \"\n+          + iip.getPath()\n+          + \", as this file/dir was already called for satisfying \"\n+          + \"storage policy.\");\n+    }\n+\n+    final List\u003cXAttr\u003e xattrs \u003d Lists.newArrayListWithCapacity(1);\n+    final XAttr satisfyXAttr \u003d\n+        XAttrHelper.buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n+    xattrs.add(satisfyXAttr);\n+\n+    for (INode node : candidateNodes) {\n+      bm.satisfyStoragePolicy(node.getId());\n+      List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(node);\n+      List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(\n+          fsd, existingXAttrs, xattrs, EnumSet.of(XAttrSetFlag.CREATE));\n+      XAttrStorage.updateINodeXAttrs(node, newXAttrs, snapshotId);\n+    }\n+    return satisfyXAttr;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static XAttr unprotectedSatisfyStoragePolicy(INodesInPath iip,\n      BlockManager bm, FSDirectory fsd) throws IOException {\n\n    final INode inode \u003d FSDirectory.resolveLastINode(iip);\n    final int snapshotId \u003d iip.getLatestSnapshotId();\n    final List\u003cINode\u003e candidateNodes \u003d new ArrayList\u003c\u003e();\n\n    // TODO: think about optimization here, label the dir instead\n    // of the sub-files of the dir.\n    if (inode.isFile()) {\n      candidateNodes.add(inode);\n    } else if (inode.isDirectory()) {\n      for (INode node : inode.asDirectory().getChildrenList(snapshotId)) {\n        if (node.isFile()) {\n          candidateNodes.add(node);\n        }\n      }\n    }\n\n    // If node has satisfy xattr, then stop adding it\n    // to satisfy movement queue.\n    if (inodeHasSatisfyXAttr(candidateNodes)) {\n      throw new IOException(\n          \"Cannot request to call satisfy storage policy on path \"\n          + iip.getPath()\n          + \", as this file/dir was already called for satisfying \"\n          + \"storage policy.\");\n    }\n\n    final List\u003cXAttr\u003e xattrs \u003d Lists.newArrayListWithCapacity(1);\n    final XAttr satisfyXAttr \u003d\n        XAttrHelper.buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n    xattrs.add(satisfyXAttr);\n\n    for (INode node : candidateNodes) {\n      bm.satisfyStoragePolicy(node.getId());\n      List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(node);\n      List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(\n          fsd, existingXAttrs, xattrs, EnumSet.of(XAttrSetFlag.CREATE));\n      XAttrStorage.updateINodeXAttrs(node, newXAttrs, snapshotId);\n    }\n    return satisfyXAttr;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirAttrOp.java",
          "extendedDetails": {
            "oldValue": "[bm-BlockManager, iip-INodesInPath]",
            "newValue": "[iip-INodesInPath, bm-BlockManager, fsd-FSDirectory]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-11150: [SPS]: Provide persistence when satisfying storage policy. Contributed by Yuanbo Liu\n",
          "commitDate": "12/08/18 3:05 AM",
          "commitName": "6215e35bb633706753a464ad3e8633366e6a10b2",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "5179d99b7e1faeac1ce041967480115913d9f795",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,43 @@\n-  static void unprotectedSatisfyStoragePolicy(BlockManager bm,\n-      INodesInPath iip) throws IOException {\n+  static XAttr unprotectedSatisfyStoragePolicy(INodesInPath iip,\n+      BlockManager bm, FSDirectory fsd) throws IOException {\n \n-    // check whether file exists.\n-    INode inode \u003d iip.getLastINode();\n-    if (inode \u003d\u003d null) {\n-      throw new FileNotFoundException(\"File/Directory does not exist: \"\n-          + iip.getPath());\n-    }\n+    final INode inode \u003d FSDirectory.resolveLastINode(iip);\n+    final int snapshotId \u003d iip.getLatestSnapshotId();\n+    final List\u003cINode\u003e candidateNodes \u003d new ArrayList\u003c\u003e();\n \n-    // TODO: need to check whether inode\u0027s storage policy\n-    // has been satisfied or inode exists in the satisfier\n-    // list before calling satisfyStoragePolicy in BlockManager.\n-    if (inode.isDirectory()) {\n-      final int snapshotId \u003d iip.getLatestSnapshotId();\n+    // TODO: think about optimization here, label the dir instead\n+    // of the sub-files of the dir.\n+    if (inode.isFile()) {\n+      candidateNodes.add(inode);\n+    } else if (inode.isDirectory()) {\n       for (INode node : inode.asDirectory().getChildrenList(snapshotId)) {\n         if (node.isFile()) {\n-          bm.satisfyStoragePolicy(node.getId());\n-\n+          candidateNodes.add(node);\n         }\n       }\n-    } else if (inode.isFile()) {\n-      bm.satisfyStoragePolicy(inode.getId());\n-    } else {\n-      throw new FileNotFoundException(\"File/Directory does not exist: \"\n-          + iip.getPath());\n     }\n+\n+    // If node has satisfy xattr, then stop adding it\n+    // to satisfy movement queue.\n+    if (inodeHasSatisfyXAttr(candidateNodes)) {\n+      throw new IOException(\n+          \"Cannot request to call satisfy storage policy on path \"\n+          + iip.getPath()\n+          + \", as this file/dir was already called for satisfying \"\n+          + \"storage policy.\");\n+    }\n+\n+    final List\u003cXAttr\u003e xattrs \u003d Lists.newArrayListWithCapacity(1);\n+    final XAttr satisfyXAttr \u003d\n+        XAttrHelper.buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n+    xattrs.add(satisfyXAttr);\n+\n+    for (INode node : candidateNodes) {\n+      bm.satisfyStoragePolicy(node.getId());\n+      List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(node);\n+      List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(\n+          fsd, existingXAttrs, xattrs, EnumSet.of(XAttrSetFlag.CREATE));\n+      XAttrStorage.updateINodeXAttrs(node, newXAttrs, snapshotId);\n+    }\n+    return satisfyXAttr;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static XAttr unprotectedSatisfyStoragePolicy(INodesInPath iip,\n      BlockManager bm, FSDirectory fsd) throws IOException {\n\n    final INode inode \u003d FSDirectory.resolveLastINode(iip);\n    final int snapshotId \u003d iip.getLatestSnapshotId();\n    final List\u003cINode\u003e candidateNodes \u003d new ArrayList\u003c\u003e();\n\n    // TODO: think about optimization here, label the dir instead\n    // of the sub-files of the dir.\n    if (inode.isFile()) {\n      candidateNodes.add(inode);\n    } else if (inode.isDirectory()) {\n      for (INode node : inode.asDirectory().getChildrenList(snapshotId)) {\n        if (node.isFile()) {\n          candidateNodes.add(node);\n        }\n      }\n    }\n\n    // If node has satisfy xattr, then stop adding it\n    // to satisfy movement queue.\n    if (inodeHasSatisfyXAttr(candidateNodes)) {\n      throw new IOException(\n          \"Cannot request to call satisfy storage policy on path \"\n          + iip.getPath()\n          + \", as this file/dir was already called for satisfying \"\n          + \"storage policy.\");\n    }\n\n    final List\u003cXAttr\u003e xattrs \u003d Lists.newArrayListWithCapacity(1);\n    final XAttr satisfyXAttr \u003d\n        XAttrHelper.buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n    xattrs.add(satisfyXAttr);\n\n    for (INode node : candidateNodes) {\n      bm.satisfyStoragePolicy(node.getId());\n      List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(node);\n      List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(\n          fsd, existingXAttrs, xattrs, EnumSet.of(XAttrSetFlag.CREATE));\n      XAttrStorage.updateINodeXAttrs(node, newXAttrs, snapshotId);\n    }\n    return satisfyXAttr;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirAttrOp.java",
          "extendedDetails": {
            "oldValue": "void",
            "newValue": "XAttr"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-11150: [SPS]: Provide persistence when satisfying storage policy. Contributed by Yuanbo Liu\n",
          "commitDate": "12/08/18 3:05 AM",
          "commitName": "6215e35bb633706753a464ad3e8633366e6a10b2",
          "commitAuthor": "Uma Maheswara Rao G",
          "commitDateOld": "12/08/18 3:05 AM",
          "commitNameOld": "5179d99b7e1faeac1ce041967480115913d9f795",
          "commitAuthorOld": "Rakesh Radhakrishnan",
          "daysBetweenCommits": 0.0,
          "commitsBetweenForRepo": 6,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,43 @@\n-  static void unprotectedSatisfyStoragePolicy(BlockManager bm,\n-      INodesInPath iip) throws IOException {\n+  static XAttr unprotectedSatisfyStoragePolicy(INodesInPath iip,\n+      BlockManager bm, FSDirectory fsd) throws IOException {\n \n-    // check whether file exists.\n-    INode inode \u003d iip.getLastINode();\n-    if (inode \u003d\u003d null) {\n-      throw new FileNotFoundException(\"File/Directory does not exist: \"\n-          + iip.getPath());\n-    }\n+    final INode inode \u003d FSDirectory.resolveLastINode(iip);\n+    final int snapshotId \u003d iip.getLatestSnapshotId();\n+    final List\u003cINode\u003e candidateNodes \u003d new ArrayList\u003c\u003e();\n \n-    // TODO: need to check whether inode\u0027s storage policy\n-    // has been satisfied or inode exists in the satisfier\n-    // list before calling satisfyStoragePolicy in BlockManager.\n-    if (inode.isDirectory()) {\n-      final int snapshotId \u003d iip.getLatestSnapshotId();\n+    // TODO: think about optimization here, label the dir instead\n+    // of the sub-files of the dir.\n+    if (inode.isFile()) {\n+      candidateNodes.add(inode);\n+    } else if (inode.isDirectory()) {\n       for (INode node : inode.asDirectory().getChildrenList(snapshotId)) {\n         if (node.isFile()) {\n-          bm.satisfyStoragePolicy(node.getId());\n-\n+          candidateNodes.add(node);\n         }\n       }\n-    } else if (inode.isFile()) {\n-      bm.satisfyStoragePolicy(inode.getId());\n-    } else {\n-      throw new FileNotFoundException(\"File/Directory does not exist: \"\n-          + iip.getPath());\n     }\n+\n+    // If node has satisfy xattr, then stop adding it\n+    // to satisfy movement queue.\n+    if (inodeHasSatisfyXAttr(candidateNodes)) {\n+      throw new IOException(\n+          \"Cannot request to call satisfy storage policy on path \"\n+          + iip.getPath()\n+          + \", as this file/dir was already called for satisfying \"\n+          + \"storage policy.\");\n+    }\n+\n+    final List\u003cXAttr\u003e xattrs \u003d Lists.newArrayListWithCapacity(1);\n+    final XAttr satisfyXAttr \u003d\n+        XAttrHelper.buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n+    xattrs.add(satisfyXAttr);\n+\n+    for (INode node : candidateNodes) {\n+      bm.satisfyStoragePolicy(node.getId());\n+      List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(node);\n+      List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(\n+          fsd, existingXAttrs, xattrs, EnumSet.of(XAttrSetFlag.CREATE));\n+      XAttrStorage.updateINodeXAttrs(node, newXAttrs, snapshotId);\n+    }\n+    return satisfyXAttr;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static XAttr unprotectedSatisfyStoragePolicy(INodesInPath iip,\n      BlockManager bm, FSDirectory fsd) throws IOException {\n\n    final INode inode \u003d FSDirectory.resolveLastINode(iip);\n    final int snapshotId \u003d iip.getLatestSnapshotId();\n    final List\u003cINode\u003e candidateNodes \u003d new ArrayList\u003c\u003e();\n\n    // TODO: think about optimization here, label the dir instead\n    // of the sub-files of the dir.\n    if (inode.isFile()) {\n      candidateNodes.add(inode);\n    } else if (inode.isDirectory()) {\n      for (INode node : inode.asDirectory().getChildrenList(snapshotId)) {\n        if (node.isFile()) {\n          candidateNodes.add(node);\n        }\n      }\n    }\n\n    // If node has satisfy xattr, then stop adding it\n    // to satisfy movement queue.\n    if (inodeHasSatisfyXAttr(candidateNodes)) {\n      throw new IOException(\n          \"Cannot request to call satisfy storage policy on path \"\n          + iip.getPath()\n          + \", as this file/dir was already called for satisfying \"\n          + \"storage policy.\");\n    }\n\n    final List\u003cXAttr\u003e xattrs \u003d Lists.newArrayListWithCapacity(1);\n    final XAttr satisfyXAttr \u003d\n        XAttrHelper.buildXAttr(XATTR_SATISFY_STORAGE_POLICY);\n    xattrs.add(satisfyXAttr);\n\n    for (INode node : candidateNodes) {\n      bm.satisfyStoragePolicy(node.getId());\n      List\u003cXAttr\u003e existingXAttrs \u003d XAttrStorage.readINodeXAttrs(node);\n      List\u003cXAttr\u003e newXAttrs \u003d FSDirXAttrOp.setINodeXAttrs(\n          fsd, existingXAttrs, xattrs, EnumSet.of(XAttrSetFlag.CREATE));\n      XAttrStorage.updateINodeXAttrs(node, newXAttrs, snapshotId);\n    }\n    return satisfyXAttr;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirAttrOp.java",
          "extendedDetails": {}
        }
      ]
    },
    "b67ae6d9d741e79ccf2bd6f08a37fce070e6ad77": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-10802. [SPS]: Add satisfyStoragePolicy API in HdfsAdmin. Contributed by Yuanbo Liu\n",
      "commitDate": "12/08/18 3:05 AM",
      "commitName": "b67ae6d9d741e79ccf2bd6f08a37fce070e6ad77",
      "commitAuthor": "Rakesh Radhakrishnan",
      "diff": "@@ -0,0 +1,28 @@\n+  static void unprotectedSatisfyStoragePolicy(BlockManager bm,\n+      INodesInPath iip) throws IOException {\n+\n+    // check whether file exists.\n+    INode inode \u003d iip.getLastINode();\n+    if (inode \u003d\u003d null) {\n+      throw new FileNotFoundException(\"File/Directory does not exist: \"\n+          + iip.getPath());\n+    }\n+\n+    // TODO: need to check whether inode\u0027s storage policy\n+    // has been satisfied or inode exists in the satisfier\n+    // list before calling satisfyStoragePolicy in BlockManager.\n+    if (inode.isDirectory()) {\n+      final int snapshotId \u003d iip.getLatestSnapshotId();\n+      for (INode node : inode.asDirectory().getChildrenList(snapshotId)) {\n+        if (node.isFile()) {\n+          bm.satisfyStoragePolicy(node.getId());\n+\n+        }\n+      }\n+    } else if (inode.isFile()) {\n+      bm.satisfyStoragePolicy(inode.getId());\n+    } else {\n+      throw new FileNotFoundException(\"File/Directory does not exist: \"\n+          + iip.getPath());\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static void unprotectedSatisfyStoragePolicy(BlockManager bm,\n      INodesInPath iip) throws IOException {\n\n    // check whether file exists.\n    INode inode \u003d iip.getLastINode();\n    if (inode \u003d\u003d null) {\n      throw new FileNotFoundException(\"File/Directory does not exist: \"\n          + iip.getPath());\n    }\n\n    // TODO: need to check whether inode\u0027s storage policy\n    // has been satisfied or inode exists in the satisfier\n    // list before calling satisfyStoragePolicy in BlockManager.\n    if (inode.isDirectory()) {\n      final int snapshotId \u003d iip.getLatestSnapshotId();\n      for (INode node : inode.asDirectory().getChildrenList(snapshotId)) {\n        if (node.isFile()) {\n          bm.satisfyStoragePolicy(node.getId());\n\n        }\n      }\n    } else if (inode.isFile()) {\n      bm.satisfyStoragePolicy(inode.getId());\n    } else {\n      throw new FileNotFoundException(\"File/Directory does not exist: \"\n          + iip.getPath());\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirAttrOp.java"
    }
  }
}