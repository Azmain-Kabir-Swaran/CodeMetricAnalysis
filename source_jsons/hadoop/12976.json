{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "DatanodeDescriptor.java",
  "functionName": "clearBlockQueues",
  "functionId": "clearBlockQueues",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
  "functionStartLine": 353,
  "functionEndLine": 365,
  "numCommitsSeen": 118,
  "timeTaken": 4272,
  "changeHistory": [
    "39ed3a66dbb01383ed16b141183fc48bfd2e613d",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
    "be7a0add8b6561d3c566237cc0370b06e7f32bb4",
    "57a84c0d149b693c913416975cafe6de4e23c321",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
    "40eb94ade3161d93e7a762a839004748f6d0ae89",
    "31c91706f7d17da006ef2d6c541f8dd092fae077"
  ],
  "changeHistoryShort": {
    "39ed3a66dbb01383ed16b141183fc48bfd2e613d": "Ybodychange",
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": "Ybodychange",
    "be7a0add8b6561d3c566237cc0370b06e7f32bb4": "Ybodychange",
    "57a84c0d149b693c913416975cafe6de4e23c321": "Ybodychange",
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": "Ybodychange",
    "40eb94ade3161d93e7a762a839004748f6d0ae89": "Ybodychange",
    "31c91706f7d17da006ef2d6c541f8dd092fae077": "Yintroduced"
  },
  "changeHistoryDetails": {
    "39ed3a66dbb01383ed16b141183fc48bfd2e613d": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13076: [SPS]: Cleanup work for HDFS-10285 merge. Contributed by Rakesh R.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "39ed3a66dbb01383ed16b141183fc48bfd2e613d",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 7,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,13 @@\n   public void clearBlockQueues() {\n     synchronized (invalidateBlocks) {\n       this.invalidateBlocks.clear();\n     }\n     this.recoverBlocks.clear();\n     this.replicateBlocks.clear();\n     this.erasurecodeBlocks.clear();\n     // pendingCached, cached, and pendingUncached are protected by the\n     // FSN lock.\n     this.pendingCached.clear();\n     this.cached.clear();\n     this.pendingUncached.clear();\n-    this.storageMovementBlocks.clear();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void clearBlockQueues() {\n    synchronized (invalidateBlocks) {\n      this.invalidateBlocks.clear();\n    }\n    this.recoverBlocks.clear();\n    this.replicateBlocks.clear();\n    this.erasurecodeBlocks.clear();\n    // pendingCached, cached, and pendingUncached are protected by the\n    // FSN lock.\n    this.pendingCached.clear();\n    this.cached.clear();\n    this.pendingUncached.clear();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13097: [SPS]: Fix the branch review comments(Part1). Contributed by Surendra Singh.\n",
      "commitDate": "12/08/18 3:06 AM",
      "commitName": "4402f3f8557527d5c6cdad6f5bdcbd707b8cbf52",
      "commitAuthor": "Uma Maheswara Rao G",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "05d4daf6ba3e5bd40f46e8003ee12fc7c613453d",
      "commitAuthorOld": "Surendra Singh Lilhore",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,14 @@\n   public void clearBlockQueues() {\n     synchronized (invalidateBlocks) {\n       this.invalidateBlocks.clear();\n     }\n     this.recoverBlocks.clear();\n     this.replicateBlocks.clear();\n     this.erasurecodeBlocks.clear();\n     // pendingCached, cached, and pendingUncached are protected by the\n     // FSN lock.\n     this.pendingCached.clear();\n     this.cached.clear();\n     this.pendingUncached.clear();\n+    this.storageMovementBlocks.clear();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void clearBlockQueues() {\n    synchronized (invalidateBlocks) {\n      this.invalidateBlocks.clear();\n    }\n    this.recoverBlocks.clear();\n    this.replicateBlocks.clear();\n    this.erasurecodeBlocks.clear();\n    // pendingCached, cached, and pendingUncached are protected by the\n    // FSN lock.\n    this.pendingCached.clear();\n    this.cached.clear();\n    this.pendingUncached.clear();\n    this.storageMovementBlocks.clear();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "be7a0add8b6561d3c566237cc0370b06e7f32bb4": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9223. Code cleanup for DatanodeDescriptor and HeartbeatManager. Contributed by Jing Zhao.\n",
      "commitDate": "14/10/15 4:17 PM",
      "commitName": "be7a0add8b6561d3c566237cc0370b06e7f32bb4",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "08/10/15 2:11 PM",
      "commitNameOld": "118a35bc2eabe3918b4797a1b626e9a39d77754b",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 6.09,
      "commitsBetweenForRepo": 56,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,13 +1,13 @@\n   public void clearBlockQueues() {\n     synchronized (invalidateBlocks) {\n       this.invalidateBlocks.clear();\n-      this.recoverBlocks.clear();\n-      this.replicateBlocks.clear();\n-      this.erasurecodeBlocks.clear();\n     }\n+    this.recoverBlocks.clear();\n+    this.replicateBlocks.clear();\n+    this.erasurecodeBlocks.clear();\n     // pendingCached, cached, and pendingUncached are protected by the\n     // FSN lock.\n     this.pendingCached.clear();\n     this.cached.clear();\n     this.pendingUncached.clear();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void clearBlockQueues() {\n    synchronized (invalidateBlocks) {\n      this.invalidateBlocks.clear();\n    }\n    this.recoverBlocks.clear();\n    this.replicateBlocks.clear();\n    this.erasurecodeBlocks.clear();\n    // pendingCached, cached, and pendingUncached are protected by the\n    // FSN lock.\n    this.pendingCached.clear();\n    this.cached.clear();\n    this.pendingUncached.clear();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "57a84c0d149b693c913416975cafe6de4e23c321": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7369. Erasure coding: distribute recovery work for striped blocks to DataNode. Contributed by Zhe Zhang.\n",
      "commitDate": "26/05/15 11:43 AM",
      "commitName": "57a84c0d149b693c913416975cafe6de4e23c321",
      "commitAuthor": "Zhe Zhang",
      "commitDateOld": "26/05/15 11:32 AM",
      "commitNameOld": "f05c21285ef23b6a973d69f045b1cb46c5abc039",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,13 @@\n   public void clearBlockQueues() {\n     synchronized (invalidateBlocks) {\n       this.invalidateBlocks.clear();\n       this.recoverBlocks.clear();\n       this.replicateBlocks.clear();\n+      this.erasurecodeBlocks.clear();\n     }\n     // pendingCached, cached, and pendingUncached are protected by the\n     // FSN lock.\n     this.pendingCached.clear();\n     this.cached.clear();\n     this.pendingUncached.clear();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void clearBlockQueues() {\n    synchronized (invalidateBlocks) {\n      this.invalidateBlocks.clear();\n      this.recoverBlocks.clear();\n      this.replicateBlocks.clear();\n      this.erasurecodeBlocks.clear();\n    }\n    // pendingCached, cached, and pendingUncached are protected by the\n    // FSN lock.\n    this.pendingCached.clear();\n    this.cached.clear();\n    this.pendingUncached.clear();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5096. Automatically cache new data added to a cached path (contributed by Colin Patrick McCabe)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1532924 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "16/10/13 3:15 PM",
      "commitName": "3cc7a38a53c8ae27ef6b2397cddc5d14a378203a",
      "commitAuthor": "Colin McCabe",
      "commitDateOld": "13/09/13 4:27 PM",
      "commitNameOld": "40eb94ade3161d93e7a762a839004748f6d0ae89",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 32.95,
      "commitsBetweenForRepo": 23,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,11 +1,12 @@\n   public void clearBlockQueues() {\n     synchronized (invalidateBlocks) {\n       this.invalidateBlocks.clear();\n       this.recoverBlocks.clear();\n       this.replicateBlocks.clear();\n     }\n-    synchronized(blocksToUncache) {\n-      this.blocksToUncache.clear();\n-      this.cacheBlocks.clear();\n-    }\n+    // pendingCached, cached, and pendingUncached are protected by the\n+    // FSN lock.\n+    this.pendingCached.clear();\n+    this.cached.clear();\n+    this.pendingUncached.clear();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void clearBlockQueues() {\n    synchronized (invalidateBlocks) {\n      this.invalidateBlocks.clear();\n      this.recoverBlocks.clear();\n      this.replicateBlocks.clear();\n    }\n    // pendingCached, cached, and pendingUncached are protected by the\n    // FSN lock.\n    this.pendingCached.clear();\n    this.cached.clear();\n    this.pendingUncached.clear();\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "40eb94ade3161d93e7a762a839004748f6d0ae89": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-5053. NameNode should invoke DataNode APIs to coordinate caching. (Andrew Wang)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-4949@1523145 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/09/13 4:27 PM",
      "commitName": "40eb94ade3161d93e7a762a839004748f6d0ae89",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "30/08/13 3:15 PM",
      "commitNameOld": "fc14a92c6b46cc435a8f33e6fa0512c70caa06e0",
      "commitAuthorOld": "Andrew Wang",
      "daysBetweenCommits": 14.05,
      "commitsBetweenForRepo": 10,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,7 +1,11 @@\n   public void clearBlockQueues() {\n     synchronized (invalidateBlocks) {\n       this.invalidateBlocks.clear();\n       this.recoverBlocks.clear();\n       this.replicateBlocks.clear();\n     }\n+    synchronized(blocksToUncache) {\n+      this.blocksToUncache.clear();\n+      this.cacheBlocks.clear();\n+    }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public void clearBlockQueues() {\n    synchronized (invalidateBlocks) {\n      this.invalidateBlocks.clear();\n      this.recoverBlocks.clear();\n      this.replicateBlocks.clear();\n    }\n    synchronized(blocksToUncache) {\n      this.blocksToUncache.clear();\n      this.cacheBlocks.clear();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java",
      "extendedDetails": {}
    },
    "31c91706f7d17da006ef2d6c541f8dd092fae077": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-1972. Fencing mechanism for block invalidations and replications. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1221608 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "20/12/11 8:32 PM",
      "commitName": "31c91706f7d17da006ef2d6c541f8dd092fae077",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,7 @@\n+  public void clearBlockQueues() {\n+    synchronized (invalidateBlocks) {\n+      this.invalidateBlocks.clear();\n+      this.recoverBlocks.clear();\n+      this.replicateBlocks.clear();\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void clearBlockQueues() {\n    synchronized (invalidateBlocks) {\n      this.invalidateBlocks.clear();\n      this.recoverBlocks.clear();\n      this.replicateBlocks.clear();\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.java"
    }
  }
}