{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "JobHistoryEventHandler.java",
  "functionName": "run",
  "functionId": "run",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
  "functionStartLine": 1549,
  "functionEndLine": 1559,
  "numCommitsSeen": 74,
  "timeTaken": 9842,
  "changeHistory": [
    "0928502029ef141759008997335ea2cd836a7154",
    "74697f231772a556884feaf1c986631d02a9ae4e",
    "e8645636ce1721aa6dc3674fbc553a7bb3522fbe",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "0928502029ef141759008997335ea2cd836a7154": "Ybodychange",
    "74697f231772a556884feaf1c986631d02a9ae4e": "Ybodychange",
    "e8645636ce1721aa6dc3674fbc553a7bb3522fbe": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": "Ymultichange(Ymovefromfile,Ybodychange)",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "0928502029ef141759008997335ea2cd836a7154": {
      "type": "Ybodychange",
      "commitMessage": "YARN-530. Defined Service model strictly, implemented AbstractService for robust subclassing and migrated yarn-common services. Contributed by Steve Loughran.\nYARN-117. Migrated rest of YARN to the new service model. Contributed by Steve Louhran.\nMAPREDUCE-5298. Moved MapReduce services to YARN-530 stricter lifecycle. Contributed by Steve Loughran.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1492718 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "13/06/13 8:54 AM",
      "commitName": "0928502029ef141759008997335ea2cd836a7154",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "03/06/13 9:05 PM",
      "commitNameOld": "a83fb61ac07c0468cbc7a38526e92683883dd932",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 9.49,
      "commitsBetweenForRepo": 61,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,10 +1,11 @@\n     public void run() {\n+      LOG.debug(\"In flush timer task\");\n       synchronized (lock) {\n         try {\n           if (!metaInfo.isTimerShutDown() \u0026\u0026 shouldRun)\n             metaInfo.flush();\n         } catch (IOException e) {\n           ioe \u003d e;\n         }\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      LOG.debug(\"In flush timer task\");\n      synchronized (lock) {\n        try {\n          if (!metaInfo.isTimerShutDown() \u0026\u0026 shouldRun)\n            metaInfo.flush();\n        } catch (IOException e) {\n          ioe \u003d e;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "74697f231772a556884feaf1c986631d02a9ae4e": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3512. Batching JobHistory flushing to DFS so that we don\u0027t flush for every event slowing down AM. Contributed by Siddarth Seth.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1230353 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "11/01/12 5:42 PM",
      "commitName": "74697f231772a556884feaf1c986631d02a9ae4e",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "09/01/12 1:04 PM",
      "commitNameOld": "e8645636ce1721aa6dc3674fbc553a7bb3522fbe",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 2.19,
      "commitsBetweenForRepo": 21,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,34 +1,10 @@\n-      public void run() {\n-        JobHistoryEvent event \u003d null;\n-        while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n-\n-          // Log the size of the history-event-queue every so often.\n-          if (eventCounter % 1000 \u003d\u003d 0) {\n-            eventCounter \u003d 0;\n-            LOG.info(\"Size of the JobHistory event queue is \"\n-                + eventQueue.size());\n-          } else {\n-            eventCounter++;\n-          }\n-\n-          try {\n-            event \u003d eventQueue.take();\n-          } catch (InterruptedException e) {\n-            LOG.info(\"EventQueue take interrupted. Returning\");\n-            return;\n-          }\n-          // If an event has been removed from the queue. Handle it.\n-          // The rest of the queue is handled via stop()\n-          // Clear the interrupt status if it\u0027s set before calling handleEvent\n-          // and set it if it was set before calling handleEvent. \n-          // Interrupts received from other threads during handleEvent cannot be\n-          // dealth with - Shell.runCommand() ignores them.\n-          synchronized (lock) {\n-            boolean isInterrupted \u003d Thread.interrupted();\n-            handleEvent(event);\n-            if (isInterrupted) {\n-              Thread.currentThread().interrupt();\n-            }\n-          }\n+    public void run() {\n+      synchronized (lock) {\n+        try {\n+          if (!metaInfo.isTimerShutDown() \u0026\u0026 shouldRun)\n+            metaInfo.flush();\n+        } catch (IOException e) {\n+          ioe \u003d e;\n         }\n-      }\n\\ No newline at end of file\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public void run() {\n      synchronized (lock) {\n        try {\n          if (!metaInfo.isTimerShutDown() \u0026\u0026 shouldRun)\n            metaInfo.flush();\n        } catch (IOException e) {\n          ioe \u003d e;\n        }\n      }\n    }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "e8645636ce1721aa6dc3674fbc553a7bb3522fbe": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-3511. Removed a multitude of cloned/duplicate counters in the AM thereby reducing the AM heap size and preventing full GCs. (vinodkv)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1229347 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/01/12 1:04 PM",
      "commitName": "e8645636ce1721aa6dc3674fbc553a7bb3522fbe",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "commitDateOld": "07/11/11 11:28 PM",
      "commitNameOld": "9fe9f42c8fad872f7aab5f9bbdac4a860edb0d43",
      "commitAuthorOld": "Vinod Kumar Vavilapalli",
      "daysBetweenCommits": 62.57,
      "commitsBetweenForRepo": 297,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,24 +1,34 @@\n       public void run() {\n         JobHistoryEvent event \u003d null;\n         while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n+\n+          // Log the size of the history-event-queue every so often.\n+          if (eventCounter % 1000 \u003d\u003d 0) {\n+            eventCounter \u003d 0;\n+            LOG.info(\"Size of the JobHistory event queue is \"\n+                + eventQueue.size());\n+          } else {\n+            eventCounter++;\n+          }\n+\n           try {\n             event \u003d eventQueue.take();\n           } catch (InterruptedException e) {\n             LOG.info(\"EventQueue take interrupted. Returning\");\n             return;\n           }\n           // If an event has been removed from the queue. Handle it.\n           // The rest of the queue is handled via stop()\n           // Clear the interrupt status if it\u0027s set before calling handleEvent\n           // and set it if it was set before calling handleEvent. \n           // Interrupts received from other threads during handleEvent cannot be\n           // dealth with - Shell.runCommand() ignores them.\n           synchronized (lock) {\n             boolean isInterrupted \u003d Thread.interrupted();\n             handleEvent(event);\n             if (isInterrupted) {\n               Thread.currentThread().interrupt();\n             }\n           }\n         }\n       }\n\\ No newline at end of file\n",
      "actualSource": "      public void run() {\n        JobHistoryEvent event \u003d null;\n        while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n\n          // Log the size of the history-event-queue every so often.\n          if (eventCounter % 1000 \u003d\u003d 0) {\n            eventCounter \u003d 0;\n            LOG.info(\"Size of the JobHistory event queue is \"\n                + eventQueue.size());\n          } else {\n            eventCounter++;\n          }\n\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.info(\"EventQueue take interrupted. Returning\");\n            return;\n          }\n          // If an event has been removed from the queue. Handle it.\n          // The rest of the queue is handled via stop()\n          // Clear the interrupt status if it\u0027s set before calling handleEvent\n          // and set it if it was set before calling handleEvent. \n          // Interrupts received from other threads during handleEvent cannot be\n          // dealth with - Shell.runCommand() ignores them.\n          synchronized (lock) {\n            boolean isInterrupted \u003d Thread.interrupted();\n            handleEvent(event);\n            if (isInterrupted) {\n              Thread.currentThread().interrupt();\n            }\n          }\n        }\n      }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "      public void run() {\n        JobHistoryEvent event \u003d null;\n        while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.info(\"EventQueue take interrupted. Returning\");\n            return;\n          }\n          // If an event has been removed from the queue. Handle it.\n          // The rest of the queue is handled via stop()\n          // Clear the interrupt status if it\u0027s set before calling handleEvent\n          // and set it if it was set before calling handleEvent. \n          // Interrupts received from other threads during handleEvent cannot be\n          // dealth with - Shell.runCommand() ignores them.\n          synchronized (lock) {\n            boolean isInterrupted \u003d Thread.interrupted();\n            handleEvent(event);\n            if (isInterrupted) {\n              Thread.currentThread().interrupt();\n            }\n          }\n        }\n      }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
      "extendedDetails": {
        "oldPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
        "newPath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java"
      }
    },
    "dbecbe5dfe50f834fc3b8401709079e9470cc517": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "18/08/11 4:07 AM",
      "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
      "commitAuthor": "Vinod Kumar Vavilapalli",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,24 @@\n-        public void run() {\n-          while (true) {\n-            try {\n-              TaskTrackerAction action \u003d tasksToCleanup.take();\n-              if (action instanceof KillJobAction) {\n-                purgeJob((KillJobAction) action);\n-              } else if (action instanceof KillTaskAction) {\n-                processKillTaskAction((KillTaskAction) action);\n-              } else {\n-                LOG.error(\"Non-delete action given to cleanup thread: \"\n-                          + action);\n-              }\n-            } catch (Throwable except) {\n-              LOG.warn(StringUtils.stringifyException(except));\n+      public void run() {\n+        JobHistoryEvent event \u003d null;\n+        while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n+          try {\n+            event \u003d eventQueue.take();\n+          } catch (InterruptedException e) {\n+            LOG.info(\"EventQueue take interrupted. Returning\");\n+            return;\n+          }\n+          // If an event has been removed from the queue. Handle it.\n+          // The rest of the queue is handled via stop()\n+          // Clear the interrupt status if it\u0027s set before calling handleEvent\n+          // and set it if it was set before calling handleEvent. \n+          // Interrupts received from other threads during handleEvent cannot be\n+          // dealth with - Shell.runCommand() ignores them.\n+          synchronized (lock) {\n+            boolean isInterrupted \u003d Thread.interrupted();\n+            handleEvent(event);\n+            if (isInterrupted) {\n+              Thread.currentThread().interrupt();\n             }\n           }\n-        }\n\\ No newline at end of file\n+        }\n+      }\n\\ No newline at end of file\n",
          "actualSource": "      public void run() {\n        JobHistoryEvent event \u003d null;\n        while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.info(\"EventQueue take interrupted. Returning\");\n            return;\n          }\n          // If an event has been removed from the queue. Handle it.\n          // The rest of the queue is handled via stop()\n          // Clear the interrupt status if it\u0027s set before calling handleEvent\n          // and set it if it was set before calling handleEvent. \n          // Interrupts received from other threads during handleEvent cannot be\n          // dealth with - Shell.runCommand() ignores them.\n          synchronized (lock) {\n            boolean isInterrupted \u003d Thread.interrupted();\n            handleEvent(event);\n            if (isInterrupted) {\n              Thread.currentThread().interrupt();\n            }\n          }\n        }\n      }",
          "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
          "extendedDetails": {
            "oldPath": "mapreduce/src/java/org/apache/hadoop/mapred/TaskTracker.java",
            "newPath": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
            "oldMethodName": "run",
            "newMethodName": "run"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "MAPREDUCE-279. MapReduce 2.0. Merging MR-279 branch into trunk. Contributed by Arun C Murthy, Christopher Douglas, Devaraj Das, Greg Roelofs, Jeffrey Naisbitt, Josh Wills, Jonathan Eagles, Krishna Ramachandran, Luke Lu, Mahadev Konar, Robert Evans, Sharad Agarwal, Siddharth Seth, Thomas Graves, and Vinod Kumar Vavilapalli.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159166 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "18/08/11 4:07 AM",
          "commitName": "dbecbe5dfe50f834fc3b8401709079e9470cc517",
          "commitAuthor": "Vinod Kumar Vavilapalli",
          "commitDateOld": "17/08/11 8:02 PM",
          "commitNameOld": "dd86860633d2ed64705b669a75bf318442ed6225",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.34,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,24 @@\n-        public void run() {\n-          while (true) {\n-            try {\n-              TaskTrackerAction action \u003d tasksToCleanup.take();\n-              if (action instanceof KillJobAction) {\n-                purgeJob((KillJobAction) action);\n-              } else if (action instanceof KillTaskAction) {\n-                processKillTaskAction((KillTaskAction) action);\n-              } else {\n-                LOG.error(\"Non-delete action given to cleanup thread: \"\n-                          + action);\n-              }\n-            } catch (Throwable except) {\n-              LOG.warn(StringUtils.stringifyException(except));\n+      public void run() {\n+        JobHistoryEvent event \u003d null;\n+        while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n+          try {\n+            event \u003d eventQueue.take();\n+          } catch (InterruptedException e) {\n+            LOG.info(\"EventQueue take interrupted. Returning\");\n+            return;\n+          }\n+          // If an event has been removed from the queue. Handle it.\n+          // The rest of the queue is handled via stop()\n+          // Clear the interrupt status if it\u0027s set before calling handleEvent\n+          // and set it if it was set before calling handleEvent. \n+          // Interrupts received from other threads during handleEvent cannot be\n+          // dealth with - Shell.runCommand() ignores them.\n+          synchronized (lock) {\n+            boolean isInterrupted \u003d Thread.interrupted();\n+            handleEvent(event);\n+            if (isInterrupted) {\n+              Thread.currentThread().interrupt();\n             }\n           }\n-        }\n\\ No newline at end of file\n+        }\n+      }\n\\ No newline at end of file\n",
          "actualSource": "      public void run() {\n        JobHistoryEvent event \u003d null;\n        while (!stopped \u0026\u0026 !Thread.currentThread().isInterrupted()) {\n          try {\n            event \u003d eventQueue.take();\n          } catch (InterruptedException e) {\n            LOG.info(\"EventQueue take interrupted. Returning\");\n            return;\n          }\n          // If an event has been removed from the queue. Handle it.\n          // The rest of the queue is handled via stop()\n          // Clear the interrupt status if it\u0027s set before calling handleEvent\n          // and set it if it was set before calling handleEvent. \n          // Interrupts received from other threads during handleEvent cannot be\n          // dealth with - Shell.runCommand() ignores them.\n          synchronized (lock) {\n            boolean isInterrupted \u003d Thread.interrupted();\n            handleEvent(event);\n            if (isInterrupted) {\n              Thread.currentThread().interrupt();\n            }\n          }\n        }\n      }",
          "path": "hadoop-mapreduce/hadoop-mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java",
          "extendedDetails": {}
        }
      ]
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,48 @@\n+  public void run() {\n+    try {\n+      startCleanupThreads();\n+      boolean denied \u003d false;\n+      while (running \u0026\u0026 !shuttingDown \u0026\u0026 !denied) {\n+        boolean staleState \u003d false;\n+        try {\n+          // This while-loop attempts reconnects if we get network errors\n+          while (running \u0026\u0026 !staleState \u0026\u0026 !shuttingDown \u0026\u0026 !denied) {\n+            try {\n+              State osState \u003d offerService();\n+              if (osState \u003d\u003d State.STALE) {\n+                staleState \u003d true;\n+              } else if (osState \u003d\u003d State.DENIED) {\n+                denied \u003d true;\n+              }\n+            } catch (Exception ex) {\n+              if (!shuttingDown) {\n+                LOG.info(\"Lost connection to JobTracker [\" +\n+                         jobTrackAddr + \"].  Retrying...\", ex);\n+                try {\n+                  Thread.sleep(5000);\n+                } catch (InterruptedException ie) {\n+                }\n+              }\n+            }\n+          }\n+        } finally {\n+          close();\n+        }\n+        if (shuttingDown) { return; }\n+        LOG.warn(\"Reinitializing local state\");\n+        initialize();\n+      }\n+      if (denied) {\n+        shutdown();\n+      }\n+    } catch (IOException iex) {\n+      LOG.error(\"Got fatal exception while reinitializing TaskTracker: \" +\n+                StringUtils.stringifyException(iex));\n+      return;\n+    }\n+    catch (InterruptedException i) {\n+      LOG.error(\"Got interrupted while reinitializing TaskTracker: \" + \n+          i.getMessage());\n+      return;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public void run() {\n    try {\n      startCleanupThreads();\n      boolean denied \u003d false;\n      while (running \u0026\u0026 !shuttingDown \u0026\u0026 !denied) {\n        boolean staleState \u003d false;\n        try {\n          // This while-loop attempts reconnects if we get network errors\n          while (running \u0026\u0026 !staleState \u0026\u0026 !shuttingDown \u0026\u0026 !denied) {\n            try {\n              State osState \u003d offerService();\n              if (osState \u003d\u003d State.STALE) {\n                staleState \u003d true;\n              } else if (osState \u003d\u003d State.DENIED) {\n                denied \u003d true;\n              }\n            } catch (Exception ex) {\n              if (!shuttingDown) {\n                LOG.info(\"Lost connection to JobTracker [\" +\n                         jobTrackAddr + \"].  Retrying...\", ex);\n                try {\n                  Thread.sleep(5000);\n                } catch (InterruptedException ie) {\n                }\n              }\n            }\n          }\n        } finally {\n          close();\n        }\n        if (shuttingDown) { return; }\n        LOG.warn(\"Reinitializing local state\");\n        initialize();\n      }\n      if (denied) {\n        shutdown();\n      }\n    } catch (IOException iex) {\n      LOG.error(\"Got fatal exception while reinitializing TaskTracker: \" +\n                StringUtils.stringifyException(iex));\n      return;\n    }\n    catch (InterruptedException i) {\n      LOG.error(\"Got interrupted while reinitializing TaskTracker: \" + \n          i.getMessage());\n      return;\n    }\n  }",
      "path": "mapreduce/src/java/org/apache/hadoop/mapred/TaskTracker.java"
    }
  }
}