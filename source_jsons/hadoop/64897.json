{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "WriteOperationHelper.java",
  "functionName": "initiateMultiPartUpload",
  "functionId": "initiateMultiPartUpload___destKey-String",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/WriteOperationHelper.java",
  "functionStartLine": 220,
  "functionEndLine": 231,
  "numCommitsSeen": 95,
  "timeTaken": 6283,
  "changeHistory": [
    "f365957c6326f88734bc0a5d01cfb7eac713db20",
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
    "839b690ed5edc2ac4984640d58c005bb63cd8a07",
    "6c348c56918973fd988b110e79231324a8befe12",
    "c58a59f7081d55dd2108545ebf9ee48cf43ca944",
    "39ec1515a205952eda7e171408a8b83eceb4abde",
    "15b7076ad5f2ae92d231140b2f8cebc392a92c87"
  ],
  "changeHistoryShort": {
    "f365957c6326f88734bc0a5d01cfb7eac713db20": "Ybodychange",
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yparameterchange)",
    "839b690ed5edc2ac4984640d58c005bb63cd8a07": "Ybodychange",
    "6c348c56918973fd988b110e79231324a8befe12": "Ymultichange(Ymovefromfile,Yreturntypechange,Ymodifierchange,Ybodychange)",
    "c58a59f7081d55dd2108545ebf9ee48cf43ca944": "Ybodychange",
    "39ec1515a205952eda7e171408a8b83eceb4abde": "Ybodychange",
    "15b7076ad5f2ae92d231140b2f8cebc392a92c87": "Yintroduced"
  },
  "changeHistoryDetails": {
    "f365957c6326f88734bc0a5d01cfb7eac713db20": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-15229. Add FileSystem builder-based openFile() API to match createFile();\nS3A to implement S3 Select through this API.\n\nThe new openFile() API is asynchronous, and implemented across FileSystem and FileContext.\n\nThe MapReduce V2 inputs are moved to this API, and you can actually set must/may\noptions to pass in.\n\nThis is more useful for setting things like s3a seek policy than for S3 select,\nas the existing input format/record readers can\u0027t handle S3 select output where\nthe stream is shorter than the file length, and splitting plain text is suboptimal.\nFuture work is needed there.\n\nIn the meantime, any/all filesystem connectors are now free to add their own filesystem-specific\nconfiguration parameters which can be set in jobs and used to set filesystem input stream\noptions (seek policy, retry, encryption secrets, etc).\n\nContributed by Steve Loughran\n",
      "commitDate": "05/02/19 3:51 AM",
      "commitName": "f365957c6326f88734bc0a5d01cfb7eac713db20",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "16/10/18 12:02 PM",
      "commitNameOld": "d59ca43bff8a457ce7ab62a61acd89aacbe71b93",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 111.7,
      "commitsBetweenForRepo": 781,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,12 @@\n   public String initiateMultiPartUpload(String destKey) throws IOException {\n     LOG.debug(\"Initiating Multipart upload to {}\", destKey);\n     final InitiateMultipartUploadRequest initiateMPURequest \u003d\n-        new InitiateMultipartUploadRequest(owner.getBucket(),\n+        new InitiateMultipartUploadRequest(bucket,\n             destKey,\n             newObjectMetadata(-1));\n     initiateMPURequest.setCannedACL(owner.getCannedACL());\n     owner.setOptionalMultipartUploadRequestParameters(initiateMPURequest);\n \n     return retry(\"initiate MultiPartUpload\", destKey, true,\n         () -\u003e owner.initiateMultipartUpload(initiateMPURequest).getUploadId());\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public String initiateMultiPartUpload(String destKey) throws IOException {\n    LOG.debug(\"Initiating Multipart upload to {}\", destKey);\n    final InitiateMultipartUploadRequest initiateMPURequest \u003d\n        new InitiateMultipartUploadRequest(bucket,\n            destKey,\n            newObjectMetadata(-1));\n    initiateMPURequest.setCannedACL(owner.getCannedACL());\n    owner.setOptionalMultipartUploadRequestParameters(initiateMPURequest);\n\n    return retry(\"initiate MultiPartUpload\", destKey, true,\n        () -\u003e owner.initiateMultipartUpload(initiateMPURequest).getUploadId());\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/WriteOperationHelper.java",
      "extendedDetails": {}
    },
    "de8b6ca5ef8614de6d6277b7617e27c788b0555c": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yparameterchange)",
      "commitMessage": "HADOOP-13786 Add S3A committer for zero-rename commits to S3 endpoints.\nContributed by Steve Loughran and Ryan Blue.\n",
      "commitDate": "22/11/17 7:28 AM",
      "commitName": "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HADOOP-13786 Add S3A committer for zero-rename commits to S3 endpoints.\nContributed by Steve Loughran and Ryan Blue.\n",
          "commitDate": "22/11/17 7:28 AM",
          "commitName": "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "21/11/17 8:42 PM",
          "commitNameOld": "782ba3bf9da52699b27405a3f147464975d1df99",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 0.45,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,12 @@\n-    String initiateMultiPartUpload() throws IOException {\n-      LOG.debug(\"Initiating Multipart upload\");\n-      final InitiateMultipartUploadRequest initiateMPURequest \u003d\n-          new InitiateMultipartUploadRequest(bucket,\n-              key,\n-              newObjectMetadata(-1));\n-      initiateMPURequest.setCannedACL(cannedACL);\n-      setOptionalMultipartUploadRequestParameters(initiateMPURequest);\n-      try {\n-        return s3.initiateMultipartUpload(initiateMPURequest)\n-            .getUploadId();\n-      } catch (AmazonClientException ace) {\n-        throw translateException(\"initiate MultiPartUpload\", key, ace);\n-      }\n-    }\n\\ No newline at end of file\n+  public String initiateMultiPartUpload(String destKey) throws IOException {\n+    LOG.debug(\"Initiating Multipart upload to {}\", destKey);\n+    final InitiateMultipartUploadRequest initiateMPURequest \u003d\n+        new InitiateMultipartUploadRequest(owner.getBucket(),\n+            destKey,\n+            newObjectMetadata(-1));\n+    initiateMPURequest.setCannedACL(owner.getCannedACL());\n+    owner.setOptionalMultipartUploadRequestParameters(initiateMPURequest);\n+\n+    return retry(\"initiate MultiPartUpload\", destKey, true,\n+        () -\u003e owner.initiateMultipartUpload(initiateMPURequest).getUploadId());\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  public String initiateMultiPartUpload(String destKey) throws IOException {\n    LOG.debug(\"Initiating Multipart upload to {}\", destKey);\n    final InitiateMultipartUploadRequest initiateMPURequest \u003d\n        new InitiateMultipartUploadRequest(owner.getBucket(),\n            destKey,\n            newObjectMetadata(-1));\n    initiateMPURequest.setCannedACL(owner.getCannedACL());\n    owner.setOptionalMultipartUploadRequestParameters(initiateMPURequest);\n\n    return retry(\"initiate MultiPartUpload\", destKey, true,\n        () -\u003e owner.initiateMultipartUpload(initiateMPURequest).getUploadId());\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/WriteOperationHelper.java",
          "extendedDetails": {
            "oldPath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
            "newPath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/WriteOperationHelper.java",
            "oldMethodName": "initiateMultiPartUpload",
            "newMethodName": "initiateMultiPartUpload"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HADOOP-13786 Add S3A committer for zero-rename commits to S3 endpoints.\nContributed by Steve Loughran and Ryan Blue.\n",
          "commitDate": "22/11/17 7:28 AM",
          "commitName": "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "21/11/17 8:42 PM",
          "commitNameOld": "782ba3bf9da52699b27405a3f147464975d1df99",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 0.45,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,12 @@\n-    String initiateMultiPartUpload() throws IOException {\n-      LOG.debug(\"Initiating Multipart upload\");\n-      final InitiateMultipartUploadRequest initiateMPURequest \u003d\n-          new InitiateMultipartUploadRequest(bucket,\n-              key,\n-              newObjectMetadata(-1));\n-      initiateMPURequest.setCannedACL(cannedACL);\n-      setOptionalMultipartUploadRequestParameters(initiateMPURequest);\n-      try {\n-        return s3.initiateMultipartUpload(initiateMPURequest)\n-            .getUploadId();\n-      } catch (AmazonClientException ace) {\n-        throw translateException(\"initiate MultiPartUpload\", key, ace);\n-      }\n-    }\n\\ No newline at end of file\n+  public String initiateMultiPartUpload(String destKey) throws IOException {\n+    LOG.debug(\"Initiating Multipart upload to {}\", destKey);\n+    final InitiateMultipartUploadRequest initiateMPURequest \u003d\n+        new InitiateMultipartUploadRequest(owner.getBucket(),\n+            destKey,\n+            newObjectMetadata(-1));\n+    initiateMPURequest.setCannedACL(owner.getCannedACL());\n+    owner.setOptionalMultipartUploadRequestParameters(initiateMPURequest);\n+\n+    return retry(\"initiate MultiPartUpload\", destKey, true,\n+        () -\u003e owner.initiateMultipartUpload(initiateMPURequest).getUploadId());\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  public String initiateMultiPartUpload(String destKey) throws IOException {\n    LOG.debug(\"Initiating Multipart upload to {}\", destKey);\n    final InitiateMultipartUploadRequest initiateMPURequest \u003d\n        new InitiateMultipartUploadRequest(owner.getBucket(),\n            destKey,\n            newObjectMetadata(-1));\n    initiateMPURequest.setCannedACL(owner.getCannedACL());\n    owner.setOptionalMultipartUploadRequestParameters(initiateMPURequest);\n\n    return retry(\"initiate MultiPartUpload\", destKey, true,\n        () -\u003e owner.initiateMultipartUpload(initiateMPURequest).getUploadId());\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/WriteOperationHelper.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[public]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-13786 Add S3A committer for zero-rename commits to S3 endpoints.\nContributed by Steve Loughran and Ryan Blue.\n",
          "commitDate": "22/11/17 7:28 AM",
          "commitName": "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "21/11/17 8:42 PM",
          "commitNameOld": "782ba3bf9da52699b27405a3f147464975d1df99",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 0.45,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,12 @@\n-    String initiateMultiPartUpload() throws IOException {\n-      LOG.debug(\"Initiating Multipart upload\");\n-      final InitiateMultipartUploadRequest initiateMPURequest \u003d\n-          new InitiateMultipartUploadRequest(bucket,\n-              key,\n-              newObjectMetadata(-1));\n-      initiateMPURequest.setCannedACL(cannedACL);\n-      setOptionalMultipartUploadRequestParameters(initiateMPURequest);\n-      try {\n-        return s3.initiateMultipartUpload(initiateMPURequest)\n-            .getUploadId();\n-      } catch (AmazonClientException ace) {\n-        throw translateException(\"initiate MultiPartUpload\", key, ace);\n-      }\n-    }\n\\ No newline at end of file\n+  public String initiateMultiPartUpload(String destKey) throws IOException {\n+    LOG.debug(\"Initiating Multipart upload to {}\", destKey);\n+    final InitiateMultipartUploadRequest initiateMPURequest \u003d\n+        new InitiateMultipartUploadRequest(owner.getBucket(),\n+            destKey,\n+            newObjectMetadata(-1));\n+    initiateMPURequest.setCannedACL(owner.getCannedACL());\n+    owner.setOptionalMultipartUploadRequestParameters(initiateMPURequest);\n+\n+    return retry(\"initiate MultiPartUpload\", destKey, true,\n+        () -\u003e owner.initiateMultipartUpload(initiateMPURequest).getUploadId());\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  public String initiateMultiPartUpload(String destKey) throws IOException {\n    LOG.debug(\"Initiating Multipart upload to {}\", destKey);\n    final InitiateMultipartUploadRequest initiateMPURequest \u003d\n        new InitiateMultipartUploadRequest(owner.getBucket(),\n            destKey,\n            newObjectMetadata(-1));\n    initiateMPURequest.setCannedACL(owner.getCannedACL());\n    owner.setOptionalMultipartUploadRequestParameters(initiateMPURequest);\n\n    return retry(\"initiate MultiPartUpload\", destKey, true,\n        () -\u003e owner.initiateMultipartUpload(initiateMPURequest).getUploadId());\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/WriteOperationHelper.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HADOOP-13786 Add S3A committer for zero-rename commits to S3 endpoints.\nContributed by Steve Loughran and Ryan Blue.\n",
          "commitDate": "22/11/17 7:28 AM",
          "commitName": "de8b6ca5ef8614de6d6277b7617e27c788b0555c",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "21/11/17 8:42 PM",
          "commitNameOld": "782ba3bf9da52699b27405a3f147464975d1df99",
          "commitAuthorOld": "Chris Douglas",
          "daysBetweenCommits": 0.45,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,12 @@\n-    String initiateMultiPartUpload() throws IOException {\n-      LOG.debug(\"Initiating Multipart upload\");\n-      final InitiateMultipartUploadRequest initiateMPURequest \u003d\n-          new InitiateMultipartUploadRequest(bucket,\n-              key,\n-              newObjectMetadata(-1));\n-      initiateMPURequest.setCannedACL(cannedACL);\n-      setOptionalMultipartUploadRequestParameters(initiateMPURequest);\n-      try {\n-        return s3.initiateMultipartUpload(initiateMPURequest)\n-            .getUploadId();\n-      } catch (AmazonClientException ace) {\n-        throw translateException(\"initiate MultiPartUpload\", key, ace);\n-      }\n-    }\n\\ No newline at end of file\n+  public String initiateMultiPartUpload(String destKey) throws IOException {\n+    LOG.debug(\"Initiating Multipart upload to {}\", destKey);\n+    final InitiateMultipartUploadRequest initiateMPURequest \u003d\n+        new InitiateMultipartUploadRequest(owner.getBucket(),\n+            destKey,\n+            newObjectMetadata(-1));\n+    initiateMPURequest.setCannedACL(owner.getCannedACL());\n+    owner.setOptionalMultipartUploadRequestParameters(initiateMPURequest);\n+\n+    return retry(\"initiate MultiPartUpload\", destKey, true,\n+        () -\u003e owner.initiateMultipartUpload(initiateMPURequest).getUploadId());\n+  }\n\\ No newline at end of file\n",
          "actualSource": "  public String initiateMultiPartUpload(String destKey) throws IOException {\n    LOG.debug(\"Initiating Multipart upload to {}\", destKey);\n    final InitiateMultipartUploadRequest initiateMPURequest \u003d\n        new InitiateMultipartUploadRequest(owner.getBucket(),\n            destKey,\n            newObjectMetadata(-1));\n    initiateMPURequest.setCannedACL(owner.getCannedACL());\n    owner.setOptionalMultipartUploadRequestParameters(initiateMPURequest);\n\n    return retry(\"initiate MultiPartUpload\", destKey, true,\n        () -\u003e owner.initiateMultipartUpload(initiateMPURequest).getUploadId());\n  }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/WriteOperationHelper.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[destKey-String]"
          }
        }
      ]
    },
    "839b690ed5edc2ac4984640d58c005bb63cd8a07": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13075. Add support for SSE-KMS and SSE-C in s3a filesystem. (Steve Moist via lei)\n",
      "commitDate": "11/02/17 1:59 PM",
      "commitName": "839b690ed5edc2ac4984640d58c005bb63cd8a07",
      "commitAuthor": "Lei Xu",
      "commitDateOld": "11/01/17 9:25 AM",
      "commitNameOld": "e648b6e1382336af69434dfbf9161bced3caa244",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 31.19,
      "commitsBetweenForRepo": 140,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,15 @@\n     String initiateMultiPartUpload() throws IOException {\n       LOG.debug(\"Initiating Multipart upload\");\n       final InitiateMultipartUploadRequest initiateMPURequest \u003d\n           new InitiateMultipartUploadRequest(bucket,\n               key,\n               newObjectMetadata(-1));\n       initiateMPURequest.setCannedACL(cannedACL);\n+      setOptionalMultipartUploadRequestParameters(initiateMPURequest);\n       try {\n         return s3.initiateMultipartUpload(initiateMPURequest)\n             .getUploadId();\n       } catch (AmazonClientException ace) {\n         throw translateException(\"initiate MultiPartUpload\", key, ace);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    String initiateMultiPartUpload() throws IOException {\n      LOG.debug(\"Initiating Multipart upload\");\n      final InitiateMultipartUploadRequest initiateMPURequest \u003d\n          new InitiateMultipartUploadRequest(bucket,\n              key,\n              newObjectMetadata(-1));\n      initiateMPURequest.setCannedACL(cannedACL);\n      setOptionalMultipartUploadRequestParameters(initiateMPURequest);\n      try {\n        return s3.initiateMultipartUpload(initiateMPURequest)\n            .getUploadId();\n      } catch (AmazonClientException ace) {\n        throw translateException(\"initiate MultiPartUpload\", key, ace);\n      }\n    }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
      "extendedDetails": {}
    },
    "6c348c56918973fd988b110e79231324a8befe12": {
      "type": "Ymultichange(Ymovefromfile,Yreturntypechange,Ymodifierchange,Ybodychange)",
      "commitMessage": "HADOOP-13560. S3ABlockOutputStream to support huge (many GB) file writes. Contributed by Steve Loughran\n",
      "commitDate": "18/10/16 1:16 PM",
      "commitName": "6c348c56918973fd988b110e79231324a8befe12",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HADOOP-13560. S3ABlockOutputStream to support huge (many GB) file writes. Contributed by Steve Loughran\n",
          "commitDate": "18/10/16 1:16 PM",
          "commitName": "6c348c56918973fd988b110e79231324a8befe12",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "18/10/16 11:06 AM",
          "commitNameOld": "b733a6f86262522e535cebc972baecbe6a6eab50",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 0.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,14 @@\n-  private MultiPartUpload initiateMultiPartUpload() throws IOException {\n-    final InitiateMultipartUploadRequest initiateMPURequest \u003d\n-        new InitiateMultipartUploadRequest(bucket,\n-            key,\n-            createDefaultMetadata());\n-    initiateMPURequest.setCannedACL(cannedACL);\n-    try {\n-      return new MultiPartUpload(\n-          client.initiateMultipartUpload(initiateMPURequest).getUploadId());\n-    } catch (AmazonClientException ace) {\n-      throw translateException(\"initiate MultiPartUpload\", key, ace);\n-    }\n-  }\n\\ No newline at end of file\n+    String initiateMultiPartUpload() throws IOException {\n+      LOG.debug(\"Initiating Multipart upload\");\n+      final InitiateMultipartUploadRequest initiateMPURequest \u003d\n+          new InitiateMultipartUploadRequest(bucket,\n+              key,\n+              newObjectMetadata(-1));\n+      initiateMPURequest.setCannedACL(cannedACL);\n+      try {\n+        return s3.initiateMultipartUpload(initiateMPURequest)\n+            .getUploadId();\n+      } catch (AmazonClientException ace) {\n+        throw translateException(\"initiate MultiPartUpload\", key, ace);\n+      }\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    String initiateMultiPartUpload() throws IOException {\n      LOG.debug(\"Initiating Multipart upload\");\n      final InitiateMultipartUploadRequest initiateMPURequest \u003d\n          new InitiateMultipartUploadRequest(bucket,\n              key,\n              newObjectMetadata(-1));\n      initiateMPURequest.setCannedACL(cannedACL);\n      try {\n        return s3.initiateMultipartUpload(initiateMPURequest)\n            .getUploadId();\n      } catch (AmazonClientException ace) {\n        throw translateException(\"initiate MultiPartUpload\", key, ace);\n      }\n    }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {
            "oldPath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java",
            "newPath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
            "oldMethodName": "initiateMultiPartUpload",
            "newMethodName": "initiateMultiPartUpload"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HADOOP-13560. S3ABlockOutputStream to support huge (many GB) file writes. Contributed by Steve Loughran\n",
          "commitDate": "18/10/16 1:16 PM",
          "commitName": "6c348c56918973fd988b110e79231324a8befe12",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "18/10/16 11:06 AM",
          "commitNameOld": "b733a6f86262522e535cebc972baecbe6a6eab50",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 0.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,14 @@\n-  private MultiPartUpload initiateMultiPartUpload() throws IOException {\n-    final InitiateMultipartUploadRequest initiateMPURequest \u003d\n-        new InitiateMultipartUploadRequest(bucket,\n-            key,\n-            createDefaultMetadata());\n-    initiateMPURequest.setCannedACL(cannedACL);\n-    try {\n-      return new MultiPartUpload(\n-          client.initiateMultipartUpload(initiateMPURequest).getUploadId());\n-    } catch (AmazonClientException ace) {\n-      throw translateException(\"initiate MultiPartUpload\", key, ace);\n-    }\n-  }\n\\ No newline at end of file\n+    String initiateMultiPartUpload() throws IOException {\n+      LOG.debug(\"Initiating Multipart upload\");\n+      final InitiateMultipartUploadRequest initiateMPURequest \u003d\n+          new InitiateMultipartUploadRequest(bucket,\n+              key,\n+              newObjectMetadata(-1));\n+      initiateMPURequest.setCannedACL(cannedACL);\n+      try {\n+        return s3.initiateMultipartUpload(initiateMPURequest)\n+            .getUploadId();\n+      } catch (AmazonClientException ace) {\n+        throw translateException(\"initiate MultiPartUpload\", key, ace);\n+      }\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    String initiateMultiPartUpload() throws IOException {\n      LOG.debug(\"Initiating Multipart upload\");\n      final InitiateMultipartUploadRequest initiateMPURequest \u003d\n          new InitiateMultipartUploadRequest(bucket,\n              key,\n              newObjectMetadata(-1));\n      initiateMPURequest.setCannedACL(cannedACL);\n      try {\n        return s3.initiateMultipartUpload(initiateMPURequest)\n            .getUploadId();\n      } catch (AmazonClientException ace) {\n        throw translateException(\"initiate MultiPartUpload\", key, ace);\n      }\n    }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {
            "oldValue": "MultiPartUpload",
            "newValue": "String"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HADOOP-13560. S3ABlockOutputStream to support huge (many GB) file writes. Contributed by Steve Loughran\n",
          "commitDate": "18/10/16 1:16 PM",
          "commitName": "6c348c56918973fd988b110e79231324a8befe12",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "18/10/16 11:06 AM",
          "commitNameOld": "b733a6f86262522e535cebc972baecbe6a6eab50",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 0.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,14 @@\n-  private MultiPartUpload initiateMultiPartUpload() throws IOException {\n-    final InitiateMultipartUploadRequest initiateMPURequest \u003d\n-        new InitiateMultipartUploadRequest(bucket,\n-            key,\n-            createDefaultMetadata());\n-    initiateMPURequest.setCannedACL(cannedACL);\n-    try {\n-      return new MultiPartUpload(\n-          client.initiateMultipartUpload(initiateMPURequest).getUploadId());\n-    } catch (AmazonClientException ace) {\n-      throw translateException(\"initiate MultiPartUpload\", key, ace);\n-    }\n-  }\n\\ No newline at end of file\n+    String initiateMultiPartUpload() throws IOException {\n+      LOG.debug(\"Initiating Multipart upload\");\n+      final InitiateMultipartUploadRequest initiateMPURequest \u003d\n+          new InitiateMultipartUploadRequest(bucket,\n+              key,\n+              newObjectMetadata(-1));\n+      initiateMPURequest.setCannedACL(cannedACL);\n+      try {\n+        return s3.initiateMultipartUpload(initiateMPURequest)\n+            .getUploadId();\n+      } catch (AmazonClientException ace) {\n+        throw translateException(\"initiate MultiPartUpload\", key, ace);\n+      }\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    String initiateMultiPartUpload() throws IOException {\n      LOG.debug(\"Initiating Multipart upload\");\n      final InitiateMultipartUploadRequest initiateMPURequest \u003d\n          new InitiateMultipartUploadRequest(bucket,\n              key,\n              newObjectMetadata(-1));\n      initiateMPURequest.setCannedACL(cannedACL);\n      try {\n        return s3.initiateMultipartUpload(initiateMPURequest)\n            .getUploadId();\n      } catch (AmazonClientException ace) {\n        throw translateException(\"initiate MultiPartUpload\", key, ace);\n      }\n    }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-13560. S3ABlockOutputStream to support huge (many GB) file writes. Contributed by Steve Loughran\n",
          "commitDate": "18/10/16 1:16 PM",
          "commitName": "6c348c56918973fd988b110e79231324a8befe12",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "18/10/16 11:06 AM",
          "commitNameOld": "b733a6f86262522e535cebc972baecbe6a6eab50",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 0.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,13 +1,14 @@\n-  private MultiPartUpload initiateMultiPartUpload() throws IOException {\n-    final InitiateMultipartUploadRequest initiateMPURequest \u003d\n-        new InitiateMultipartUploadRequest(bucket,\n-            key,\n-            createDefaultMetadata());\n-    initiateMPURequest.setCannedACL(cannedACL);\n-    try {\n-      return new MultiPartUpload(\n-          client.initiateMultipartUpload(initiateMPURequest).getUploadId());\n-    } catch (AmazonClientException ace) {\n-      throw translateException(\"initiate MultiPartUpload\", key, ace);\n-    }\n-  }\n\\ No newline at end of file\n+    String initiateMultiPartUpload() throws IOException {\n+      LOG.debug(\"Initiating Multipart upload\");\n+      final InitiateMultipartUploadRequest initiateMPURequest \u003d\n+          new InitiateMultipartUploadRequest(bucket,\n+              key,\n+              newObjectMetadata(-1));\n+      initiateMPURequest.setCannedACL(cannedACL);\n+      try {\n+        return s3.initiateMultipartUpload(initiateMPURequest)\n+            .getUploadId();\n+      } catch (AmazonClientException ace) {\n+        throw translateException(\"initiate MultiPartUpload\", key, ace);\n+      }\n+    }\n\\ No newline at end of file\n",
          "actualSource": "    String initiateMultiPartUpload() throws IOException {\n      LOG.debug(\"Initiating Multipart upload\");\n      final InitiateMultipartUploadRequest initiateMPURequest \u003d\n          new InitiateMultipartUploadRequest(bucket,\n              key,\n              newObjectMetadata(-1));\n      initiateMPURequest.setCannedACL(cannedACL);\n      try {\n        return s3.initiateMultipartUpload(initiateMPURequest)\n            .getUploadId();\n      } catch (AmazonClientException ace) {\n        throw translateException(\"initiate MultiPartUpload\", key, ace);\n      }\n    }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java",
          "extendedDetails": {}
        }
      ]
    },
    "c58a59f7081d55dd2108545ebf9ee48cf43ca944": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13171. Add StorageStatistics to S3A; instrument some more operations. Contributed by Steve Loughran.\n",
      "commitDate": "03/06/16 8:55 AM",
      "commitName": "c58a59f7081d55dd2108545ebf9ee48cf43ca944",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "21/05/16 8:39 AM",
      "commitNameOld": "39ec1515a205952eda7e171408a8b83eceb4abde",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 13.01,
      "commitsBetweenForRepo": 75,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,12 +1,13 @@\n   private MultiPartUpload initiateMultiPartUpload() throws IOException {\n-    final ObjectMetadata om \u003d createDefaultMetadata();\n     final InitiateMultipartUploadRequest initiateMPURequest \u003d\n-        new InitiateMultipartUploadRequest(bucket, key, om);\n+        new InitiateMultipartUploadRequest(bucket,\n+            key,\n+            createDefaultMetadata());\n     initiateMPURequest.setCannedACL(cannedACL);\n     try {\n       return new MultiPartUpload(\n           client.initiateMultipartUpload(initiateMPURequest).getUploadId());\n     } catch (AmazonClientException ace) {\n       throw translateException(\"initiate MultiPartUpload\", key, ace);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private MultiPartUpload initiateMultiPartUpload() throws IOException {\n    final InitiateMultipartUploadRequest initiateMPURequest \u003d\n        new InitiateMultipartUploadRequest(bucket,\n            key,\n            createDefaultMetadata());\n    initiateMPURequest.setCannedACL(cannedACL);\n    try {\n      return new MultiPartUpload(\n          client.initiateMultipartUpload(initiateMPURequest).getUploadId());\n    } catch (AmazonClientException ace) {\n      throw translateException(\"initiate MultiPartUpload\", key, ace);\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java",
      "extendedDetails": {}
    },
    "39ec1515a205952eda7e171408a8b83eceb4abde": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13130. s3a failures can surface as RTEs, not IOEs. (Steve Loughran)\n",
      "commitDate": "21/05/16 8:39 AM",
      "commitName": "39ec1515a205952eda7e171408a8b83eceb4abde",
      "commitAuthor": "Steve Loughran",
      "commitDateOld": "12/05/16 11:24 AM",
      "commitNameOld": "27c4e90efce04e1b1302f668b5eb22412e00d033",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 8.89,
      "commitsBetweenForRepo": 74,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,12 @@\n   private MultiPartUpload initiateMultiPartUpload() throws IOException {\n     final ObjectMetadata om \u003d createDefaultMetadata();\n     final InitiateMultipartUploadRequest initiateMPURequest \u003d\n         new InitiateMultipartUploadRequest(bucket, key, om);\n     initiateMPURequest.setCannedACL(cannedACL);\n     try {\n       return new MultiPartUpload(\n           client.initiateMultipartUpload(initiateMPURequest).getUploadId());\n-    } catch (AmazonServiceException ase) {\n-      throw new IOException(\"Unable to initiate MultiPartUpload (server side)\" +\n-          \": \" + ase, ase);\n     } catch (AmazonClientException ace) {\n-      throw new IOException(\"Unable to initiate MultiPartUpload (client side)\" +\n-          \": \" + ace, ace);\n+      throw translateException(\"initiate MultiPartUpload\", key, ace);\n     }\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private MultiPartUpload initiateMultiPartUpload() throws IOException {\n    final ObjectMetadata om \u003d createDefaultMetadata();\n    final InitiateMultipartUploadRequest initiateMPURequest \u003d\n        new InitiateMultipartUploadRequest(bucket, key, om);\n    initiateMPURequest.setCannedACL(cannedACL);\n    try {\n      return new MultiPartUpload(\n          client.initiateMultipartUpload(initiateMPURequest).getUploadId());\n    } catch (AmazonClientException ace) {\n      throw translateException(\"initiate MultiPartUpload\", key, ace);\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java",
      "extendedDetails": {}
    },
    "15b7076ad5f2ae92d231140b2f8cebc392a92c87": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-11183. Memory-based S3AOutputstream. (Thomas Demoor via stevel)\n",
      "commitDate": "03/03/15 4:18 PM",
      "commitName": "15b7076ad5f2ae92d231140b2f8cebc392a92c87",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,16 @@\n+  private MultiPartUpload initiateMultiPartUpload() throws IOException {\n+    final ObjectMetadata om \u003d createDefaultMetadata();\n+    final InitiateMultipartUploadRequest initiateMPURequest \u003d\n+        new InitiateMultipartUploadRequest(bucket, key, om);\n+    initiateMPURequest.setCannedACL(cannedACL);\n+    try {\n+      return new MultiPartUpload(\n+          client.initiateMultipartUpload(initiateMPURequest).getUploadId());\n+    } catch (AmazonServiceException ase) {\n+      throw new IOException(\"Unable to initiate MultiPartUpload (server side)\" +\n+          \": \" + ase, ase);\n+    } catch (AmazonClientException ace) {\n+      throw new IOException(\"Unable to initiate MultiPartUpload (client side)\" +\n+          \": \" + ace, ace);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private MultiPartUpload initiateMultiPartUpload() throws IOException {\n    final ObjectMetadata om \u003d createDefaultMetadata();\n    final InitiateMultipartUploadRequest initiateMPURequest \u003d\n        new InitiateMultipartUploadRequest(bucket, key, om);\n    initiateMPURequest.setCannedACL(cannedACL);\n    try {\n      return new MultiPartUpload(\n          client.initiateMultipartUpload(initiateMPURequest).getUploadId());\n    } catch (AmazonServiceException ase) {\n      throw new IOException(\"Unable to initiate MultiPartUpload (server side)\" +\n          \": \" + ase, ase);\n    } catch (AmazonClientException ace) {\n      throw new IOException(\"Unable to initiate MultiPartUpload (client side)\" +\n          \": \" + ace, ace);\n    }\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java"
    }
  }
}