{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImageSerialization.java",
  "functionName": "writeCompactBlockArray",
  "functionId": "writeCompactBlockArray___blocks-Block[]__out-DataOutputStream",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java",
  "functionStartLine": 486,
  "functionEndLine": 500,
  "numCommitsSeen": 62,
  "timeTaken": 1797,
  "changeHistory": [
    "30cffeb388f9065f0c5ce5fa53e127940a8917b6"
  ],
  "changeHistoryShort": {
    "30cffeb388f9065f0c5ce5fa53e127940a8917b6": "Yintroduced"
  },
  "changeHistoryDetails": {
    "30cffeb388f9065f0c5ce5fa53e127940a8917b6": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3023. Optimize entries in edits log for persistBlocks call. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1295356 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/02/12 4:37 PM",
      "commitName": "30cffeb388f9065f0c5ce5fa53e127940a8917b6",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,15 @@\n+  public static void writeCompactBlockArray(\n+      Block[] blocks, DataOutputStream out) throws IOException {\n+    WritableUtils.writeVInt(out, blocks.length);\n+    Block prev \u003d null;\n+    for (Block b : blocks) {\n+      long szDelta \u003d b.getNumBytes() -\n+          (prev !\u003d null ? prev.getNumBytes() : 0);\n+      long gsDelta \u003d b.getGenerationStamp() -\n+          (prev !\u003d null ? prev.getGenerationStamp() : 0);\n+      out.writeLong(b.getBlockId()); // blockid is random\n+      WritableUtils.writeVLong(out, szDelta);\n+      WritableUtils.writeVLong(out, gsDelta);\n+      prev \u003d b;\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static void writeCompactBlockArray(\n      Block[] blocks, DataOutputStream out) throws IOException {\n    WritableUtils.writeVInt(out, blocks.length);\n    Block prev \u003d null;\n    for (Block b : blocks) {\n      long szDelta \u003d b.getNumBytes() -\n          (prev !\u003d null ? prev.getNumBytes() : 0);\n      long gsDelta \u003d b.getGenerationStamp() -\n          (prev !\u003d null ? prev.getGenerationStamp() : 0);\n      out.writeLong(b.getBlockId()); // blockid is random\n      WritableUtils.writeVLong(out, szDelta);\n      WritableUtils.writeVLong(out, gsDelta);\n      prev \u003d b;\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java"
    }
  }
}