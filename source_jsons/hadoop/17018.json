{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "NamenodeBeanMetrics.java",
  "functionName": "getNodes",
  "functionId": "getNodes___type-DatanodeReportType(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/NamenodeBeanMetrics.java",
  "functionStartLine": 453,
  "functionEndLine": 461,
  "numCommitsSeen": 17,
  "timeTaken": 2469,
  "changeHistory": [
    "a71656c1c1bf6c680f1382a76ddcac870061f320",
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d",
    "bc9e588a19c0aaf518de8dab719362be4a8d6a54"
  ],
  "changeHistoryShort": {
    "a71656c1c1bf6c680f1382a76ddcac870061f320": "Ymultichange(Ybodychange,Yparametermetachange)",
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d": "Yfilerename",
    "bc9e588a19c0aaf518de8dab719362be4a8d6a54": "Yintroduced"
  },
  "changeHistoryDetails": {
    "a71656c1c1bf6c680f1382a76ddcac870061f320": {
      "type": "Ymultichange(Ybodychange,Yparametermetachange)",
      "commitMessage": "HDFS-13347. RBF: Cache datanode reports. Contributed by Inigo Goiri.\n",
      "commitDate": "27/03/18 8:00 PM",
      "commitName": "a71656c1c1bf6c680f1382a76ddcac870061f320",
      "commitAuthor": "Yiqun Lin",
      "subchanges": [
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-13347. RBF: Cache datanode reports. Contributed by Inigo Goiri.\n",
          "commitDate": "27/03/18 8:00 PM",
          "commitName": "a71656c1c1bf6c680f1382a76ddcac870061f320",
          "commitAuthor": "Yiqun Lin",
          "commitDateOld": "19/03/18 10:13 PM",
          "commitNameOld": "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d",
          "commitAuthorOld": "weiy",
          "daysBetweenCommits": 7.91,
          "commitsBetweenForRepo": 186,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,35 +1,9 @@\n-  private String getNodes(DatanodeReportType type) {\n-    final Map\u003cString, Map\u003cString, Object\u003e\u003e info \u003d new HashMap\u003c\u003e();\n+  private String getNodes(final DatanodeReportType type) {\n     try {\n-      RouterRpcServer rpcServer \u003d this.router.getRpcServer();\n-      DatanodeInfo[] datanodes \u003d rpcServer.getDatanodeReport(type);\n-      for (DatanodeInfo node : datanodes) {\n-        Map\u003cString, Object\u003e innerinfo \u003d new HashMap\u003c\u003e();\n-        innerinfo.put(\"infoAddr\", node.getInfoAddr());\n-        innerinfo.put(\"infoSecureAddr\", node.getInfoSecureAddr());\n-        innerinfo.put(\"xferaddr\", node.getXferAddr());\n-        innerinfo.put(\"location\", node.getNetworkLocation());\n-        innerinfo.put(\"lastContact\", getLastContact(node));\n-        innerinfo.put(\"usedSpace\", node.getDfsUsed());\n-        innerinfo.put(\"adminState\", node.getAdminState().toString());\n-        innerinfo.put(\"nonDfsUsedSpace\", node.getNonDfsUsed());\n-        innerinfo.put(\"capacity\", node.getCapacity());\n-        innerinfo.put(\"numBlocks\", -1); // node.numBlocks()\n-        innerinfo.put(\"version\", (node.getSoftwareVersion() \u003d\u003d null ?\n-                        \"UNKNOWN\" : node.getSoftwareVersion()));\n-        innerinfo.put(\"used\", node.getDfsUsed());\n-        innerinfo.put(\"remaining\", node.getRemaining());\n-        innerinfo.put(\"blockScheduled\", -1); // node.getBlocksScheduled()\n-        innerinfo.put(\"blockPoolUsed\", node.getBlockPoolUsed());\n-        innerinfo.put(\"blockPoolUsedPercent\", node.getBlockPoolUsedPercent());\n-        innerinfo.put(\"volfails\", -1); // node.getVolumeFailures()\n-        info.put(node.getHostName() + \":\" + node.getXferPort(),\n-            Collections.unmodifiableMap(innerinfo));\n-      }\n-    } catch (StandbyException e) {\n-      LOG.error(\"Cannot get {} nodes, Router in safe mode\", type);\n-    } catch (IOException e) {\n-      LOG.error(\"Cannot get \" + type + \" nodes\", e);\n+      return this.dnCache.get(type);\n+    } catch (ExecutionException e) {\n+      LOG.error(\"Cannot get the DN storage report for {}\", type, e);\n     }\n-    return JSON.toString(info);\n+    // If we cannot get the report, return empty JSON\n+    return \"{}\";\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private String getNodes(final DatanodeReportType type) {\n    try {\n      return this.dnCache.get(type);\n    } catch (ExecutionException e) {\n      LOG.error(\"Cannot get the DN storage report for {}\", type, e);\n    }\n    // If we cannot get the report, return empty JSON\n    return \"{}\";\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/NamenodeBeanMetrics.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparametermetachange",
          "commitMessage": "HDFS-13347. RBF: Cache datanode reports. Contributed by Inigo Goiri.\n",
          "commitDate": "27/03/18 8:00 PM",
          "commitName": "a71656c1c1bf6c680f1382a76ddcac870061f320",
          "commitAuthor": "Yiqun Lin",
          "commitDateOld": "19/03/18 10:13 PM",
          "commitNameOld": "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d",
          "commitAuthorOld": "weiy",
          "daysBetweenCommits": 7.91,
          "commitsBetweenForRepo": 186,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,35 +1,9 @@\n-  private String getNodes(DatanodeReportType type) {\n-    final Map\u003cString, Map\u003cString, Object\u003e\u003e info \u003d new HashMap\u003c\u003e();\n+  private String getNodes(final DatanodeReportType type) {\n     try {\n-      RouterRpcServer rpcServer \u003d this.router.getRpcServer();\n-      DatanodeInfo[] datanodes \u003d rpcServer.getDatanodeReport(type);\n-      for (DatanodeInfo node : datanodes) {\n-        Map\u003cString, Object\u003e innerinfo \u003d new HashMap\u003c\u003e();\n-        innerinfo.put(\"infoAddr\", node.getInfoAddr());\n-        innerinfo.put(\"infoSecureAddr\", node.getInfoSecureAddr());\n-        innerinfo.put(\"xferaddr\", node.getXferAddr());\n-        innerinfo.put(\"location\", node.getNetworkLocation());\n-        innerinfo.put(\"lastContact\", getLastContact(node));\n-        innerinfo.put(\"usedSpace\", node.getDfsUsed());\n-        innerinfo.put(\"adminState\", node.getAdminState().toString());\n-        innerinfo.put(\"nonDfsUsedSpace\", node.getNonDfsUsed());\n-        innerinfo.put(\"capacity\", node.getCapacity());\n-        innerinfo.put(\"numBlocks\", -1); // node.numBlocks()\n-        innerinfo.put(\"version\", (node.getSoftwareVersion() \u003d\u003d null ?\n-                        \"UNKNOWN\" : node.getSoftwareVersion()));\n-        innerinfo.put(\"used\", node.getDfsUsed());\n-        innerinfo.put(\"remaining\", node.getRemaining());\n-        innerinfo.put(\"blockScheduled\", -1); // node.getBlocksScheduled()\n-        innerinfo.put(\"blockPoolUsed\", node.getBlockPoolUsed());\n-        innerinfo.put(\"blockPoolUsedPercent\", node.getBlockPoolUsedPercent());\n-        innerinfo.put(\"volfails\", -1); // node.getVolumeFailures()\n-        info.put(node.getHostName() + \":\" + node.getXferPort(),\n-            Collections.unmodifiableMap(innerinfo));\n-      }\n-    } catch (StandbyException e) {\n-      LOG.error(\"Cannot get {} nodes, Router in safe mode\", type);\n-    } catch (IOException e) {\n-      LOG.error(\"Cannot get \" + type + \" nodes\", e);\n+      return this.dnCache.get(type);\n+    } catch (ExecutionException e) {\n+      LOG.error(\"Cannot get the DN storage report for {}\", type, e);\n     }\n-    return JSON.toString(info);\n+    // If we cannot get the report, return empty JSON\n+    return \"{}\";\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private String getNodes(final DatanodeReportType type) {\n    try {\n      return this.dnCache.get(type);\n    } catch (ExecutionException e) {\n      LOG.error(\"Cannot get the DN storage report for {}\", type, e);\n    }\n    // If we cannot get the report, return empty JSON\n    return \"{}\";\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/NamenodeBeanMetrics.java",
          "extendedDetails": {
            "oldValue": "[type-DatanodeReportType]",
            "newValue": "[type-DatanodeReportType(modifiers-final)]"
          }
        }
      ]
    },
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-13215. RBF: Move Router to its own module. Contributed by Wei Yan\n",
      "commitDate": "19/03/18 10:13 PM",
      "commitName": "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d",
      "commitAuthor": "weiy",
      "commitDateOld": "19/03/18 5:19 PM",
      "commitNameOld": "e65ff1c8be48ef4f04ed96f96ac4caef4974944d",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 0.2,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private String getNodes(DatanodeReportType type) {\n    final Map\u003cString, Map\u003cString, Object\u003e\u003e info \u003d new HashMap\u003c\u003e();\n    try {\n      RouterRpcServer rpcServer \u003d this.router.getRpcServer();\n      DatanodeInfo[] datanodes \u003d rpcServer.getDatanodeReport(type);\n      for (DatanodeInfo node : datanodes) {\n        Map\u003cString, Object\u003e innerinfo \u003d new HashMap\u003c\u003e();\n        innerinfo.put(\"infoAddr\", node.getInfoAddr());\n        innerinfo.put(\"infoSecureAddr\", node.getInfoSecureAddr());\n        innerinfo.put(\"xferaddr\", node.getXferAddr());\n        innerinfo.put(\"location\", node.getNetworkLocation());\n        innerinfo.put(\"lastContact\", getLastContact(node));\n        innerinfo.put(\"usedSpace\", node.getDfsUsed());\n        innerinfo.put(\"adminState\", node.getAdminState().toString());\n        innerinfo.put(\"nonDfsUsedSpace\", node.getNonDfsUsed());\n        innerinfo.put(\"capacity\", node.getCapacity());\n        innerinfo.put(\"numBlocks\", -1); // node.numBlocks()\n        innerinfo.put(\"version\", (node.getSoftwareVersion() \u003d\u003d null ?\n                        \"UNKNOWN\" : node.getSoftwareVersion()));\n        innerinfo.put(\"used\", node.getDfsUsed());\n        innerinfo.put(\"remaining\", node.getRemaining());\n        innerinfo.put(\"blockScheduled\", -1); // node.getBlocksScheduled()\n        innerinfo.put(\"blockPoolUsed\", node.getBlockPoolUsed());\n        innerinfo.put(\"blockPoolUsedPercent\", node.getBlockPoolUsedPercent());\n        innerinfo.put(\"volfails\", -1); // node.getVolumeFailures()\n        info.put(node.getHostName() + \":\" + node.getXferPort(),\n            Collections.unmodifiableMap(innerinfo));\n      }\n    } catch (StandbyException e) {\n      LOG.error(\"Cannot get {} nodes, Router in safe mode\", type);\n    } catch (IOException e) {\n      LOG.error(\"Cannot get \" + type + \" nodes\", e);\n    }\n    return JSON.toString(info);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/NamenodeBeanMetrics.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/NamenodeBeanMetrics.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/NamenodeBeanMetrics.java"
      }
    },
    "bc9e588a19c0aaf518de8dab719362be4a8d6a54": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-12335. Federation Metrics. Contributed by Inigo Goiri.\n\n(cherry picked from commit 3b19e77752afce87936f5c0d1e6d272fba798d7b)\n",
      "commitDate": "06/10/17 6:50 PM",
      "commitName": "bc9e588a19c0aaf518de8dab719362be4a8d6a54",
      "commitAuthor": "Inigo Goiri",
      "diff": "@@ -0,0 +1,35 @@\n+  private String getNodes(DatanodeReportType type) {\n+    final Map\u003cString, Map\u003cString, Object\u003e\u003e info \u003d new HashMap\u003c\u003e();\n+    try {\n+      RouterRpcServer rpcServer \u003d this.router.getRpcServer();\n+      DatanodeInfo[] datanodes \u003d rpcServer.getDatanodeReport(type);\n+      for (DatanodeInfo node : datanodes) {\n+        Map\u003cString, Object\u003e innerinfo \u003d new HashMap\u003c\u003e();\n+        innerinfo.put(\"infoAddr\", node.getInfoAddr());\n+        innerinfo.put(\"infoSecureAddr\", node.getInfoSecureAddr());\n+        innerinfo.put(\"xferaddr\", node.getXferAddr());\n+        innerinfo.put(\"location\", node.getNetworkLocation());\n+        innerinfo.put(\"lastContact\", getLastContact(node));\n+        innerinfo.put(\"usedSpace\", node.getDfsUsed());\n+        innerinfo.put(\"adminState\", node.getAdminState().toString());\n+        innerinfo.put(\"nonDfsUsedSpace\", node.getNonDfsUsed());\n+        innerinfo.put(\"capacity\", node.getCapacity());\n+        innerinfo.put(\"numBlocks\", -1); // node.numBlocks()\n+        innerinfo.put(\"version\", (node.getSoftwareVersion() \u003d\u003d null ?\n+                        \"UNKNOWN\" : node.getSoftwareVersion()));\n+        innerinfo.put(\"used\", node.getDfsUsed());\n+        innerinfo.put(\"remaining\", node.getRemaining());\n+        innerinfo.put(\"blockScheduled\", -1); // node.getBlocksScheduled()\n+        innerinfo.put(\"blockPoolUsed\", node.getBlockPoolUsed());\n+        innerinfo.put(\"blockPoolUsedPercent\", node.getBlockPoolUsedPercent());\n+        innerinfo.put(\"volfails\", -1); // node.getVolumeFailures()\n+        info.put(node.getHostName() + \":\" + node.getXferPort(),\n+            Collections.unmodifiableMap(innerinfo));\n+      }\n+    } catch (StandbyException e) {\n+      LOG.error(\"Cannot get {} nodes, Router in safe mode\", type);\n+    } catch (IOException e) {\n+      LOG.error(\"Cannot get \" + type + \" nodes\", e);\n+    }\n+    return JSON.toString(info);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private String getNodes(DatanodeReportType type) {\n    final Map\u003cString, Map\u003cString, Object\u003e\u003e info \u003d new HashMap\u003c\u003e();\n    try {\n      RouterRpcServer rpcServer \u003d this.router.getRpcServer();\n      DatanodeInfo[] datanodes \u003d rpcServer.getDatanodeReport(type);\n      for (DatanodeInfo node : datanodes) {\n        Map\u003cString, Object\u003e innerinfo \u003d new HashMap\u003c\u003e();\n        innerinfo.put(\"infoAddr\", node.getInfoAddr());\n        innerinfo.put(\"infoSecureAddr\", node.getInfoSecureAddr());\n        innerinfo.put(\"xferaddr\", node.getXferAddr());\n        innerinfo.put(\"location\", node.getNetworkLocation());\n        innerinfo.put(\"lastContact\", getLastContact(node));\n        innerinfo.put(\"usedSpace\", node.getDfsUsed());\n        innerinfo.put(\"adminState\", node.getAdminState().toString());\n        innerinfo.put(\"nonDfsUsedSpace\", node.getNonDfsUsed());\n        innerinfo.put(\"capacity\", node.getCapacity());\n        innerinfo.put(\"numBlocks\", -1); // node.numBlocks()\n        innerinfo.put(\"version\", (node.getSoftwareVersion() \u003d\u003d null ?\n                        \"UNKNOWN\" : node.getSoftwareVersion()));\n        innerinfo.put(\"used\", node.getDfsUsed());\n        innerinfo.put(\"remaining\", node.getRemaining());\n        innerinfo.put(\"blockScheduled\", -1); // node.getBlocksScheduled()\n        innerinfo.put(\"blockPoolUsed\", node.getBlockPoolUsed());\n        innerinfo.put(\"blockPoolUsedPercent\", node.getBlockPoolUsedPercent());\n        innerinfo.put(\"volfails\", -1); // node.getVolumeFailures()\n        info.put(node.getHostName() + \":\" + node.getXferPort(),\n            Collections.unmodifiableMap(innerinfo));\n      }\n    } catch (StandbyException e) {\n      LOG.error(\"Cannot get {} nodes, Router in safe mode\", type);\n    } catch (IOException e) {\n      LOG.error(\"Cannot get \" + type + \" nodes\", e);\n    }\n    return JSON.toString(info);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/metrics/NamenodeBeanMetrics.java"
    }
  }
}