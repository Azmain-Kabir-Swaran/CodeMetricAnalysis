{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "ByteRangeInputStream.java",
  "functionName": "getInputStream",
  "functionId": "getInputStream",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/ByteRangeInputStream.java",
  "functionStartLine": 110,
  "functionEndLine": 127,
  "numCommitsSeen": 23,
  "timeTaken": 5371,
  "changeHistory": [
    "e91ccfad07ec5b5674a84009772dd31a82b4e4de",
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
    "68a79b0d3f189dfdbd3a3e2a0b906627db3eff8d",
    "920b8fac187de859307ae960b7abd456e23d87e6",
    "f86352c2dff7e75314a8fc08c32f4a37c098cc62",
    "6afe3e0d22caa2b0752d52ddf7794c25a66cc9c8",
    "0bd8f0bd40bb6a497dfa7ebf823a52d67624e8ce",
    "50cb2771e924d2d6d9d04e588cb0a94aefb25b70",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
    "d86f3183d93714ba078416af4f609d26376eadb0",
    "7663caab5a2371a9fe36e26fd70438e64e31810c",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc"
  ],
  "changeHistoryShort": {
    "e91ccfad07ec5b5674a84009772dd31a82b4e4de": "Ybodychange",
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": "Yfilerename",
    "68a79b0d3f189dfdbd3a3e2a0b906627db3eff8d": "Yfilerename",
    "920b8fac187de859307ae960b7abd456e23d87e6": "Ymultichange(Ymodifierchange,Ybodychange)",
    "f86352c2dff7e75314a8fc08c32f4a37c098cc62": "Ybodychange",
    "6afe3e0d22caa2b0752d52ddf7794c25a66cc9c8": "Ybodychange",
    "0bd8f0bd40bb6a497dfa7ebf823a52d67624e8ce": "Ybodychange",
    "50cb2771e924d2d6d9d04e588cb0a94aefb25b70": "Ybodychange",
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": "Yfilerename",
    "d86f3183d93714ba078416af4f609d26376eadb0": "Yfilerename",
    "7663caab5a2371a9fe36e26fd70438e64e31810c": "Ybodychange",
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": "Yintroduced"
  },
  "changeHistoryDetails": {
    "e91ccfad07ec5b5674a84009772dd31a82b4e4de": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8797. WebHdfsFileSystem creates too many connections for pread. Contributed by Jing Zhao.\n",
      "commitDate": "22/07/15 5:42 PM",
      "commitName": "e91ccfad07ec5b5674a84009772dd31a82b4e4de",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "23/04/15 5:33 PM",
      "commitNameOld": "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 90.01,
      "commitsBetweenForRepo": 732,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,16 +1,18 @@\n   protected InputStream getInputStream() throws IOException {\n     switch (status) {\n       case NORMAL:\n         break;\n       case SEEK:\n         if (in !\u003d null) {\n           in.close();\n         }\n-        in \u003d openInputStream();\n+        InputStreamAndFileLength fin \u003d openInputStream(startPos);\n+        in \u003d fin.in;\n+        fileLength \u003d fin.length;\n         status \u003d StreamStatus.NORMAL;\n         break;\n       case CLOSED:\n         throw new IOException(\"Stream closed\");\n     }\n     return in;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected InputStream getInputStream() throws IOException {\n    switch (status) {\n      case NORMAL:\n        break;\n      case SEEK:\n        if (in !\u003d null) {\n          in.close();\n        }\n        InputStreamAndFileLength fin \u003d openInputStream(startPos);\n        in \u003d fin.in;\n        fileLength \u003d fin.length;\n        status \u003d StreamStatus.NORMAL;\n        break;\n      case CLOSED:\n        throw new IOException(\"Stream closed\");\n    }\n    return in;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/ByteRangeInputStream.java",
      "extendedDetails": {}
    },
    "bcf89ddc7d52e04725caf104f5958e33d9f51b35": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-8052. Move WebHdfsFileSystem into hadoop-hdfs-client. Contributed by Haohui Mai.\n",
      "commitDate": "23/04/15 5:33 PM",
      "commitName": "bcf89ddc7d52e04725caf104f5958e33d9f51b35",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "23/04/15 4:40 PM",
      "commitNameOld": "0b3f8957a87ada1a275c9904b211fdbdcefafb02",
      "commitAuthorOld": "Xuan",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected InputStream getInputStream() throws IOException {\n    switch (status) {\n      case NORMAL:\n        break;\n      case SEEK:\n        if (in !\u003d null) {\n          in.close();\n        }\n        in \u003d openInputStream();\n        status \u003d StreamStatus.NORMAL;\n        break;\n      case CLOSED:\n        throw new IOException(\"Stream closed\");\n    }\n    return in;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/ByteRangeInputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/ByteRangeInputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/web/ByteRangeInputStream.java"
      }
    },
    "68a79b0d3f189dfdbd3a3e2a0b906627db3eff8d": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-5436. Move HsFtpFileSystem and HFtpFileSystem into org.apache.hdfs.web. (Contributed by Haohui Mai)\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1536921 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "29/10/13 3:44 PM",
      "commitName": "68a79b0d3f189dfdbd3a3e2a0b906627db3eff8d",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "29/10/13 2:11 PM",
      "commitNameOld": "7dd201c541c811069a898403cf28a50152a38737",
      "commitAuthorOld": "Bikas Saha",
      "daysBetweenCommits": 0.06,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  protected InputStream getInputStream() throws IOException {\n    switch (status) {\n      case NORMAL:\n        break;\n      case SEEK:\n        if (in !\u003d null) {\n          in.close();\n        }\n        in \u003d openInputStream();\n        status \u003d StreamStatus.NORMAL;\n        break;\n      case CLOSED:\n        throw new IOException(\"Stream closed\");\n    }\n    return in;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/ByteRangeInputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/ByteRangeInputStream.java"
      }
    },
    "920b8fac187de859307ae960b7abd456e23d87e6": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HDFS-3334. Fix ByteRangeInputStream stream leakage.  Contributed by Daryn Sharp\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1331570 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "27/04/12 1:13 PM",
      "commitName": "920b8fac187de859307ae960b7abd456e23d87e6",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-3334. Fix ByteRangeInputStream stream leakage.  Contributed by Daryn Sharp\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1331570 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/04/12 1:13 PM",
          "commitName": "920b8fac187de859307ae960b7abd456e23d87e6",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "25/04/12 12:24 PM",
          "commitNameOld": "f86352c2dff7e75314a8fc08c32f4a37c098cc62",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 2.03,
          "commitsBetweenForRepo": 16,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,16 @@\n-  private InputStream getInputStream() throws IOException {\n-    if (status !\u003d StreamStatus.NORMAL) {\n-      \n-      if (in !\u003d null) {\n-        in.close();\n-        in \u003d null;\n-      }\n-      \n-      // Use the original url if no resolved url exists, eg. if\n-      // it\u0027s the first time a request is made.\n-      final URLOpener opener \u003d\n-        (resolvedURL.getURL() \u003d\u003d null) ? originalURL : resolvedURL;\n-\n-      final HttpURLConnection connection \u003d opener.openConnection(startPos);\n-      connection.connect();\n-      checkResponseCode(connection);\n-\n-      final String cl \u003d connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n-      if (cl \u003d\u003d null) {\n-        throw new IOException(StreamFile.CONTENT_LENGTH+\" header is missing\");\n-      }\n-      final long streamlength \u003d Long.parseLong(cl);\n-      filelength \u003d startPos + streamlength;\n-      // Java has a bug with \u003e2GB request streams.  It won\u0027t bounds check\n-      // the reads so the transfer blocks until the server times out\n-      in \u003d new BoundedInputStream(connection.getInputStream(), streamlength);\n-\n-      resolvedURL.setURL(getResolvedUrl(connection));\n-      status \u003d StreamStatus.NORMAL;\n+  protected InputStream getInputStream() throws IOException {\n+    switch (status) {\n+      case NORMAL:\n+        break;\n+      case SEEK:\n+        if (in !\u003d null) {\n+          in.close();\n+        }\n+        in \u003d openInputStream();\n+        status \u003d StreamStatus.NORMAL;\n+        break;\n+      case CLOSED:\n+        throw new IOException(\"Stream closed\");\n     }\n-    \n     return in;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected InputStream getInputStream() throws IOException {\n    switch (status) {\n      case NORMAL:\n        break;\n      case SEEK:\n        if (in !\u003d null) {\n          in.close();\n        }\n        in \u003d openInputStream();\n        status \u003d StreamStatus.NORMAL;\n        break;\n      case CLOSED:\n        throw new IOException(\"Stream closed\");\n    }\n    return in;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java",
          "extendedDetails": {
            "oldValue": "[private]",
            "newValue": "[protected]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3334. Fix ByteRangeInputStream stream leakage.  Contributed by Daryn Sharp\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1331570 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "27/04/12 1:13 PM",
          "commitName": "920b8fac187de859307ae960b7abd456e23d87e6",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "25/04/12 12:24 PM",
          "commitNameOld": "f86352c2dff7e75314a8fc08c32f4a37c098cc62",
          "commitAuthorOld": "Tsz-wo Sze",
          "daysBetweenCommits": 2.03,
          "commitsBetweenForRepo": 16,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,33 +1,16 @@\n-  private InputStream getInputStream() throws IOException {\n-    if (status !\u003d StreamStatus.NORMAL) {\n-      \n-      if (in !\u003d null) {\n-        in.close();\n-        in \u003d null;\n-      }\n-      \n-      // Use the original url if no resolved url exists, eg. if\n-      // it\u0027s the first time a request is made.\n-      final URLOpener opener \u003d\n-        (resolvedURL.getURL() \u003d\u003d null) ? originalURL : resolvedURL;\n-\n-      final HttpURLConnection connection \u003d opener.openConnection(startPos);\n-      connection.connect();\n-      checkResponseCode(connection);\n-\n-      final String cl \u003d connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n-      if (cl \u003d\u003d null) {\n-        throw new IOException(StreamFile.CONTENT_LENGTH+\" header is missing\");\n-      }\n-      final long streamlength \u003d Long.parseLong(cl);\n-      filelength \u003d startPos + streamlength;\n-      // Java has a bug with \u003e2GB request streams.  It won\u0027t bounds check\n-      // the reads so the transfer blocks until the server times out\n-      in \u003d new BoundedInputStream(connection.getInputStream(), streamlength);\n-\n-      resolvedURL.setURL(getResolvedUrl(connection));\n-      status \u003d StreamStatus.NORMAL;\n+  protected InputStream getInputStream() throws IOException {\n+    switch (status) {\n+      case NORMAL:\n+        break;\n+      case SEEK:\n+        if (in !\u003d null) {\n+          in.close();\n+        }\n+        in \u003d openInputStream();\n+        status \u003d StreamStatus.NORMAL;\n+        break;\n+      case CLOSED:\n+        throw new IOException(\"Stream closed\");\n     }\n-    \n     return in;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected InputStream getInputStream() throws IOException {\n    switch (status) {\n      case NORMAL:\n        break;\n      case SEEK:\n        if (in !\u003d null) {\n          in.close();\n        }\n        in \u003d openInputStream();\n        status \u003d StreamStatus.NORMAL;\n        break;\n      case CLOSED:\n        throw new IOException(\"Stream closed\");\n    }\n    return in;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "f86352c2dff7e75314a8fc08c32f4a37c098cc62": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-3318. Use BoundedInputStream in ByteRangeInputStream, otherwise, it hangs on transfers \u003e2 GB.  Contributed by Daryn Sharp \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1330500 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "25/04/12 12:24 PM",
      "commitName": "f86352c2dff7e75314a8fc08c32f4a37c098cc62",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "03/11/11 3:34 PM",
      "commitNameOld": "6afe3e0d22caa2b0752d52ddf7794c25a66cc9c8",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 173.87,
      "commitsBetweenForRepo": 1188,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,27 +1,33 @@\n   private InputStream getInputStream() throws IOException {\n     if (status !\u003d StreamStatus.NORMAL) {\n       \n       if (in !\u003d null) {\n         in.close();\n         in \u003d null;\n       }\n       \n       // Use the original url if no resolved url exists, eg. if\n       // it\u0027s the first time a request is made.\n       final URLOpener opener \u003d\n         (resolvedURL.getURL() \u003d\u003d null) ? originalURL : resolvedURL;\n \n       final HttpURLConnection connection \u003d opener.openConnection(startPos);\n       connection.connect();\n       checkResponseCode(connection);\n \n       final String cl \u003d connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n-      filelength \u003d (cl \u003d\u003d null) ? -1 : Long.parseLong(cl);\n-      in \u003d connection.getInputStream();\n+      if (cl \u003d\u003d null) {\n+        throw new IOException(StreamFile.CONTENT_LENGTH+\" header is missing\");\n+      }\n+      final long streamlength \u003d Long.parseLong(cl);\n+      filelength \u003d startPos + streamlength;\n+      // Java has a bug with \u003e2GB request streams.  It won\u0027t bounds check\n+      // the reads so the transfer blocks until the server times out\n+      in \u003d new BoundedInputStream(connection.getInputStream(), streamlength);\n \n       resolvedURL.setURL(getResolvedUrl(connection));\n       status \u003d StreamStatus.NORMAL;\n     }\n     \n     return in;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private InputStream getInputStream() throws IOException {\n    if (status !\u003d StreamStatus.NORMAL) {\n      \n      if (in !\u003d null) {\n        in.close();\n        in \u003d null;\n      }\n      \n      // Use the original url if no resolved url exists, eg. if\n      // it\u0027s the first time a request is made.\n      final URLOpener opener \u003d\n        (resolvedURL.getURL() \u003d\u003d null) ? originalURL : resolvedURL;\n\n      final HttpURLConnection connection \u003d opener.openConnection(startPos);\n      connection.connect();\n      checkResponseCode(connection);\n\n      final String cl \u003d connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n      if (cl \u003d\u003d null) {\n        throw new IOException(StreamFile.CONTENT_LENGTH+\" header is missing\");\n      }\n      final long streamlength \u003d Long.parseLong(cl);\n      filelength \u003d startPos + streamlength;\n      // Java has a bug with \u003e2GB request streams.  It won\u0027t bounds check\n      // the reads so the transfer blocks until the server times out\n      in \u003d new BoundedInputStream(connection.getInputStream(), streamlength);\n\n      resolvedURL.setURL(getResolvedUrl(connection));\n      status \u003d StreamStatus.NORMAL;\n    }\n    \n    return in;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java",
      "extendedDetails": {}
    },
    "6afe3e0d22caa2b0752d52ddf7794c25a66cc9c8": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2527. WebHdfs: remove the use of \"Range\" header in Open; use ugi username if renewer parameter is null in GetDelegationToken; response OK when setting replication for non-files; rename GETFILEBLOCKLOCATIONS to GET_BLOCK_LOCATIONS and state that it is a private unstable API; replace isDirectory and isSymlink with enum {FILE, DIRECTORY, SYMLINK} in HdfsFileStatus JSON object. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1197329 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "03/11/11 3:34 PM",
      "commitName": "6afe3e0d22caa2b0752d52ddf7794c25a66cc9c8",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "01/11/11 7:08 PM",
      "commitNameOld": "bd21ddcb78350b311f271e233038b8ca78a65242",
      "commitAuthorOld": "Jitendra Nath Pandey",
      "daysBetweenCommits": 1.85,
      "commitsBetweenForRepo": 14,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,45 +1,27 @@\n   private InputStream getInputStream() throws IOException {\n     if (status !\u003d StreamStatus.NORMAL) {\n       \n       if (in !\u003d null) {\n         in.close();\n         in \u003d null;\n       }\n       \n       // Use the original url if no resolved url exists, eg. if\n       // it\u0027s the first time a request is made.\n       final URLOpener opener \u003d\n         (resolvedURL.getURL() \u003d\u003d null) ? originalURL : resolvedURL;\n \n       final HttpURLConnection connection \u003d opener.openConnection(startPos);\n-      try {\n-        connection.connect();\n-        final String cl \u003d connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n-        filelength \u003d (cl \u003d\u003d null) ? -1 : Long.parseLong(cl);\n-        if (HftpFileSystem.LOG.isDebugEnabled()) {\n-          HftpFileSystem.LOG.debug(\"filelength \u003d \" + filelength);\n-        }\n-        in \u003d connection.getInputStream();\n-      } catch (FileNotFoundException fnfe) {\n-        throw fnfe;\n-      } catch (IOException ioe) {\n-        HftpFileSystem.throwIOExceptionFromConnection(connection, ioe);\n-      }\n-      \n-      int respCode \u003d connection.getResponseCode();\n-      if (startPos !\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_PARTIAL) {\n-        // We asked for a byte range but did not receive a partial content\n-        // response...\n-        throw new IOException(\"HTTP_PARTIAL expected, received \" + respCode);\n-      } else if (startPos \u003d\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_OK) {\n-        // We asked for all bytes from the beginning but didn\u0027t receive a 200\n-        // response (none of the other 2xx codes are valid here)\n-        throw new IOException(\"HTTP_OK expected, received \" + respCode);\n-      }\n+      connection.connect();\n+      checkResponseCode(connection);\n \n-      resolvedURL.setURL(removeOffsetParam(connection.getURL()));\n+      final String cl \u003d connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n+      filelength \u003d (cl \u003d\u003d null) ? -1 : Long.parseLong(cl);\n+      in \u003d connection.getInputStream();\n+\n+      resolvedURL.setURL(getResolvedUrl(connection));\n       status \u003d StreamStatus.NORMAL;\n     }\n     \n     return in;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private InputStream getInputStream() throws IOException {\n    if (status !\u003d StreamStatus.NORMAL) {\n      \n      if (in !\u003d null) {\n        in.close();\n        in \u003d null;\n      }\n      \n      // Use the original url if no resolved url exists, eg. if\n      // it\u0027s the first time a request is made.\n      final URLOpener opener \u003d\n        (resolvedURL.getURL() \u003d\u003d null) ? originalURL : resolvedURL;\n\n      final HttpURLConnection connection \u003d opener.openConnection(startPos);\n      connection.connect();\n      checkResponseCode(connection);\n\n      final String cl \u003d connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n      filelength \u003d (cl \u003d\u003d null) ? -1 : Long.parseLong(cl);\n      in \u003d connection.getInputStream();\n\n      resolvedURL.setURL(getResolvedUrl(connection));\n      status \u003d StreamStatus.NORMAL;\n    }\n    \n    return in;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java",
      "extendedDetails": {}
    },
    "0bd8f0bd40bb6a497dfa7ebf823a52d67624e8ce": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2453. Fix http response code for partial content in webhdfs, added getDefaultBlockSize() and getDefaultReplication() in WebHdfsFileSystem and cleared content type in ExceptionHandler. \n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1186508 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/10/11 2:38 PM",
      "commitName": "0bd8f0bd40bb6a497dfa7ebf823a52d67624e8ce",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "14/10/11 4:25 PM",
      "commitNameOld": "50cb2771e924d2d6d9d04e588cb0a94aefb25b70",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 4.93,
      "commitsBetweenForRepo": 29,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,49 +1,45 @@\n   private InputStream getInputStream() throws IOException {\n     if (status !\u003d StreamStatus.NORMAL) {\n       \n       if (in !\u003d null) {\n         in.close();\n         in \u003d null;\n       }\n       \n       // Use the original url if no resolved url exists, eg. if\n       // it\u0027s the first time a request is made.\n       final URLOpener opener \u003d\n         (resolvedURL.getURL() \u003d\u003d null) ? originalURL : resolvedURL;\n \n-      final HttpURLConnection connection \u003d opener.openConnection();\n+      final HttpURLConnection connection \u003d opener.openConnection(startPos);\n       try {\n-        connection.setRequestMethod(\"GET\");\n-        if (startPos !\u003d 0) {\n-          connection.setRequestProperty(\"Range\", \"bytes\u003d\"+startPos+\"-\");\n-        }\n         connection.connect();\n         final String cl \u003d connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n         filelength \u003d (cl \u003d\u003d null) ? -1 : Long.parseLong(cl);\n         if (HftpFileSystem.LOG.isDebugEnabled()) {\n           HftpFileSystem.LOG.debug(\"filelength \u003d \" + filelength);\n         }\n         in \u003d connection.getInputStream();\n       } catch (FileNotFoundException fnfe) {\n         throw fnfe;\n       } catch (IOException ioe) {\n         HftpFileSystem.throwIOExceptionFromConnection(connection, ioe);\n       }\n       \n       int respCode \u003d connection.getResponseCode();\n       if (startPos !\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_PARTIAL) {\n         // We asked for a byte range but did not receive a partial content\n         // response...\n         throw new IOException(\"HTTP_PARTIAL expected, received \" + respCode);\n       } else if (startPos \u003d\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_OK) {\n         // We asked for all bytes from the beginning but didn\u0027t receive a 200\n         // response (none of the other 2xx codes are valid here)\n         throw new IOException(\"HTTP_OK expected, received \" + respCode);\n       }\n \n-      resolvedURL.setURL(connection.getURL());\n+      resolvedURL.setURL(removeOffsetParam(connection.getURL()));\n       status \u003d StreamStatus.NORMAL;\n     }\n     \n     return in;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private InputStream getInputStream() throws IOException {\n    if (status !\u003d StreamStatus.NORMAL) {\n      \n      if (in !\u003d null) {\n        in.close();\n        in \u003d null;\n      }\n      \n      // Use the original url if no resolved url exists, eg. if\n      // it\u0027s the first time a request is made.\n      final URLOpener opener \u003d\n        (resolvedURL.getURL() \u003d\u003d null) ? originalURL : resolvedURL;\n\n      final HttpURLConnection connection \u003d opener.openConnection(startPos);\n      try {\n        connection.connect();\n        final String cl \u003d connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n        filelength \u003d (cl \u003d\u003d null) ? -1 : Long.parseLong(cl);\n        if (HftpFileSystem.LOG.isDebugEnabled()) {\n          HftpFileSystem.LOG.debug(\"filelength \u003d \" + filelength);\n        }\n        in \u003d connection.getInputStream();\n      } catch (FileNotFoundException fnfe) {\n        throw fnfe;\n      } catch (IOException ioe) {\n        HftpFileSystem.throwIOExceptionFromConnection(connection, ioe);\n      }\n      \n      int respCode \u003d connection.getResponseCode();\n      if (startPos !\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_PARTIAL) {\n        // We asked for a byte range but did not receive a partial content\n        // response...\n        throw new IOException(\"HTTP_PARTIAL expected, received \" + respCode);\n      } else if (startPos \u003d\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_OK) {\n        // We asked for all bytes from the beginning but didn\u0027t receive a 200\n        // response (none of the other 2xx codes are valid here)\n        throw new IOException(\"HTTP_OK expected, received \" + respCode);\n      }\n\n      resolvedURL.setURL(removeOffsetParam(connection.getURL()));\n      status \u003d StreamStatus.NORMAL;\n    }\n    \n    return in;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java",
      "extendedDetails": {}
    },
    "50cb2771e924d2d6d9d04e588cb0a94aefb25b70": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2439. Fix NullPointerException in webhdfs when opening a non-existing file or creating a file without specifying the replication parameter.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1183554 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "14/10/11 4:25 PM",
      "commitName": "50cb2771e924d2d6d9d04e588cb0a94aefb25b70",
      "commitAuthor": "Tsz-wo Sze",
      "commitDateOld": "13/09/11 1:34 AM",
      "commitNameOld": "6c3b59505b863f03629da52a1e9b886fe9b496d0",
      "commitAuthorOld": "Tsz-wo Sze",
      "daysBetweenCommits": 31.62,
      "commitsBetweenForRepo": 239,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,49 @@\n   private InputStream getInputStream() throws IOException {\n     if (status !\u003d StreamStatus.NORMAL) {\n       \n       if (in !\u003d null) {\n         in.close();\n         in \u003d null;\n       }\n       \n       // Use the original url if no resolved url exists, eg. if\n       // it\u0027s the first time a request is made.\n       final URLOpener opener \u003d\n         (resolvedURL.getURL() \u003d\u003d null) ? originalURL : resolvedURL;\n \n       final HttpURLConnection connection \u003d opener.openConnection();\n       try {\n         connection.setRequestMethod(\"GET\");\n         if (startPos !\u003d 0) {\n           connection.setRequestProperty(\"Range\", \"bytes\u003d\"+startPos+\"-\");\n         }\n         connection.connect();\n         final String cl \u003d connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n         filelength \u003d (cl \u003d\u003d null) ? -1 : Long.parseLong(cl);\n         if (HftpFileSystem.LOG.isDebugEnabled()) {\n           HftpFileSystem.LOG.debug(\"filelength \u003d \" + filelength);\n         }\n         in \u003d connection.getInputStream();\n+      } catch (FileNotFoundException fnfe) {\n+        throw fnfe;\n       } catch (IOException ioe) {\n         HftpFileSystem.throwIOExceptionFromConnection(connection, ioe);\n       }\n       \n       int respCode \u003d connection.getResponseCode();\n       if (startPos !\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_PARTIAL) {\n         // We asked for a byte range but did not receive a partial content\n         // response...\n         throw new IOException(\"HTTP_PARTIAL expected, received \" + respCode);\n       } else if (startPos \u003d\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_OK) {\n         // We asked for all bytes from the beginning but didn\u0027t receive a 200\n         // response (none of the other 2xx codes are valid here)\n         throw new IOException(\"HTTP_OK expected, received \" + respCode);\n       }\n \n       resolvedURL.setURL(connection.getURL());\n       status \u003d StreamStatus.NORMAL;\n     }\n     \n     return in;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private InputStream getInputStream() throws IOException {\n    if (status !\u003d StreamStatus.NORMAL) {\n      \n      if (in !\u003d null) {\n        in.close();\n        in \u003d null;\n      }\n      \n      // Use the original url if no resolved url exists, eg. if\n      // it\u0027s the first time a request is made.\n      final URLOpener opener \u003d\n        (resolvedURL.getURL() \u003d\u003d null) ? originalURL : resolvedURL;\n\n      final HttpURLConnection connection \u003d opener.openConnection();\n      try {\n        connection.setRequestMethod(\"GET\");\n        if (startPos !\u003d 0) {\n          connection.setRequestProperty(\"Range\", \"bytes\u003d\"+startPos+\"-\");\n        }\n        connection.connect();\n        final String cl \u003d connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n        filelength \u003d (cl \u003d\u003d null) ? -1 : Long.parseLong(cl);\n        if (HftpFileSystem.LOG.isDebugEnabled()) {\n          HftpFileSystem.LOG.debug(\"filelength \u003d \" + filelength);\n        }\n        in \u003d connection.getInputStream();\n      } catch (FileNotFoundException fnfe) {\n        throw fnfe;\n      } catch (IOException ioe) {\n        HftpFileSystem.throwIOExceptionFromConnection(connection, ioe);\n      }\n      \n      int respCode \u003d connection.getResponseCode();\n      if (startPos !\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_PARTIAL) {\n        // We asked for a byte range but did not receive a partial content\n        // response...\n        throw new IOException(\"HTTP_PARTIAL expected, received \" + respCode);\n      } else if (startPos \u003d\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_OK) {\n        // We asked for all bytes from the beginning but didn\u0027t receive a 200\n        // response (none of the other 2xx codes are valid here)\n        throw new IOException(\"HTTP_OK expected, received \" + respCode);\n      }\n\n      resolvedURL.setURL(connection.getURL());\n      status \u003d StreamStatus.NORMAL;\n    }\n    \n    return in;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java",
      "extendedDetails": {}
    },
    "cd7157784e5e5ddc4e77144d042e54dd0d04bac1": {
      "type": "Yfilerename",
      "commitMessage": "HADOOP-7560. Change src layout to be heirarchical. Contributed by Alejandro Abdelnur.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1161332 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/08/11 5:14 PM",
      "commitName": "cd7157784e5e5ddc4e77144d042e54dd0d04bac1",
      "commitAuthor": "Arun Murthy",
      "commitDateOld": "24/08/11 5:06 PM",
      "commitNameOld": "bb0005cfec5fd2861600ff5babd259b48ba18b63",
      "commitAuthorOld": "Arun Murthy",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private InputStream getInputStream() throws IOException {\n    if (status !\u003d StreamStatus.NORMAL) {\n      \n      if (in !\u003d null) {\n        in.close();\n        in \u003d null;\n      }\n      \n      // Use the original url if no resolved url exists, eg. if\n      // it\u0027s the first time a request is made.\n      final URLOpener opener \u003d\n        (resolvedURL.getURL() \u003d\u003d null) ? originalURL : resolvedURL;\n\n      final HttpURLConnection connection \u003d opener.openConnection();\n      try {\n        connection.setRequestMethod(\"GET\");\n        if (startPos !\u003d 0) {\n          connection.setRequestProperty(\"Range\", \"bytes\u003d\"+startPos+\"-\");\n        }\n        connection.connect();\n        final String cl \u003d connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n        filelength \u003d (cl \u003d\u003d null) ? -1 : Long.parseLong(cl);\n        if (HftpFileSystem.LOG.isDebugEnabled()) {\n          HftpFileSystem.LOG.debug(\"filelength \u003d \" + filelength);\n        }\n        in \u003d connection.getInputStream();\n      } catch (IOException ioe) {\n        HftpFileSystem.throwIOExceptionFromConnection(connection, ioe);\n      }\n      \n      int respCode \u003d connection.getResponseCode();\n      if (startPos !\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_PARTIAL) {\n        // We asked for a byte range but did not receive a partial content\n        // response...\n        throw new IOException(\"HTTP_PARTIAL expected, received \" + respCode);\n      } else if (startPos \u003d\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_OK) {\n        // We asked for all bytes from the beginning but didn\u0027t receive a 200\n        // response (none of the other 2xx codes are valid here)\n        throw new IOException(\"HTTP_OK expected, received \" + respCode);\n      }\n\n      resolvedURL.setURL(connection.getURL());\n      status \u003d StreamStatus.NORMAL;\n    }\n    \n    return in;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java"
      }
    },
    "d86f3183d93714ba078416af4f609d26376eadb0": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-2096. Mavenization of hadoop-hdfs. Contributed by Alejandro Abdelnur.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1159702 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/08/11 10:36 AM",
      "commitName": "d86f3183d93714ba078416af4f609d26376eadb0",
      "commitAuthor": "Thomas White",
      "commitDateOld": "19/08/11 10:26 AM",
      "commitNameOld": "6ee5a73e0e91a2ef27753a32c576835e951d8119",
      "commitAuthorOld": "Thomas White",
      "daysBetweenCommits": 0.01,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private InputStream getInputStream() throws IOException {\n    if (status !\u003d StreamStatus.NORMAL) {\n      \n      if (in !\u003d null) {\n        in.close();\n        in \u003d null;\n      }\n      \n      // Use the original url if no resolved url exists, eg. if\n      // it\u0027s the first time a request is made.\n      final URLOpener opener \u003d\n        (resolvedURL.getURL() \u003d\u003d null) ? originalURL : resolvedURL;\n\n      final HttpURLConnection connection \u003d opener.openConnection();\n      try {\n        connection.setRequestMethod(\"GET\");\n        if (startPos !\u003d 0) {\n          connection.setRequestProperty(\"Range\", \"bytes\u003d\"+startPos+\"-\");\n        }\n        connection.connect();\n        final String cl \u003d connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n        filelength \u003d (cl \u003d\u003d null) ? -1 : Long.parseLong(cl);\n        if (HftpFileSystem.LOG.isDebugEnabled()) {\n          HftpFileSystem.LOG.debug(\"filelength \u003d \" + filelength);\n        }\n        in \u003d connection.getInputStream();\n      } catch (IOException ioe) {\n        HftpFileSystem.throwIOExceptionFromConnection(connection, ioe);\n      }\n      \n      int respCode \u003d connection.getResponseCode();\n      if (startPos !\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_PARTIAL) {\n        // We asked for a byte range but did not receive a partial content\n        // response...\n        throw new IOException(\"HTTP_PARTIAL expected, received \" + respCode);\n      } else if (startPos \u003d\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_OK) {\n        // We asked for all bytes from the beginning but didn\u0027t receive a 200\n        // response (none of the other 2xx codes are valid here)\n        throw new IOException(\"HTTP_OK expected, received \" + respCode);\n      }\n\n      resolvedURL.setURL(connection.getURL());\n      status \u003d StreamStatus.NORMAL;\n    }\n    \n    return in;\n  }",
      "path": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java",
      "extendedDetails": {
        "oldPath": "hdfs/src/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java",
        "newPath": "hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java"
      }
    },
    "7663caab5a2371a9fe36e26fd70438e64e31810c": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-2110. StreamFile and ByteRangeInputStream cleanup. Contributed by Eli Collins\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1140694 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/06/11 8:59 AM",
      "commitName": "7663caab5a2371a9fe36e26fd70438e64e31810c",
      "commitAuthor": "Eli Collins",
      "commitDateOld": "12/06/11 3:00 PM",
      "commitNameOld": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthorOld": "Todd Lipcon",
      "daysBetweenCommits": 15.75,
      "commitsBetweenForRepo": 50,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,47 +1,47 @@\n   private InputStream getInputStream() throws IOException {\n-    if (status !\u003d STATUS_NORMAL) {\n+    if (status !\u003d StreamStatus.NORMAL) {\n       \n       if (in !\u003d null) {\n         in.close();\n         in \u003d null;\n       }\n       \n-      // use the original url  if no resolved url exists (e.g., if it\u0027s \n-      // the first time a request is made)\n-      final URLOpener o \u003d resolvedURL.getURL() \u003d\u003d null? originalURL: resolvedURL;\n+      // Use the original url if no resolved url exists, eg. if\n+      // it\u0027s the first time a request is made.\n+      final URLOpener opener \u003d\n+        (resolvedURL.getURL() \u003d\u003d null) ? originalURL : resolvedURL;\n \n-      final HttpURLConnection connection \u003d o.openConnection();\n+      final HttpURLConnection connection \u003d opener.openConnection();\n       try {\n         connection.setRequestMethod(\"GET\");\n         if (startPos !\u003d 0) {\n           connection.setRequestProperty(\"Range\", \"bytes\u003d\"+startPos+\"-\");\n         }\n         connection.connect();\n         final String cl \u003d connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n-        filelength \u003d cl \u003d\u003d null? -1: Long.parseLong(cl);\n+        filelength \u003d (cl \u003d\u003d null) ? -1 : Long.parseLong(cl);\n         if (HftpFileSystem.LOG.isDebugEnabled()) {\n           HftpFileSystem.LOG.debug(\"filelength \u003d \" + filelength);\n         }\n         in \u003d connection.getInputStream();\n-      } catch(IOException ioe) {\n+      } catch (IOException ioe) {\n         HftpFileSystem.throwIOExceptionFromConnection(connection, ioe);\n       }\n       \n-      if (startPos !\u003d 0 \u0026\u0026 connection.getResponseCode() !\u003d 206) {\n-        // we asked for a byte range but did not receive a partial content\n+      int respCode \u003d connection.getResponseCode();\n+      if (startPos !\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_PARTIAL) {\n+        // We asked for a byte range but did not receive a partial content\n         // response...\n-        throw new IOException(\"206 expected, but received \"\n-                              + connection.getResponseCode());\n-      } else if(startPos \u003d\u003d 0 \u0026\u0026 connection.getResponseCode() !\u003d 200) {\n-        // we asked for all bytes from the beginning but didn\u0027t receive a 200\n+        throw new IOException(\"HTTP_PARTIAL expected, received \" + respCode);\n+      } else if (startPos \u003d\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_OK) {\n+        // We asked for all bytes from the beginning but didn\u0027t receive a 200\n         // response (none of the other 2xx codes are valid here)\n-        throw new IOException(\"200 expected, but received \"\n-                              + connection.getResponseCode());\n+        throw new IOException(\"HTTP_OK expected, received \" + respCode);\n       }\n-      \n+\n       resolvedURL.setURL(connection.getURL());\n-      status \u003d STATUS_NORMAL;\n+      status \u003d StreamStatus.NORMAL;\n     }\n     \n     return in;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private InputStream getInputStream() throws IOException {\n    if (status !\u003d StreamStatus.NORMAL) {\n      \n      if (in !\u003d null) {\n        in.close();\n        in \u003d null;\n      }\n      \n      // Use the original url if no resolved url exists, eg. if\n      // it\u0027s the first time a request is made.\n      final URLOpener opener \u003d\n        (resolvedURL.getURL() \u003d\u003d null) ? originalURL : resolvedURL;\n\n      final HttpURLConnection connection \u003d opener.openConnection();\n      try {\n        connection.setRequestMethod(\"GET\");\n        if (startPos !\u003d 0) {\n          connection.setRequestProperty(\"Range\", \"bytes\u003d\"+startPos+\"-\");\n        }\n        connection.connect();\n        final String cl \u003d connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n        filelength \u003d (cl \u003d\u003d null) ? -1 : Long.parseLong(cl);\n        if (HftpFileSystem.LOG.isDebugEnabled()) {\n          HftpFileSystem.LOG.debug(\"filelength \u003d \" + filelength);\n        }\n        in \u003d connection.getInputStream();\n      } catch (IOException ioe) {\n        HftpFileSystem.throwIOExceptionFromConnection(connection, ioe);\n      }\n      \n      int respCode \u003d connection.getResponseCode();\n      if (startPos !\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_PARTIAL) {\n        // We asked for a byte range but did not receive a partial content\n        // response...\n        throw new IOException(\"HTTP_PARTIAL expected, received \" + respCode);\n      } else if (startPos \u003d\u003d 0 \u0026\u0026 respCode !\u003d HttpURLConnection.HTTP_OK) {\n        // We asked for all bytes from the beginning but didn\u0027t receive a 200\n        // response (none of the other 2xx codes are valid here)\n        throw new IOException(\"HTTP_OK expected, received \" + respCode);\n      }\n\n      resolvedURL.setURL(connection.getURL());\n      status \u003d StreamStatus.NORMAL;\n    }\n    \n    return in;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java",
      "extendedDetails": {}
    },
    "a196766ea07775f18ded69bd9e8d239f8cfd3ccc": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-7106. Reorganize SVN layout to combine HDFS, Common, and MR in a single tree (project unsplit)\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1134994 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "12/06/11 3:00 PM",
      "commitName": "a196766ea07775f18ded69bd9e8d239f8cfd3ccc",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,47 @@\n+  private InputStream getInputStream() throws IOException {\n+    if (status !\u003d STATUS_NORMAL) {\n+      \n+      if (in !\u003d null) {\n+        in.close();\n+        in \u003d null;\n+      }\n+      \n+      // use the original url  if no resolved url exists (e.g., if it\u0027s \n+      // the first time a request is made)\n+      final URLOpener o \u003d resolvedURL.getURL() \u003d\u003d null? originalURL: resolvedURL;\n+\n+      final HttpURLConnection connection \u003d o.openConnection();\n+      try {\n+        connection.setRequestMethod(\"GET\");\n+        if (startPos !\u003d 0) {\n+          connection.setRequestProperty(\"Range\", \"bytes\u003d\"+startPos+\"-\");\n+        }\n+        connection.connect();\n+        final String cl \u003d connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n+        filelength \u003d cl \u003d\u003d null? -1: Long.parseLong(cl);\n+        if (HftpFileSystem.LOG.isDebugEnabled()) {\n+          HftpFileSystem.LOG.debug(\"filelength \u003d \" + filelength);\n+        }\n+        in \u003d connection.getInputStream();\n+      } catch(IOException ioe) {\n+        HftpFileSystem.throwIOExceptionFromConnection(connection, ioe);\n+      }\n+      \n+      if (startPos !\u003d 0 \u0026\u0026 connection.getResponseCode() !\u003d 206) {\n+        // we asked for a byte range but did not receive a partial content\n+        // response...\n+        throw new IOException(\"206 expected, but received \"\n+                              + connection.getResponseCode());\n+      } else if(startPos \u003d\u003d 0 \u0026\u0026 connection.getResponseCode() !\u003d 200) {\n+        // we asked for all bytes from the beginning but didn\u0027t receive a 200\n+        // response (none of the other 2xx codes are valid here)\n+        throw new IOException(\"200 expected, but received \"\n+                              + connection.getResponseCode());\n+      }\n+      \n+      resolvedURL.setURL(connection.getURL());\n+      status \u003d STATUS_NORMAL;\n+    }\n+    \n+    return in;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private InputStream getInputStream() throws IOException {\n    if (status !\u003d STATUS_NORMAL) {\n      \n      if (in !\u003d null) {\n        in.close();\n        in \u003d null;\n      }\n      \n      // use the original url  if no resolved url exists (e.g., if it\u0027s \n      // the first time a request is made)\n      final URLOpener o \u003d resolvedURL.getURL() \u003d\u003d null? originalURL: resolvedURL;\n\n      final HttpURLConnection connection \u003d o.openConnection();\n      try {\n        connection.setRequestMethod(\"GET\");\n        if (startPos !\u003d 0) {\n          connection.setRequestProperty(\"Range\", \"bytes\u003d\"+startPos+\"-\");\n        }\n        connection.connect();\n        final String cl \u003d connection.getHeaderField(StreamFile.CONTENT_LENGTH);\n        filelength \u003d cl \u003d\u003d null? -1: Long.parseLong(cl);\n        if (HftpFileSystem.LOG.isDebugEnabled()) {\n          HftpFileSystem.LOG.debug(\"filelength \u003d \" + filelength);\n        }\n        in \u003d connection.getInputStream();\n      } catch(IOException ioe) {\n        HftpFileSystem.throwIOExceptionFromConnection(connection, ioe);\n      }\n      \n      if (startPos !\u003d 0 \u0026\u0026 connection.getResponseCode() !\u003d 206) {\n        // we asked for a byte range but did not receive a partial content\n        // response...\n        throw new IOException(\"206 expected, but received \"\n                              + connection.getResponseCode());\n      } else if(startPos \u003d\u003d 0 \u0026\u0026 connection.getResponseCode() !\u003d 200) {\n        // we asked for all bytes from the beginning but didn\u0027t receive a 200\n        // response (none of the other 2xx codes are valid here)\n        throw new IOException(\"200 expected, but received \"\n                              + connection.getResponseCode());\n      }\n      \n      resolvedURL.setURL(connection.getURL());\n      status \u003d STATUS_NORMAL;\n    }\n    \n    return in;\n  }",
      "path": "hdfs/src/java/org/apache/hadoop/hdfs/ByteRangeInputStream.java"
    }
  }
}