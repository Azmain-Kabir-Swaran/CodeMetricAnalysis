{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3ABlockOutputStream.java",
  "functionName": "waitForAllPartUploads",
  "functionId": "waitForAllPartUploads",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
  "functionStartLine": 676,
  "functionEndLine": 693,
  "numCommitsSeen": 18,
  "timeTaken": 2799,
  "changeHistory": [
    "29b19cd59245c8809b697b3d7d7445813a685aad",
    "6c348c56918973fd988b110e79231324a8befe12",
    "c58a59f7081d55dd2108545ebf9ee48cf43ca944",
    "39ec1515a205952eda7e171408a8b83eceb4abde",
    "15b7076ad5f2ae92d231140b2f8cebc392a92c87"
  ],
  "changeHistoryShort": {
    "29b19cd59245c8809b697b3d7d7445813a685aad": "Ybodychange",
    "6c348c56918973fd988b110e79231324a8befe12": "Ymultichange(Ymovefromfile,Ybodychange)",
    "c58a59f7081d55dd2108545ebf9ee48cf43ca944": "Ybodychange",
    "39ec1515a205952eda7e171408a8b83eceb4abde": "Ymultichange(Ymodifierchange,Ybodychange)",
    "15b7076ad5f2ae92d231140b2f8cebc392a92c87": "Yintroduced"
  },
  "changeHistoryDetails": {
    "29b19cd59245c8809b697b3d7d7445813a685aad": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-16900. Very large files can be truncated when written through the S3A FileSystem.\n\nContributed by Mukund Thakur and Steve Loughran.\n\nThis patch ensures that writes to S3A fail when more than 10,000 blocks are\nwritten. That upper bound still exists. To write massive files, make sure\nthat the value of fs.s3a.multipart.size is set to a size which is large\nenough to upload the files in fewer than 10,000 blocks.\n\nChange-Id: Icec604e2a357ffd38d7ae7bc3f887ff55f2d721a\n",
      "commitDate": "20/05/20 5:42 AM",
      "commitName": "29b19cd59245c8809b697b3d7d7445813a685aad",
      "commitAuthor": "Mukund Thakur",
      "commitDateOld": "12/11/19 10:17 AM",
      "commitNameOld": "990063d2af0a37e9474949f33128805e34c3f016",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 189.77,
      "commitsBetweenForRepo": 658,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,22 +1,18 @@\n     private List\u003cPartETag\u003e waitForAllPartUploads() throws IOException {\n       LOG.debug(\"Waiting for {} uploads to complete\", partETagsFutures.size());\n       try {\n         return Futures.allAsList(partETagsFutures).get();\n       } catch (InterruptedException ie) {\n         LOG.warn(\"Interrupted partUpload\", ie);\n         Thread.currentThread().interrupt();\n         return null;\n       } catch (ExecutionException ee) {\n         //there is no way of recovering so abort\n         //cancel all partUploads\n         LOG.debug(\"While waiting for upload completion\", ee);\n-        LOG.debug(\"Cancelling futures\");\n-        for (ListenableFuture\u003cPartETag\u003e future : partETagsFutures) {\n-          future.cancel(true);\n-        }\n         //abort multipartupload\n         this.abort();\n         throw extractException(\"Multi-part upload with id \u0027\" + uploadId\n                 + \"\u0027 to \" + key, key, ee);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private List\u003cPartETag\u003e waitForAllPartUploads() throws IOException {\n      LOG.debug(\"Waiting for {} uploads to complete\", partETagsFutures.size());\n      try {\n        return Futures.allAsList(partETagsFutures).get();\n      } catch (InterruptedException ie) {\n        LOG.warn(\"Interrupted partUpload\", ie);\n        Thread.currentThread().interrupt();\n        return null;\n      } catch (ExecutionException ee) {\n        //there is no way of recovering so abort\n        //cancel all partUploads\n        LOG.debug(\"While waiting for upload completion\", ee);\n        //abort multipartupload\n        this.abort();\n        throw extractException(\"Multi-part upload with id \u0027\" + uploadId\n                + \"\u0027 to \" + key, key, ee);\n      }\n    }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
      "extendedDetails": {}
    },
    "6c348c56918973fd988b110e79231324a8befe12": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange)",
      "commitMessage": "HADOOP-13560. S3ABlockOutputStream to support huge (many GB) file writes. Contributed by Steve Loughran\n",
      "commitDate": "18/10/16 1:16 PM",
      "commitName": "6c348c56918973fd988b110e79231324a8befe12",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HADOOP-13560. S3ABlockOutputStream to support huge (many GB) file writes. Contributed by Steve Loughran\n",
          "commitDate": "18/10/16 1:16 PM",
          "commitName": "6c348c56918973fd988b110e79231324a8befe12",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "18/10/16 11:06 AM",
          "commitNameOld": "b733a6f86262522e535cebc972baecbe6a6eab50",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 0.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,22 @@\n     private List\u003cPartETag\u003e waitForAllPartUploads() throws IOException {\n+      LOG.debug(\"Waiting for {} uploads to complete\", partETagsFutures.size());\n       try {\n         return Futures.allAsList(partETagsFutures).get();\n       } catch (InterruptedException ie) {\n-        LOG.warn(\"Interrupted partUpload: {}\", ie, ie);\n+        LOG.warn(\"Interrupted partUpload\", ie);\n         Thread.currentThread().interrupt();\n         return null;\n       } catch (ExecutionException ee) {\n         //there is no way of recovering so abort\n         //cancel all partUploads\n+        LOG.debug(\"While waiting for upload completion\", ee);\n+        LOG.debug(\"Cancelling futures\");\n         for (ListenableFuture\u003cPartETag\u003e future : partETagsFutures) {\n           future.cancel(true);\n         }\n         //abort multipartupload\n         this.abort();\n-        throw extractException(\"Multi-part upload with id \u0027\" + uploadId + \"\u0027\",\n-            key, ee);\n+        throw extractException(\"Multi-part upload with id \u0027\" + uploadId\n+                + \"\u0027 to \" + key, key, ee);\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private List\u003cPartETag\u003e waitForAllPartUploads() throws IOException {\n      LOG.debug(\"Waiting for {} uploads to complete\", partETagsFutures.size());\n      try {\n        return Futures.allAsList(partETagsFutures).get();\n      } catch (InterruptedException ie) {\n        LOG.warn(\"Interrupted partUpload\", ie);\n        Thread.currentThread().interrupt();\n        return null;\n      } catch (ExecutionException ee) {\n        //there is no way of recovering so abort\n        //cancel all partUploads\n        LOG.debug(\"While waiting for upload completion\", ee);\n        LOG.debug(\"Cancelling futures\");\n        for (ListenableFuture\u003cPartETag\u003e future : partETagsFutures) {\n          future.cancel(true);\n        }\n        //abort multipartupload\n        this.abort();\n        throw extractException(\"Multi-part upload with id \u0027\" + uploadId\n                + \"\u0027 to \" + key, key, ee);\n      }\n    }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
          "extendedDetails": {
            "oldPath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java",
            "newPath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
            "oldMethodName": "waitForAllPartUploads",
            "newMethodName": "waitForAllPartUploads"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-13560. S3ABlockOutputStream to support huge (many GB) file writes. Contributed by Steve Loughran\n",
          "commitDate": "18/10/16 1:16 PM",
          "commitName": "6c348c56918973fd988b110e79231324a8befe12",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "18/10/16 11:06 AM",
          "commitNameOld": "b733a6f86262522e535cebc972baecbe6a6eab50",
          "commitAuthorOld": "Xuan",
          "daysBetweenCommits": 0.09,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,19 +1,22 @@\n     private List\u003cPartETag\u003e waitForAllPartUploads() throws IOException {\n+      LOG.debug(\"Waiting for {} uploads to complete\", partETagsFutures.size());\n       try {\n         return Futures.allAsList(partETagsFutures).get();\n       } catch (InterruptedException ie) {\n-        LOG.warn(\"Interrupted partUpload: {}\", ie, ie);\n+        LOG.warn(\"Interrupted partUpload\", ie);\n         Thread.currentThread().interrupt();\n         return null;\n       } catch (ExecutionException ee) {\n         //there is no way of recovering so abort\n         //cancel all partUploads\n+        LOG.debug(\"While waiting for upload completion\", ee);\n+        LOG.debug(\"Cancelling futures\");\n         for (ListenableFuture\u003cPartETag\u003e future : partETagsFutures) {\n           future.cancel(true);\n         }\n         //abort multipartupload\n         this.abort();\n-        throw extractException(\"Multi-part upload with id \u0027\" + uploadId + \"\u0027\",\n-            key, ee);\n+        throw extractException(\"Multi-part upload with id \u0027\" + uploadId\n+                + \"\u0027 to \" + key, key, ee);\n       }\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private List\u003cPartETag\u003e waitForAllPartUploads() throws IOException {\n      LOG.debug(\"Waiting for {} uploads to complete\", partETagsFutures.size());\n      try {\n        return Futures.allAsList(partETagsFutures).get();\n      } catch (InterruptedException ie) {\n        LOG.warn(\"Interrupted partUpload\", ie);\n        Thread.currentThread().interrupt();\n        return null;\n      } catch (ExecutionException ee) {\n        //there is no way of recovering so abort\n        //cancel all partUploads\n        LOG.debug(\"While waiting for upload completion\", ee);\n        LOG.debug(\"Cancelling futures\");\n        for (ListenableFuture\u003cPartETag\u003e future : partETagsFutures) {\n          future.cancel(true);\n        }\n        //abort multipartupload\n        this.abort();\n        throw extractException(\"Multi-part upload with id \u0027\" + uploadId\n                + \"\u0027 to \" + key, key, ee);\n      }\n    }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3ABlockOutputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "c58a59f7081d55dd2108545ebf9ee48cf43ca944": {
      "type": "Ybodychange",
      "commitMessage": "HADOOP-13171. Add StorageStatistics to S3A; instrument some more operations. Contributed by Steve Loughran.\n",
      "commitDate": "03/06/16 8:55 AM",
      "commitName": "c58a59f7081d55dd2108545ebf9ee48cf43ca944",
      "commitAuthor": "Chris Nauroth",
      "commitDateOld": "21/05/16 8:39 AM",
      "commitNameOld": "39ec1515a205952eda7e171408a8b83eceb4abde",
      "commitAuthorOld": "Steve Loughran",
      "daysBetweenCommits": 13.01,
      "commitsBetweenForRepo": 75,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,19 +1,19 @@\n     private List\u003cPartETag\u003e waitForAllPartUploads() throws IOException {\n       try {\n         return Futures.allAsList(partETagsFutures).get();\n       } catch (InterruptedException ie) {\n-        LOG.warn(\"Interrupted partUpload:\" + ie, ie);\n+        LOG.warn(\"Interrupted partUpload: {}\", ie, ie);\n         Thread.currentThread().interrupt();\n         return null;\n       } catch (ExecutionException ee) {\n         //there is no way of recovering so abort\n         //cancel all partUploads\n         for (ListenableFuture\u003cPartETag\u003e future : partETagsFutures) {\n           future.cancel(true);\n         }\n         //abort multipartupload\n         this.abort();\n         throw extractException(\"Multi-part upload with id \u0027\" + uploadId + \"\u0027\",\n             key, ee);\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    private List\u003cPartETag\u003e waitForAllPartUploads() throws IOException {\n      try {\n        return Futures.allAsList(partETagsFutures).get();\n      } catch (InterruptedException ie) {\n        LOG.warn(\"Interrupted partUpload: {}\", ie, ie);\n        Thread.currentThread().interrupt();\n        return null;\n      } catch (ExecutionException ee) {\n        //there is no way of recovering so abort\n        //cancel all partUploads\n        for (ListenableFuture\u003cPartETag\u003e future : partETagsFutures) {\n          future.cancel(true);\n        }\n        //abort multipartupload\n        this.abort();\n        throw extractException(\"Multi-part upload with id \u0027\" + uploadId + \"\u0027\",\n            key, ee);\n      }\n    }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java",
      "extendedDetails": {}
    },
    "39ec1515a205952eda7e171408a8b83eceb4abde": {
      "type": "Ymultichange(Ymodifierchange,Ybodychange)",
      "commitMessage": "HADOOP-13130. s3a failures can surface as RTEs, not IOEs. (Steve Loughran)\n",
      "commitDate": "21/05/16 8:39 AM",
      "commitName": "39ec1515a205952eda7e171408a8b83eceb4abde",
      "commitAuthor": "Steve Loughran",
      "subchanges": [
        {
          "type": "Ymodifierchange",
          "commitMessage": "HADOOP-13130. s3a failures can surface as RTEs, not IOEs. (Steve Loughran)\n",
          "commitDate": "21/05/16 8:39 AM",
          "commitName": "39ec1515a205952eda7e171408a8b83eceb4abde",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "12/05/16 11:24 AM",
          "commitNameOld": "27c4e90efce04e1b1302f668b5eb22412e00d033",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 8.89,
          "commitsBetweenForRepo": 74,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,19 @@\n-    public List\u003cPartETag\u003e waitForAllPartUploads() throws IOException {\n+    private List\u003cPartETag\u003e waitForAllPartUploads() throws IOException {\n       try {\n         return Futures.allAsList(partETagsFutures).get();\n       } catch (InterruptedException ie) {\n         LOG.warn(\"Interrupted partUpload:\" + ie, ie);\n         Thread.currentThread().interrupt();\n+        return null;\n       } catch (ExecutionException ee) {\n         //there is no way of recovering so abort\n         //cancel all partUploads\n         for (ListenableFuture\u003cPartETag\u003e future : partETagsFutures) {\n           future.cancel(true);\n         }\n         //abort multipartupload\n         this.abort();\n-        throw new IOException(\"Part upload failed in multi-part upload with \" +\n-            \"id \u0027\" +uploadId + \"\u0027:\" + ee, ee);\n+        throw extractException(\"Multi-part upload with id \u0027\" + uploadId + \"\u0027\",\n+            key, ee);\n       }\n-      //should not happen?\n-      return null;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private List\u003cPartETag\u003e waitForAllPartUploads() throws IOException {\n      try {\n        return Futures.allAsList(partETagsFutures).get();\n      } catch (InterruptedException ie) {\n        LOG.warn(\"Interrupted partUpload:\" + ie, ie);\n        Thread.currentThread().interrupt();\n        return null;\n      } catch (ExecutionException ee) {\n        //there is no way of recovering so abort\n        //cancel all partUploads\n        for (ListenableFuture\u003cPartETag\u003e future : partETagsFutures) {\n          future.cancel(true);\n        }\n        //abort multipartupload\n        this.abort();\n        throw extractException(\"Multi-part upload with id \u0027\" + uploadId + \"\u0027\",\n            key, ee);\n      }\n    }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HADOOP-13130. s3a failures can surface as RTEs, not IOEs. (Steve Loughran)\n",
          "commitDate": "21/05/16 8:39 AM",
          "commitName": "39ec1515a205952eda7e171408a8b83eceb4abde",
          "commitAuthor": "Steve Loughran",
          "commitDateOld": "12/05/16 11:24 AM",
          "commitNameOld": "27c4e90efce04e1b1302f668b5eb22412e00d033",
          "commitAuthorOld": "Steve Loughran",
          "daysBetweenCommits": 8.89,
          "commitsBetweenForRepo": 74,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,20 +1,19 @@\n-    public List\u003cPartETag\u003e waitForAllPartUploads() throws IOException {\n+    private List\u003cPartETag\u003e waitForAllPartUploads() throws IOException {\n       try {\n         return Futures.allAsList(partETagsFutures).get();\n       } catch (InterruptedException ie) {\n         LOG.warn(\"Interrupted partUpload:\" + ie, ie);\n         Thread.currentThread().interrupt();\n+        return null;\n       } catch (ExecutionException ee) {\n         //there is no way of recovering so abort\n         //cancel all partUploads\n         for (ListenableFuture\u003cPartETag\u003e future : partETagsFutures) {\n           future.cancel(true);\n         }\n         //abort multipartupload\n         this.abort();\n-        throw new IOException(\"Part upload failed in multi-part upload with \" +\n-            \"id \u0027\" +uploadId + \"\u0027:\" + ee, ee);\n+        throw extractException(\"Multi-part upload with id \u0027\" + uploadId + \"\u0027\",\n+            key, ee);\n       }\n-      //should not happen?\n-      return null;\n     }\n\\ No newline at end of file\n",
          "actualSource": "    private List\u003cPartETag\u003e waitForAllPartUploads() throws IOException {\n      try {\n        return Futures.allAsList(partETagsFutures).get();\n      } catch (InterruptedException ie) {\n        LOG.warn(\"Interrupted partUpload:\" + ie, ie);\n        Thread.currentThread().interrupt();\n        return null;\n      } catch (ExecutionException ee) {\n        //there is no way of recovering so abort\n        //cancel all partUploads\n        for (ListenableFuture\u003cPartETag\u003e future : partETagsFutures) {\n          future.cancel(true);\n        }\n        //abort multipartupload\n        this.abort();\n        throw extractException(\"Multi-part upload with id \u0027\" + uploadId + \"\u0027\",\n            key, ee);\n      }\n    }",
          "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java",
          "extendedDetails": {}
        }
      ]
    },
    "15b7076ad5f2ae92d231140b2f8cebc392a92c87": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-11183. Memory-based S3AOutputstream. (Thomas Demoor via stevel)\n",
      "commitDate": "03/03/15 4:18 PM",
      "commitName": "15b7076ad5f2ae92d231140b2f8cebc392a92c87",
      "commitAuthor": "Steve Loughran",
      "diff": "@@ -0,0 +1,20 @@\n+    public List\u003cPartETag\u003e waitForAllPartUploads() throws IOException {\n+      try {\n+        return Futures.allAsList(partETagsFutures).get();\n+      } catch (InterruptedException ie) {\n+        LOG.warn(\"Interrupted partUpload:\" + ie, ie);\n+        Thread.currentThread().interrupt();\n+      } catch (ExecutionException ee) {\n+        //there is no way of recovering so abort\n+        //cancel all partUploads\n+        for (ListenableFuture\u003cPartETag\u003e future : partETagsFutures) {\n+          future.cancel(true);\n+        }\n+        //abort multipartupload\n+        this.abort();\n+        throw new IOException(\"Part upload failed in multi-part upload with \" +\n+            \"id \u0027\" +uploadId + \"\u0027:\" + ee, ee);\n+      }\n+      //should not happen?\n+      return null;\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    public List\u003cPartETag\u003e waitForAllPartUploads() throws IOException {\n      try {\n        return Futures.allAsList(partETagsFutures).get();\n      } catch (InterruptedException ie) {\n        LOG.warn(\"Interrupted partUpload:\" + ie, ie);\n        Thread.currentThread().interrupt();\n      } catch (ExecutionException ee) {\n        //there is no way of recovering so abort\n        //cancel all partUploads\n        for (ListenableFuture\u003cPartETag\u003e future : partETagsFutures) {\n          future.cancel(true);\n        }\n        //abort multipartupload\n        this.abort();\n        throw new IOException(\"Part upload failed in multi-part upload with \" +\n            \"id \u0027\" +uploadId + \"\u0027:\" + ee, ee);\n      }\n      //should not happen?\n      return null;\n    }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFastOutputStream.java"
    }
  }
}