{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "RouterRpcServer.java",
  "functionName": "getDatanodeReport",
  "functionId": "getDatanodeReport___type-DatanodeReportType",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
  "functionStartLine": 866,
  "functionEndLine": 869,
  "numCommitsSeen": 75,
  "timeTaken": 4992,
  "changeHistory": [
    "6425ed27ea638da75f656204d6df4adad1d91fe1",
    "fb5b3dce6192265bce9b9d93ab663bdc5be8048e",
    "fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a",
    "a71656c1c1bf6c680f1382a76ddcac870061f320",
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d",
    "81601dac8ec7650bec14700b174910390a92fe1f",
    "ca4f209b49e3aad6a80306f7342c9b6b560a79a7"
  ],
  "changeHistoryShort": {
    "6425ed27ea638da75f656204d6df4adad1d91fe1": "Ybodychange",
    "fb5b3dce6192265bce9b9d93ab663bdc5be8048e": "Ybodychange",
    "fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a": "Ybodychange",
    "a71656c1c1bf6c680f1382a76ddcac870061f320": "Ybodychange",
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d": "Yfilerename",
    "81601dac8ec7650bec14700b174910390a92fe1f": "Ybodychange",
    "ca4f209b49e3aad6a80306f7342c9b6b560a79a7": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6425ed27ea638da75f656204d6df4adad1d91fe1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13790. RBF: Move ClientProtocol APIs to its own module. Contributed by Chao Sun.\n",
      "commitDate": "19/08/18 11:50 PM",
      "commitName": "6425ed27ea638da75f656204d6df4adad1d91fe1",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "17/08/18 8:01 AM",
      "commitNameOld": "fb5b3dce6192265bce9b9d93ab663bdc5be8048e",
      "commitAuthorOld": "Xiaoyu Yao",
      "daysBetweenCommits": 2.66,
      "commitsBetweenForRepo": 8,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,4 @@\n   public DatanodeInfo[] getDatanodeReport(DatanodeReportType type)\n       throws IOException {\n-    checkOperation(OperationCategory.UNCHECKED);\n-    return getDatanodeReport(type, true, 0);\n+    return clientProto.getDatanodeReport(type);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeInfo[] getDatanodeReport(DatanodeReportType type)\n      throws IOException {\n    return clientProto.getDatanodeReport(type);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
      "extendedDetails": {}
    },
    "fb5b3dce6192265bce9b9d93ab663bdc5be8048e": {
      "type": "Ybodychange",
      "commitMessage": "Revert \"HDFS-13790. RBF: Move ClientProtocol APIs to its own module. Contributed by Chao Sun.\"\n\nThis reverts commit fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a.\n",
      "commitDate": "17/08/18 8:01 AM",
      "commitName": "fb5b3dce6192265bce9b9d93ab663bdc5be8048e",
      "commitAuthor": "Xiaoyu Yao",
      "commitDateOld": "17/08/18 2:52 AM",
      "commitNameOld": "fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a",
      "commitAuthorOld": "Brahma Reddy Battula",
      "daysBetweenCommits": 0.21,
      "commitsBetweenForRepo": 2,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,4 +1,5 @@\n   public DatanodeInfo[] getDatanodeReport(DatanodeReportType type)\n       throws IOException {\n-    return clientProto.getDatanodeReport(type);\n+    checkOperation(OperationCategory.UNCHECKED);\n+    return getDatanodeReport(type, true, 0);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeInfo[] getDatanodeReport(DatanodeReportType type)\n      throws IOException {\n    checkOperation(OperationCategory.UNCHECKED);\n    return getDatanodeReport(type, true, 0);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
      "extendedDetails": {}
    },
    "fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13790. RBF: Move ClientProtocol APIs to its own module. Contributed by Chao Sun.\n",
      "commitDate": "17/08/18 2:52 AM",
      "commitName": "fa121eb66bc42e9cb5586f8c2e268cfdc2ed187a",
      "commitAuthor": "Brahma Reddy Battula",
      "commitDateOld": "12/08/18 3:06 AM",
      "commitNameOld": "39ed3a66dbb01383ed16b141183fc48bfd2e613d",
      "commitAuthorOld": "Uma Maheswara Rao G",
      "daysBetweenCommits": 4.99,
      "commitsBetweenForRepo": 43,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,4 @@\n   public DatanodeInfo[] getDatanodeReport(DatanodeReportType type)\n       throws IOException {\n-    checkOperation(OperationCategory.UNCHECKED);\n-    return getDatanodeReport(type, true, 0);\n+    return clientProto.getDatanodeReport(type);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeInfo[] getDatanodeReport(DatanodeReportType type)\n      throws IOException {\n    return clientProto.getDatanodeReport(type);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
      "extendedDetails": {}
    },
    "a71656c1c1bf6c680f1382a76ddcac870061f320": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13347. RBF: Cache datanode reports. Contributed by Inigo Goiri.\n",
      "commitDate": "27/03/18 8:00 PM",
      "commitName": "a71656c1c1bf6c680f1382a76ddcac870061f320",
      "commitAuthor": "Yiqun Lin",
      "commitDateOld": "26/03/18 3:33 AM",
      "commitNameOld": "cfc3a1c8f06fba4f4bd5ffe8bb2a6944d066948e",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 1.69,
      "commitsBetweenForRepo": 17,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,5 +1,5 @@\n   public DatanodeInfo[] getDatanodeReport(DatanodeReportType type)\n       throws IOException {\n     checkOperation(OperationCategory.UNCHECKED);\n-    return getDatanodeReport(type, 0);\n+    return getDatanodeReport(type, true, 0);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeInfo[] getDatanodeReport(DatanodeReportType type)\n      throws IOException {\n    checkOperation(OperationCategory.UNCHECKED);\n    return getDatanodeReport(type, true, 0);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
      "extendedDetails": {}
    },
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-13215. RBF: Move Router to its own module. Contributed by Wei Yan\n",
      "commitDate": "19/03/18 10:13 PM",
      "commitName": "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d",
      "commitAuthor": "weiy",
      "commitDateOld": "19/03/18 5:19 PM",
      "commitNameOld": "e65ff1c8be48ef4f04ed96f96ac4caef4974944d",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 0.2,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  public DatanodeInfo[] getDatanodeReport(DatanodeReportType type)\n      throws IOException {\n    checkOperation(OperationCategory.UNCHECKED);\n    return getDatanodeReport(type, 0);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java"
      }
    },
    "81601dac8ec7650bec14700b174910390a92fe1f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-12273. Federation UI. Contributed by Inigo Goiri.\n\n(cherry picked from commit adbb2e00c7b85524fd43bd68895d49814c16680a)\n",
      "commitDate": "06/10/17 6:50 PM",
      "commitName": "81601dac8ec7650bec14700b174910390a92fe1f",
      "commitAuthor": "Inigo Goiri",
      "commitDateOld": "06/10/17 6:50 PM",
      "commitNameOld": "6c69e23dcdf1cdbddd47bacdf2dace5c9f06e3ad",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 0.0,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,33 +1,5 @@\n   public DatanodeInfo[] getDatanodeReport(DatanodeReportType type)\n       throws IOException {\n     checkOperation(OperationCategory.UNCHECKED);\n-\n-    Map\u003cString, DatanodeInfo\u003e datanodesMap \u003d new LinkedHashMap\u003c\u003e();\n-    RemoteMethod method \u003d new RemoteMethod(\"getDatanodeReport\",\n-        new Class\u003c?\u003e[] {DatanodeReportType.class}, type);\n-\n-    Set\u003cFederationNamespaceInfo\u003e nss \u003d namenodeResolver.getNamespaces();\n-    Map\u003cFederationNamespaceInfo, Object\u003e results \u003d\n-        rpcClient.invokeConcurrent(nss, method, true, false);\n-    for (Entry\u003cFederationNamespaceInfo, Object\u003e entry : results.entrySet()) {\n-      FederationNamespaceInfo ns \u003d entry.getKey();\n-      DatanodeInfo[] result \u003d (DatanodeInfo[]) entry.getValue();\n-      for (DatanodeInfo node : result) {\n-        String nodeId \u003d node.getXferAddr();\n-        if (!datanodesMap.containsKey(nodeId)) {\n-          // Add the subcluster as a suffix to the network location\n-          node.setNetworkLocation(\n-              NodeBase.PATH_SEPARATOR_STR + ns.getNameserviceId() +\n-              node.getNetworkLocation());\n-          datanodesMap.put(nodeId, node);\n-        } else {\n-          LOG.debug(\"{} is in multiple subclusters\", nodeId);\n-        }\n-      }\n-    }\n-    // Map -\u003e Array\n-    Collection\u003cDatanodeInfo\u003e datanodes \u003d datanodesMap.values();\n-    DatanodeInfo[] combinedData \u003d new DatanodeInfo[datanodes.size()];\n-    combinedData \u003d datanodes.toArray(combinedData);\n-    return combinedData;\n+    return getDatanodeReport(type, 0);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeInfo[] getDatanodeReport(DatanodeReportType type)\n      throws IOException {\n    checkOperation(OperationCategory.UNCHECKED);\n    return getDatanodeReport(type, 0);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java",
      "extendedDetails": {}
    },
    "ca4f209b49e3aad6a80306f7342c9b6b560a79a7": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-11546. Federation Router RPC server. Contributed by Jason Kace and Inigo Goiri.\n\n(cherry picked from commit 8a9cdebebf26841a0f1e99fb08135f4597f2eba2)\n",
      "commitDate": "06/10/17 6:50 PM",
      "commitName": "ca4f209b49e3aad6a80306f7342c9b6b560a79a7",
      "commitAuthor": "Inigo Goiri",
      "diff": "@@ -0,0 +1,33 @@\n+  public DatanodeInfo[] getDatanodeReport(DatanodeReportType type)\n+      throws IOException {\n+    checkOperation(OperationCategory.UNCHECKED);\n+\n+    Map\u003cString, DatanodeInfo\u003e datanodesMap \u003d new LinkedHashMap\u003c\u003e();\n+    RemoteMethod method \u003d new RemoteMethod(\"getDatanodeReport\",\n+        new Class\u003c?\u003e[] {DatanodeReportType.class}, type);\n+\n+    Set\u003cFederationNamespaceInfo\u003e nss \u003d namenodeResolver.getNamespaces();\n+    Map\u003cFederationNamespaceInfo, Object\u003e results \u003d\n+        rpcClient.invokeConcurrent(nss, method, true, false);\n+    for (Entry\u003cFederationNamespaceInfo, Object\u003e entry : results.entrySet()) {\n+      FederationNamespaceInfo ns \u003d entry.getKey();\n+      DatanodeInfo[] result \u003d (DatanodeInfo[]) entry.getValue();\n+      for (DatanodeInfo node : result) {\n+        String nodeId \u003d node.getXferAddr();\n+        if (!datanodesMap.containsKey(nodeId)) {\n+          // Add the subcluster as a suffix to the network location\n+          node.setNetworkLocation(\n+              NodeBase.PATH_SEPARATOR_STR + ns.getNameserviceId() +\n+              node.getNetworkLocation());\n+          datanodesMap.put(nodeId, node);\n+        } else {\n+          LOG.debug(\"{} is in multiple subclusters\", nodeId);\n+        }\n+      }\n+    }\n+    // Map -\u003e Array\n+    Collection\u003cDatanodeInfo\u003e datanodes \u003d datanodesMap.values();\n+    DatanodeInfo[] combinedData \u003d new DatanodeInfo[datanodes.size()];\n+    combinedData \u003d datanodes.toArray(combinedData);\n+    return combinedData;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public DatanodeInfo[] getDatanodeReport(DatanodeReportType type)\n      throws IOException {\n    checkOperation(OperationCategory.UNCHECKED);\n\n    Map\u003cString, DatanodeInfo\u003e datanodesMap \u003d new LinkedHashMap\u003c\u003e();\n    RemoteMethod method \u003d new RemoteMethod(\"getDatanodeReport\",\n        new Class\u003c?\u003e[] {DatanodeReportType.class}, type);\n\n    Set\u003cFederationNamespaceInfo\u003e nss \u003d namenodeResolver.getNamespaces();\n    Map\u003cFederationNamespaceInfo, Object\u003e results \u003d\n        rpcClient.invokeConcurrent(nss, method, true, false);\n    for (Entry\u003cFederationNamespaceInfo, Object\u003e entry : results.entrySet()) {\n      FederationNamespaceInfo ns \u003d entry.getKey();\n      DatanodeInfo[] result \u003d (DatanodeInfo[]) entry.getValue();\n      for (DatanodeInfo node : result) {\n        String nodeId \u003d node.getXferAddr();\n        if (!datanodesMap.containsKey(nodeId)) {\n          // Add the subcluster as a suffix to the network location\n          node.setNetworkLocation(\n              NodeBase.PATH_SEPARATOR_STR + ns.getNameserviceId() +\n              node.getNetworkLocation());\n          datanodesMap.put(nodeId, node);\n        } else {\n          LOG.debug(\"{} is in multiple subclusters\", nodeId);\n        }\n      }\n    }\n    // Map -\u003e Array\n    Collection\u003cDatanodeInfo\u003e datanodes \u003d datanodesMap.values();\n    DatanodeInfo[] combinedData \u003d new DatanodeInfo[datanodes.size()];\n    combinedData \u003d datanodes.toArray(combinedData);\n    return combinedData;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterRpcServer.java"
    }
  }
}