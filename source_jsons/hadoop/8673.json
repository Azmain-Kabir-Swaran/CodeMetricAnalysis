{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSDirTruncateOp.java",
  "functionName": "unprotectedTruncate",
  "functionId": "unprotectedTruncate___fsn-FSNamesystem(modifiers-final)__iip-INodesInPath(modifiers-final)__clientName-String(modifiers-final)__clientMachine-String(modifiers-final)__newLength-long(modifiers-final)__mtime-long(modifiers-final)__truncateBlock-Block(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
  "functionStartLine": 167,
  "functionEndLine": 197,
  "numCommitsSeen": 498,
  "timeTaken": 8189,
  "changeHistory": [
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
    "972782d9568e0849484c027f27c1638ba50ec56e",
    "a49cc74b4c72195dee1dfb6f9548e5e411dff553",
    "31f117138a00794de4951ee8433e304d72b04094",
    "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
    "4928f5473394981829e5ffd4b16ea0801baf5c45",
    "d368d3647a858644b9fcd3be33d9fea2a6962f69",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
    "08ac06283a3e9bf0d49d873823aabd419b08e41f",
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2"
  ],
  "changeHistoryShort": {
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04": "Ymultichange(Yparameterchange,Ybodychange)",
    "972782d9568e0849484c027f27c1638ba50ec56e": "Ybodychange",
    "a49cc74b4c72195dee1dfb6f9548e5e411dff553": "Ybodychange",
    "31f117138a00794de4951ee8433e304d72b04094": "Ybodychange",
    "d3797f9f3cf502b7bfee3b64c641807b276c6faf": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yparametermetachange,Yparameterchange)",
    "4928f5473394981829e5ffd4b16ea0801baf5c45": "Ybodychange",
    "d368d3647a858644b9fcd3be33d9fea2a6962f69": "Ybodychange",
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": "Ybodychange",
    "08ac06283a3e9bf0d49d873823aabd419b08e41f": "Ymultichange(Yparameterchange,Ybodychange)",
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2": "Yintroduced"
  },
  "changeHistoryDetails": {
    "9d175853b0170683ad5f21d9bcdeaac49fe89e04": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-10997. Reduce number of path resolving methods. Contributed by Daryn Sharp.\n",
      "commitDate": "24/10/16 3:14 PM",
      "commitName": "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
      "commitAuthor": "Kihwal Lee",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-10997. Reduce number of path resolving methods. Contributed by Daryn Sharp.\n",
          "commitDate": "24/10/16 3:14 PM",
          "commitName": "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "17/08/16 1:53 PM",
          "commitNameOld": "869393643de23dcb010cc33091c8eb398de0fd6c",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 68.06,
          "commitsBetweenForRepo": 438,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,31 +1,31 @@\n-  static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n+  static void unprotectedTruncate(final FSNamesystem fsn,\n+      final INodesInPath iip,\n       final String clientName, final String clientMachine,\n       final long newLength, final long mtime, final Block truncateBlock)\n       throws UnresolvedLinkException, QuotaExceededException,\n       SnapshotAccessControlException, IOException {\n     assert fsn.hasWriteLock();\n \n     FSDirectory fsd \u003d fsn.getFSDirectory();\n-    INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n     INodeFile file \u003d iip.getLastINode().asFile();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n         collectedBlocks, mtime, null);\n \n     if (!onBlockBoundary) {\n       BlockInfo oldBlock \u003d file.getLastBlock();\n       Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n           file.computeFileSize() - newLength, truncateBlock);\n       assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n           tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n           \"Should be the same block.\";\n       if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n           \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n         oldBlock.delete();\n         fsd.getBlockManager().removeBlockFromMap(oldBlock);\n       }\n     }\n     assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n       \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n     fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static void unprotectedTruncate(final FSNamesystem fsn,\n      final INodesInPath iip,\n      final String clientName, final String clientMachine,\n      final long newLength, final long mtime, final Block truncateBlock)\n      throws UnresolvedLinkException, QuotaExceededException,\n      SnapshotAccessControlException, IOException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    INodeFile file \u003d iip.getLastINode().asFile();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n        collectedBlocks, mtime, null);\n\n    if (!onBlockBoundary) {\n      BlockInfo oldBlock \u003d file.getLastBlock();\n      Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n          file.computeFileSize() - newLength, truncateBlock);\n      assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n          tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n          \"Should be the same block.\";\n      if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n          \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n        oldBlock.delete();\n        fsd.getBlockManager().removeBlockFromMap(oldBlock);\n      }\n    }\n    assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n      \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n    fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {
            "oldValue": "[fsn-FSNamesystem(modifiers-final), src-String(modifiers-final), clientName-String(modifiers-final), clientMachine-String(modifiers-final), newLength-long(modifiers-final), mtime-long(modifiers-final), truncateBlock-Block(modifiers-final)]",
            "newValue": "[fsn-FSNamesystem(modifiers-final), iip-INodesInPath(modifiers-final), clientName-String(modifiers-final), clientMachine-String(modifiers-final), newLength-long(modifiers-final), mtime-long(modifiers-final), truncateBlock-Block(modifiers-final)]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-10997. Reduce number of path resolving methods. Contributed by Daryn Sharp.\n",
          "commitDate": "24/10/16 3:14 PM",
          "commitName": "9d175853b0170683ad5f21d9bcdeaac49fe89e04",
          "commitAuthor": "Kihwal Lee",
          "commitDateOld": "17/08/16 1:53 PM",
          "commitNameOld": "869393643de23dcb010cc33091c8eb398de0fd6c",
          "commitAuthorOld": "Kihwal Lee",
          "daysBetweenCommits": 68.06,
          "commitsBetweenForRepo": 438,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,31 +1,31 @@\n-  static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n+  static void unprotectedTruncate(final FSNamesystem fsn,\n+      final INodesInPath iip,\n       final String clientName, final String clientMachine,\n       final long newLength, final long mtime, final Block truncateBlock)\n       throws UnresolvedLinkException, QuotaExceededException,\n       SnapshotAccessControlException, IOException {\n     assert fsn.hasWriteLock();\n \n     FSDirectory fsd \u003d fsn.getFSDirectory();\n-    INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n     INodeFile file \u003d iip.getLastINode().asFile();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n         collectedBlocks, mtime, null);\n \n     if (!onBlockBoundary) {\n       BlockInfo oldBlock \u003d file.getLastBlock();\n       Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n           file.computeFileSize() - newLength, truncateBlock);\n       assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n           tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n           \"Should be the same block.\";\n       if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n           \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n         oldBlock.delete();\n         fsd.getBlockManager().removeBlockFromMap(oldBlock);\n       }\n     }\n     assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n       \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n     fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static void unprotectedTruncate(final FSNamesystem fsn,\n      final INodesInPath iip,\n      final String clientName, final String clientMachine,\n      final long newLength, final long mtime, final Block truncateBlock)\n      throws UnresolvedLinkException, QuotaExceededException,\n      SnapshotAccessControlException, IOException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    INodeFile file \u003d iip.getLastINode().asFile();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n        collectedBlocks, mtime, null);\n\n    if (!onBlockBoundary) {\n      BlockInfo oldBlock \u003d file.getLastBlock();\n      Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n          file.computeFileSize() - newLength, truncateBlock);\n      assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n          tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n          \"Should be the same block.\";\n      if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n          \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n        oldBlock.delete();\n        fsd.getBlockManager().removeBlockFromMap(oldBlock);\n      }\n    }\n    assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n      \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n    fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {}
        }
      ]
    },
    "972782d9568e0849484c027f27c1638ba50ec56e": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9754. Avoid unnecessary getBlockCollection calls in BlockManager. Contributed by Jing Zhao.\n",
      "commitDate": "12/02/16 11:07 AM",
      "commitName": "972782d9568e0849484c027f27c1638ba50ec56e",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "21/01/16 11:13 AM",
      "commitNameOld": "c304890c8c7782d835896859f5b7f60b96c306c0",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 22.0,
      "commitsBetweenForRepo": 168,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,31 @@\n   static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n       final String clientName, final String clientMachine,\n       final long newLength, final long mtime, final Block truncateBlock)\n       throws UnresolvedLinkException, QuotaExceededException,\n       SnapshotAccessControlException, IOException {\n     assert fsn.hasWriteLock();\n \n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n     INodeFile file \u003d iip.getLastINode().asFile();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n         collectedBlocks, mtime, null);\n \n     if (!onBlockBoundary) {\n       BlockInfo oldBlock \u003d file.getLastBlock();\n       Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n           file.computeFileSize() - newLength, truncateBlock);\n       assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n           tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n           \"Should be the same block.\";\n       if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n           \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n+        oldBlock.delete();\n         fsd.getBlockManager().removeBlockFromMap(oldBlock);\n       }\n     }\n     assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n       \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n     fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n      final String clientName, final String clientMachine,\n      final long newLength, final long mtime, final Block truncateBlock)\n      throws UnresolvedLinkException, QuotaExceededException,\n      SnapshotAccessControlException, IOException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n    INodeFile file \u003d iip.getLastINode().asFile();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n        collectedBlocks, mtime, null);\n\n    if (!onBlockBoundary) {\n      BlockInfo oldBlock \u003d file.getLastBlock();\n      Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n          file.computeFileSize() - newLength, truncateBlock);\n      assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n          tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n          \"Should be the same block.\";\n      if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n          \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n        oldBlock.delete();\n        fsd.getBlockManager().removeBlockFromMap(oldBlock);\n      }\n    }\n    assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n      \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n    fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
      "extendedDetails": {}
    },
    "a49cc74b4c72195dee1dfb6f9548e5e411dff553": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9129. Move the safemode block count into BlockManager. Contributed by Mingliang Liu.\n",
      "commitDate": "01/12/15 4:09 PM",
      "commitName": "a49cc74b4c72195dee1dfb6f9548e5e411dff553",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "01/09/15 2:30 PM",
      "commitNameOld": "ab56fcdb1219d03713b408dd3a95d7405635254d",
      "commitAuthorOld": "",
      "daysBetweenCommits": 91.11,
      "commitsBetweenForRepo": 691,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,30 @@\n   static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n       final String clientName, final String clientMachine,\n       final long newLength, final long mtime, final Block truncateBlock)\n       throws UnresolvedLinkException, QuotaExceededException,\n       SnapshotAccessControlException, IOException {\n     assert fsn.hasWriteLock();\n \n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n     INodeFile file \u003d iip.getLastINode().asFile();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n         collectedBlocks, mtime, null);\n \n     if (!onBlockBoundary) {\n       BlockInfo oldBlock \u003d file.getLastBlock();\n       Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n           file.computeFileSize() - newLength, truncateBlock);\n       assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n           tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n           \"Should be the same block.\";\n       if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n           \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n         fsd.getBlockManager().removeBlockFromMap(oldBlock);\n       }\n     }\n     assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n       \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n-    fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n+    fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n      final String clientName, final String clientMachine,\n      final long newLength, final long mtime, final Block truncateBlock)\n      throws UnresolvedLinkException, QuotaExceededException,\n      SnapshotAccessControlException, IOException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n    INodeFile file \u003d iip.getLastINode().asFile();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n        collectedBlocks, mtime, null);\n\n    if (!onBlockBoundary) {\n      BlockInfo oldBlock \u003d file.getLastBlock();\n      Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n          file.computeFileSize() - newLength, truncateBlock);\n      assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n          tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n          \"Should be the same block.\";\n      if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n          \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n        fsd.getBlockManager().removeBlockFromMap(oldBlock);\n      }\n    }\n    assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n      \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n    fsn.getBlockManager().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
      "extendedDetails": {}
    },
    "31f117138a00794de4951ee8433e304d72b04094": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8495. Consolidate append() related implementation into a single class. Contributed by Rakesh R.\n",
      "commitDate": "21/07/15 5:25 PM",
      "commitName": "31f117138a00794de4951ee8433e304d72b04094",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "29/06/15 4:45 PM",
      "commitNameOld": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 22.03,
      "commitsBetweenForRepo": 136,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,30 +1,30 @@\n   static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n       final String clientName, final String clientMachine,\n       final long newLength, final long mtime, final Block truncateBlock)\n       throws UnresolvedLinkException, QuotaExceededException,\n       SnapshotAccessControlException, IOException {\n     assert fsn.hasWriteLock();\n \n     FSDirectory fsd \u003d fsn.getFSDirectory();\n     INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n     INodeFile file \u003d iip.getLastINode().asFile();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n         collectedBlocks, mtime, null);\n \n     if (!onBlockBoundary) {\n       BlockInfo oldBlock \u003d file.getLastBlock();\n       Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n           file.computeFileSize() - newLength, truncateBlock);\n       assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n           tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n           \"Should be the same block.\";\n       if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n           \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n-        fsn.getBlockManager().removeBlockFromMap(oldBlock);\n+        fsd.getBlockManager().removeBlockFromMap(oldBlock);\n       }\n     }\n     assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n       \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n     fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n      final String clientName, final String clientMachine,\n      final long newLength, final long mtime, final Block truncateBlock)\n      throws UnresolvedLinkException, QuotaExceededException,\n      SnapshotAccessControlException, IOException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n    INodeFile file \u003d iip.getLastINode().asFile();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n        collectedBlocks, mtime, null);\n\n    if (!onBlockBoundary) {\n      BlockInfo oldBlock \u003d file.getLastBlock();\n      Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n          file.computeFileSize() - newLength, truncateBlock);\n      assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n          tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n          \"Should be the same block.\";\n      if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n          \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n        fsd.getBlockManager().removeBlockFromMap(oldBlock);\n      }\n    }\n    assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n      \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n    fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
      "extendedDetails": {}
    },
    "d3797f9f3cf502b7bfee3b64c641807b276c6faf": {
      "type": "Ymultichange(Ymovefromfile,Ymodifierchange,Ybodychange,Yparametermetachange,Yparameterchange)",
      "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
      "commitDate": "29/06/15 4:45 PM",
      "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
          "commitDate": "29/06/15 4:45 PM",
          "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "29/06/15 2:56 PM",
          "commitNameOld": "8e333720e13428a4d0d0f65692102f8f2e5da98d",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,30 @@\n-  void unprotectedTruncate(String src, String clientName, String clientMachine,\n-                           long newLength, long mtime, Block truncateBlock)\n+  static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n+      final String clientName, final String clientMachine,\n+      final long newLength, final long mtime, final Block truncateBlock)\n       throws UnresolvedLinkException, QuotaExceededException,\n       SnapshotAccessControlException, IOException {\n-    INodesInPath iip \u003d getINodesInPath(src, true);\n+    assert fsn.hasWriteLock();\n+\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n     INodeFile file \u003d iip.getLastINode().asFile();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n-    boolean onBlockBoundary \u003d\n-        unprotectedTruncate(iip, newLength, collectedBlocks, mtime, null);\n+    boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n+        collectedBlocks, mtime, null);\n \n-    if(! onBlockBoundary) {\n+    if (!onBlockBoundary) {\n       BlockInfo oldBlock \u003d file.getLastBlock();\n-      Block tBlk \u003d\n-      getFSNamesystem().prepareFileForTruncate(iip,\n-          clientName, clientMachine, file.computeFileSize() - newLength,\n-          truncateBlock);\n+      Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n+          file.computeFileSize() - newLength, truncateBlock);\n       assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n           tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n           \"Should be the same block.\";\n-      if(oldBlock.getBlockId() !\u003d tBlk.getBlockId() \u0026\u0026\n-         !file.isBlockInLatestSnapshot(oldBlock)) {\n-        getBlockManager().removeBlockFromMap(oldBlock);\n+      if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n+          \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n+        fsn.getBlockManager().removeBlockFromMap(oldBlock);\n       }\n     }\n     assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n       \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n-    getFSNamesystem().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n+    fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n      final String clientName, final String clientMachine,\n      final long newLength, final long mtime, final Block truncateBlock)\n      throws UnresolvedLinkException, QuotaExceededException,\n      SnapshotAccessControlException, IOException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n    INodeFile file \u003d iip.getLastINode().asFile();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n        collectedBlocks, mtime, null);\n\n    if (!onBlockBoundary) {\n      BlockInfo oldBlock \u003d file.getLastBlock();\n      Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n          file.computeFileSize() - newLength, truncateBlock);\n      assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n          tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n          \"Should be the same block.\";\n      if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n          \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n        fsn.getBlockManager().removeBlockFromMap(oldBlock);\n      }\n    }\n    assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n      \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n    fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
            "oldMethodName": "unprotectedTruncate",
            "newMethodName": "unprotectedTruncate"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
          "commitDate": "29/06/15 4:45 PM",
          "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "29/06/15 2:56 PM",
          "commitNameOld": "8e333720e13428a4d0d0f65692102f8f2e5da98d",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,30 @@\n-  void unprotectedTruncate(String src, String clientName, String clientMachine,\n-                           long newLength, long mtime, Block truncateBlock)\n+  static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n+      final String clientName, final String clientMachine,\n+      final long newLength, final long mtime, final Block truncateBlock)\n       throws UnresolvedLinkException, QuotaExceededException,\n       SnapshotAccessControlException, IOException {\n-    INodesInPath iip \u003d getINodesInPath(src, true);\n+    assert fsn.hasWriteLock();\n+\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n     INodeFile file \u003d iip.getLastINode().asFile();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n-    boolean onBlockBoundary \u003d\n-        unprotectedTruncate(iip, newLength, collectedBlocks, mtime, null);\n+    boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n+        collectedBlocks, mtime, null);\n \n-    if(! onBlockBoundary) {\n+    if (!onBlockBoundary) {\n       BlockInfo oldBlock \u003d file.getLastBlock();\n-      Block tBlk \u003d\n-      getFSNamesystem().prepareFileForTruncate(iip,\n-          clientName, clientMachine, file.computeFileSize() - newLength,\n-          truncateBlock);\n+      Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n+          file.computeFileSize() - newLength, truncateBlock);\n       assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n           tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n           \"Should be the same block.\";\n-      if(oldBlock.getBlockId() !\u003d tBlk.getBlockId() \u0026\u0026\n-         !file.isBlockInLatestSnapshot(oldBlock)) {\n-        getBlockManager().removeBlockFromMap(oldBlock);\n+      if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n+          \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n+        fsn.getBlockManager().removeBlockFromMap(oldBlock);\n       }\n     }\n     assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n       \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n-    getFSNamesystem().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n+    fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n      final String clientName, final String clientMachine,\n      final long newLength, final long mtime, final Block truncateBlock)\n      throws UnresolvedLinkException, QuotaExceededException,\n      SnapshotAccessControlException, IOException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n    INodeFile file \u003d iip.getLastINode().asFile();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n        collectedBlocks, mtime, null);\n\n    if (!onBlockBoundary) {\n      BlockInfo oldBlock \u003d file.getLastBlock();\n      Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n          file.computeFileSize() - newLength, truncateBlock);\n      assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n          tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n          \"Should be the same block.\";\n      if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n          \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n        fsn.getBlockManager().removeBlockFromMap(oldBlock);\n      }\n    }\n    assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n      \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n    fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {
            "oldValue": "[]",
            "newValue": "[static]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
          "commitDate": "29/06/15 4:45 PM",
          "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "29/06/15 2:56 PM",
          "commitNameOld": "8e333720e13428a4d0d0f65692102f8f2e5da98d",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,30 @@\n-  void unprotectedTruncate(String src, String clientName, String clientMachine,\n-                           long newLength, long mtime, Block truncateBlock)\n+  static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n+      final String clientName, final String clientMachine,\n+      final long newLength, final long mtime, final Block truncateBlock)\n       throws UnresolvedLinkException, QuotaExceededException,\n       SnapshotAccessControlException, IOException {\n-    INodesInPath iip \u003d getINodesInPath(src, true);\n+    assert fsn.hasWriteLock();\n+\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n     INodeFile file \u003d iip.getLastINode().asFile();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n-    boolean onBlockBoundary \u003d\n-        unprotectedTruncate(iip, newLength, collectedBlocks, mtime, null);\n+    boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n+        collectedBlocks, mtime, null);\n \n-    if(! onBlockBoundary) {\n+    if (!onBlockBoundary) {\n       BlockInfo oldBlock \u003d file.getLastBlock();\n-      Block tBlk \u003d\n-      getFSNamesystem().prepareFileForTruncate(iip,\n-          clientName, clientMachine, file.computeFileSize() - newLength,\n-          truncateBlock);\n+      Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n+          file.computeFileSize() - newLength, truncateBlock);\n       assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n           tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n           \"Should be the same block.\";\n-      if(oldBlock.getBlockId() !\u003d tBlk.getBlockId() \u0026\u0026\n-         !file.isBlockInLatestSnapshot(oldBlock)) {\n-        getBlockManager().removeBlockFromMap(oldBlock);\n+      if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n+          \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n+        fsn.getBlockManager().removeBlockFromMap(oldBlock);\n       }\n     }\n     assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n       \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n-    getFSNamesystem().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n+    fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n      final String clientName, final String clientMachine,\n      final long newLength, final long mtime, final Block truncateBlock)\n      throws UnresolvedLinkException, QuotaExceededException,\n      SnapshotAccessControlException, IOException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n    INodeFile file \u003d iip.getLastINode().asFile();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n        collectedBlocks, mtime, null);\n\n    if (!onBlockBoundary) {\n      BlockInfo oldBlock \u003d file.getLastBlock();\n      Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n          file.computeFileSize() - newLength, truncateBlock);\n      assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n          tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n          \"Should be the same block.\";\n      if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n          \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n        fsn.getBlockManager().removeBlockFromMap(oldBlock);\n      }\n    }\n    assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n      \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n    fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparametermetachange",
          "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
          "commitDate": "29/06/15 4:45 PM",
          "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "29/06/15 2:56 PM",
          "commitNameOld": "8e333720e13428a4d0d0f65692102f8f2e5da98d",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,30 @@\n-  void unprotectedTruncate(String src, String clientName, String clientMachine,\n-                           long newLength, long mtime, Block truncateBlock)\n+  static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n+      final String clientName, final String clientMachine,\n+      final long newLength, final long mtime, final Block truncateBlock)\n       throws UnresolvedLinkException, QuotaExceededException,\n       SnapshotAccessControlException, IOException {\n-    INodesInPath iip \u003d getINodesInPath(src, true);\n+    assert fsn.hasWriteLock();\n+\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n     INodeFile file \u003d iip.getLastINode().asFile();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n-    boolean onBlockBoundary \u003d\n-        unprotectedTruncate(iip, newLength, collectedBlocks, mtime, null);\n+    boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n+        collectedBlocks, mtime, null);\n \n-    if(! onBlockBoundary) {\n+    if (!onBlockBoundary) {\n       BlockInfo oldBlock \u003d file.getLastBlock();\n-      Block tBlk \u003d\n-      getFSNamesystem().prepareFileForTruncate(iip,\n-          clientName, clientMachine, file.computeFileSize() - newLength,\n-          truncateBlock);\n+      Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n+          file.computeFileSize() - newLength, truncateBlock);\n       assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n           tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n           \"Should be the same block.\";\n-      if(oldBlock.getBlockId() !\u003d tBlk.getBlockId() \u0026\u0026\n-         !file.isBlockInLatestSnapshot(oldBlock)) {\n-        getBlockManager().removeBlockFromMap(oldBlock);\n+      if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n+          \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n+        fsn.getBlockManager().removeBlockFromMap(oldBlock);\n       }\n     }\n     assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n       \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n-    getFSNamesystem().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n+    fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n      final String clientName, final String clientMachine,\n      final long newLength, final long mtime, final Block truncateBlock)\n      throws UnresolvedLinkException, QuotaExceededException,\n      SnapshotAccessControlException, IOException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n    INodeFile file \u003d iip.getLastINode().asFile();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n        collectedBlocks, mtime, null);\n\n    if (!onBlockBoundary) {\n      BlockInfo oldBlock \u003d file.getLastBlock();\n      Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n          file.computeFileSize() - newLength, truncateBlock);\n      assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n          tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n          \"Should be the same block.\";\n      if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n          \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n        fsn.getBlockManager().removeBlockFromMap(oldBlock);\n      }\n    }\n    assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n      \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n    fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {
            "oldValue": "[src-String, clientName-String, clientMachine-String, newLength-long, mtime-long, truncateBlock-Block]",
            "newValue": "[fsn-FSNamesystem(modifiers-final), src-String(modifiers-final), clientName-String(modifiers-final), clientMachine-String(modifiers-final), newLength-long(modifiers-final), mtime-long(modifiers-final), truncateBlock-Block(modifiers-final)]"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-8493. Consolidate truncate() related implementation in a single class. Contributed by Rakesh R.\n",
          "commitDate": "29/06/15 4:45 PM",
          "commitName": "d3797f9f3cf502b7bfee3b64c641807b276c6faf",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "29/06/15 2:56 PM",
          "commitNameOld": "8e333720e13428a4d0d0f65692102f8f2e5da98d",
          "commitAuthorOld": "Arpit Agarwal",
          "daysBetweenCommits": 0.08,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,28 +1,30 @@\n-  void unprotectedTruncate(String src, String clientName, String clientMachine,\n-                           long newLength, long mtime, Block truncateBlock)\n+  static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n+      final String clientName, final String clientMachine,\n+      final long newLength, final long mtime, final Block truncateBlock)\n       throws UnresolvedLinkException, QuotaExceededException,\n       SnapshotAccessControlException, IOException {\n-    INodesInPath iip \u003d getINodesInPath(src, true);\n+    assert fsn.hasWriteLock();\n+\n+    FSDirectory fsd \u003d fsn.getFSDirectory();\n+    INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n     INodeFile file \u003d iip.getLastINode().asFile();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n-    boolean onBlockBoundary \u003d\n-        unprotectedTruncate(iip, newLength, collectedBlocks, mtime, null);\n+    boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n+        collectedBlocks, mtime, null);\n \n-    if(! onBlockBoundary) {\n+    if (!onBlockBoundary) {\n       BlockInfo oldBlock \u003d file.getLastBlock();\n-      Block tBlk \u003d\n-      getFSNamesystem().prepareFileForTruncate(iip,\n-          clientName, clientMachine, file.computeFileSize() - newLength,\n-          truncateBlock);\n+      Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n+          file.computeFileSize() - newLength, truncateBlock);\n       assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n           tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n           \"Should be the same block.\";\n-      if(oldBlock.getBlockId() !\u003d tBlk.getBlockId() \u0026\u0026\n-         !file.isBlockInLatestSnapshot(oldBlock)) {\n-        getBlockManager().removeBlockFromMap(oldBlock);\n+      if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n+          \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n+        fsn.getBlockManager().removeBlockFromMap(oldBlock);\n       }\n     }\n     assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n       \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n-    getFSNamesystem().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n+    fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  static void unprotectedTruncate(final FSNamesystem fsn, final String src,\n      final String clientName, final String clientMachine,\n      final long newLength, final long mtime, final Block truncateBlock)\n      throws UnresolvedLinkException, QuotaExceededException,\n      SnapshotAccessControlException, IOException {\n    assert fsn.hasWriteLock();\n\n    FSDirectory fsd \u003d fsn.getFSDirectory();\n    INodesInPath iip \u003d fsd.getINodesInPath(src, true);\n    INodeFile file \u003d iip.getLastINode().asFile();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d unprotectedTruncate(fsn, iip, newLength,\n        collectedBlocks, mtime, null);\n\n    if (!onBlockBoundary) {\n      BlockInfo oldBlock \u003d file.getLastBlock();\n      Block tBlk \u003d prepareFileForTruncate(fsn, iip, clientName, clientMachine,\n          file.computeFileSize() - newLength, truncateBlock);\n      assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n          tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n          \"Should be the same block.\";\n      if (oldBlock.getBlockId() !\u003d tBlk.getBlockId()\n          \u0026\u0026 !file.isBlockInLatestSnapshot(oldBlock)) {\n        fsn.getBlockManager().removeBlockFromMap(oldBlock);\n      }\n    }\n    assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n      \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n    fsn.removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirTruncateOp.java",
          "extendedDetails": {
            "oldValue": "[src-String, clientName-String, clientMachine-String, newLength-long, mtime-long, truncateBlock-Block]",
            "newValue": "[fsn-FSNamesystem(modifiers-final), src-String(modifiers-final), clientName-String(modifiers-final), clientMachine-String(modifiers-final), newLength-long(modifiers-final), mtime-long(modifiers-final), truncateBlock-Block(modifiers-final)]"
          }
        }
      ]
    },
    "4928f5473394981829e5ffd4b16ea0801baf5c45": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8482. Rename BlockInfoContiguous to BlockInfo. Contributed by Zhe Zhang.\n",
      "commitDate": "27/05/15 3:42 PM",
      "commitName": "4928f5473394981829e5ffd4b16ea0801baf5c45",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "21/05/15 8:08 AM",
      "commitNameOld": "2b6bcfdafa91223a4116e3e9304579f5f91dccac",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 6.32,
      "commitsBetweenForRepo": 32,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n   void unprotectedTruncate(String src, String clientName, String clientMachine,\n                            long newLength, long mtime, Block truncateBlock)\n       throws UnresolvedLinkException, QuotaExceededException,\n       SnapshotAccessControlException, IOException {\n     INodesInPath iip \u003d getINodesInPath(src, true);\n     INodeFile file \u003d iip.getLastINode().asFile();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     boolean onBlockBoundary \u003d\n         unprotectedTruncate(iip, newLength, collectedBlocks, mtime, null);\n \n     if(! onBlockBoundary) {\n-      BlockInfoContiguous oldBlock \u003d file.getLastBlock();\n+      BlockInfo oldBlock \u003d file.getLastBlock();\n       Block tBlk \u003d\n       getFSNamesystem().prepareFileForTruncate(iip,\n           clientName, clientMachine, file.computeFileSize() - newLength,\n           truncateBlock);\n       assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n           tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n           \"Should be the same block.\";\n       if(oldBlock.getBlockId() !\u003d tBlk.getBlockId() \u0026\u0026\n          !file.isBlockInLatestSnapshot(oldBlock)) {\n         getBlockManager().removeBlockFromMap(oldBlock);\n       }\n     }\n     assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n       \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n     getFSNamesystem().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void unprotectedTruncate(String src, String clientName, String clientMachine,\n                           long newLength, long mtime, Block truncateBlock)\n      throws UnresolvedLinkException, QuotaExceededException,\n      SnapshotAccessControlException, IOException {\n    INodesInPath iip \u003d getINodesInPath(src, true);\n    INodeFile file \u003d iip.getLastINode().asFile();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d\n        unprotectedTruncate(iip, newLength, collectedBlocks, mtime, null);\n\n    if(! onBlockBoundary) {\n      BlockInfo oldBlock \u003d file.getLastBlock();\n      Block tBlk \u003d\n      getFSNamesystem().prepareFileForTruncate(iip,\n          clientName, clientMachine, file.computeFileSize() - newLength,\n          truncateBlock);\n      assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n          tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n          \"Should be the same block.\";\n      if(oldBlock.getBlockId() !\u003d tBlk.getBlockId() \u0026\u0026\n         !file.isBlockInLatestSnapshot(oldBlock)) {\n        getBlockManager().removeBlockFromMap(oldBlock);\n      }\n    }\n    assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n      \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n    getFSNamesystem().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "d368d3647a858644b9fcd3be33d9fea2a6962f69": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7957. Truncate should verify quota before making changes. Contributed by Jing Zhao.\n",
      "commitDate": "20/03/15 11:50 AM",
      "commitName": "d368d3647a858644b9fcd3be33d9fea2a6962f69",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "21/02/15 3:38 PM",
      "commitNameOld": "8b465b4b8caed31ca9daeaae108f9a868a30a455",
      "commitAuthorOld": "Arpit Agarwal",
      "daysBetweenCommits": 26.8,
      "commitsBetweenForRepo": 228,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n   void unprotectedTruncate(String src, String clientName, String clientMachine,\n                            long newLength, long mtime, Block truncateBlock)\n       throws UnresolvedLinkException, QuotaExceededException,\n       SnapshotAccessControlException, IOException {\n     INodesInPath iip \u003d getINodesInPath(src, true);\n     INodeFile file \u003d iip.getLastINode().asFile();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     boolean onBlockBoundary \u003d\n-        unprotectedTruncate(iip, newLength, collectedBlocks, mtime);\n+        unprotectedTruncate(iip, newLength, collectedBlocks, mtime, null);\n \n     if(! onBlockBoundary) {\n       BlockInfoContiguous oldBlock \u003d file.getLastBlock();\n       Block tBlk \u003d\n       getFSNamesystem().prepareFileForTruncate(iip,\n           clientName, clientMachine, file.computeFileSize() - newLength,\n           truncateBlock);\n       assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n           tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n           \"Should be the same block.\";\n       if(oldBlock.getBlockId() !\u003d tBlk.getBlockId() \u0026\u0026\n          !file.isBlockInLatestSnapshot(oldBlock)) {\n         getBlockManager().removeBlockFromMap(oldBlock);\n       }\n     }\n     assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n       \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n     getFSNamesystem().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void unprotectedTruncate(String src, String clientName, String clientMachine,\n                           long newLength, long mtime, Block truncateBlock)\n      throws UnresolvedLinkException, QuotaExceededException,\n      SnapshotAccessControlException, IOException {\n    INodesInPath iip \u003d getINodesInPath(src, true);\n    INodeFile file \u003d iip.getLastINode().asFile();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d\n        unprotectedTruncate(iip, newLength, collectedBlocks, mtime, null);\n\n    if(! onBlockBoundary) {\n      BlockInfoContiguous oldBlock \u003d file.getLastBlock();\n      Block tBlk \u003d\n      getFSNamesystem().prepareFileForTruncate(iip,\n          clientName, clientMachine, file.computeFileSize() - newLength,\n          truncateBlock);\n      assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n          tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n          \"Should be the same block.\";\n      if(oldBlock.getBlockId() !\u003d tBlk.getBlockId() \u0026\u0026\n         !file.isBlockInLatestSnapshot(oldBlock)) {\n        getBlockManager().removeBlockFromMap(oldBlock);\n      }\n    }\n    assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n      \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n    getFSNamesystem().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "1382ae525c67bf95d8f3a436b547dbc72cfbb177": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-7743. Code cleanup of BlockInfo and rename BlockInfo to BlockInfoContiguous. Contributed by Jing Zhao.\n",
      "commitDate": "08/02/15 11:51 AM",
      "commitName": "1382ae525c67bf95d8f3a436b547dbc72cfbb177",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "02/02/15 4:32 PM",
      "commitNameOld": "8cb473124c1cf1c6f68ead7bde06558ebf7ce47e",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 5.8,
      "commitsBetweenForRepo": 69,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,28 +1,28 @@\n   void unprotectedTruncate(String src, String clientName, String clientMachine,\n                            long newLength, long mtime, Block truncateBlock)\n       throws UnresolvedLinkException, QuotaExceededException,\n       SnapshotAccessControlException, IOException {\n     INodesInPath iip \u003d getINodesInPath(src, true);\n     INodeFile file \u003d iip.getLastINode().asFile();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     boolean onBlockBoundary \u003d\n         unprotectedTruncate(iip, newLength, collectedBlocks, mtime);\n \n     if(! onBlockBoundary) {\n-      BlockInfo oldBlock \u003d file.getLastBlock();\n+      BlockInfoContiguous oldBlock \u003d file.getLastBlock();\n       Block tBlk \u003d\n       getFSNamesystem().prepareFileForTruncate(iip,\n           clientName, clientMachine, file.computeFileSize() - newLength,\n           truncateBlock);\n       assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n           tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n           \"Should be the same block.\";\n       if(oldBlock.getBlockId() !\u003d tBlk.getBlockId() \u0026\u0026\n          !file.isBlockInLatestSnapshot(oldBlock)) {\n         getBlockManager().removeBlockFromMap(oldBlock);\n       }\n     }\n     assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n       \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n     getFSNamesystem().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  void unprotectedTruncate(String src, String clientName, String clientMachine,\n                           long newLength, long mtime, Block truncateBlock)\n      throws UnresolvedLinkException, QuotaExceededException,\n      SnapshotAccessControlException, IOException {\n    INodesInPath iip \u003d getINodesInPath(src, true);\n    INodeFile file \u003d iip.getLastINode().asFile();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d\n        unprotectedTruncate(iip, newLength, collectedBlocks, mtime);\n\n    if(! onBlockBoundary) {\n      BlockInfoContiguous oldBlock \u003d file.getLastBlock();\n      Block tBlk \u003d\n      getFSNamesystem().prepareFileForTruncate(iip,\n          clientName, clientMachine, file.computeFileSize() - newLength,\n          truncateBlock);\n      assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n          tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n          \"Should be the same block.\";\n      if(oldBlock.getBlockId() !\u003d tBlk.getBlockId() \u0026\u0026\n         !file.isBlockInLatestSnapshot(oldBlock)) {\n        getBlockManager().removeBlockFromMap(oldBlock);\n      }\n    }\n    assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n      \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n    getFSNamesystem().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
      "extendedDetails": {}
    },
    "08ac06283a3e9bf0d49d873823aabd419b08e41f": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-7056. Snapshot support for truncate. Contributed by Konstantin Shvachko and Plamen Jeliazkov.",
      "commitDate": "13/01/15 12:24 AM",
      "commitName": "08ac06283a3e9bf0d49d873823aabd419b08e41f",
      "commitAuthor": "Konstantin V Shvachko",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-7056. Snapshot support for truncate. Contributed by Konstantin Shvachko and Plamen Jeliazkov.",
          "commitDate": "13/01/15 12:24 AM",
          "commitName": "08ac06283a3e9bf0d49d873823aabd419b08e41f",
          "commitAuthor": "Konstantin V Shvachko",
          "commitDateOld": "12/01/15 10:50 PM",
          "commitNameOld": "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
          "commitAuthorOld": "Plamen Jeliazkov",
          "daysBetweenCommits": 0.07,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,28 @@\n   void unprotectedTruncate(String src, String clientName, String clientMachine,\n-                           long newLength, long mtime)\n+                           long newLength, long mtime, Block truncateBlock)\n       throws UnresolvedLinkException, QuotaExceededException,\n       SnapshotAccessControlException, IOException {\n     INodesInPath iip \u003d getINodesInPath(src, true);\n+    INodeFile file \u003d iip.getLastINode().asFile();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     boolean onBlockBoundary \u003d\n         unprotectedTruncate(iip, newLength, collectedBlocks, mtime);\n \n     if(! onBlockBoundary) {\n-      getFSNamesystem().prepareFileForWrite(src,\n-          iip, clientName, clientMachine, false, false);\n+      BlockInfo oldBlock \u003d file.getLastBlock();\n+      Block tBlk \u003d\n+      getFSNamesystem().prepareFileForTruncate(iip,\n+          clientName, clientMachine, file.computeFileSize() - newLength,\n+          truncateBlock);\n+      assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n+          tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n+          \"Should be the same block.\";\n+      if(oldBlock.getBlockId() !\u003d tBlk.getBlockId() \u0026\u0026\n+         !file.isBlockInLatestSnapshot(oldBlock)) {\n+        getBlockManager().removeBlockFromMap(oldBlock);\n+      }\n     }\n+    assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n+      \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n     getFSNamesystem().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void unprotectedTruncate(String src, String clientName, String clientMachine,\n                           long newLength, long mtime, Block truncateBlock)\n      throws UnresolvedLinkException, QuotaExceededException,\n      SnapshotAccessControlException, IOException {\n    INodesInPath iip \u003d getINodesInPath(src, true);\n    INodeFile file \u003d iip.getLastINode().asFile();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d\n        unprotectedTruncate(iip, newLength, collectedBlocks, mtime);\n\n    if(! onBlockBoundary) {\n      BlockInfo oldBlock \u003d file.getLastBlock();\n      Block tBlk \u003d\n      getFSNamesystem().prepareFileForTruncate(iip,\n          clientName, clientMachine, file.computeFileSize() - newLength,\n          truncateBlock);\n      assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n          tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n          \"Should be the same block.\";\n      if(oldBlock.getBlockId() !\u003d tBlk.getBlockId() \u0026\u0026\n         !file.isBlockInLatestSnapshot(oldBlock)) {\n        getBlockManager().removeBlockFromMap(oldBlock);\n      }\n    }\n    assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n      \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n    getFSNamesystem().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {
            "oldValue": "[src-String, clientName-String, clientMachine-String, newLength-long, mtime-long]",
            "newValue": "[src-String, clientName-String, clientMachine-String, newLength-long, mtime-long, truncateBlock-Block]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-7056. Snapshot support for truncate. Contributed by Konstantin Shvachko and Plamen Jeliazkov.",
          "commitDate": "13/01/15 12:24 AM",
          "commitName": "08ac06283a3e9bf0d49d873823aabd419b08e41f",
          "commitAuthor": "Konstantin V Shvachko",
          "commitDateOld": "12/01/15 10:50 PM",
          "commitNameOld": "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
          "commitAuthorOld": "Plamen Jeliazkov",
          "daysBetweenCommits": 0.07,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,15 +1,28 @@\n   void unprotectedTruncate(String src, String clientName, String clientMachine,\n-                           long newLength, long mtime)\n+                           long newLength, long mtime, Block truncateBlock)\n       throws UnresolvedLinkException, QuotaExceededException,\n       SnapshotAccessControlException, IOException {\n     INodesInPath iip \u003d getINodesInPath(src, true);\n+    INodeFile file \u003d iip.getLastINode().asFile();\n     BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n     boolean onBlockBoundary \u003d\n         unprotectedTruncate(iip, newLength, collectedBlocks, mtime);\n \n     if(! onBlockBoundary) {\n-      getFSNamesystem().prepareFileForWrite(src,\n-          iip, clientName, clientMachine, false, false);\n+      BlockInfo oldBlock \u003d file.getLastBlock();\n+      Block tBlk \u003d\n+      getFSNamesystem().prepareFileForTruncate(iip,\n+          clientName, clientMachine, file.computeFileSize() - newLength,\n+          truncateBlock);\n+      assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n+          tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n+          \"Should be the same block.\";\n+      if(oldBlock.getBlockId() !\u003d tBlk.getBlockId() \u0026\u0026\n+         !file.isBlockInLatestSnapshot(oldBlock)) {\n+        getBlockManager().removeBlockFromMap(oldBlock);\n+      }\n     }\n+    assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n+      \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n     getFSNamesystem().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  void unprotectedTruncate(String src, String clientName, String clientMachine,\n                           long newLength, long mtime, Block truncateBlock)\n      throws UnresolvedLinkException, QuotaExceededException,\n      SnapshotAccessControlException, IOException {\n    INodesInPath iip \u003d getINodesInPath(src, true);\n    INodeFile file \u003d iip.getLastINode().asFile();\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d\n        unprotectedTruncate(iip, newLength, collectedBlocks, mtime);\n\n    if(! onBlockBoundary) {\n      BlockInfo oldBlock \u003d file.getLastBlock();\n      Block tBlk \u003d\n      getFSNamesystem().prepareFileForTruncate(iip,\n          clientName, clientMachine, file.computeFileSize() - newLength,\n          truncateBlock);\n      assert Block.matchingIdAndGenStamp(tBlk, truncateBlock) \u0026\u0026\n          tBlk.getNumBytes() \u003d\u003d truncateBlock.getNumBytes() :\n          \"Should be the same block.\";\n      if(oldBlock.getBlockId() !\u003d tBlk.getBlockId() \u0026\u0026\n         !file.isBlockInLatestSnapshot(oldBlock)) {\n        getBlockManager().removeBlockFromMap(oldBlock);\n      }\n    }\n    assert onBlockBoundary \u003d\u003d (truncateBlock \u003d\u003d null) :\n      \"truncateBlock is null iff on block boundary: \" + truncateBlock;\n    getFSNamesystem().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java",
          "extendedDetails": {}
        }
      ]
    },
    "7e9358feb326d48b8c4f00249e7af5023cebd2e2": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3107. Introduce truncate. Contributed by Plamen Jeliazkov.",
      "commitDate": "12/01/15 10:50 PM",
      "commitName": "7e9358feb326d48b8c4f00249e7af5023cebd2e2",
      "commitAuthor": "Plamen Jeliazkov",
      "diff": "@@ -0,0 +1,15 @@\n+  void unprotectedTruncate(String src, String clientName, String clientMachine,\n+                           long newLength, long mtime)\n+      throws UnresolvedLinkException, QuotaExceededException,\n+      SnapshotAccessControlException, IOException {\n+    INodesInPath iip \u003d getINodesInPath(src, true);\n+    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n+    boolean onBlockBoundary \u003d\n+        unprotectedTruncate(iip, newLength, collectedBlocks, mtime);\n+\n+    if(! onBlockBoundary) {\n+      getFSNamesystem().prepareFileForWrite(src,\n+          iip, clientName, clientMachine, false, false);\n+    }\n+    getFSNamesystem().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  void unprotectedTruncate(String src, String clientName, String clientMachine,\n                           long newLength, long mtime)\n      throws UnresolvedLinkException, QuotaExceededException,\n      SnapshotAccessControlException, IOException {\n    INodesInPath iip \u003d getINodesInPath(src, true);\n    BlocksMapUpdateInfo collectedBlocks \u003d new BlocksMapUpdateInfo();\n    boolean onBlockBoundary \u003d\n        unprotectedTruncate(iip, newLength, collectedBlocks, mtime);\n\n    if(! onBlockBoundary) {\n      getFSNamesystem().prepareFileForWrite(src,\n          iip, clientName, clientMachine, false, false);\n    }\n    getFSNamesystem().removeBlocksAndUpdateSafemodeTotal(collectedBlocks);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java"
    }
  }
}