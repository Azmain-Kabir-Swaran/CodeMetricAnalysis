{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "S3AMultipartUploader.java",
  "functionName": "buildPartHandlePayload",
  "functionId": "buildPartHandlePayload___eTag-String__len-long",
  "sourceFilePath": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AMultipartUploader.java",
  "functionStartLine": 175,
  "functionEndLine": 189,
  "numCommitsSeen": 5,
  "timeTaken": 1340,
  "changeHistory": [
    "c1d24f848345f6d34a2ac2d570d49e9787a0df6a",
    "2ec97abb2e93c1a8127e7a146c08e26454b583fa"
  ],
  "changeHistoryShort": {
    "c1d24f848345f6d34a2ac2d570d49e9787a0df6a": "Ybodychange",
    "2ec97abb2e93c1a8127e7a146c08e26454b583fa": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c1d24f848345f6d34a2ac2d570d49e9787a0df6a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13713. Add specification of Multipart Upload API to FS specification, with contract tests.\n\nContributed by Ewan Higgs and Steve Loughran.\n",
      "commitDate": "29/11/18 7:12 AM",
      "commitName": "c1d24f848345f6d34a2ac2d570d49e9787a0df6a",
      "commitAuthor": "Ewan Higgs",
      "commitDateOld": "24/09/18 8:49 AM",
      "commitNameOld": "d060cbea48ffc75da0f4fa98c3ea5203d6db1360",
      "commitAuthorOld": "Sunil G",
      "daysBetweenCommits": 65.97,
      "commitsBetweenForRepo": 566,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,15 +1,15 @@\n   static byte[] buildPartHandlePayload(String eTag, long len)\n       throws IOException {\n     Preconditions.checkArgument(StringUtils.isNotEmpty(eTag),\n         \"Empty etag\");\n-    Preconditions.checkArgument(len \u003e 0,\n+    Preconditions.checkArgument(len \u003e\u003d 0,\n         \"Invalid length\");\n \n     ByteArrayOutputStream bytes \u003d new ByteArrayOutputStream();\n     try(DataOutputStream output \u003d new DataOutputStream(bytes)) {\n       output.writeUTF(HEADER);\n       output.writeLong(len);\n       output.writeUTF(eTag);\n     }\n     return bytes.toByteArray();\n   }\n\\ No newline at end of file\n",
      "actualSource": "  static byte[] buildPartHandlePayload(String eTag, long len)\n      throws IOException {\n    Preconditions.checkArgument(StringUtils.isNotEmpty(eTag),\n        \"Empty etag\");\n    Preconditions.checkArgument(len \u003e\u003d 0,\n        \"Invalid length\");\n\n    ByteArrayOutputStream bytes \u003d new ByteArrayOutputStream();\n    try(DataOutputStream output \u003d new DataOutputStream(bytes)) {\n      output.writeUTF(HEADER);\n      output.writeLong(len);\n      output.writeUTF(eTag);\n    }\n    return bytes.toByteArray();\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AMultipartUploader.java",
      "extendedDetails": {}
    },
    "2ec97abb2e93c1a8127e7a146c08e26454b583fa": {
      "type": "Yintroduced",
      "commitMessage": "HADOOP-15576. S3A Multipart Uploader to work with S3Guard and encryption Originally contributed by Ewan Higgs with refinements by Steve Loughran.\n",
      "commitDate": "08/08/18 4:50 AM",
      "commitName": "2ec97abb2e93c1a8127e7a146c08e26454b583fa",
      "commitAuthor": "Ewan Higgs",
      "diff": "@@ -0,0 +1,15 @@\n+  static byte[] buildPartHandlePayload(String eTag, long len)\n+      throws IOException {\n+    Preconditions.checkArgument(StringUtils.isNotEmpty(eTag),\n+        \"Empty etag\");\n+    Preconditions.checkArgument(len \u003e 0,\n+        \"Invalid length\");\n+\n+    ByteArrayOutputStream bytes \u003d new ByteArrayOutputStream();\n+    try(DataOutputStream output \u003d new DataOutputStream(bytes)) {\n+      output.writeUTF(HEADER);\n+      output.writeLong(len);\n+      output.writeUTF(eTag);\n+    }\n+    return bytes.toByteArray();\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  static byte[] buildPartHandlePayload(String eTag, long len)\n      throws IOException {\n    Preconditions.checkArgument(StringUtils.isNotEmpty(eTag),\n        \"Empty etag\");\n    Preconditions.checkArgument(len \u003e 0,\n        \"Invalid length\");\n\n    ByteArrayOutputStream bytes \u003d new ByteArrayOutputStream();\n    try(DataOutputStream output \u003d new DataOutputStream(bytes)) {\n      output.writeUTF(HEADER);\n      output.writeLong(len);\n      output.writeUTF(eTag);\n    }\n    return bytes.toByteArray();\n  }",
      "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AMultipartUploader.java"
    }
  }
}