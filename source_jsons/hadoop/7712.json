{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "FSImageFormatProtobuf.java",
  "functionName": "load",
  "functionId": "load___file-File",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java",
  "functionStartLine": 237,
  "functionEndLine": 258,
  "numCommitsSeen": 38,
  "timeTaken": 3875,
  "changeHistory": [
    "b67812ea2111fa11bdd76096b923c93e1bdf2923",
    "9c907294860a48f0d1676a31bda15795b7a6771a",
    "af9bdbe447b119bff10ec5281993bfc36b6dea71",
    "66c5bcfc6df4dfe824b664be302f5ee3193b7187",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305"
  ],
  "changeHistoryShort": {
    "b67812ea2111fa11bdd76096b923c93e1bdf2923": "Ybodychange",
    "9c907294860a48f0d1676a31bda15795b7a6771a": "Ybodychange",
    "af9bdbe447b119bff10ec5281993bfc36b6dea71": "Ybodychange",
    "66c5bcfc6df4dfe824b664be302f5ee3193b7187": "Ybodychange",
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": "Yintroduced"
  },
  "changeHistoryDetails": {
    "b67812ea2111fa11bdd76096b923c93e1bdf2923": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-14617. Improve fsimage load time by writing sub-sections to the fsimage index (#1028). Contributed by  Stephen O\u0027Donnell.\n\nReviewed-by: He Xiaoqiao \u003chexiaoqiao@apache.org\u003e",
      "commitDate": "22/08/19 5:09 PM",
      "commitName": "b67812ea2111fa11bdd76096b923c93e1bdf2923",
      "commitAuthor": "Stephen O\u0027Donnell",
      "commitDateOld": "05/07/19 10:17 AM",
      "commitNameOld": "9c907294860a48f0d1676a31bda15795b7a6771a",
      "commitAuthorOld": "leosunli",
      "daysBetweenCommits": 48.29,
      "commitsBetweenForRepo": 420,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,21 +1,22 @@\n     void load(File file) throws IOException {\n+      filename \u003d file;\n       long start \u003d Time.monotonicNow();\n       DigestThread dt \u003d new DigestThread(file);\n       dt.start();\n       RandomAccessFile raFile \u003d new RandomAccessFile(file, \"r\");\n       FileInputStream fin \u003d new FileInputStream(file);\n       try {\n         loadInternal(raFile, fin);\n         try {\n           dt.join();\n           imgDigest \u003d dt.getDigest();\n         } catch (InterruptedException ie) {\n           throw new IOException(ie);\n         }\n         long end \u003d Time.monotonicNow();\n         LOG.info(\"Loaded FSImage in {} seconds.\", (end - start) / 1000);\n       } finally {\n         fin.close();\n         raFile.close();\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File file) throws IOException {\n      filename \u003d file;\n      long start \u003d Time.monotonicNow();\n      DigestThread dt \u003d new DigestThread(file);\n      dt.start();\n      RandomAccessFile raFile \u003d new RandomAccessFile(file, \"r\");\n      FileInputStream fin \u003d new FileInputStream(file);\n      try {\n        loadInternal(raFile, fin);\n        try {\n          dt.join();\n          imgDigest \u003d dt.getDigest();\n        } catch (InterruptedException ie) {\n          throw new IOException(ie);\n        }\n        long end \u003d Time.monotonicNow();\n        LOG.info(\"Loaded FSImage in {} seconds.\", (end - start) / 1000);\n      } finally {\n        fin.close();\n        raFile.close();\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java",
      "extendedDetails": {}
    },
    "9c907294860a48f0d1676a31bda15795b7a6771a": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-13694. Making md5 computing being in parallel with image loading.\n\n",
      "commitDate": "05/07/19 10:17 AM",
      "commitName": "9c907294860a48f0d1676a31bda15795b7a6771a",
      "commitAuthor": "leosunli",
      "commitDateOld": "08/02/19 4:51 AM",
      "commitNameOld": "177131793a88960b734038f6e646476d568c3626",
      "commitAuthorOld": "Yiqun Lin",
      "daysBetweenCommits": 147.18,
      "commitsBetweenForRepo": 1091,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,21 @@\n     void load(File file) throws IOException {\n       long start \u003d Time.monotonicNow();\n-      imgDigest \u003d MD5FileUtils.computeMd5ForFile(file);\n+      DigestThread dt \u003d new DigestThread(file);\n+      dt.start();\n       RandomAccessFile raFile \u003d new RandomAccessFile(file, \"r\");\n       FileInputStream fin \u003d new FileInputStream(file);\n       try {\n         loadInternal(raFile, fin);\n+        try {\n+          dt.join();\n+          imgDigest \u003d dt.getDigest();\n+        } catch (InterruptedException ie) {\n+          throw new IOException(ie);\n+        }\n         long end \u003d Time.monotonicNow();\n         LOG.info(\"Loaded FSImage in {} seconds.\", (end - start) / 1000);\n       } finally {\n         fin.close();\n         raFile.close();\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File file) throws IOException {\n      long start \u003d Time.monotonicNow();\n      DigestThread dt \u003d new DigestThread(file);\n      dt.start();\n      RandomAccessFile raFile \u003d new RandomAccessFile(file, \"r\");\n      FileInputStream fin \u003d new FileInputStream(file);\n      try {\n        loadInternal(raFile, fin);\n        try {\n          dt.join();\n          imgDigest \u003d dt.getDigest();\n        } catch (InterruptedException ie) {\n          throw new IOException(ie);\n        }\n        long end \u003d Time.monotonicNow();\n        LOG.info(\"Loaded FSImage in {} seconds.\", (end - start) / 1000);\n      } finally {\n        fin.close();\n        raFile.close();\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java",
      "extendedDetails": {}
    },
    "af9bdbe447b119bff10ec5281993bfc36b6dea71": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10264. Logging improvements in FSImageFormatProtobuf.Saver. (Contributed by Xiaobing Zhou)\n",
      "commitDate": "19/04/16 11:26 AM",
      "commitName": "af9bdbe447b119bff10ec5281993bfc36b6dea71",
      "commitAuthor": "Arpit Agarwal",
      "commitDateOld": "27/01/16 4:34 PM",
      "commitNameOld": "ec25c7f9c7e60c077d8c4143253c20445fcdaecf",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 82.74,
      "commitsBetweenForRepo": 524,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n     void load(File file) throws IOException {\n       long start \u003d Time.monotonicNow();\n       imgDigest \u003d MD5FileUtils.computeMd5ForFile(file);\n       RandomAccessFile raFile \u003d new RandomAccessFile(file, \"r\");\n       FileInputStream fin \u003d new FileInputStream(file);\n       try {\n         loadInternal(raFile, fin);\n         long end \u003d Time.monotonicNow();\n-        LOG.info(\"Loaded FSImage in \" + (end - start) / 1000 + \" seconds.\");\n+        LOG.info(\"Loaded FSImage in {} seconds.\", (end - start) / 1000);\n       } finally {\n         fin.close();\n         raFile.close();\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File file) throws IOException {\n      long start \u003d Time.monotonicNow();\n      imgDigest \u003d MD5FileUtils.computeMd5ForFile(file);\n      RandomAccessFile raFile \u003d new RandomAccessFile(file, \"r\");\n      FileInputStream fin \u003d new FileInputStream(file);\n      try {\n        loadInternal(raFile, fin);\n        long end \u003d Time.monotonicNow();\n        LOG.info(\"Loaded FSImage in {} seconds.\", (end - start) / 1000);\n      } finally {\n        fin.close();\n        raFile.close();\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java",
      "extendedDetails": {}
    },
    "66c5bcfc6df4dfe824b664be302f5ee3193b7187": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6453. Use Time#monotonicNow to avoid system clock reset. Contributed by Liang Xie.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1598144 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "28/05/14 2:24 PM",
      "commitName": "66c5bcfc6df4dfe824b664be302f5ee3193b7187",
      "commitAuthor": "Andrew Wang",
      "commitDateOld": "25/02/14 1:58 PM",
      "commitNameOld": "e3d2e4c156851de7dac16154521a2e06ea83ec7b",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 91.98,
      "commitsBetweenForRepo": 614,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,14 +1,14 @@\n     void load(File file) throws IOException {\n-      long start \u003d System.currentTimeMillis();\n+      long start \u003d Time.monotonicNow();\n       imgDigest \u003d MD5FileUtils.computeMd5ForFile(file);\n       RandomAccessFile raFile \u003d new RandomAccessFile(file, \"r\");\n       FileInputStream fin \u003d new FileInputStream(file);\n       try {\n         loadInternal(raFile, fin);\n-        long end \u003d System.currentTimeMillis();\n+        long end \u003d Time.monotonicNow();\n         LOG.info(\"Loaded FSImage in \" + (end - start) / 1000 + \" seconds.\");\n       } finally {\n         fin.close();\n         raFile.close();\n       }\n     }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File file) throws IOException {\n      long start \u003d Time.monotonicNow();\n      imgDigest \u003d MD5FileUtils.computeMd5ForFile(file);\n      RandomAccessFile raFile \u003d new RandomAccessFile(file, \"r\");\n      FileInputStream fin \u003d new FileInputStream(file);\n      try {\n        loadInternal(raFile, fin);\n        long end \u003d Time.monotonicNow();\n        LOG.info(\"Loaded FSImage in \" + (end - start) / 1000 + \" seconds.\");\n      } finally {\n        fin.close();\n        raFile.close();\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java",
      "extendedDetails": {}
    },
    "a2edb11b68ae01a44092cb14ac2717a6aad93305": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-5698. Use protobuf to serialize / deserialize FSImage. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1566359 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "09/02/14 11:18 AM",
      "commitName": "a2edb11b68ae01a44092cb14ac2717a6aad93305",
      "commitAuthor": "Jing Zhao",
      "diff": "@@ -0,0 +1,14 @@\n+    void load(File file) throws IOException {\n+      long start \u003d System.currentTimeMillis();\n+      imgDigest \u003d MD5FileUtils.computeMd5ForFile(file);\n+      RandomAccessFile raFile \u003d new RandomAccessFile(file, \"r\");\n+      FileInputStream fin \u003d new FileInputStream(file);\n+      try {\n+        loadInternal(raFile, fin);\n+        long end \u003d System.currentTimeMillis();\n+        LOG.info(\"Loaded FSImage in \" + (end - start) / 1000 + \" seconds.\");\n+      } finally {\n+        fin.close();\n+        raFile.close();\n+      }\n+    }\n\\ No newline at end of file\n",
      "actualSource": "    void load(File file) throws IOException {\n      long start \u003d System.currentTimeMillis();\n      imgDigest \u003d MD5FileUtils.computeMd5ForFile(file);\n      RandomAccessFile raFile \u003d new RandomAccessFile(file, \"r\");\n      FileInputStream fin \u003d new FileInputStream(file);\n      try {\n        loadInternal(raFile, fin);\n        long end \u003d System.currentTimeMillis();\n        LOG.info(\"Loaded FSImage in \" + (end - start) / 1000 + \" seconds.\");\n      } finally {\n        fin.close();\n        raFile.close();\n      }\n    }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java"
    }
  }
}