{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "StateStoreFileBaseImpl.java",
  "functionName": "getRecord",
  "functionId": "getRecord___path-String(modifiers-final)__clazz-Class__T__(modifiers-final)",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/store/driver/impl/StateStoreFileBaseImpl.java",
  "functionStartLine": 260,
  "functionEndLine": 282,
  "numCommitsSeen": 7,
  "timeTaken": 4651,
  "changeHistory": [
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d",
    "76be6cbf6c33f866794f27ca2560ca7c7b2fa0e7",
    "4bf877b03f0e01c4bcedc689c66689701e62b560"
  ],
  "changeHistoryShort": {
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d": "Yfilerename",
    "76be6cbf6c33f866794f27ca2560ca7c7b2fa0e7": "Ymultichange(Yrename,Yparameterchange,Yreturntypechange,Ymodifierchange,Ybodychange,Yparametermetachange)",
    "4bf877b03f0e01c4bcedc689c66689701e62b560": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d": {
      "type": "Yfilerename",
      "commitMessage": "HDFS-13215. RBF: Move Router to its own module. Contributed by Wei Yan\n",
      "commitDate": "19/03/18 10:13 PM",
      "commitName": "6e2b5fa493ff8e8c2bb28e6f6f4c19347bc9b99d",
      "commitAuthor": "weiy",
      "commitDateOld": "19/03/18 5:19 PM",
      "commitNameOld": "e65ff1c8be48ef4f04ed96f96ac4caef4974944d",
      "commitAuthorOld": "Inigo Goiri",
      "daysBetweenCommits": 0.2,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "",
      "actualSource": "  private \u003cT extends BaseRecord\u003e T getRecord(\n      final String path, final Class\u003cT\u003e clazz) throws IOException {\n    BufferedReader reader \u003d getReader(path);\n    try {\n      String line;\n      while ((line \u003d reader.readLine()) !\u003d null) {\n        if (!line.startsWith(\"#\") \u0026\u0026 line.length() \u003e 0) {\n          try {\n            T record \u003d newRecord(line, clazz, false);\n            return record;\n          } catch (Exception ex) {\n            LOG.error(\"Cannot parse line {} in file {}\", line, path, ex);\n          }\n        }\n      }\n    } finally {\n      if (reader !\u003d null) {\n        reader.close();\n      }\n    }\n    throw new IOException(\"Cannot read \" + path + \" for record \" +\n        clazz.getSimpleName());\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/store/driver/impl/StateStoreFileBaseImpl.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/store/driver/impl/StateStoreFileBaseImpl.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/store/driver/impl/StateStoreFileBaseImpl.java"
      }
    },
    "76be6cbf6c33f866794f27ca2560ca7c7b2fa0e7": {
      "type": "Ymultichange(Yrename,Yparameterchange,Yreturntypechange,Ymodifierchange,Ybodychange,Yparametermetachange)",
      "commitMessage": "HDFS-12773. RBF: Improve State Store FS implementation. Contributed by Inigo Goiri.\n",
      "commitDate": "13/03/18 8:20 PM",
      "commitName": "76be6cbf6c33f866794f27ca2560ca7c7b2fa0e7",
      "commitAuthor": "Yiqun Lin",
      "subchanges": [
        {
          "type": "Yrename",
          "commitMessage": "HDFS-12773. RBF: Improve State Store FS implementation. Contributed by Inigo Goiri.\n",
          "commitDate": "13/03/18 8:20 PM",
          "commitName": "76be6cbf6c33f866794f27ca2560ca7c7b2fa0e7",
          "commitAuthor": "Yiqun Lin",
          "commitDateOld": "29/11/17 9:43 AM",
          "commitNameOld": "301641811d93ac22dc6fe1a05f18c1f266cc5e54",
          "commitAuthorOld": "Wei Yan",
          "daysBetweenCommits": 104.4,
          "commitsBetweenForRepo": 654,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,23 @@\n-  public \u003cT extends BaseRecord\u003e QueryResult\u003cT\u003e get(Class\u003cT\u003e clazz, String sub)\n-      throws IOException {\n-    verifyDriverReady();\n-    BufferedReader reader \u003d null;\n-    lockRecordRead(clazz);\n+  private \u003cT extends BaseRecord\u003e T getRecord(\n+      final String path, final Class\u003cT\u003e clazz) throws IOException {\n+    BufferedReader reader \u003d getReader(path);\n     try {\n-      reader \u003d getReader(clazz, sub);\n-      List\u003cT\u003e data \u003d getAllFile(reader, clazz, true);\n-      return new QueryResult\u003cT\u003e(data, getTime());\n-    } catch (Exception ex) {\n-      LOG.error(\"Cannot fetch records {}\", clazz.getSimpleName());\n-      throw new IOException(\"Cannot read from data store \" + ex.getMessage());\n-    } finally {\n-      if (reader !\u003d null) {\n-        try {\n-          reader.close();\n-        } catch (IOException e) {\n-          LOG.error(\"Failed closing file\", e);\n+      String line;\n+      while ((line \u003d reader.readLine()) !\u003d null) {\n+        if (!line.startsWith(\"#\") \u0026\u0026 line.length() \u003e 0) {\n+          try {\n+            T record \u003d newRecord(line, clazz, false);\n+            return record;\n+          } catch (Exception ex) {\n+            LOG.error(\"Cannot parse line {} in file {}\", line, path, ex);\n+          }\n         }\n       }\n-      unlockRecordRead(clazz);\n+    } finally {\n+      if (reader !\u003d null) {\n+        reader.close();\n+      }\n     }\n+    throw new IOException(\"Cannot read \" + path + \" for record \" +\n+        clazz.getSimpleName());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private \u003cT extends BaseRecord\u003e T getRecord(\n      final String path, final Class\u003cT\u003e clazz) throws IOException {\n    BufferedReader reader \u003d getReader(path);\n    try {\n      String line;\n      while ((line \u003d reader.readLine()) !\u003d null) {\n        if (!line.startsWith(\"#\") \u0026\u0026 line.length() \u003e 0) {\n          try {\n            T record \u003d newRecord(line, clazz, false);\n            return record;\n          } catch (Exception ex) {\n            LOG.error(\"Cannot parse line {} in file {}\", line, path, ex);\n          }\n        }\n      }\n    } finally {\n      if (reader !\u003d null) {\n        reader.close();\n      }\n    }\n    throw new IOException(\"Cannot read \" + path + \" for record \" +\n        clazz.getSimpleName());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/store/driver/impl/StateStoreFileBaseImpl.java",
          "extendedDetails": {
            "oldValue": "get",
            "newValue": "getRecord"
          }
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-12773. RBF: Improve State Store FS implementation. Contributed by Inigo Goiri.\n",
          "commitDate": "13/03/18 8:20 PM",
          "commitName": "76be6cbf6c33f866794f27ca2560ca7c7b2fa0e7",
          "commitAuthor": "Yiqun Lin",
          "commitDateOld": "29/11/17 9:43 AM",
          "commitNameOld": "301641811d93ac22dc6fe1a05f18c1f266cc5e54",
          "commitAuthorOld": "Wei Yan",
          "daysBetweenCommits": 104.4,
          "commitsBetweenForRepo": 654,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,23 @@\n-  public \u003cT extends BaseRecord\u003e QueryResult\u003cT\u003e get(Class\u003cT\u003e clazz, String sub)\n-      throws IOException {\n-    verifyDriverReady();\n-    BufferedReader reader \u003d null;\n-    lockRecordRead(clazz);\n+  private \u003cT extends BaseRecord\u003e T getRecord(\n+      final String path, final Class\u003cT\u003e clazz) throws IOException {\n+    BufferedReader reader \u003d getReader(path);\n     try {\n-      reader \u003d getReader(clazz, sub);\n-      List\u003cT\u003e data \u003d getAllFile(reader, clazz, true);\n-      return new QueryResult\u003cT\u003e(data, getTime());\n-    } catch (Exception ex) {\n-      LOG.error(\"Cannot fetch records {}\", clazz.getSimpleName());\n-      throw new IOException(\"Cannot read from data store \" + ex.getMessage());\n-    } finally {\n-      if (reader !\u003d null) {\n-        try {\n-          reader.close();\n-        } catch (IOException e) {\n-          LOG.error(\"Failed closing file\", e);\n+      String line;\n+      while ((line \u003d reader.readLine()) !\u003d null) {\n+        if (!line.startsWith(\"#\") \u0026\u0026 line.length() \u003e 0) {\n+          try {\n+            T record \u003d newRecord(line, clazz, false);\n+            return record;\n+          } catch (Exception ex) {\n+            LOG.error(\"Cannot parse line {} in file {}\", line, path, ex);\n+          }\n         }\n       }\n-      unlockRecordRead(clazz);\n+    } finally {\n+      if (reader !\u003d null) {\n+        reader.close();\n+      }\n     }\n+    throw new IOException(\"Cannot read \" + path + \" for record \" +\n+        clazz.getSimpleName());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private \u003cT extends BaseRecord\u003e T getRecord(\n      final String path, final Class\u003cT\u003e clazz) throws IOException {\n    BufferedReader reader \u003d getReader(path);\n    try {\n      String line;\n      while ((line \u003d reader.readLine()) !\u003d null) {\n        if (!line.startsWith(\"#\") \u0026\u0026 line.length() \u003e 0) {\n          try {\n            T record \u003d newRecord(line, clazz, false);\n            return record;\n          } catch (Exception ex) {\n            LOG.error(\"Cannot parse line {} in file {}\", line, path, ex);\n          }\n        }\n      }\n    } finally {\n      if (reader !\u003d null) {\n        reader.close();\n      }\n    }\n    throw new IOException(\"Cannot read \" + path + \" for record \" +\n        clazz.getSimpleName());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/store/driver/impl/StateStoreFileBaseImpl.java",
          "extendedDetails": {
            "oldValue": "[clazz-Class\u003cT\u003e, sub-String]",
            "newValue": "[path-String(modifiers-final), clazz-Class\u003cT\u003e(modifiers-final)]"
          }
        },
        {
          "type": "Yreturntypechange",
          "commitMessage": "HDFS-12773. RBF: Improve State Store FS implementation. Contributed by Inigo Goiri.\n",
          "commitDate": "13/03/18 8:20 PM",
          "commitName": "76be6cbf6c33f866794f27ca2560ca7c7b2fa0e7",
          "commitAuthor": "Yiqun Lin",
          "commitDateOld": "29/11/17 9:43 AM",
          "commitNameOld": "301641811d93ac22dc6fe1a05f18c1f266cc5e54",
          "commitAuthorOld": "Wei Yan",
          "daysBetweenCommits": 104.4,
          "commitsBetweenForRepo": 654,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,23 @@\n-  public \u003cT extends BaseRecord\u003e QueryResult\u003cT\u003e get(Class\u003cT\u003e clazz, String sub)\n-      throws IOException {\n-    verifyDriverReady();\n-    BufferedReader reader \u003d null;\n-    lockRecordRead(clazz);\n+  private \u003cT extends BaseRecord\u003e T getRecord(\n+      final String path, final Class\u003cT\u003e clazz) throws IOException {\n+    BufferedReader reader \u003d getReader(path);\n     try {\n-      reader \u003d getReader(clazz, sub);\n-      List\u003cT\u003e data \u003d getAllFile(reader, clazz, true);\n-      return new QueryResult\u003cT\u003e(data, getTime());\n-    } catch (Exception ex) {\n-      LOG.error(\"Cannot fetch records {}\", clazz.getSimpleName());\n-      throw new IOException(\"Cannot read from data store \" + ex.getMessage());\n-    } finally {\n-      if (reader !\u003d null) {\n-        try {\n-          reader.close();\n-        } catch (IOException e) {\n-          LOG.error(\"Failed closing file\", e);\n+      String line;\n+      while ((line \u003d reader.readLine()) !\u003d null) {\n+        if (!line.startsWith(\"#\") \u0026\u0026 line.length() \u003e 0) {\n+          try {\n+            T record \u003d newRecord(line, clazz, false);\n+            return record;\n+          } catch (Exception ex) {\n+            LOG.error(\"Cannot parse line {} in file {}\", line, path, ex);\n+          }\n         }\n       }\n-      unlockRecordRead(clazz);\n+    } finally {\n+      if (reader !\u003d null) {\n+        reader.close();\n+      }\n     }\n+    throw new IOException(\"Cannot read \" + path + \" for record \" +\n+        clazz.getSimpleName());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private \u003cT extends BaseRecord\u003e T getRecord(\n      final String path, final Class\u003cT\u003e clazz) throws IOException {\n    BufferedReader reader \u003d getReader(path);\n    try {\n      String line;\n      while ((line \u003d reader.readLine()) !\u003d null) {\n        if (!line.startsWith(\"#\") \u0026\u0026 line.length() \u003e 0) {\n          try {\n            T record \u003d newRecord(line, clazz, false);\n            return record;\n          } catch (Exception ex) {\n            LOG.error(\"Cannot parse line {} in file {}\", line, path, ex);\n          }\n        }\n      }\n    } finally {\n      if (reader !\u003d null) {\n        reader.close();\n      }\n    }\n    throw new IOException(\"Cannot read \" + path + \" for record \" +\n        clazz.getSimpleName());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/store/driver/impl/StateStoreFileBaseImpl.java",
          "extendedDetails": {
            "oldValue": "QueryResult\u003cT\u003e",
            "newValue": "T"
          }
        },
        {
          "type": "Ymodifierchange",
          "commitMessage": "HDFS-12773. RBF: Improve State Store FS implementation. Contributed by Inigo Goiri.\n",
          "commitDate": "13/03/18 8:20 PM",
          "commitName": "76be6cbf6c33f866794f27ca2560ca7c7b2fa0e7",
          "commitAuthor": "Yiqun Lin",
          "commitDateOld": "29/11/17 9:43 AM",
          "commitNameOld": "301641811d93ac22dc6fe1a05f18c1f266cc5e54",
          "commitAuthorOld": "Wei Yan",
          "daysBetweenCommits": 104.4,
          "commitsBetweenForRepo": 654,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,23 @@\n-  public \u003cT extends BaseRecord\u003e QueryResult\u003cT\u003e get(Class\u003cT\u003e clazz, String sub)\n-      throws IOException {\n-    verifyDriverReady();\n-    BufferedReader reader \u003d null;\n-    lockRecordRead(clazz);\n+  private \u003cT extends BaseRecord\u003e T getRecord(\n+      final String path, final Class\u003cT\u003e clazz) throws IOException {\n+    BufferedReader reader \u003d getReader(path);\n     try {\n-      reader \u003d getReader(clazz, sub);\n-      List\u003cT\u003e data \u003d getAllFile(reader, clazz, true);\n-      return new QueryResult\u003cT\u003e(data, getTime());\n-    } catch (Exception ex) {\n-      LOG.error(\"Cannot fetch records {}\", clazz.getSimpleName());\n-      throw new IOException(\"Cannot read from data store \" + ex.getMessage());\n-    } finally {\n-      if (reader !\u003d null) {\n-        try {\n-          reader.close();\n-        } catch (IOException e) {\n-          LOG.error(\"Failed closing file\", e);\n+      String line;\n+      while ((line \u003d reader.readLine()) !\u003d null) {\n+        if (!line.startsWith(\"#\") \u0026\u0026 line.length() \u003e 0) {\n+          try {\n+            T record \u003d newRecord(line, clazz, false);\n+            return record;\n+          } catch (Exception ex) {\n+            LOG.error(\"Cannot parse line {} in file {}\", line, path, ex);\n+          }\n         }\n       }\n-      unlockRecordRead(clazz);\n+    } finally {\n+      if (reader !\u003d null) {\n+        reader.close();\n+      }\n     }\n+    throw new IOException(\"Cannot read \" + path + \" for record \" +\n+        clazz.getSimpleName());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private \u003cT extends BaseRecord\u003e T getRecord(\n      final String path, final Class\u003cT\u003e clazz) throws IOException {\n    BufferedReader reader \u003d getReader(path);\n    try {\n      String line;\n      while ((line \u003d reader.readLine()) !\u003d null) {\n        if (!line.startsWith(\"#\") \u0026\u0026 line.length() \u003e 0) {\n          try {\n            T record \u003d newRecord(line, clazz, false);\n            return record;\n          } catch (Exception ex) {\n            LOG.error(\"Cannot parse line {} in file {}\", line, path, ex);\n          }\n        }\n      }\n    } finally {\n      if (reader !\u003d null) {\n        reader.close();\n      }\n    }\n    throw new IOException(\"Cannot read \" + path + \" for record \" +\n        clazz.getSimpleName());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/store/driver/impl/StateStoreFileBaseImpl.java",
          "extendedDetails": {
            "oldValue": "[public]",
            "newValue": "[private]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-12773. RBF: Improve State Store FS implementation. Contributed by Inigo Goiri.\n",
          "commitDate": "13/03/18 8:20 PM",
          "commitName": "76be6cbf6c33f866794f27ca2560ca7c7b2fa0e7",
          "commitAuthor": "Yiqun Lin",
          "commitDateOld": "29/11/17 9:43 AM",
          "commitNameOld": "301641811d93ac22dc6fe1a05f18c1f266cc5e54",
          "commitAuthorOld": "Wei Yan",
          "daysBetweenCommits": 104.4,
          "commitsBetweenForRepo": 654,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,23 @@\n-  public \u003cT extends BaseRecord\u003e QueryResult\u003cT\u003e get(Class\u003cT\u003e clazz, String sub)\n-      throws IOException {\n-    verifyDriverReady();\n-    BufferedReader reader \u003d null;\n-    lockRecordRead(clazz);\n+  private \u003cT extends BaseRecord\u003e T getRecord(\n+      final String path, final Class\u003cT\u003e clazz) throws IOException {\n+    BufferedReader reader \u003d getReader(path);\n     try {\n-      reader \u003d getReader(clazz, sub);\n-      List\u003cT\u003e data \u003d getAllFile(reader, clazz, true);\n-      return new QueryResult\u003cT\u003e(data, getTime());\n-    } catch (Exception ex) {\n-      LOG.error(\"Cannot fetch records {}\", clazz.getSimpleName());\n-      throw new IOException(\"Cannot read from data store \" + ex.getMessage());\n-    } finally {\n-      if (reader !\u003d null) {\n-        try {\n-          reader.close();\n-        } catch (IOException e) {\n-          LOG.error(\"Failed closing file\", e);\n+      String line;\n+      while ((line \u003d reader.readLine()) !\u003d null) {\n+        if (!line.startsWith(\"#\") \u0026\u0026 line.length() \u003e 0) {\n+          try {\n+            T record \u003d newRecord(line, clazz, false);\n+            return record;\n+          } catch (Exception ex) {\n+            LOG.error(\"Cannot parse line {} in file {}\", line, path, ex);\n+          }\n         }\n       }\n-      unlockRecordRead(clazz);\n+    } finally {\n+      if (reader !\u003d null) {\n+        reader.close();\n+      }\n     }\n+    throw new IOException(\"Cannot read \" + path + \" for record \" +\n+        clazz.getSimpleName());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private \u003cT extends BaseRecord\u003e T getRecord(\n      final String path, final Class\u003cT\u003e clazz) throws IOException {\n    BufferedReader reader \u003d getReader(path);\n    try {\n      String line;\n      while ((line \u003d reader.readLine()) !\u003d null) {\n        if (!line.startsWith(\"#\") \u0026\u0026 line.length() \u003e 0) {\n          try {\n            T record \u003d newRecord(line, clazz, false);\n            return record;\n          } catch (Exception ex) {\n            LOG.error(\"Cannot parse line {} in file {}\", line, path, ex);\n          }\n        }\n      }\n    } finally {\n      if (reader !\u003d null) {\n        reader.close();\n      }\n    }\n    throw new IOException(\"Cannot read \" + path + \" for record \" +\n        clazz.getSimpleName());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/store/driver/impl/StateStoreFileBaseImpl.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparametermetachange",
          "commitMessage": "HDFS-12773. RBF: Improve State Store FS implementation. Contributed by Inigo Goiri.\n",
          "commitDate": "13/03/18 8:20 PM",
          "commitName": "76be6cbf6c33f866794f27ca2560ca7c7b2fa0e7",
          "commitAuthor": "Yiqun Lin",
          "commitDateOld": "29/11/17 9:43 AM",
          "commitNameOld": "301641811d93ac22dc6fe1a05f18c1f266cc5e54",
          "commitAuthorOld": "Wei Yan",
          "daysBetweenCommits": 104.4,
          "commitsBetweenForRepo": 654,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,23 +1,23 @@\n-  public \u003cT extends BaseRecord\u003e QueryResult\u003cT\u003e get(Class\u003cT\u003e clazz, String sub)\n-      throws IOException {\n-    verifyDriverReady();\n-    BufferedReader reader \u003d null;\n-    lockRecordRead(clazz);\n+  private \u003cT extends BaseRecord\u003e T getRecord(\n+      final String path, final Class\u003cT\u003e clazz) throws IOException {\n+    BufferedReader reader \u003d getReader(path);\n     try {\n-      reader \u003d getReader(clazz, sub);\n-      List\u003cT\u003e data \u003d getAllFile(reader, clazz, true);\n-      return new QueryResult\u003cT\u003e(data, getTime());\n-    } catch (Exception ex) {\n-      LOG.error(\"Cannot fetch records {}\", clazz.getSimpleName());\n-      throw new IOException(\"Cannot read from data store \" + ex.getMessage());\n-    } finally {\n-      if (reader !\u003d null) {\n-        try {\n-          reader.close();\n-        } catch (IOException e) {\n-          LOG.error(\"Failed closing file\", e);\n+      String line;\n+      while ((line \u003d reader.readLine()) !\u003d null) {\n+        if (!line.startsWith(\"#\") \u0026\u0026 line.length() \u003e 0) {\n+          try {\n+            T record \u003d newRecord(line, clazz, false);\n+            return record;\n+          } catch (Exception ex) {\n+            LOG.error(\"Cannot parse line {} in file {}\", line, path, ex);\n+          }\n         }\n       }\n-      unlockRecordRead(clazz);\n+    } finally {\n+      if (reader !\u003d null) {\n+        reader.close();\n+      }\n     }\n+    throw new IOException(\"Cannot read \" + path + \" for record \" +\n+        clazz.getSimpleName());\n   }\n\\ No newline at end of file\n",
          "actualSource": "  private \u003cT extends BaseRecord\u003e T getRecord(\n      final String path, final Class\u003cT\u003e clazz) throws IOException {\n    BufferedReader reader \u003d getReader(path);\n    try {\n      String line;\n      while ((line \u003d reader.readLine()) !\u003d null) {\n        if (!line.startsWith(\"#\") \u0026\u0026 line.length() \u003e 0) {\n          try {\n            T record \u003d newRecord(line, clazz, false);\n            return record;\n          } catch (Exception ex) {\n            LOG.error(\"Cannot parse line {} in file {}\", line, path, ex);\n          }\n        }\n      }\n    } finally {\n      if (reader !\u003d null) {\n        reader.close();\n      }\n    }\n    throw new IOException(\"Cannot read \" + path + \" for record \" +\n        clazz.getSimpleName());\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/store/driver/impl/StateStoreFileBaseImpl.java",
          "extendedDetails": {
            "oldValue": "[clazz-Class\u003cT\u003e, sub-String]",
            "newValue": "[path-String(modifiers-final), clazz-Class\u003cT\u003e(modifiers-final)]"
          }
        }
      ]
    },
    "4bf877b03f0e01c4bcedc689c66689701e62b560": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-10630. Federation State Store FS Implementation. Contributed by Jason Kace and Inigo Goiri.\n\n(cherry picked from commit c6e0bd640cdaf83a660fa050809cad6f1d4c6f4d)\n",
      "commitDate": "06/10/17 6:50 PM",
      "commitName": "4bf877b03f0e01c4bcedc689c66689701e62b560",
      "commitAuthor": "Inigo Goiri",
      "diff": "@@ -0,0 +1,23 @@\n+  public \u003cT extends BaseRecord\u003e QueryResult\u003cT\u003e get(Class\u003cT\u003e clazz, String sub)\n+      throws IOException {\n+    verifyDriverReady();\n+    BufferedReader reader \u003d null;\n+    lockRecordRead(clazz);\n+    try {\n+      reader \u003d getReader(clazz, sub);\n+      List\u003cT\u003e data \u003d getAllFile(reader, clazz, true);\n+      return new QueryResult\u003cT\u003e(data, getTime());\n+    } catch (Exception ex) {\n+      LOG.error(\"Cannot fetch records {}\", clazz.getSimpleName());\n+      throw new IOException(\"Cannot read from data store \" + ex.getMessage());\n+    } finally {\n+      if (reader !\u003d null) {\n+        try {\n+          reader.close();\n+        } catch (IOException e) {\n+          LOG.error(\"Failed closing file\", e);\n+        }\n+      }\n+      unlockRecordRead(clazz);\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public \u003cT extends BaseRecord\u003e QueryResult\u003cT\u003e get(Class\u003cT\u003e clazz, String sub)\n      throws IOException {\n    verifyDriverReady();\n    BufferedReader reader \u003d null;\n    lockRecordRead(clazz);\n    try {\n      reader \u003d getReader(clazz, sub);\n      List\u003cT\u003e data \u003d getAllFile(reader, clazz, true);\n      return new QueryResult\u003cT\u003e(data, getTime());\n    } catch (Exception ex) {\n      LOG.error(\"Cannot fetch records {}\", clazz.getSimpleName());\n      throw new IOException(\"Cannot read from data store \" + ex.getMessage());\n    } finally {\n      if (reader !\u003d null) {\n        try {\n          reader.close();\n        } catch (IOException e) {\n          LOG.error(\"Failed closing file\", e);\n        }\n      }\n      unlockRecordRead(clazz);\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/federation/store/driver/impl/StateStoreFileBaseImpl.java"
    }
  }
}