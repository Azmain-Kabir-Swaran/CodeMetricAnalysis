{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "YARNRunner.java",
  "functionName": "setupLocalResources",
  "functionId": "setupLocalResources___jobConf-Configuration__jobSubmitDir-String",
  "sourceFilePath": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
  "functionStartLine": 388,
  "functionEndLine": 442,
  "numCommitsSeen": 80,
  "timeTaken": 1203,
  "changeHistory": [
    "e46d5bb962b0c942f993afc505b165b1cd96e51b",
    "732ee6f0b58a12500198c0d934cc570c7490b520"
  ],
  "changeHistoryShort": {
    "e46d5bb962b0c942f993afc505b165b1cd96e51b": "Ybodychange",
    "732ee6f0b58a12500198c0d934cc570c7490b520": "Yintroduced"
  },
  "changeHistoryDetails": {
    "e46d5bb962b0c942f993afc505b165b1cd96e51b": {
      "type": "Ybodychange",
      "commitMessage": "MAPREDUCE-5951. Add support for the YARN Shared Cache.\n",
      "commitDate": "12/10/17 10:59 AM",
      "commitName": "e46d5bb962b0c942f993afc505b165b1cd96e51b",
      "commitAuthor": "Chris Trezzo",
      "commitDateOld": "21/04/17 4:12 PM",
      "commitNameOld": "3721cfe1fbd98c5b6aa46aefdfcf62276c28c4a4",
      "commitAuthorOld": "Robert Kanter",
      "daysBetweenCommits": 173.78,
      "commitsBetweenForRepo": 1195,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,44 +1,55 @@\n   private Map\u003cString, LocalResource\u003e setupLocalResources(Configuration jobConf,\n       String jobSubmitDir) throws IOException {\n     Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003c\u003e();\n \n     Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n \n     URL yarnUrlForJobSubmitDir \u003d URL.fromPath(defaultFileContext\n         .getDefaultFileSystem().resolvePath(\n             defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n     LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n         + yarnUrlForJobSubmitDir);\n \n     localResources.put(MRJobConfig.JOB_CONF_FILE,\n         createApplicationResource(defaultFileContext,\n             jobConfPath, LocalResourceType.FILE));\n     if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n       Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n+      // We hard code the job.jar symlink because mapreduce code expects the\n+      // job.jar to be named that way.\n+      FileContext fccc \u003d\n+          FileContext.getFileContext(jobJarPath.toUri(), jobConf);\n+      LocalResourceVisibility jobJarViz \u003d\n+          jobConf.getBoolean(MRJobConfig.JOBJAR_VISIBILITY,\n+              MRJobConfig.JOBJAR_VISIBILITY_DEFAULT)\n+                  ? LocalResourceVisibility.PUBLIC\n+                  : LocalResourceVisibility.APPLICATION;\n       LocalResource rc \u003d createApplicationResource(\n-          FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n-          jobJarPath,\n-          LocalResourceType.PATTERN);\n+          FileContext.getFileContext(jobJarPath.toUri(), jobConf), jobJarPath,\n+          MRJobConfig.JOB_JAR, LocalResourceType.PATTERN, jobJarViz,\n+          jobConf.getBoolean(\n+                  MRJobConfig.JOBJAR_SHARED_CACHE_UPLOAD_POLICY,\n+                  MRJobConfig.JOBJAR_SHARED_CACHE_UPLOAD_POLICY_DEFAULT));\n       String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN,\n           JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n       rc.setPattern(pattern);\n       localResources.put(MRJobConfig.JOB_JAR, rc);\n     } else {\n       // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n       // mapreduce jar itself which is already on the classpath.\n       LOG.info(\"Job jar is not present. \"\n           + \"Not adding any jar to the list of resources.\");\n     }\n \n     // TODO gross hack\n     for (String s : new String[] {\n         MRJobConfig.JOB_SPLIT,\n         MRJobConfig.JOB_SPLIT_METAINFO }) {\n       localResources.put(\n           MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n           createApplicationResource(defaultFileContext,\n               new Path(jobSubmitDir, s), LocalResourceType.FILE));\n     }\n \n     return localResources;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private Map\u003cString, LocalResource\u003e setupLocalResources(Configuration jobConf,\n      String jobSubmitDir) throws IOException {\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003c\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d URL.fromPath(defaultFileContext\n        .getDefaultFileSystem().resolvePath(\n            defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      // We hard code the job.jar symlink because mapreduce code expects the\n      // job.jar to be named that way.\n      FileContext fccc \u003d\n          FileContext.getFileContext(jobJarPath.toUri(), jobConf);\n      LocalResourceVisibility jobJarViz \u003d\n          jobConf.getBoolean(MRJobConfig.JOBJAR_VISIBILITY,\n              MRJobConfig.JOBJAR_VISIBILITY_DEFAULT)\n                  ? LocalResourceVisibility.PUBLIC\n                  : LocalResourceVisibility.APPLICATION;\n      LocalResource rc \u003d createApplicationResource(\n          FileContext.getFileContext(jobJarPath.toUri(), jobConf), jobJarPath,\n          MRJobConfig.JOB_JAR, LocalResourceType.PATTERN, jobJarViz,\n          jobConf.getBoolean(\n                  MRJobConfig.JOBJAR_SHARED_CACHE_UPLOAD_POLICY,\n                  MRJobConfig.JOBJAR_SHARED_CACHE_UPLOAD_POLICY_DEFAULT));\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN,\n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    return localResources;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java",
      "extendedDetails": {}
    },
    "732ee6f0b58a12500198c0d934cc570c7490b520": {
      "type": "Yintroduced",
      "commitMessage": "MAPREDUCE-6825. YARNRunner#createApplicationSubmissionContext method is longer than 150 lines (Contributed by Gergely Nov√°k via Daniel Templeton)\n",
      "commitDate": "22/02/17 3:38 PM",
      "commitName": "732ee6f0b58a12500198c0d934cc570c7490b520",
      "commitAuthor": "Daniel Templeton",
      "diff": "@@ -0,0 +1,44 @@\n+  private Map\u003cString, LocalResource\u003e setupLocalResources(Configuration jobConf,\n+      String jobSubmitDir) throws IOException {\n+    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003c\u003e();\n+\n+    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n+\n+    URL yarnUrlForJobSubmitDir \u003d URL.fromPath(defaultFileContext\n+        .getDefaultFileSystem().resolvePath(\n+            defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n+    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n+        + yarnUrlForJobSubmitDir);\n+\n+    localResources.put(MRJobConfig.JOB_CONF_FILE,\n+        createApplicationResource(defaultFileContext,\n+            jobConfPath, LocalResourceType.FILE));\n+    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n+      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n+      LocalResource rc \u003d createApplicationResource(\n+          FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n+          jobJarPath,\n+          LocalResourceType.PATTERN);\n+      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN,\n+          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n+      rc.setPattern(pattern);\n+      localResources.put(MRJobConfig.JOB_JAR, rc);\n+    } else {\n+      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n+      // mapreduce jar itself which is already on the classpath.\n+      LOG.info(\"Job jar is not present. \"\n+          + \"Not adding any jar to the list of resources.\");\n+    }\n+\n+    // TODO gross hack\n+    for (String s : new String[] {\n+        MRJobConfig.JOB_SPLIT,\n+        MRJobConfig.JOB_SPLIT_METAINFO }) {\n+      localResources.put(\n+          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n+          createApplicationResource(defaultFileContext,\n+              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n+    }\n+\n+    return localResources;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private Map\u003cString, LocalResource\u003e setupLocalResources(Configuration jobConf,\n      String jobSubmitDir) throws IOException {\n    Map\u003cString, LocalResource\u003e localResources \u003d new HashMap\u003c\u003e();\n\n    Path jobConfPath \u003d new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\n\n    URL yarnUrlForJobSubmitDir \u003d URL.fromPath(defaultFileContext\n        .getDefaultFileSystem().resolvePath(\n            defaultFileContext.makeQualified(new Path(jobSubmitDir))));\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \"\n        + yarnUrlForJobSubmitDir);\n\n    localResources.put(MRJobConfig.JOB_CONF_FILE,\n        createApplicationResource(defaultFileContext,\n            jobConfPath, LocalResourceType.FILE));\n    if (jobConf.get(MRJobConfig.JAR) !\u003d null) {\n      Path jobJarPath \u003d new Path(jobConf.get(MRJobConfig.JAR));\n      LocalResource rc \u003d createApplicationResource(\n          FileContext.getFileContext(jobJarPath.toUri(), jobConf),\n          jobJarPath,\n          LocalResourceType.PATTERN);\n      String pattern \u003d conf.getPattern(JobContext.JAR_UNPACK_PATTERN,\n          JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\n      rc.setPattern(pattern);\n      localResources.put(MRJobConfig.JOB_JAR, rc);\n    } else {\n      // Job jar may be null. For e.g, for pipes, the job jar is the hadoop\n      // mapreduce jar itself which is already on the classpath.\n      LOG.info(\"Job jar is not present. \"\n          + \"Not adding any jar to the list of resources.\");\n    }\n\n    // TODO gross hack\n    for (String s : new String[] {\n        MRJobConfig.JOB_SPLIT,\n        MRJobConfig.JOB_SPLIT_METAINFO }) {\n      localResources.put(\n          MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s,\n          createApplicationResource(defaultFileContext,\n              new Path(jobSubmitDir, s), LocalResourceType.FILE));\n    }\n\n    return localResources;\n  }",
      "path": "hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java"
    }
  }
}