{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "BlockPlacementPolicyDefault.java",
  "functionName": "chooseLocalStorage",
  "functionId": "chooseLocalStorage___localMachine-Node__excludedNodes-Set__Node____blocksize-long__maxNodesPerRack-int__results-List__DatanodeStorageInfo____avoidStaleNodes-boolean__storageTypes-EnumMap__StorageType,Integer____fallbackToLocalRack-boolean",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
  "functionStartLine": 636,
  "functionEndLine": 654,
  "numCommitsSeen": 177,
  "timeTaken": 3678,
  "changeHistory": [
    "80a29906bcd718bbba223fa099e523281d9f3369",
    "88ceb382ef45bd09cf004cf44aedbabaf3976759",
    "e08701ec71f7c10d8f15122d90c35f9f22e40837",
    "44d9bb26d640ca5c1de651563c7993b4ecd6b653"
  ],
  "changeHistoryShort": {
    "80a29906bcd718bbba223fa099e523281d9f3369": "Ybodychange",
    "88ceb382ef45bd09cf004cf44aedbabaf3976759": "Ybodychange",
    "e08701ec71f7c10d8f15122d90c35f9f22e40837": "Ymultichange(Yparameterchange,Ybodychange)",
    "44d9bb26d640ca5c1de651563c7993b4ecd6b653": "Ymultichange(Yparameterchange,Ybodychange)"
  },
  "changeHistoryDetails": {
    "80a29906bcd718bbba223fa099e523281d9f3369": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8884. Fail-fast check in BlockPlacementPolicyDefault#chooseTarget. (yliu)\n",
      "commitDate": "20/08/15 5:07 AM",
      "commitName": "80a29906bcd718bbba223fa099e523281d9f3369",
      "commitAuthor": "yliu",
      "commitDateOld": "29/06/15 2:55 AM",
      "commitNameOld": "88ceb382ef45bd09cf004cf44aedbabaf3976759",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 52.09,
      "commitsBetweenForRepo": 309,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,43 +1,19 @@\n   protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n       Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n       List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n       EnumMap\u003cStorageType, Integer\u003e storageTypes, boolean fallbackToLocalRack)\n       throws NotEnoughReplicasException {\n-    // if no local machine, randomly choose one node\n-    if (localMachine \u003d\u003d null) {\n-      return chooseRandom(NodeBase.ROOT, excludedNodes, blocksize,\n-          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n-    }\n-    if (preferLocalNode \u0026\u0026 localMachine instanceof DatanodeDescriptor\n-        \u0026\u0026 clusterMap.contains(localMachine)) {\n-      DatanodeDescriptor localDatanode \u003d (DatanodeDescriptor) localMachine;\n-      // otherwise try local machine first\n-      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n-        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n-            .entrySet().iterator(); iter.hasNext(); ) {\n-          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n-          for (DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n-              localDatanode.getStorageInfos())) {\n-            StorageType type \u003d entry.getKey();\n-            if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n-                maxNodesPerRack, false, results, avoidStaleNodes, type) \u003e\u003d 0) {\n-              int num \u003d entry.getValue();\n-              if (num \u003d\u003d 1) {\n-                iter.remove();\n-              } else {\n-                entry.setValue(num - 1);\n-              }\n-              return localStorage;\n-            }\n-          }\n-        }\n-      } \n+    DatanodeStorageInfo localStorage \u003d chooseLocalStorage(localMachine,\n+        excludedNodes, blocksize, maxNodesPerRack, results,\n+        avoidStaleNodes, storageTypes);\n+    if (localStorage !\u003d null) {\n+      return localStorage;\n     }\n \n     if (!fallbackToLocalRack) {\n       return null;\n     }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, blocksize,\n         maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n      EnumMap\u003cStorageType, Integer\u003e storageTypes, boolean fallbackToLocalRack)\n      throws NotEnoughReplicasException {\n    DatanodeStorageInfo localStorage \u003d chooseLocalStorage(localMachine,\n        excludedNodes, blocksize, maxNodesPerRack, results,\n        avoidStaleNodes, storageTypes);\n    if (localStorage !\u003d null) {\n      return localStorage;\n    }\n\n    if (!fallbackToLocalRack) {\n      return null;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, blocksize,\n        maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "88ceb382ef45bd09cf004cf44aedbabaf3976759": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8586. Dead Datanode is allocated for write when client is from deadnode (Contributed by Brahma Reddy Battula)\n",
      "commitDate": "29/06/15 2:55 AM",
      "commitName": "88ceb382ef45bd09cf004cf44aedbabaf3976759",
      "commitAuthor": "Vinayakumar B",
      "commitDateOld": "19/05/15 6:04 AM",
      "commitNameOld": "de30d66b2673d0344346fb985e786247ca682317",
      "commitAuthorOld": "Kihwal Lee",
      "daysBetweenCommits": 40.87,
      "commitsBetweenForRepo": 278,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,42 +1,43 @@\n   protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n       Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n       List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n       EnumMap\u003cStorageType, Integer\u003e storageTypes, boolean fallbackToLocalRack)\n       throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n     if (localMachine \u003d\u003d null) {\n       return chooseRandom(NodeBase.ROOT, excludedNodes, blocksize,\n           maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n     }\n-    if (preferLocalNode \u0026\u0026 localMachine instanceof DatanodeDescriptor) {\n+    if (preferLocalNode \u0026\u0026 localMachine instanceof DatanodeDescriptor\n+        \u0026\u0026 clusterMap.contains(localMachine)) {\n       DatanodeDescriptor localDatanode \u003d (DatanodeDescriptor) localMachine;\n       // otherwise try local machine first\n       if (excludedNodes.add(localMachine)) { // was not in the excluded list\n         for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n             .entrySet().iterator(); iter.hasNext(); ) {\n           Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n           for (DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n               localDatanode.getStorageInfos())) {\n             StorageType type \u003d entry.getKey();\n             if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n                 maxNodesPerRack, false, results, avoidStaleNodes, type) \u003e\u003d 0) {\n               int num \u003d entry.getValue();\n               if (num \u003d\u003d 1) {\n                 iter.remove();\n               } else {\n                 entry.setValue(num - 1);\n               }\n               return localStorage;\n             }\n           }\n         }\n       } \n     }\n \n     if (!fallbackToLocalRack) {\n       return null;\n     }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, blocksize,\n         maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n      EnumMap\u003cStorageType, Integer\u003e storageTypes, boolean fallbackToLocalRack)\n      throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null) {\n      return chooseRandom(NodeBase.ROOT, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    }\n    if (preferLocalNode \u0026\u0026 localMachine instanceof DatanodeDescriptor\n        \u0026\u0026 clusterMap.contains(localMachine)) {\n      DatanodeDescriptor localDatanode \u003d (DatanodeDescriptor) localMachine;\n      // otherwise try local machine first\n      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n            .entrySet().iterator(); iter.hasNext(); ) {\n          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n          for (DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n              localDatanode.getStorageInfos())) {\n            StorageType type \u003d entry.getKey();\n            if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n                maxNodesPerRack, false, results, avoidStaleNodes, type) \u003e\u003d 0) {\n              int num \u003d entry.getValue();\n              if (num \u003d\u003d 1) {\n                iter.remove();\n              } else {\n                entry.setValue(num - 1);\n              }\n              return localStorage;\n            }\n          }\n        }\n      } \n    }\n\n    if (!fallbackToLocalRack) {\n      return null;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, blocksize,\n        maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
      "extendedDetails": {}
    },
    "e08701ec71f7c10d8f15122d90c35f9f22e40837": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6961. Archival Storage: BlockPlacementPolicy#chooseTarget should check each valid storage type in each choosing round.\n",
      "commitDate": "04/09/14 2:19 PM",
      "commitName": "e08701ec71f7c10d8f15122d90c35f9f22e40837",
      "commitAuthor": "Jing Zhao",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6961. Archival Storage: BlockPlacementPolicy#chooseTarget should check each valid storage type in each choosing round.\n",
          "commitDate": "04/09/14 2:19 PM",
          "commitName": "e08701ec71f7c10d8f15122d90c35f9f22e40837",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "27/08/14 2:08 PM",
          "commitNameOld": "b7ded466b00db0fe273058b844d56d810e0f8cc2",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 8.01,
          "commitsBetweenForRepo": 50,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,35 +1,42 @@\n   protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n-                                             Set\u003cNode\u003e excludedNodes,\n-                                             long blocksize,\n-                                             int maxNodesPerRack,\n-                                             List\u003cDatanodeStorageInfo\u003e results,\n-                                             boolean avoidStaleNodes,\n-                                             StorageType storageType,\n-                                             boolean fallbackToLocalRack)\n+      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n+      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n+      EnumMap\u003cStorageType, Integer\u003e storageTypes, boolean fallbackToLocalRack)\n       throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n     if (localMachine \u003d\u003d null) {\n       return chooseRandom(NodeBase.ROOT, excludedNodes, blocksize,\n-          maxNodesPerRack, results, avoidStaleNodes, storageType);\n+          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n     }\n     if (preferLocalNode \u0026\u0026 localMachine instanceof DatanodeDescriptor) {\n       DatanodeDescriptor localDatanode \u003d (DatanodeDescriptor) localMachine;\n       // otherwise try local machine first\n       if (excludedNodes.add(localMachine)) { // was not in the excluded list\n-        for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n-            localDatanode.getStorageInfos())) {\n-          if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n-              maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n-            return localStorage;\n+        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n+            .entrySet().iterator(); iter.hasNext(); ) {\n+          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n+          for (DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n+              localDatanode.getStorageInfos())) {\n+            StorageType type \u003d entry.getKey();\n+            if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n+                maxNodesPerRack, false, results, avoidStaleNodes, type) \u003e\u003d 0) {\n+              int num \u003d entry.getValue();\n+              if (num \u003d\u003d 1) {\n+                iter.remove();\n+              } else {\n+                entry.setValue(num - 1);\n+              }\n+              return localStorage;\n+            }\n           }\n         }\n       } \n     }\n \n     if (!fallbackToLocalRack) {\n       return null;\n     }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, blocksize,\n-        maxNodesPerRack, results, avoidStaleNodes, storageType);\n+        maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n      EnumMap\u003cStorageType, Integer\u003e storageTypes, boolean fallbackToLocalRack)\n      throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null) {\n      return chooseRandom(NodeBase.ROOT, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    }\n    if (preferLocalNode \u0026\u0026 localMachine instanceof DatanodeDescriptor) {\n      DatanodeDescriptor localDatanode \u003d (DatanodeDescriptor) localMachine;\n      // otherwise try local machine first\n      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n            .entrySet().iterator(); iter.hasNext(); ) {\n          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n          for (DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n              localDatanode.getStorageInfos())) {\n            StorageType type \u003d entry.getKey();\n            if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n                maxNodesPerRack, false, results, avoidStaleNodes, type) \u003e\u003d 0) {\n              int num \u003d entry.getValue();\n              if (num \u003d\u003d 1) {\n                iter.remove();\n              } else {\n                entry.setValue(num - 1);\n              }\n              return localStorage;\n            }\n          }\n        }\n      } \n    }\n\n    if (!fallbackToLocalRack) {\n      return null;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, blocksize,\n        maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
          "extendedDetails": {
            "oldValue": "[localMachine-Node, excludedNodes-Set\u003cNode\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeStorageInfo\u003e, avoidStaleNodes-boolean, storageType-StorageType, fallbackToLocalRack-boolean]",
            "newValue": "[localMachine-Node, excludedNodes-Set\u003cNode\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeStorageInfo\u003e, avoidStaleNodes-boolean, storageTypes-EnumMap\u003cStorageType,Integer\u003e, fallbackToLocalRack-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6961. Archival Storage: BlockPlacementPolicy#chooseTarget should check each valid storage type in each choosing round.\n",
          "commitDate": "04/09/14 2:19 PM",
          "commitName": "e08701ec71f7c10d8f15122d90c35f9f22e40837",
          "commitAuthor": "Jing Zhao",
          "commitDateOld": "27/08/14 2:08 PM",
          "commitNameOld": "b7ded466b00db0fe273058b844d56d810e0f8cc2",
          "commitAuthorOld": "Jing Zhao",
          "daysBetweenCommits": 8.01,
          "commitsBetweenForRepo": 50,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,35 +1,42 @@\n   protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n-                                             Set\u003cNode\u003e excludedNodes,\n-                                             long blocksize,\n-                                             int maxNodesPerRack,\n-                                             List\u003cDatanodeStorageInfo\u003e results,\n-                                             boolean avoidStaleNodes,\n-                                             StorageType storageType,\n-                                             boolean fallbackToLocalRack)\n+      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n+      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n+      EnumMap\u003cStorageType, Integer\u003e storageTypes, boolean fallbackToLocalRack)\n       throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n     if (localMachine \u003d\u003d null) {\n       return chooseRandom(NodeBase.ROOT, excludedNodes, blocksize,\n-          maxNodesPerRack, results, avoidStaleNodes, storageType);\n+          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n     }\n     if (preferLocalNode \u0026\u0026 localMachine instanceof DatanodeDescriptor) {\n       DatanodeDescriptor localDatanode \u003d (DatanodeDescriptor) localMachine;\n       // otherwise try local machine first\n       if (excludedNodes.add(localMachine)) { // was not in the excluded list\n-        for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n-            localDatanode.getStorageInfos())) {\n-          if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n-              maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n-            return localStorage;\n+        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n+            .entrySet().iterator(); iter.hasNext(); ) {\n+          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n+          for (DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n+              localDatanode.getStorageInfos())) {\n+            StorageType type \u003d entry.getKey();\n+            if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n+                maxNodesPerRack, false, results, avoidStaleNodes, type) \u003e\u003d 0) {\n+              int num \u003d entry.getValue();\n+              if (num \u003d\u003d 1) {\n+                iter.remove();\n+              } else {\n+                entry.setValue(num - 1);\n+              }\n+              return localStorage;\n+            }\n           }\n         }\n       } \n     }\n \n     if (!fallbackToLocalRack) {\n       return null;\n     }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, blocksize,\n-        maxNodesPerRack, results, avoidStaleNodes, storageType);\n+        maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n      Set\u003cNode\u003e excludedNodes, long blocksize, int maxNodesPerRack,\n      List\u003cDatanodeStorageInfo\u003e results, boolean avoidStaleNodes,\n      EnumMap\u003cStorageType, Integer\u003e storageTypes, boolean fallbackToLocalRack)\n      throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null) {\n      return chooseRandom(NodeBase.ROOT, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n    }\n    if (preferLocalNode \u0026\u0026 localMachine instanceof DatanodeDescriptor) {\n      DatanodeDescriptor localDatanode \u003d (DatanodeDescriptor) localMachine;\n      // otherwise try local machine first\n      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n        for (Iterator\u003cMap.Entry\u003cStorageType, Integer\u003e\u003e iter \u003d storageTypes\n            .entrySet().iterator(); iter.hasNext(); ) {\n          Map.Entry\u003cStorageType, Integer\u003e entry \u003d iter.next();\n          for (DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n              localDatanode.getStorageInfos())) {\n            StorageType type \u003d entry.getKey();\n            if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n                maxNodesPerRack, false, results, avoidStaleNodes, type) \u003e\u003d 0) {\n              int num \u003d entry.getValue();\n              if (num \u003d\u003d 1) {\n                iter.remove();\n              } else {\n                entry.setValue(num - 1);\n              }\n              return localStorage;\n            }\n          }\n        }\n      } \n    }\n\n    if (!fallbackToLocalRack) {\n      return null;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, blocksize,\n        maxNodesPerRack, results, avoidStaleNodes, storageTypes);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
          "extendedDetails": {}
        }
      ]
    },
    "44d9bb26d640ca5c1de651563c7993b4ecd6b653": {
      "type": "Ymultichange(Yparameterchange,Ybodychange)",
      "commitMessage": "HDFS-6680. BlockPlacementPolicyDefault does not choose favored nodes correctly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1612427 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "21/07/14 4:21 PM",
      "commitName": "44d9bb26d640ca5c1de651563c7993b4ecd6b653",
      "commitAuthor": "Tsz-wo Sze",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6680. BlockPlacementPolicyDefault does not choose favored nodes correctly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1612427 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/07/14 4:21 PM",
          "commitName": "44d9bb26d640ca5c1de651563c7993b4ecd6b653",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "18/07/14 10:58 AM",
          "commitNameOld": "551024915d487957d9e829493ab319c8e31dfa81",
          "commitAuthorOld": "Daryn Sharp",
          "daysBetweenCommits": 3.22,
          "commitsBetweenForRepo": 14,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,35 @@\n   protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n                                              Set\u003cNode\u003e excludedNodes,\n                                              long blocksize,\n                                              int maxNodesPerRack,\n                                              List\u003cDatanodeStorageInfo\u003e results,\n                                              boolean avoidStaleNodes,\n-                                             StorageType storageType)\n+                                             StorageType storageType,\n+                                             boolean fallbackToLocalRack)\n       throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n-    if (localMachine \u003d\u003d null)\n+    if (localMachine \u003d\u003d null) {\n       return chooseRandom(NodeBase.ROOT, excludedNodes, blocksize,\n           maxNodesPerRack, results, avoidStaleNodes, storageType);\n+    }\n     if (preferLocalNode \u0026\u0026 localMachine instanceof DatanodeDescriptor) {\n       DatanodeDescriptor localDatanode \u003d (DatanodeDescriptor) localMachine;\n       // otherwise try local machine first\n       if (excludedNodes.add(localMachine)) { // was not in the excluded list\n         for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n             localDatanode.getStorageInfos())) {\n           if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n               maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n             return localStorage;\n           }\n         }\n       } \n-    }      \n+    }\n+\n+    if (!fallbackToLocalRack) {\n+      return null;\n+    }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, blocksize,\n         maxNodesPerRack, results, avoidStaleNodes, storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n                                             Set\u003cNode\u003e excludedNodes,\n                                             long blocksize,\n                                             int maxNodesPerRack,\n                                             List\u003cDatanodeStorageInfo\u003e results,\n                                             boolean avoidStaleNodes,\n                                             StorageType storageType,\n                                             boolean fallbackToLocalRack)\n      throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null) {\n      return chooseRandom(NodeBase.ROOT, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageType);\n    }\n    if (preferLocalNode \u0026\u0026 localMachine instanceof DatanodeDescriptor) {\n      DatanodeDescriptor localDatanode \u003d (DatanodeDescriptor) localMachine;\n      // otherwise try local machine first\n      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n        for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n            localDatanode.getStorageInfos())) {\n          if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n              maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n            return localStorage;\n          }\n        }\n      } \n    }\n\n    if (!fallbackToLocalRack) {\n      return null;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, blocksize,\n        maxNodesPerRack, results, avoidStaleNodes, storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
          "extendedDetails": {
            "oldValue": "[localMachine-Node, excludedNodes-Set\u003cNode\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeStorageInfo\u003e, avoidStaleNodes-boolean, storageType-StorageType]",
            "newValue": "[localMachine-Node, excludedNodes-Set\u003cNode\u003e, blocksize-long, maxNodesPerRack-int, results-List\u003cDatanodeStorageInfo\u003e, avoidStaleNodes-boolean, storageType-StorageType, fallbackToLocalRack-boolean]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6680. BlockPlacementPolicyDefault does not choose favored nodes correctly.\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1612427 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "21/07/14 4:21 PM",
          "commitName": "44d9bb26d640ca5c1de651563c7993b4ecd6b653",
          "commitAuthor": "Tsz-wo Sze",
          "commitDateOld": "18/07/14 10:58 AM",
          "commitNameOld": "551024915d487957d9e829493ab319c8e31dfa81",
          "commitAuthorOld": "Daryn Sharp",
          "daysBetweenCommits": 3.22,
          "commitsBetweenForRepo": 14,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,29 +1,35 @@\n   protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n                                              Set\u003cNode\u003e excludedNodes,\n                                              long blocksize,\n                                              int maxNodesPerRack,\n                                              List\u003cDatanodeStorageInfo\u003e results,\n                                              boolean avoidStaleNodes,\n-                                             StorageType storageType)\n+                                             StorageType storageType,\n+                                             boolean fallbackToLocalRack)\n       throws NotEnoughReplicasException {\n     // if no local machine, randomly choose one node\n-    if (localMachine \u003d\u003d null)\n+    if (localMachine \u003d\u003d null) {\n       return chooseRandom(NodeBase.ROOT, excludedNodes, blocksize,\n           maxNodesPerRack, results, avoidStaleNodes, storageType);\n+    }\n     if (preferLocalNode \u0026\u0026 localMachine instanceof DatanodeDescriptor) {\n       DatanodeDescriptor localDatanode \u003d (DatanodeDescriptor) localMachine;\n       // otherwise try local machine first\n       if (excludedNodes.add(localMachine)) { // was not in the excluded list\n         for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n             localDatanode.getStorageInfos())) {\n           if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n               maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n             return localStorage;\n           }\n         }\n       } \n-    }      \n+    }\n+\n+    if (!fallbackToLocalRack) {\n+      return null;\n+    }\n     // try a node on local rack\n     return chooseLocalRack(localMachine, excludedNodes, blocksize,\n         maxNodesPerRack, results, avoidStaleNodes, storageType);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  protected DatanodeStorageInfo chooseLocalStorage(Node localMachine,\n                                             Set\u003cNode\u003e excludedNodes,\n                                             long blocksize,\n                                             int maxNodesPerRack,\n                                             List\u003cDatanodeStorageInfo\u003e results,\n                                             boolean avoidStaleNodes,\n                                             StorageType storageType,\n                                             boolean fallbackToLocalRack)\n      throws NotEnoughReplicasException {\n    // if no local machine, randomly choose one node\n    if (localMachine \u003d\u003d null) {\n      return chooseRandom(NodeBase.ROOT, excludedNodes, blocksize,\n          maxNodesPerRack, results, avoidStaleNodes, storageType);\n    }\n    if (preferLocalNode \u0026\u0026 localMachine instanceof DatanodeDescriptor) {\n      DatanodeDescriptor localDatanode \u003d (DatanodeDescriptor) localMachine;\n      // otherwise try local machine first\n      if (excludedNodes.add(localMachine)) { // was not in the excluded list\n        for(DatanodeStorageInfo localStorage : DFSUtil.shuffle(\n            localDatanode.getStorageInfos())) {\n          if (addIfIsGoodTarget(localStorage, excludedNodes, blocksize,\n              maxNodesPerRack, false, results, avoidStaleNodes, storageType) \u003e\u003d 0) {\n            return localStorage;\n          }\n        }\n      } \n    }\n\n    if (!fallbackToLocalRack) {\n      return null;\n    }\n    // try a node on local rack\n    return chooseLocalRack(localMachine, excludedNodes, blocksize,\n        maxNodesPerRack, results, avoidStaleNodes, storageType);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyDefault.java",
          "extendedDetails": {}
        }
      ]
    }
  }
}