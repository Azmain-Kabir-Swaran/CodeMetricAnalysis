{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "HAUtilClient.java",
  "functionName": "getServiceUriFromToken",
  "functionId": "getServiceUriFromToken___scheme-String(modifiers-final)__token-Token__?__",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/HAUtilClient.java",
  "functionStartLine": 92,
  "functionEndLine": 100,
  "numCommitsSeen": 51,
  "timeTaken": 3050,
  "changeHistory": [
    "6f8003dc7bc9e8be7b0512c514d370c303faf003",
    "7ba5913797c49d5001ad95558eadd119c3361060",
    "aa4a045925649949b2eaa5b7238edbd742cbcf9a",
    "481f84597bf842df45b068cc24c328112e8bcf40"
  ],
  "changeHistoryShort": {
    "6f8003dc7bc9e8be7b0512c514d370c303faf003": "Ymovefromfile",
    "7ba5913797c49d5001ad95558eadd119c3361060": "Ybodychange",
    "aa4a045925649949b2eaa5b7238edbd742cbcf9a": "Ymultichange(Yparameterchange,Yexceptionschange,Ybodychange)",
    "481f84597bf842df45b068cc24c328112e8bcf40": "Yintroduced"
  },
  "changeHistoryDetails": {
    "6f8003dc7bc9e8be7b0512c514d370c303faf003": {
      "type": "Ymovefromfile",
      "commitMessage": "HDFS-8185. Separate client related routines in HAUtil into a new class. Contributed by Haohui Mai.\n",
      "commitDate": "21/04/15 9:59 PM",
      "commitName": "6f8003dc7bc9e8be7b0512c514d370c303faf003",
      "commitAuthor": "Haohui Mai",
      "commitDateOld": "21/04/15 8:57 PM",
      "commitNameOld": "674c7ef64916fabbe59c8d6cdd50ca19cf7ddb7c",
      "commitAuthorOld": "Jian He",
      "daysBetweenCommits": 0.04,
      "commitsBetweenForRepo": 1,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,8 +1,9 @@\n   public static URI getServiceUriFromToken(final String scheme, Token\u003c?\u003e token) {\n     String tokStr \u003d token.getService().toString();\n-    final String prefix \u003d buildTokenServicePrefixForLogicalUri(scheme);\n+    final String prefix \u003d buildTokenServicePrefixForLogicalUri(\n+        scheme);\n     if (tokStr.startsWith(prefix)) {\n       tokStr \u003d tokStr.replaceFirst(prefix, \"\");\n     }\n     return URI.create(scheme + \"://\" + tokStr);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static URI getServiceUriFromToken(final String scheme, Token\u003c?\u003e token) {\n    String tokStr \u003d token.getService().toString();\n    final String prefix \u003d buildTokenServicePrefixForLogicalUri(\n        scheme);\n    if (tokStr.startsWith(prefix)) {\n      tokStr \u003d tokStr.replaceFirst(prefix, \"\");\n    }\n    return URI.create(scheme + \"://\" + tokStr);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/HAUtilClient.java",
      "extendedDetails": {
        "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
        "newPath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/HAUtilClient.java",
        "oldMethodName": "getServiceUriFromToken",
        "newMethodName": "getServiceUriFromToken"
      }
    },
    "7ba5913797c49d5001ad95558eadd119c3361060": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-6667. In HDFS HA mode, Distcp/SLive with webhdfs on secure cluster fails with Client cannot authenticate via:[TOKEN, KERBEROS] error. Contributed by Jing Zhao.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1611508 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "17/07/14 4:11 PM",
      "commitName": "7ba5913797c49d5001ad95558eadd119c3361060",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "22/06/14 10:16 PM",
      "commitNameOld": "e8ca6480050e38d2fe4859baf4f9a8d22e7f9b85",
      "commitAuthorOld": "Vinayakumar B",
      "daysBetweenCommits": 24.75,
      "commitsBetweenForRepo": 171,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,9 +1,8 @@\n-  public static URI getServiceUriFromToken(final String scheme,\n-                                           Token\u003c?\u003e token) {\n+  public static URI getServiceUriFromToken(final String scheme, Token\u003c?\u003e token) {\n     String tokStr \u003d token.getService().toString();\n-\n-    if (tokStr.startsWith(HA_DT_SERVICE_PREFIX)) {\n-      tokStr \u003d tokStr.replaceFirst(HA_DT_SERVICE_PREFIX, \"\");\n+    final String prefix \u003d buildTokenServicePrefixForLogicalUri(scheme);\n+    if (tokStr.startsWith(prefix)) {\n+      tokStr \u003d tokStr.replaceFirst(prefix, \"\");\n     }\n     return URI.create(scheme + \"://\" + tokStr);\n   }\n\\ No newline at end of file\n",
      "actualSource": "  public static URI getServiceUriFromToken(final String scheme, Token\u003c?\u003e token) {\n    String tokStr \u003d token.getService().toString();\n    final String prefix \u003d buildTokenServicePrefixForLogicalUri(scheme);\n    if (tokStr.startsWith(prefix)) {\n      tokStr \u003d tokStr.replaceFirst(prefix, \"\");\n    }\n    return URI.create(scheme + \"://\" + tokStr);\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
      "extendedDetails": {}
    },
    "aa4a045925649949b2eaa5b7238edbd742cbcf9a": {
      "type": "Ymultichange(Yparameterchange,Yexceptionschange,Ybodychange)",
      "commitMessage": "HDFS-6127. WebHDFS tokens cannot be renewed in HA setup. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1579546 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/03/14 11:47 PM",
      "commitName": "aa4a045925649949b2eaa5b7238edbd742cbcf9a",
      "commitAuthor": "Haohui Mai",
      "subchanges": [
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-6127. WebHDFS tokens cannot be renewed in HA setup. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1579546 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "19/03/14 11:47 PM",
          "commitName": "aa4a045925649949b2eaa5b7238edbd742cbcf9a",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "25/01/14 12:01 PM",
          "commitNameOld": "edb6dc5f303093c2604cd07b0c0dacf12dbce5de",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 53.45,
          "commitsBetweenForRepo": 495,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,9 @@\n-  public static URI getServiceUriFromToken(\n-      Token\u003cDelegationTokenIdentifier\u003e token)\n-      throws IOException {\n+  public static URI getServiceUriFromToken(final String scheme,\n+                                           Token\u003c?\u003e token) {\n     String tokStr \u003d token.getService().toString();\n \n     if (tokStr.startsWith(HA_DT_SERVICE_PREFIX)) {\n       tokStr \u003d tokStr.replaceFirst(HA_DT_SERVICE_PREFIX, \"\");\n     }\n-    \n-    try {\n-      return new URI(HdfsConstants.HDFS_URI_SCHEME + \"://\" +\n-          tokStr);\n-    } catch (URISyntaxException e) {\n-      throw new IOException(\"Invalid token contents: \u0027\" +\n-          tokStr + \"\u0027\");\n-    }\n+    return URI.create(scheme + \"://\" + tokStr);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static URI getServiceUriFromToken(final String scheme,\n                                           Token\u003c?\u003e token) {\n    String tokStr \u003d token.getService().toString();\n\n    if (tokStr.startsWith(HA_DT_SERVICE_PREFIX)) {\n      tokStr \u003d tokStr.replaceFirst(HA_DT_SERVICE_PREFIX, \"\");\n    }\n    return URI.create(scheme + \"://\" + tokStr);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
          "extendedDetails": {
            "oldValue": "[token-Token\u003cDelegationTokenIdentifier\u003e]",
            "newValue": "[scheme-String(modifiers-final), token-Token\u003c?\u003e]"
          }
        },
        {
          "type": "Yexceptionschange",
          "commitMessage": "HDFS-6127. WebHDFS tokens cannot be renewed in HA setup. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1579546 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "19/03/14 11:47 PM",
          "commitName": "aa4a045925649949b2eaa5b7238edbd742cbcf9a",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "25/01/14 12:01 PM",
          "commitNameOld": "edb6dc5f303093c2604cd07b0c0dacf12dbce5de",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 53.45,
          "commitsBetweenForRepo": 495,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,9 @@\n-  public static URI getServiceUriFromToken(\n-      Token\u003cDelegationTokenIdentifier\u003e token)\n-      throws IOException {\n+  public static URI getServiceUriFromToken(final String scheme,\n+                                           Token\u003c?\u003e token) {\n     String tokStr \u003d token.getService().toString();\n \n     if (tokStr.startsWith(HA_DT_SERVICE_PREFIX)) {\n       tokStr \u003d tokStr.replaceFirst(HA_DT_SERVICE_PREFIX, \"\");\n     }\n-    \n-    try {\n-      return new URI(HdfsConstants.HDFS_URI_SCHEME + \"://\" +\n-          tokStr);\n-    } catch (URISyntaxException e) {\n-      throw new IOException(\"Invalid token contents: \u0027\" +\n-          tokStr + \"\u0027\");\n-    }\n+    return URI.create(scheme + \"://\" + tokStr);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static URI getServiceUriFromToken(final String scheme,\n                                           Token\u003c?\u003e token) {\n    String tokStr \u003d token.getService().toString();\n\n    if (tokStr.startsWith(HA_DT_SERVICE_PREFIX)) {\n      tokStr \u003d tokStr.replaceFirst(HA_DT_SERVICE_PREFIX, \"\");\n    }\n    return URI.create(scheme + \"://\" + tokStr);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
          "extendedDetails": {
            "oldValue": "[IOException]",
            "newValue": "[]"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-6127. WebHDFS tokens cannot be renewed in HA setup. Contributed by Haohui Mai.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1579546 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "19/03/14 11:47 PM",
          "commitName": "aa4a045925649949b2eaa5b7238edbd742cbcf9a",
          "commitAuthor": "Haohui Mai",
          "commitDateOld": "25/01/14 12:01 PM",
          "commitNameOld": "edb6dc5f303093c2604cd07b0c0dacf12dbce5de",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 53.45,
          "commitsBetweenForRepo": 495,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,17 +1,9 @@\n-  public static URI getServiceUriFromToken(\n-      Token\u003cDelegationTokenIdentifier\u003e token)\n-      throws IOException {\n+  public static URI getServiceUriFromToken(final String scheme,\n+                                           Token\u003c?\u003e token) {\n     String tokStr \u003d token.getService().toString();\n \n     if (tokStr.startsWith(HA_DT_SERVICE_PREFIX)) {\n       tokStr \u003d tokStr.replaceFirst(HA_DT_SERVICE_PREFIX, \"\");\n     }\n-    \n-    try {\n-      return new URI(HdfsConstants.HDFS_URI_SCHEME + \"://\" +\n-          tokStr);\n-    } catch (URISyntaxException e) {\n-      throw new IOException(\"Invalid token contents: \u0027\" +\n-          tokStr + \"\u0027\");\n-    }\n+    return URI.create(scheme + \"://\" + tokStr);\n   }\n\\ No newline at end of file\n",
          "actualSource": "  public static URI getServiceUriFromToken(final String scheme,\n                                           Token\u003c?\u003e token) {\n    String tokStr \u003d token.getService().toString();\n\n    if (tokStr.startsWith(HA_DT_SERVICE_PREFIX)) {\n      tokStr \u003d tokStr.replaceFirst(HA_DT_SERVICE_PREFIX, \"\");\n    }\n    return URI.create(scheme + \"://\" + tokStr);\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java",
          "extendedDetails": {}
        }
      ]
    },
    "481f84597bf842df45b068cc24c328112e8bcf40": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-2904. Client support for getting delegation tokens. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-1623@1293486 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "24/02/12 4:03 PM",
      "commitName": "481f84597bf842df45b068cc24c328112e8bcf40",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,17 @@\n+  public static URI getServiceUriFromToken(\n+      Token\u003cDelegationTokenIdentifier\u003e token)\n+      throws IOException {\n+    String tokStr \u003d token.getService().toString();\n+\n+    if (tokStr.startsWith(HA_DT_SERVICE_PREFIX)) {\n+      tokStr \u003d tokStr.replaceFirst(HA_DT_SERVICE_PREFIX, \"\");\n+    }\n+    \n+    try {\n+      return new URI(HdfsConstants.HDFS_URI_SCHEME + \"://\" +\n+          tokStr);\n+    } catch (URISyntaxException e) {\n+      throw new IOException(\"Invalid token contents: \u0027\" +\n+          tokStr + \"\u0027\");\n+    }\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  public static URI getServiceUriFromToken(\n      Token\u003cDelegationTokenIdentifier\u003e token)\n      throws IOException {\n    String tokStr \u003d token.getService().toString();\n\n    if (tokStr.startsWith(HA_DT_SERVICE_PREFIX)) {\n      tokStr \u003d tokStr.replaceFirst(HA_DT_SERVICE_PREFIX, \"\");\n    }\n    \n    try {\n      return new URI(HdfsConstants.HDFS_URI_SCHEME + \"://\" +\n          tokStr);\n    } catch (URISyntaxException e) {\n      throw new IOException(\"Invalid token contents: \u0027\" +\n          tokStr + \"\u0027\");\n    }\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java"
    }
  }
}