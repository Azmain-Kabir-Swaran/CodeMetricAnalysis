{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "QuorumJournalManager.java",
  "functionName": "createNewUniqueEpoch",
  "functionId": "createNewUniqueEpoch",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
  "functionStartLine": 227,
  "functionEndLine": 249,
  "numCommitsSeen": 51,
  "timeTaken": 1853,
  "changeHistory": [
    "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38",
    "74d4573a23db5586c6e47ff2277aa7c35237da34"
  ],
  "changeHistoryShort": {
    "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38": "Ymultichange(Ymovefromfile,Ybodychange,Yparameterchange)",
    "74d4573a23db5586c6e47ff2277aa7c35237da34": "Yintroduced"
  },
  "changeHistoryDetails": {
    "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38": {
      "type": "Ymultichange(Ymovefromfile,Ybodychange,Yparameterchange)",
      "commitMessage": "HDFS-3906. QJM: quorum timeout on failover with large log segment. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1383251 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "10/09/12 11:31 PM",
      "commitName": "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38",
      "commitAuthor": "Todd Lipcon",
      "subchanges": [
        {
          "type": "Ymovefromfile",
          "commitMessage": "HDFS-3906. QJM: quorum timeout on failover with large log segment. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1383251 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/09/12 11:31 PM",
          "commitName": "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "10/09/12 9:53 PM",
          "commitNameOld": "c859e87d1efdc48b9a7f6d2b41151094825d881e",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.07,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,23 @@\n-  Map\u003cAsyncLogger, NewEpochResponseProto\u003e createNewUniqueEpoch(\n-      NamespaceInfo nsInfo) throws IOException {\n-    Preconditions.checkState(myEpoch \u003d\u003d -1,\n-        \"epoch already created: epoch\u003d\" + myEpoch);\n+  Map\u003cAsyncLogger, NewEpochResponseProto\u003e createNewUniqueEpoch()\n+      throws IOException {\n+    Preconditions.checkState(!loggers.isEpochEstablished(),\n+        \"epoch already created\");\n     \n     Map\u003cAsyncLogger, GetJournalStateResponseProto\u003e lastPromises \u003d\n-      waitForWriteQuorum(getJournalState(), NEWEPOCH_TIMEOUT_MS);\n+      loggers.waitForWriteQuorum(loggers.getJournalState(),\n+          getJournalStateTimeoutMs, \"getJournalState()\");\n     \n     long maxPromised \u003d Long.MIN_VALUE;\n     for (GetJournalStateResponseProto resp : lastPromises.values()) {\n       maxPromised \u003d Math.max(maxPromised, resp.getLastPromisedEpoch());\n     }\n     assert maxPromised \u003e\u003d 0;\n     \n     long myEpoch \u003d maxPromised + 1;\n     Map\u003cAsyncLogger, NewEpochResponseProto\u003e resps \u003d\n-        waitForWriteQuorum(newEpoch(nsInfo, myEpoch), NEWEPOCH_TIMEOUT_MS);\n-    this.myEpoch \u003d myEpoch;\n-    setEpoch(myEpoch);\n+        loggers.waitForWriteQuorum(loggers.newEpoch(nsInfo, myEpoch),\n+            newEpochTimeoutMs, \"newEpoch(\" + myEpoch + \")\");\n+        \n+    loggers.setEpoch(myEpoch);\n     return resps;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  Map\u003cAsyncLogger, NewEpochResponseProto\u003e createNewUniqueEpoch()\n      throws IOException {\n    Preconditions.checkState(!loggers.isEpochEstablished(),\n        \"epoch already created\");\n    \n    Map\u003cAsyncLogger, GetJournalStateResponseProto\u003e lastPromises \u003d\n      loggers.waitForWriteQuorum(loggers.getJournalState(),\n          getJournalStateTimeoutMs, \"getJournalState()\");\n    \n    long maxPromised \u003d Long.MIN_VALUE;\n    for (GetJournalStateResponseProto resp : lastPromises.values()) {\n      maxPromised \u003d Math.max(maxPromised, resp.getLastPromisedEpoch());\n    }\n    assert maxPromised \u003e\u003d 0;\n    \n    long myEpoch \u003d maxPromised + 1;\n    Map\u003cAsyncLogger, NewEpochResponseProto\u003e resps \u003d\n        loggers.waitForWriteQuorum(loggers.newEpoch(nsInfo, myEpoch),\n            newEpochTimeoutMs, \"newEpoch(\" + myEpoch + \")\");\n        \n    loggers.setEpoch(myEpoch);\n    return resps;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
          "extendedDetails": {
            "oldPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/AsyncLoggerSet.java",
            "newPath": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
            "oldMethodName": "createNewUniqueEpoch",
            "newMethodName": "createNewUniqueEpoch"
          }
        },
        {
          "type": "Ybodychange",
          "commitMessage": "HDFS-3906. QJM: quorum timeout on failover with large log segment. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1383251 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/09/12 11:31 PM",
          "commitName": "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "10/09/12 9:53 PM",
          "commitNameOld": "c859e87d1efdc48b9a7f6d2b41151094825d881e",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.07,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,23 @@\n-  Map\u003cAsyncLogger, NewEpochResponseProto\u003e createNewUniqueEpoch(\n-      NamespaceInfo nsInfo) throws IOException {\n-    Preconditions.checkState(myEpoch \u003d\u003d -1,\n-        \"epoch already created: epoch\u003d\" + myEpoch);\n+  Map\u003cAsyncLogger, NewEpochResponseProto\u003e createNewUniqueEpoch()\n+      throws IOException {\n+    Preconditions.checkState(!loggers.isEpochEstablished(),\n+        \"epoch already created\");\n     \n     Map\u003cAsyncLogger, GetJournalStateResponseProto\u003e lastPromises \u003d\n-      waitForWriteQuorum(getJournalState(), NEWEPOCH_TIMEOUT_MS);\n+      loggers.waitForWriteQuorum(loggers.getJournalState(),\n+          getJournalStateTimeoutMs, \"getJournalState()\");\n     \n     long maxPromised \u003d Long.MIN_VALUE;\n     for (GetJournalStateResponseProto resp : lastPromises.values()) {\n       maxPromised \u003d Math.max(maxPromised, resp.getLastPromisedEpoch());\n     }\n     assert maxPromised \u003e\u003d 0;\n     \n     long myEpoch \u003d maxPromised + 1;\n     Map\u003cAsyncLogger, NewEpochResponseProto\u003e resps \u003d\n-        waitForWriteQuorum(newEpoch(nsInfo, myEpoch), NEWEPOCH_TIMEOUT_MS);\n-    this.myEpoch \u003d myEpoch;\n-    setEpoch(myEpoch);\n+        loggers.waitForWriteQuorum(loggers.newEpoch(nsInfo, myEpoch),\n+            newEpochTimeoutMs, \"newEpoch(\" + myEpoch + \")\");\n+        \n+    loggers.setEpoch(myEpoch);\n     return resps;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  Map\u003cAsyncLogger, NewEpochResponseProto\u003e createNewUniqueEpoch()\n      throws IOException {\n    Preconditions.checkState(!loggers.isEpochEstablished(),\n        \"epoch already created\");\n    \n    Map\u003cAsyncLogger, GetJournalStateResponseProto\u003e lastPromises \u003d\n      loggers.waitForWriteQuorum(loggers.getJournalState(),\n          getJournalStateTimeoutMs, \"getJournalState()\");\n    \n    long maxPromised \u003d Long.MIN_VALUE;\n    for (GetJournalStateResponseProto resp : lastPromises.values()) {\n      maxPromised \u003d Math.max(maxPromised, resp.getLastPromisedEpoch());\n    }\n    assert maxPromised \u003e\u003d 0;\n    \n    long myEpoch \u003d maxPromised + 1;\n    Map\u003cAsyncLogger, NewEpochResponseProto\u003e resps \u003d\n        loggers.waitForWriteQuorum(loggers.newEpoch(nsInfo, myEpoch),\n            newEpochTimeoutMs, \"newEpoch(\" + myEpoch + \")\");\n        \n    loggers.setEpoch(myEpoch);\n    return resps;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
          "extendedDetails": {}
        },
        {
          "type": "Yparameterchange",
          "commitMessage": "HDFS-3906. QJM: quorum timeout on failover with large log segment. Contributed by Todd Lipcon.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1383251 13f79535-47bb-0310-9956-ffa450edef68\n",
          "commitDate": "10/09/12 11:31 PM",
          "commitName": "8a8c9c18d37f0c8b219264796c0df4bcae6f4e38",
          "commitAuthor": "Todd Lipcon",
          "commitDateOld": "10/09/12 9:53 PM",
          "commitNameOld": "c859e87d1efdc48b9a7f6d2b41151094825d881e",
          "commitAuthorOld": "Todd Lipcon",
          "daysBetweenCommits": 0.07,
          "commitsBetweenForRepo": 1,
          "commitsBetweenForFile": 1,
          "diff": "@@ -1,21 +1,23 @@\n-  Map\u003cAsyncLogger, NewEpochResponseProto\u003e createNewUniqueEpoch(\n-      NamespaceInfo nsInfo) throws IOException {\n-    Preconditions.checkState(myEpoch \u003d\u003d -1,\n-        \"epoch already created: epoch\u003d\" + myEpoch);\n+  Map\u003cAsyncLogger, NewEpochResponseProto\u003e createNewUniqueEpoch()\n+      throws IOException {\n+    Preconditions.checkState(!loggers.isEpochEstablished(),\n+        \"epoch already created\");\n     \n     Map\u003cAsyncLogger, GetJournalStateResponseProto\u003e lastPromises \u003d\n-      waitForWriteQuorum(getJournalState(), NEWEPOCH_TIMEOUT_MS);\n+      loggers.waitForWriteQuorum(loggers.getJournalState(),\n+          getJournalStateTimeoutMs, \"getJournalState()\");\n     \n     long maxPromised \u003d Long.MIN_VALUE;\n     for (GetJournalStateResponseProto resp : lastPromises.values()) {\n       maxPromised \u003d Math.max(maxPromised, resp.getLastPromisedEpoch());\n     }\n     assert maxPromised \u003e\u003d 0;\n     \n     long myEpoch \u003d maxPromised + 1;\n     Map\u003cAsyncLogger, NewEpochResponseProto\u003e resps \u003d\n-        waitForWriteQuorum(newEpoch(nsInfo, myEpoch), NEWEPOCH_TIMEOUT_MS);\n-    this.myEpoch \u003d myEpoch;\n-    setEpoch(myEpoch);\n+        loggers.waitForWriteQuorum(loggers.newEpoch(nsInfo, myEpoch),\n+            newEpochTimeoutMs, \"newEpoch(\" + myEpoch + \")\");\n+        \n+    loggers.setEpoch(myEpoch);\n     return resps;\n   }\n\\ No newline at end of file\n",
          "actualSource": "  Map\u003cAsyncLogger, NewEpochResponseProto\u003e createNewUniqueEpoch()\n      throws IOException {\n    Preconditions.checkState(!loggers.isEpochEstablished(),\n        \"epoch already created\");\n    \n    Map\u003cAsyncLogger, GetJournalStateResponseProto\u003e lastPromises \u003d\n      loggers.waitForWriteQuorum(loggers.getJournalState(),\n          getJournalStateTimeoutMs, \"getJournalState()\");\n    \n    long maxPromised \u003d Long.MIN_VALUE;\n    for (GetJournalStateResponseProto resp : lastPromises.values()) {\n      maxPromised \u003d Math.max(maxPromised, resp.getLastPromisedEpoch());\n    }\n    assert maxPromised \u003e\u003d 0;\n    \n    long myEpoch \u003d maxPromised + 1;\n    Map\u003cAsyncLogger, NewEpochResponseProto\u003e resps \u003d\n        loggers.waitForWriteQuorum(loggers.newEpoch(nsInfo, myEpoch),\n            newEpochTimeoutMs, \"newEpoch(\" + myEpoch + \")\");\n        \n    loggers.setEpoch(myEpoch);\n    return resps;\n  }",
          "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/QuorumJournalManager.java",
          "extendedDetails": {
            "oldValue": "[nsInfo-NamespaceInfo]",
            "newValue": "[]"
          }
        }
      ]
    },
    "74d4573a23db5586c6e47ff2277aa7c35237da34": {
      "type": "Yintroduced",
      "commitMessage": "HDFS-3077. Quorum-based protocol for reading and writing edit logs. Contributed by Todd Lipcon based on initial work from Brandon Li and Hari Mankude.\n\ngit-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-3077@1363596 13f79535-47bb-0310-9956-ffa450edef68\n",
      "commitDate": "19/07/12 5:25 PM",
      "commitName": "74d4573a23db5586c6e47ff2277aa7c35237da34",
      "commitAuthor": "Todd Lipcon",
      "diff": "@@ -0,0 +1,21 @@\n+  Map\u003cAsyncLogger, NewEpochResponseProto\u003e createNewUniqueEpoch(\n+      NamespaceInfo nsInfo) throws IOException {\n+    Preconditions.checkState(myEpoch \u003d\u003d -1,\n+        \"epoch already created: epoch\u003d\" + myEpoch);\n+    \n+    Map\u003cAsyncLogger, GetJournalStateResponseProto\u003e lastPromises \u003d\n+      waitForWriteQuorum(getJournalState(), NEWEPOCH_TIMEOUT_MS);\n+    \n+    long maxPromised \u003d Long.MIN_VALUE;\n+    for (GetJournalStateResponseProto resp : lastPromises.values()) {\n+      maxPromised \u003d Math.max(maxPromised, resp.getLastPromisedEpoch());\n+    }\n+    assert maxPromised \u003e\u003d 0;\n+    \n+    long myEpoch \u003d maxPromised + 1;\n+    Map\u003cAsyncLogger, NewEpochResponseProto\u003e resps \u003d\n+        waitForWriteQuorum(newEpoch(nsInfo, myEpoch), NEWEPOCH_TIMEOUT_MS);\n+    this.myEpoch \u003d myEpoch;\n+    setEpoch(myEpoch);\n+    return resps;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  Map\u003cAsyncLogger, NewEpochResponseProto\u003e createNewUniqueEpoch(\n      NamespaceInfo nsInfo) throws IOException {\n    Preconditions.checkState(myEpoch \u003d\u003d -1,\n        \"epoch already created: epoch\u003d\" + myEpoch);\n    \n    Map\u003cAsyncLogger, GetJournalStateResponseProto\u003e lastPromises \u003d\n      waitForWriteQuorum(getJournalState(), NEWEPOCH_TIMEOUT_MS);\n    \n    long maxPromised \u003d Long.MIN_VALUE;\n    for (GetJournalStateResponseProto resp : lastPromises.values()) {\n      maxPromised \u003d Math.max(maxPromised, resp.getLastPromisedEpoch());\n    }\n    assert maxPromised \u003e\u003d 0;\n    \n    long myEpoch \u003d maxPromised + 1;\n    Map\u003cAsyncLogger, NewEpochResponseProto\u003e resps \u003d\n        waitForWriteQuorum(newEpoch(nsInfo, myEpoch), NEWEPOCH_TIMEOUT_MS);\n    this.myEpoch \u003d myEpoch;\n    setEpoch(myEpoch);\n    return resps;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/qjournal/client/AsyncLoggerSet.java"
    }
  }
}