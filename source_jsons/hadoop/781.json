{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "StripedDataStreamer.java",
  "functionName": "nextBlockOutputStream",
  "functionId": "nextBlockOutputStream",
  "sourceFilePath": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/StripedDataStreamer.java",
  "functionStartLine": 93,
  "functionEndLine": 117,
  "numCommitsSeen": 8,
  "timeTaken": 991,
  "changeHistory": [
    "a3954ccab148bddc290cb96528e63ff19799bcc9",
    "627da6f7178e18aa41996969c408b6f344e297d1",
    "16c07cc68a3e0a06f57b7f4c7207cc8e5dce211f",
    "a8b4d0ff283a0af1075aaa94904d4c6e63a9a3dd"
  ],
  "changeHistoryShort": {
    "a3954ccab148bddc290cb96528e63ff19799bcc9": "Ybodychange",
    "627da6f7178e18aa41996969c408b6f344e297d1": "Ybodychange",
    "16c07cc68a3e0a06f57b7f4c7207cc8e5dce211f": "Ybodychange",
    "a8b4d0ff283a0af1075aaa94904d4c6e63a9a3dd": "Ybodychange"
  },
  "changeHistoryDetails": {
    "a3954ccab148bddc290cb96528e63ff19799bcc9": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9807. Add an optional StorageID to writes. Contributed by Ewan Higgs\n",
      "commitDate": "05/05/17 12:01 PM",
      "commitName": "a3954ccab148bddc290cb96528e63ff19799bcc9",
      "commitAuthor": "Chris Douglas",
      "commitDateOld": "15/02/17 10:44 AM",
      "commitNameOld": "627da6f7178e18aa41996969c408b6f344e297d1",
      "commitAuthorOld": "Jing Zhao",
      "daysBetweenCommits": 79.01,
      "commitsBetweenForRepo": 465,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,25 @@\n   protected LocatedBlock nextBlockOutputStream() throws IOException {\n     boolean success;\n     LocatedBlock lb \u003d getFollowingBlock();\n     block.setCurrentBlock(lb.getBlock());\n     block.setNumBytes(0);\n     bytesSent \u003d 0;\n     accessToken \u003d lb.getBlockToken();\n \n     DatanodeInfo[] nodes \u003d lb.getLocations();\n     StorageType[] storageTypes \u003d lb.getStorageTypes();\n+    String[] storageIDs \u003d lb.getStorageIDs();\n \n     // Connect to the DataNode. If fail the internal error state will be set.\n-    success \u003d createBlockOutputStream(nodes, storageTypes, 0L, false);\n+    success \u003d createBlockOutputStream(nodes, storageTypes, storageIDs, 0L,\n+        false);\n \n     if (!success) {\n       block.setCurrentBlock(null);\n       final DatanodeInfo badNode \u003d nodes[getErrorState().getBadNodeIndex()];\n       LOG.warn(\"Excluding datanode \" + badNode);\n       excludedNodes.put(badNode, badNode);\n       throw new IOException(\"Unable to create new block.\" + this);\n     }\n     return lb;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected LocatedBlock nextBlockOutputStream() throws IOException {\n    boolean success;\n    LocatedBlock lb \u003d getFollowingBlock();\n    block.setCurrentBlock(lb.getBlock());\n    block.setNumBytes(0);\n    bytesSent \u003d 0;\n    accessToken \u003d lb.getBlockToken();\n\n    DatanodeInfo[] nodes \u003d lb.getLocations();\n    StorageType[] storageTypes \u003d lb.getStorageTypes();\n    String[] storageIDs \u003d lb.getStorageIDs();\n\n    // Connect to the DataNode. If fail the internal error state will be set.\n    success \u003d createBlockOutputStream(nodes, storageTypes, storageIDs, 0L,\n        false);\n\n    if (!success) {\n      block.setCurrentBlock(null);\n      final DatanodeInfo badNode \u003d nodes[getErrorState().getBadNodeIndex()];\n      LOG.warn(\"Excluding datanode \" + badNode);\n      excludedNodes.put(badNode, badNode);\n      throw new IOException(\"Unable to create new block.\" + this);\n    }\n    return lb;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/StripedDataStreamer.java",
      "extendedDetails": {}
    },
    "627da6f7178e18aa41996969c408b6f344e297d1": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-8498. Blocks can be committed with wrong size. Contributed by Jing Zhao.\n",
      "commitDate": "15/02/17 10:44 AM",
      "commitName": "627da6f7178e18aa41996969c408b6f344e297d1",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "17/05/16 3:57 PM",
      "commitNameOld": "16c07cc68a3e0a06f57b7f4c7207cc8e5dce211f",
      "commitAuthorOld": "Yongjun Zhang",
      "daysBetweenCommits": 273.82,
      "commitsBetweenForRepo": 1886,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,23 @@\n   protected LocatedBlock nextBlockOutputStream() throws IOException {\n     boolean success;\n     LocatedBlock lb \u003d getFollowingBlock();\n-    block \u003d lb.getBlock();\n+    block.setCurrentBlock(lb.getBlock());\n     block.setNumBytes(0);\n     bytesSent \u003d 0;\n     accessToken \u003d lb.getBlockToken();\n \n     DatanodeInfo[] nodes \u003d lb.getLocations();\n     StorageType[] storageTypes \u003d lb.getStorageTypes();\n \n     // Connect to the DataNode. If fail the internal error state will be set.\n     success \u003d createBlockOutputStream(nodes, storageTypes, 0L, false);\n \n     if (!success) {\n-      block \u003d null;\n+      block.setCurrentBlock(null);\n       final DatanodeInfo badNode \u003d nodes[getErrorState().getBadNodeIndex()];\n       LOG.warn(\"Excluding datanode \" + badNode);\n       excludedNodes.put(badNode, badNode);\n       throw new IOException(\"Unable to create new block.\" + this);\n     }\n     return lb;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected LocatedBlock nextBlockOutputStream() throws IOException {\n    boolean success;\n    LocatedBlock lb \u003d getFollowingBlock();\n    block.setCurrentBlock(lb.getBlock());\n    block.setNumBytes(0);\n    bytesSent \u003d 0;\n    accessToken \u003d lb.getBlockToken();\n\n    DatanodeInfo[] nodes \u003d lb.getLocations();\n    StorageType[] storageTypes \u003d lb.getStorageTypes();\n\n    // Connect to the DataNode. If fail the internal error state will be set.\n    success \u003d createBlockOutputStream(nodes, storageTypes, 0L, false);\n\n    if (!success) {\n      block.setCurrentBlock(null);\n      final DatanodeInfo badNode \u003d nodes[getErrorState().getBadNodeIndex()];\n      LOG.warn(\"Excluding datanode \" + badNode);\n      excludedNodes.put(badNode, badNode);\n      throw new IOException(\"Unable to create new block.\" + this);\n    }\n    return lb;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/StripedDataStreamer.java",
      "extendedDetails": {}
    },
    "16c07cc68a3e0a06f57b7f4c7207cc8e5dce211f": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-10381, DataStreamer DataNode exclusion log message should be warning. (John Zhuge via Yongjun Zhang)\n",
      "commitDate": "17/05/16 3:57 PM",
      "commitName": "16c07cc68a3e0a06f57b7f4c7207cc8e5dce211f",
      "commitAuthor": "Yongjun Zhang",
      "commitDateOld": "27/04/16 2:22 PM",
      "commitNameOld": "0a152103f19a3e8e1b7f33aeb9dd115ba231d7b7",
      "commitAuthorOld": "Lei Xu",
      "daysBetweenCommits": 20.07,
      "commitsBetweenForRepo": 131,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,23 @@\n   protected LocatedBlock nextBlockOutputStream() throws IOException {\n     boolean success;\n     LocatedBlock lb \u003d getFollowingBlock();\n     block \u003d lb.getBlock();\n     block.setNumBytes(0);\n     bytesSent \u003d 0;\n     accessToken \u003d lb.getBlockToken();\n \n     DatanodeInfo[] nodes \u003d lb.getLocations();\n     StorageType[] storageTypes \u003d lb.getStorageTypes();\n \n     // Connect to the DataNode. If fail the internal error state will be set.\n     success \u003d createBlockOutputStream(nodes, storageTypes, 0L, false);\n \n     if (!success) {\n       block \u003d null;\n       final DatanodeInfo badNode \u003d nodes[getErrorState().getBadNodeIndex()];\n-      LOG.info(\"Excluding datanode \" + badNode);\n+      LOG.warn(\"Excluding datanode \" + badNode);\n       excludedNodes.put(badNode, badNode);\n       throw new IOException(\"Unable to create new block.\" + this);\n     }\n     return lb;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected LocatedBlock nextBlockOutputStream() throws IOException {\n    boolean success;\n    LocatedBlock lb \u003d getFollowingBlock();\n    block \u003d lb.getBlock();\n    block.setNumBytes(0);\n    bytesSent \u003d 0;\n    accessToken \u003d lb.getBlockToken();\n\n    DatanodeInfo[] nodes \u003d lb.getLocations();\n    StorageType[] storageTypes \u003d lb.getStorageTypes();\n\n    // Connect to the DataNode. If fail the internal error state will be set.\n    success \u003d createBlockOutputStream(nodes, storageTypes, 0L, false);\n\n    if (!success) {\n      block \u003d null;\n      final DatanodeInfo badNode \u003d nodes[getErrorState().getBadNodeIndex()];\n      LOG.warn(\"Excluding datanode \" + badNode);\n      excludedNodes.put(badNode, badNode);\n      throw new IOException(\"Unable to create new block.\" + this);\n    }\n    return lb;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/StripedDataStreamer.java",
      "extendedDetails": {}
    },
    "a8b4d0ff283a0af1075aaa94904d4c6e63a9a3dd": {
      "type": "Ybodychange",
      "commitMessage": "HDFS-9180. Update excluded DataNodes in DFSStripedOutputStream based on failures in data streamers. Contributed by Jing Zhao.\n",
      "commitDate": "06/10/15 10:56 AM",
      "commitName": "a8b4d0ff283a0af1075aaa94904d4c6e63a9a3dd",
      "commitAuthor": "Jing Zhao",
      "commitDateOld": "03/10/15 11:38 AM",
      "commitNameOld": "7136e8c5582dc4061b566cb9f11a0d6a6d08bb93",
      "commitAuthorOld": "Haohui Mai",
      "daysBetweenCommits": 2.97,
      "commitsBetweenForRepo": 12,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,23 +1,23 @@\n   protected LocatedBlock nextBlockOutputStream() throws IOException {\n     boolean success;\n     LocatedBlock lb \u003d getFollowingBlock();\n     block \u003d lb.getBlock();\n     block.setNumBytes(0);\n     bytesSent \u003d 0;\n     accessToken \u003d lb.getBlockToken();\n \n     DatanodeInfo[] nodes \u003d lb.getLocations();\n     StorageType[] storageTypes \u003d lb.getStorageTypes();\n \n     // Connect to the DataNode. If fail the internal error state will be set.\n     success \u003d createBlockOutputStream(nodes, storageTypes, 0L, false);\n \n     if (!success) {\n       block \u003d null;\n       final DatanodeInfo badNode \u003d nodes[getErrorState().getBadNodeIndex()];\n       LOG.info(\"Excluding datanode \" + badNode);\n       excludedNodes.put(badNode, badNode);\n-      throw new IOException(\"Unable to create new block.\");\n+      throw new IOException(\"Unable to create new block.\" + this);\n     }\n     return lb;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  protected LocatedBlock nextBlockOutputStream() throws IOException {\n    boolean success;\n    LocatedBlock lb \u003d getFollowingBlock();\n    block \u003d lb.getBlock();\n    block.setNumBytes(0);\n    bytesSent \u003d 0;\n    accessToken \u003d lb.getBlockToken();\n\n    DatanodeInfo[] nodes \u003d lb.getLocations();\n    StorageType[] storageTypes \u003d lb.getStorageTypes();\n\n    // Connect to the DataNode. If fail the internal error state will be set.\n    success \u003d createBlockOutputStream(nodes, storageTypes, 0L, false);\n\n    if (!success) {\n      block \u003d null;\n      final DatanodeInfo badNode \u003d nodes[getErrorState().getBadNodeIndex()];\n      LOG.info(\"Excluding datanode \" + badNode);\n      excludedNodes.put(badNode, badNode);\n      throw new IOException(\"Unable to create new block.\" + this);\n    }\n    return lb;\n  }",
      "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/StripedDataStreamer.java",
      "extendedDetails": {}
    }
  }
}