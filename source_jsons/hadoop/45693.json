{
  "origin": "codeshovel",
  "repositoryName": "hadoop",
  "repositoryPath": "/home/shaiful/research/codeshovel/codeshovel-projects/hadoop/.git",
  "startCommitName": "HEAD",
  "sourceFileName": "IndexedFileAggregatedLogsBlock.java",
  "functionName": "readContainerLog",
  "functionId": "readContainerLog___compressAlgo-String__html-Block__thisNodeFile-FileStatus__start-long__end-long__candidates-List__IndexedFileLogMeta____startTime-long__endTime-long__foundLog-boolean__logEntity-String",
  "sourceFilePath": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/filecontroller/ifile/IndexedFileAggregatedLogsBlock.java",
  "functionStartLine": 196,
  "functionEndLine": 240,
  "numCommitsSeen": 8,
  "timeTaken": 1356,
  "changeHistory": [
    "c24af4b0d6fc32938b076161b5a8c86d38e3e0a1",
    "74411ce0ce7336c0f7bb5793939fdd64a5dcdef6"
  ],
  "changeHistoryShort": {
    "c24af4b0d6fc32938b076161b5a8c86d38e3e0a1": "Ybodychange",
    "74411ce0ce7336c0f7bb5793939fdd64a5dcdef6": "Yintroduced"
  },
  "changeHistoryDetails": {
    "c24af4b0d6fc32938b076161b5a8c86d38e3e0a1": {
      "type": "Ybodychange",
      "commitMessage": "YARN-9336. JobHistoryServer leaks CLOSE_WAIT tcp connections when using LogAggregationIndexedFileController. Contributed by Tarun Parimi.\n",
      "commitDate": "12/03/19 8:27 AM",
      "commitName": "c24af4b0d6fc32938b076161b5a8c86d38e3e0a1",
      "commitAuthor": "Rohith Sharma K S",
      "commitDateOld": "13/08/18 1:50 PM",
      "commitNameOld": "74411ce0ce7336c0f7bb5793939fdd64a5dcdef6",
      "commitAuthorOld": "Eric Yang",
      "daysBetweenCommits": 210.78,
      "commitsBetweenForRepo": 1665,
      "commitsBetweenForFile": 1,
      "diff": "@@ -1,45 +1,45 @@\n   private boolean readContainerLog(String compressAlgo, Block html,\n       FileStatus thisNodeFile, long start, long end,\n       List\u003cIndexedFileLogMeta\u003e candidates, long startTime, long endTime,\n       boolean foundLog, String logEntity) throws IOException {\n     Algorithm compressName \u003d Compression.getCompressionAlgorithmByName(\n         compressAlgo);\n     Decompressor decompressor \u003d compressName.getDecompressor();\n     FileContext fileContext \u003d FileContext.getFileContext(\n         thisNodeFile.getPath().toUri(), conf);\n-    FSDataInputStream fsin \u003d fileContext.open(thisNodeFile.getPath());\n-    int bufferSize \u003d 65536;\n-    for (IndexedFileLogMeta candidate : candidates) {\n-      if (candidate.getLastModifiedTime() \u003c startTime\n-          || candidate.getLastModifiedTime() \u003e endTime) {\n-        continue;\n-      }\n-      byte[] cbuf \u003d new byte[bufferSize];\n-      InputStream in \u003d null;\n-      try {\n-        in \u003d compressName.createDecompressionStream(\n-            new BoundedRangeFileInputStream(fsin, candidate.getStartIndex(),\n-                candidate.getFileCompressedSize()), decompressor,\n-            LogAggregationIndexedFileController.getFSInputBufferSize(conf));\n-        long logLength \u003d candidate.getFileSize();\n-        html.pre().__(\"\\n\\n\").__();\n-        html.p().__(\"Log Type: \" + candidate.getFileName()).__();\n-        html.p().__(\n-            \"Log Upload Time: \" + Times.format(candidate.getLastModifiedTime()))\n-            .__();\n-        html.p().__(\"Log Length: \" + Long.toString(logLength)).__();\n+    try (FSDataInputStream fsin \u003d fileContext.open(thisNodeFile.getPath())) {\n+      int bufferSize \u003d 65536;\n+      for (IndexedFileLogMeta candidate : candidates) {\n+        if (candidate.getLastModifiedTime() \u003c startTime\n+            || candidate.getLastModifiedTime() \u003e endTime) {\n+          continue;\n+        }\n+        byte[] cbuf \u003d new byte[bufferSize];\n+        InputStream in \u003d null;\n+        try {\n+          in \u003d compressName.createDecompressionStream(\n+              new BoundedRangeFileInputStream(fsin, candidate.getStartIndex(),\n+                  candidate.getFileCompressedSize()), decompressor,\n+              LogAggregationIndexedFileController.getFSInputBufferSize(conf));\n+          long logLength \u003d candidate.getFileSize();\n+          html.pre().__(\"\\n\\n\").__();\n+          html.p().__(\"Log Type: \" + candidate.getFileName()).__();\n+          html.p().__(\"Log Upload Time: \" +\n+              Times.format(candidate.getLastModifiedTime())).__();\n+          html.p().__(\"Log Length: \" + Long.toString(logLength)).__();\n \n-        long[] range \u003d checkParseRange(html, start, end, startTime, endTime,\n-            logLength, candidate.getFileName());\n-        processContainerLog(html, range, in, bufferSize, cbuf);\n+          long[] range \u003d checkParseRange(html, start, end, startTime, endTime,\n+              logLength, candidate.getFileName());\n+          processContainerLog(html, range, in, bufferSize, cbuf);\n \n-        foundLog \u003d true;\n-      } catch (Exception ex) {\n-        LOG.error(\"Error getting logs for \" + logEntity, ex);\n-        continue;\n-      } finally {\n-        IOUtils.closeQuietly(in);\n+          foundLog \u003d true;\n+        } catch (Exception ex) {\n+          LOG.error(\"Error getting logs for \" + logEntity, ex);\n+          continue;\n+        } finally {\n+          IOUtils.closeQuietly(in);\n+        }\n       }\n     }\n     return foundLog;\n   }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean readContainerLog(String compressAlgo, Block html,\n      FileStatus thisNodeFile, long start, long end,\n      List\u003cIndexedFileLogMeta\u003e candidates, long startTime, long endTime,\n      boolean foundLog, String logEntity) throws IOException {\n    Algorithm compressName \u003d Compression.getCompressionAlgorithmByName(\n        compressAlgo);\n    Decompressor decompressor \u003d compressName.getDecompressor();\n    FileContext fileContext \u003d FileContext.getFileContext(\n        thisNodeFile.getPath().toUri(), conf);\n    try (FSDataInputStream fsin \u003d fileContext.open(thisNodeFile.getPath())) {\n      int bufferSize \u003d 65536;\n      for (IndexedFileLogMeta candidate : candidates) {\n        if (candidate.getLastModifiedTime() \u003c startTime\n            || candidate.getLastModifiedTime() \u003e endTime) {\n          continue;\n        }\n        byte[] cbuf \u003d new byte[bufferSize];\n        InputStream in \u003d null;\n        try {\n          in \u003d compressName.createDecompressionStream(\n              new BoundedRangeFileInputStream(fsin, candidate.getStartIndex(),\n                  candidate.getFileCompressedSize()), decompressor,\n              LogAggregationIndexedFileController.getFSInputBufferSize(conf));\n          long logLength \u003d candidate.getFileSize();\n          html.pre().__(\"\\n\\n\").__();\n          html.p().__(\"Log Type: \" + candidate.getFileName()).__();\n          html.p().__(\"Log Upload Time: \" +\n              Times.format(candidate.getLastModifiedTime())).__();\n          html.p().__(\"Log Length: \" + Long.toString(logLength)).__();\n\n          long[] range \u003d checkParseRange(html, start, end, startTime, endTime,\n              logLength, candidate.getFileName());\n          processContainerLog(html, range, in, bufferSize, cbuf);\n\n          foundLog \u003d true;\n        } catch (Exception ex) {\n          LOG.error(\"Error getting logs for \" + logEntity, ex);\n          continue;\n        } finally {\n          IOUtils.closeQuietly(in);\n        }\n      }\n    }\n    return foundLog;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/filecontroller/ifile/IndexedFileAggregatedLogsBlock.java",
      "extendedDetails": {}
    },
    "74411ce0ce7336c0f7bb5793939fdd64a5dcdef6": {
      "type": "Yintroduced",
      "commitMessage": "YARN-7417. Remove duplicated code from IndexedFileAggregatedLogsBlock\n           and TFileAggregatedLogsBlock.\n           Contributed by Zian Chen\n",
      "commitDate": "13/08/18 1:50 PM",
      "commitName": "74411ce0ce7336c0f7bb5793939fdd64a5dcdef6",
      "commitAuthor": "Eric Yang",
      "diff": "@@ -0,0 +1,45 @@\n+  private boolean readContainerLog(String compressAlgo, Block html,\n+      FileStatus thisNodeFile, long start, long end,\n+      List\u003cIndexedFileLogMeta\u003e candidates, long startTime, long endTime,\n+      boolean foundLog, String logEntity) throws IOException {\n+    Algorithm compressName \u003d Compression.getCompressionAlgorithmByName(\n+        compressAlgo);\n+    Decompressor decompressor \u003d compressName.getDecompressor();\n+    FileContext fileContext \u003d FileContext.getFileContext(\n+        thisNodeFile.getPath().toUri(), conf);\n+    FSDataInputStream fsin \u003d fileContext.open(thisNodeFile.getPath());\n+    int bufferSize \u003d 65536;\n+    for (IndexedFileLogMeta candidate : candidates) {\n+      if (candidate.getLastModifiedTime() \u003c startTime\n+          || candidate.getLastModifiedTime() \u003e endTime) {\n+        continue;\n+      }\n+      byte[] cbuf \u003d new byte[bufferSize];\n+      InputStream in \u003d null;\n+      try {\n+        in \u003d compressName.createDecompressionStream(\n+            new BoundedRangeFileInputStream(fsin, candidate.getStartIndex(),\n+                candidate.getFileCompressedSize()), decompressor,\n+            LogAggregationIndexedFileController.getFSInputBufferSize(conf));\n+        long logLength \u003d candidate.getFileSize();\n+        html.pre().__(\"\\n\\n\").__();\n+        html.p().__(\"Log Type: \" + candidate.getFileName()).__();\n+        html.p().__(\n+            \"Log Upload Time: \" + Times.format(candidate.getLastModifiedTime()))\n+            .__();\n+        html.p().__(\"Log Length: \" + Long.toString(logLength)).__();\n+\n+        long[] range \u003d checkParseRange(html, start, end, startTime, endTime,\n+            logLength, candidate.getFileName());\n+        processContainerLog(html, range, in, bufferSize, cbuf);\n+\n+        foundLog \u003d true;\n+      } catch (Exception ex) {\n+        LOG.error(\"Error getting logs for \" + logEntity, ex);\n+        continue;\n+      } finally {\n+        IOUtils.closeQuietly(in);\n+      }\n+    }\n+    return foundLog;\n+  }\n\\ No newline at end of file\n",
      "actualSource": "  private boolean readContainerLog(String compressAlgo, Block html,\n      FileStatus thisNodeFile, long start, long end,\n      List\u003cIndexedFileLogMeta\u003e candidates, long startTime, long endTime,\n      boolean foundLog, String logEntity) throws IOException {\n    Algorithm compressName \u003d Compression.getCompressionAlgorithmByName(\n        compressAlgo);\n    Decompressor decompressor \u003d compressName.getDecompressor();\n    FileContext fileContext \u003d FileContext.getFileContext(\n        thisNodeFile.getPath().toUri(), conf);\n    FSDataInputStream fsin \u003d fileContext.open(thisNodeFile.getPath());\n    int bufferSize \u003d 65536;\n    for (IndexedFileLogMeta candidate : candidates) {\n      if (candidate.getLastModifiedTime() \u003c startTime\n          || candidate.getLastModifiedTime() \u003e endTime) {\n        continue;\n      }\n      byte[] cbuf \u003d new byte[bufferSize];\n      InputStream in \u003d null;\n      try {\n        in \u003d compressName.createDecompressionStream(\n            new BoundedRangeFileInputStream(fsin, candidate.getStartIndex(),\n                candidate.getFileCompressedSize()), decompressor,\n            LogAggregationIndexedFileController.getFSInputBufferSize(conf));\n        long logLength \u003d candidate.getFileSize();\n        html.pre().__(\"\\n\\n\").__();\n        html.p().__(\"Log Type: \" + candidate.getFileName()).__();\n        html.p().__(\n            \"Log Upload Time: \" + Times.format(candidate.getLastModifiedTime()))\n            .__();\n        html.p().__(\"Log Length: \" + Long.toString(logLength)).__();\n\n        long[] range \u003d checkParseRange(html, start, end, startTime, endTime,\n            logLength, candidate.getFileName());\n        processContainerLog(html, range, in, bufferSize, cbuf);\n\n        foundLog \u003d true;\n      } catch (Exception ex) {\n        LOG.error(\"Error getting logs for \" + logEntity, ex);\n        continue;\n      } finally {\n        IOUtils.closeQuietly(in);\n      }\n    }\n    return foundLog;\n  }",
      "path": "hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/logaggregation/filecontroller/ifile/IndexedFileAggregatedLogsBlock.java"
    }
  }
}